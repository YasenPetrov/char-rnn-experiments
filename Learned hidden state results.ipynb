{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from time import time\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Softmax\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from datautils.dataset import Alphabet, to_categorical, SentenceDataset, Dataset\n",
    "from models.utils import RNN_Hyperparameters\n",
    "from models.rnn import get_rnn_for_hyperparams\n",
    "\n",
    "from training import evaluate_rnn, evaluate_rnn_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "\n",
    "exp_dir = '../rnn-experiment-storage/22_en_60_b250_lstm_1024/'\n",
    "\n",
    "model_id = '0'\n",
    "\n",
    "alphabet = Alphabet.from_json(os.path.join(exp_dir, 'alphabet.json'))\n",
    "\n",
    "results_file = os.path.join(exp_dir, 'out/results.json')\n",
    "with open(results_file, 'r') as fp:\n",
    "    exp_results = json.load(fp)\n",
    "\n",
    "hyperparams = RNN_Hyperparameters(**exp_results[str(model_id)]['config'])\n",
    "\n",
    "model = get_rnn_for_hyperparams(hyperparams, alphabet.get_size(), use_gpu)\n",
    "\n",
    "checkpoint_path = exp_results[str(model_id)]['path']\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "hidden_states_folder = os.path.join(exp_dir, 'out', model_id, 'init_hiddens')\n",
    "\n",
    "df = None\n",
    "\n",
    "for fold in os.listdir(hidden_states_folder):\n",
    "    with open(os.path.join(hidden_states_folder, fold, 'stats.json'), 'r') as fp:\n",
    "        stats = json.load(fp)\n",
    "        stats['min_val_loss'] = min(stats['valid_losses'])\n",
    "        stats['init_val_loss'] = stats['valid_losses'][0]\n",
    "\n",
    "    with open(os.path.join(hidden_states_folder, fold, 'stats.json'), 'w') as fp:\n",
    "        json.dump(stats, fp, indent=2)\n",
    "\n",
    "    del stats['train_losses']\n",
    "    del stats['valid_losses']\n",
    "    stats['id'] = fold\n",
    "    if df is None:\n",
    "        df = pd.DataFrame(stats)\n",
    "    else:\n",
    "        df = df.append(pd.DataFrame(stats))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_timesteps</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_files_list</th>\n",
       "      <th>valid_files_list</th>\n",
       "      <th>min_val_loss</th>\n",
       "      <th>init_val_loss</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>2.098500</td>\n",
       "      <td>4.847192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>2.102540</td>\n",
       "      <td>4.847192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>2.177338</td>\n",
       "      <td>4.847192</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>2.269687</td>\n",
       "      <td>4.847192</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>2.355624</td>\n",
       "      <td>4.847192</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>4.847192</td>\n",
       "      <td>4.847192</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>1.583148</td>\n",
       "      <td>3.101713</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>1.586567</td>\n",
       "      <td>3.101713</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>1.651159</td>\n",
       "      <td>3.101713</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>1.707644</td>\n",
       "      <td>3.101713</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>1.777724</td>\n",
       "      <td>3.101713</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>3.101713</td>\n",
       "      <td>3.101713</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>1.413729</td>\n",
       "      <td>2.237097</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>1.469708</td>\n",
       "      <td>2.237097</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>1.504819</td>\n",
       "      <td>2.237097</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>1.561689</td>\n",
       "      <td>2.237097</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>2.237097</td>\n",
       "      <td>2.237097</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>datasets/es-en/en/train.txt</td>\n",
       "      <td>datasets/es-en/en/valid.txt</td>\n",
       "      <td>2.237097</td>\n",
       "      <td>2.237097</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  num_timesteps   lr  epochs             train_files_list  \\\n",
       "0          10              5  0.3      10  datasets/es-en/en/train.txt   \n",
       "0          10              5  0.1      10  datasets/es-en/en/train.txt   \n",
       "0         100              5  0.9      10  datasets/es-en/en/train.txt   \n",
       "0         100              5  0.3      10  datasets/es-en/en/train.txt   \n",
       "0         100              5  0.1      10  datasets/es-en/en/train.txt   \n",
       "0          10              5  0.9      10  datasets/es-en/en/train.txt   \n",
       "0          10             10  0.3      10  datasets/es-en/en/train.txt   \n",
       "0          10             10  0.1      10  datasets/es-en/en/train.txt   \n",
       "0         100             10  0.9      10  datasets/es-en/en/train.txt   \n",
       "0         100             10  0.3      10  datasets/es-en/en/train.txt   \n",
       "0         100             10  0.1      10  datasets/es-en/en/train.txt   \n",
       "0          10             10  0.9      10  datasets/es-en/en/train.txt   \n",
       "0          10             20  0.1      10  datasets/es-en/en/train.txt   \n",
       "0         100             20  0.9      10  datasets/es-en/en/train.txt   \n",
       "0         100             20  0.3      10  datasets/es-en/en/train.txt   \n",
       "0         100             20  0.1      10  datasets/es-en/en/train.txt   \n",
       "0          10             20  0.3      10  datasets/es-en/en/train.txt   \n",
       "0          10             20  0.9      10  datasets/es-en/en/train.txt   \n",
       "\n",
       "              valid_files_list  min_val_loss  init_val_loss  id  \n",
       "0  datasets/es-en/en/valid.txt      2.098500       4.847192   1  \n",
       "0  datasets/es-en/en/valid.txt      2.102540       4.847192   0  \n",
       "0  datasets/es-en/en/valid.txt      2.177338       4.847192  11  \n",
       "0  datasets/es-en/en/valid.txt      2.269687       4.847192  10  \n",
       "0  datasets/es-en/en/valid.txt      2.355624       4.847192   9  \n",
       "0  datasets/es-en/en/valid.txt      4.847192       4.847192   2  \n",
       "0  datasets/es-en/en/valid.txt      1.583148       3.101713   4  \n",
       "0  datasets/es-en/en/valid.txt      1.586567       3.101713   3  \n",
       "0  datasets/es-en/en/valid.txt      1.651159       3.101713  14  \n",
       "0  datasets/es-en/en/valid.txt      1.707644       3.101713  13  \n",
       "0  datasets/es-en/en/valid.txt      1.777724       3.101713  12  \n",
       "0  datasets/es-en/en/valid.txt      3.101713       3.101713   5  \n",
       "0  datasets/es-en/en/valid.txt      1.413729       2.237097   6  \n",
       "0  datasets/es-en/en/valid.txt      1.469708       2.237097  17  \n",
       "0  datasets/es-en/en/valid.txt      1.504819       2.237097  16  \n",
       "0  datasets/es-en/en/valid.txt      1.561689       2.237097  15  \n",
       "0  datasets/es-en/en/valid.txt      2.237097       2.237097   7  \n",
       "0  datasets/es-en/en/valid.txt      2.237097       2.237097   8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &     0 &      0 &      0 \\\\\n",
      "\\midrule\n",
      "Sequence length         &  5.00 &  10.00 &  20.00 \\\\\n",
      "Best validation loss    &  2.10 &   1.58 &   1.41 \\\\\n",
      "Default validation loss &  4.85 &   3.10 &   2.24 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(by=['num_timesteps', 'min_val_loss'])\n",
    "display(df)\n",
    "\n",
    "dft = df.groupby(['num_timesteps']).head(1)\n",
    "dft = dft[['num_timesteps', 'min_val_loss', 'init_val_loss']]\n",
    "dft = dft.rename(columns={'num_timesteps': 'Sequence length', 'min_val_loss': 'Best validation loss',\n",
    "             'init_val_loss': 'Default validation loss'})\n",
    "print(dft.T.round(2).to_latex(index_names=False, index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sequence length</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best validation loss</th>\n",
       "      <td>2.098500</td>\n",
       "      <td>1.583148</td>\n",
       "      <td>1.413729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Default validation loss</th>\n",
       "      <td>4.847192</td>\n",
       "      <td>3.101713</td>\n",
       "      <td>2.237097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0          0          0\n",
       "Sequence length          5.000000  10.000000  20.000000\n",
       "Best validation loss     2.098500   1.583148   1.413729\n",
       "Default validation loss  4.847192   3.101713   2.237097"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much does a good hidden state decrease the loss on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\studies\\uoe\\fyp\\project\\char-rnn-experiments\\training.py\u001b[0m in \u001b[0;36mevaluate_rnn\u001b[1;34m(model, data, loss_function, num_timesteps, use_gpu, dynamic, learning_rate, record_stats, stats_interval, decay_coef, remove_unknown_tokens, initial_hidden)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;31m# Calculate average loss (see training function if confused by reshaping) and multiply by the number of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;31m# timesteps to get the sum of losses for this batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mtot_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[0mchars_processed\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\variable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     62\u001b[0m     }\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "init_state_id = '6'\n",
    "h = np.load(os.path.join(hidden_states_folder, init_state_id, 'h.npy'))\n",
    "c = np.load(os.path.join(hidden_states_folder, init_state_id, 'c.npy'))\n",
    "\n",
    "init_hidden = (Variable(torch.Tensor(h)), Variable(torch.Tensor(c)))\n",
    "\n",
    "if use_gpu:\n",
    "    init_hidden = (init_hidden[0].cuda(), init_hidden[1].cuda())\n",
    "\n",
    "test_file = 'datasets/es-en/en/test.txt'\n",
    "test_data = Dataset(test_file, alphabet)\n",
    "\n",
    "loss_function = nn.modules.loss.CrossEntropyLoss()\n",
    "num_timesteps = 30\n",
    "\n",
    "stats = {}\n",
    "for dynamic in (False, True):\n",
    "    stats[dynamic] = dict()\n",
    "    for use_init in True, False:\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        ih = init_hidden if use_init else None\n",
    "        _, loss = evaluate_rnn(model, test_data, loss_function, num_timesteps, use_gpu, dynamic=dynamic, learning_rate=0.3,\n",
    "                               initial_hidden=ih, record_stats=False, stats_interval=num_timesteps)\n",
    "        stats[dynamic][use_init] = ss\n",
    "        print(dynamic, use_init, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18b1cd22358>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dynamic in True, False:\n",
    "    for use_init in True, False:\n",
    "        ss = stats[dynamic][use_init]\n",
    "        plt.plot(ss['chars_processed'], ss['loss'], label=f'{dynamic}, {use_init}', alpha=0.5, lw=3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " ( 0  ,.,.) = \n",
       "   4.0742e-05 -2.1260e-03 -9.6314e-04  ...  -3.8516e-09 -1.1363e-09 -2.3503e-05\n",
       " [torch.cuda.FloatTensor of size 1x1x1024 (GPU 0)], Variable containing:\n",
       " ( 0  ,.,.) = \n",
       "   2.2716e-02 -3.1635e-03 -3.5629e-02  ...  -3.9950e-04 -2.0459e-05 -1.4536e-02\n",
       " [torch.cuda.FloatTensor of size 1x1x1024 (GPU 0)])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "LOG_2E = np.log2(np.e)\n",
    "def evaluate_rnn_sentences(model, valid_data, initial_hidden, batch_size, num_timesteps, pad_input, loss_function,\n",
    "                       use_gpu, max_chars=np.inf, dynamic=False, learning_rate=0.1, decay_coef=0):\n",
    "    tot_val_loss = 0\n",
    "    val_chars_processed = 0\n",
    "    val_loss_history = []\n",
    "\n",
    "    if dynamic:\n",
    "        original_weigths = [copy.deepcopy(p.data) for p in model.parameters()]\n",
    "\n",
    "    for inputs, targets in valid_data.get_batch_iterator(batch_size=1, num_timesteps=num_timesteps,\n",
    "                                                         pad_input=pad_input, max_chars_per_file=max_chars):\n",
    "        model.hidden = (Variable(initial_hidden[0].data.mean(1).view(model.num_layers, 1, model.hidden_dim)),\n",
    "                        Variable(initial_hidden[1].data.mean(1).view(model.num_layers, 1, model.hidden_dim)))\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs = Variable(torch.Tensor(inputs)).cuda()\n",
    "            targets = Variable(torch.LongTensor(targets)).cuda()\n",
    "        else:\n",
    "            inputs = Variable(torch.Tensor(inputs))\n",
    "            targets = Variable(torch.LongTensor(targets))\n",
    "\n",
    "        # Forward pass through a batch of sequences - the result is <batch_size x num_timesteps x alphabet_size> -\n",
    "        # the outputs for each sequence in the batch, at every timestep in the sequence\n",
    "        logits = model(inputs)\n",
    "\n",
    "        loss = loss_function(logits.contiguous().view(-1, logits.data.shape[-1]), targets.contiguous().view(-1))\n",
    "\n",
    "        if dynamic:\n",
    "            # Backward pass - compute gradients, propagate gradient information back through the network\n",
    "            loss.backward()\n",
    "\n",
    "            # SGD with global prior update\n",
    "            for p, o in zip(model.parameters(), original_weigths):\n",
    "                p.data += - learning_rate * p.grad.data + decay_coef * (o - p.data)\n",
    "\n",
    "        val_loss_history.append(loss.data[0])\n",
    "        tot_val_loss += loss.data[0] * inputs.shape[1]\n",
    "        val_chars_processed += inputs.shape[1]\n",
    "\n",
    "    val_loss = tot_val_loss / val_chars_processed\n",
    "    return LOG_2E * val_loss, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True 2.7232699394226074\n",
      "False False 1.773155927658081\n",
      "True True 0.3498876988887787\n",
      "True False 0.20157508552074432\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "init_state_id = '6'\n",
    "h = np.load(os.path.join(hidden_states_folder, init_state_id, 'h.npy'))\n",
    "c = np.load(os.path.join(hidden_states_folder, init_state_id, 'c.npy'))\n",
    "\n",
    "init_hidden = (Variable(torch.Tensor(h)), Variable(torch.Tensor(c)))\n",
    "\n",
    "if use_gpu:\n",
    "    init_hidden = (init_hidden[0].cuda(), init_hidden[1].cuda())\n",
    "\n",
    "test_file = 'datasets/en_test.txt'\n",
    "test_data = SentenceDataset([test_file], alphabet)\n",
    "\n",
    "loss_function = nn.modules.loss.CrossEntropyLoss()\n",
    "num_timesteps = 10\n",
    "\n",
    "stats = {}\n",
    "for dynamic in (False, True):\n",
    "    stats[dynamic] = dict()\n",
    "    for use_init in True, False:\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        ih = init_hidden if use_init else model.init_hidden()\n",
    "        _, losses = evaluate_rnn_sentences(model, test_data, initial_hidden=ih, batch_size=1,\n",
    "                                             num_timesteps=num_timesteps, loss_function=loss_function,\n",
    "                                             pad_input=True, use_gpu=True, dynamic=dynamic, learning_rate=0.3)\n",
    "        stats[dynamic][use_init] = losses\n",
    "        print(dynamic, use_init, min(losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
