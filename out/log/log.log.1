2018-02-03 16:25:55,530 __main__ [INFO ] ====================
Starting experiment test_small
====================
2018-02-03 16:25:55,533 __main__ [INFO ] --------------------
2018-02-03 16:25:55,533 __main__ [INFO ] Starting training for model with hyperparameters
2018-02-03 16:25:55,534 __main__ [INFO ] --------------------
2018-02-03 16:25:55,534 __main__ [INFO ] --------------------
2018-02-03 16:25:55,534 __main__ [INFO ] Starting training for model with hyperparameters
2018-02-03 16:25:55,534 __main__ [INFO ] --------------------
2018-02-03 16:25:55,535 __main__ [INFO ] --------------------
2018-02-03 16:25:55,535 __main__ [INFO ] Starting training for model with hyperparameters
2018-02-03 16:25:55,535 __main__ [INFO ] --------------------
2018-02-03 16:25:55,535 __main__ [INFO ] --------------------
2018-02-03 16:25:55,536 __main__ [INFO ] Starting training for model with hyperparameters
2018-02-03 16:25:55,536 __main__ [INFO ] --------------------
2018-02-03 16:27:53,514 __main__ [INFO ] 
====================
Starting experiment test_small
====================
2018-02-03 16:27:53,518 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:27:53,518 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:27:53,519 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:27:53,519 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:48:42,424 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:48:42,426 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:48:42,427 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:48:42,427 __main__ [INFO ] Removing old results directory for this configuration: /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/1
2018-02-03 16:48:42,427 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 91, in <module>
    shutil.rmtree(out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/shutil.py", line 471, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/home/yasen/anaconda3/lib/python3.6/shutil.py", line 469, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/1'
2018-02-03 16:48:42,438 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:48:42,438 __main__ [INFO ] Removing old results directory for this configuration: /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/2
2018-02-03 16:48:42,439 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 91, in <module>
    shutil.rmtree(out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/shutil.py", line 471, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/home/yasen/anaconda3/lib/python3.6/shutil.py", line 469, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/2'
2018-02-03 16:48:42,439 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:48:42,440 __main__ [INFO ] Removing old results directory for this configuration: /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/3
2018-02-03 16:48:42,440 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 91, in <module>
    shutil.rmtree(out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/shutil.py", line 471, in rmtree
    onerror(os.lstat, path, sys.exc_info())
  File "/home/yasen/anaconda3/lib/python3.6/shutil.py", line 469, in rmtree
    orig_st = os.lstat(path)
FileNotFoundError: [Errno 2] No such file or directory: '/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/3'
2018-02-03 16:49:04,477 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:49:04,481 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:49:04,482 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:04,484 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:04,486 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:04,487 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:12,137 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:49:12,140 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:49:12,142 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:12,144 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:12,146 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:12,147 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:27,330 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:49:27,334 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:49:27,335 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:27,351 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:27,352 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:27,353 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:46,601 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:49:46,603 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:49:46,604 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:46,605 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:46,605 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:49:46,606 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:50:26,044 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:50:26,048 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:50:26,049 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:50:26,049 __main__ [INFO ] INFORM!!
2018-02-03 16:50:26,050 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:50:26,050 __main__ [INFO ] INFORM!!
2018-02-03 16:50:26,051 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:50:26,051 __main__ [INFO ] INFORM!!
2018-02-03 16:50:26,052 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:50:26,052 __main__ [INFO ] INFORM!!
2018-02-03 16:50:58,355 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:50:58,358 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:50:58,360 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:50:58,360 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:50:58,363 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:50:58,364 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:05,820 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:51:05,824 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:51:05,825 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:05,827 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:05,830 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:05,831 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:13,585 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:51:13,590 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:51:13,592 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:13,593 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:13,594 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:13,594 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:39,239 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:51:39,243 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:51:39,244 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:39,245 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:39,246 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:39,247 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:55,630 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:51:55,634 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:55,636 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:55,636 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:51:55,637 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:59:48,837 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 16:59:48,839 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 16:59:48,840 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:59:48,841 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 95, in <module>
    model = RNN_LM(hyperparams.hidden_dim, hyperparams.alphabet_size, hyperparams.batch_size,
AttributeError: 'Hyperparameters' object has no attribute 'hidden_dim'
2018-02-03 16:59:48,841 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:59:48,842 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 95, in <module>
    model = RNN_LM(hyperparams.hidden_dim, hyperparams.alphabet_size, hyperparams.batch_size,
AttributeError: 'Hyperparameters' object has no attribute 'hidden_dim'
2018-02-03 16:59:48,842 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:59:48,843 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 95, in <module>
    model = RNN_LM(hyperparams.hidden_dim, hyperparams.alphabet_size, hyperparams.batch_size,
AttributeError: 'Hyperparameters' object has no attribute 'hidden_dim'
2018-02-03 16:59:48,843 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 16:59:48,843 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 95, in <module>
    model = RNN_LM(hyperparams.hidden_dim, hyperparams.alphabet_size, hyperparams.batch_size,
AttributeError: 'Hyperparameters' object has no attribute 'hidden_dim'
2018-02-03 17:00:19,328 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:00:19,331 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:00:19,332 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:00:19,332 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 95, in <module>
    model = RNN_LM(hyperparams.hidden_size, hyperparams.alphabet_size, hyperparams.batch_size,
AttributeError: 'Hyperparameters' object has no attribute 'alphabet_size'
2018-02-03 17:00:19,333 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:00:19,333 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 95, in <module>
    model = RNN_LM(hyperparams.hidden_size, hyperparams.alphabet_size, hyperparams.batch_size,
AttributeError: 'Hyperparameters' object has no attribute 'alphabet_size'
2018-02-03 17:00:19,333 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:00:19,334 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 95, in <module>
    model = RNN_LM(hyperparams.hidden_size, hyperparams.alphabet_size, hyperparams.batch_size,
AttributeError: 'Hyperparameters' object has no attribute 'alphabet_size'
2018-02-03 17:00:19,334 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:00:19,334 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 95, in <module>
    model = RNN_LM(hyperparams.hidden_size, hyperparams.alphabet_size, hyperparams.batch_size,
AttributeError: 'Hyperparameters' object has no attribute 'alphabet_size'
2018-02-03 17:00:32,394 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:00:32,397 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:00:32,398 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:00:32,399 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 97, in <module>
    hyperparams.linear_dropout)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 25, in __init__
    self.rnn = self._create_network()
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 41, in _create_network
    return nn.LSTM(**kwargs)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 365, in __init__
    super(LSTM, self).__init__('LSTM', *args, **kwargs)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 59, in __init__
    self.reset_parameters()
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 120, in reset_parameters
    stdv = 1.0 / math.sqrt(self.hidden_size)
ZeroDivisionError: float division by zero
2018-02-03 17:00:32,423 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:00:32,424 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 97, in <module>
    hyperparams.linear_dropout)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 25, in __init__
    self.rnn = self._create_network()
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 41, in _create_network
    return nn.LSTM(**kwargs)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 365, in __init__
    super(LSTM, self).__init__('LSTM', *args, **kwargs)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 59, in __init__
    self.reset_parameters()
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 120, in reset_parameters
    stdv = 1.0 / math.sqrt(self.hidden_size)
ZeroDivisionError: float division by zero
2018-02-03 17:00:32,425 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:00:32,425 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 97, in <module>
    hyperparams.linear_dropout)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 25, in __init__
    self.rnn = self._create_network()
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 41, in _create_network
    return nn.LSTM(**kwargs)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 365, in __init__
    super(LSTM, self).__init__('LSTM', *args, **kwargs)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 59, in __init__
    self.reset_parameters()
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 120, in reset_parameters
    stdv = 1.0 / math.sqrt(self.hidden_size)
ZeroDivisionError: float division by zero
2018-02-03 17:00:32,426 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:00:32,427 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 97, in <module>
    hyperparams.linear_dropout)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 25, in __init__
    self.rnn = self._create_network()
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 41, in _create_network
    return nn.LSTM(**kwargs)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 365, in __init__
    super(LSTM, self).__init__('LSTM', *args, **kwargs)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 59, in __init__
    self.reset_parameters()
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 120, in reset_parameters
    stdv = 1.0 / math.sqrt(self.hidden_size)
ZeroDivisionError: float division by zero
2018-02-03 17:05:25,842 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:05:25,844 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:05:25,845 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:05:25,845 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:05:30,601 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:05:30,602 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:05:30,639 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:05:30,640 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:05:30,641 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": "SGD",
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:05:30,661 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:22:56,141 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:22:56,161 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:22:56,162 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:22:56,162 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:22:58,820 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 109, in <module>
    optimizer_spec = hyperparams['optimizer']
TypeError: 'Hyperparameters' object is not subscriptable
2018-02-03 17:22:58,822 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:22:58,822 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:22:58,825 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 109, in <module>
    optimizer_spec = hyperparams['optimizer']
TypeError: 'Hyperparameters' object is not subscriptable
2018-02-03 17:22:58,825 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:22:58,825 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:22:58,826 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 109, in <module>
    optimizer_spec = hyperparams['optimizer']
TypeError: 'Hyperparameters' object is not subscriptable
2018-02-03 17:22:58,827 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:22:58,827 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:22:58,829 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 109, in <module>
    optimizer_spec = hyperparams['optimizer']
TypeError: 'Hyperparameters' object is not subscriptable
2018-02-03 17:23:21,225 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:23:21,245 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:23:21,246 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:23:21,246 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:23:21,248 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 115, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 13, in get_optimizer
    return optim.SGD(model, **optimizer_spec['kwargs'])
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/optim/sgd.py", line 56, in __init__
    super(SGD, self).__init__(params, defaults)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/optim/optimizer.py", line 28, in __init__
    self.param_groups = list(params)
TypeError: 'RNN_LM' object is not iterable
2018-02-03 17:23:21,265 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:23:21,265 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:23:21,266 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 115, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 13, in get_optimizer
    return optim.SGD(model, **optimizer_spec['kwargs'])
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/optim/sgd.py", line 56, in __init__
    super(SGD, self).__init__(params, defaults)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/optim/optimizer.py", line 28, in __init__
    self.param_groups = list(params)
TypeError: 'RNN_LM' object is not iterable
2018-02-03 17:23:21,266 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:23:21,267 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:23:21,268 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 115, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 13, in get_optimizer
    return optim.SGD(model, **optimizer_spec['kwargs'])
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/optim/sgd.py", line 56, in __init__
    super(SGD, self).__init__(params, defaults)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/optim/optimizer.py", line 28, in __init__
    self.param_groups = list(params)
TypeError: 'RNN_LM' object is not iterable
2018-02-03 17:23:21,268 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:23:21,268 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:23:21,269 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 115, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 13, in get_optimizer
    return optim.SGD(model, **optimizer_spec['kwargs'])
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/optim/sgd.py", line 56, in __init__
    super(SGD, self).__init__(params, defaults)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/optim/optimizer.py", line 28, in __init__
    self.param_groups = list(params)
TypeError: 'RNN_LM' object is not iterable
2018-02-03 17:25:09,985 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:25:09,987 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:25:09,988 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:25:09,988 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:25:09,990 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 115, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model(), **optimizer_spec['kwargs'])
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
TypeError: forward() missing 1 required positional argument: 'inputs'
2018-02-03 17:25:10,000 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:25:10,000 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:25:10,001 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 115, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model(), **optimizer_spec['kwargs'])
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
TypeError: forward() missing 1 required positional argument: 'inputs'
2018-02-03 17:25:10,002 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:25:10,002 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:25:10,003 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 115, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model(), **optimizer_spec['kwargs'])
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
TypeError: forward() missing 1 required positional argument: 'inputs'
2018-02-03 17:25:10,003 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:25:10,004 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:25:10,005 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 115, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model(), **optimizer_spec['kwargs'])
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 224, in __call__
    result = self.forward(*input, **kwargs)
TypeError: forward() missing 1 required positional argument: 'inputs'
2018-02-03 17:25:30,002 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:25:30,004 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:25:30,005 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:25:30,005 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:25:30,007 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:25:30,007 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:25:30,008 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:25:30,008 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:25:30,009 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:25:30,010 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:13,186 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:26:13,189 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:26:13,190 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:13,190 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:13,274 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:13,274 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:13,279 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:13,279 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:13,283 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:13,284 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:31,394 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:26:31,396 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:26:31,397 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:31,397 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:31,399 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 116, in <module>
    print(optimizer.__dict__['lr'])
KeyError: 'lr'
2018-02-03 17:26:31,399 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:31,400 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:31,401 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 116, in <module>
    print(optimizer.__dict__['lr'])
KeyError: 'lr'
2018-02-03 17:26:31,401 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:31,401 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:31,402 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 116, in <module>
    print(optimizer.__dict__['lr'])
KeyError: 'lr'
2018-02-03 17:26:31,403 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:31,403 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:31,404 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 116, in <module>
    print(optimizer.__dict__['lr'])
KeyError: 'lr'
2018-02-03 17:26:41,646 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:26:41,649 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:26:41,650 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:41,650 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:41,653 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:41,653 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:41,654 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:41,654 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:26:41,655 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:26:41,655 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:27:42,503 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 17:27:42,505 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 17:27:42,506 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:27:42,507 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:27:42,508 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 117, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model.parameters(), **optimizer_spec['kwargs'])
TypeError: __init__() got an unexpected keyword argument 'gosho'
2018-02-03 17:27:42,509 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "gosho": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:27:42,509 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:27:42,510 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 117, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model.parameters(), **optimizer_spec['kwargs'])
TypeError: __init__() got an unexpected keyword argument 'gosho'
2018-02-03 17:27:42,511 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:27:42,511 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:27:42,512 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 117, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model.parameters(), **optimizer_spec['kwargs'])
TypeError: __init__() got an unexpected keyword argument 'gosho'
2018-02-03 17:27:42,512 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "gosho": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 17:27:42,512 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 17:27:42,513 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 117, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model.parameters(), **optimizer_spec['kwargs'])
TypeError: __init__() got an unexpected keyword argument 'gosho'
2018-02-03 18:27:59,888 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:27:59,929 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:27:59,930 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:27:59,930 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:28:00,369 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 135, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 75, in train_rnn
    loss = loss_function(logits.view(-1, logits.data.shape[-1]), targets.view(-1))
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py", line 510, in view
    return View.apply(self, sizes)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py", line 96, in forward
    result = i.view(*sizes)
RuntimeError: invalid argument 1: input is not contiguous at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/TH/generic/THTensor.c:231
2018-02-03 18:28:00,392 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:28:00,392 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:28:00,411 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 135, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 75, in train_rnn
    loss = loss_function(logits.view(-1, logits.data.shape[-1]), targets.view(-1))
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py", line 510, in view
    return View.apply(self, sizes)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py", line 96, in forward
    result = i.view(*sizes)
RuntimeError: invalid argument 1: input is not contiguous at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/TH/generic/THTensor.c:231
2018-02-03 18:28:00,423 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:28:00,423 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:28:00,443 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 135, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 75, in train_rnn
    loss = loss_function(logits.view(-1, logits.data.shape[-1]), targets.view(-1))
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py", line 510, in view
    return View.apply(self, sizes)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py", line 96, in forward
    result = i.view(*sizes)
RuntimeError: invalid argument 1: input is not contiguous at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/TH/generic/THTensor.c:231
2018-02-03 18:28:00,443 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:28:00,444 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:28:00,499 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "experiment.py", line 135, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 75, in train_rnn
    loss = loss_function(logits.view(-1, logits.data.shape[-1]), targets.view(-1))
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py", line 510, in view
    return View.apply(self, sizes)
  File "/home/yasen/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py", line 96, in forward
    result = i.view(*sizes)
RuntimeError: invalid argument 1: input is not contiguous at /opt/conda/conda-bld/pytorch_1503965122592/work/torch/lib/TH/generic/THTensor.c:231
2018-02-03 18:28:36,219 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:28:36,222 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:28:36,223 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:28:36,223 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:29:23,650 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:29:23,714 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:29:23,730 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:29:23,730 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:30:01,087 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:30:01,089 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:30:01,090 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:30:01,090 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:30:44,628 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:30:44,631 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:30:44,632 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:30:44,632 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:34:48,765 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:34:48,806 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:34:48,806 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:34:48,823 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:35:41,332 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:35:41,335 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:35:41,335 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:35:41,335 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:36:30,031 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:36:30,034 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:36:30,036 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:36:30,036 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:38:57,300 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:38:57,302 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:38:57,303 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:38:57,304 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:39:38,386 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:39:38,389 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:39:38,391 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:39:38,391 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:40:12,887 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:40:12,890 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:40:12,891 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:40:12,891 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:40:14,134 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:14,807 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:15,396 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:15,929 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:16,464 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:16,985 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:17,520 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:18,164 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:18,839 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:19,532 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:20,194 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:20,861 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:21,524 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:22,196 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:22,877 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:23,543 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:24,209 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:24,873 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:25,414 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:25,925 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:26,410 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:26,906 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:27,445 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:27,975 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:28,532 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:29,197 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:29,759 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:30,421 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:40:31,102 trainutils.trainutils [WARNI] Overwriting log in /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out/0/train_log.json
2018-02-03 18:41:03,327 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:41:03,330 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:41:03,331 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:41:03,331 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:41:04,998 training [INFO ] Epoch  1 Batch   50 Training err. 4.04818 Training err. RA 4.04818 Valid. err. 3.55375
2018-02-03 18:41:06,663 training [INFO ] Epoch  1 Batch  100 Training err. 3.40990 Training err. RA 3.72904 Valid. err. 3.30926
2018-02-03 18:41:08,304 training [INFO ] Epoch  1 Batch  150 Training err. 3.28412 Training err. RA 3.58073 Valid. err. 3.28706
2018-02-03 18:41:10,072 training [INFO ] Epoch  1 Batch  200 Training err. 3.26695 Training err. RA 3.50229 Valid. err. 3.25592
2018-02-03 18:41:11,727 training [INFO ] Epoch  1 Batch  250 Training err. 3.22096 Training err. RA 3.44602 Valid. err. 3.25790
2018-02-03 18:41:13,388 training [INFO ] Epoch  1 Batch  300 Training err. 3.26952 Training err. RA 3.41660 Valid. err. 3.22135
2018-02-03 18:41:15,484 training [INFO ] Epoch  2 Batch  350 Training err. 3.22435 Training err. RA 3.38914 Valid. err. 3.23549
2018-02-03 18:41:16,749 training [INFO ] Epoch  2 Batch  400 Training err. 3.22693 Training err. RA 3.36886 Valid. err. 3.24152
2018-02-03 18:41:18,553 training [INFO ] Epoch  2 Batch  450 Training err. 3.21566 Training err. RA 3.35184 Valid. err. 3.20923
2018-02-03 18:41:20,355 training [INFO ] Epoch  2 Batch  500 Training err. 3.20564 Training err. RA 3.33722 Valid. err. 3.21650
2018-02-03 18:41:22,125 training [INFO ] Epoch  2 Batch  550 Training err. 3.18777 Training err. RA 3.32363 Valid. err. 3.21887
2018-02-03 18:41:25,028 training [INFO ] Epoch  2 Batch  600 Training err. 3.20787 Training err. RA 3.31399 Valid. err. 3.17208
2018-02-03 18:41:27,291 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:41:27,291 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:41:29,526 training [INFO ] Epoch  1 Batch   50 Training err. 4.01334 Training err. RA 4.01334 Valid. err. 3.49057
2018-02-03 18:41:31,690 training [INFO ] Epoch  1 Batch  100 Training err. 3.37464 Training err. RA 3.69399 Valid. err. 3.29958
2018-02-03 18:41:33,671 training [INFO ] Epoch  1 Batch  150 Training err. 3.27154 Training err. RA 3.55317 Valid. err. 3.24877
2018-02-03 18:41:37,281 training [INFO ] Epoch  1 Batch  200 Training err. 3.25628 Training err. RA 3.47895 Valid. err. 3.23240
2018-02-03 18:41:40,658 training [INFO ] Epoch  2 Batch  250 Training err. 3.25450 Training err. RA 3.43406 Valid. err. 3.25581
2018-02-03 18:41:42,801 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.39795 Valid. err. 3.22068
2018-02-03 18:41:44,970 training [INFO ] Epoch  2 Batch  350 Training err. 3.21523 Training err. RA 3.37185 Valid. err. 3.22596
2018-02-03 18:41:48,043 training [INFO ] Epoch  2 Batch  400 Training err. 3.22136 Training err. RA 3.35304 Valid. err. 3.20094
2018-02-03 18:41:50,267 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:41:50,267 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:41:51,754 training [INFO ] Epoch  1 Batch   50 Training err. 4.27390 Training err. RA 4.27390 Valid. err. 4.07735
2018-02-03 18:41:53,111 training [INFO ] Epoch  1 Batch  100 Training err. 3.92485 Training err. RA 4.09937 Valid. err. 3.66197
2018-02-03 18:41:54,408 training [INFO ] Epoch  1 Batch  150 Training err. 3.59839 Training err. RA 3.93238 Valid. err. 3.42593
2018-02-03 18:41:55,537 training [INFO ] Epoch  1 Batch  200 Training err. 3.43520 Training err. RA 3.80808 Valid. err. 3.34822
2018-02-03 18:41:56,683 training [INFO ] Epoch  1 Batch  250 Training err. 3.35460 Training err. RA 3.71739 Valid. err. 3.31543
2018-02-03 18:41:57,955 training [INFO ] Epoch  1 Batch  300 Training err. 3.33894 Training err. RA 3.65431 Valid. err. 3.28913
2018-02-03 18:42:00,134 training [INFO ] Epoch  2 Batch  350 Training err. 3.30511 Training err. RA 3.60443 Valid. err. 3.27012
2018-02-03 18:42:01,600 training [INFO ] Epoch  2 Batch  400 Training err. 3.29710 Training err. RA 3.56601 Valid. err. 3.25450
2018-02-03 18:42:03,104 training [INFO ] Epoch  2 Batch  450 Training err. 3.24637 Training err. RA 3.53050 Valid. err. 3.26129
2018-02-03 18:42:04,242 training [INFO ] Epoch  2 Batch  500 Training err. 3.22640 Training err. RA 3.50009 Valid. err. 3.26235
2018-02-03 18:42:05,347 training [INFO ] Epoch  2 Batch  550 Training err. 3.26993 Training err. RA 3.47916 Valid. err. 3.24479
2018-02-03 18:42:06,509 training [INFO ] Epoch  2 Batch  600 Training err. 3.24798 Training err. RA 3.45990 Valid. err. 3.23187
2018-02-03 18:42:07,945 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:42:07,945 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:42:09,587 training [INFO ] Epoch  1 Batch   50 Training err. 4.26460 Training err. RA 4.26460 Valid. err. 4.06014
2018-02-03 18:42:12,216 training [INFO ] Epoch  1 Batch  100 Training err. 3.89402 Training err. RA 4.07931 Valid. err. 3.61558
2018-02-03 18:42:14,963 training [INFO ] Epoch  1 Batch  150 Training err. 3.54984 Training err. RA 3.90282 Valid. err. 3.40147
2018-02-03 18:42:17,364 training [INFO ] Epoch  1 Batch  200 Training err. 3.40647 Training err. RA 3.77873 Valid. err. 3.33074
2018-02-03 18:42:19,576 training [INFO ] Epoch  2 Batch  250 Training err. 3.34417 Training err. RA 3.69182 Valid. err. 3.29182
2018-02-03 18:42:21,118 training [INFO ] Epoch  2 Batch  300 Training err. 3.29997 Training err. RA 3.62651 Valid. err. 3.27235
2018-02-03 18:42:22,659 training [INFO ] Epoch  2 Batch  350 Training err. 3.28069 Training err. RA 3.57711 Valid. err. 3.25439
2018-02-03 18:42:24,186 training [INFO ] Epoch  2 Batch  400 Training err. 3.26423 Training err. RA 3.53800 Valid. err. 3.24165
2018-02-03 18:47:41,336 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:47:41,339 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:47:41,342 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:47:41,342 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:47:42,933 training [INFO ] Epoch  1 Batch   50 Training err. 4.06816 Training err. RA 4.06816 Valid. err. 3.57432
2018-02-03 18:47:44,216 training [INFO ] Epoch  1 Batch  100 Training err. 3.42509 Training err. RA 3.74662 Valid. err. 3.30983
2018-02-03 18:47:45,629 training [INFO ] Epoch  1 Batch  150 Training err. 3.28561 Training err. RA 3.59295 Valid. err. 3.28474
2018-02-03 18:47:47,398 training [INFO ] Epoch  1 Batch  200 Training err. 3.26794 Training err. RA 3.51170 Valid. err. 3.25677
2018-02-03 18:47:49,172 training [INFO ] Epoch  1 Batch  250 Training err. 3.22189 Training err. RA 3.45374 Valid. err. 3.25910
2018-02-03 18:47:50,964 training [INFO ] Epoch  1 Batch  300 Training err. 3.26959 Training err. RA 3.42305 Valid. err. 3.22244
2018-02-03 18:47:53,414 training [INFO ] Epoch  2 Batch  350 Training err. 3.22613 Training err. RA 3.39491 Valid. err. 3.23577
2018-02-03 18:47:55,148 training [INFO ] Epoch  2 Batch  400 Training err. 3.22731 Training err. RA 3.37396 Valid. err. 3.24117
2018-02-03 18:47:56,813 training [INFO ] Epoch  2 Batch  450 Training err. 3.21652 Training err. RA 3.35647 Valid. err. 3.21083
2018-02-03 18:47:58,490 training [INFO ] Epoch  2 Batch  500 Training err. 3.20765 Training err. RA 3.34159 Valid. err. 3.21768
2018-02-03 18:48:00,232 training [INFO ] Epoch  2 Batch  550 Training err. 3.19085 Training err. RA 3.32789 Valid. err. 3.22489
2018-02-03 18:48:02,008 training [INFO ] Epoch  2 Batch  600 Training err. 3.20995 Training err. RA 3.31806 Valid. err. 3.17574
2018-02-03 18:48:03,628 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:48:03,629 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:48:05,842 training [INFO ] Epoch  1 Batch   50 Training err. 4.01334 Training err. RA 4.01334 Valid. err. 3.49057
2018-02-03 18:48:09,521 training [INFO ] Epoch  1 Batch  100 Training err. 3.37464 Training err. RA 3.69399 Valid. err. 3.29958
2018-02-03 18:48:12,153 training [INFO ] Epoch  1 Batch  150 Training err. 3.27154 Training err. RA 3.55317 Valid. err. 3.24877
2018-02-03 18:48:14,428 training [INFO ] Epoch  1 Batch  200 Training err. 3.25628 Training err. RA 3.47895 Valid. err. 3.23240
2018-02-03 18:48:17,269 training [INFO ] Epoch  2 Batch  250 Training err. 3.25450 Training err. RA 3.43406 Valid. err. 3.25581
2018-02-03 18:48:20,597 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.39795 Valid. err. 3.22068
2018-02-03 18:48:23,896 training [INFO ] Epoch  2 Batch  350 Training err. 3.21523 Training err. RA 3.37185 Valid. err. 3.22596
2018-02-03 18:48:26,262 training [INFO ] Epoch  2 Batch  400 Training err. 3.22136 Training err. RA 3.35304 Valid. err. 3.20094
2018-02-03 18:48:27,722 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:48:27,723 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:48:28,960 training [INFO ] Epoch  1 Batch   50 Training err. 4.27390 Training err. RA 4.27390 Valid. err. 4.07735
2018-02-03 18:48:30,348 training [INFO ] Epoch  1 Batch  100 Training err. 3.92485 Training err. RA 4.09937 Valid. err. 3.66197
2018-02-03 18:48:32,811 training [INFO ] Epoch  1 Batch  150 Training err. 3.59839 Training err. RA 3.93238 Valid. err. 3.42593
2018-02-03 18:48:35,040 training [INFO ] Epoch  1 Batch  200 Training err. 3.43520 Training err. RA 3.80808 Valid. err. 3.34822
2018-02-03 18:48:36,494 training [INFO ] Epoch  1 Batch  250 Training err. 3.35460 Training err. RA 3.71739 Valid. err. 3.31543
2018-02-03 18:48:37,847 training [INFO ] Epoch  1 Batch  300 Training err. 3.33894 Training err. RA 3.65431 Valid. err. 3.28913
2018-02-03 18:48:39,381 training [INFO ] Epoch  2 Batch  350 Training err. 3.30511 Training err. RA 3.60443 Valid. err. 3.27012
2018-02-03 18:48:40,614 training [INFO ] Epoch  2 Batch  400 Training err. 3.29710 Training err. RA 3.56601 Valid. err. 3.25450
2018-02-03 18:48:42,024 training [INFO ] Epoch  2 Batch  450 Training err. 3.24637 Training err. RA 3.53050 Valid. err. 3.26129
2018-02-03 18:48:43,613 training [INFO ] Epoch  2 Batch  500 Training err. 3.22640 Training err. RA 3.50009 Valid. err. 3.26235
2018-02-03 18:48:45,243 training [INFO ] Epoch  2 Batch  550 Training err. 3.26993 Training err. RA 3.47916 Valid. err. 3.24479
2018-02-03 18:48:46,572 training [INFO ] Epoch  2 Batch  600 Training err. 3.24798 Training err. RA 3.45990 Valid. err. 3.23187
2018-02-03 18:48:47,773 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:48:47,774 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:48:49,513 training [INFO ] Epoch  1 Batch   50 Training err. 4.26460 Training err. RA 4.26460 Valid. err. 4.06014
2018-02-03 18:48:51,555 training [INFO ] Epoch  1 Batch  100 Training err. 3.89402 Training err. RA 4.07931 Valid. err. 3.61558
2018-02-03 18:48:55,528 training [INFO ] Epoch  1 Batch  150 Training err. 3.54984 Training err. RA 3.90282 Valid. err. 3.40147
2018-02-03 18:48:58,520 training [INFO ] Epoch  1 Batch  200 Training err. 3.40647 Training err. RA 3.77873 Valid. err. 3.33074
2018-02-03 18:49:00,636 training [INFO ] Epoch  2 Batch  250 Training err. 3.34417 Training err. RA 3.69182 Valid. err. 3.29182
2018-02-03 18:49:03,190 training [INFO ] Epoch  2 Batch  300 Training err. 3.29997 Training err. RA 3.62651 Valid. err. 3.27235
2018-02-03 18:49:04,594 training [INFO ] Epoch  2 Batch  350 Training err. 3.28069 Training err. RA 3.57711 Valid. err. 3.25439
2018-02-03 18:49:05,994 training [INFO ] Epoch  2 Batch  400 Training err. 3.26423 Training err. RA 3.53800 Valid. err. 3.24165
2018-02-03 18:49:40,748 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:49:40,750 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:49:40,754 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:49:40,754 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:49:42,652 training [INFO ] Epoch  1 Batch   50 Training err. 4.01097 Training err. RA 4.01097 Valid. err. 3.52268
2018-02-03 18:49:44,641 training [INFO ] Epoch  1 Batch  100 Training err. 3.40803 Training err. RA 3.70950 Valid. err. 3.30227
2018-02-03 18:49:46,604 training [INFO ] Epoch  1 Batch  150 Training err. 3.28140 Training err. RA 3.56680 Valid. err. 3.28168
2018-02-03 18:49:48,726 training [INFO ] Epoch  1 Batch  200 Training err. 3.26400 Training err. RA 3.49110 Valid. err. 3.25452
2018-02-03 18:49:50,447 training [INFO ] Epoch  1 Batch  250 Training err. 3.21972 Training err. RA 3.43682 Valid. err. 3.25669
2018-02-03 18:49:52,257 training [INFO ] Epoch  1 Batch  300 Training err. 3.26934 Training err. RA 3.40891 Valid. err. 3.22111
2018-02-03 18:49:54,807 training [INFO ] Epoch  2 Batch  350 Training err. 3.22513 Training err. RA 3.38266 Valid. err. 3.23380
2018-02-03 18:49:57,325 training [INFO ] Epoch  2 Batch  400 Training err. 3.22674 Training err. RA 3.36317 Valid. err. 3.24011
2018-02-03 18:49:59,624 training [INFO ] Epoch  2 Batch  450 Training err. 3.21591 Training err. RA 3.34680 Valid. err. 3.20977
2018-02-03 18:50:03,941 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:50:03,944 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:50:03,945 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:50:03,945 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:50:05,571 training [INFO ] Epoch  1 Batch   50 Training err. 4.05363 Training err. RA 4.05363 Valid. err. 3.53587
2018-02-03 18:50:07,339 training [INFO ] Epoch  1 Batch  100 Training err. 3.40510 Training err. RA 3.72936 Valid. err. 3.30049
2018-02-03 18:50:09,054 training [INFO ] Epoch  1 Batch  150 Training err. 3.27950 Training err. RA 3.57941 Valid. err. 3.28471
2018-02-03 18:50:10,895 training [INFO ] Epoch  1 Batch  200 Training err. 3.26621 Training err. RA 3.50111 Valid. err. 3.25515
2018-02-03 18:50:13,955 training [INFO ] Epoch  1 Batch  250 Training err. 3.22091 Training err. RA 3.44507 Valid. err. 3.25782
2018-02-03 18:50:16,168 training [INFO ] Epoch  1 Batch  300 Training err. 3.26992 Training err. RA 3.41588 Valid. err. 3.22159
2018-02-03 18:50:18,871 training [INFO ] Epoch  2 Batch  350 Training err. 3.22673 Training err. RA 3.38886 Valid. err. 3.23482
2018-02-03 18:50:20,539 training [INFO ] Epoch  2 Batch  400 Training err. 3.22690 Training err. RA 3.36861 Valid. err. 3.24120
2018-02-03 18:50:22,147 training [INFO ] Epoch  2 Batch  450 Training err. 3.21487 Training err. RA 3.35153 Valid. err. 3.21007
2018-02-03 18:50:23,954 training [INFO ] Epoch  2 Batch  500 Training err. 3.20655 Training err. RA 3.33703 Valid. err. 3.21841
2018-02-03 18:50:25,808 training [INFO ] Epoch  2 Batch  550 Training err. 3.18939 Training err. RA 3.32361 Valid. err. 3.22016
2018-02-03 18:50:27,673 training [INFO ] Epoch  2 Batch  600 Training err. 3.21030 Training err. RA 3.31417 Valid. err. 3.17506
2018-02-03 18:50:29,267 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:50:29,268 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:50:31,587 training [INFO ] Epoch  1 Batch   50 Training err. 4.01334 Training err. RA 4.01334 Valid. err. 3.49057
2018-02-03 18:50:34,082 training [INFO ] Epoch  1 Batch  100 Training err. 3.37464 Training err. RA 3.69399 Valid. err. 3.29958
2018-02-03 18:50:36,258 training [INFO ] Epoch  1 Batch  150 Training err. 3.27154 Training err. RA 3.55317 Valid. err. 3.24877
2018-02-03 18:50:38,472 training [INFO ] Epoch  1 Batch  200 Training err. 3.25628 Training err. RA 3.47895 Valid. err. 3.23240
2018-02-03 18:50:41,612 training [INFO ] Epoch  2 Batch  250 Training err. 3.25450 Training err. RA 3.43406 Valid. err. 3.25581
2018-02-03 18:50:45,423 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.39795 Valid. err. 3.22068
2018-02-03 18:50:49,426 training [INFO ] Epoch  2 Batch  350 Training err. 3.21523 Training err. RA 3.37185 Valid. err. 3.22596
2018-02-03 18:50:52,313 training [INFO ] Epoch  2 Batch  400 Training err. 3.22136 Training err. RA 3.35304 Valid. err. 3.20094
2018-02-03 18:50:54,136 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:50:54,137 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:50:55,450 training [INFO ] Epoch  1 Batch   50 Training err. 4.27390 Training err. RA 4.27390 Valid. err. 4.07735
2018-02-03 18:50:56,578 training [INFO ] Epoch  1 Batch  100 Training err. 3.92485 Training err. RA 4.09937 Valid. err. 3.66197
2018-02-03 18:50:57,792 training [INFO ] Epoch  1 Batch  150 Training err. 3.59839 Training err. RA 3.93238 Valid. err. 3.42593
2018-02-03 18:50:58,932 training [INFO ] Epoch  1 Batch  200 Training err. 3.43520 Training err. RA 3.80808 Valid. err. 3.34822
2018-02-03 18:51:00,261 training [INFO ] Epoch  1 Batch  250 Training err. 3.35460 Training err. RA 3.71739 Valid. err. 3.31543
2018-02-03 18:51:01,522 training [INFO ] Epoch  1 Batch  300 Training err. 3.33894 Training err. RA 3.65431 Valid. err. 3.28913
2018-02-03 18:51:03,541 training [INFO ] Epoch  2 Batch  350 Training err. 3.30511 Training err. RA 3.60443 Valid. err. 3.27012
2018-02-03 18:51:04,672 training [INFO ] Epoch  2 Batch  400 Training err. 3.29710 Training err. RA 3.56601 Valid. err. 3.25450
2018-02-03 18:51:05,550 training [INFO ] Epoch  2 Batch  450 Training err. 3.24637 Training err. RA 3.53050 Valid. err. 3.26129
2018-02-03 18:51:06,554 training [INFO ] Epoch  2 Batch  500 Training err. 3.22640 Training err. RA 3.50009 Valid. err. 3.26235
2018-02-03 18:51:07,790 training [INFO ] Epoch  2 Batch  550 Training err. 3.26993 Training err. RA 3.47916 Valid. err. 3.24479
2018-02-03 18:51:09,060 training [INFO ] Epoch  2 Batch  600 Training err. 3.24798 Training err. RA 3.45990 Valid. err. 3.23187
2018-02-03 18:51:10,671 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:51:10,672 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:51:12,277 training [INFO ] Epoch  1 Batch   50 Training err. 4.26460 Training err. RA 4.26460 Valid. err. 4.06014
2018-02-03 18:51:13,691 training [INFO ] Epoch  1 Batch  100 Training err. 3.89402 Training err. RA 4.07931 Valid. err. 3.61558
2018-02-03 18:51:15,114 training [INFO ] Epoch  1 Batch  150 Training err. 3.54984 Training err. RA 3.90282 Valid. err. 3.40147
2018-02-03 18:51:16,801 training [INFO ] Epoch  1 Batch  200 Training err. 3.40647 Training err. RA 3.77873 Valid. err. 3.33074
2018-02-03 18:51:19,624 training [INFO ] Epoch  2 Batch  250 Training err. 3.34417 Training err. RA 3.69182 Valid. err. 3.29182
2018-02-03 18:51:22,809 training [INFO ] Epoch  2 Batch  300 Training err. 3.29997 Training err. RA 3.62651 Valid. err. 3.27235
2018-02-03 18:51:25,395 training [INFO ] Epoch  2 Batch  350 Training err. 3.28069 Training err. RA 3.57711 Valid. err. 3.25439
2018-02-03 18:51:27,560 training [INFO ] Epoch  2 Batch  400 Training err. 3.26423 Training err. RA 3.53800 Valid. err. 3.24165
2018-02-03 18:52:18,979 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 18:52:18,982 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 18:52:18,985 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:52:18,986 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:52:36,634 training [INFO ] Epoch  1 Batch   50 Training err. 4.06936 Training err. RA 4.06936 Valid. err. 3.58583
2018-02-03 18:52:36,888 training [INFO ] Epoch  1 Batch  100 Training err. 3.44065 Training err. RA 3.75500 Valid. err. 3.31394
2018-02-03 18:52:37,143 training [INFO ] Epoch  1 Batch  150 Training err. 3.28609 Training err. RA 3.59870 Valid. err. 3.28418
2018-02-03 18:52:37,395 training [INFO ] Epoch  1 Batch  200 Training err. 3.26543 Training err. RA 3.51538 Valid. err. 3.25391
2018-02-03 18:52:37,771 training [INFO ] Epoch  1 Batch  250 Training err. 3.22008 Training err. RA 3.45632 Valid. err. 3.25663
2018-02-03 18:52:38,023 training [INFO ] Epoch  1 Batch  300 Training err. 3.26813 Training err. RA 3.42496 Valid. err. 3.21928
2018-02-03 18:52:38,559 training [INFO ] Epoch  2 Batch  350 Training err. 3.22319 Training err. RA 3.39613 Valid. err. 3.23196
2018-02-03 18:52:38,811 training [INFO ] Epoch  2 Batch  400 Training err. 3.22310 Training err. RA 3.37450 Valid. err. 3.23659
2018-02-03 18:52:39,064 training [INFO ] Epoch  2 Batch  450 Training err. 3.21174 Training err. RA 3.35642 Valid. err. 3.20582
2018-02-03 18:52:39,320 training [INFO ] Epoch  2 Batch  500 Training err. 3.20184 Training err. RA 3.34096 Valid. err. 3.21122
2018-02-03 18:52:39,571 training [INFO ] Epoch  2 Batch  550 Training err. 3.18453 Training err. RA 3.32674 Valid. err. 3.21485
2018-02-03 18:52:39,824 training [INFO ] Epoch  2 Batch  600 Training err. 3.20555 Training err. RA 3.31664 Valid. err. 3.16860
2018-02-03 18:52:40,119 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:52:40,119 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:52:40,602 training [INFO ] Epoch  1 Batch   50 Training err. 4.06005 Training err. RA 4.06005 Valid. err. 3.57507
2018-02-03 18:52:40,866 training [INFO ] Epoch  1 Batch  100 Training err. 3.40803 Training err. RA 3.73404 Valid. err. 3.31751
2018-02-03 18:52:41,127 training [INFO ] Epoch  1 Batch  150 Training err. 3.27883 Training err. RA 3.58230 Valid. err. 3.25590
2018-02-03 18:52:41,394 training [INFO ] Epoch  1 Batch  200 Training err. 3.25966 Training err. RA 3.50164 Valid. err. 3.23481
2018-02-03 18:52:41,768 training [INFO ] Epoch  2 Batch  250 Training err. 3.25368 Training err. RA 3.45205 Valid. err. 3.25694
2018-02-03 18:52:42,031 training [INFO ] Epoch  2 Batch  300 Training err. 3.21709 Training err. RA 3.41289 Valid. err. 3.22118
2018-02-03 18:52:42,296 training [INFO ] Epoch  2 Batch  350 Training err. 3.21196 Training err. RA 3.38419 Valid. err. 3.22408
2018-02-03 18:52:42,563 training [INFO ] Epoch  2 Batch  400 Training err. 3.21765 Training err. RA 3.36337 Valid. err. 3.19563
2018-02-03 18:52:42,796 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:52:42,797 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:52:43,087 training [INFO ] Epoch  1 Batch   50 Training err. 4.27591 Training err. RA 4.27591 Valid. err. 4.07798
2018-02-03 18:52:43,339 training [INFO ] Epoch  1 Batch  100 Training err. 3.92676 Training err. RA 4.10134 Valid. err. 3.66655
2018-02-03 18:52:43,585 training [INFO ] Epoch  1 Batch  150 Training err. 3.60168 Training err. RA 3.93479 Valid. err. 3.43703
2018-02-03 18:52:43,835 training [INFO ] Epoch  1 Batch  200 Training err. 3.44982 Training err. RA 3.81354 Valid. err. 3.35717
2018-02-03 18:52:44,080 training [INFO ] Epoch  1 Batch  250 Training err. 3.36569 Training err. RA 3.72397 Valid. err. 3.32296
2018-02-03 18:52:44,332 training [INFO ] Epoch  1 Batch  300 Training err. 3.34807 Training err. RA 3.66132 Valid. err. 3.29593
2018-02-03 18:52:44,735 training [INFO ] Epoch  2 Batch  350 Training err. 3.30838 Training err. RA 3.61090 Valid. err. 3.27651
2018-02-03 18:52:44,978 training [INFO ] Epoch  2 Batch  400 Training err. 3.29979 Training err. RA 3.57202 Valid. err. 3.26055
2018-02-03 18:52:45,226 training [INFO ] Epoch  2 Batch  450 Training err. 3.25008 Training err. RA 3.53624 Valid. err. 3.26620
2018-02-03 18:52:45,477 training [INFO ] Epoch  2 Batch  500 Training err. 3.23211 Training err. RA 3.50583 Valid. err. 3.26573
2018-02-03 18:52:45,732 training [INFO ] Epoch  2 Batch  550 Training err. 3.27609 Training err. RA 3.48495 Valid. err. 3.24762
2018-02-03 18:52:45,983 training [INFO ] Epoch  2 Batch  600 Training err. 3.25268 Training err. RA 3.46559 Valid. err. 3.23496
2018-02-03 18:52:46,230 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 2,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 15,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 18:52:46,231 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 18:52:46,508 training [INFO ] Epoch  1 Batch   50 Training err. 4.28636 Training err. RA 4.28636 Valid. err. 4.10963
2018-02-03 18:52:46,769 training [INFO ] Epoch  1 Batch  100 Training err. 3.95495 Training err. RA 4.12066 Valid. err. 3.71769
2018-02-03 18:52:46,997 training [INFO ] Epoch  1 Batch  150 Training err. 3.61779 Training err. RA 3.95304 Valid. err. 3.44749
2018-02-03 18:52:47,224 training [INFO ] Epoch  1 Batch  200 Training err. 3.43405 Training err. RA 3.82329 Valid. err. 3.35611
2018-02-03 18:52:47,580 training [INFO ] Epoch  2 Batch  250 Training err. 3.35883 Training err. RA 3.73040 Valid. err. 3.30817
2018-02-03 18:52:47,800 training [INFO ] Epoch  2 Batch  300 Training err. 3.30994 Training err. RA 3.66032 Valid. err. 3.28409
2018-02-03 18:52:48,021 training [INFO ] Epoch  2 Batch  350 Training err. 3.28947 Training err. RA 3.60734 Valid. err. 3.26352
2018-02-03 18:52:48,253 training [INFO ] Epoch  2 Batch  400 Training err. 3.27004 Training err. RA 3.56518 Valid. err. 3.24806
2018-02-03 19:11:43,230 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 19:11:43,271 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 19:11:43,284 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 19:11:43,284 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 19:19:48,542 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 19:19:48,571 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 19:19:48,572 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 19:19:48,572 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 19:20:02,180 training [INFO ] Epoch  1 Batch   50 Training err. 4.05154 Training err. RA 4.05154 Valid. err. 3.56695
2018-02-03 19:20:02,775 training [INFO ] Epoch  1 Batch  100 Training err. 3.42641 Training err. RA 3.73898 Valid. err. 3.30685
2018-02-03 19:20:03,206 training [INFO ] Epoch  1 Batch  150 Training err. 3.28090 Training err. RA 3.58628 Valid. err. 3.28412
2018-02-03 19:20:03,507 training [INFO ] Epoch  1 Batch  200 Training err. 3.26432 Training err. RA 3.50579 Valid. err. 3.25579
2018-02-03 19:20:03,871 training [INFO ] Epoch  1 Batch  250 Training err. 3.22070 Training err. RA 3.44878 Valid. err. 3.25816
2018-02-03 19:20:04,171 training [INFO ] Epoch  1 Batch  300 Training err. 3.27021 Training err. RA 3.41901 Valid. err. 3.22300
2018-02-03 19:20:04,823 training [INFO ] Epoch  2 Batch  350 Training err. 3.22645 Training err. RA 3.39151 Valid. err. 3.23694
2018-02-03 19:20:05,136 training [INFO ] Epoch  2 Batch  400 Training err. 3.22739 Training err. RA 3.37099 Valid. err. 3.24320
2018-02-03 19:20:05,446 training [INFO ] Epoch  2 Batch  450 Training err. 3.21707 Training err. RA 3.35389 Valid. err. 3.21141
2018-02-03 19:20:05,767 training [INFO ] Epoch  2 Batch  500 Training err. 3.20664 Training err. RA 3.33916 Valid. err. 3.21983
2018-02-03 19:20:06,064 training [INFO ] Epoch  2 Batch  550 Training err. 3.19048 Training err. RA 3.32565 Valid. err. 3.22276
2018-02-03 19:20:06,417 training [INFO ] Epoch  2 Batch  600 Training err. 3.21141 Training err. RA 3.31613 Valid. err. 3.17646
2018-02-03 19:20:06,867 training [INFO ] Epoch  3 Batch  650 Training err. 3.18587 Training err. RA 3.30611 Valid. err. 3.18150
2018-02-03 19:20:07,177 training [INFO ] Epoch  3 Batch  700 Training err. 3.17416 Training err. RA 3.29668 Valid. err. 3.16362
2018-02-03 19:20:07,467 training [INFO ] Epoch  3 Batch  750 Training err. 3.12766 Training err. RA 3.28541 Valid. err. 3.13960
2018-02-03 19:20:07,758 training [INFO ] Epoch  3 Batch  800 Training err. 3.13552 Training err. RA 3.27605 Valid. err. 3.11051
2018-02-03 19:20:08,045 training [INFO ] Epoch  3 Batch  850 Training err. 3.07375 Training err. RA 3.26415 Valid. err. 3.13857
2018-02-03 19:20:08,287 training [INFO ] Epoch  3 Batch  900 Training err. 3.11513 Training err. RA 3.25587 Valid. err. 3.03820
2018-02-03 19:20:08,640 training [INFO ] Epoch  4 Batch  950 Training err. 3.08133 Training err. RA 3.24668 Valid. err. 3.07850
2018-02-03 19:20:08,912 training [INFO ] Epoch  4 Batch 1000 Training err. 3.00947 Training err. RA 3.23482 Valid. err. 2.99756
2018-02-03 19:20:09,156 training [INFO ] Epoch  4 Batch 1050 Training err. 2.94363 Training err. RA 3.22095 Valid. err. 2.96466
2018-02-03 19:20:09,397 training [INFO ] Epoch  4 Batch 1100 Training err. 2.94341 Training err. RA 3.20834 Valid. err. 2.89695
2018-02-03 19:20:09,677 training [INFO ] Epoch  4 Batch 1150 Training err. 2.89915 Training err. RA 3.19490 Valid. err. 2.92819
2018-02-03 19:20:09,972 training [INFO ] Epoch  4 Batch 1200 Training err. 2.89802 Training err. RA 3.18253 Valid. err. 2.83967
2018-02-03 19:20:10,398 training [INFO ] Epoch  5 Batch 1250 Training err. 2.93585 Training err. RA 3.17266 Valid. err. 2.88087
2018-02-03 19:20:10,743 training [INFO ] Epoch  5 Batch 1300 Training err. 2.87494 Training err. RA 3.16121 Valid. err. 2.82516
2018-02-03 19:20:11,063 training [INFO ] Epoch  5 Batch 1350 Training err. 2.77596 Training err. RA 3.14694 Valid. err. 2.80166
2018-02-03 19:20:11,320 training [INFO ] Epoch  5 Batch 1400 Training err. 2.80034 Training err. RA 3.13456 Valid. err. 2.77960
2018-02-03 19:20:11,582 training [INFO ] Epoch  5 Batch 1450 Training err. 2.80276 Training err. RA 3.12312 Valid. err. 2.78305
2018-02-03 19:20:11,826 training [INFO ] Epoch  5 Batch 1500 Training err. 2.76086 Training err. RA 3.11104 Valid. err. 2.72707
2018-02-03 19:20:12,243 training [INFO ] Epoch  6 Batch 1550 Training err. 2.84503 Training err. RA 3.10246 Valid. err. 2.74069
2018-02-03 19:20:12,506 training [INFO ] Epoch  6 Batch 1600 Training err. 2.78506 Training err. RA 3.09254 Valid. err. 2.76814
2018-02-03 19:20:12,807 training [INFO ] Epoch  6 Batch 1650 Training err. 2.70184 Training err. RA 3.08071 Valid. err. 2.71378
2018-02-03 19:20:13,095 training [INFO ] Epoch  6 Batch 1700 Training err. 2.67773 Training err. RA 3.06885 Valid. err. 2.68382
2018-02-03 19:20:13,431 training [INFO ] Epoch  6 Batch 1750 Training err. 2.74970 Training err. RA 3.05973 Valid. err. 2.67609
2018-02-03 19:20:13,739 training [INFO ] Epoch  6 Batch 1800 Training err. 2.64940 Training err. RA 3.04834 Valid. err. 2.64847
2018-02-03 19:20:14,135 training [INFO ] Epoch  7 Batch 1850 Training err. 2.75648 Training err. RA 3.04045 Valid. err. 2.67547
2018-02-03 19:20:14,441 training [INFO ] Epoch  7 Batch 1900 Training err. 2.73593 Training err. RA 3.03243 Valid. err. 2.62883
2018-02-03 19:20:14,733 training [INFO ] Epoch  7 Batch 1950 Training err. 2.62347 Training err. RA 3.02195 Valid. err. 2.60838
2018-02-03 19:20:14,982 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59623 Training err. RA 3.01131 Valid. err. 2.59373
2018-02-03 19:20:15,270 training [INFO ] Epoch  7 Batch 2050 Training err. 2.69528 Training err. RA 3.00360 Valid. err. 2.58789
2018-02-03 19:20:15,527 training [INFO ] Epoch  7 Batch 2100 Training err. 2.56838 Training err. RA 2.99324 Valid. err. 2.56635
2018-02-03 19:20:15,948 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64858 Training err. RA 2.98522 Valid. err. 2.55063
2018-02-03 19:20:16,256 training [INFO ] Epoch  8 Batch 2200 Training err. 2.71313 Training err. RA 2.97904 Valid. err. 2.55588
2018-02-03 19:20:16,559 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58281 Training err. RA 2.97023 Valid. err. 2.54824
2018-02-03 19:20:16,873 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55072 Training err. RA 2.96111 Valid. err. 2.54452
2018-02-03 19:20:17,137 training [INFO ] Epoch  8 Batch 2350 Training err. 2.61219 Training err. RA 2.95369 Valid. err. 2.54435
2018-02-03 19:20:17,384 training [INFO ] Epoch  8 Batch 2400 Training err. 2.50174 Training err. RA 2.94427 Valid. err. 2.50664
2018-02-03 19:20:17,636 training [INFO ] Epoch  8 Batch 2450 Training err. 2.58907 Training err. RA 2.93702 Valid. err. 2.52486
2018-02-03 19:20:17,987 training [INFO ] Epoch  9 Batch 2500 Training err. 2.62521 Training err. RA 2.93079 Valid. err. 2.53231
2018-02-03 19:20:18,231 training [INFO ] Epoch  9 Batch 2550 Training err. 2.58746 Training err. RA 2.92405 Valid. err. 2.48392
2018-02-03 19:20:18,474 training [INFO ] Epoch  9 Batch 2600 Training err. 2.50241 Training err. RA 2.91595 Valid. err. 2.48040
2018-02-03 19:20:18,719 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56517 Training err. RA 2.90933 Valid. err. 2.51307
2018-02-03 19:20:18,955 training [INFO ] Epoch  9 Batch 2700 Training err. 2.45344 Training err. RA 2.90089 Valid. err. 2.50575
2018-02-03 19:20:19,194 training [INFO ] Epoch  9 Batch 2750 Training err. 2.51490 Training err. RA 2.89387 Valid. err. 2.45085
2018-02-03 19:20:19,544 training [INFO ] Epoch 10 Batch 2800 Training err. 2.55903 Training err. RA 2.88789 Valid. err. 2.48255
2018-02-03 19:20:19,781 training [INFO ] Epoch 10 Batch 2850 Training err. 2.57037 Training err. RA 2.88232 Valid. err. 2.45368
2018-02-03 19:20:20,028 training [INFO ] Epoch 10 Batch 2900 Training err. 2.45659 Training err. RA 2.87498 Valid. err. 2.43246
2018-02-03 19:20:20,273 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51037 Training err. RA 2.86880 Valid. err. 2.47586
2018-02-03 19:20:20,522 training [INFO ] Epoch 10 Batch 3000 Training err. 2.43502 Training err. RA 2.86157 Valid. err. 2.41196
2018-02-03 19:20:20,766 training [INFO ] Epoch 10 Batch 3050 Training err. 2.45684 Training err. RA 2.85493 Valid. err. 2.44717
2018-02-03 19:20:20,934 __main__ [INFO ] End of training
2018-02-03 19:20:38,844 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 19:20:38,844 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 19:20:39,245 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004
2018-02-03 19:20:39,678 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220
2018-02-03 19:20:40,148 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708
2018-02-03 19:20:40,476 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226
2018-02-03 19:20:40,830 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791
2018-02-03 19:20:41,091 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095
2018-02-03 19:20:41,346 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617
2018-02-03 19:20:41,604 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091
2018-02-03 19:20:41,951 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571
2018-02-03 19:20:42,204 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752
2018-02-03 19:20:42,467 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115
2018-02-03 19:20:42,730 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850
2018-02-03 19:20:43,134 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007
2018-02-03 19:20:43,416 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578
2018-02-03 19:20:43,726 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063
2018-02-03 19:20:44,011 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541
2018-02-03 19:20:44,367 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331
2018-02-03 19:20:44,645 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885
2018-02-03 19:20:44,931 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402
2018-02-03 19:20:45,218 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876
2018-02-03 19:20:45,581 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261
2018-02-03 19:20:45,857 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771
2018-02-03 19:20:46,134 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434
2018-02-03 19:20:46,400 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230
2018-02-03 19:20:46,771 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620
2018-02-03 19:20:47,035 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672
2018-02-03 19:20:47,302 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298
2018-02-03 19:20:47,563 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529
2018-02-03 19:20:47,923 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410
2018-02-03 19:20:48,195 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609
2018-02-03 19:20:48,463 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099
2018-02-03 19:20:48,903 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653
2018-02-03 19:20:49,499 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570
2018-02-03 19:20:49,763 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963
2018-02-03 19:20:50,028 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815
2018-02-03 19:20:50,268 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999
2018-02-03 19:20:50,611 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695
2018-02-03 19:20:50,860 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245
2018-02-03 19:20:51,116 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415
2018-02-03 19:20:51,376 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328
2018-02-03 19:20:51,628 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049
2018-02-03 19:20:51,724 __main__ [INFO ] End of training
2018-02-03 19:20:51,865 __main__ [INFO ] 
--------------------------------------------------
Starting training for model with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 19:20:51,865 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 19:20:52,129 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945
2018-02-03 19:20:52,394 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585
2018-02-03 19:20:52,650 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036
2018-02-03 19:20:52,900 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844
2018-02-03 19:20:53,150 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920
2018-02-03 19:20:53,531 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863
2018-02-03 19:20:54,105 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650
2018-02-03 19:20:54,461 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923
2018-02-03 19:20:54,727 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288
2018-02-03 19:20:54,996 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297
2018-02-03 19:20:55,253 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633
2018-02-03 19:20:55,517 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329
2018-02-03 19:20:55,876 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222
2018-02-03 19:20:56,139 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798
2018-02-03 19:20:56,430 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300
2018-02-03 19:20:56,712 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864
2018-02-03 19:20:56,979 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590
2018-02-03 19:20:57,307 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607
2018-02-03 19:20:57,716 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056
2018-02-03 19:20:57,997 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954
2018-02-03 19:20:58,297 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403
2018-02-03 19:20:58,563 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444
2018-02-03 19:20:58,858 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682
2018-02-03 19:20:59,133 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167
2018-02-03 19:20:59,516 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971
2018-02-03 19:20:59,780 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051
2018-02-03 19:21:00,077 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551
2018-02-03 19:21:00,364 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389
2018-02-03 19:21:00,648 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053
2018-02-03 19:21:00,917 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556
2018-02-03 19:21:01,266 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131
2018-02-03 19:21:01,523 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897
2018-02-03 19:21:01,777 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355
2018-02-03 19:21:02,055 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367
2018-02-03 19:21:02,325 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858
2018-02-03 19:21:02,639 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398
2018-02-03 19:21:03,032 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153
2018-02-03 19:21:03,302 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232
2018-02-03 19:21:03,618 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708
2018-02-03 19:21:03,905 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540
2018-02-03 19:21:04,182 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636
2018-02-03 19:21:04,448 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333
2018-02-03 19:21:04,807 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953
2018-02-03 19:21:05,091 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544
2018-02-03 19:21:05,357 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447
2018-02-03 19:21:05,667 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667
2018-02-03 19:21:05,946 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969
2018-02-03 19:21:06,251 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715
2018-02-03 19:21:06,531 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796
2018-02-03 19:21:06,905 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617
2018-02-03 19:21:07,168 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010
2018-02-03 19:21:07,433 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204
2018-02-03 19:21:07,692 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228
2018-02-03 19:21:07,958 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751
2018-02-03 19:21:08,227 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178
2018-02-03 19:21:08,586 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059
2018-02-03 19:21:08,855 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651
2018-02-03 19:21:09,116 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126
2018-02-03 19:21:09,385 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984
2018-02-03 19:21:09,649 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388
2018-02-03 19:21:09,930 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202
2018-02-03 19:21:10,100 __main__ [INFO ] End of training
2018-02-03 20:24:08,280 __main__ [INFO ] 
==============================
Starting experiment alice_test
==============================
2018-02-03 20:25:07,993 __main__ [INFO ] 
==============================
Starting experiment alice_test
==============================
2018-02-03 20:27:30,654 __main__ [INFO ] 
==============================
Starting experiment alice_test
==============================
2018-02-03 20:27:30,658 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 2 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1000,
  "num_timesteps": 100,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:27:30,658 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:27:41,231 training [INFO ] Epoch  1 Batch   20 Training err. 4.24471 Training err. RA 4.24471 Valid. err. 4.16787
2018-02-03 20:27:41,706 training [INFO ] Epoch  1 Batch   40 Training err. 4.06793 Training err. RA 4.15632 Valid. err. 4.00114
2018-02-03 20:27:42,174 training [INFO ] Epoch  1 Batch   60 Training err. 3.91353 Training err. RA 4.07539 Valid. err. 3.82120
2018-02-03 20:27:42,639 training [INFO ] Epoch  1 Batch   80 Training err. 3.69047 Training err. RA 3.97916 Valid. err. 3.63040
2018-02-03 20:27:43,108 training [INFO ] Epoch  1 Batch  100 Training err. 3.55667 Training err. RA 3.89466 Valid. err. 3.49288
2018-02-03 20:27:43,578 training [INFO ] Epoch  1 Batch  120 Training err. 3.41290 Training err. RA 3.81437 Valid. err. 3.39046
2018-02-03 20:27:44,438 training [INFO ] Epoch  2 Batch  140 Training err. 3.33793 Training err. RA 3.74631 Valid. err. 3.32358
2018-02-03 20:27:44,903 training [INFO ] Epoch  2 Batch  160 Training err. 3.27147 Training err. RA 3.68695 Valid. err. 3.28009
2018-02-03 20:27:45,375 training [INFO ] Epoch  2 Batch  180 Training err. 3.18967 Training err. RA 3.63170 Valid. err. 3.25800
2018-02-03 20:27:45,839 training [INFO ] Epoch  2 Batch  200 Training err. 3.21026 Training err. RA 3.58955 Valid. err. 3.23892
2018-02-03 20:27:46,303 training [INFO ] Epoch  2 Batch  220 Training err. 3.18706 Training err. RA 3.55296 Valid. err. 3.22664
2018-02-03 20:27:46,764 training [INFO ] Epoch  2 Batch  240 Training err. 3.17583 Training err. RA 3.52154 Valid. err. 3.21922
2018-02-03 20:27:47,232 training [INFO ] Epoch  2 Batch  260 Training err. 3.18833 Training err. RA 3.49590 Valid. err. 3.21068
2018-02-03 20:27:48,041 training [INFO ] Epoch  3 Batch  280 Training err. 3.18717 Training err. RA 3.47385 Valid. err. 3.20579
2018-02-03 20:27:48,508 training [INFO ] Epoch  3 Batch  300 Training err. 3.13844 Training err. RA 3.45149 Valid. err. 3.20900
2018-02-03 20:27:48,976 training [INFO ] Epoch  3 Batch  320 Training err. 3.15053 Training err. RA 3.43268 Valid. err. 3.20038
2018-02-03 20:27:49,443 training [INFO ] Epoch  3 Batch  340 Training err. 3.12171 Training err. RA 3.41439 Valid. err. 3.19835
2018-02-03 20:27:49,906 training [INFO ] Epoch  3 Batch  360 Training err. 3.15895 Training err. RA 3.40020 Valid. err. 3.19500
2018-02-03 20:27:50,368 training [INFO ] Epoch  3 Batch  380 Training err. 3.15056 Training err. RA 3.38706 Valid. err. 3.19386
2018-02-03 20:27:51,166 training [INFO ] Epoch  4 Batch  400 Training err. 3.17922 Training err. RA 3.37667 Valid. err. 3.19137
2018-02-03 20:27:51,631 training [INFO ] Epoch  4 Batch  420 Training err. 3.15166 Training err. RA 3.36595 Valid. err. 3.19017
2018-02-03 20:27:52,096 training [INFO ] Epoch  4 Batch  440 Training err. 3.09201 Training err. RA 3.35350 Valid. err. 3.20116
2018-02-03 20:27:52,562 training [INFO ] Epoch  4 Batch  460 Training err. 3.16005 Training err. RA 3.34509 Valid. err. 3.18795
2018-02-03 20:27:53,027 training [INFO ] Epoch  4 Batch  480 Training err. 3.10352 Training err. RA 3.33502 Valid. err. 3.18844
2018-02-03 20:27:53,492 training [INFO ] Epoch  4 Batch  500 Training err. 3.15379 Training err. RA 3.32777 Valid. err. 3.18642
2018-02-03 20:27:53,965 training [INFO ] Epoch  4 Batch  520 Training err. 3.14556 Training err. RA 3.32077 Valid. err. 3.18749
2018-02-03 20:27:54,768 training [INFO ] Epoch  5 Batch  540 Training err. 3.16493 Training err. RA 3.31499 Valid. err. 3.18489
2018-02-03 20:27:55,228 training [INFO ] Epoch  5 Batch  560 Training err. 3.14300 Training err. RA 3.30885 Valid. err. 3.18511
2018-02-03 20:27:55,691 training [INFO ] Epoch  5 Batch  580 Training err. 3.10147 Training err. RA 3.30170 Valid. err. 3.18505
2018-02-03 20:27:56,157 training [INFO ] Epoch  5 Batch  600 Training err. 3.12199 Training err. RA 3.29571 Valid. err. 3.18460
2018-02-03 20:27:56,623 training [INFO ] Epoch  5 Batch  620 Training err. 3.13044 Training err. RA 3.29038 Valid. err. 3.18281
2018-02-03 20:27:57,091 training [INFO ] Epoch  5 Batch  640 Training err. 3.13310 Training err. RA 3.28546 Valid. err. 3.18426
2018-02-03 20:27:57,572 training [INFO ] Epoch  5 Batch  660 Training err. 3.15304 Training err. RA 3.28145 Valid. err. 3.18082
2018-02-03 20:27:58,370 training [INFO ] Epoch  6 Batch  680 Training err. 3.15765 Training err. RA 3.27781 Valid. err. 3.18086
2018-02-03 20:27:58,836 training [INFO ] Epoch  6 Batch  700 Training err. 3.10444 Training err. RA 3.27286 Valid. err. 3.18708
2018-02-03 20:27:59,305 training [INFO ] Epoch  6 Batch  720 Training err. 3.13003 Training err. RA 3.26889 Valid. err. 3.18079
2018-02-03 20:27:59,774 training [INFO ] Epoch  6 Batch  740 Training err. 3.09177 Training err. RA 3.26410 Valid. err. 3.18208
2018-02-03 20:28:00,247 training [INFO ] Epoch  6 Batch  760 Training err. 3.14151 Training err. RA 3.26088 Valid. err. 3.18006
2018-02-03 20:28:00,710 training [INFO ] Epoch  6 Batch  780 Training err. 3.13257 Training err. RA 3.25759 Valid. err. 3.18001
2018-02-03 20:28:01,500 training [INFO ] Epoch  7 Batch  800 Training err. 3.16544 Training err. RA 3.25528 Valid. err. 3.18075
2018-02-03 20:28:01,964 training [INFO ] Epoch  7 Batch  820 Training err. 3.13272 Training err. RA 3.25229 Valid. err. 3.17843
2018-02-03 20:28:02,424 training [INFO ] Epoch  7 Batch  840 Training err. 3.07952 Training err. RA 3.24818 Valid. err. 3.18628
2018-02-03 20:28:02,885 training [INFO ] Epoch  7 Batch  860 Training err. 3.14158 Training err. RA 3.24570 Valid. err. 3.17791
2018-02-03 20:28:03,345 training [INFO ] Epoch  7 Batch  880 Training err. 3.09797 Training err. RA 3.24234 Valid. err. 3.17770
2018-02-03 20:28:03,812 training [INFO ] Epoch  7 Batch  900 Training err. 3.13379 Training err. RA 3.23993 Valid. err. 3.17640
2018-02-03 20:28:04,278 training [INFO ] Epoch  7 Batch  920 Training err. 3.13708 Training err. RA 3.23769 Valid. err. 3.17571
2018-02-03 20:28:05,080 training [INFO ] Epoch  8 Batch  940 Training err. 3.15216 Training err. RA 3.23587 Valid. err. 3.17439
2018-02-03 20:28:05,546 training [INFO ] Epoch  8 Batch  960 Training err. 3.12872 Training err. RA 3.23364 Valid. err. 3.17624
2018-02-03 20:28:06,012 training [INFO ] Epoch  8 Batch  980 Training err. 3.09306 Training err. RA 3.23077 Valid. err. 3.17550
2018-02-03 20:28:06,480 training [INFO ] Epoch  8 Batch 1000 Training err. 3.10683 Training err. RA 3.22829 Valid. err. 3.17428
2018-02-03 20:28:06,948 training [INFO ] Epoch  8 Batch 1020 Training err. 3.11788 Training err. RA 3.22613 Valid. err. 3.17447
2018-02-03 20:28:07,413 training [INFO ] Epoch  8 Batch 1040 Training err. 3.12289 Training err. RA 3.22414 Valid. err. 3.17458
2018-02-03 20:28:07,881 training [INFO ] Epoch  8 Batch 1060 Training err. 3.14098 Training err. RA 3.22257 Valid. err. 3.17050
2018-02-03 20:28:08,687 training [INFO ] Epoch  9 Batch 1080 Training err. 3.14433 Training err. RA 3.22113 Valid. err. 3.17247
2018-02-03 20:28:09,154 training [INFO ] Epoch  9 Batch 1100 Training err. 3.09121 Training err. RA 3.21876 Valid. err. 3.17794
2018-02-03 20:28:09,618 training [INFO ] Epoch  9 Batch 1120 Training err. 3.12189 Training err. RA 3.21703 Valid. err. 3.16949
2018-02-03 20:28:10,084 training [INFO ] Epoch  9 Batch 1140 Training err. 3.07649 Training err. RA 3.21457 Valid. err. 3.17526
2018-02-03 20:28:10,549 training [INFO ] Epoch  9 Batch 1160 Training err. 3.13194 Training err. RA 3.21314 Valid. err. 3.16880
2018-02-03 20:28:11,016 training [INFO ] Epoch  9 Batch 1180 Training err. 3.12407 Training err. RA 3.21163 Valid. err. 3.16772
2018-02-03 20:28:11,820 training [INFO ] Epoch 10 Batch 1200 Training err. 3.15098 Training err. RA 3.21062 Valid. err. 3.16831
2018-02-03 20:28:12,290 training [INFO ] Epoch 10 Batch 1220 Training err. 3.11458 Training err. RA 3.20905 Valid. err. 3.16595
2018-02-03 20:28:12,758 training [INFO ] Epoch 10 Batch 1240 Training err. 3.07354 Training err. RA 3.20686 Valid. err. 3.16929
2018-02-03 20:28:13,222 training [INFO ] Epoch 10 Batch 1260 Training err. 3.12458 Training err. RA 3.20556 Valid. err. 3.16393
2018-02-03 20:28:13,686 training [INFO ] Epoch 10 Batch 1280 Training err. 3.08649 Training err. RA 3.20370 Valid. err. 3.16337
2018-02-03 20:28:14,148 training [INFO ] Epoch 10 Batch 1300 Training err. 3.12146 Training err. RA 3.20243 Valid. err. 3.16161
2018-02-03 20:28:14,614 training [INFO ] Epoch 10 Batch 1320 Training err. 3.11755 Training err. RA 3.20114 Valid. err. 3.15969
2018-02-03 20:28:14,993 __main__ [INFO ] End of training
2018-02-03 20:28:17,321 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 2 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.01,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1000,
  "num_timesteps": 100,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:28:17,322 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:28:17,920 training [INFO ] Epoch  1 Batch   20 Training err. 4.32131 Training err. RA 4.32131 Valid. err. 4.31017
2018-02-03 20:28:18,384 training [INFO ] Epoch  1 Batch   40 Training err. 4.30466 Training err. RA 4.31299 Valid. err. 4.29449
2018-02-03 20:28:18,881 training [INFO ] Epoch  1 Batch   60 Training err. 4.28862 Training err. RA 4.30487 Valid. err. 4.27999
2018-02-03 20:28:19,650 training [INFO ] Epoch  1 Batch   80 Training err. 4.27223 Training err. RA 4.29671 Valid. err. 4.26499
2018-02-03 20:28:20,150 training [INFO ] Epoch  1 Batch  100 Training err. 4.25830 Training err. RA 4.28902 Valid. err. 4.25069
2018-02-03 20:28:20,640 training [INFO ] Epoch  1 Batch  120 Training err. 4.24353 Training err. RA 4.28144 Valid. err. 4.23609
2018-02-03 20:28:21,459 training [INFO ] Epoch  2 Batch  140 Training err. 4.22895 Training err. RA 4.27394 Valid. err. 4.22162
2018-02-03 20:28:21,926 training [INFO ] Epoch  2 Batch  160 Training err. 4.21406 Training err. RA 4.26646 Valid. err. 4.20722
2018-02-03 20:28:22,426 training [INFO ] Epoch  2 Batch  180 Training err. 4.19084 Training err. RA 4.25805 Valid. err. 4.19180
2018-02-03 20:28:22,890 training [INFO ] Epoch  2 Batch  200 Training err. 4.18318 Training err. RA 4.25057 Valid. err. 4.17737
2018-02-03 20:28:23,381 training [INFO ] Epoch  2 Batch  220 Training err. 4.16758 Training err. RA 4.24302 Valid. err. 4.16279
2018-02-03 20:28:23,947 training [INFO ] Epoch  2 Batch  240 Training err. 4.15180 Training err. RA 4.23542 Valid. err. 4.14808
2018-02-03 20:28:24,461 training [INFO ] Epoch  2 Batch  260 Training err. 4.13797 Training err. RA 4.22792 Valid. err. 4.13337
2018-02-03 20:28:25,274 training [INFO ] Epoch  3 Batch  280 Training err. 4.12239 Training err. RA 4.22039 Valid. err. 4.11846
2018-02-03 20:28:25,755 training [INFO ] Epoch  3 Batch  300 Training err. 4.09977 Training err. RA 4.21235 Valid. err. 4.10294
2018-02-03 20:28:26,233 training [INFO ] Epoch  3 Batch  320 Training err. 4.08387 Training err. RA 4.20432 Valid. err. 4.08734
2018-02-03 20:28:26,730 training [INFO ] Epoch  3 Batch  340 Training err. 4.07244 Training err. RA 4.19656 Valid. err. 4.07183
2018-02-03 20:28:27,216 training [INFO ] Epoch  3 Batch  360 Training err. 4.05805 Training err. RA 4.18886 Valid. err. 4.05626
2018-02-03 20:28:27,679 training [INFO ] Epoch  3 Batch  380 Training err. 4.04306 Training err. RA 4.18119 Valid. err. 4.04051
2018-02-03 20:28:28,477 training [INFO ] Epoch  4 Batch  400 Training err. 4.02716 Training err. RA 4.17349 Valid. err. 4.02452
2018-02-03 20:28:28,946 training [INFO ] Epoch  4 Batch  420 Training err. 4.00667 Training err. RA 4.16554 Valid. err. 4.00804
2018-02-03 20:28:29,411 training [INFO ] Epoch  4 Batch  440 Training err. 3.96842 Training err. RA 4.15658 Valid. err. 3.99020
2018-02-03 20:28:29,874 training [INFO ] Epoch  4 Batch  460 Training err. 3.98024 Training err. RA 4.14892 Valid. err. 3.97365
2018-02-03 20:28:30,336 training [INFO ] Epoch  4 Batch  480 Training err. 3.94634 Training err. RA 4.14048 Valid. err. 3.95590
2018-02-03 20:28:30,794 training [INFO ] Epoch  4 Batch  500 Training err. 3.94324 Training err. RA 4.13259 Valid. err. 3.93860
2018-02-03 20:28:31,259 training [INFO ] Epoch  4 Batch  520 Training err. 3.91705 Training err. RA 4.12430 Valid. err. 3.92055
2018-02-03 20:28:32,055 training [INFO ] Epoch  5 Batch  540 Training err. 3.90136 Training err. RA 4.11604 Valid. err. 3.90233
2018-02-03 20:28:32,517 training [INFO ] Epoch  5 Batch  560 Training err. 3.88476 Training err. RA 4.10778 Valid. err. 3.88385
2018-02-03 20:28:32,979 training [INFO ] Epoch  5 Batch  580 Training err. 3.83086 Training err. RA 4.09823 Valid. err. 3.86366
2018-02-03 20:28:33,441 training [INFO ] Epoch  5 Batch  600 Training err. 3.84152 Training err. RA 4.08967 Valid. err. 3.84446
2018-02-03 20:28:33,903 training [INFO ] Epoch  5 Batch  620 Training err. 3.82389 Training err. RA 4.08110 Valid. err. 3.82513
2018-02-03 20:28:34,362 training [INFO ] Epoch  5 Batch  640 Training err. 3.80050 Training err. RA 4.07233 Valid. err. 3.80548
2018-02-03 20:28:34,824 training [INFO ] Epoch  5 Batch  660 Training err. 3.78584 Training err. RA 4.06365 Valid. err. 3.78596
2018-02-03 20:28:35,625 training [INFO ] Epoch  6 Batch  680 Training err. 3.75604 Training err. RA 4.05460 Valid. err. 3.76604
2018-02-03 20:28:36,093 training [INFO ] Epoch  6 Batch  700 Training err. 3.71982 Training err. RA 4.04504 Valid. err. 3.74564
2018-02-03 20:28:36,564 training [INFO ] Epoch  6 Batch  720 Training err. 3.70547 Training err. RA 4.03561 Valid. err. 3.72586
2018-02-03 20:28:37,048 training [INFO ] Epoch  6 Batch  740 Training err. 3.69033 Training err. RA 4.02627 Valid. err. 3.70624
2018-02-03 20:28:37,510 training [INFO ] Epoch  6 Batch  760 Training err. 3.68176 Training err. RA 4.01721 Valid. err. 3.68759
2018-02-03 20:28:37,976 training [INFO ] Epoch  6 Batch  780 Training err. 3.66352 Training err. RA 4.00814 Valid. err. 3.66939
2018-02-03 20:28:38,780 training [INFO ] Epoch  7 Batch  800 Training err. 3.64339 Training err. RA 3.99902 Valid. err. 3.65190
2018-02-03 20:28:39,255 training [INFO ] Epoch  7 Batch  820 Training err. 3.61988 Training err. RA 3.98977 Valid. err. 3.63472
2018-02-03 20:28:39,717 training [INFO ] Epoch  7 Batch  840 Training err. 3.55001 Training err. RA 3.97930 Valid. err. 3.61743
2018-02-03 20:28:40,182 training [INFO ] Epoch  7 Batch  860 Training err. 3.60428 Training err. RA 3.97058 Valid. err. 3.60223
2018-02-03 20:28:40,647 training [INFO ] Epoch  7 Batch  880 Training err. 3.55705 Training err. RA 3.96118 Valid. err. 3.58675
2018-02-03 20:28:41,115 training [INFO ] Epoch  7 Batch  900 Training err. 3.56716 Training err. RA 3.95243 Valid. err. 3.57240
2018-02-03 20:28:41,580 training [INFO ] Epoch  7 Batch  920 Training err. 3.53946 Training err. RA 3.94345 Valid. err. 3.55871
2018-02-03 20:28:42,403 training [INFO ] Epoch  8 Batch  940 Training err. 3.53214 Training err. RA 3.93470 Valid. err. 3.54562
2018-02-03 20:28:42,868 training [INFO ] Epoch  8 Batch  960 Training err. 3.51649 Training err. RA 3.92598 Valid. err. 3.53251
2018-02-03 20:28:43,333 training [INFO ] Epoch  8 Batch  980 Training err. 3.45195 Training err. RA 3.91631 Valid. err. 3.52032
2018-02-03 20:28:43,801 training [INFO ] Epoch  8 Batch 1000 Training err. 3.48643 Training err. RA 3.90771 Valid. err. 3.50765
2018-02-03 20:28:44,268 training [INFO ] Epoch  8 Batch 1020 Training err. 3.47358 Training err. RA 3.89920 Valid. err. 3.49552
2018-02-03 20:28:44,734 training [INFO ] Epoch  8 Batch 1040 Training err. 3.46593 Training err. RA 3.89087 Valid. err. 3.48358
2018-02-03 20:28:45,222 training [INFO ] Epoch  8 Batch 1060 Training err. 3.46467 Training err. RA 3.88283 Valid. err. 3.47224
2018-02-03 20:28:46,036 training [INFO ] Epoch  9 Batch 1080 Training err. 3.43226 Training err. RA 3.87448 Valid. err. 3.46146
2018-02-03 20:28:46,508 training [INFO ] Epoch  9 Batch 1100 Training err. 3.40012 Training err. RA 3.86586 Valid. err. 3.45072
2018-02-03 20:28:46,977 training [INFO ] Epoch  9 Batch 1120 Training err. 3.40990 Training err. RA 3.85772 Valid. err. 3.44058
2018-02-03 20:28:47,450 training [INFO ] Epoch  9 Batch 1140 Training err. 3.38142 Training err. RA 3.84936 Valid. err. 3.42958
2018-02-03 20:28:47,938 training [INFO ] Epoch  9 Batch 1160 Training err. 3.41063 Training err. RA 3.84180 Valid. err. 3.41932
2018-02-03 20:28:48,406 training [INFO ] Epoch  9 Batch 1180 Training err. 3.39575 Training err. RA 3.83424 Valid. err. 3.40944
2018-02-03 20:28:49,219 training [INFO ] Epoch 10 Batch 1200 Training err. 3.38715 Training err. RA 3.82678 Valid. err. 3.40068
2018-02-03 20:28:49,684 training [INFO ] Epoch 10 Batch 1220 Training err. 3.36360 Training err. RA 3.81919 Valid. err. 3.39145
2018-02-03 20:28:50,159 training [INFO ] Epoch 10 Batch 1240 Training err. 3.30454 Training err. RA 3.81089 Valid. err. 3.38392
2018-02-03 20:28:50,640 training [INFO ] Epoch 10 Batch 1260 Training err. 3.36984 Training err. RA 3.80389 Valid. err. 3.37507
2018-02-03 20:28:51,105 training [INFO ] Epoch 10 Batch 1280 Training err. 3.32088 Training err. RA 3.79634 Valid. err. 3.36667
2018-02-03 20:28:51,566 training [INFO ] Epoch 10 Batch 1300 Training err. 3.34562 Training err. RA 3.78941 Valid. err. 3.35865
2018-02-03 20:28:52,027 training [INFO ] Epoch 10 Batch 1320 Training err. 3.32595 Training err. RA 3.78239 Valid. err. 3.35164
2018-02-03 20:28:52,396 __main__ [INFO ] End of training
2018-02-03 20:30:57,875 __main__ [INFO ] 
==============================
Starting experiment alice_test
==============================
2018-02-03 20:30:57,879 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/alice_test/out
2018-02-03 20:30:57,882 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1024,
  "num_timesteps": 64,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:30:57,882 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:31:00,472 training [INFO ] Epoch  1 Batch   20 Training err. 4.23836 Training err. RA 4.23836 Valid. err. 4.16681
2018-02-03 20:31:00,860 training [INFO ] Epoch  1 Batch   40 Training err. 4.08808 Training err. RA 4.16322 Valid. err. 4.02054
2018-02-03 20:31:01,243 training [INFO ] Epoch  1 Batch   60 Training err. 3.84148 Training err. RA 4.05597 Valid. err. 3.83841
2018-02-03 20:31:01,628 training [INFO ] Epoch  1 Batch   80 Training err. 3.73721 Training err. RA 3.97628 Valid. err. 3.69588
2018-02-03 20:31:02,019 training [INFO ] Epoch  1 Batch  100 Training err. 3.62597 Training err. RA 3.90622 Valid. err. 3.57621
2018-02-03 20:31:02,415 training [INFO ] Epoch  1 Batch  120 Training err. 3.46012 Training err. RA 3.83187 Valid. err. 3.46787
2018-02-03 20:31:02,799 training [INFO ] Epoch  1 Batch  140 Training err. 3.39256 Training err. RA 3.76911 Valid. err. 3.38790
2018-02-03 20:31:03,186 training [INFO ] Epoch  1 Batch  160 Training err. 3.30358 Training err. RA 3.71092 Valid. err. 3.32310
2018-02-03 20:31:03,572 training [INFO ] Epoch  1 Batch  180 Training err. 3.27796 Training err. RA 3.66281 Valid. err. 3.28689
2018-02-03 20:31:03,969 training [INFO ] Epoch  1 Batch  200 Training err. 3.22670 Training err. RA 3.61920 Valid. err. 3.26504
2018-02-03 20:31:04,362 training [INFO ] Epoch  1 Batch  220 Training err. 3.23406 Training err. RA 3.58419 Valid. err. 3.24955
2018-02-03 20:31:04,750 training [INFO ] Epoch  1 Batch  240 Training err. 3.22057 Training err. RA 3.55389 Valid. err. 3.23755
2018-02-03 20:31:05,144 training [INFO ] Epoch  1 Batch  260 Training err. 3.16918 Training err. RA 3.52429 Valid. err. 3.22950
2018-02-03 20:31:05,538 training [INFO ] Epoch  1 Batch  280 Training err. 3.19255 Training err. RA 3.50060 Valid. err. 3.22119
2018-02-03 20:31:05,933 training [INFO ] Epoch  1 Batch  300 Training err. 3.14993 Training err. RA 3.47722 Valid. err. 3.21525
2018-02-03 20:31:06,323 training [INFO ] Epoch  1 Batch  320 Training err. 3.10854 Training err. RA 3.45418 Valid. err. 3.21222
2018-02-03 20:31:06,715 training [INFO ] Epoch  1 Batch  340 Training err. 3.17391 Training err. RA 3.43769 Valid. err. 3.20447
2018-02-03 20:31:07,106 training [INFO ] Epoch  1 Batch  360 Training err. 3.18642 Training err. RA 3.42373 Valid. err. 3.20208
2018-02-03 20:31:07,501 training [INFO ] Epoch  1 Batch  380 Training err. 3.18219 Training err. RA 3.41102 Valid. err. 3.19759
2018-02-03 20:31:07,893 training [INFO ] Epoch  1 Batch  400 Training err. 3.18973 Training err. RA 3.39995 Valid. err. 3.19431
2018-02-03 20:31:08,637 training [INFO ] Epoch  2 Batch  420 Training err. 3.19094 Training err. RA 3.39000 Valid. err. 3.19890
2018-02-03 20:31:09,028 training [INFO ] Epoch  2 Batch  440 Training err. 3.13253 Training err. RA 3.37830 Valid. err. 3.20085
2018-02-03 20:31:09,424 training [INFO ] Epoch  2 Batch  460 Training err. 3.14157 Training err. RA 3.36801 Valid. err. 3.19205
2018-02-03 20:31:09,813 training [INFO ] Epoch  2 Batch  480 Training err. 3.01134 Training err. RA 3.35314 Valid. err. 3.23103
2018-02-03 20:31:10,205 training [INFO ] Epoch  2 Batch  500 Training err. 3.20977 Training err. RA 3.34741 Valid. err. 3.18872
2018-02-03 20:31:10,596 training [INFO ] Epoch  2 Batch  520 Training err. 3.12413 Training err. RA 3.33882 Valid. err. 3.19088
2018-02-03 20:31:10,990 training [INFO ] Epoch  2 Batch  540 Training err. 3.12280 Training err. RA 3.33082 Valid. err. 3.18942
2018-02-03 20:31:11,382 training [INFO ] Epoch  2 Batch  560 Training err. 3.12986 Training err. RA 3.32364 Valid. err. 3.19084
2018-02-03 20:31:11,773 training [INFO ] Epoch  2 Batch  580 Training err. 3.10828 Training err. RA 3.31622 Valid. err. 3.19517
2018-02-03 20:31:12,167 training [INFO ] Epoch  2 Batch  600 Training err. 3.15158 Training err. RA 3.31073 Valid. err. 3.19005
2018-02-03 20:31:12,562 training [INFO ] Epoch  2 Batch  620 Training err. 3.16326 Training err. RA 3.30597 Valid. err. 3.18847
2018-02-03 20:31:12,957 training [INFO ] Epoch  2 Batch  640 Training err. 3.13606 Training err. RA 3.30066 Valid. err. 3.18445
2018-02-03 20:31:13,350 training [INFO ] Epoch  2 Batch  660 Training err. 3.15744 Training err. RA 3.29632 Valid. err. 3.18659
2018-02-03 20:31:13,736 training [INFO ] Epoch  2 Batch  680 Training err. 3.10703 Training err. RA 3.29075 Valid. err. 3.18757
2018-02-03 20:31:14,125 training [INFO ] Epoch  2 Batch  700 Training err. 3.15502 Training err. RA 3.28688 Valid. err. 3.18761
2018-02-03 20:31:14,514 training [INFO ] Epoch  2 Batch  720 Training err. 3.09007 Training err. RA 3.28141 Valid. err. 3.18543
2018-02-03 20:31:14,903 training [INFO ] Epoch  2 Batch  740 Training err. 3.08159 Training err. RA 3.27601 Valid. err. 3.19043
2018-02-03 20:31:15,291 training [INFO ] Epoch  2 Batch  760 Training err. 3.14704 Training err. RA 3.27262 Valid. err. 3.18311
2018-02-03 20:31:15,676 training [INFO ] Epoch  2 Batch  780 Training err. 3.15893 Training err. RA 3.26970 Valid. err. 3.18399
2018-02-03 20:31:16,063 training [INFO ] Epoch  2 Batch  800 Training err. 3.16378 Training err. RA 3.26705 Valid. err. 3.18021
2018-02-03 20:31:16,464 training [INFO ] Epoch  2 Batch  820 Training err. 3.17232 Training err. RA 3.26474 Valid. err. 3.17717
2018-02-03 20:31:17,195 training [INFO ] Epoch  3 Batch  840 Training err. 3.15360 Training err. RA 3.26210 Valid. err. 3.18603
2018-02-03 20:31:17,585 training [INFO ] Epoch  3 Batch  860 Training err. 3.12794 Training err. RA 3.25898 Valid. err. 3.17867
2018-02-03 20:31:17,976 training [INFO ] Epoch  3 Batch  880 Training err. 3.12062 Training err. RA 3.25583 Valid. err. 3.18452
2018-02-03 20:31:18,367 training [INFO ] Epoch  3 Batch  900 Training err. 3.01178 Training err. RA 3.25041 Valid. err. 3.18449
2018-02-03 20:31:18,756 training [INFO ] Epoch  3 Batch  920 Training err. 3.18404 Training err. RA 3.24897 Valid. err. 3.17707
2018-02-03 20:31:19,148 training [INFO ] Epoch  3 Batch  940 Training err. 3.09547 Training err. RA 3.24570 Valid. err. 3.18097
2018-02-03 20:31:19,537 training [INFO ] Epoch  3 Batch  960 Training err. 3.11765 Training err. RA 3.24303 Valid. err. 3.17859
2018-02-03 20:31:19,927 training [INFO ] Epoch  3 Batch  980 Training err. 3.12115 Training err. RA 3.24054 Valid. err. 3.17644
2018-02-03 20:31:20,332 training [INFO ] Epoch  3 Batch 1000 Training err. 3.07986 Training err. RA 3.23733 Valid. err. 3.18261
2018-02-03 20:31:20,721 training [INFO ] Epoch  3 Batch 1020 Training err. 3.12540 Training err. RA 3.23514 Valid. err. 3.20299
2018-02-03 20:31:21,109 training [INFO ] Epoch  3 Batch 1040 Training err. 3.17700 Training err. RA 3.23402 Valid. err. 3.17795
2018-02-03 20:31:21,500 training [INFO ] Epoch  3 Batch 1060 Training err. 3.12884 Training err. RA 3.23203 Valid. err. 3.17351
2018-02-03 20:31:21,890 training [INFO ] Epoch  3 Batch 1080 Training err. 3.13974 Training err. RA 3.23032 Valid. err. 3.17533
2018-02-03 20:31:22,278 training [INFO ] Epoch  3 Batch 1100 Training err. 3.08411 Training err. RA 3.22767 Valid. err. 3.17686
2018-02-03 20:31:22,672 training [INFO ] Epoch  3 Batch 1120 Training err. 3.13637 Training err. RA 3.22604 Valid. err. 3.17572
2018-02-03 20:31:23,065 training [INFO ] Epoch  3 Batch 1140 Training err. 3.06999 Training err. RA 3.22330 Valid. err. 3.17403
2018-02-03 20:31:23,460 training [INFO ] Epoch  3 Batch 1160 Training err. 3.06946 Training err. RA 3.22065 Valid. err. 3.17782
2018-02-03 20:31:23,850 training [INFO ] Epoch  3 Batch 1180 Training err. 3.14555 Training err. RA 3.21937 Valid. err. 3.17110
2018-02-03 20:31:24,239 training [INFO ] Epoch  3 Batch 1200 Training err. 3.14489 Training err. RA 3.21813 Valid. err. 3.16796
2018-02-03 20:31:24,636 training [INFO ] Epoch  3 Batch 1220 Training err. 3.13943 Training err. RA 3.21684 Valid. err. 3.16653
2018-02-03 20:31:25,030 training [INFO ] Epoch  3 Batch 1240 Training err. 3.16474 Training err. RA 3.21600 Valid. err. 3.16314
2018-02-03 20:31:25,775 training [INFO ] Epoch  4 Batch 1260 Training err. 3.13037 Training err. RA 3.21464 Valid. err. 3.16335
2018-02-03 20:31:26,181 training [INFO ] Epoch  4 Batch 1280 Training err. 3.11633 Training err. RA 3.21311 Valid. err. 3.16416
2018-02-03 20:31:26,575 training [INFO ] Epoch  4 Batch 1300 Training err. 3.08295 Training err. RA 3.21110 Valid. err. 3.18017
2018-02-03 20:31:26,969 training [INFO ] Epoch  4 Batch 1320 Training err. 3.03330 Training err. RA 3.20841 Valid. err. 3.16422
2018-02-03 20:31:27,360 training [INFO ] Epoch  4 Batch 1340 Training err. 3.15296 Training err. RA 3.20758 Valid. err. 3.16120
2018-02-03 20:31:27,750 training [INFO ] Epoch  4 Batch 1360 Training err. 3.07981 Training err. RA 3.20570 Valid. err. 3.16331
2018-02-03 20:31:28,144 training [INFO ] Epoch  4 Batch 1380 Training err. 3.10284 Training err. RA 3.20421 Valid. err. 3.16105
2018-02-03 20:31:28,534 training [INFO ] Epoch  4 Batch 1400 Training err. 3.09976 Training err. RA 3.20272 Valid. err. 3.15843
2018-02-03 20:31:28,925 training [INFO ] Epoch  4 Batch 1420 Training err. 3.06145 Training err. RA 3.20073 Valid. err. 3.16345
2018-02-03 20:31:29,314 training [INFO ] Epoch  4 Batch 1440 Training err. 3.11295 Training err. RA 3.19951 Valid. err. 3.16002
2018-02-03 20:31:29,708 training [INFO ] Epoch  4 Batch 1460 Training err. 3.16062 Training err. RA 3.19898 Valid. err. 3.16295
2018-02-03 20:31:30,103 training [INFO ] Epoch  4 Batch 1480 Training err. 3.10542 Training err. RA 3.19771 Valid. err. 3.15284
2018-02-03 20:31:30,498 training [INFO ] Epoch  4 Batch 1500 Training err. 3.12010 Training err. RA 3.19668 Valid. err. 3.15224
2018-02-03 20:31:30,893 training [INFO ] Epoch  4 Batch 1520 Training err. 3.05201 Training err. RA 3.19478 Valid. err. 3.15169
2018-02-03 20:31:31,285 training [INFO ] Epoch  4 Batch 1540 Training err. 3.11736 Training err. RA 3.19377 Valid. err. 3.14952
2018-02-03 20:31:31,679 training [INFO ] Epoch  4 Batch 1560 Training err. 3.03551 Training err. RA 3.19174 Valid. err. 3.14537
2018-02-03 20:31:32,070 training [INFO ] Epoch  4 Batch 1580 Training err. 3.04223 Training err. RA 3.18985 Valid. err. 3.14590
2018-02-03 20:31:32,466 training [INFO ] Epoch  4 Batch 1600 Training err. 3.12425 Training err. RA 3.18903 Valid. err. 3.14000
2018-02-03 20:31:32,856 training [INFO ] Epoch  4 Batch 1620 Training err. 3.12624 Training err. RA 3.18825 Valid. err. 3.13381
2018-02-03 20:31:33,247 training [INFO ] Epoch  4 Batch 1640 Training err. 3.09113 Training err. RA 3.18707 Valid. err. 3.13334
2018-02-03 20:31:33,641 training [INFO ] Epoch  4 Batch 1660 Training err. 3.12172 Training err. RA 3.18628 Valid. err. 3.12636
2018-02-03 20:31:34,386 training [INFO ] Epoch  5 Batch 1680 Training err. 3.09775 Training err. RA 3.18523 Valid. err. 3.12452
2018-02-03 20:31:34,776 training [INFO ] Epoch  5 Batch 1700 Training err. 3.06869 Training err. RA 3.18386 Valid. err. 3.12560
2018-02-03 20:31:35,171 training [INFO ] Epoch  5 Batch 1720 Training err. 3.03881 Training err. RA 3.18217 Valid. err. 3.14185
2018-02-03 20:31:35,565 training [INFO ] Epoch  5 Batch 1740 Training err. 3.05363 Training err. RA 3.18069 Valid. err. 3.12817
2018-02-03 20:31:35,967 training [INFO ] Epoch  5 Batch 1760 Training err. 3.10879 Training err. RA 3.17988 Valid. err. 3.11817
2018-02-03 20:31:36,356 training [INFO ] Epoch  5 Batch 1780 Training err. 3.02996 Training err. RA 3.17819 Valid. err. 3.12606
2018-02-03 20:31:36,749 training [INFO ] Epoch  5 Batch 1800 Training err. 3.07208 Training err. RA 3.17701 Valid. err. 3.11258
2018-02-03 20:31:37,142 training [INFO ] Epoch  5 Batch 1820 Training err. 3.06173 Training err. RA 3.17575 Valid. err. 3.10837
2018-02-03 20:31:37,538 training [INFO ] Epoch  5 Batch 1840 Training err. 3.01035 Training err. RA 3.17395 Valid. err. 3.10982
2018-02-03 20:31:37,932 training [INFO ] Epoch  5 Batch 1860 Training err. 3.05915 Training err. RA 3.17271 Valid. err. 3.10537
2018-02-03 20:31:38,324 training [INFO ] Epoch  5 Batch 1880 Training err. 3.12197 Training err. RA 3.17217 Valid. err. 3.10079
2018-02-03 20:31:38,717 training [INFO ] Epoch  5 Batch 1900 Training err. 3.05052 Training err. RA 3.17089 Valid. err. 3.09382
2018-02-03 20:31:39,112 training [INFO ] Epoch  5 Batch 1920 Training err. 3.05266 Training err. RA 3.16966 Valid. err. 3.09054
2018-02-03 20:31:39,508 training [INFO ] Epoch  5 Batch 1940 Training err. 3.01199 Training err. RA 3.16804 Valid. err. 3.08870
2018-02-03 20:31:39,902 training [INFO ] Epoch  5 Batch 1960 Training err. 3.04018 Training err. RA 3.16673 Valid. err. 3.08051
2018-02-03 20:31:40,290 training [INFO ] Epoch  5 Batch 1980 Training err. 2.96650 Training err. RA 3.16471 Valid. err. 3.07630
2018-02-03 20:31:40,683 training [INFO ] Epoch  5 Batch 2000 Training err. 2.99593 Training err. RA 3.16302 Valid. err. 3.07627
2018-02-03 20:31:41,078 training [INFO ] Epoch  5 Batch 2020 Training err. 3.05893 Training err. RA 3.16199 Valid. err. 3.06875
2018-02-03 20:31:41,473 training [INFO ] Epoch  5 Batch 2040 Training err. 3.05360 Training err. RA 3.16093 Valid. err. 3.05919
2018-02-03 20:31:41,863 training [INFO ] Epoch  5 Batch 2060 Training err. 3.02303 Training err. RA 3.15959 Valid. err. 3.05497
2018-02-03 20:31:42,254 training [INFO ] Epoch  5 Batch 2080 Training err. 3.03864 Training err. RA 3.15843 Valid. err. 3.05150
2018-02-03 20:31:43,001 training [INFO ] Epoch  6 Batch 2100 Training err. 3.04066 Training err. RA 3.15730 Valid. err. 3.04190
2018-02-03 20:31:43,393 training [INFO ] Epoch  6 Batch 2120 Training err. 2.96050 Training err. RA 3.15545 Valid. err. 3.03969
2018-02-03 20:31:43,785 training [INFO ] Epoch  6 Batch 2140 Training err. 2.97465 Training err. RA 3.15376 Valid. err. 3.08215
2018-02-03 20:31:44,178 training [INFO ] Epoch  6 Batch 2160 Training err. 3.01364 Training err. RA 3.15246 Valid. err. 3.03689
2018-02-03 20:31:44,571 training [INFO ] Epoch  6 Batch 2180 Training err. 3.01023 Training err. RA 3.15116 Valid. err. 3.02427
2018-02-03 20:31:44,967 training [INFO ] Epoch  6 Batch 2200 Training err. 2.94081 Training err. RA 3.14924 Valid. err. 3.02571
2018-02-03 20:31:45,358 training [INFO ] Epoch  6 Batch 2220 Training err. 2.99971 Training err. RA 3.14790 Valid. err. 3.01206
2018-02-03 20:31:45,750 training [INFO ] Epoch  6 Batch 2240 Training err. 2.95377 Training err. RA 3.14616 Valid. err. 3.00797
2018-02-03 20:31:46,142 training [INFO ] Epoch  6 Batch 2260 Training err. 2.92405 Training err. RA 3.14420 Valid. err. 3.00575
2018-02-03 20:31:46,539 training [INFO ] Epoch  6 Batch 2280 Training err. 2.97161 Training err. RA 3.14268 Valid. err. 2.99845
2018-02-03 20:31:46,934 training [INFO ] Epoch  6 Batch 2300 Training err. 3.00351 Training err. RA 3.14147 Valid. err. 2.99502
2018-02-03 20:31:47,322 training [INFO ] Epoch  6 Batch 2320 Training err. 2.96930 Training err. RA 3.13999 Valid. err. 2.98209
2018-02-03 20:31:47,717 training [INFO ] Epoch  6 Batch 2340 Training err. 2.91619 Training err. RA 3.13808 Valid. err. 2.98352
2018-02-03 20:31:48,117 training [INFO ] Epoch  6 Batch 2360 Training err. 2.90956 Training err. RA 3.13614 Valid. err. 2.97251
2018-02-03 20:31:48,510 training [INFO ] Epoch  6 Batch 2380 Training err. 2.90701 Training err. RA 3.13421 Valid. err. 2.96791
2018-02-03 20:31:48,904 training [INFO ] Epoch  6 Batch 2400 Training err. 2.85928 Training err. RA 3.13192 Valid. err. 2.96017
2018-02-03 20:31:49,292 training [INFO ] Epoch  6 Batch 2420 Training err. 2.89348 Training err. RA 3.12995 Valid. err. 2.95465
2018-02-03 20:31:49,690 training [INFO ] Epoch  6 Batch 2440 Training err. 2.93791 Training err. RA 3.12838 Valid. err. 2.94612
2018-02-03 20:31:50,084 training [INFO ] Epoch  6 Batch 2460 Training err. 2.93254 Training err. RA 3.12679 Valid. err. 2.93557
2018-02-03 20:31:50,480 training [INFO ] Epoch  6 Batch 2480 Training err. 2.91219 Training err. RA 3.12506 Valid. err. 2.93176
2018-02-03 20:31:50,872 training [INFO ] Epoch  6 Batch 2500 Training err. 2.92401 Training err. RA 3.12345 Valid. err. 2.92069
2018-02-03 20:31:51,613 training [INFO ] Epoch  7 Batch 2520 Training err. 2.89280 Training err. RA 3.12162 Valid. err. 2.91602
2018-02-03 20:31:52,007 training [INFO ] Epoch  7 Batch 2540 Training err. 2.83768 Training err. RA 3.11938 Valid. err. 2.91277
2018-02-03 20:31:52,401 training [INFO ] Epoch  7 Batch 2560 Training err. 2.83521 Training err. RA 3.11716 Valid. err. 2.93438
2018-02-03 20:31:52,791 training [INFO ] Epoch  7 Batch 2580 Training err. 2.88415 Training err. RA 3.11535 Valid. err. 2.90659
2018-02-03 20:31:53,186 training [INFO ] Epoch  7 Batch 2600 Training err. 2.88282 Training err. RA 3.11357 Valid. err. 2.89582
2018-02-03 20:31:53,583 training [INFO ] Epoch  7 Batch 2620 Training err. 2.80427 Training err. RA 3.11120 Valid. err. 2.89262
2018-02-03 20:31:53,982 training [INFO ] Epoch  7 Batch 2640 Training err. 2.88369 Training err. RA 3.10948 Valid. err. 2.96006
2018-02-03 20:31:54,373 training [INFO ] Epoch  7 Batch 2660 Training err. 2.80026 Training err. RA 3.10716 Valid. err. 2.88326
2018-02-03 20:31:54,766 training [INFO ] Epoch  7 Batch 2680 Training err. 2.81150 Training err. RA 3.10495 Valid. err. 2.87494
2018-02-03 20:31:55,162 training [INFO ] Epoch  7 Batch 2700 Training err. 2.81987 Training err. RA 3.10284 Valid. err. 2.86756
2018-02-03 20:31:55,558 training [INFO ] Epoch  7 Batch 2720 Training err. 2.85851 Training err. RA 3.10104 Valid. err. 2.86432
2018-02-03 20:31:55,951 training [INFO ] Epoch  7 Batch 2740 Training err. 2.83915 Training err. RA 3.09913 Valid. err. 2.85531
2018-02-03 20:31:56,341 training [INFO ] Epoch  7 Batch 2760 Training err. 2.79767 Training err. RA 3.09695 Valid. err. 2.85963
2018-02-03 20:31:56,736 training [INFO ] Epoch  7 Batch 2780 Training err. 2.79215 Training err. RA 3.09475 Valid. err. 2.84437
2018-02-03 20:31:57,129 training [INFO ] Epoch  7 Batch 2800 Training err. 2.77802 Training err. RA 3.09249 Valid. err. 2.84437
2018-02-03 20:31:57,524 training [INFO ] Epoch  7 Batch 2820 Training err. 2.72108 Training err. RA 3.08986 Valid. err. 2.83959
2018-02-03 20:31:57,913 training [INFO ] Epoch  7 Batch 2840 Training err. 2.79639 Training err. RA 3.08779 Valid. err. 2.82779
2018-02-03 20:31:58,302 training [INFO ] Epoch  7 Batch 2860 Training err. 2.81350 Training err. RA 3.08587 Valid. err. 2.82650
2018-02-03 20:31:58,695 training [INFO ] Epoch  7 Batch 2880 Training err. 2.80210 Training err. RA 3.08390 Valid. err. 2.81861
2018-02-03 20:31:59,089 training [INFO ] Epoch  7 Batch 2900 Training err. 2.80838 Training err. RA 3.08200 Valid. err. 2.82774
2018-02-03 20:31:59,836 training [INFO ] Epoch  8 Batch 2920 Training err. 2.80655 Training err. RA 3.08011 Valid. err. 2.83175
2018-02-03 20:32:00,237 training [INFO ] Epoch  8 Batch 2940 Training err. 2.74271 Training err. RA 3.07782 Valid. err. 2.82684
2018-02-03 20:32:00,630 training [INFO ] Epoch  8 Batch 2960 Training err. 2.72329 Training err. RA 3.07542 Valid. err. 2.80024
2018-02-03 20:32:01,025 training [INFO ] Epoch  8 Batch 2980 Training err. 2.63563 Training err. RA 3.07247 Valid. err. 2.79789
2018-02-03 20:32:01,417 training [INFO ] Epoch  8 Batch 3000 Training err. 2.80884 Training err. RA 3.07071 Valid. err. 2.78473
2018-02-03 20:32:01,808 training [INFO ] Epoch  8 Batch 3020 Training err. 2.74396 Training err. RA 3.06855 Valid. err. 2.79122
2018-02-03 20:32:02,202 training [INFO ] Epoch  8 Batch 3040 Training err. 2.69103 Training err. RA 3.06607 Valid. err. 2.77667
2018-02-03 20:32:02,595 training [INFO ] Epoch  8 Batch 3060 Training err. 2.77874 Training err. RA 3.06419 Valid. err. 2.78033
2018-02-03 20:32:02,989 training [INFO ] Epoch  8 Batch 3080 Training err. 2.67240 Training err. RA 3.06164 Valid. err. 2.78922
2018-02-03 20:32:03,375 training [INFO ] Epoch  8 Batch 3100 Training err. 2.73176 Training err. RA 3.05952 Valid. err. 2.76637
2018-02-03 20:32:03,767 training [INFO ] Epoch  8 Batch 3120 Training err. 2.71463 Training err. RA 3.05730 Valid. err. 2.75436
2018-02-03 20:32:04,163 training [INFO ] Epoch  8 Batch 3140 Training err. 2.72966 Training err. RA 3.05522 Valid. err. 2.76706
2018-02-03 20:32:04,557 training [INFO ] Epoch  8 Batch 3160 Training err. 2.76282 Training err. RA 3.05337 Valid. err. 2.75102
2018-02-03 20:32:04,950 training [INFO ] Epoch  8 Batch 3180 Training err. 2.67803 Training err. RA 3.05101 Valid. err. 2.74476
2018-02-03 20:32:05,342 training [INFO ] Epoch  8 Batch 3200 Training err. 2.70343 Training err. RA 3.04883 Valid. err. 2.73935
2018-02-03 20:32:05,738 training [INFO ] Epoch  8 Batch 3220 Training err. 2.66229 Training err. RA 3.04643 Valid. err. 2.74156
2018-02-03 20:32:06,132 training [INFO ] Epoch  8 Batch 3240 Training err. 2.64070 Training err. RA 3.04393 Valid. err. 2.73534
2018-02-03 20:32:06,528 training [INFO ] Epoch  8 Batch 3260 Training err. 2.69236 Training err. RA 3.04177 Valid. err. 2.72379
2018-02-03 20:32:06,923 training [INFO ] Epoch  8 Batch 3280 Training err. 2.70006 Training err. RA 3.03969 Valid. err. 2.72230
2018-02-03 20:32:07,327 training [INFO ] Epoch  8 Batch 3300 Training err. 2.71126 Training err. RA 3.03770 Valid. err. 2.74795
2018-02-03 20:32:07,724 training [INFO ] Epoch  8 Batch 3320 Training err. 2.71519 Training err. RA 3.03576 Valid. err. 2.70804
2018-02-03 20:32:08,466 training [INFO ] Epoch  9 Batch 3340 Training err. 2.70566 Training err. RA 3.03378 Valid. err. 2.70406
2018-02-03 20:32:08,853 training [INFO ] Epoch  9 Batch 3360 Training err. 2.64420 Training err. RA 3.03146 Valid. err. 2.70613
2018-02-03 20:32:09,240 training [INFO ] Epoch  9 Batch 3380 Training err. 2.65086 Training err. RA 3.02921 Valid. err. 2.70303
2018-02-03 20:32:09,632 training [INFO ] Epoch  9 Batch 3400 Training err. 2.49615 Training err. RA 3.02607 Valid. err. 2.69936
2018-02-03 20:32:10,026 training [INFO ] Epoch  9 Batch 3420 Training err. 2.76617 Training err. RA 3.02455 Valid. err. 2.70687
2018-02-03 20:32:10,413 training [INFO ] Epoch  9 Batch 3440 Training err. 2.63236 Training err. RA 3.02227 Valid. err. 2.69655
2018-02-03 20:32:10,800 training [INFO ] Epoch  9 Batch 3460 Training err. 2.64370 Training err. RA 3.02008 Valid. err. 2.68405
2018-02-03 20:32:11,190 training [INFO ] Epoch  9 Batch 3480 Training err. 2.64809 Training err. RA 3.01795 Valid. err. 2.68444
2018-02-03 20:32:11,580 training [INFO ] Epoch  9 Batch 3500 Training err. 2.58817 Training err. RA 3.01549 Valid. err. 2.68845
2018-02-03 20:32:11,977 training [INFO ] Epoch  9 Batch 3520 Training err. 2.63741 Training err. RA 3.01334 Valid. err. 2.69830
2018-02-03 20:32:12,364 training [INFO ] Epoch  9 Batch 3540 Training err. 2.66592 Training err. RA 3.01138 Valid. err. 2.68738
2018-02-03 20:32:12,755 training [INFO ] Epoch  9 Batch 3560 Training err. 2.63191 Training err. RA 3.00925 Valid. err. 2.67060
2018-02-03 20:32:13,144 training [INFO ] Epoch  9 Batch 3580 Training err. 2.69224 Training err. RA 3.00748 Valid. err. 2.67111
2018-02-03 20:32:13,536 training [INFO ] Epoch  9 Batch 3600 Training err. 2.59951 Training err. RA 3.00521 Valid. err. 2.68303
2018-02-03 20:32:13,931 training [INFO ] Epoch  9 Batch 3620 Training err. 2.63629 Training err. RA 3.00317 Valid. err. 2.65746
2018-02-03 20:32:14,320 training [INFO ] Epoch  9 Batch 3640 Training err. 2.56133 Training err. RA 3.00074 Valid. err. 2.66475
2018-02-03 20:32:14,714 training [INFO ] Epoch  9 Batch 3660 Training err. 2.56616 Training err. RA 2.99837 Valid. err. 2.65564
2018-02-03 20:32:15,110 training [INFO ] Epoch  9 Batch 3680 Training err. 2.63446 Training err. RA 2.99639 Valid. err. 2.64914
2018-02-03 20:32:15,507 training [INFO ] Epoch  9 Batch 3700 Training err. 2.60726 Training err. RA 2.99429 Valid. err. 2.66648
2018-02-03 20:32:15,898 training [INFO ] Epoch  9 Batch 3720 Training err. 2.63080 Training err. RA 2.99233 Valid. err. 2.63869
2018-02-03 20:32:16,289 training [INFO ] Epoch  9 Batch 3740 Training err. 2.64530 Training err. RA 2.99048 Valid. err. 2.63160
2018-02-03 20:32:17,036 training [INFO ] Epoch 10 Batch 3760 Training err. 2.60971 Training err. RA 2.98845 Valid. err. 2.62388
2018-02-03 20:32:17,430 training [INFO ] Epoch 10 Batch 3780 Training err. 2.58997 Training err. RA 2.98634 Valid. err. 2.64514
2018-02-03 20:32:17,821 training [INFO ] Epoch 10 Batch 3800 Training err. 2.57188 Training err. RA 2.98416 Valid. err. 2.62421
2018-02-03 20:32:18,223 training [INFO ] Epoch 10 Batch 3820 Training err. 2.44589 Training err. RA 2.98134 Valid. err. 2.63003
2018-02-03 20:32:18,618 training [INFO ] Epoch 10 Batch 3840 Training err. 2.68231 Training err. RA 2.97979 Valid. err. 2.63267
2018-02-03 20:32:19,013 training [INFO ] Epoch 10 Batch 3860 Training err. 2.55682 Training err. RA 2.97760 Valid. err. 2.62705
2018-02-03 20:32:19,404 training [INFO ] Epoch 10 Batch 3880 Training err. 2.59130 Training err. RA 2.97560 Valid. err. 2.61989
2018-02-03 20:32:19,793 training [INFO ] Epoch 10 Batch 3900 Training err. 2.58739 Training err. RA 2.97361 Valid. err. 2.60713
2018-02-03 20:32:20,187 training [INFO ] Epoch 10 Batch 3920 Training err. 2.50223 Training err. RA 2.97121 Valid. err. 2.62295
2018-02-03 20:32:20,584 training [INFO ] Epoch 10 Batch 3940 Training err. 2.54388 Training err. RA 2.96904 Valid. err. 2.61937
2018-02-03 20:32:20,978 training [INFO ] Epoch 10 Batch 3960 Training err. 2.63316 Training err. RA 2.96734 Valid. err. 2.60865
2018-02-03 20:32:21,368 training [INFO ] Epoch 10 Batch 3980 Training err. 2.58614 Training err. RA 2.96543 Valid. err. 2.60089
2018-02-03 20:32:21,761 training [INFO ] Epoch 10 Batch 4000 Training err. 2.62965 Training err. RA 2.96375 Valid. err. 2.60118
2018-02-03 20:32:22,156 training [INFO ] Epoch 10 Batch 4020 Training err. 2.52400 Training err. RA 2.96156 Valid. err. 2.59249
2018-02-03 20:32:22,553 training [INFO ] Epoch 10 Batch 4040 Training err. 2.55673 Training err. RA 2.95956 Valid. err. 2.59684
2018-02-03 20:32:22,946 training [INFO ] Epoch 10 Batch 4060 Training err. 2.49166 Training err. RA 2.95725 Valid. err. 2.59357
2018-02-03 20:32:23,335 training [INFO ] Epoch 10 Batch 4080 Training err. 2.50004 Training err. RA 2.95501 Valid. err. 2.62153
2018-02-03 20:32:23,727 training [INFO ] Epoch 10 Batch 4100 Training err. 2.58454 Training err. RA 2.95320 Valid. err. 2.57809
2018-02-03 20:32:24,127 training [INFO ] Epoch 10 Batch 4120 Training err. 2.53947 Training err. RA 2.95119 Valid. err. 2.57074
2018-02-03 20:32:24,520 training [INFO ] Epoch 10 Batch 4140 Training err. 2.56068 Training err. RA 2.94931 Valid. err. 2.57420
2018-02-03 20:32:24,910 training [INFO ] Epoch 10 Batch 4160 Training err. 2.57541 Training err. RA 2.94751 Valid. err. 2.57247
2018-02-03 20:32:25,656 training [INFO ] Epoch 11 Batch 4180 Training err. 2.52432 Training err. RA 2.94549 Valid. err. 2.56876
2018-02-03 20:32:26,052 training [INFO ] Epoch 11 Batch 4200 Training err. 2.54527 Training err. RA 2.94358 Valid. err. 2.58076
2018-02-03 20:32:26,445 training [INFO ] Epoch 11 Batch 4220 Training err. 2.47514 Training err. RA 2.94136 Valid. err. 2.56082
2018-02-03 20:32:26,837 training [INFO ] Epoch 11 Batch 4240 Training err. 2.44505 Training err. RA 2.93902 Valid. err. 2.55715
2018-02-03 20:32:27,233 training [INFO ] Epoch 11 Batch 4260 Training err. 2.60575 Training err. RA 2.93745 Valid. err. 2.56956
2018-02-03 20:32:27,626 training [INFO ] Epoch 11 Batch 4280 Training err. 2.49265 Training err. RA 2.93538 Valid. err. 2.55880
2018-02-03 20:32:28,022 training [INFO ] Epoch 11 Batch 4300 Training err. 2.54080 Training err. RA 2.93354 Valid. err. 2.55667
2018-02-03 20:32:28,412 training [INFO ] Epoch 11 Batch 4320 Training err. 2.51392 Training err. RA 2.93160 Valid. err. 2.54884
2018-02-03 20:32:28,806 training [INFO ] Epoch 11 Batch 4340 Training err. 2.44501 Training err. RA 2.92936 Valid. err. 2.55209
2018-02-03 20:32:29,203 training [INFO ] Epoch 11 Batch 4360 Training err. 2.50525 Training err. RA 2.92741 Valid. err. 2.55667
2018-02-03 20:32:29,597 training [INFO ] Epoch 11 Batch 4380 Training err. 2.56035 Training err. RA 2.92573 Valid. err. 2.53565
2018-02-03 20:32:29,996 training [INFO ] Epoch 11 Batch 4400 Training err. 2.55406 Training err. RA 2.92404 Valid. err. 2.55618
2018-02-03 20:32:30,388 training [INFO ] Epoch 11 Batch 4420 Training err. 2.55653 Training err. RA 2.92238 Valid. err. 2.53587
2018-02-03 20:32:30,788 training [INFO ] Epoch 11 Batch 4440 Training err. 2.46415 Training err. RA 2.92032 Valid. err. 2.53726
2018-02-03 20:32:31,179 training [INFO ] Epoch 11 Batch 4460 Training err. 2.50875 Training err. RA 2.91847 Valid. err. 2.52514
2018-02-03 20:32:31,572 training [INFO ] Epoch 11 Batch 4480 Training err. 2.42241 Training err. RA 2.91626 Valid. err. 2.54331
2018-02-03 20:32:31,970 training [INFO ] Epoch 11 Batch 4500 Training err. 2.44473 Training err. RA 2.91416 Valid. err. 2.54215
2018-02-03 20:32:32,360 training [INFO ] Epoch 11 Batch 4520 Training err. 2.53928 Training err. RA 2.91250 Valid. err. 2.54200
2018-02-03 20:32:32,752 training [INFO ] Epoch 11 Batch 4540 Training err. 2.49190 Training err. RA 2.91065 Valid. err. 2.52054
2018-02-03 20:32:33,144 training [INFO ] Epoch 11 Batch 4560 Training err. 2.48317 Training err. RA 2.90878 Valid. err. 2.52488
2018-02-03 20:32:33,537 training [INFO ] Epoch 11 Batch 4580 Training err. 2.51583 Training err. RA 2.90706 Valid. err. 2.50818
2018-02-03 20:32:34,278 training [INFO ] Epoch 12 Batch 4600 Training err. 2.48602 Training err. RA 2.90523 Valid. err. 2.50296
2018-02-03 20:32:34,671 training [INFO ] Epoch 12 Batch 4620 Training err. 2.46179 Training err. RA 2.90331 Valid. err. 2.51560
2018-02-03 20:32:35,067 training [INFO ] Epoch 12 Batch 4640 Training err. 2.41391 Training err. RA 2.90120 Valid. err. 2.51190
2018-02-03 20:32:35,462 training [INFO ] Epoch 12 Batch 4660 Training err. 2.43445 Training err. RA 2.89920 Valid. err. 2.54049
2018-02-03 20:32:35,853 training [INFO ] Epoch 12 Batch 4680 Training err. 2.53733 Training err. RA 2.89765 Valid. err. 2.50336
2018-02-03 20:32:36,246 training [INFO ] Epoch 12 Batch 4700 Training err. 2.42186 Training err. RA 2.89563 Valid. err. 2.51839
2018-02-03 20:32:36,639 training [INFO ] Epoch 12 Batch 4720 Training err. 2.51401 Training err. RA 2.89401 Valid. err. 2.49584
2018-02-03 20:32:37,032 training [INFO ] Epoch 12 Batch 4740 Training err. 2.45787 Training err. RA 2.89217 Valid. err. 2.50732
2018-02-03 20:32:37,422 training [INFO ] Epoch 12 Batch 4760 Training err. 2.39013 Training err. RA 2.89006 Valid. err. 2.52505
2018-02-03 20:32:37,812 training [INFO ] Epoch 12 Batch 4780 Training err. 2.45807 Training err. RA 2.88825 Valid. err. 2.48870
2018-02-03 20:32:38,208 training [INFO ] Epoch 12 Batch 4800 Training err. 2.49298 Training err. RA 2.88660 Valid. err. 2.48424
2018-02-03 20:32:38,603 training [INFO ] Epoch 12 Batch 4820 Training err. 2.52027 Training err. RA 2.88508 Valid. err. 2.49398
2018-02-03 20:32:38,998 training [INFO ] Epoch 12 Batch 4840 Training err. 2.48219 Training err. RA 2.88342 Valid. err. 2.48098
2018-02-03 20:32:39,387 training [INFO ] Epoch 12 Batch 4860 Training err. 2.43773 Training err. RA 2.88159 Valid. err. 2.48443
2018-02-03 20:32:39,780 training [INFO ] Epoch 12 Batch 4880 Training err. 2.44233 Training err. RA 2.87978 Valid. err. 2.47924
2018-02-03 20:32:40,172 training [INFO ] Epoch 12 Batch 4900 Training err. 2.38284 Training err. RA 2.87776 Valid. err. 2.48661
2018-02-03 20:32:40,569 training [INFO ] Epoch 12 Batch 4920 Training err. 2.39970 Training err. RA 2.87581 Valid. err. 2.47300
2018-02-03 20:32:40,964 training [INFO ] Epoch 12 Batch 4940 Training err. 2.48572 Training err. RA 2.87423 Valid. err. 2.46591
2018-02-03 20:32:41,354 training [INFO ] Epoch 12 Batch 4960 Training err. 2.44178 Training err. RA 2.87249 Valid. err. 2.46071
2018-02-03 20:32:41,749 training [INFO ] Epoch 12 Batch 4980 Training err. 2.43591 Training err. RA 2.87074 Valid. err. 2.46910
2018-02-03 20:32:42,149 training [INFO ] Epoch 12 Batch 5000 Training err. 2.45260 Training err. RA 2.86906 Valid. err. 2.46446
2018-02-03 20:32:42,891 training [INFO ] Epoch 13 Batch 5020 Training err. 2.44861 Training err. RA 2.86739 Valid. err. 2.45210
2018-02-03 20:32:43,283 training [INFO ] Epoch 13 Batch 5040 Training err. 2.38848 Training err. RA 2.86549 Valid. err. 2.45778
2018-02-03 20:32:43,676 training [INFO ] Epoch 13 Batch 5060 Training err. 2.34808 Training err. RA 2.86344 Valid. err. 2.45914
2018-02-03 20:32:44,072 training [INFO ] Epoch 13 Batch 5080 Training err. 2.42599 Training err. RA 2.86172 Valid. err. 2.45727
2018-02-03 20:32:44,468 training [INFO ] Epoch 13 Batch 5100 Training err. 2.47630 Training err. RA 2.86021 Valid. err. 2.44664
2018-02-03 20:32:44,858 training [INFO ] Epoch 13 Batch 5120 Training err. 2.37297 Training err. RA 2.85831 Valid. err. 2.45690
2018-02-03 20:32:45,251 training [INFO ] Epoch 13 Batch 5140 Training err. 2.48830 Training err. RA 2.85687 Valid. err. 2.44256
2018-02-03 20:32:45,645 training [INFO ] Epoch 13 Batch 5160 Training err. 2.38971 Training err. RA 2.85506 Valid. err. 2.45192
2018-02-03 20:32:46,040 training [INFO ] Epoch 13 Batch 5180 Training err. 2.36770 Training err. RA 2.85317 Valid. err. 2.45299
2018-02-03 20:32:46,431 training [INFO ] Epoch 13 Batch 5200 Training err. 2.41175 Training err. RA 2.85148 Valid. err. 2.48751
2018-02-03 20:32:46,824 training [INFO ] Epoch 13 Batch 5220 Training err. 2.42784 Training err. RA 2.84985 Valid. err. 2.46074
2018-02-03 20:32:47,220 training [INFO ] Epoch 13 Batch 5240 Training err. 2.49541 Training err. RA 2.84850 Valid. err. 2.46333
2018-02-03 20:32:47,610 training [INFO ] Epoch 13 Batch 5260 Training err. 2.41680 Training err. RA 2.84686 Valid. err. 2.44409
2018-02-03 20:32:48,013 training [INFO ] Epoch 13 Batch 5280 Training err. 2.38973 Training err. RA 2.84513 Valid. err. 2.43265
2018-02-03 20:32:48,404 training [INFO ] Epoch 13 Batch 5300 Training err. 2.39036 Training err. RA 2.84341 Valid. err. 2.43409
2018-02-03 20:32:48,799 training [INFO ] Epoch 13 Batch 5320 Training err. 2.34704 Training err. RA 2.84155 Valid. err. 2.42844
2018-02-03 20:32:49,193 training [INFO ] Epoch 13 Batch 5340 Training err. 2.37513 Training err. RA 2.83980 Valid. err. 2.43963
2018-02-03 20:32:49,589 training [INFO ] Epoch 13 Batch 5360 Training err. 2.42674 Training err. RA 2.83826 Valid. err. 2.42241
2018-02-03 20:32:49,985 training [INFO ] Epoch 13 Batch 5380 Training err. 2.39820 Training err. RA 2.83662 Valid. err. 2.42528
2018-02-03 20:32:50,374 training [INFO ] Epoch 13 Batch 5400 Training err. 2.39338 Training err. RA 2.83498 Valid. err. 2.41393
2018-02-03 20:32:50,767 training [INFO ] Epoch 13 Batch 5420 Training err. 2.41808 Training err. RA 2.83344 Valid. err. 2.41133
2018-02-03 20:32:51,516 training [INFO ] Epoch 14 Batch 5440 Training err. 2.40839 Training err. RA 2.83188 Valid. err. 2.45098
2018-02-03 20:32:51,907 training [INFO ] Epoch 14 Batch 5460 Training err. 2.33401 Training err. RA 2.83006 Valid. err. 2.42151
2018-02-03 20:32:52,306 training [INFO ] Epoch 14 Batch 5480 Training err. 2.28719 Training err. RA 2.82807 Valid. err. 2.41341
2018-02-03 20:32:52,712 training [INFO ] Epoch 14 Batch 5500 Training err. 2.40367 Training err. RA 2.82653 Valid. err. 2.42835
2018-02-03 20:32:53,122 training [INFO ] Epoch 14 Batch 5520 Training err. 2.42075 Training err. RA 2.82506 Valid. err. 2.41898
2018-02-03 20:32:53,531 training [INFO ] Epoch 14 Batch 5540 Training err. 2.34128 Training err. RA 2.82331 Valid. err. 2.41264
2018-02-03 20:32:53,943 training [INFO ] Epoch 14 Batch 5560 Training err. 2.42892 Training err. RA 2.82190 Valid. err. 2.39971
2018-02-03 20:32:54,360 training [INFO ] Epoch 14 Batch 5580 Training err. 2.33088 Training err. RA 2.82014 Valid. err. 2.41469
2018-02-03 20:32:54,767 training [INFO ] Epoch 14 Batch 5600 Training err. 2.36704 Training err. RA 2.81852 Valid. err. 2.40961
2018-02-03 20:32:55,175 training [INFO ] Epoch 14 Batch 5620 Training err. 2.35755 Training err. RA 2.81688 Valid. err. 2.40262
2018-02-03 20:32:55,583 training [INFO ] Epoch 14 Batch 5640 Training err. 2.39899 Training err. RA 2.81539 Valid. err. 2.39604
2018-02-03 20:32:55,992 training [INFO ] Epoch 14 Batch 5660 Training err. 2.46369 Training err. RA 2.81415 Valid. err. 2.40352
2018-02-03 20:32:56,394 training [INFO ] Epoch 14 Batch 5680 Training err. 2.35903 Training err. RA 2.81255 Valid. err. 2.40714
2018-02-03 20:32:56,801 training [INFO ] Epoch 14 Batch 5700 Training err. 2.36420 Training err. RA 2.81098 Valid. err. 2.40869
2018-02-03 20:32:57,212 training [INFO ] Epoch 14 Batch 5720 Training err. 2.34497 Training err. RA 2.80935 Valid. err. 2.38998
2018-02-03 20:32:57,621 training [INFO ] Epoch 14 Batch 5740 Training err. 2.30511 Training err. RA 2.80759 Valid. err. 2.38895
2018-02-03 20:32:58,029 training [INFO ] Epoch 14 Batch 5760 Training err. 2.35208 Training err. RA 2.80601 Valid. err. 2.39519
2018-02-03 20:32:58,431 training [INFO ] Epoch 14 Batch 5780 Training err. 2.36960 Training err. RA 2.80450 Valid. err. 2.37794
2018-02-03 20:32:58,835 training [INFO ] Epoch 14 Batch 5800 Training err. 2.36458 Training err. RA 2.80298 Valid. err. 2.38391
2018-02-03 20:32:59,241 training [INFO ] Epoch 14 Batch 5820 Training err. 2.35964 Training err. RA 2.80146 Valid. err. 2.37240
2018-02-03 20:33:00,008 training [INFO ] Epoch 15 Batch 5840 Training err. 2.37559 Training err. RA 2.80000 Valid. err. 2.38346
2018-02-03 20:33:00,418 training [INFO ] Epoch 15 Batch 5860 Training err. 2.33113 Training err. RA 2.79840 Valid. err. 2.38125
2018-02-03 20:33:00,824 training [INFO ] Epoch 15 Batch 5880 Training err. 2.32481 Training err. RA 2.79679 Valid. err. 2.37999
2018-02-03 20:33:01,229 training [INFO ] Epoch 15 Batch 5900 Training err. 2.20388 Training err. RA 2.79478 Valid. err. 2.37972
2018-02-03 20:33:01,639 training [INFO ] Epoch 15 Batch 5920 Training err. 2.41775 Training err. RA 2.79350 Valid. err. 2.36679
2018-02-03 20:33:02,045 training [INFO ] Epoch 15 Batch 5940 Training err. 2.35201 Training err. RA 2.79202 Valid. err. 2.37654
2018-02-03 20:33:02,447 training [INFO ] Epoch 15 Batch 5960 Training err. 2.33324 Training err. RA 2.79048 Valid. err. 2.36664
2018-02-03 20:33:02,851 training [INFO ] Epoch 15 Batch 5980 Training err. 2.37222 Training err. RA 2.78908 Valid. err. 2.37897
2018-02-03 20:33:03,258 training [INFO ] Epoch 15 Batch 6000 Training err. 2.28934 Training err. RA 2.78741 Valid. err. 2.36689
2018-02-03 20:33:03,660 training [INFO ] Epoch 15 Batch 6020 Training err. 2.34990 Training err. RA 2.78596 Valid. err. 2.37052
2018-02-03 20:33:04,068 training [INFO ] Epoch 15 Batch 6040 Training err. 2.33944 Training err. RA 2.78448 Valid. err. 2.36780
2018-02-03 20:33:04,470 training [INFO ] Epoch 15 Batch 6060 Training err. 2.34655 Training err. RA 2.78304 Valid. err. 2.38503
2018-02-03 20:33:04,874 training [INFO ] Epoch 15 Batch 6080 Training err. 2.42509 Training err. RA 2.78186 Valid. err. 2.35780
2018-02-03 20:33:05,279 training [INFO ] Epoch 15 Batch 6100 Training err. 2.32411 Training err. RA 2.78036 Valid. err. 2.37370
2018-02-03 20:33:05,685 training [INFO ] Epoch 15 Batch 6120 Training err. 2.31903 Training err. RA 2.77885 Valid. err. 2.35722
2018-02-03 20:33:06,094 training [INFO ] Epoch 15 Batch 6140 Training err. 2.30562 Training err. RA 2.77731 Valid. err. 2.35952
2018-02-03 20:33:06,500 training [INFO ] Epoch 15 Batch 6160 Training err. 2.28196 Training err. RA 2.77570 Valid. err. 2.35917
2018-02-03 20:33:06,903 training [INFO ] Epoch 15 Batch 6180 Training err. 2.32192 Training err. RA 2.77423 Valid. err. 2.34981
2018-02-03 20:33:07,307 training [INFO ] Epoch 15 Batch 6200 Training err. 2.30991 Training err. RA 2.77273 Valid. err. 2.34470
2018-02-03 20:33:07,714 training [INFO ] Epoch 15 Batch 6220 Training err. 2.34866 Training err. RA 2.77137 Valid. err. 2.35967
2018-02-03 20:33:08,117 training [INFO ] Epoch 15 Batch 6240 Training err. 2.31792 Training err. RA 2.76992 Valid. err. 2.36151
2018-02-03 20:33:08,904 training [INFO ] Epoch 16 Batch 6260 Training err. 2.32919 Training err. RA 2.76851 Valid. err. 2.33946
2018-02-03 20:33:09,313 training [INFO ] Epoch 16 Batch 6280 Training err. 2.29484 Training err. RA 2.76700 Valid. err. 2.34255
2018-02-03 20:33:09,720 training [INFO ] Epoch 16 Batch 6300 Training err. 2.29553 Training err. RA 2.76550 Valid. err. 2.35751
2018-02-03 20:33:10,125 training [INFO ] Epoch 16 Batch 6320 Training err. 2.17231 Training err. RA 2.76363 Valid. err. 2.36514
2018-02-03 20:33:10,532 training [INFO ] Epoch 16 Batch 6340 Training err. 2.38420 Training err. RA 2.76243 Valid. err. 2.34245
2018-02-03 20:33:10,935 training [INFO ] Epoch 16 Batch 6360 Training err. 2.30383 Training err. RA 2.76099 Valid. err. 2.34390
2018-02-03 20:33:11,345 training [INFO ] Epoch 16 Batch 6380 Training err. 2.32186 Training err. RA 2.75961 Valid. err. 2.34292
2018-02-03 20:33:11,751 training [INFO ] Epoch 16 Batch 6400 Training err. 2.32332 Training err. RA 2.75825 Valid. err. 2.33647
2018-02-03 20:33:12,160 training [INFO ] Epoch 16 Batch 6420 Training err. 2.25348 Training err. RA 2.75668 Valid. err. 2.33585
2018-02-03 20:33:12,568 training [INFO ] Epoch 16 Batch 6440 Training err. 2.30770 Training err. RA 2.75528 Valid. err. 2.33074
2018-02-03 20:33:12,973 training [INFO ] Epoch 16 Batch 6460 Training err. 2.33644 Training err. RA 2.75398 Valid. err. 2.35534
2018-02-03 20:33:13,374 training [INFO ] Epoch 16 Batch 6480 Training err. 2.32276 Training err. RA 2.75265 Valid. err. 2.34268
2018-02-03 20:33:13,781 training [INFO ] Epoch 16 Batch 6500 Training err. 2.38450 Training err. RA 2.75152 Valid. err. 2.33859
2018-02-03 20:33:14,185 training [INFO ] Epoch 16 Batch 6520 Training err. 2.28571 Training err. RA 2.75009 Valid. err. 2.32147
2018-02-03 20:33:14,594 training [INFO ] Epoch 16 Batch 6540 Training err. 2.28451 Training err. RA 2.74867 Valid. err. 2.32547
2018-02-03 20:33:15,003 training [INFO ] Epoch 16 Batch 6560 Training err. 2.24978 Training err. RA 2.74715 Valid. err. 2.33789
2018-02-03 20:33:15,406 training [INFO ] Epoch 16 Batch 6580 Training err. 2.25130 Training err. RA 2.74564 Valid. err. 2.32772
2018-02-03 20:33:15,813 training [INFO ] Epoch 16 Batch 6600 Training err. 2.30771 Training err. RA 2.74431 Valid. err. 2.32161
2018-02-03 20:33:16,220 training [INFO ] Epoch 16 Batch 6620 Training err. 2.27106 Training err. RA 2.74288 Valid. err. 2.31178
2018-02-03 20:33:16,626 training [INFO ] Epoch 16 Batch 6640 Training err. 2.30858 Training err. RA 2.74157 Valid. err. 2.31182
2018-02-03 20:33:17,033 training [INFO ] Epoch 16 Batch 6660 Training err. 2.29213 Training err. RA 2.74023 Valid. err. 2.30680
2018-02-03 20:33:17,796 training [INFO ] Epoch 17 Batch 6680 Training err. 2.28282 Training err. RA 2.73886 Valid. err. 2.30303
2018-02-03 20:33:18,201 training [INFO ] Epoch 17 Batch 6700 Training err. 2.28653 Training err. RA 2.73751 Valid. err. 2.32106
2018-02-03 20:33:18,611 training [INFO ] Epoch 17 Batch 6720 Training err. 2.23910 Training err. RA 2.73602 Valid. err. 2.30839
2018-02-03 20:33:19,015 training [INFO ] Epoch 17 Batch 6740 Training err. 2.17241 Training err. RA 2.73435 Valid. err. 2.31210
2018-02-03 20:33:19,415 training [INFO ] Epoch 17 Batch 6760 Training err. 2.33729 Training err. RA 2.73318 Valid. err. 2.30998
2018-02-03 20:33:19,819 training [INFO ] Epoch 17 Batch 6780 Training err. 2.27321 Training err. RA 2.73182 Valid. err. 2.32651
2018-02-03 20:33:20,223 training [INFO ] Epoch 17 Batch 6800 Training err. 2.30185 Training err. RA 2.73055 Valid. err. 2.30044
2018-02-03 20:33:20,631 training [INFO ] Epoch 17 Batch 6820 Training err. 2.28704 Training err. RA 2.72925 Valid. err. 2.30161
2018-02-03 20:33:21,037 training [INFO ] Epoch 17 Batch 6840 Training err. 2.22024 Training err. RA 2.72776 Valid. err. 2.30935
2018-02-03 20:33:21,435 training [INFO ] Epoch 17 Batch 6860 Training err. 2.25944 Training err. RA 2.72640 Valid. err. 2.30081
2018-02-03 20:33:21,841 training [INFO ] Epoch 17 Batch 6880 Training err. 2.31981 Training err. RA 2.72522 Valid. err. 2.29781
2018-02-03 20:33:22,244 training [INFO ] Epoch 17 Batch 6900 Training err. 2.31573 Training err. RA 2.72403 Valid. err. 2.30325
2018-02-03 20:33:22,647 training [INFO ] Epoch 17 Batch 6920 Training err. 2.35344 Training err. RA 2.72296 Valid. err. 2.29680
2018-02-03 20:33:23,055 training [INFO ] Epoch 17 Batch 6940 Training err. 2.24599 Training err. RA 2.72158 Valid. err. 2.30263
2018-02-03 20:33:23,455 training [INFO ] Epoch 17 Batch 6960 Training err. 2.26174 Training err. RA 2.72026 Valid. err. 2.30640
2018-02-03 20:33:23,868 training [INFO ] Epoch 17 Batch 6980 Training err. 2.20099 Training err. RA 2.71878 Valid. err. 2.29190
2018-02-03 20:33:24,272 training [INFO ] Epoch 17 Batch 7000 Training err. 2.21792 Training err. RA 2.71734 Valid. err. 2.28886
2018-02-03 20:33:24,678 training [INFO ] Epoch 17 Batch 7020 Training err. 2.29238 Training err. RA 2.71613 Valid. err. 2.29520
2018-02-03 20:33:25,085 training [INFO ] Epoch 17 Batch 7040 Training err. 2.24632 Training err. RA 2.71480 Valid. err. 2.28229
2018-02-03 20:33:25,486 training [INFO ] Epoch 17 Batch 7060 Training err. 2.25744 Training err. RA 2.71350 Valid. err. 2.28260
2018-02-03 20:33:25,889 training [INFO ] Epoch 17 Batch 7080 Training err. 2.26375 Training err. RA 2.71223 Valid. err. 2.27955
2018-02-03 20:33:26,656 training [INFO ] Epoch 18 Batch 7100 Training err. 2.25736 Training err. RA 2.71095 Valid. err. 2.28348
2018-02-03 20:33:27,059 training [INFO ] Epoch 18 Batch 7120 Training err. 2.24666 Training err. RA 2.70965 Valid. err. 2.30855
2018-02-03 20:33:27,459 training [INFO ] Epoch 18 Batch 7140 Training err. 2.19344 Training err. RA 2.70820 Valid. err. 2.29005
2018-02-03 20:33:27,863 training [INFO ] Epoch 18 Batch 7160 Training err. 2.18710 Training err. RA 2.70675 Valid. err. 2.28400
2018-02-03 20:33:28,266 training [INFO ] Epoch 18 Batch 7180 Training err. 2.30392 Training err. RA 2.70562 Valid. err. 2.31907
2018-02-03 20:33:28,671 training [INFO ] Epoch 18 Batch 7200 Training err. 2.23695 Training err. RA 2.70432 Valid. err. 2.29194
2018-02-03 20:33:29,073 training [INFO ] Epoch 18 Batch 7220 Training err. 2.27563 Training err. RA 2.70313 Valid. err. 2.27314
2018-02-03 20:33:29,471 training [INFO ] Epoch 18 Batch 7240 Training err. 2.24613 Training err. RA 2.70187 Valid. err. 2.28465
2018-02-03 20:33:29,874 training [INFO ] Epoch 18 Batch 7260 Training err. 2.20437 Training err. RA 2.70050 Valid. err. 2.29253
2018-02-03 20:33:30,277 training [INFO ] Epoch 18 Batch 7280 Training err. 2.23434 Training err. RA 2.69922 Valid. err. 2.27654
2018-02-03 20:33:30,682 training [INFO ] Epoch 18 Batch 7300 Training err. 2.28458 Training err. RA 2.69808 Valid. err. 2.26760
2018-02-03 20:33:31,091 training [INFO ] Epoch 18 Batch 7320 Training err. 2.30891 Training err. RA 2.69702 Valid. err. 2.28213
2018-02-03 20:33:31,493 training [INFO ] Epoch 18 Batch 7340 Training err. 2.29705 Training err. RA 2.69593 Valid. err. 2.27382
2018-02-03 20:33:31,894 training [INFO ] Epoch 18 Batch 7360 Training err. 2.22751 Training err. RA 2.69466 Valid. err. 2.26518
2018-02-03 20:33:32,299 training [INFO ] Epoch 18 Batch 7380 Training err. 2.23466 Training err. RA 2.69341 Valid. err. 2.27743
2018-02-03 20:33:32,704 training [INFO ] Epoch 18 Batch 7400 Training err. 2.16995 Training err. RA 2.69200 Valid. err. 2.26920
2018-02-03 20:33:33,105 training [INFO ] Epoch 18 Batch 7420 Training err. 2.19842 Training err. RA 2.69067 Valid. err. 2.28434
2018-02-03 20:33:33,512 training [INFO ] Epoch 18 Batch 7440 Training err. 2.27004 Training err. RA 2.68954 Valid. err. 2.25815
2018-02-03 20:33:33,912 training [INFO ] Epoch 18 Batch 7460 Training err. 2.22260 Training err. RA 2.68828 Valid. err. 2.26182
2018-02-03 20:33:34,319 training [INFO ] Epoch 18 Batch 7480 Training err. 2.22510 Training err. RA 2.68705 Valid. err. 2.27175
2018-02-03 20:33:34,725 training [INFO ] Epoch 18 Batch 7500 Training err. 2.22757 Training err. RA 2.68582 Valid. err. 2.24925
2018-02-03 20:33:35,490 training [INFO ] Epoch 19 Batch 7520 Training err. 2.25761 Training err. RA 2.68468 Valid. err. 2.25399
2018-02-03 20:33:35,891 training [INFO ] Epoch 19 Batch 7540 Training err. 2.18341 Training err. RA 2.68335 Valid. err. 2.26535
2018-02-03 20:33:36,296 training [INFO ] Epoch 19 Batch 7560 Training err. 2.15581 Training err. RA 2.68196 Valid. err. 2.25236
2018-02-03 20:33:36,701 training [INFO ] Epoch 19 Batch 7580 Training err. 2.19783 Training err. RA 2.68068 Valid. err. 2.25514
2018-02-03 20:33:37,109 training [INFO ] Epoch 19 Batch 7600 Training err. 2.26935 Training err. RA 2.67960 Valid. err. 2.25949
2018-02-03 20:33:37,512 training [INFO ] Epoch 19 Batch 7620 Training err. 2.19541 Training err. RA 2.67833 Valid. err. 2.26243
2018-02-03 20:33:37,911 training [INFO ] Epoch 19 Batch 7640 Training err. 2.27688 Training err. RA 2.67728 Valid. err. 2.28224
2018-02-03 20:33:38,314 training [INFO ] Epoch 19 Batch 7660 Training err. 2.21429 Training err. RA 2.67607 Valid. err. 2.25518
2018-02-03 20:33:38,718 training [INFO ] Epoch 19 Batch 7680 Training err. 2.18447 Training err. RA 2.67479 Valid. err. 2.25194
2018-02-03 20:33:39,124 training [INFO ] Epoch 19 Batch 7700 Training err. 2.21382 Training err. RA 2.67359 Valid. err. 2.24539
2018-02-03 20:33:39,527 training [INFO ] Epoch 19 Batch 7720 Training err. 2.23872 Training err. RA 2.67246 Valid. err. 2.25148
2018-02-03 20:33:39,927 training [INFO ] Epoch 19 Batch 7740 Training err. 2.31142 Training err. RA 2.67153 Valid. err. 2.24394
2018-02-03 20:33:40,332 training [INFO ] Epoch 19 Batch 7760 Training err. 2.24302 Training err. RA 2.67042 Valid. err. 2.24188
2018-02-03 20:33:40,736 training [INFO ] Epoch 19 Batch 7780 Training err. 2.19612 Training err. RA 2.66921 Valid. err. 2.24708
2018-02-03 20:33:41,145 training [INFO ] Epoch 19 Batch 7800 Training err. 2.20580 Training err. RA 2.66802 Valid. err. 2.25055
2018-02-03 20:33:41,552 training [INFO ] Epoch 19 Batch 7820 Training err. 2.15458 Training err. RA 2.66670 Valid. err. 2.23963
2018-02-03 20:33:41,963 training [INFO ] Epoch 19 Batch 7840 Training err. 2.17936 Training err. RA 2.66546 Valid. err. 2.23566
2018-02-03 20:33:42,369 training [INFO ] Epoch 19 Batch 7860 Training err. 2.23678 Training err. RA 2.66437 Valid. err. 2.23394
2018-02-03 20:33:42,777 training [INFO ] Epoch 19 Batch 7880 Training err. 2.20609 Training err. RA 2.66321 Valid. err. 2.23582
2018-02-03 20:33:43,184 training [INFO ] Epoch 19 Batch 7900 Training err. 2.19911 Training err. RA 2.66203 Valid. err. 2.22917
2018-02-03 20:33:43,596 training [INFO ] Epoch 19 Batch 7920 Training err. 2.19903 Training err. RA 2.66086 Valid. err. 2.23031
2018-02-03 20:33:44,365 training [INFO ] Epoch 20 Batch 7940 Training err. 2.23036 Training err. RA 2.65978 Valid. err. 2.22831
2018-02-03 20:33:44,770 training [INFO ] Epoch 20 Batch 7960 Training err. 2.15266 Training err. RA 2.65850 Valid. err. 2.23401
2018-02-03 20:33:45,179 training [INFO ] Epoch 20 Batch 7980 Training err. 2.13011 Training err. RA 2.65718 Valid. err. 2.23598
2018-02-03 20:33:45,590 training [INFO ] Epoch 20 Batch 8000 Training err. 2.18567 Training err. RA 2.65600 Valid. err. 2.23325
2018-02-03 20:33:45,996 training [INFO ] Epoch 20 Batch 8020 Training err. 2.25691 Training err. RA 2.65501 Valid. err. 2.23384
2018-02-03 20:33:46,399 training [INFO ] Epoch 20 Batch 8040 Training err. 2.15646 Training err. RA 2.65377 Valid. err. 2.23609
2018-02-03 20:33:46,804 training [INFO ] Epoch 20 Batch 8060 Training err. 2.27744 Training err. RA 2.65283 Valid. err. 2.24444
2018-02-03 20:33:47,211 training [INFO ] Epoch 20 Batch 8080 Training err. 2.17008 Training err. RA 2.65164 Valid. err. 2.24856
2018-02-03 20:33:47,619 training [INFO ] Epoch 20 Batch 8100 Training err. 2.16882 Training err. RA 2.65044 Valid. err. 2.22697
2018-02-03 20:33:48,032 training [INFO ] Epoch 20 Batch 8120 Training err. 2.19271 Training err. RA 2.64932 Valid. err. 2.22685
2018-02-03 20:33:48,435 training [INFO ] Epoch 20 Batch 8140 Training err. 2.20703 Training err. RA 2.64823 Valid. err. 2.22266
2018-02-03 20:33:48,841 training [INFO ] Epoch 20 Batch 8160 Training err. 2.29033 Training err. RA 2.64735 Valid. err. 2.24169
2018-02-03 20:33:49,247 training [INFO ] Epoch 20 Batch 8180 Training err. 2.21181 Training err. RA 2.64629 Valid. err. 2.24096
2018-02-03 20:33:49,655 training [INFO ] Epoch 20 Batch 8200 Training err. 2.18577 Training err. RA 2.64517 Valid. err. 2.22179
2018-02-03 20:33:50,061 training [INFO ] Epoch 20 Batch 8220 Training err. 2.18127 Training err. RA 2.64404 Valid. err. 2.22017
2018-02-03 20:33:50,461 training [INFO ] Epoch 20 Batch 8240 Training err. 2.13202 Training err. RA 2.64279 Valid. err. 2.23690
2018-02-03 20:33:50,865 training [INFO ] Epoch 20 Batch 8260 Training err. 2.17231 Training err. RA 2.64165 Valid. err. 2.21577
2018-02-03 20:33:51,268 training [INFO ] Epoch 20 Batch 8280 Training err. 2.20184 Training err. RA 2.64059 Valid. err. 2.22325
2018-02-03 20:33:51,671 training [INFO ] Epoch 20 Batch 8300 Training err. 2.18093 Training err. RA 2.63948 Valid. err. 2.22756
2018-02-03 20:33:52,075 training [INFO ] Epoch 20 Batch 8320 Training err. 2.17255 Training err. RA 2.63836 Valid. err. 2.20693
2018-02-03 20:33:52,475 training [INFO ] Epoch 20 Batch 8340 Training err. 2.19897 Training err. RA 2.63731 Valid. err. 2.22163
2018-02-03 20:33:52,775 __main__ [INFO ] End of training
2018-02-03 20:33:53,036 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 64,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:33:53,036 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:33:53,540 training [INFO ] Epoch  1 Batch   20 Training err. 3.62791 Training err. RA 3.62791 Valid. err. 3.34025
2018-02-03 20:33:53,935 training [INFO ] Epoch  1 Batch   40 Training err. 3.15398 Training err. RA 3.39094 Valid. err. 3.22220
2018-02-03 20:33:54,326 training [INFO ] Epoch  1 Batch   60 Training err. 3.11176 Training err. RA 3.29788 Valid. err. 3.20479
2018-02-03 20:33:54,721 training [INFO ] Epoch  1 Batch   80 Training err. 3.17240 Training err. RA 3.26651 Valid. err. 3.19249
2018-02-03 20:33:55,112 training [INFO ] Epoch  1 Batch  100 Training err. 3.14030 Training err. RA 3.24127 Valid. err. 3.21909
2018-02-03 20:33:55,505 training [INFO ] Epoch  1 Batch  120 Training err. 3.12432 Training err. RA 3.22178 Valid. err. 3.18345
2018-02-03 20:33:55,901 training [INFO ] Epoch  1 Batch  140 Training err. 3.13342 Training err. RA 3.20916 Valid. err. 3.26738
2018-02-03 20:33:56,302 training [INFO ] Epoch  1 Batch  160 Training err. 3.10440 Training err. RA 3.19606 Valid. err. 3.31616
2018-02-03 20:33:56,695 training [INFO ] Epoch  1 Batch  180 Training err. 3.13365 Training err. RA 3.18913 Valid. err. 3.16327
2018-02-03 20:33:57,089 training [INFO ] Epoch  1 Batch  200 Training err. 3.09473 Training err. RA 3.17969 Valid. err. 3.13737
2018-02-03 20:33:57,481 training [INFO ] Epoch  1 Batch  220 Training err. 3.11507 Training err. RA 3.17381 Valid. err. 3.12434
2018-02-03 20:33:57,875 training [INFO ] Epoch  1 Batch  240 Training err. 3.08139 Training err. RA 3.16611 Valid. err. 3.10246
2018-02-03 20:33:58,269 training [INFO ] Epoch  1 Batch  260 Training err. 3.01307 Training err. RA 3.15434 Valid. err. 3.06024
2018-02-03 20:33:58,671 training [INFO ] Epoch  1 Batch  280 Training err. 2.98910 Training err. RA 3.14254 Valid. err. 3.00534
2018-02-03 20:33:59,067 training [INFO ] Epoch  1 Batch  300 Training err. 2.93822 Training err. RA 3.12892 Valid. err. 2.97786
2018-02-03 20:33:59,457 training [INFO ] Epoch  1 Batch  320 Training err. 2.82759 Training err. RA 3.11008 Valid. err. 3.00091
2018-02-03 20:33:59,855 training [INFO ] Epoch  1 Batch  340 Training err. 2.92562 Training err. RA 3.09923 Valid. err. 2.88265
2018-02-03 20:34:00,252 training [INFO ] Epoch  1 Batch  360 Training err. 2.83136 Training err. RA 3.08435 Valid. err. 2.88598
2018-02-03 20:34:00,651 training [INFO ] Epoch  1 Batch  380 Training err. 2.81942 Training err. RA 3.07041 Valid. err. 2.82583
2018-02-03 20:34:01,047 training [INFO ] Epoch  1 Batch  400 Training err. 2.80414 Training err. RA 3.05709 Valid. err. 2.78664
2018-02-03 20:34:01,784 training [INFO ] Epoch  2 Batch  420 Training err. 2.77820 Training err. RA 3.04381 Valid. err. 2.83841
2018-02-03 20:34:02,181 training [INFO ] Epoch  2 Batch  440 Training err. 2.68554 Training err. RA 3.02753 Valid. err. 3.00829
2018-02-03 20:34:02,577 training [INFO ] Epoch  2 Batch  460 Training err. 2.67251 Training err. RA 3.01209 Valid. err. 2.77756
2018-02-03 20:34:02,967 training [INFO ] Epoch  2 Batch  480 Training err. 2.48998 Training err. RA 2.99034 Valid. err. 2.69507
2018-02-03 20:34:03,360 training [INFO ] Epoch  2 Batch  500 Training err. 2.70791 Training err. RA 2.97904 Valid. err. 2.64724
2018-02-03 20:34:03,751 training [INFO ] Epoch  2 Batch  520 Training err. 2.59365 Training err. RA 2.96422 Valid. err. 2.63056
2018-02-03 20:34:04,146 training [INFO ] Epoch  2 Batch  540 Training err. 2.55962 Training err. RA 2.94923 Valid. err. 2.61079
2018-02-03 20:34:04,542 training [INFO ] Epoch  2 Batch  560 Training err. 2.55889 Training err. RA 2.93529 Valid. err. 2.58208
2018-02-03 20:34:04,932 training [INFO ] Epoch  2 Batch  580 Training err. 2.48133 Training err. RA 2.91964 Valid. err. 2.56193
2018-02-03 20:34:05,329 training [INFO ] Epoch  2 Batch  600 Training err. 2.51350 Training err. RA 2.90610 Valid. err. 2.54416
2018-02-03 20:34:05,725 training [INFO ] Epoch  2 Batch  620 Training err. 2.50283 Training err. RA 2.89309 Valid. err. 2.51466
2018-02-03 20:34:06,124 training [INFO ] Epoch  2 Batch  640 Training err. 2.48673 Training err. RA 2.88039 Valid. err. 2.52921
2018-02-03 20:34:06,515 training [INFO ] Epoch  2 Batch  660 Training err. 2.53939 Training err. RA 2.87006 Valid. err. 2.47564
2018-02-03 20:34:06,907 training [INFO ] Epoch  2 Batch  680 Training err. 2.43684 Training err. RA 2.85732 Valid. err. 2.47618
2018-02-03 20:34:07,304 training [INFO ] Epoch  2 Batch  700 Training err. 2.43037 Training err. RA 2.84512 Valid. err. 2.47783
2018-02-03 20:34:07,697 training [INFO ] Epoch  2 Batch  720 Training err. 2.37301 Training err. RA 2.83200 Valid. err. 2.48366
2018-02-03 20:34:08,093 training [INFO ] Epoch  2 Batch  740 Training err. 2.35752 Training err. RA 2.81918 Valid. err. 2.42130
2018-02-03 20:34:08,489 training [INFO ] Epoch  2 Batch  760 Training err. 2.37661 Training err. RA 2.80753 Valid. err. 2.40825
2018-02-03 20:34:08,883 training [INFO ] Epoch  2 Batch  780 Training err. 2.35684 Training err. RA 2.79598 Valid. err. 2.40084
2018-02-03 20:34:09,276 training [INFO ] Epoch  2 Batch  800 Training err. 2.37951 Training err. RA 2.78557 Valid. err. 2.37572
2018-02-03 20:34:09,669 training [INFO ] Epoch  2 Batch  820 Training err. 2.34671 Training err. RA 2.77486 Valid. err. 2.34011
2018-02-03 20:34:10,404 training [INFO ] Epoch  3 Batch  840 Training err. 2.33084 Training err. RA 2.76429 Valid. err. 2.34091
2018-02-03 20:34:10,791 training [INFO ] Epoch  3 Batch  860 Training err. 2.31432 Training err. RA 2.75383 Valid. err. 2.44194
2018-02-03 20:34:11,184 training [INFO ] Epoch  3 Batch  880 Training err. 2.28661 Training err. RA 2.74321 Valid. err. 2.31343
2018-02-03 20:34:11,577 training [INFO ] Epoch  3 Batch  900 Training err. 2.14034 Training err. RA 2.72981 Valid. err. 2.30936
2018-02-03 20:34:11,963 training [INFO ] Epoch  3 Batch  920 Training err. 2.35424 Training err. RA 2.72165 Valid. err. 2.31618
2018-02-03 20:34:12,352 training [INFO ] Epoch  3 Batch  940 Training err. 2.27286 Training err. RA 2.71210 Valid. err. 2.28774
2018-02-03 20:34:12,742 training [INFO ] Epoch  3 Batch  960 Training err. 2.27630 Training err. RA 2.70302 Valid. err. 2.30165
2018-02-03 20:34:13,139 training [INFO ] Epoch  3 Batch  980 Training err. 2.27001 Training err. RA 2.69418 Valid. err. 2.29986
2018-02-03 20:34:13,534 training [INFO ] Epoch  3 Batch 1000 Training err. 2.19615 Training err. RA 2.68422 Valid. err. 2.28557
2018-02-03 20:34:13,945 training [INFO ] Epoch  3 Batch 1020 Training err. 2.22968 Training err. RA 2.67531 Valid. err. 2.25525
2018-02-03 20:34:14,340 training [INFO ] Epoch  3 Batch 1040 Training err. 2.28286 Training err. RA 2.66776 Valid. err. 2.28184
2018-02-03 20:34:14,733 training [INFO ] Epoch  3 Batch 1060 Training err. 2.27019 Training err. RA 2.66026 Valid. err. 2.33916
2018-02-03 20:34:15,128 training [INFO ] Epoch  3 Batch 1080 Training err. 2.29607 Training err. RA 2.65351 Valid. err. 2.23492
2018-02-03 20:34:15,520 training [INFO ] Epoch  3 Batch 1100 Training err. 2.19854 Training err. RA 2.64524 Valid. err. 2.23655
2018-02-03 20:34:15,922 training [INFO ] Epoch  3 Batch 1120 Training err. 2.16711 Training err. RA 2.63670 Valid. err. 2.25364
2018-02-03 20:34:16,316 training [INFO ] Epoch  3 Batch 1140 Training err. 2.14041 Training err. RA 2.62800 Valid. err. 2.30548
2018-02-03 20:34:16,708 training [INFO ] Epoch  3 Batch 1160 Training err. 2.15557 Training err. RA 2.61985 Valid. err. 2.21523
2018-02-03 20:34:17,101 training [INFO ] Epoch  3 Batch 1180 Training err. 2.18387 Training err. RA 2.61246 Valid. err. 2.20016
2018-02-03 20:34:17,493 training [INFO ] Epoch  3 Batch 1200 Training err. 2.14025 Training err. RA 2.60459 Valid. err. 2.18957
2018-02-03 20:34:17,895 training [INFO ] Epoch  3 Batch 1220 Training err. 2.17194 Training err. RA 2.59750 Valid. err. 2.18458
2018-02-03 20:34:18,287 training [INFO ] Epoch  3 Batch 1240 Training err. 2.14498 Training err. RA 2.59020 Valid. err. 2.18118
2018-02-03 20:34:19,038 training [INFO ] Epoch  4 Batch 1260 Training err. 2.13030 Training err. RA 2.58290 Valid. err. 2.17470
2018-02-03 20:34:19,429 training [INFO ] Epoch  4 Batch 1280 Training err. 2.15799 Training err. RA 2.57626 Valid. err. 2.15510
2018-02-03 20:34:19,825 training [INFO ] Epoch  4 Batch 1300 Training err. 2.07512 Training err. RA 2.56855 Valid. err. 2.15466
2018-02-03 20:34:20,217 training [INFO ] Epoch  4 Batch 1320 Training err. 2.02737 Training err. RA 2.56035 Valid. err. 2.19785
2018-02-03 20:34:20,623 training [INFO ] Epoch  4 Batch 1340 Training err. 2.15282 Training err. RA 2.55427 Valid. err. 2.14249
2018-02-03 20:34:21,028 training [INFO ] Epoch  4 Batch 1360 Training err. 2.12325 Training err. RA 2.54793 Valid. err. 2.18550
2018-02-03 20:34:21,438 training [INFO ] Epoch  4 Batch 1380 Training err. 2.13816 Training err. RA 2.54199 Valid. err. 2.13816
2018-02-03 20:34:21,845 training [INFO ] Epoch  4 Batch 1400 Training err. 2.10807 Training err. RA 2.53579 Valid. err. 2.14043
2018-02-03 20:34:22,252 training [INFO ] Epoch  4 Batch 1420 Training err. 2.07169 Training err. RA 2.52926 Valid. err. 2.13474
2018-02-03 20:34:22,658 training [INFO ] Epoch  4 Batch 1440 Training err. 2.07528 Training err. RA 2.52295 Valid. err. 2.12050
2018-02-03 20:34:23,065 training [INFO ] Epoch  4 Batch 1460 Training err. 2.11265 Training err. RA 2.51733 Valid. err. 2.13060
2018-02-03 20:34:23,470 training [INFO ] Epoch  4 Batch 1480 Training err. 2.15555 Training err. RA 2.51244 Valid. err. 2.11334
2018-02-03 20:34:23,882 training [INFO ] Epoch  4 Batch 1500 Training err. 2.15593 Training err. RA 2.50769 Valid. err. 2.12558
2018-02-03 20:34:24,288 training [INFO ] Epoch  4 Batch 1520 Training err. 2.05521 Training err. RA 2.50173 Valid. err. 2.10072
2018-02-03 20:34:24,698 training [INFO ] Epoch  4 Batch 1540 Training err. 2.04354 Training err. RA 2.49578 Valid. err. 2.11820
2018-02-03 20:34:25,107 training [INFO ] Epoch  4 Batch 1560 Training err. 2.00140 Training err. RA 2.48945 Valid. err. 2.13263
2018-02-03 20:34:25,513 training [INFO ] Epoch  4 Batch 1580 Training err. 2.02233 Training err. RA 2.48353 Valid. err. 2.07966
2018-02-03 20:34:25,917 training [INFO ] Epoch  4 Batch 1600 Training err. 2.07400 Training err. RA 2.47841 Valid. err. 2.09716
2018-02-03 20:34:26,323 training [INFO ] Epoch  4 Batch 1620 Training err. 2.02113 Training err. RA 2.47277 Valid. err. 2.15654
2018-02-03 20:34:26,726 training [INFO ] Epoch  4 Batch 1640 Training err. 2.01312 Training err. RA 2.46716 Valid. err. 2.08070
2018-02-03 20:34:27,136 training [INFO ] Epoch  4 Batch 1660 Training err. 2.02506 Training err. RA 2.46184 Valid. err. 2.07331
2018-02-03 20:34:27,903 training [INFO ] Epoch  5 Batch 1680 Training err. 2.03321 Training err. RA 2.45673 Valid. err. 2.05742
2018-02-03 20:34:28,307 training [INFO ] Epoch  5 Batch 1700 Training err. 2.01733 Training err. RA 2.45156 Valid. err. 2.06946
2018-02-03 20:34:28,713 training [INFO ] Epoch  5 Batch 1720 Training err. 1.95329 Training err. RA 2.44577 Valid. err. 2.10905
2018-02-03 20:34:29,120 training [INFO ] Epoch  5 Batch 1740 Training err. 1.94664 Training err. RA 2.44003 Valid. err. 2.08718
2018-02-03 20:34:29,521 training [INFO ] Epoch  5 Batch 1760 Training err. 2.06385 Training err. RA 2.43576 Valid. err. 2.07705
2018-02-03 20:34:29,925 training [INFO ] Epoch  5 Batch 1780 Training err. 1.98592 Training err. RA 2.43070 Valid. err. 2.06117
2018-02-03 20:34:30,331 training [INFO ] Epoch  5 Batch 1800 Training err. 2.05900 Training err. RA 2.42657 Valid. err. 2.04711
2018-02-03 20:34:30,737 training [INFO ] Epoch  5 Batch 1820 Training err. 2.01012 Training err. RA 2.42200 Valid. err. 2.11186
2018-02-03 20:34:31,146 training [INFO ] Epoch  5 Batch 1840 Training err. 1.96643 Training err. RA 2.41705 Valid. err. 2.06220
2018-02-03 20:34:31,545 training [INFO ] Epoch  5 Batch 1860 Training err. 1.97765 Training err. RA 2.41232 Valid. err. 2.02657
2018-02-03 20:34:31,946 training [INFO ] Epoch  5 Batch 1880 Training err. 2.00988 Training err. RA 2.40804 Valid. err. 2.01750
2018-02-03 20:34:32,353 training [INFO ] Epoch  5 Batch 1900 Training err. 2.07202 Training err. RA 2.40450 Valid. err. 2.02982
2018-02-03 20:34:32,757 training [INFO ] Epoch  5 Batch 1920 Training err. 2.03688 Training err. RA 2.40067 Valid. err. 2.01441
2018-02-03 20:34:33,165 training [INFO ] Epoch  5 Batch 1940 Training err. 1.97123 Training err. RA 2.39625 Valid. err. 2.02566
2018-02-03 20:34:33,573 training [INFO ] Epoch  5 Batch 1960 Training err. 1.95322 Training err. RA 2.39173 Valid. err. 2.02019
2018-02-03 20:34:33,975 training [INFO ] Epoch  5 Batch 1980 Training err. 1.91694 Training err. RA 2.38693 Valid. err. 2.05551
2018-02-03 20:34:34,381 training [INFO ] Epoch  5 Batch 2000 Training err. 1.93688 Training err. RA 2.38243 Valid. err. 2.04729
2018-02-03 20:34:34,786 training [INFO ] Epoch  5 Batch 2020 Training err. 1.96685 Training err. RA 2.37831 Valid. err. 2.00147
2018-02-03 20:34:35,193 training [INFO ] Epoch  5 Batch 2040 Training err. 1.96345 Training err. RA 2.37425 Valid. err. 1.99334
2018-02-03 20:34:35,596 training [INFO ] Epoch  5 Batch 2060 Training err. 1.92653 Training err. RA 2.36990 Valid. err. 1.99061
2018-02-03 20:34:35,997 training [INFO ] Epoch  5 Batch 2080 Training err. 1.91653 Training err. RA 2.36554 Valid. err. 1.98339
2018-02-03 20:34:36,763 training [INFO ] Epoch  6 Batch 2100 Training err. 1.99016 Training err. RA 2.36197 Valid. err. 1.98889
2018-02-03 20:34:37,166 training [INFO ] Epoch  6 Batch 2120 Training err. 1.88529 Training err. RA 2.35747 Valid. err. 2.01528
2018-02-03 20:34:37,575 training [INFO ] Epoch  6 Batch 2140 Training err. 1.86048 Training err. RA 2.35282 Valid. err. 1.98519
2018-02-03 20:34:37,974 training [INFO ] Epoch  6 Batch 2160 Training err. 1.89090 Training err. RA 2.34855 Valid. err. 1.98814
2018-02-03 20:34:38,379 training [INFO ] Epoch  6 Batch 2180 Training err. 1.97283 Training err. RA 2.34510 Valid. err. 1.97695
2018-02-03 20:34:38,784 training [INFO ] Epoch  6 Batch 2200 Training err. 1.90069 Training err. RA 2.34106 Valid. err. 1.99336
2018-02-03 20:34:39,188 training [INFO ] Epoch  6 Batch 2220 Training err. 2.00432 Training err. RA 2.33803 Valid. err. 1.97496
2018-02-03 20:34:39,597 training [INFO ] Epoch  6 Batch 2240 Training err. 1.92373 Training err. RA 2.33433 Valid. err. 1.97791
2018-02-03 20:34:40,001 training [INFO ] Epoch  6 Batch 2260 Training err. 1.89788 Training err. RA 2.33046 Valid. err. 1.96662
2018-02-03 20:34:40,408 training [INFO ] Epoch  6 Batch 2280 Training err. 1.90491 Training err. RA 2.32673 Valid. err. 1.95324
2018-02-03 20:34:40,815 training [INFO ] Epoch  6 Batch 2300 Training err. 1.93596 Training err. RA 2.32333 Valid. err. 1.99223
2018-02-03 20:34:41,219 training [INFO ] Epoch  6 Batch 2320 Training err. 2.00061 Training err. RA 2.32055 Valid. err. 1.96622
2018-02-03 20:34:41,623 training [INFO ] Epoch  6 Batch 2340 Training err. 1.93596 Training err. RA 2.31726 Valid. err. 1.94188
2018-02-03 20:34:42,027 training [INFO ] Epoch  6 Batch 2360 Training err. 1.89344 Training err. RA 2.31367 Valid. err. 1.95281
2018-02-03 20:34:42,432 training [INFO ] Epoch  6 Batch 2380 Training err. 1.89155 Training err. RA 2.31013 Valid. err. 1.97251
2018-02-03 20:34:42,836 training [INFO ] Epoch  6 Batch 2400 Training err. 1.82918 Training err. RA 2.30612 Valid. err. 1.95391
2018-02-03 20:34:43,238 training [INFO ] Epoch  6 Batch 2420 Training err. 1.88612 Training err. RA 2.30265 Valid. err. 1.94061
2018-02-03 20:34:43,641 training [INFO ] Epoch  6 Batch 2440 Training err. 1.89445 Training err. RA 2.29930 Valid. err. 1.93465
2018-02-03 20:34:44,042 training [INFO ] Epoch  6 Batch 2460 Training err. 1.91583 Training err. RA 2.29618 Valid. err. 1.96632
2018-02-03 20:34:44,447 training [INFO ] Epoch  6 Batch 2480 Training err. 1.86741 Training err. RA 2.29273 Valid. err. 1.96851
2018-02-03 20:34:44,854 training [INFO ] Epoch  6 Batch 2500 Training err. 1.87375 Training err. RA 2.28937 Valid. err. 1.93650
2018-02-03 20:34:45,616 training [INFO ] Epoch  7 Batch 2520 Training err. 1.91059 Training err. RA 2.28637 Valid. err. 1.93687
2018-02-03 20:34:46,017 training [INFO ] Epoch  7 Batch 2540 Training err. 1.81544 Training err. RA 2.28266 Valid. err. 1.93810
2018-02-03 20:34:46,421 training [INFO ] Epoch  7 Batch 2560 Training err. 1.80077 Training err. RA 2.27889 Valid. err. 1.93934
2018-02-03 20:34:46,825 training [INFO ] Epoch  7 Batch 2580 Training err. 1.82604 Training err. RA 2.27538 Valid. err. 1.92462
2018-02-03 20:34:47,229 training [INFO ] Epoch  7 Batch 2600 Training err. 1.91511 Training err. RA 2.27261 Valid. err. 1.94236
2018-02-03 20:34:47,638 training [INFO ] Epoch  7 Batch 2620 Training err. 1.84725 Training err. RA 2.26937 Valid. err. 1.92211
2018-02-03 20:34:48,044 training [INFO ] Epoch  7 Batch 2640 Training err. 1.95897 Training err. RA 2.26701 Valid. err. 1.93200
2018-02-03 20:34:48,449 training [INFO ] Epoch  7 Batch 2660 Training err. 1.84486 Training err. RA 2.26384 Valid. err. 1.93737
2018-02-03 20:34:48,856 training [INFO ] Epoch  7 Batch 2680 Training err. 1.83822 Training err. RA 2.26066 Valid. err. 1.91819
2018-02-03 20:34:49,263 training [INFO ] Epoch  7 Batch 2700 Training err. 1.84751 Training err. RA 2.25760 Valid. err. 1.91271
2018-02-03 20:34:49,675 training [INFO ] Epoch  7 Batch 2720 Training err. 1.88648 Training err. RA 2.25487 Valid. err. 1.89260
2018-02-03 20:34:50,076 training [INFO ] Epoch  7 Batch 2740 Training err. 1.92496 Training err. RA 2.25247 Valid. err. 1.89309
2018-02-03 20:34:50,480 training [INFO ] Epoch  7 Batch 2760 Training err. 1.87720 Training err. RA 2.24975 Valid. err. 1.90405
2018-02-03 20:34:50,888 training [INFO ] Epoch  7 Batch 2780 Training err. 1.83714 Training err. RA 2.24678 Valid. err. 1.91452
2018-02-03 20:34:51,292 training [INFO ] Epoch  7 Batch 2800 Training err. 1.83129 Training err. RA 2.24381 Valid. err. 1.91732
2018-02-03 20:34:51,699 training [INFO ] Epoch  7 Batch 2820 Training err. 1.78036 Training err. RA 2.24052 Valid. err. 1.91262
2018-02-03 20:34:52,105 training [INFO ] Epoch  7 Batch 2840 Training err. 1.84137 Training err. RA 2.23771 Valid. err. 1.90598
2018-02-03 20:34:52,511 training [INFO ] Epoch  7 Batch 2860 Training err. 1.82179 Training err. RA 2.23480 Valid. err. 1.88578
2018-02-03 20:34:52,917 training [INFO ] Epoch  7 Batch 2880 Training err. 1.82914 Training err. RA 2.23199 Valid. err. 1.87670
2018-02-03 20:34:53,322 training [INFO ] Epoch  7 Batch 2900 Training err. 1.81784 Training err. RA 2.22913 Valid. err. 1.88882
2018-02-03 20:34:54,090 training [INFO ] Epoch  8 Batch 2920 Training err. 1.83842 Training err. RA 2.22646 Valid. err. 2.68820
2018-02-03 20:34:54,494 training [INFO ] Epoch  8 Batch 2940 Training err. 1.96534 Training err. RA 2.22468 Valid. err. 1.92965
2018-02-03 20:34:54,897 training [INFO ] Epoch  8 Batch 2960 Training err. 1.81073 Training err. RA 2.22188 Valid. err. 1.90055
2018-02-03 20:34:55,304 training [INFO ] Epoch  8 Batch 2980 Training err. 1.73894 Training err. RA 2.21864 Valid. err. 1.91681
2018-02-03 20:34:55,713 training [INFO ] Epoch  8 Batch 3000 Training err. 1.84713 Training err. RA 2.21616 Valid. err. 1.94421
2018-02-03 20:34:56,123 training [INFO ] Epoch  8 Batch 3020 Training err. 1.85846 Training err. RA 2.21380 Valid. err. 1.93703
2018-02-03 20:34:56,530 training [INFO ] Epoch  8 Batch 3040 Training err. 1.82881 Training err. RA 2.21126 Valid. err. 1.90405
2018-02-03 20:34:56,937 training [INFO ] Epoch  8 Batch 3060 Training err. 1.91039 Training err. RA 2.20930 Valid. err. 1.89104
2018-02-03 20:34:57,344 training [INFO ] Epoch  8 Batch 3080 Training err. 1.79773 Training err. RA 2.20662 Valid. err. 1.91318
2018-02-03 20:34:57,756 training [INFO ] Epoch  8 Batch 3100 Training err. 1.82542 Training err. RA 2.20416 Valid. err. 1.90377
2018-02-03 20:34:58,166 training [INFO ] Epoch  8 Batch 3120 Training err. 1.82788 Training err. RA 2.20175 Valid. err. 1.87298
2018-02-03 20:34:58,571 training [INFO ] Epoch  8 Batch 3140 Training err. 1.84354 Training err. RA 2.19947 Valid. err. 1.87299
2018-02-03 20:34:58,972 training [INFO ] Epoch  8 Batch 3160 Training err. 1.90291 Training err. RA 2.19759 Valid. err. 1.87195
2018-02-03 20:34:59,375 training [INFO ] Epoch  8 Batch 3180 Training err. 1.81468 Training err. RA 2.19519 Valid. err. 1.90172
2018-02-03 20:34:59,781 training [INFO ] Epoch  8 Batch 3200 Training err. 1.78850 Training err. RA 2.19264 Valid. err. 1.88181
2018-02-03 20:35:00,193 training [INFO ] Epoch  8 Batch 3220 Training err. 1.79034 Training err. RA 2.19014 Valid. err. 1.88533
2018-02-03 20:35:00,597 training [INFO ] Epoch  8 Batch 3240 Training err. 1.75928 Training err. RA 2.18749 Valid. err. 1.87656
2018-02-03 20:35:00,998 training [INFO ] Epoch  8 Batch 3260 Training err. 1.79241 Training err. RA 2.18506 Valid. err. 1.90714
2018-02-03 20:35:01,406 training [INFO ] Epoch  8 Batch 3280 Training err. 1.77418 Training err. RA 2.18256 Valid. err. 1.85201
2018-02-03 20:35:01,813 training [INFO ] Epoch  8 Batch 3300 Training err. 1.81290 Training err. RA 2.18032 Valid. err. 1.87184
2018-02-03 20:35:02,217 training [INFO ] Epoch  8 Batch 3320 Training err. 1.78409 Training err. RA 2.17793 Valid. err. 1.84156
2018-02-03 20:35:02,983 training [INFO ] Epoch  9 Batch 3340 Training err. 1.78032 Training err. RA 2.17555 Valid. err. 1.83455
2018-02-03 20:35:03,387 training [INFO ] Epoch  9 Batch 3360 Training err. 1.77456 Training err. RA 2.17316 Valid. err. 1.83601
2018-02-03 20:35:03,793 training [INFO ] Epoch  9 Batch 3380 Training err. 1.74533 Training err. RA 2.17063 Valid. err. 1.83667
2018-02-03 20:35:04,197 training [INFO ] Epoch  9 Batch 3400 Training err. 1.68401 Training err. RA 2.16777 Valid. err. 1.84464
2018-02-03 20:35:04,606 training [INFO ] Epoch  9 Batch 3420 Training err. 1.81394 Training err. RA 2.16570 Valid. err. 1.84242
2018-02-03 20:35:05,011 training [INFO ] Epoch  9 Batch 3440 Training err. 1.77202 Training err. RA 2.16341 Valid. err. 1.85655
2018-02-03 20:35:05,418 training [INFO ] Epoch  9 Batch 3460 Training err. 1.80776 Training err. RA 2.16135 Valid. err. 1.85692
2018-02-03 20:35:05,825 training [INFO ] Epoch  9 Batch 3480 Training err. 1.83096 Training err. RA 2.15945 Valid. err. 1.83285
2018-02-03 20:35:06,236 training [INFO ] Epoch  9 Batch 3500 Training err. 1.76729 Training err. RA 2.15721 Valid. err. 1.86347
2018-02-03 20:35:06,642 training [INFO ] Epoch  9 Batch 3520 Training err. 1.76861 Training err. RA 2.15501 Valid. err. 1.83229
2018-02-03 20:35:07,048 training [INFO ] Epoch  9 Batch 3540 Training err. 1.78318 Training err. RA 2.15290 Valid. err. 1.81624
2018-02-03 20:35:07,455 training [INFO ] Epoch  9 Batch 3560 Training err. 1.80293 Training err. RA 2.15094 Valid. err. 1.83680
2018-02-03 20:35:07,860 training [INFO ] Epoch  9 Batch 3580 Training err. 1.83840 Training err. RA 2.14919 Valid. err. 1.84800
2018-02-03 20:35:08,270 training [INFO ] Epoch  9 Batch 3600 Training err. 1.76923 Training err. RA 2.14708 Valid. err. 1.83941
2018-02-03 20:35:08,680 training [INFO ] Epoch  9 Batch 3620 Training err. 1.73627 Training err. RA 2.14481 Valid. err. 1.84205
2018-02-03 20:35:09,086 training [INFO ] Epoch  9 Batch 3640 Training err. 1.74171 Training err. RA 2.14260 Valid. err. 1.85147
2018-02-03 20:35:09,488 training [INFO ] Epoch  9 Batch 3660 Training err. 1.71968 Training err. RA 2.14029 Valid. err. 1.83084
2018-02-03 20:35:09,895 training [INFO ] Epoch  9 Batch 3680 Training err. 1.74462 Training err. RA 2.13814 Valid. err. 1.82193
2018-02-03 20:35:10,302 training [INFO ] Epoch  9 Batch 3700 Training err. 1.72639 Training err. RA 2.13591 Valid. err. 1.80705
2018-02-03 20:35:10,709 training [INFO ] Epoch  9 Batch 3720 Training err. 1.76968 Training err. RA 2.13394 Valid. err. 1.80599
2018-02-03 20:35:11,119 training [INFO ] Epoch  9 Batch 3740 Training err. 1.73266 Training err. RA 2.13180 Valid. err. 1.82067
2018-02-03 20:35:11,894 training [INFO ] Epoch 10 Batch 3760 Training err. 1.73030 Training err. RA 2.12966 Valid. err. 1.81634
2018-02-03 20:35:12,300 training [INFO ] Epoch 10 Batch 3780 Training err. 1.75476 Training err. RA 2.12768 Valid. err. 1.80067
2018-02-03 20:35:12,709 training [INFO ] Epoch 10 Batch 3800 Training err. 1.69880 Training err. RA 2.12542 Valid. err. 1.81117
2018-02-03 20:35:13,115 training [INFO ] Epoch 10 Batch 3820 Training err. 1.65957 Training err. RA 2.12298 Valid. err. 1.82446
2018-02-03 20:35:13,517 training [INFO ] Epoch 10 Batch 3840 Training err. 1.77566 Training err. RA 2.12117 Valid. err. 1.80912
2018-02-03 20:35:13,922 training [INFO ] Epoch 10 Batch 3860 Training err. 1.72720 Training err. RA 2.11913 Valid. err. 1.83610
2018-02-03 20:35:14,327 training [INFO ] Epoch 10 Batch 3880 Training err. 1.79216 Training err. RA 2.11744 Valid. err. 1.80556
2018-02-03 20:35:14,734 training [INFO ] Epoch 10 Batch 3900 Training err. 1.77800 Training err. RA 2.11570 Valid. err. 1.80989
2018-02-03 20:35:15,142 training [INFO ] Epoch 10 Batch 3920 Training err. 1.72870 Training err. RA 2.11373 Valid. err. 1.82517
2018-02-03 20:35:15,546 training [INFO ] Epoch 10 Batch 3940 Training err. 1.70008 Training err. RA 2.11163 Valid. err. 1.79737
2018-02-03 20:35:15,955 training [INFO ] Epoch 10 Batch 3960 Training err. 1.79065 Training err. RA 2.11001 Valid. err. 1.78033
2018-02-03 20:35:16,360 training [INFO ] Epoch 10 Batch 3980 Training err. 1.77230 Training err. RA 2.10831 Valid. err. 1.80417
2018-02-03 20:35:16,769 training [INFO ] Epoch 10 Batch 4000 Training err. 1.80288 Training err. RA 2.10678 Valid. err. 1.79809
2018-02-03 20:35:17,179 training [INFO ] Epoch 10 Batch 4020 Training err. 1.71465 Training err. RA 2.10483 Valid. err. 1.79948
2018-02-03 20:35:17,584 training [INFO ] Epoch 10 Batch 4040 Training err. 1.69701 Training err. RA 2.10281 Valid. err. 1.79937
2018-02-03 20:35:17,991 training [INFO ] Epoch 10 Batch 4060 Training err. 1.68371 Training err. RA 2.10075 Valid. err. 1.80045
2018-02-03 20:35:18,398 training [INFO ] Epoch 10 Batch 4080 Training err. 1.69534 Training err. RA 2.09876 Valid. err. 1.78968
2018-02-03 20:35:18,801 training [INFO ] Epoch 10 Batch 4100 Training err. 1.72614 Training err. RA 2.09694 Valid. err. 1.79017
2018-02-03 20:35:19,210 training [INFO ] Epoch 10 Batch 4120 Training err. 1.68811 Training err. RA 2.09496 Valid. err. 1.78694
2018-02-03 20:35:19,619 training [INFO ] Epoch 10 Batch 4140 Training err. 1.72922 Training err. RA 2.09319 Valid. err. 1.78055
2018-02-03 20:35:20,021 training [INFO ] Epoch 10 Batch 4160 Training err. 1.70160 Training err. RA 2.09131 Valid. err. 1.77780
2018-02-03 20:35:20,794 training [INFO ] Epoch 11 Batch 4180 Training err. 1.67044 Training err. RA 2.08930 Valid. err. 1.79088
2018-02-03 20:35:21,211 training [INFO ] Epoch 11 Batch 4200 Training err. 1.72313 Training err. RA 2.08755 Valid. err. 1.79064
2018-02-03 20:35:21,627 training [INFO ] Epoch 11 Batch 4220 Training err. 1.65427 Training err. RA 2.08550 Valid. err. 1.78497
2018-02-03 20:35:22,036 training [INFO ] Epoch 11 Batch 4240 Training err. 1.64493 Training err. RA 2.08342 Valid. err. 1.78600
2018-02-03 20:35:22,448 training [INFO ] Epoch 11 Batch 4260 Training err. 1.75004 Training err. RA 2.08186 Valid. err. 1.78314
2018-02-03 20:35:22,859 training [INFO ] Epoch 11 Batch 4280 Training err. 1.69630 Training err. RA 2.08005 Valid. err. 1.79565
2018-02-03 20:35:23,270 training [INFO ] Epoch 11 Batch 4300 Training err. 1.77358 Training err. RA 2.07863 Valid. err. 1.78851
2018-02-03 20:35:23,684 training [INFO ] Epoch 11 Batch 4320 Training err. 1.73083 Training err. RA 2.07702 Valid. err. 1.81114
2018-02-03 20:35:24,107 training [INFO ] Epoch 11 Batch 4340 Training err. 1.70277 Training err. RA 2.07529 Valid. err. 1.79116
2018-02-03 20:35:24,517 training [INFO ] Epoch 11 Batch 4360 Training err. 1.67217 Training err. RA 2.07345 Valid. err. 1.76326
2018-02-03 20:35:24,923 training [INFO ] Epoch 11 Batch 4380 Training err. 1.73770 Training err. RA 2.07191 Valid. err. 1.77602
2018-02-03 20:35:25,328 training [INFO ] Epoch 11 Batch 4400 Training err. 1.75690 Training err. RA 2.07048 Valid. err. 1.79083
2018-02-03 20:35:25,736 training [INFO ] Epoch 11 Batch 4420 Training err. 1.75256 Training err. RA 2.06904 Valid. err. 1.78780
2018-02-03 20:35:26,147 training [INFO ] Epoch 11 Batch 4440 Training err. 1.68126 Training err. RA 2.06729 Valid. err. 1.77653
2018-02-03 20:35:26,554 training [INFO ] Epoch 11 Batch 4460 Training err. 1.67173 Training err. RA 2.06552 Valid. err. 1.77550
2018-02-03 20:35:26,959 training [INFO ] Epoch 11 Batch 4480 Training err. 1.64911 Training err. RA 2.06366 Valid. err. 1.77856
2018-02-03 20:35:27,365 training [INFO ] Epoch 11 Batch 4500 Training err. 1.66305 Training err. RA 2.06188 Valid. err. 1.76910
2018-02-03 20:35:27,774 training [INFO ] Epoch 11 Batch 4520 Training err. 1.70776 Training err. RA 2.06031 Valid. err. 1.75022
2018-02-03 20:35:28,182 training [INFO ] Epoch 11 Batch 4540 Training err. 1.66192 Training err. RA 2.05856 Valid. err. 1.76735
2018-02-03 20:35:28,588 training [INFO ] Epoch 11 Batch 4560 Training err. 1.67098 Training err. RA 2.05686 Valid. err. 1.78055
2018-02-03 20:35:28,994 training [INFO ] Epoch 11 Batch 4580 Training err. 1.67735 Training err. RA 2.05520 Valid. err. 1.75598
2018-02-03 20:35:29,772 training [INFO ] Epoch 12 Batch 4600 Training err. 1.67659 Training err. RA 2.05356 Valid. err. 1.75548
2018-02-03 20:35:30,181 training [INFO ] Epoch 12 Batch 4620 Training err. 1.65026 Training err. RA 2.05181 Valid. err. 1.76459
2018-02-03 20:35:30,585 training [INFO ] Epoch 12 Batch 4640 Training err. 1.63243 Training err. RA 2.05000 Valid. err. 1.77637
2018-02-03 20:35:30,987 training [INFO ] Epoch 12 Batch 4660 Training err. 1.63477 Training err. RA 2.04822 Valid. err. 1.75298
2018-02-03 20:35:31,393 training [INFO ] Epoch 12 Batch 4680 Training err. 1.73317 Training err. RA 2.04687 Valid. err. 1.76493
2018-02-03 20:35:31,792 training [INFO ] Epoch 12 Batch 4700 Training err. 1.64043 Training err. RA 2.04514 Valid. err. 1.76603
2018-02-03 20:35:32,194 training [INFO ] Epoch 12 Batch 4720 Training err. 1.77634 Training err. RA 2.04401 Valid. err. 1.75165
2018-02-03 20:35:32,593 training [INFO ] Epoch 12 Batch 4740 Training err. 1.69871 Training err. RA 2.04255 Valid. err. 1.74903
2018-02-03 20:35:32,998 training [INFO ] Epoch 12 Batch 4760 Training err. 1.65524 Training err. RA 2.04092 Valid. err. 1.75749
2018-02-03 20:35:33,404 training [INFO ] Epoch 12 Batch 4780 Training err. 1.64486 Training err. RA 2.03926 Valid. err. 1.74296
2018-02-03 20:35:33,808 training [INFO ] Epoch 12 Batch 4800 Training err. 1.70045 Training err. RA 2.03785 Valid. err. 1.74711
2018-02-03 20:35:34,218 training [INFO ] Epoch 12 Batch 4820 Training err. 1.74017 Training err. RA 2.03662 Valid. err. 1.75324
2018-02-03 20:35:34,625 training [INFO ] Epoch 12 Batch 4840 Training err. 1.70221 Training err. RA 2.03524 Valid. err. 1.75409
2018-02-03 20:35:35,029 training [INFO ] Epoch 12 Batch 4860 Training err. 1.66318 Training err. RA 2.03370 Valid. err. 1.74706
2018-02-03 20:35:35,433 training [INFO ] Epoch 12 Batch 4880 Training err. 1.65890 Training err. RA 2.03217 Valid. err. 1.76421
2018-02-03 20:35:35,840 training [INFO ] Epoch 12 Batch 4900 Training err. 1.61139 Training err. RA 2.03045 Valid. err. 1.75285
2018-02-03 20:35:36,248 training [INFO ] Epoch 12 Batch 4920 Training err. 1.64614 Training err. RA 2.02889 Valid. err. 1.75444
2018-02-03 20:35:36,658 training [INFO ] Epoch 12 Batch 4940 Training err. 1.67024 Training err. RA 2.02744 Valid. err. 1.73681
2018-02-03 20:35:37,060 training [INFO ] Epoch 12 Batch 4960 Training err. 1.63757 Training err. RA 2.02586 Valid. err. 1.73527
2018-02-03 20:35:37,466 training [INFO ] Epoch 12 Batch 4980 Training err. 1.65910 Training err. RA 2.02439 Valid. err. 1.74151
2018-02-03 20:35:37,873 training [INFO ] Epoch 12 Batch 5000 Training err. 1.62811 Training err. RA 2.02281 Valid. err. 1.74490
2018-02-03 20:35:38,663 training [INFO ] Epoch 13 Batch 5020 Training err. 1.66304 Training err. RA 2.02137 Valid. err. 1.72740
2018-02-03 20:35:39,074 training [INFO ] Epoch 13 Batch 5040 Training err. 1.60676 Training err. RA 2.01973 Valid. err. 1.73731
2018-02-03 20:35:39,485 training [INFO ] Epoch 13 Batch 5060 Training err. 1.60101 Training err. RA 2.01807 Valid. err. 1.75277
2018-02-03 20:35:39,892 training [INFO ] Epoch 13 Batch 5080 Training err. 1.61537 Training err. RA 2.01649 Valid. err. 1.74638
2018-02-03 20:35:40,309 training [INFO ] Epoch 13 Batch 5100 Training err. 1.70143 Training err. RA 2.01525 Valid. err. 1.74468
2018-02-03 20:35:40,719 training [INFO ] Epoch 13 Batch 5120 Training err. 1.63429 Training err. RA 2.01376 Valid. err. 1.76321
2018-02-03 20:35:41,126 training [INFO ] Epoch 13 Batch 5140 Training err. 1.76609 Training err. RA 2.01280 Valid. err. 1.73857
2018-02-03 20:35:41,532 training [INFO ] Epoch 13 Batch 5160 Training err. 1.64640 Training err. RA 2.01138 Valid. err. 1.75768
2018-02-03 20:35:41,940 training [INFO ] Epoch 13 Batch 5180 Training err. 1.63139 Training err. RA 2.00991 Valid. err. 1.74039
2018-02-03 20:35:42,347 training [INFO ] Epoch 13 Batch 5200 Training err. 1.62260 Training err. RA 2.00842 Valid. err. 1.73849
2018-02-03 20:35:42,757 training [INFO ] Epoch 13 Batch 5220 Training err. 1.68253 Training err. RA 2.00717 Valid. err. 1.71817
2018-02-03 20:35:43,167 training [INFO ] Epoch 13 Batch 5240 Training err. 1.70061 Training err. RA 2.00600 Valid. err. 1.72108
2018-02-03 20:35:43,572 training [INFO ] Epoch 13 Batch 5260 Training err. 1.68414 Training err. RA 2.00478 Valid. err. 1.72668
2018-02-03 20:35:43,977 training [INFO ] Epoch 13 Batch 5280 Training err. 1.61745 Training err. RA 2.00331 Valid. err. 1.73332
2018-02-03 20:35:44,383 training [INFO ] Epoch 13 Batch 5300 Training err. 1.64090 Training err. RA 2.00195 Valid. err. 1.73510
2018-02-03 20:35:44,788 training [INFO ] Epoch 13 Batch 5320 Training err. 1.59011 Training err. RA 2.00040 Valid. err. 1.73325
2018-02-03 20:35:45,196 training [INFO ] Epoch 13 Batch 5340 Training err. 1.61977 Training err. RA 1.99897 Valid. err. 1.71046
2018-02-03 20:35:45,601 training [INFO ] Epoch 13 Batch 5360 Training err. 1.64135 Training err. RA 1.99764 Valid. err. 1.70472
2018-02-03 20:35:46,008 training [INFO ] Epoch 13 Batch 5380 Training err. 1.62715 Training err. RA 1.99626 Valid. err. 1.71333
2018-02-03 20:35:46,414 training [INFO ] Epoch 13 Batch 5400 Training err. 1.62792 Training err. RA 1.99490 Valid. err. 1.71899
2018-02-03 20:35:46,819 training [INFO ] Epoch 13 Batch 5420 Training err. 1.61346 Training err. RA 1.99349 Valid. err. 1.70708
2018-02-03 20:35:47,585 training [INFO ] Epoch 14 Batch 5440 Training err. 1.65507 Training err. RA 1.99224 Valid. err. 1.72285
2018-02-03 20:35:47,990 training [INFO ] Epoch 14 Batch 5460 Training err. 1.57164 Training err. RA 1.99070 Valid. err. 1.71826
2018-02-03 20:35:48,393 training [INFO ] Epoch 14 Batch 5480 Training err. 1.56786 Training err. RA 1.98916 Valid. err. 1.72925
2018-02-03 20:35:48,800 training [INFO ] Epoch 14 Batch 5500 Training err. 1.60583 Training err. RA 1.98777 Valid. err. 1.72039
2018-02-03 20:35:49,205 training [INFO ] Epoch 14 Batch 5520 Training err. 1.67142 Training err. RA 1.98662 Valid. err. 1.72206
2018-02-03 20:35:49,609 training [INFO ] Epoch 14 Batch 5540 Training err. 1.61992 Training err. RA 1.98530 Valid. err. 1.72175
2018-02-03 20:35:50,017 training [INFO ] Epoch 14 Batch 5560 Training err. 1.72674 Training err. RA 1.98437 Valid. err. 1.72298
2018-02-03 20:35:50,424 training [INFO ] Epoch 14 Batch 5580 Training err. 1.60824 Training err. RA 1.98302 Valid. err. 1.71840
2018-02-03 20:35:50,829 training [INFO ] Epoch 14 Batch 5600 Training err. 1.61971 Training err. RA 1.98172 Valid. err. 1.71494
2018-02-03 20:35:51,238 training [INFO ] Epoch 14 Batch 5620 Training err. 1.60960 Training err. RA 1.98040 Valid. err. 1.70448
2018-02-03 20:35:51,644 training [INFO ] Epoch 14 Batch 5640 Training err. 1.66317 Training err. RA 1.97927 Valid. err. 1.70616
2018-02-03 20:35:52,049 training [INFO ] Epoch 14 Batch 5660 Training err. 1.67964 Training err. RA 1.97821 Valid. err. 1.71105
2018-02-03 20:35:52,457 training [INFO ] Epoch 14 Batch 5680 Training err. 1.64313 Training err. RA 1.97703 Valid. err. 1.71530
2018-02-03 20:35:52,865 training [INFO ] Epoch 14 Batch 5700 Training err. 1.61845 Training err. RA 1.97577 Valid. err. 1.71147
2018-02-03 20:35:53,273 training [INFO ] Epoch 14 Batch 5720 Training err. 1.60484 Training err. RA 1.97448 Valid. err. 1.72228
2018-02-03 20:35:53,681 training [INFO ] Epoch 14 Batch 5740 Training err. 1.57492 Training err. RA 1.97309 Valid. err. 1.71225
2018-02-03 20:35:54,088 training [INFO ] Epoch 14 Batch 5760 Training err. 1.61705 Training err. RA 1.97185 Valid. err. 1.71340
2018-02-03 20:35:54,494 training [INFO ] Epoch 14 Batch 5780 Training err. 1.58960 Training err. RA 1.97053 Valid. err. 1.70453
2018-02-03 20:35:54,900 training [INFO ] Epoch 14 Batch 5800 Training err. 1.61293 Training err. RA 1.96929 Valid. err. 1.69733
2018-02-03 20:35:55,307 training [INFO ] Epoch 14 Batch 5820 Training err. 1.59857 Training err. RA 1.96802 Valid. err. 1.69244
2018-02-03 20:35:56,075 training [INFO ] Epoch 15 Batch 5840 Training err. 1.61744 Training err. RA 1.96682 Valid. err. 1.69161
2018-02-03 20:35:56,481 training [INFO ] Epoch 15 Batch 5860 Training err. 1.58504 Training err. RA 1.96552 Valid. err. 1.71018
2018-02-03 20:35:56,882 training [INFO ] Epoch 15 Batch 5880 Training err. 1.57619 Training err. RA 1.96419 Valid. err. 1.69919
2018-02-03 20:35:57,288 training [INFO ] Epoch 15 Batch 5900 Training err. 1.51948 Training err. RA 1.96268 Valid. err. 1.70695
2018-02-03 20:35:57,691 training [INFO ] Epoch 15 Batch 5920 Training err. 1.62870 Training err. RA 1.96156 Valid. err. 1.71323
2018-02-03 20:35:58,094 training [INFO ] Epoch 15 Batch 5940 Training err. 1.62840 Training err. RA 1.96043 Valid. err. 1.70983
2018-02-03 20:35:58,499 training [INFO ] Epoch 15 Batch 5960 Training err. 1.61684 Training err. RA 1.95928 Valid. err. 1.69452
2018-02-03 20:35:58,901 training [INFO ] Epoch 15 Batch 5980 Training err. 1.68759 Training err. RA 1.95837 Valid. err. 1.69880
2018-02-03 20:35:59,306 training [INFO ] Epoch 15 Batch 6000 Training err. 1.58873 Training err. RA 1.95714 Valid. err. 1.70166
2018-02-03 20:35:59,714 training [INFO ] Epoch 15 Batch 6020 Training err. 1.60286 Training err. RA 1.95596 Valid. err. 1.70509
2018-02-03 20:36:00,121 training [INFO ] Epoch 15 Batch 6040 Training err. 1.60298 Training err. RA 1.95479 Valid. err. 1.68174
2018-02-03 20:36:00,527 training [INFO ] Epoch 15 Batch 6060 Training err. 1.63327 Training err. RA 1.95373 Valid. err. 1.69725
2018-02-03 20:36:00,933 training [INFO ] Epoch 15 Batch 6080 Training err. 1.66530 Training err. RA 1.95278 Valid. err. 1.70895
2018-02-03 20:36:01,337 training [INFO ] Epoch 15 Batch 6100 Training err. 1.62785 Training err. RA 1.95172 Valid. err. 1.69657
2018-02-03 20:36:01,748 training [INFO ] Epoch 15 Batch 6120 Training err. 1.57098 Training err. RA 1.95047 Valid. err. 1.71009
2018-02-03 20:36:02,159 training [INFO ] Epoch 15 Batch 6140 Training err. 1.59267 Training err. RA 1.94931 Valid. err. 1.70168
2018-02-03 20:36:02,564 training [INFO ] Epoch 15 Batch 6160 Training err. 1.56888 Training err. RA 1.94807 Valid. err. 1.70510
2018-02-03 20:36:02,969 training [INFO ] Epoch 15 Batch 6180 Training err. 1.58563 Training err. RA 1.94690 Valid. err. 1.68673
2018-02-03 20:36:03,375 training [INFO ] Epoch 15 Batch 6200 Training err. 1.55935 Training err. RA 1.94565 Valid. err. 1.70305
2018-02-03 20:36:03,786 training [INFO ] Epoch 15 Batch 6220 Training err. 1.60255 Training err. RA 1.94455 Valid. err. 1.69301
2018-02-03 20:36:04,198 training [INFO ] Epoch 15 Batch 6240 Training err. 1.58260 Training err. RA 1.94339 Valid. err. 1.67786
2018-02-03 20:36:04,964 training [INFO ] Epoch 16 Batch 6260 Training err. 1.57060 Training err. RA 1.94220 Valid. err. 1.68348
2018-02-03 20:36:05,368 training [INFO ] Epoch 16 Batch 6280 Training err. 1.57124 Training err. RA 1.94102 Valid. err. 1.68500
2018-02-03 20:36:05,772 training [INFO ] Epoch 16 Batch 6300 Training err. 1.55562 Training err. RA 1.93979 Valid. err. 1.68239
2018-02-03 20:36:06,181 training [INFO ] Epoch 16 Batch 6320 Training err. 1.51319 Training err. RA 1.93844 Valid. err. 1.69547
2018-02-03 20:36:06,586 training [INFO ] Epoch 16 Batch 6340 Training err. 1.61711 Training err. RA 1.93743 Valid. err. 1.68348
2018-02-03 20:36:06,992 training [INFO ] Epoch 16 Batch 6360 Training err. 1.58867 Training err. RA 1.93633 Valid. err. 1.69398
2018-02-03 20:36:07,396 training [INFO ] Epoch 16 Batch 6380 Training err. 1.62928 Training err. RA 1.93537 Valid. err. 1.68676
2018-02-03 20:36:07,801 training [INFO ] Epoch 16 Batch 6400 Training err. 1.64511 Training err. RA 1.93446 Valid. err. 1.69210
2018-02-03 20:36:08,205 training [INFO ] Epoch 16 Batch 6420 Training err. 1.57763 Training err. RA 1.93335 Valid. err. 1.69840
2018-02-03 20:36:08,612 training [INFO ] Epoch 16 Batch 6440 Training err. 1.56315 Training err. RA 1.93220 Valid. err. 1.68335
2018-02-03 20:36:09,019 training [INFO ] Epoch 16 Batch 6460 Training err. 1.61377 Training err. RA 1.93121 Valid. err. 1.67112
2018-02-03 20:36:09,427 training [INFO ] Epoch 16 Batch 6480 Training err. 1.63039 Training err. RA 1.93029 Valid. err. 1.69897
2018-02-03 20:36:09,831 training [INFO ] Epoch 16 Batch 6500 Training err. 1.64850 Training err. RA 1.92942 Valid. err. 1.69582
2018-02-03 20:36:10,239 training [INFO ] Epoch 16 Batch 6520 Training err. 1.59098 Training err. RA 1.92838 Valid. err. 1.70158
2018-02-03 20:36:10,644 training [INFO ] Epoch 16 Batch 6540 Training err. 1.53827 Training err. RA 1.92719 Valid. err. 1.70360
2018-02-03 20:36:11,050 training [INFO ] Epoch 16 Batch 6560 Training err. 1.56549 Training err. RA 1.92609 Valid. err. 1.68769
2018-02-03 20:36:11,456 training [INFO ] Epoch 16 Batch 6580 Training err. 1.56254 Training err. RA 1.92498 Valid. err. 1.68331
2018-02-03 20:36:11,859 training [INFO ] Epoch 16 Batch 6600 Training err. 1.56319 Training err. RA 1.92388 Valid. err. 1.67435
2018-02-03 20:36:12,263 training [INFO ] Epoch 16 Batch 6620 Training err. 1.53958 Training err. RA 1.92272 Valid. err. 1.66273
2018-02-03 20:36:12,666 training [INFO ] Epoch 16 Batch 6640 Training err. 1.58759 Training err. RA 1.92171 Valid. err. 1.67058
2018-02-03 20:36:13,070 training [INFO ] Epoch 16 Batch 6660 Training err. 1.57086 Training err. RA 1.92066 Valid. err. 1.66495
2018-02-03 20:36:13,839 training [INFO ] Epoch 17 Batch 6680 Training err. 1.52289 Training err. RA 1.91947 Valid. err. 1.67570
2018-02-03 20:36:14,247 training [INFO ] Epoch 17 Batch 6700 Training err. 1.58560 Training err. RA 1.91847 Valid. err. 1.67856
2018-02-03 20:36:14,667 training [INFO ] Epoch 17 Batch 6720 Training err. 1.52945 Training err. RA 1.91731 Valid. err. 1.66870
2018-02-03 20:36:15,073 training [INFO ] Epoch 17 Batch 6740 Training err. 1.50158 Training err. RA 1.91608 Valid. err. 1.68415
2018-02-03 20:36:15,478 training [INFO ] Epoch 17 Batch 6760 Training err. 1.59510 Training err. RA 1.91513 Valid. err. 1.68286
2018-02-03 20:36:15,885 training [INFO ] Epoch 17 Batch 6780 Training err. 1.56909 Training err. RA 1.91411 Valid. err. 1.69097
2018-02-03 20:36:16,296 training [INFO ] Epoch 17 Batch 6800 Training err. 1.63242 Training err. RA 1.91328 Valid. err. 1.66819
2018-02-03 20:36:16,708 training [INFO ] Epoch 17 Batch 6820 Training err. 1.60004 Training err. RA 1.91236 Valid. err. 1.66532
2018-02-03 20:36:17,116 training [INFO ] Epoch 17 Batch 6840 Training err. 1.57169 Training err. RA 1.91137 Valid. err. 1.69243
2018-02-03 20:36:17,525 training [INFO ] Epoch 17 Batch 6860 Training err. 1.51498 Training err. RA 1.91021 Valid. err. 1.67219
2018-02-03 20:36:17,931 training [INFO ] Epoch 17 Batch 6880 Training err. 1.62555 Training err. RA 1.90938 Valid. err. 1.65700
2018-02-03 20:36:18,337 training [INFO ] Epoch 17 Batch 6900 Training err. 1.60964 Training err. RA 1.90852 Valid. err. 1.68689
2018-02-03 20:36:18,741 training [INFO ] Epoch 17 Batch 6920 Training err. 1.63694 Training err. RA 1.90773 Valid. err. 1.67381
2018-02-03 20:36:19,142 training [INFO ] Epoch 17 Batch 6940 Training err. 1.62465 Training err. RA 1.90691 Valid. err. 1.70281
2018-02-03 20:36:19,550 training [INFO ] Epoch 17 Batch 6960 Training err. 1.54455 Training err. RA 1.90587 Valid. err. 1.71281
2018-02-03 20:36:19,955 training [INFO ] Epoch 17 Batch 6980 Training err. 1.52145 Training err. RA 1.90477 Valid. err. 1.71210
2018-02-03 20:36:20,360 training [INFO ] Epoch 17 Batch 7000 Training err. 1.55039 Training err. RA 1.90376 Valid. err. 1.66055
2018-02-03 20:36:20,770 training [INFO ] Epoch 17 Batch 7020 Training err. 1.56787 Training err. RA 1.90280 Valid. err. 1.66019
2018-02-03 20:36:21,173 training [INFO ] Epoch 17 Batch 7040 Training err. 1.51795 Training err. RA 1.90171 Valid. err. 1.67301
2018-02-03 20:36:21,579 training [INFO ] Epoch 17 Batch 7060 Training err. 1.56539 Training err. RA 1.90076 Valid. err. 1.65574
2018-02-03 20:36:21,984 training [INFO ] Epoch 17 Batch 7080 Training err. 1.54924 Training err. RA 1.89976 Valid. err. 1.65393
2018-02-03 20:36:22,761 training [INFO ] Epoch 18 Batch 7100 Training err. 1.52101 Training err. RA 1.89870 Valid. err. 1.65852
2018-02-03 20:36:23,167 training [INFO ] Epoch 18 Batch 7120 Training err. 1.54388 Training err. RA 1.89770 Valid. err. 1.66895
2018-02-03 20:36:23,573 training [INFO ] Epoch 18 Batch 7140 Training err. 1.51261 Training err. RA 1.89662 Valid. err. 1.66698
2018-02-03 20:36:23,979 training [INFO ] Epoch 18 Batch 7160 Training err. 1.50088 Training err. RA 1.89552 Valid. err. 1.66392
2018-02-03 20:36:24,387 training [INFO ] Epoch 18 Batch 7180 Training err. 1.60209 Training err. RA 1.89470 Valid. err. 1.66121
2018-02-03 20:36:24,794 training [INFO ] Epoch 18 Batch 7200 Training err. 1.53646 Training err. RA 1.89370 Valid. err. 1.67712
2018-02-03 20:36:25,210 training [INFO ] Epoch 18 Batch 7220 Training err. 1.62385 Training err. RA 1.89296 Valid. err. 1.66418
2018-02-03 20:36:25,619 training [INFO ] Epoch 18 Batch 7240 Training err. 1.58129 Training err. RA 1.89209 Valid. err. 1.66545
2018-02-03 20:36:26,031 training [INFO ] Epoch 18 Batch 7260 Training err. 1.54009 Training err. RA 1.89113 Valid. err. 1.68264
2018-02-03 20:36:26,441 training [INFO ] Epoch 18 Batch 7280 Training err. 1.51428 Training err. RA 1.89009 Valid. err. 1.64806
2018-02-03 20:36:26,854 training [INFO ] Epoch 18 Batch 7300 Training err. 1.59457 Training err. RA 1.88928 Valid. err. 1.65446
2018-02-03 20:36:27,269 training [INFO ] Epoch 18 Batch 7320 Training err. 1.60294 Training err. RA 1.88850 Valid. err. 1.67442
2018-02-03 20:36:27,680 training [INFO ] Epoch 18 Batch 7340 Training err. 1.60575 Training err. RA 1.88773 Valid. err. 1.66730
2018-02-03 20:36:28,092 training [INFO ] Epoch 18 Batch 7360 Training err. 1.54571 Training err. RA 1.88680 Valid. err. 1.66556
2018-02-03 20:36:28,504 training [INFO ] Epoch 18 Batch 7380 Training err. 1.53460 Training err. RA 1.88584 Valid. err. 1.68505
2018-02-03 20:36:28,916 training [INFO ] Epoch 18 Batch 7400 Training err. 1.49214 Training err. RA 1.88478 Valid. err. 1.67243
2018-02-03 20:36:29,323 training [INFO ] Epoch 18 Batch 7420 Training err. 1.53548 Training err. RA 1.88384 Valid. err. 1.64908
2018-02-03 20:36:29,733 training [INFO ] Epoch 18 Batch 7440 Training err. 1.54555 Training err. RA 1.88293 Valid. err. 1.64457
2018-02-03 20:36:30,138 training [INFO ] Epoch 18 Batch 7460 Training err. 1.51203 Training err. RA 1.88193 Valid. err. 1.64809
2018-02-03 20:36:30,546 training [INFO ] Epoch 18 Batch 7480 Training err. 1.54819 Training err. RA 1.88104 Valid. err. 1.66472
2018-02-03 20:36:30,951 training [INFO ] Epoch 18 Batch 7500 Training err. 1.52026 Training err. RA 1.88008 Valid. err. 1.65514
2018-02-03 20:36:31,724 training [INFO ] Epoch 19 Batch 7520 Training err. 1.53564 Training err. RA 1.87916 Valid. err. 1.65903
2018-02-03 20:36:32,132 training [INFO ] Epoch 19 Batch 7540 Training err. 1.49388 Training err. RA 1.87814 Valid. err. 1.66069
2018-02-03 20:36:32,540 training [INFO ] Epoch 19 Batch 7560 Training err. 1.49950 Training err. RA 1.87714 Valid. err. 1.66050
2018-02-03 20:36:32,946 training [INFO ] Epoch 19 Batch 7580 Training err. 1.49495 Training err. RA 1.87613 Valid. err. 1.65183
2018-02-03 20:36:33,351 training [INFO ] Epoch 19 Batch 7600 Training err. 1.58986 Training err. RA 1.87538 Valid. err. 1.65661
2018-02-03 20:36:33,759 training [INFO ] Epoch 19 Batch 7620 Training err. 1.51381 Training err. RA 1.87443 Valid. err. 1.65067
2018-02-03 20:36:34,161 training [INFO ] Epoch 19 Batch 7640 Training err. 1.63979 Training err. RA 1.87382 Valid. err. 1.64887
2018-02-03 20:36:34,568 training [INFO ] Epoch 19 Batch 7660 Training err. 1.54053 Training err. RA 1.87294 Valid. err. 1.64864
2018-02-03 20:36:34,973 training [INFO ] Epoch 19 Batch 7680 Training err. 1.53270 Training err. RA 1.87206 Valid. err. 1.64745
2018-02-03 20:36:35,379 training [INFO ] Epoch 19 Batch 7700 Training err. 1.48651 Training err. RA 1.87106 Valid. err. 1.65012
2018-02-03 20:36:35,785 training [INFO ] Epoch 19 Batch 7720 Training err. 1.58130 Training err. RA 1.87031 Valid. err. 1.64392
2018-02-03 20:36:36,197 training [INFO ] Epoch 19 Batch 7740 Training err. 1.59523 Training err. RA 1.86960 Valid. err. 1.64919
2018-02-03 20:36:36,602 training [INFO ] Epoch 19 Batch 7760 Training err. 1.57122 Training err. RA 1.86883 Valid. err. 1.65884
2018-02-03 20:36:37,005 training [INFO ] Epoch 19 Batch 7780 Training err. 1.51711 Training err. RA 1.86792 Valid. err. 1.66355
2018-02-03 20:36:37,410 training [INFO ] Epoch 19 Batch 7800 Training err. 1.52655 Training err. RA 1.86705 Valid. err. 1.66925
2018-02-03 20:36:37,815 training [INFO ] Epoch 19 Batch 7820 Training err. 1.48312 Training err. RA 1.86607 Valid. err. 1.65637
2018-02-03 20:36:38,220 training [INFO ] Epoch 19 Batch 7840 Training err. 1.51339 Training err. RA 1.86517 Valid. err. 1.63700
2018-02-03 20:36:38,620 training [INFO ] Epoch 19 Batch 7860 Training err. 1.52546 Training err. RA 1.86430 Valid. err. 1.64254
2018-02-03 20:36:39,026 training [INFO ] Epoch 19 Batch 7880 Training err. 1.50435 Training err. RA 1.86339 Valid. err. 1.64968
2018-02-03 20:36:39,430 training [INFO ] Epoch 19 Batch 7900 Training err. 1.54020 Training err. RA 1.86257 Valid. err. 1.63891
2018-02-03 20:36:39,837 training [INFO ] Epoch 19 Batch 7920 Training err. 1.49598 Training err. RA 1.86164 Valid. err. 1.64232
2018-02-03 20:36:40,601 training [INFO ] Epoch 20 Batch 7940 Training err. 1.53838 Training err. RA 1.86083 Valid. err. 1.63481
2018-02-03 20:36:41,006 training [INFO ] Epoch 20 Batch 7960 Training err. 1.47288 Training err. RA 1.85985 Valid. err. 1.65029
2018-02-03 20:36:41,410 training [INFO ] Epoch 20 Batch 7980 Training err. 1.48397 Training err. RA 1.85891 Valid. err. 1.65688
2018-02-03 20:36:41,814 training [INFO ] Epoch 20 Batch 8000 Training err. 1.48760 Training err. RA 1.85798 Valid. err. 1.64031
2018-02-03 20:36:42,218 training [INFO ] Epoch 20 Batch 8020 Training err. 1.57581 Training err. RA 1.85728 Valid. err. 1.64104
2018-02-03 20:36:42,620 training [INFO ] Epoch 20 Batch 8040 Training err. 1.49741 Training err. RA 1.85639 Valid. err. 1.64561
2018-02-03 20:36:43,027 training [INFO ] Epoch 20 Batch 8060 Training err. 1.65293 Training err. RA 1.85588 Valid. err. 1.63042
2018-02-03 20:36:43,432 training [INFO ] Epoch 20 Batch 8080 Training err. 1.49387 Training err. RA 1.85498 Valid. err. 1.65556
2018-02-03 20:36:43,839 training [INFO ] Epoch 20 Batch 8100 Training err. 1.50629 Training err. RA 1.85412 Valid. err. 1.65049
2018-02-03 20:36:44,245 training [INFO ] Epoch 20 Batch 8120 Training err. 1.48992 Training err. RA 1.85323 Valid. err. 1.62771
2018-02-03 20:36:44,644 training [INFO ] Epoch 20 Batch 8140 Training err. 1.56195 Training err. RA 1.85251 Valid. err. 1.63835
2018-02-03 20:36:45,051 training [INFO ] Epoch 20 Batch 8160 Training err. 1.56419 Training err. RA 1.85180 Valid. err. 1.64635
2018-02-03 20:36:45,457 training [INFO ] Epoch 20 Batch 8180 Training err. 1.56893 Training err. RA 1.85111 Valid. err. 1.64448
2018-02-03 20:36:45,863 training [INFO ] Epoch 20 Batch 8200 Training err. 1.50572 Training err. RA 1.85027 Valid. err. 1.64647
2018-02-03 20:36:46,265 training [INFO ] Epoch 20 Batch 8220 Training err. 1.51574 Training err. RA 1.84946 Valid. err. 1.66221
2018-02-03 20:36:46,668 training [INFO ] Epoch 20 Batch 8240 Training err. 1.47199 Training err. RA 1.84854 Valid. err. 1.65429
2018-02-03 20:36:47,079 training [INFO ] Epoch 20 Batch 8260 Training err. 1.48897 Training err. RA 1.84767 Valid. err. 1.63078
2018-02-03 20:36:47,484 training [INFO ] Epoch 20 Batch 8280 Training err. 1.50626 Training err. RA 1.84684 Valid. err. 1.64308
2018-02-03 20:36:47,888 training [INFO ] Epoch 20 Batch 8300 Training err. 1.50444 Training err. RA 1.84602 Valid. err. 1.63403
2018-02-03 20:36:48,291 training [INFO ] Epoch 20 Batch 8320 Training err. 1.51662 Training err. RA 1.84523 Valid. err. 1.62905
2018-02-03 20:36:48,691 training [INFO ] Epoch 20 Batch 8340 Training err. 1.49822 Training err. RA 1.84440 Valid. err. 1.62206
2018-02-03 20:36:48,987 __main__ [INFO ] End of training
2018-02-03 20:36:49,243 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:36:49,243 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:36:49,843 training [INFO ] Epoch  1 Batch   20 Training err. 4.24075 Training err. RA 4.24075 Valid. err. 4.16570
2018-02-03 20:36:50,305 training [INFO ] Epoch  1 Batch   40 Training err. 4.05742 Training err. RA 4.14908 Valid. err. 3.99696
2018-02-03 20:36:50,769 training [INFO ] Epoch  1 Batch   60 Training err. 3.89706 Training err. RA 4.06507 Valid. err. 3.81715
2018-02-03 20:36:51,235 training [INFO ] Epoch  1 Batch   80 Training err. 3.71444 Training err. RA 3.97741 Valid. err. 3.63759
2018-02-03 20:36:51,703 training [INFO ] Epoch  1 Batch  100 Training err. 3.52375 Training err. RA 3.88668 Valid. err. 3.49663
2018-02-03 20:36:52,169 training [INFO ] Epoch  1 Batch  120 Training err. 3.42041 Training err. RA 3.80897 Valid. err. 3.38641
2018-02-03 20:36:52,641 training [INFO ] Epoch  1 Batch  140 Training err. 3.30871 Training err. RA 3.73750 Valid. err. 3.31360
2018-02-03 20:36:53,112 training [INFO ] Epoch  1 Batch  160 Training err. 3.22842 Training err. RA 3.67387 Valid. err. 3.27293
2018-02-03 20:36:53,580 training [INFO ] Epoch  1 Batch  180 Training err. 3.23881 Training err. RA 3.62553 Valid. err. 3.25048
2018-02-03 20:36:54,049 training [INFO ] Epoch  1 Batch  200 Training err. 3.22753 Training err. RA 3.58573 Valid. err. 3.23379
2018-02-03 20:36:54,855 training [INFO ] Epoch  2 Batch  220 Training err. 3.19508 Training err. RA 3.55021 Valid. err. 3.22830
2018-02-03 20:36:55,327 training [INFO ] Epoch  2 Batch  240 Training err. 3.11016 Training err. RA 3.51354 Valid. err. 3.24637
2018-02-03 20:36:55,798 training [INFO ] Epoch  2 Batch  260 Training err. 3.19329 Training err. RA 3.48891 Valid. err. 3.21041
2018-02-03 20:36:56,270 training [INFO ] Epoch  2 Batch  280 Training err. 3.14734 Training err. RA 3.46451 Valid. err. 3.20660
2018-02-03 20:36:56,740 training [INFO ] Epoch  2 Batch  300 Training err. 3.14179 Training err. RA 3.44300 Valid. err. 3.20566
2018-02-03 20:36:57,211 training [INFO ] Epoch  2 Batch  320 Training err. 3.17221 Training err. RA 3.42607 Valid. err. 3.19932
2018-02-03 20:36:57,679 training [INFO ] Epoch  2 Batch  340 Training err. 3.14889 Training err. RA 3.40977 Valid. err. 3.19875
2018-02-03 20:36:58,151 training [INFO ] Epoch  2 Batch  360 Training err. 3.13575 Training err. RA 3.39454 Valid. err. 3.19636
2018-02-03 20:36:58,621 training [INFO ] Epoch  2 Batch  380 Training err. 3.12856 Training err. RA 3.38054 Valid. err. 3.19286
2018-02-03 20:36:59,091 training [INFO ] Epoch  2 Batch  400 Training err. 3.17184 Training err. RA 3.37011 Valid. err. 3.19051
2018-02-03 20:36:59,895 training [INFO ] Epoch  3 Batch  420 Training err. 3.16671 Training err. RA 3.36042 Valid. err. 3.18990
2018-02-03 20:37:00,369 training [INFO ] Epoch  3 Batch  440 Training err. 3.12924 Training err. RA 3.34992 Valid. err. 3.19301
2018-02-03 20:37:00,843 training [INFO ] Epoch  3 Batch  460 Training err. 3.11594 Training err. RA 3.33974 Valid. err. 3.18715
2018-02-03 20:37:01,312 training [INFO ] Epoch  3 Batch  480 Training err. 3.12235 Training err. RA 3.33068 Valid. err. 3.18786
2018-02-03 20:37:01,786 training [INFO ] Epoch  3 Batch  500 Training err. 3.10940 Training err. RA 3.32183 Valid. err. 3.19288
2018-02-03 20:37:02,257 training [INFO ] Epoch  3 Batch  520 Training err. 3.16395 Training err. RA 3.31576 Valid. err. 3.18907
2018-02-03 20:37:02,727 training [INFO ] Epoch  3 Batch  540 Training err. 3.15348 Training err. RA 3.30975 Valid. err. 3.18724
2018-02-03 20:37:03,193 training [INFO ] Epoch  3 Batch  560 Training err. 3.12082 Training err. RA 3.30300 Valid. err. 3.18699
2018-02-03 20:37:03,663 training [INFO ] Epoch  3 Batch  580 Training err. 3.08353 Training err. RA 3.29543 Valid. err. 3.18929
2018-02-03 20:37:04,137 training [INFO ] Epoch  3 Batch  600 Training err. 3.16463 Training err. RA 3.29107 Valid. err. 3.18399
2018-02-03 20:37:04,608 training [INFO ] Epoch  3 Batch  620 Training err. 3.16484 Training err. RA 3.28700 Valid. err. 3.18074
2018-02-03 20:37:05,417 training [INFO ] Epoch  4 Batch  640 Training err. 3.13581 Training err. RA 3.28228 Valid. err. 3.18325
2018-02-03 20:37:05,889 training [INFO ] Epoch  4 Batch  660 Training err. 3.07855 Training err. RA 3.27610 Valid. err. 3.18440
2018-02-03 20:37:06,361 training [INFO ] Epoch  4 Batch  680 Training err. 3.13639 Training err. RA 3.27199 Valid. err. 3.18339
2018-02-03 20:37:06,833 training [INFO ] Epoch  4 Batch  700 Training err. 3.12092 Training err. RA 3.26768 Valid. err. 3.18221
2018-02-03 20:37:07,316 training [INFO ] Epoch  4 Batch  720 Training err. 3.11238 Training err. RA 3.26336 Valid. err. 3.18507
2018-02-03 20:37:07,808 training [INFO ] Epoch  4 Batch  740 Training err. 3.16624 Training err. RA 3.26074 Valid. err. 3.18070
2018-02-03 20:37:08,286 training [INFO ] Epoch  4 Batch  760 Training err. 3.11394 Training err. RA 3.25688 Valid. err. 3.18318
2018-02-03 20:37:08,762 training [INFO ] Epoch  4 Batch  780 Training err. 3.11338 Training err. RA 3.25320 Valid. err. 3.18119
2018-02-03 20:37:09,234 training [INFO ] Epoch  4 Batch  800 Training err. 3.12278 Training err. RA 3.24994 Valid. err. 3.18045
2018-02-03 20:37:09,707 training [INFO ] Epoch  4 Batch  820 Training err. 3.14813 Training err. RA 3.24745 Valid. err. 3.17887
2018-02-03 20:37:10,541 training [INFO ] Epoch  5 Batch  840 Training err. 3.15721 Training err. RA 3.24530 Valid. err. 3.17633
2018-02-03 20:37:11,016 training [INFO ] Epoch  5 Batch  860 Training err. 3.07934 Training err. RA 3.24145 Valid. err. 3.20086
2018-02-03 20:37:11,492 training [INFO ] Epoch  5 Batch  880 Training err. 3.13334 Training err. RA 3.23899 Valid. err. 3.17804
2018-02-03 20:37:11,977 training [INFO ] Epoch  5 Batch  900 Training err. 3.11432 Training err. RA 3.23622 Valid. err. 3.17788
2018-02-03 20:37:12,456 training [INFO ] Epoch  5 Batch  920 Training err. 3.09222 Training err. RA 3.23309 Valid. err. 3.18158
2018-02-03 20:37:12,932 training [INFO ] Epoch  5 Batch  940 Training err. 3.15353 Training err. RA 3.23139 Valid. err. 3.18056
2018-02-03 20:37:13,405 training [INFO ] Epoch  5 Batch  960 Training err. 3.12553 Training err. RA 3.22919 Valid. err. 3.18036
2018-02-03 20:37:13,878 training [INFO ] Epoch  5 Batch  980 Training err. 3.11818 Training err. RA 3.22692 Valid. err. 3.17670
2018-02-03 20:37:14,349 training [INFO ] Epoch  5 Batch 1000 Training err. 3.08150 Training err. RA 3.22402 Valid. err. 3.17613
2018-02-03 20:37:14,821 training [INFO ] Epoch  5 Batch 1020 Training err. 3.15970 Training err. RA 3.22275 Valid. err. 3.17408
2018-02-03 20:37:15,294 training [INFO ] Epoch  5 Batch 1040 Training err. 3.14538 Training err. RA 3.22127 Valid. err. 3.17074
2018-02-03 20:37:16,100 training [INFO ] Epoch  6 Batch 1060 Training err. 3.11108 Training err. RA 3.21919 Valid. err. 3.17322
2018-02-03 20:37:16,579 training [INFO ] Epoch  6 Batch 1080 Training err. 3.09104 Training err. RA 3.21681 Valid. err. 3.17300
2018-02-03 20:37:17,053 training [INFO ] Epoch  6 Batch 1100 Training err. 3.10018 Training err. RA 3.21469 Valid. err. 3.17444
2018-02-03 20:37:17,530 training [INFO ] Epoch  6 Batch 1120 Training err. 3.11753 Training err. RA 3.21296 Valid. err. 3.17371
2018-02-03 20:37:18,012 training [INFO ] Epoch  6 Batch 1140 Training err. 3.11428 Training err. RA 3.21123 Valid. err. 3.17254
2018-02-03 20:37:18,488 training [INFO ] Epoch  6 Batch 1160 Training err. 3.14800 Training err. RA 3.21014 Valid. err. 3.17077
2018-02-03 20:37:18,964 training [INFO ] Epoch  6 Batch 1180 Training err. 3.10531 Training err. RA 3.20836 Valid. err. 3.17136
2018-02-03 20:37:19,443 training [INFO ] Epoch  6 Batch 1200 Training err. 3.07800 Training err. RA 3.20619 Valid. err. 3.17094
2018-02-03 20:37:19,923 training [INFO ] Epoch  6 Batch 1220 Training err. 3.12973 Training err. RA 3.20493 Valid. err. 3.16932
2018-02-03 20:37:20,402 training [INFO ] Epoch  6 Batch 1240 Training err. 3.14078 Training err. RA 3.20390 Valid. err. 3.16535
2018-02-03 20:37:21,216 training [INFO ] Epoch  7 Batch 1260 Training err. 3.12989 Training err. RA 3.20272 Valid. err. 3.17520
2018-02-03 20:37:21,686 training [INFO ] Epoch  7 Batch 1280 Training err. 3.05066 Training err. RA 3.20035 Valid. err. 3.20161
2018-02-03 20:37:22,160 training [INFO ] Epoch  7 Batch 1300 Training err. 3.13236 Training err. RA 3.19930 Valid. err. 3.16602
2018-02-03 20:37:22,633 training [INFO ] Epoch  7 Batch 1320 Training err. 3.09985 Training err. RA 3.19780 Valid. err. 3.16449
2018-02-03 20:37:23,106 training [INFO ] Epoch  7 Batch 1340 Training err. 3.09450 Training err. RA 3.19625 Valid. err. 3.16794
2018-02-03 20:37:23,577 training [INFO ] Epoch  7 Batch 1360 Training err. 3.13366 Training err. RA 3.19533 Valid. err. 3.16182
2018-02-03 20:37:24,056 training [INFO ] Epoch  7 Batch 1380 Training err. 3.10715 Training err. RA 3.19406 Valid. err. 3.16314
2018-02-03 20:37:24,527 training [INFO ] Epoch  7 Batch 1400 Training err. 3.09290 Training err. RA 3.19261 Valid. err. 3.16163
2018-02-03 20:37:24,998 training [INFO ] Epoch  7 Batch 1420 Training err. 3.08662 Training err. RA 3.19112 Valid. err. 3.15850
2018-02-03 20:37:25,467 training [INFO ] Epoch  7 Batch 1440 Training err. 3.13180 Training err. RA 3.19029 Valid. err. 3.15552
2018-02-03 20:37:26,283 training [INFO ] Epoch  8 Batch 1460 Training err. 3.12792 Training err. RA 3.18944 Valid. err. 3.15504
2018-02-03 20:37:26,753 training [INFO ] Epoch  8 Batch 1480 Training err. 3.09162 Training err. RA 3.18812 Valid. err. 3.16132
2018-02-03 20:37:27,222 training [INFO ] Epoch  8 Batch 1500 Training err. 3.08483 Training err. RA 3.18674 Valid. err. 3.15229
2018-02-03 20:37:27,691 training [INFO ] Epoch  8 Batch 1520 Training err. 3.08351 Training err. RA 3.18538 Valid. err. 3.15213
2018-02-03 20:37:28,163 training [INFO ] Epoch  8 Batch 1540 Training err. 3.07272 Training err. RA 3.18392 Valid. err. 3.15652
2018-02-03 20:37:28,637 training [INFO ] Epoch  8 Batch 1560 Training err. 3.12623 Training err. RA 3.18318 Valid. err. 3.15143
2018-02-03 20:37:29,110 training [INFO ] Epoch  8 Batch 1580 Training err. 3.11376 Training err. RA 3.18230 Valid. err. 3.14808
2018-02-03 20:37:29,582 training [INFO ] Epoch  8 Batch 1600 Training err. 3.07683 Training err. RA 3.18098 Valid. err. 3.14583
2018-02-03 20:37:30,053 training [INFO ] Epoch  8 Batch 1620 Training err. 3.03979 Training err. RA 3.17924 Valid. err. 3.14658
2018-02-03 20:37:30,523 training [INFO ] Epoch  8 Batch 1640 Training err. 3.11676 Training err. RA 3.17848 Valid. err. 3.13923
2018-02-03 20:37:30,995 training [INFO ] Epoch  8 Batch 1660 Training err. 3.11660 Training err. RA 3.17773 Valid. err. 3.13373
2018-02-03 20:37:31,808 training [INFO ] Epoch  9 Batch 1680 Training err. 3.09079 Training err. RA 3.17670 Valid. err. 3.13469
2018-02-03 20:37:32,281 training [INFO ] Epoch  9 Batch 1700 Training err. 3.04415 Training err. RA 3.17514 Valid. err. 3.13394
2018-02-03 20:37:32,755 training [INFO ] Epoch  9 Batch 1720 Training err. 3.08417 Training err. RA 3.17408 Valid. err. 3.13233
2018-02-03 20:37:33,228 training [INFO ] Epoch  9 Batch 1740 Training err. 3.07123 Training err. RA 3.17290 Valid. err. 3.12818
2018-02-03 20:37:33,705 training [INFO ] Epoch  9 Batch 1760 Training err. 3.06038 Training err. RA 3.17162 Valid. err. 3.12832
2018-02-03 20:37:34,185 training [INFO ] Epoch  9 Batch 1780 Training err. 3.11166 Training err. RA 3.17095 Valid. err. 3.12247
2018-02-03 20:37:34,664 training [INFO ] Epoch  9 Batch 1800 Training err. 3.05306 Training err. RA 3.16964 Valid. err. 3.12045
2018-02-03 20:37:35,143 training [INFO ] Epoch  9 Batch 1820 Training err. 3.04650 Training err. RA 3.16828 Valid. err. 3.11522
2018-02-03 20:37:35,622 training [INFO ] Epoch  9 Batch 1840 Training err. 3.05701 Training err. RA 3.16707 Valid. err. 3.11042
2018-02-03 20:37:36,098 training [INFO ] Epoch  9 Batch 1860 Training err. 3.07691 Training err. RA 3.16610 Valid. err. 3.10481
2018-02-03 20:37:36,925 training [INFO ] Epoch 10 Batch 1880 Training err. 3.08421 Training err. RA 3.16523 Valid. err. 3.09883
2018-02-03 20:37:37,415 training [INFO ] Epoch 10 Batch 1900 Training err. 3.01896 Training err. RA 3.16369 Valid. err. 3.13132
2018-02-03 20:37:37,908 training [INFO ] Epoch 10 Batch 1920 Training err. 3.06794 Training err. RA 3.16269 Valid. err. 3.09687
2018-02-03 20:37:38,407 training [INFO ] Epoch 10 Batch 1940 Training err. 3.03462 Training err. RA 3.16137 Valid. err. 3.09058
2018-02-03 20:37:38,889 training [INFO ] Epoch 10 Batch 1960 Training err. 3.01093 Training err. RA 3.15984 Valid. err. 3.09121
2018-02-03 20:37:39,392 training [INFO ] Epoch 10 Batch 1980 Training err. 3.07372 Training err. RA 3.15897 Valid. err. 3.08673
2018-02-03 20:37:39,873 training [INFO ] Epoch 10 Batch 2000 Training err. 3.03432 Training err. RA 3.15772 Valid. err. 3.08108
2018-02-03 20:37:40,381 training [INFO ] Epoch 10 Batch 2020 Training err. 3.01418 Training err. RA 3.15630 Valid. err. 3.07508
2018-02-03 20:37:40,870 training [INFO ] Epoch 10 Batch 2040 Training err. 2.98039 Training err. RA 3.15458 Valid. err. 3.06612
2018-02-03 20:37:41,362 training [INFO ] Epoch 10 Batch 2060 Training err. 3.04647 Training err. RA 3.15353 Valid. err. 3.05754
2018-02-03 20:37:41,869 training [INFO ] Epoch 10 Batch 2080 Training err. 3.02780 Training err. RA 3.15232 Valid. err. 3.04797
2018-02-03 20:37:42,763 training [INFO ] Epoch 11 Batch 2100 Training err. 2.99873 Training err. RA 3.15086 Valid. err. 3.04594
2018-02-03 20:37:43,269 training [INFO ] Epoch 11 Batch 2120 Training err. 3.01492 Training err. RA 3.14957 Valid. err. 3.04840
2018-02-03 20:37:43,746 training [INFO ] Epoch 11 Batch 2140 Training err. 2.97789 Training err. RA 3.14797 Valid. err. 3.04043
2018-02-03 20:37:44,221 training [INFO ] Epoch 11 Batch 2160 Training err. 2.98672 Training err. RA 3.14648 Valid. err. 3.03330
2018-02-03 20:37:44,705 training [INFO ] Epoch 11 Batch 2180 Training err. 2.98711 Training err. RA 3.14501 Valid. err. 3.02744
2018-02-03 20:37:45,212 training [INFO ] Epoch 11 Batch 2200 Training err. 3.01593 Training err. RA 3.14384 Valid. err. 3.02075
2018-02-03 20:37:45,687 training [INFO ] Epoch 11 Batch 2220 Training err. 2.95721 Training err. RA 3.14216 Valid. err. 3.01499
2018-02-03 20:37:46,163 training [INFO ] Epoch 11 Batch 2240 Training err. 2.92243 Training err. RA 3.14020 Valid. err. 3.00932
2018-02-03 20:37:46,855 training [INFO ] Epoch 11 Batch 2260 Training err. 2.97643 Training err. RA 3.13875 Valid. err. 3.00166
2018-02-03 20:37:47,485 training [INFO ] Epoch 11 Batch 2280 Training err. 2.97864 Training err. RA 3.13734 Valid. err. 2.99250
2018-02-03 20:37:48,307 training [INFO ] Epoch 12 Batch 2300 Training err. 2.96923 Training err. RA 3.13588 Valid. err. 3.03809
2018-02-03 20:37:48,777 training [INFO ] Epoch 12 Batch 2320 Training err. 2.90960 Training err. RA 3.13393 Valid. err. 3.03998
2018-02-03 20:37:49,246 training [INFO ] Epoch 12 Batch 2340 Training err. 2.96083 Training err. RA 3.13245 Valid. err. 2.98074
2018-02-03 20:37:49,718 training [INFO ] Epoch 12 Batch 2360 Training err. 2.92835 Training err. RA 3.13072 Valid. err. 2.97210
2018-02-03 20:37:50,193 training [INFO ] Epoch 12 Batch 2380 Training err. 2.90107 Training err. RA 3.12879 Valid. err. 2.97555
2018-02-03 20:37:50,673 training [INFO ] Epoch 12 Batch 2400 Training err. 2.95217 Training err. RA 3.12732 Valid. err. 2.95893
2018-02-03 20:37:51,145 training [INFO ] Epoch 12 Batch 2420 Training err. 2.91413 Training err. RA 3.12556 Valid. err. 2.95500
2018-02-03 20:37:51,619 training [INFO ] Epoch 12 Batch 2440 Training err. 2.88893 Training err. RA 3.12362 Valid. err. 2.94897
2018-02-03 20:37:52,097 training [INFO ] Epoch 12 Batch 2460 Training err. 2.88237 Training err. RA 3.12166 Valid. err. 2.94026
2018-02-03 20:37:52,577 training [INFO ] Epoch 12 Batch 2480 Training err. 2.91216 Training err. RA 3.11997 Valid. err. 2.92976
2018-02-03 20:37:53,390 training [INFO ] Epoch 13 Batch 2500 Training err. 2.90810 Training err. RA 3.11827 Valid. err. 2.92453
2018-02-03 20:37:53,864 training [INFO ] Epoch 13 Batch 2520 Training err. 2.86307 Training err. RA 3.11625 Valid. err. 2.94014
2018-02-03 20:37:54,343 training [INFO ] Epoch 13 Batch 2540 Training err. 2.87520 Training err. RA 3.11435 Valid. err. 2.91569
2018-02-03 20:37:54,822 training [INFO ] Epoch 13 Batch 2560 Training err. 2.84840 Training err. RA 3.11227 Valid. err. 2.90462
2018-02-03 20:37:55,309 training [INFO ] Epoch 13 Batch 2580 Training err. 2.82723 Training err. RA 3.11006 Valid. err. 2.91153
2018-02-03 20:37:55,780 training [INFO ] Epoch 13 Batch 2600 Training err. 2.87383 Training err. RA 3.10824 Valid. err. 2.90319
2018-02-03 20:37:56,263 training [INFO ] Epoch 13 Batch 2620 Training err. 2.87744 Training err. RA 3.10648 Valid. err. 2.88594
2018-02-03 20:37:56,744 training [INFO ] Epoch 13 Batch 2640 Training err. 2.82487 Training err. RA 3.10435 Valid. err. 2.88085
2018-02-03 20:37:57,227 training [INFO ] Epoch 13 Batch 2660 Training err. 2.77993 Training err. RA 3.10191 Valid. err. 2.89488
2018-02-03 20:37:57,705 training [INFO ] Epoch 13 Batch 2680 Training err. 2.84869 Training err. RA 3.10002 Valid. err. 2.86542
2018-02-03 20:37:58,185 training [INFO ] Epoch 13 Batch 2700 Training err. 2.85576 Training err. RA 3.09821 Valid. err. 2.85891
2018-02-03 20:37:59,015 training [INFO ] Epoch 14 Batch 2720 Training err. 2.80658 Training err. RA 3.09607 Valid. err. 2.86298
2018-02-03 20:37:59,492 training [INFO ] Epoch 14 Batch 2740 Training err. 2.82568 Training err. RA 3.09409 Valid. err. 2.88313
2018-02-03 20:37:59,986 training [INFO ] Epoch 14 Batch 2760 Training err. 2.82689 Training err. RA 3.09216 Valid. err. 2.85597
2018-02-03 20:38:00,476 training [INFO ] Epoch 14 Batch 2780 Training err. 2.80694 Training err. RA 3.09011 Valid. err. 2.84778
2018-02-03 20:38:00,950 training [INFO ] Epoch 14 Batch 2800 Training err. 2.77525 Training err. RA 3.08786 Valid. err. 2.84392
2018-02-03 20:38:01,428 training [INFO ] Epoch 14 Batch 2820 Training err. 2.84055 Training err. RA 3.08610 Valid. err. 2.83625
2018-02-03 20:38:01,900 training [INFO ] Epoch 14 Batch 2840 Training err. 2.77475 Training err. RA 3.08391 Valid. err. 2.84423
2018-02-03 20:38:02,370 training [INFO ] Epoch 14 Batch 2860 Training err. 2.76003 Training err. RA 3.08164 Valid. err. 2.82230
2018-02-03 20:38:02,885 training [INFO ] Epoch 14 Batch 2880 Training err. 2.77755 Training err. RA 3.07953 Valid. err. 2.81645
2018-02-03 20:38:03,373 training [INFO ] Epoch 14 Batch 2900 Training err. 2.78098 Training err. RA 3.07747 Valid. err. 2.80701
2018-02-03 20:38:04,218 training [INFO ] Epoch 15 Batch 2920 Training err. 2.78799 Training err. RA 3.07549 Valid. err. 2.79845
2018-02-03 20:38:04,701 training [INFO ] Epoch 15 Batch 2940 Training err. 2.68824 Training err. RA 3.07286 Valid. err. 2.80074
2018-02-03 20:38:05,182 training [INFO ] Epoch 15 Batch 2960 Training err. 2.76571 Training err. RA 3.07078 Valid. err. 2.79815
2018-02-03 20:38:05,661 training [INFO ] Epoch 15 Batch 2980 Training err. 2.73662 Training err. RA 3.06854 Valid. err. 2.78704
2018-02-03 20:38:06,142 training [INFO ] Epoch 15 Batch 3000 Training err. 2.69224 Training err. RA 3.06603 Valid. err. 2.78867
2018-02-03 20:38:06,625 training [INFO ] Epoch 15 Batch 3020 Training err. 2.75079 Training err. RA 3.06394 Valid. err. 2.79328
2018-02-03 20:38:07,106 training [INFO ] Epoch 15 Batch 3040 Training err. 2.75057 Training err. RA 3.06188 Valid. err. 2.77323
2018-02-03 20:38:07,586 training [INFO ] Epoch 15 Batch 3060 Training err. 2.72527 Training err. RA 3.05968 Valid. err. 2.77933
2018-02-03 20:38:08,059 training [INFO ] Epoch 15 Batch 3080 Training err. 2.66765 Training err. RA 3.05714 Valid. err. 2.78382
2018-02-03 20:38:08,532 training [INFO ] Epoch 15 Batch 3100 Training err. 2.74619 Training err. RA 3.05513 Valid. err. 2.75828
2018-02-03 20:38:09,007 training [INFO ] Epoch 15 Batch 3120 Training err. 2.74205 Training err. RA 3.05312 Valid. err. 2.75275
2018-02-03 20:38:09,815 training [INFO ] Epoch 16 Batch 3140 Training err. 2.67684 Training err. RA 3.05073 Valid. err. 2.74775
2018-02-03 20:38:10,288 training [INFO ] Epoch 16 Batch 3160 Training err. 2.66020 Training err. RA 3.04825 Valid. err. 2.75285
2018-02-03 20:38:10,753 training [INFO ] Epoch 16 Batch 3180 Training err. 2.69064 Training err. RA 3.04600 Valid. err. 2.74060
2018-02-03 20:38:11,226 training [INFO ] Epoch 16 Batch 3200 Training err. 2.68915 Training err. RA 3.04377 Valid. err. 2.73557
2018-02-03 20:38:11,699 training [INFO ] Epoch 16 Batch 3220 Training err. 2.67238 Training err. RA 3.04147 Valid. err. 2.73487
2018-02-03 20:38:12,175 training [INFO ] Epoch 16 Batch 3240 Training err. 2.73003 Training err. RA 3.03955 Valid. err. 2.73963
2018-02-03 20:38:12,659 training [INFO ] Epoch 16 Batch 3260 Training err. 2.67808 Training err. RA 3.03733 Valid. err. 2.73504
2018-02-03 20:38:13,128 training [INFO ] Epoch 16 Batch 3280 Training err. 2.64248 Training err. RA 3.03492 Valid. err. 2.73459
2018-02-03 20:38:13,612 training [INFO ] Epoch 16 Batch 3300 Training err. 2.68213 Training err. RA 3.03278 Valid. err. 2.71508
2018-02-03 20:38:14,097 training [INFO ] Epoch 16 Batch 3320 Training err. 2.69256 Training err. RA 3.03073 Valid. err. 2.71739
2018-02-03 20:38:14,924 training [INFO ] Epoch 17 Batch 3340 Training err. 2.66849 Training err. RA 3.02856 Valid. err. 2.70935
2018-02-03 20:38:15,413 training [INFO ] Epoch 17 Batch 3360 Training err. 2.57056 Training err. RA 3.02584 Valid. err. 2.70807
2018-02-03 20:38:15,890 training [INFO ] Epoch 17 Batch 3380 Training err. 2.70585 Training err. RA 3.02394 Valid. err. 2.69903
2018-02-03 20:38:16,360 training [INFO ] Epoch 17 Batch 3400 Training err. 2.64181 Training err. RA 3.02170 Valid. err. 2.69186
2018-02-03 20:38:16,831 training [INFO ] Epoch 17 Batch 3420 Training err. 2.62334 Training err. RA 3.01937 Valid. err. 2.70589
2018-02-03 20:38:17,301 training [INFO ] Epoch 17 Batch 3440 Training err. 2.67039 Training err. RA 3.01734 Valid. err. 2.68194
2018-02-03 20:38:17,774 training [INFO ] Epoch 17 Batch 3460 Training err. 2.66974 Training err. RA 3.01533 Valid. err. 2.69761
2018-02-03 20:38:18,255 training [INFO ] Epoch 17 Batch 3480 Training err. 2.62876 Training err. RA 3.01311 Valid. err. 2.68137
2018-02-03 20:38:18,742 training [INFO ] Epoch 17 Batch 3500 Training err. 2.61973 Training err. RA 3.01086 Valid. err. 2.68511
2018-02-03 20:38:19,211 training [INFO ] Epoch 17 Batch 3520 Training err. 2.64613 Training err. RA 3.00879 Valid. err. 2.67015
2018-02-03 20:38:20,067 training [INFO ] Epoch 18 Batch 3540 Training err. 2.64800 Training err. RA 3.00675 Valid. err. 2.66206
2018-02-03 20:38:20,538 training [INFO ] Epoch 18 Batch 3560 Training err. 2.60065 Training err. RA 3.00447 Valid. err. 2.66174
2018-02-03 20:38:21,009 training [INFO ] Epoch 18 Batch 3580 Training err. 2.59860 Training err. RA 3.00220 Valid. err. 2.71158
2018-02-03 20:38:21,477 training [INFO ] Epoch 18 Batch 3600 Training err. 2.62006 Training err. RA 3.00008 Valid. err. 2.65562
2018-02-03 20:38:21,943 training [INFO ] Epoch 18 Batch 3620 Training err. 2.58223 Training err. RA 2.99777 Valid. err. 2.68235
2018-02-03 20:38:22,416 training [INFO ] Epoch 18 Batch 3640 Training err. 2.63686 Training err. RA 2.99578 Valid. err. 2.66774
2018-02-03 20:38:22,886 training [INFO ] Epoch 18 Batch 3660 Training err. 2.65701 Training err. RA 2.99393 Valid. err. 2.65800
2018-02-03 20:38:23,352 training [INFO ] Epoch 18 Batch 3680 Training err. 2.59370 Training err. RA 2.99176 Valid. err. 2.64584
2018-02-03 20:38:23,819 training [INFO ] Epoch 18 Batch 3700 Training err. 2.55340 Training err. RA 2.98939 Valid. err. 2.64864
2018-02-03 20:38:24,289 training [INFO ] Epoch 18 Batch 3720 Training err. 2.61694 Training err. RA 2.98739 Valid. err. 2.63808
2018-02-03 20:38:24,759 training [INFO ] Epoch 18 Batch 3740 Training err. 2.62805 Training err. RA 2.98546 Valid. err. 2.63696
2018-02-03 20:38:25,583 training [INFO ] Epoch 19 Batch 3760 Training err. 2.58593 Training err. RA 2.98334 Valid. err. 2.62752
2018-02-03 20:38:26,073 training [INFO ] Epoch 19 Batch 3780 Training err. 2.51739 Training err. RA 2.98087 Valid. err. 2.63205
2018-02-03 20:38:26,553 training [INFO ] Epoch 19 Batch 3800 Training err. 2.62508 Training err. RA 2.97900 Valid. err. 2.62739
2018-02-03 20:38:27,030 training [INFO ] Epoch 19 Batch 3820 Training err. 2.57792 Training err. RA 2.97690 Valid. err. 2.63115
2018-02-03 20:38:27,540 training [INFO ] Epoch 19 Batch 3840 Training err. 2.54991 Training err. RA 2.97468 Valid. err. 2.63408
2018-02-03 20:38:28,024 training [INFO ] Epoch 19 Batch 3860 Training err. 2.63327 Training err. RA 2.97291 Valid. err. 2.61911
2018-02-03 20:38:28,508 training [INFO ] Epoch 19 Batch 3880 Training err. 2.58327 Training err. RA 2.97090 Valid. err. 2.61951
2018-02-03 20:38:28,993 training [INFO ] Epoch 19 Batch 3900 Training err. 2.55547 Training err. RA 2.96877 Valid. err. 2.60791
2018-02-03 20:38:29,475 training [INFO ] Epoch 19 Batch 3920 Training err. 2.56736 Training err. RA 2.96672 Valid. err. 2.60297
2018-02-03 20:38:29,959 training [INFO ] Epoch 19 Batch 3940 Training err. 2.56996 Training err. RA 2.96471 Valid. err. 2.60029
2018-02-03 20:38:30,771 training [INFO ] Epoch 20 Batch 3960 Training err. 2.58572 Training err. RA 2.96279 Valid. err. 2.59887
2018-02-03 20:38:31,252 training [INFO ] Epoch 20 Batch 3980 Training err. 2.49559 Training err. RA 2.96045 Valid. err. 2.59575
2018-02-03 20:38:31,734 training [INFO ] Epoch 20 Batch 4000 Training err. 2.59157 Training err. RA 2.95860 Valid. err. 2.60526
2018-02-03 20:38:32,211 training [INFO ] Epoch 20 Batch 4020 Training err. 2.55173 Training err. RA 2.95658 Valid. err. 2.58594
2018-02-03 20:38:32,682 training [INFO ] Epoch 20 Batch 4040 Training err. 2.51661 Training err. RA 2.95440 Valid. err. 2.60451
2018-02-03 20:38:33,206 training [INFO ] Epoch 20 Batch 4060 Training err. 2.56988 Training err. RA 2.95251 Valid. err. 2.60490
2018-02-03 20:38:33,692 training [INFO ] Epoch 20 Batch 4080 Training err. 2.58606 Training err. RA 2.95071 Valid. err. 2.58694
2018-02-03 20:38:34,163 training [INFO ] Epoch 20 Batch 4100 Training err. 2.54563 Training err. RA 2.94873 Valid. err. 2.59275
2018-02-03 20:38:34,637 training [INFO ] Epoch 20 Batch 4120 Training err. 2.49151 Training err. RA 2.94651 Valid. err. 2.59884
2018-02-03 20:38:35,117 training [INFO ] Epoch 20 Batch 4140 Training err. 2.56355 Training err. RA 2.94466 Valid. err. 2.57291
2018-02-03 20:38:35,592 training [INFO ] Epoch 20 Batch 4160 Training err. 2.55870 Training err. RA 2.94281 Valid. err. 2.56966
2018-02-03 20:38:35,868 __main__ [INFO ] End of training
2018-02-03 20:38:36,104 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:38:36,104 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:38:36,689 training [INFO ] Epoch  1 Batch   20 Training err. 3.61960 Training err. RA 3.61960 Valid. err. 3.26900
2018-02-03 20:38:37,161 training [INFO ] Epoch  1 Batch   40 Training err. 3.16451 Training err. RA 3.39206 Valid. err. 3.20785
2018-02-03 20:38:37,631 training [INFO ] Epoch  1 Batch   60 Training err. 3.14266 Training err. RA 3.30892 Valid. err. 3.21520
2018-02-03 20:38:38,100 training [INFO ] Epoch  1 Batch   80 Training err. 3.14482 Training err. RA 3.26790 Valid. err. 3.19921
2018-02-03 20:38:38,572 training [INFO ] Epoch  1 Batch  100 Training err. 3.13253 Training err. RA 3.24082 Valid. err. 3.18234
2018-02-03 20:38:39,040 training [INFO ] Epoch  1 Batch  120 Training err. 3.16005 Training err. RA 3.22736 Valid. err. 3.18177
2018-02-03 20:38:39,509 training [INFO ] Epoch  1 Batch  140 Training err. 3.11154 Training err. RA 3.21082 Valid. err. 3.17591
2018-02-03 20:38:39,977 training [INFO ] Epoch  1 Batch  160 Training err. 3.07374 Training err. RA 3.19368 Valid. err. 3.18111
2018-02-03 20:38:40,446 training [INFO ] Epoch  1 Batch  180 Training err. 3.13767 Training err. RA 3.18746 Valid. err. 3.15215
2018-02-03 20:38:40,915 training [INFO ] Epoch  1 Batch  200 Training err. 3.11172 Training err. RA 3.17988 Valid. err. 3.12498
2018-02-03 20:38:41,725 training [INFO ] Epoch  2 Batch  220 Training err. 3.09203 Training err. RA 3.17190 Valid. err. 3.24514
2018-02-03 20:38:42,198 training [INFO ] Epoch  2 Batch  240 Training err. 3.00704 Training err. RA 3.15816 Valid. err. 3.25077
2018-02-03 20:38:42,669 training [INFO ] Epoch  2 Batch  260 Training err. 3.04350 Training err. RA 3.14934 Valid. err. 3.06779
2018-02-03 20:38:43,143 training [INFO ] Epoch  2 Batch  280 Training err. 2.95615 Training err. RA 3.13554 Valid. err. 2.96950
2018-02-03 20:38:43,619 training [INFO ] Epoch  2 Batch  300 Training err. 2.91098 Training err. RA 3.12057 Valid. err. 2.93786
2018-02-03 20:38:44,094 training [INFO ] Epoch  2 Batch  320 Training err. 2.91274 Training err. RA 3.10758 Valid. err. 2.87445
2018-02-03 20:38:44,566 training [INFO ] Epoch  2 Batch  340 Training err. 2.84085 Training err. RA 3.09189 Valid. err. 2.89567
2018-02-03 20:38:45,035 training [INFO ] Epoch  2 Batch  360 Training err. 2.78615 Training err. RA 3.07490 Valid. err. 2.84160
2018-02-03 20:38:45,504 training [INFO ] Epoch  2 Batch  380 Training err. 2.75629 Training err. RA 3.05813 Valid. err. 2.76108
2018-02-03 20:38:45,984 training [INFO ] Epoch  2 Batch  400 Training err. 2.74023 Training err. RA 3.04224 Valid. err. 2.73576
2018-02-03 20:38:46,802 training [INFO ] Epoch  3 Batch  420 Training err. 2.71897 Training err. RA 3.02684 Valid. err. 2.71592
2018-02-03 20:38:47,282 training [INFO ] Epoch  3 Batch  440 Training err. 2.68361 Training err. RA 3.01124 Valid. err. 2.67827
2018-02-03 20:38:47,771 training [INFO ] Epoch  3 Batch  460 Training err. 2.68367 Training err. RA 2.99700 Valid. err. 2.70387
2018-02-03 20:38:48,259 training [INFO ] Epoch  3 Batch  480 Training err. 2.63076 Training err. RA 2.98174 Valid. err. 2.64704
2018-02-03 20:38:48,746 training [INFO ] Epoch  3 Batch  500 Training err. 2.57247 Training err. RA 2.96537 Valid. err. 2.67914
2018-02-03 20:38:49,217 training [INFO ] Epoch  3 Batch  520 Training err. 2.59499 Training err. RA 2.95112 Valid. err. 2.63512
2018-02-03 20:38:49,691 training [INFO ] Epoch  3 Batch  540 Training err. 2.60183 Training err. RA 2.93819 Valid. err. 2.57641
2018-02-03 20:38:50,173 training [INFO ] Epoch  3 Batch  560 Training err. 2.51011 Training err. RA 2.92290 Valid. err. 2.55734
2018-02-03 20:38:50,653 training [INFO ] Epoch  3 Batch  580 Training err. 2.48781 Training err. RA 2.90790 Valid. err. 2.53040
2018-02-03 20:38:51,122 training [INFO ] Epoch  3 Batch  600 Training err. 2.49745 Training err. RA 2.89421 Valid. err. 2.48537
2018-02-03 20:38:51,591 training [INFO ] Epoch  3 Batch  620 Training err. 2.49292 Training err. RA 2.88127 Valid. err. 2.47771
2018-02-03 20:38:52,395 training [INFO ] Epoch  4 Batch  640 Training err. 2.47650 Training err. RA 2.86862 Valid. err. 2.51311
2018-02-03 20:38:52,865 training [INFO ] Epoch  4 Batch  660 Training err. 2.37025 Training err. RA 2.85352 Valid. err. 2.45003
2018-02-03 20:38:53,337 training [INFO ] Epoch  4 Batch  680 Training err. 2.45212 Training err. RA 2.84171 Valid. err. 2.47973
2018-02-03 20:38:53,811 training [INFO ] Epoch  4 Batch  700 Training err. 2.41335 Training err. RA 2.82947 Valid. err. 2.41565
2018-02-03 20:38:54,287 training [INFO ] Epoch  4 Batch  720 Training err. 2.36791 Training err. RA 2.81665 Valid. err. 2.42630
2018-02-03 20:38:54,759 training [INFO ] Epoch  4 Batch  740 Training err. 2.44181 Training err. RA 2.80652 Valid. err. 2.38410
2018-02-03 20:38:55,229 training [INFO ] Epoch  4 Batch  760 Training err. 2.37558 Training err. RA 2.79518 Valid. err. 2.38640
2018-02-03 20:38:55,702 training [INFO ] Epoch  4 Batch  780 Training err. 2.32773 Training err. RA 2.78320 Valid. err. 2.36916
2018-02-03 20:38:56,174 training [INFO ] Epoch  4 Batch  800 Training err. 2.33880 Training err. RA 2.77209 Valid. err. 2.35003
2018-02-03 20:38:56,647 training [INFO ] Epoch  4 Batch  820 Training err. 2.30026 Training err. RA 2.76058 Valid. err. 2.34226
2018-02-03 20:38:57,461 training [INFO ] Epoch  5 Batch  840 Training err. 2.31742 Training err. RA 2.75003 Valid. err. 2.31449
2018-02-03 20:38:57,936 training [INFO ] Epoch  5 Batch  860 Training err. 2.22937 Training err. RA 2.73792 Valid. err. 2.31568
2018-02-03 20:38:58,411 training [INFO ] Epoch  5 Batch  880 Training err. 2.30994 Training err. RA 2.72819 Valid. err. 2.31677
2018-02-03 20:38:58,887 training [INFO ] Epoch  5 Batch  900 Training err. 2.28994 Training err. RA 2.71845 Valid. err. 2.29137
2018-02-03 20:38:59,366 training [INFO ] Epoch  5 Batch  920 Training err. 2.24494 Training err. RA 2.70816 Valid. err. 2.29566
2018-02-03 20:38:59,844 training [INFO ] Epoch  5 Batch  940 Training err. 2.25150 Training err. RA 2.69844 Valid. err. 2.36763
2018-02-03 20:39:00,325 training [INFO ] Epoch  5 Batch  960 Training err. 2.31402 Training err. RA 2.69043 Valid. err. 2.25473
2018-02-03 20:39:00,802 training [INFO ] Epoch  5 Batch  980 Training err. 2.23237 Training err. RA 2.68108 Valid. err. 2.29985
2018-02-03 20:39:01,274 training [INFO ] Epoch  5 Batch 1000 Training err. 2.18871 Training err. RA 2.67124 Valid. err. 2.23909
2018-02-03 20:39:01,740 training [INFO ] Epoch  5 Batch 1020 Training err. 2.21454 Training err. RA 2.66228 Valid. err. 2.23944
2018-02-03 20:39:02,211 training [INFO ] Epoch  5 Batch 1040 Training err. 2.19099 Training err. RA 2.65322 Valid. err. 2.22163
2018-02-03 20:39:03,027 training [INFO ] Epoch  6 Batch 1060 Training err. 2.18748 Training err. RA 2.64443 Valid. err. 2.23252
2018-02-03 20:39:03,503 training [INFO ] Epoch  6 Batch 1080 Training err. 2.12749 Training err. RA 2.63486 Valid. err. 2.22500
2018-02-03 20:39:03,986 training [INFO ] Epoch  6 Batch 1100 Training err. 2.19631 Training err. RA 2.62688 Valid. err. 2.20863
2018-02-03 20:39:04,471 training [INFO ] Epoch  6 Batch 1120 Training err. 2.19084 Training err. RA 2.61910 Valid. err. 2.20936
2018-02-03 20:39:04,948 training [INFO ] Epoch  6 Batch 1140 Training err. 2.15706 Training err. RA 2.61099 Valid. err. 2.18362
2018-02-03 20:39:05,419 training [INFO ] Epoch  6 Batch 1160 Training err. 2.22363 Training err. RA 2.60431 Valid. err. 2.17416
2018-02-03 20:39:05,902 training [INFO ] Epoch  6 Batch 1180 Training err. 2.15467 Training err. RA 2.59669 Valid. err. 2.19134
2018-02-03 20:39:06,383 training [INFO ] Epoch  6 Batch 1200 Training err. 2.11931 Training err. RA 2.58874 Valid. err. 2.24957
2018-02-03 20:39:06,851 training [INFO ] Epoch  6 Batch 1220 Training err. 2.11965 Training err. RA 2.58105 Valid. err. 2.16841
2018-02-03 20:39:07,334 training [INFO ] Epoch  6 Batch 1240 Training err. 2.11408 Training err. RA 2.57351 Valid. err. 2.21675
2018-02-03 20:39:08,161 training [INFO ] Epoch  7 Batch 1260 Training err. 2.11787 Training err. RA 2.56628 Valid. err. 2.14030
2018-02-03 20:39:08,642 training [INFO ] Epoch  7 Batch 1280 Training err. 2.03156 Training err. RA 2.55793 Valid. err. 2.15300
2018-02-03 20:39:09,119 training [INFO ] Epoch  7 Batch 1300 Training err. 2.12346 Training err. RA 2.55124 Valid. err. 2.12870
2018-02-03 20:39:09,608 training [INFO ] Epoch  7 Batch 1320 Training err. 2.12503 Training err. RA 2.54479 Valid. err. 2.13924
2018-02-03 20:39:10,091 training [INFO ] Epoch  7 Batch 1340 Training err. 2.07239 Training err. RA 2.53773 Valid. err. 2.11838
2018-02-03 20:39:10,567 training [INFO ] Epoch  7 Batch 1360 Training err. 2.11763 Training err. RA 2.53156 Valid. err. 2.12402
2018-02-03 20:39:11,064 training [INFO ] Epoch  7 Batch 1380 Training err. 2.13421 Training err. RA 2.52580 Valid. err. 2.11611
2018-02-03 20:39:11,557 training [INFO ] Epoch  7 Batch 1400 Training err. 2.05787 Training err. RA 2.51911 Valid. err. 2.11672
2018-02-03 20:39:12,042 training [INFO ] Epoch  7 Batch 1420 Training err. 2.05897 Training err. RA 2.51263 Valid. err. 2.12501
2018-02-03 20:39:12,521 training [INFO ] Epoch  7 Batch 1440 Training err. 2.05242 Training err. RA 2.50624 Valid. err. 2.11771
2018-02-03 20:39:13,351 training [INFO ] Epoch  8 Batch 1460 Training err. 2.04565 Training err. RA 2.49993 Valid. err. 2.09167
2018-02-03 20:39:13,817 training [INFO ] Epoch  8 Batch 1480 Training err. 2.02012 Training err. RA 2.49345 Valid. err. 2.08719
2018-02-03 20:39:14,287 training [INFO ] Epoch  8 Batch 1500 Training err. 2.00979 Training err. RA 2.48700 Valid. err. 2.07394
2018-02-03 20:39:14,775 training [INFO ] Epoch  8 Batch 1520 Training err. 2.06271 Training err. RA 2.48142 Valid. err. 2.06886
2018-02-03 20:39:15,250 training [INFO ] Epoch  8 Batch 1540 Training err. 2.02455 Training err. RA 2.47548 Valid. err. 2.10265
2018-02-03 20:39:15,745 training [INFO ] Epoch  8 Batch 1560 Training err. 2.04376 Training err. RA 2.46995 Valid. err. 2.08314
2018-02-03 20:39:16,248 training [INFO ] Epoch  8 Batch 1580 Training err. 2.10266 Training err. RA 2.46530 Valid. err. 2.06952
2018-02-03 20:39:16,753 training [INFO ] Epoch  8 Batch 1600 Training err. 1.99341 Training err. RA 2.45940 Valid. err. 2.06533
2018-02-03 20:39:17,272 training [INFO ] Epoch  8 Batch 1620 Training err. 1.99164 Training err. RA 2.45363 Valid. err. 2.06229
2018-02-03 20:39:17,765 training [INFO ] Epoch  8 Batch 1640 Training err. 1.99600 Training err. RA 2.44804 Valid. err. 2.03735
2018-02-03 20:39:18,253 training [INFO ] Epoch  8 Batch 1660 Training err. 1.99125 Training err. RA 2.44254 Valid. err. 2.02764
2018-02-03 20:39:19,082 training [INFO ] Epoch  9 Batch 1680 Training err. 1.99365 Training err. RA 2.43720 Valid. err. 2.03431
2018-02-03 20:39:19,558 training [INFO ] Epoch  9 Batch 1700 Training err. 1.92673 Training err. RA 2.43119 Valid. err. 2.04569
2018-02-03 20:39:20,031 training [INFO ] Epoch  9 Batch 1720 Training err. 2.00329 Training err. RA 2.42622 Valid. err. 2.03884
2018-02-03 20:39:20,503 training [INFO ] Epoch  9 Batch 1740 Training err. 2.00623 Training err. RA 2.42139 Valid. err. 2.02856
2018-02-03 20:39:20,976 training [INFO ] Epoch  9 Batch 1760 Training err. 1.96840 Training err. RA 2.41624 Valid. err. 2.05933
2018-02-03 20:39:21,445 training [INFO ] Epoch  9 Batch 1780 Training err. 2.03376 Training err. RA 2.41194 Valid. err. 2.04554
2018-02-03 20:39:21,915 training [INFO ] Epoch  9 Batch 1800 Training err. 1.99424 Training err. RA 2.40730 Valid. err. 2.01234
2018-02-03 20:39:22,392 training [INFO ] Epoch  9 Batch 1820 Training err. 1.94253 Training err. RA 2.40219 Valid. err. 2.00243
2018-02-03 20:39:22,869 training [INFO ] Epoch  9 Batch 1840 Training err. 1.95212 Training err. RA 2.39730 Valid. err. 1.98972
2018-02-03 20:39:23,338 training [INFO ] Epoch  9 Batch 1860 Training err. 1.94070 Training err. RA 2.39239 Valid. err. 1.98964
2018-02-03 20:39:24,163 training [INFO ] Epoch 10 Batch 1880 Training err. 1.97060 Training err. RA 2.38791 Valid. err. 1.99572
2018-02-03 20:39:24,636 training [INFO ] Epoch 10 Batch 1900 Training err. 1.88909 Training err. RA 2.38265 Valid. err. 1.99825
2018-02-03 20:39:25,110 training [INFO ] Epoch 10 Batch 1920 Training err. 1.95014 Training err. RA 2.37815 Valid. err. 2.00108
2018-02-03 20:39:25,590 training [INFO ] Epoch 10 Batch 1940 Training err. 1.97126 Training err. RA 2.37395 Valid. err. 1.97502
2018-02-03 20:39:26,058 training [INFO ] Epoch 10 Batch 1960 Training err. 1.91781 Training err. RA 2.36930 Valid. err. 1.97977
2018-02-03 20:39:26,534 training [INFO ] Epoch 10 Batch 1980 Training err. 1.92945 Training err. RA 2.36486 Valid. err. 2.01285
2018-02-03 20:39:27,007 training [INFO ] Epoch 10 Batch 2000 Training err. 2.00565 Training err. RA 2.36127 Valid. err. 1.96706
2018-02-03 20:39:27,476 training [INFO ] Epoch 10 Batch 2020 Training err. 1.91464 Training err. RA 2.35684 Valid. err. 1.98927
2018-02-03 20:39:27,945 training [INFO ] Epoch 10 Batch 2040 Training err. 1.88893 Training err. RA 2.35226 Valid. err. 1.97318
2018-02-03 20:39:28,413 training [INFO ] Epoch 10 Batch 2060 Training err. 1.91218 Training err. RA 2.34798 Valid. err. 1.94144
2018-02-03 20:39:28,882 training [INFO ] Epoch 10 Batch 2080 Training err. 1.89083 Training err. RA 2.34359 Valid. err. 1.95733
2018-02-03 20:39:29,691 training [INFO ] Epoch 11 Batch 2100 Training err. 1.90826 Training err. RA 2.33944 Valid. err. 1.94689
2018-02-03 20:39:30,170 training [INFO ] Epoch 11 Batch 2120 Training err. 1.84632 Training err. RA 2.33479 Valid. err. 1.96036
2018-02-03 20:39:30,645 training [INFO ] Epoch 11 Batch 2140 Training err. 1.91834 Training err. RA 2.33090 Valid. err. 1.95161
2018-02-03 20:39:31,121 training [INFO ] Epoch 11 Batch 2160 Training err. 1.92657 Training err. RA 2.32715 Valid. err. 1.94553
2018-02-03 20:39:31,596 training [INFO ] Epoch 11 Batch 2180 Training err. 1.88732 Training err. RA 2.32312 Valid. err. 1.93280
2018-02-03 20:39:32,070 training [INFO ] Epoch 11 Batch 2200 Training err. 1.95136 Training err. RA 2.31974 Valid. err. 1.93187
2018-02-03 20:39:32,545 training [INFO ] Epoch 11 Batch 2220 Training err. 1.90028 Training err. RA 2.31596 Valid. err. 1.94464
2018-02-03 20:39:33,017 training [INFO ] Epoch 11 Batch 2240 Training err. 1.85450 Training err. RA 2.31184 Valid. err. 1.97681
2018-02-03 20:39:33,485 training [INFO ] Epoch 11 Batch 2260 Training err. 1.86981 Training err. RA 2.30793 Valid. err. 1.93750
2018-02-03 20:39:33,950 training [INFO ] Epoch 11 Batch 2280 Training err. 1.86803 Training err. RA 2.30407 Valid. err. 1.92960
2018-02-03 20:39:34,763 training [INFO ] Epoch 12 Batch 2300 Training err. 1.86886 Training err. RA 2.30028 Valid. err. 1.91125
2018-02-03 20:39:35,238 training [INFO ] Epoch 12 Batch 2320 Training err. 1.79812 Training err. RA 2.29596 Valid. err. 1.92386
2018-02-03 20:39:35,727 training [INFO ] Epoch 12 Batch 2340 Training err. 1.88214 Training err. RA 2.29242 Valid. err. 1.91688
2018-02-03 20:39:36,217 training [INFO ] Epoch 12 Batch 2360 Training err. 1.90487 Training err. RA 2.28913 Valid. err. 1.92338
2018-02-03 20:39:36,701 training [INFO ] Epoch 12 Batch 2380 Training err. 1.84100 Training err. RA 2.28537 Valid. err. 1.91197
2018-02-03 20:39:37,179 training [INFO ] Epoch 12 Batch 2400 Training err. 1.88591 Training err. RA 2.28204 Valid. err. 1.91094
2018-02-03 20:39:37,656 training [INFO ] Epoch 12 Batch 2420 Training err. 1.91367 Training err. RA 2.27900 Valid. err. 1.91108
2018-02-03 20:39:38,129 training [INFO ] Epoch 12 Batch 2440 Training err. 1.83411 Training err. RA 2.27535 Valid. err. 1.90855
2018-02-03 20:39:38,603 training [INFO ] Epoch 12 Batch 2460 Training err. 1.83508 Training err. RA 2.27177 Valid. err. 1.89662
2018-02-03 20:39:39,087 training [INFO ] Epoch 12 Batch 2480 Training err. 1.83347 Training err. RA 2.26823 Valid. err. 1.89089
2018-02-03 20:39:39,928 training [INFO ] Epoch 13 Batch 2500 Training err. 1.81623 Training err. RA 2.26462 Valid. err. 1.89240
2018-02-03 20:39:40,408 training [INFO ] Epoch 13 Batch 2520 Training err. 1.80791 Training err. RA 2.26099 Valid. err. 1.88448
2018-02-03 20:39:40,893 training [INFO ] Epoch 13 Batch 2540 Training err. 1.81253 Training err. RA 2.25746 Valid. err. 1.89266
2018-02-03 20:39:41,378 training [INFO ] Epoch 13 Batch 2560 Training err. 1.85917 Training err. RA 2.25435 Valid. err. 1.88785
2018-02-03 20:39:41,847 training [INFO ] Epoch 13 Batch 2580 Training err. 1.83872 Training err. RA 2.25113 Valid. err. 1.89979
2018-02-03 20:39:42,315 training [INFO ] Epoch 13 Batch 2600 Training err. 1.84035 Training err. RA 2.24797 Valid. err. 1.87064
2018-02-03 20:39:42,813 training [INFO ] Epoch 13 Batch 2620 Training err. 1.90413 Training err. RA 2.24534 Valid. err. 1.90805
2018-02-03 20:39:43,298 training [INFO ] Epoch 13 Batch 2640 Training err. 1.80094 Training err. RA 2.24198 Valid. err. 1.88881
2018-02-03 20:39:43,800 training [INFO ] Epoch 13 Batch 2660 Training err. 1.79455 Training err. RA 2.23861 Valid. err. 1.90543
2018-02-03 20:39:44,288 training [INFO ] Epoch 13 Batch 2680 Training err. 1.80678 Training err. RA 2.23539 Valid. err. 1.85973
2018-02-03 20:39:44,768 training [INFO ] Epoch 13 Batch 2700 Training err. 1.80719 Training err. RA 2.23222 Valid. err. 1.85625
2018-02-03 20:39:45,609 training [INFO ] Epoch 14 Batch 2720 Training err. 1.78668 Training err. RA 2.22894 Valid. err. 1.87249
2018-02-03 20:39:46,093 training [INFO ] Epoch 14 Batch 2740 Training err. 1.75312 Training err. RA 2.22547 Valid. err. 1.88305
2018-02-03 20:39:46,626 training [INFO ] Epoch 14 Batch 2760 Training err. 1.82232 Training err. RA 2.22255 Valid. err. 1.87528
2018-02-03 20:39:47,110 training [INFO ] Epoch 14 Batch 2780 Training err. 1.84066 Training err. RA 2.21980 Valid. err. 1.86200
2018-02-03 20:39:47,596 training [INFO ] Epoch 14 Batch 2800 Training err. 1.79516 Training err. RA 2.21677 Valid. err. 1.89204
2018-02-03 20:39:48,090 training [INFO ] Epoch 14 Batch 2820 Training err. 1.85707 Training err. RA 2.21422 Valid. err. 1.86429
2018-02-03 20:39:48,572 training [INFO ] Epoch 14 Batch 2840 Training err. 1.82279 Training err. RA 2.21146 Valid. err. 1.86132
2018-02-03 20:39:49,052 training [INFO ] Epoch 14 Batch 2860 Training err. 1.76939 Training err. RA 2.20837 Valid. err. 1.85154
2018-02-03 20:39:49,524 training [INFO ] Epoch 14 Batch 2880 Training err. 1.78420 Training err. RA 2.20542 Valid. err. 1.84290
2018-02-03 20:39:50,026 training [INFO ] Epoch 14 Batch 2900 Training err. 1.77963 Training err. RA 2.20249 Valid. err. 1.84229
2018-02-03 20:39:50,830 training [INFO ] Epoch 15 Batch 2920 Training err. 1.76234 Training err. RA 2.19947 Valid. err. 1.84496
2018-02-03 20:39:51,300 training [INFO ] Epoch 15 Batch 2940 Training err. 1.72996 Training err. RA 2.19628 Valid. err. 1.86656
2018-02-03 20:39:51,768 training [INFO ] Epoch 15 Batch 2960 Training err. 1.79393 Training err. RA 2.19356 Valid. err. 1.87009
2018-02-03 20:39:52,258 training [INFO ] Epoch 15 Batch 2980 Training err. 1.81834 Training err. RA 2.19104 Valid. err. 1.83940
2018-02-03 20:39:52,734 training [INFO ] Epoch 15 Batch 3000 Training err. 1.76546 Training err. RA 2.18820 Valid. err. 1.85522
2018-02-03 20:39:53,207 training [INFO ] Epoch 15 Batch 3020 Training err. 1.78205 Training err. RA 2.18551 Valid. err. 1.85192
2018-02-03 20:39:53,684 training [INFO ] Epoch 15 Batch 3040 Training err. 1.84238 Training err. RA 2.18326 Valid. err. 1.83692
2018-02-03 20:39:54,158 training [INFO ] Epoch 15 Batch 3060 Training err. 1.76136 Training err. RA 2.18050 Valid. err. 1.84594
2018-02-03 20:39:54,631 training [INFO ] Epoch 15 Batch 3080 Training err. 1.74253 Training err. RA 2.17766 Valid. err. 1.85156
2018-02-03 20:39:55,107 training [INFO ] Epoch 15 Batch 3100 Training err. 1.75873 Training err. RA 2.17495 Valid. err. 1.80911
2018-02-03 20:39:55,581 training [INFO ] Epoch 15 Batch 3120 Training err. 1.74266 Training err. RA 2.17218 Valid. err. 1.83196
2018-02-03 20:39:56,411 training [INFO ] Epoch 16 Batch 3140 Training err. 1.74240 Training err. RA 2.16944 Valid. err. 1.82581
2018-02-03 20:39:56,886 training [INFO ] Epoch 16 Batch 3160 Training err. 1.70707 Training err. RA 2.16652 Valid. err. 1.83527
2018-02-03 20:39:57,353 training [INFO ] Epoch 16 Batch 3180 Training err. 1.77777 Training err. RA 2.16407 Valid. err. 1.83894
2018-02-03 20:39:57,821 training [INFO ] Epoch 16 Batch 3200 Training err. 1.79470 Training err. RA 2.16176 Valid. err. 1.83274
2018-02-03 20:39:58,291 training [INFO ] Epoch 16 Batch 3220 Training err. 1.74570 Training err. RA 2.15918 Valid. err. 1.82344
2018-02-03 20:39:58,763 training [INFO ] Epoch 16 Batch 3240 Training err. 1.80851 Training err. RA 2.15702 Valid. err. 1.82372
2018-02-03 20:39:59,228 training [INFO ] Epoch 16 Batch 3260 Training err. 1.76485 Training err. RA 2.15461 Valid. err. 1.82266
2018-02-03 20:39:59,698 training [INFO ] Epoch 16 Batch 3280 Training err. 1.71926 Training err. RA 2.15195 Valid. err. 1.84348
2018-02-03 20:40:00,176 training [INFO ] Epoch 16 Batch 3300 Training err. 1.73636 Training err. RA 2.14944 Valid. err. 1.82632
2018-02-03 20:40:00,647 training [INFO ] Epoch 16 Batch 3320 Training err. 1.73636 Training err. RA 2.14695 Valid. err. 1.81096
2018-02-03 20:40:01,459 training [INFO ] Epoch 17 Batch 3340 Training err. 1.72192 Training err. RA 2.14440 Valid. err. 1.79765
2018-02-03 20:40:01,933 training [INFO ] Epoch 17 Batch 3360 Training err. 1.67303 Training err. RA 2.14160 Valid. err. 1.82093
2018-02-03 20:40:02,406 training [INFO ] Epoch 17 Batch 3380 Training err. 1.75016 Training err. RA 2.13928 Valid. err. 1.80488
2018-02-03 20:40:02,878 training [INFO ] Epoch 17 Batch 3400 Training err. 1.78305 Training err. RA 2.13719 Valid. err. 1.82487
2018-02-03 20:40:03,354 training [INFO ] Epoch 17 Batch 3420 Training err. 1.71882 Training err. RA 2.13474 Valid. err. 1.81587
2018-02-03 20:40:03,828 training [INFO ] Epoch 17 Batch 3440 Training err. 1.75479 Training err. RA 2.13253 Valid. err. 1.81198
2018-02-03 20:40:04,303 training [INFO ] Epoch 17 Batch 3460 Training err. 1.78821 Training err. RA 2.13054 Valid. err. 1.79848
2018-02-03 20:40:04,777 training [INFO ] Epoch 17 Batch 3480 Training err. 1.70859 Training err. RA 2.12811 Valid. err. 1.80523
2018-02-03 20:40:05,264 training [INFO ] Epoch 17 Batch 3500 Training err. 1.71788 Training err. RA 2.12577 Valid. err. 1.79181
2018-02-03 20:40:05,762 training [INFO ] Epoch 17 Batch 3520 Training err. 1.70839 Training err. RA 2.12340 Valid. err. 1.79292
2018-02-03 20:40:06,595 training [INFO ] Epoch 18 Batch 3540 Training err. 1.69392 Training err. RA 2.12097 Valid. err. 1.78720
2018-02-03 20:40:07,074 training [INFO ] Epoch 18 Batch 3560 Training err. 1.68751 Training err. RA 2.11854 Valid. err. 1.78707
2018-02-03 20:40:07,563 training [INFO ] Epoch 18 Batch 3580 Training err. 1.69402 Training err. RA 2.11617 Valid. err. 1.79583
2018-02-03 20:40:08,034 training [INFO ] Epoch 18 Batch 3600 Training err. 1.74323 Training err. RA 2.11409 Valid. err. 1.78230
2018-02-03 20:40:08,514 training [INFO ] Epoch 18 Batch 3620 Training err. 1.72873 Training err. RA 2.11196 Valid. err. 1.79896
2018-02-03 20:40:08,997 training [INFO ] Epoch 18 Batch 3640 Training err. 1.72165 Training err. RA 2.10982 Valid. err. 1.77494
2018-02-03 20:40:09,479 training [INFO ] Epoch 18 Batch 3660 Training err. 1.78684 Training err. RA 2.10806 Valid. err. 1.80871
2018-02-03 20:40:09,958 training [INFO ] Epoch 18 Batch 3680 Training err. 1.68712 Training err. RA 2.10577 Valid. err. 1.79191
2018-02-03 20:40:10,443 training [INFO ] Epoch 18 Batch 3700 Training err. 1.68517 Training err. RA 2.10349 Valid. err. 1.81537
2018-02-03 20:40:10,920 training [INFO ] Epoch 18 Batch 3720 Training err. 1.68685 Training err. RA 2.10125 Valid. err. 1.77392
2018-02-03 20:40:11,401 training [INFO ] Epoch 18 Batch 3740 Training err. 1.70216 Training err. RA 2.09912 Valid. err. 1.76106
2018-02-03 20:40:12,240 training [INFO ] Epoch 19 Batch 3760 Training err. 1.67096 Training err. RA 2.09684 Valid. err. 1.78980
2018-02-03 20:40:12,803 training [INFO ] Epoch 19 Batch 3780 Training err. 1.64627 Training err. RA 2.09446 Valid. err. 1.78595
2018-02-03 20:40:13,319 training [INFO ] Epoch 19 Batch 3800 Training err. 1.71068 Training err. RA 2.09244 Valid. err. 1.78010
2018-02-03 20:40:13,825 training [INFO ] Epoch 19 Batch 3820 Training err. 1.73965 Training err. RA 2.09059 Valid. err. 1.77460
2018-02-03 20:40:14,330 training [INFO ] Epoch 19 Batch 3840 Training err. 1.68642 Training err. RA 2.08849 Valid. err. 1.80645
2018-02-03 20:40:14,821 training [INFO ] Epoch 19 Batch 3860 Training err. 1.74345 Training err. RA 2.08670 Valid. err. 1.77944
2018-02-03 20:40:15,296 training [INFO ] Epoch 19 Batch 3880 Training err. 1.72033 Training err. RA 2.08481 Valid. err. 1.76892
2018-02-03 20:40:15,769 training [INFO ] Epoch 19 Batch 3900 Training err. 1.66456 Training err. RA 2.08265 Valid. err. 1.76584
2018-02-03 20:40:16,240 training [INFO ] Epoch 19 Batch 3920 Training err. 1.67879 Training err. RA 2.08059 Valid. err. 1.75281
2018-02-03 20:40:16,709 training [INFO ] Epoch 19 Batch 3940 Training err. 1.68088 Training err. RA 2.07857 Valid. err. 1.77006
2018-02-03 20:40:17,530 training [INFO ] Epoch 20 Batch 3960 Training err. 1.65460 Training err. RA 2.07642 Valid. err. 1.76082
2018-02-03 20:40:18,006 training [INFO ] Epoch 20 Batch 3980 Training err. 1.63028 Training err. RA 2.07418 Valid. err. 1.77756
2018-02-03 20:40:18,483 training [INFO ] Epoch 20 Batch 4000 Training err. 1.68736 Training err. RA 2.07225 Valid. err. 1.77757
2018-02-03 20:40:18,961 training [INFO ] Epoch 20 Batch 4020 Training err. 1.72315 Training err. RA 2.07051 Valid. err. 1.76170
2018-02-03 20:40:19,438 training [INFO ] Epoch 20 Batch 4040 Training err. 1.66963 Training err. RA 2.06853 Valid. err. 1.77756
2018-02-03 20:40:19,915 training [INFO ] Epoch 20 Batch 4060 Training err. 1.67494 Training err. RA 2.06659 Valid. err. 1.76506
2018-02-03 20:40:20,388 training [INFO ] Epoch 20 Batch 4080 Training err. 1.74169 Training err. RA 2.06500 Valid. err. 1.75606
2018-02-03 20:40:20,862 training [INFO ] Epoch 20 Batch 4100 Training err. 1.66283 Training err. RA 2.06303 Valid. err. 1.76905
2018-02-03 20:40:21,335 training [INFO ] Epoch 20 Batch 4120 Training err. 1.64733 Training err. RA 2.06102 Valid. err. 1.74973
2018-02-03 20:40:21,805 training [INFO ] Epoch 20 Batch 4140 Training err. 1.65916 Training err. RA 2.05907 Valid. err. 1.73419
2018-02-03 20:40:22,275 training [INFO ] Epoch 20 Batch 4160 Training err. 1.64794 Training err. RA 2.05710 Valid. err. 1.75227
2018-02-03 20:40:22,547 __main__ [INFO ] End of training
2018-02-03 20:40:22,820 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 64,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:40:22,820 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:40:23,361 training [INFO ] Epoch  1 Batch   20 Training err. 4.21741 Training err. RA 4.21741 Valid. err. 4.14263
2018-02-03 20:40:23,766 training [INFO ] Epoch  1 Batch   40 Training err. 4.06181 Training err. RA 4.13961 Valid. err. 3.98674
2018-02-03 20:40:24,172 training [INFO ] Epoch  1 Batch   60 Training err. 3.84187 Training err. RA 4.04036 Valid. err. 3.80023
2018-02-03 20:40:24,575 training [INFO ] Epoch  1 Batch   80 Training err. 3.69945 Training err. RA 3.95513 Valid. err. 3.65306
2018-02-03 20:40:24,979 training [INFO ] Epoch  1 Batch  100 Training err. 3.57748 Training err. RA 3.87960 Valid. err. 3.53437
2018-02-03 20:40:25,386 training [INFO ] Epoch  1 Batch  120 Training err. 3.41376 Training err. RA 3.80196 Valid. err. 3.43425
2018-02-03 20:40:25,795 training [INFO ] Epoch  1 Batch  140 Training err. 3.39474 Training err. RA 3.74379 Valid. err. 3.36393
2018-02-03 20:40:26,210 training [INFO ] Epoch  1 Batch  160 Training err. 3.31800 Training err. RA 3.69057 Valid. err. 3.31054
2018-02-03 20:40:26,620 training [INFO ] Epoch  1 Batch  180 Training err. 3.26682 Training err. RA 3.64348 Valid. err. 3.27951
2018-02-03 20:40:27,060 training [INFO ] Epoch  1 Batch  200 Training err. 3.25584 Training err. RA 3.60472 Valid. err. 3.25661
2018-02-03 20:40:27,797 training [INFO ] Epoch  2 Batch  220 Training err. 3.22245 Training err. RA 3.56997 Valid. err. 3.24331
2018-02-03 20:40:28,210 training [INFO ] Epoch  2 Batch  240 Training err. 3.20726 Training err. RA 3.53974 Valid. err. 3.23143
2018-02-03 20:40:28,621 training [INFO ] Epoch  2 Batch  260 Training err. 3.15450 Training err. RA 3.51011 Valid. err. 3.22940
2018-02-03 20:40:29,030 training [INFO ] Epoch  2 Batch  280 Training err. 3.14674 Training err. RA 3.48415 Valid. err. 3.21720
2018-02-03 20:40:29,442 training [INFO ] Epoch  2 Batch  300 Training err. 3.18959 Training err. RA 3.46451 Valid. err. 3.20908
2018-02-03 20:40:29,852 training [INFO ] Epoch  2 Batch  320 Training err. 3.12189 Training err. RA 3.44310 Valid. err. 3.20675
2018-02-03 20:40:30,265 training [INFO ] Epoch  2 Batch  340 Training err. 3.15930 Training err. RA 3.42641 Valid. err. 3.20200
2018-02-03 20:40:30,679 training [INFO ] Epoch  2 Batch  360 Training err. 3.16363 Training err. RA 3.41181 Valid. err. 3.19866
2018-02-03 20:40:31,090 training [INFO ] Epoch  2 Batch  380 Training err. 3.15416 Training err. RA 3.39825 Valid. err. 3.19742
2018-02-03 20:40:31,499 training [INFO ] Epoch  2 Batch  400 Training err. 3.16307 Training err. RA 3.38649 Valid. err. 3.19375
2018-02-03 20:40:32,251 training [INFO ] Epoch  3 Batch  420 Training err. 3.19512 Training err. RA 3.37738 Valid. err. 3.19550
2018-02-03 20:40:32,667 training [INFO ] Epoch  3 Batch  440 Training err. 3.14857 Training err. RA 3.36698 Valid. err. 3.19363
2018-02-03 20:40:33,077 training [INFO ] Epoch  3 Batch  460 Training err. 3.14766 Training err. RA 3.35744 Valid. err. 3.19144
2018-02-03 20:40:33,489 training [INFO ] Epoch  3 Batch  480 Training err. 3.06510 Training err. RA 3.34526 Valid. err. 3.20267
2018-02-03 20:40:33,899 training [INFO ] Epoch  3 Batch  500 Training err. 3.17796 Training err. RA 3.33857 Valid. err. 3.18915
2018-02-03 20:40:34,309 training [INFO ] Epoch  3 Batch  520 Training err. 3.11569 Training err. RA 3.33000 Valid. err. 3.18837
2018-02-03 20:40:34,719 training [INFO ] Epoch  3 Batch  540 Training err. 3.09946 Training err. RA 3.32146 Valid. err. 3.18902
2018-02-03 20:40:35,130 training [INFO ] Epoch  3 Batch  560 Training err. 3.16337 Training err. RA 3.31581 Valid. err. 3.18622
2018-02-03 20:40:35,537 training [INFO ] Epoch  3 Batch  580 Training err. 3.14704 Training err. RA 3.30999 Valid. err. 3.18656
2018-02-03 20:40:35,949 training [INFO ] Epoch  3 Batch  600 Training err. 3.13933 Training err. RA 3.30430 Valid. err. 3.18699
2018-02-03 20:40:36,358 training [INFO ] Epoch  3 Batch  620 Training err. 3.17879 Training err. RA 3.30025 Valid. err. 3.18326
2018-02-03 20:40:37,108 training [INFO ] Epoch  4 Batch  640 Training err. 3.14643 Training err. RA 3.29545 Valid. err. 3.18178
2018-02-03 20:40:37,528 training [INFO ] Epoch  4 Batch  660 Training err. 3.13200 Training err. RA 3.29049 Valid. err. 3.18417
2018-02-03 20:40:37,949 training [INFO ] Epoch  4 Batch  680 Training err. 3.09089 Training err. RA 3.28462 Valid. err. 3.19239
2018-02-03 20:40:38,370 training [INFO ] Epoch  4 Batch  700 Training err. 3.13402 Training err. RA 3.28032 Valid. err. 3.18422
2018-02-03 20:40:38,794 training [INFO ] Epoch  4 Batch  720 Training err. 3.13136 Training err. RA 3.27618 Valid. err. 3.18232
2018-02-03 20:40:39,219 training [INFO ] Epoch  4 Batch  740 Training err. 3.08736 Training err. RA 3.27108 Valid. err. 3.18451
2018-02-03 20:40:39,646 training [INFO ] Epoch  4 Batch  760 Training err. 3.15014 Training err. RA 3.26790 Valid. err. 3.18137
2018-02-03 20:40:40,065 training [INFO ] Epoch  4 Batch  780 Training err. 3.13202 Training err. RA 3.26441 Valid. err. 3.18104
2018-02-03 20:40:40,486 training [INFO ] Epoch  4 Batch  800 Training err. 3.13090 Training err. RA 3.26107 Valid. err. 3.18136
2018-02-03 20:40:40,905 training [INFO ] Epoch  4 Batch  820 Training err. 3.14867 Training err. RA 3.25833 Valid. err. 3.17912
2018-02-03 20:40:41,662 training [INFO ] Epoch  5 Batch  840 Training err. 3.16462 Training err. RA 3.25610 Valid. err. 3.18119
2018-02-03 20:40:42,071 training [INFO ] Epoch  5 Batch  860 Training err. 3.13598 Training err. RA 3.25331 Valid. err. 3.17849
2018-02-03 20:40:42,481 training [INFO ] Epoch  5 Batch  880 Training err. 3.11489 Training err. RA 3.25016 Valid. err. 3.18600
2018-02-03 20:40:42,893 training [INFO ] Epoch  5 Batch  900 Training err. 3.07585 Training err. RA 3.24629 Valid. err. 3.18054
2018-02-03 20:40:43,305 training [INFO ] Epoch  5 Batch  920 Training err. 3.15622 Training err. RA 3.24433 Valid. err. 3.17679
2018-02-03 20:40:43,720 training [INFO ] Epoch  5 Batch  940 Training err. 3.08954 Training err. RA 3.24104 Valid. err. 3.17875
2018-02-03 20:40:44,131 training [INFO ] Epoch  5 Batch  960 Training err. 3.10909 Training err. RA 3.23829 Valid. err. 3.17754
2018-02-03 20:40:44,539 training [INFO ] Epoch  5 Batch  980 Training err. 3.14110 Training err. RA 3.23630 Valid. err. 3.17682
2018-02-03 20:40:44,951 training [INFO ] Epoch  5 Batch 1000 Training err. 3.12626 Training err. RA 3.23410 Valid. err. 3.17789
2018-02-03 20:40:45,361 training [INFO ] Epoch  5 Batch 1020 Training err. 3.13576 Training err. RA 3.23218 Valid. err. 3.17903
2018-02-03 20:40:45,772 training [INFO ] Epoch  5 Batch 1040 Training err. 3.16617 Training err. RA 3.23091 Valid. err. 3.17290
2018-02-03 20:40:46,537 training [INFO ] Epoch  6 Batch 1060 Training err. 3.13448 Training err. RA 3.22909 Valid. err. 3.17224
2018-02-03 20:40:46,960 training [INFO ] Epoch  6 Batch 1080 Training err. 3.12210 Training err. RA 3.22711 Valid. err. 3.17507
2018-02-03 20:40:47,371 training [INFO ] Epoch  6 Batch 1100 Training err. 3.06671 Training err. RA 3.22419 Valid. err. 3.18437
2018-02-03 20:40:47,785 training [INFO ] Epoch  6 Batch 1120 Training err. 3.13631 Training err. RA 3.22262 Valid. err. 3.17375
2018-02-03 20:40:48,356 training [INFO ] Epoch  6 Batch 1140 Training err. 3.11009 Training err. RA 3.22065 Valid. err. 3.17249
2018-02-03 20:40:48,840 training [INFO ] Epoch  6 Batch 1160 Training err. 3.06439 Training err. RA 3.21795 Valid. err. 3.17572
2018-02-03 20:40:49,259 training [INFO ] Epoch  6 Batch 1180 Training err. 3.14867 Training err. RA 3.21678 Valid. err. 3.17535
2018-02-03 20:40:49,685 training [INFO ] Epoch  6 Batch 1200 Training err. 3.12248 Training err. RA 3.21521 Valid. err. 3.17034
2018-02-03 20:40:50,172 training [INFO ] Epoch  6 Batch 1220 Training err. 3.12434 Training err. RA 3.21372 Valid. err. 3.17009
2018-02-03 20:40:50,586 training [INFO ] Epoch  6 Batch 1240 Training err. 3.14107 Training err. RA 3.21254 Valid. err. 3.16728
2018-02-03 20:40:51,356 training [INFO ] Epoch  7 Batch 1260 Training err. 3.13932 Training err. RA 3.21138 Valid. err. 3.16697
2018-02-03 20:40:51,776 training [INFO ] Epoch  7 Batch 1280 Training err. 3.12985 Training err. RA 3.21011 Valid. err. 3.16763
2018-02-03 20:40:52,203 training [INFO ] Epoch  7 Batch 1300 Training err. 3.08406 Training err. RA 3.20817 Valid. err. 3.17451
2018-02-03 20:40:52,630 training [INFO ] Epoch  7 Batch 1320 Training err. 3.08894 Training err. RA 3.20636 Valid. err. 3.16689
2018-02-03 20:40:53,051 training [INFO ] Epoch  7 Batch 1340 Training err. 3.12851 Training err. RA 3.20520 Valid. err. 3.16437
2018-02-03 20:40:53,475 training [INFO ] Epoch  7 Batch 1360 Training err. 3.06764 Training err. RA 3.20318 Valid. err. 3.16620
2018-02-03 20:40:53,899 training [INFO ] Epoch  7 Batch 1380 Training err. 3.11117 Training err. RA 3.20184 Valid. err. 3.16387
2018-02-03 20:40:54,322 training [INFO ] Epoch  7 Batch 1400 Training err. 3.11944 Training err. RA 3.20067 Valid. err. 3.16204
2018-02-03 20:40:54,747 training [INFO ] Epoch  7 Batch 1420 Training err. 3.11087 Training err. RA 3.19940 Valid. err. 3.16190
2018-02-03 20:40:55,209 training [INFO ] Epoch  7 Batch 1440 Training err. 3.12282 Training err. RA 3.19834 Valid. err. 3.15877
2018-02-03 20:40:56,062 training [INFO ] Epoch  8 Batch 1460 Training err. 3.15697 Training err. RA 3.19777 Valid. err. 3.16225
2018-02-03 20:40:56,515 training [INFO ] Epoch  8 Batch 1480 Training err. 3.11127 Training err. RA 3.19660 Valid. err. 3.16103
2018-02-03 20:40:57,015 training [INFO ] Epoch  8 Batch 1500 Training err. 3.10448 Training err. RA 3.19537 Valid. err. 3.15729
2018-02-03 20:40:57,486 training [INFO ] Epoch  8 Batch 1520 Training err. 3.03689 Training err. RA 3.19329 Valid. err. 3.16866
2018-02-03 20:40:58,003 training [INFO ] Epoch  8 Batch 1540 Training err. 3.13650 Training err. RA 3.19255 Valid. err. 3.15471
2018-02-03 20:40:58,459 training [INFO ] Epoch  8 Batch 1560 Training err. 3.07312 Training err. RA 3.19102 Valid. err. 3.15306
2018-02-03 20:40:58,887 training [INFO ] Epoch  8 Batch 1580 Training err. 3.06197 Training err. RA 3.18939 Valid. err. 3.15260
2018-02-03 20:40:59,315 training [INFO ] Epoch  8 Batch 1600 Training err. 3.12251 Training err. RA 3.18855 Valid. err. 3.14899
2018-02-03 20:40:59,745 training [INFO ] Epoch  8 Batch 1620 Training err. 3.10436 Training err. RA 3.18751 Valid. err. 3.14856
2018-02-03 20:41:00,176 training [INFO ] Epoch  8 Batch 1640 Training err. 3.09822 Training err. RA 3.18642 Valid. err. 3.14796
2018-02-03 20:41:00,597 training [INFO ] Epoch  8 Batch 1660 Training err. 3.13646 Training err. RA 3.18582 Valid. err. 3.14290
2018-02-03 20:41:01,395 training [INFO ] Epoch  9 Batch 1680 Training err. 3.10524 Training err. RA 3.18486 Valid. err. 3.13907
2018-02-03 20:41:01,928 training [INFO ] Epoch  9 Batch 1700 Training err. 3.08547 Training err. RA 3.18369 Valid. err. 3.13966
2018-02-03 20:41:02,391 training [INFO ] Epoch  9 Batch 1720 Training err. 3.05308 Training err. RA 3.18217 Valid. err. 3.14746
2018-02-03 20:41:02,863 training [INFO ] Epoch  9 Batch 1740 Training err. 3.09258 Training err. RA 3.18114 Valid. err. 3.13712
2018-02-03 20:41:03,360 training [INFO ] Epoch  9 Batch 1760 Training err. 3.08050 Training err. RA 3.18000 Valid. err. 3.13280
2018-02-03 20:41:03,814 training [INFO ] Epoch  9 Batch 1780 Training err. 3.03512 Training err. RA 3.17837 Valid. err. 3.13286
2018-02-03 20:41:04,231 training [INFO ] Epoch  9 Batch 1800 Training err. 3.09734 Training err. RA 3.17747 Valid. err. 3.12706
2018-02-03 20:41:04,656 training [INFO ] Epoch  9 Batch 1820 Training err. 3.07677 Training err. RA 3.17637 Valid. err. 3.12367
2018-02-03 20:41:05,082 training [INFO ] Epoch  9 Batch 1840 Training err. 3.07332 Training err. RA 3.17525 Valid. err. 3.12105
2018-02-03 20:41:05,539 training [INFO ] Epoch  9 Batch 1860 Training err. 3.09074 Training err. RA 3.17434 Valid. err. 3.11621
2018-02-03 20:41:06,390 training [INFO ] Epoch 10 Batch 1880 Training err. 3.10739 Training err. RA 3.17362 Valid. err. 3.11609
2018-02-03 20:41:06,843 training [INFO ] Epoch 10 Batch 1900 Training err. 3.07142 Training err. RA 3.17255 Valid. err. 3.10931
2018-02-03 20:41:07,300 training [INFO ] Epoch 10 Batch 1920 Training err. 3.04684 Training err. RA 3.17124 Valid. err. 3.11775
2018-02-03 20:41:07,945 training [INFO ] Epoch 10 Batch 1940 Training err. 3.03027 Training err. RA 3.16979 Valid. err. 3.10608
2018-02-03 20:41:08,409 training [INFO ] Epoch 10 Batch 1960 Training err. 3.08079 Training err. RA 3.16888 Valid. err. 3.09915
2018-02-03 20:41:08,835 training [INFO ] Epoch 10 Batch 1980 Training err. 3.00999 Training err. RA 3.16727 Valid. err. 3.09618
2018-02-03 20:41:09,271 training [INFO ] Epoch 10 Batch 2000 Training err. 3.03324 Training err. RA 3.16593 Valid. err. 3.09141
2018-02-03 20:41:09,754 training [INFO ] Epoch 10 Batch 2020 Training err. 3.05846 Training err. RA 3.16487 Valid. err. 3.08638
2018-02-03 20:41:10,202 training [INFO ] Epoch 10 Batch 2040 Training err. 3.03693 Training err. RA 3.16361 Valid. err. 3.08257
2018-02-03 20:41:10,672 training [INFO ] Epoch 10 Batch 2060 Training err. 3.05203 Training err. RA 3.16253 Valid. err. 3.07797
2018-02-03 20:41:11,105 training [INFO ] Epoch 10 Batch 2080 Training err. 3.06545 Training err. RA 3.16160 Valid. err. 3.06800
2018-02-03 20:41:11,861 training [INFO ] Epoch 11 Batch 2100 Training err. 3.04105 Training err. RA 3.16045 Valid. err. 3.06330
2018-02-03 20:41:12,263 training [INFO ] Epoch 11 Batch 2120 Training err. 3.01716 Training err. RA 3.15910 Valid. err. 3.06048
2018-02-03 20:41:12,670 training [INFO ] Epoch 11 Batch 2140 Training err. 2.99104 Training err. RA 3.15753 Valid. err. 3.07190
2018-02-03 20:41:13,077 training [INFO ] Epoch 11 Batch 2160 Training err. 3.03237 Training err. RA 3.15637 Valid. err. 3.05197
2018-02-03 20:41:13,492 training [INFO ] Epoch 11 Batch 2180 Training err. 2.98759 Training err. RA 3.15482 Valid. err. 3.04429
2018-02-03 20:41:13,901 training [INFO ] Epoch 11 Batch 2200 Training err. 2.94983 Training err. RA 3.15296 Valid. err. 3.04187
2018-02-03 20:41:14,301 training [INFO ] Epoch 11 Batch 2220 Training err. 3.02610 Training err. RA 3.15181 Valid. err. 3.04284
2018-02-03 20:41:14,711 training [INFO ] Epoch 11 Batch 2240 Training err. 2.97773 Training err. RA 3.15026 Valid. err. 3.02648
2018-02-03 20:41:15,118 training [INFO ] Epoch 11 Batch 2260 Training err. 2.99315 Training err. RA 3.14887 Valid. err. 3.02281
2018-02-03 20:41:15,535 training [INFO ] Epoch 11 Batch 2280 Training err. 3.00252 Training err. RA 3.14758 Valid. err. 3.01065
2018-02-03 20:41:16,272 training [INFO ] Epoch 12 Batch 2300 Training err. 3.00648 Training err. RA 3.14636 Valid. err. 3.00429
2018-02-03 20:41:16,673 training [INFO ] Epoch 12 Batch 2320 Training err. 2.97697 Training err. RA 3.14490 Valid. err. 2.99980
2018-02-03 20:41:17,080 training [INFO ] Epoch 12 Batch 2340 Training err. 2.93976 Training err. RA 3.14314 Valid. err. 3.00260
2018-02-03 20:41:17,508 training [INFO ] Epoch 12 Batch 2360 Training err. 2.95393 Training err. RA 3.14154 Valid. err. 2.99210
2018-02-03 20:41:17,934 training [INFO ] Epoch 12 Batch 2380 Training err. 2.95820 Training err. RA 3.14000 Valid. err. 2.98022
2018-02-03 20:41:18,352 training [INFO ] Epoch 12 Batch 2400 Training err. 2.88990 Training err. RA 3.13792 Valid. err. 2.97655
2018-02-03 20:41:18,773 training [INFO ] Epoch 12 Batch 2420 Training err. 2.93899 Training err. RA 3.13627 Valid. err. 2.96780
2018-02-03 20:41:19,195 training [INFO ] Epoch 12 Batch 2440 Training err. 2.93446 Training err. RA 3.13462 Valid. err. 2.95965
2018-02-03 20:41:19,615 training [INFO ] Epoch 12 Batch 2460 Training err. 2.92138 Training err. RA 3.13288 Valid. err. 2.95380
2018-02-03 20:41:20,041 training [INFO ] Epoch 12 Batch 2480 Training err. 2.93505 Training err. RA 3.13129 Valid. err. 2.94684
2018-02-03 20:41:20,810 training [INFO ] Epoch 13 Batch 2500 Training err. 2.96564 Training err. RA 3.12996 Valid. err. 2.94429
2018-02-03 20:41:21,221 training [INFO ] Epoch 13 Batch 2520 Training err. 2.91264 Training err. RA 3.12824 Valid. err. 2.94452
2018-02-03 20:41:21,627 training [INFO ] Epoch 13 Batch 2540 Training err. 2.88201 Training err. RA 3.12630 Valid. err. 2.93291
2018-02-03 20:41:22,042 training [INFO ] Epoch 13 Batch 2560 Training err. 2.86216 Training err. RA 3.12424 Valid. err. 2.94045
2018-02-03 20:41:22,451 training [INFO ] Epoch 13 Batch 2580 Training err. 2.91897 Training err. RA 3.12265 Valid. err. 2.91759
2018-02-03 20:41:22,853 training [INFO ] Epoch 13 Batch 2600 Training err. 2.84260 Training err. RA 3.12049 Valid. err. 2.91007
2018-02-03 20:41:23,263 training [INFO ] Epoch 13 Batch 2620 Training err. 2.83459 Training err. RA 3.11831 Valid. err. 2.90440
2018-02-03 20:41:23,671 training [INFO ] Epoch 13 Batch 2640 Training err. 2.88969 Training err. RA 3.11658 Valid. err. 2.89450
2018-02-03 20:41:24,088 training [INFO ] Epoch 13 Batch 2660 Training err. 2.85233 Training err. RA 3.11459 Valid. err. 2.88963
2018-02-03 20:41:24,498 training [INFO ] Epoch 13 Batch 2680 Training err. 2.86093 Training err. RA 3.11270 Valid. err. 2.89940
2018-02-03 20:41:24,901 training [INFO ] Epoch 13 Batch 2700 Training err. 2.89108 Training err. RA 3.11106 Valid. err. 2.87508
2018-02-03 20:41:25,651 training [INFO ] Epoch 14 Batch 2720 Training err. 2.85524 Training err. RA 3.10917 Valid. err. 2.87235
2018-02-03 20:41:26,059 training [INFO ] Epoch 14 Batch 2740 Training err. 2.82722 Training err. RA 3.10712 Valid. err. 2.86746
2018-02-03 20:41:26,470 training [INFO ] Epoch 14 Batch 2760 Training err. 2.79946 Training err. RA 3.10489 Valid. err. 2.86600
2018-02-03 20:41:26,864 training [INFO ] Epoch 14 Batch 2780 Training err. 2.84035 Training err. RA 3.10298 Valid. err. 2.85824
2018-02-03 20:41:27,261 training [INFO ] Epoch 14 Batch 2800 Training err. 2.81817 Training err. RA 3.10095 Valid. err. 2.84666
2018-02-03 20:41:27,665 training [INFO ] Epoch 14 Batch 2820 Training err. 2.75894 Training err. RA 3.09852 Valid. err. 2.85186
2018-02-03 20:41:28,069 training [INFO ] Epoch 14 Batch 2840 Training err. 2.82124 Training err. RA 3.09657 Valid. err. 2.83489
2018-02-03 20:41:28,467 training [INFO ] Epoch 14 Batch 2860 Training err. 2.79437 Training err. RA 3.09446 Valid. err. 2.83085
2018-02-03 20:41:28,859 training [INFO ] Epoch 14 Batch 2880 Training err. 2.79071 Training err. RA 3.09235 Valid. err. 2.81975
2018-02-03 20:41:29,260 training [INFO ] Epoch 14 Batch 2900 Training err. 2.80743 Training err. RA 3.09038 Valid. err. 2.81296
2018-02-03 20:41:30,022 training [INFO ] Epoch 15 Batch 2920 Training err. 2.81119 Training err. RA 3.08847 Valid. err. 2.81215
2018-02-03 20:41:30,438 training [INFO ] Epoch 15 Batch 2940 Training err. 2.78119 Training err. RA 3.08638 Valid. err. 2.80109
2018-02-03 20:41:30,845 training [INFO ] Epoch 15 Batch 2960 Training err. 2.75396 Training err. RA 3.08413 Valid. err. 2.82441
2018-02-03 20:41:31,258 training [INFO ] Epoch 15 Batch 2980 Training err. 2.71580 Training err. RA 3.08166 Valid. err. 2.79563
2018-02-03 20:41:31,671 training [INFO ] Epoch 15 Batch 3000 Training err. 2.79723 Training err. RA 3.07977 Valid. err. 2.78781
2018-02-03 20:41:32,091 training [INFO ] Epoch 15 Batch 3020 Training err. 2.70724 Training err. RA 3.07730 Valid. err. 2.78489
2018-02-03 20:41:32,509 training [INFO ] Epoch 15 Batch 3040 Training err. 2.72075 Training err. RA 3.07495 Valid. err. 2.77630
2018-02-03 20:41:32,926 training [INFO ] Epoch 15 Batch 3060 Training err. 2.76866 Training err. RA 3.07295 Valid. err. 2.77091
2018-02-03 20:41:33,322 training [INFO ] Epoch 15 Batch 3080 Training err. 2.71675 Training err. RA 3.07064 Valid. err. 2.76374
2018-02-03 20:41:33,722 training [INFO ] Epoch 15 Batch 3100 Training err. 2.74933 Training err. RA 3.06857 Valid. err. 2.76739
2018-02-03 20:41:34,117 training [INFO ] Epoch 15 Batch 3120 Training err. 2.76658 Training err. RA 3.06663 Valid. err. 2.75039
2018-02-03 20:41:34,857 training [INFO ] Epoch 16 Batch 3140 Training err. 2.73447 Training err. RA 3.06451 Valid. err. 2.74698
2018-02-03 20:41:35,250 training [INFO ] Epoch 16 Batch 3160 Training err. 2.71612 Training err. RA 3.06231 Valid. err. 2.74878
2018-02-03 20:41:35,651 training [INFO ] Epoch 16 Batch 3180 Training err. 2.65787 Training err. RA 3.05977 Valid. err. 2.79476
2018-02-03 20:41:36,051 training [INFO ] Epoch 16 Batch 3200 Training err. 2.72670 Training err. RA 3.05768 Valid. err. 2.74213
2018-02-03 20:41:36,450 training [INFO ] Epoch 16 Batch 3220 Training err. 2.69624 Training err. RA 3.05544 Valid. err. 2.74159
2018-02-03 20:41:36,843 training [INFO ] Epoch 16 Batch 3240 Training err. 2.63453 Training err. RA 3.05284 Valid. err. 2.73045
2018-02-03 20:41:37,243 training [INFO ] Epoch 16 Batch 3260 Training err. 2.72678 Training err. RA 3.05084 Valid. err. 2.76323
2018-02-03 20:41:37,658 training [INFO ] Epoch 16 Batch 3280 Training err. 2.68282 Training err. RA 3.04860 Valid. err. 2.71904
2018-02-03 20:41:38,079 training [INFO ] Epoch 16 Batch 3300 Training err. 2.69353 Training err. RA 3.04644 Valid. err. 2.72490
2018-02-03 20:41:38,493 training [INFO ] Epoch 16 Batch 3320 Training err. 2.70024 Training err. RA 3.04436 Valid. err. 2.70900
2018-02-03 20:41:39,248 training [INFO ] Epoch 17 Batch 3340 Training err. 2.69237 Training err. RA 3.04225 Valid. err. 2.71384
2018-02-03 20:41:39,654 training [INFO ] Epoch 17 Batch 3360 Training err. 2.69395 Training err. RA 3.04018 Valid. err. 2.69869
2018-02-03 20:41:40,075 training [INFO ] Epoch 17 Batch 3380 Training err. 2.63899 Training err. RA 3.03780 Valid. err. 2.69732
2018-02-03 20:41:40,488 training [INFO ] Epoch 17 Batch 3400 Training err. 2.63758 Training err. RA 3.03545 Valid. err. 2.69208
2018-02-03 20:41:40,894 training [INFO ] Epoch 17 Batch 3420 Training err. 2.69062 Training err. RA 3.03343 Valid. err. 2.68561
2018-02-03 20:41:41,295 training [INFO ] Epoch 17 Batch 3440 Training err. 2.60891 Training err. RA 3.03097 Valid. err. 2.68836
2018-02-03 20:41:41,702 training [INFO ] Epoch 17 Batch 3460 Training err. 2.64443 Training err. RA 3.02873 Valid. err. 2.67755
2018-02-03 20:41:42,106 training [INFO ] Epoch 17 Batch 3480 Training err. 2.66770 Training err. RA 3.02666 Valid. err. 2.67480
2018-02-03 20:41:42,528 training [INFO ] Epoch 17 Batch 3500 Training err. 2.63226 Training err. RA 3.02440 Valid. err. 2.66972
2018-02-03 20:41:42,936 training [INFO ] Epoch 17 Batch 3520 Training err. 2.65127 Training err. RA 3.02228 Valid. err. 2.66290
2018-02-03 20:41:43,682 training [INFO ] Epoch 18 Batch 3540 Training err. 2.68530 Training err. RA 3.02038 Valid. err. 2.65768
2018-02-03 20:41:44,087 training [INFO ] Epoch 18 Batch 3560 Training err. 2.64322 Training err. RA 3.01826 Valid. err. 2.65502
2018-02-03 20:41:44,497 training [INFO ] Epoch 18 Batch 3580 Training err. 2.63767 Training err. RA 3.01613 Valid. err. 2.65854
2018-02-03 20:41:44,902 training [INFO ] Epoch 18 Batch 3600 Training err. 2.54685 Training err. RA 3.01353 Valid. err. 2.68200
2018-02-03 20:41:45,337 training [INFO ] Epoch 18 Batch 3620 Training err. 2.66973 Training err. RA 3.01163 Valid. err. 2.64696
2018-02-03 20:41:45,768 training [INFO ] Epoch 18 Batch 3640 Training err. 2.59214 Training err. RA 3.00932 Valid. err. 2.64723
2018-02-03 20:41:46,184 training [INFO ] Epoch 18 Batch 3660 Training err. 2.57014 Training err. RA 3.00692 Valid. err. 2.64323
2018-02-03 20:41:46,612 training [INFO ] Epoch 18 Batch 3680 Training err. 2.65011 Training err. RA 3.00498 Valid. err. 2.64025
2018-02-03 20:41:47,075 training [INFO ] Epoch 18 Batch 3700 Training err. 2.59796 Training err. RA 3.00278 Valid. err. 2.63102
2018-02-03 20:41:47,574 training [INFO ] Epoch 18 Batch 3720 Training err. 2.60801 Training err. RA 3.00066 Valid. err. 2.66649
2018-02-03 20:41:48,010 training [INFO ] Epoch 18 Batch 3740 Training err. 2.64056 Training err. RA 2.99873 Valid. err. 2.63400
2018-02-03 20:41:48,924 training [INFO ] Epoch 19 Batch 3760 Training err. 2.60987 Training err. RA 2.99667 Valid. err. 2.63866
2018-02-03 20:41:49,418 training [INFO ] Epoch 19 Batch 3780 Training err. 2.60047 Training err. RA 2.99457 Valid. err. 2.63632
2018-02-03 20:41:49,892 training [INFO ] Epoch 19 Batch 3800 Training err. 2.55299 Training err. RA 2.99225 Valid. err. 2.62140
2018-02-03 20:41:50,331 training [INFO ] Epoch 19 Batch 3820 Training err. 2.58223 Training err. RA 2.99010 Valid. err. 2.62169
2018-02-03 20:41:50,768 training [INFO ] Epoch 19 Batch 3840 Training err. 2.60099 Training err. RA 2.98807 Valid. err. 2.61038
2018-02-03 20:41:51,257 training [INFO ] Epoch 19 Batch 3860 Training err. 2.54319 Training err. RA 2.98577 Valid. err. 2.61090
2018-02-03 20:41:51,915 training [INFO ] Epoch 19 Batch 3880 Training err. 2.59537 Training err. RA 2.98375 Valid. err. 2.61454
2018-02-03 20:41:52,337 training [INFO ] Epoch 19 Batch 3900 Training err. 2.56625 Training err. RA 2.98161 Valid. err. 2.61664
2018-02-03 20:41:52,763 training [INFO ] Epoch 19 Batch 3920 Training err. 2.56980 Training err. RA 2.97951 Valid. err. 2.59184
2018-02-03 20:41:53,182 training [INFO ] Epoch 19 Batch 3940 Training err. 2.58306 Training err. RA 2.97750 Valid. err. 2.58845
2018-02-03 20:41:53,998 training [INFO ] Epoch 20 Batch 3960 Training err. 2.58692 Training err. RA 2.97553 Valid. err. 2.59149
2018-02-03 20:41:54,428 training [INFO ] Epoch 20 Batch 3980 Training err. 2.58666 Training err. RA 2.97357 Valid. err. 2.58151
2018-02-03 20:41:54,880 training [INFO ] Epoch 20 Batch 4000 Training err. 2.55308 Training err. RA 2.97147 Valid. err. 2.59208
2018-02-03 20:41:55,356 training [INFO ] Epoch 20 Batch 4020 Training err. 2.49430 Training err. RA 2.96910 Valid. err. 2.58695
2018-02-03 20:41:55,792 training [INFO ] Epoch 20 Batch 4040 Training err. 2.59707 Training err. RA 2.96726 Valid. err. 2.57209
2018-02-03 20:41:56,229 training [INFO ] Epoch 20 Batch 4060 Training err. 2.51565 Training err. RA 2.96503 Valid. err. 2.59054
2018-02-03 20:41:56,653 training [INFO ] Epoch 20 Batch 4080 Training err. 2.53131 Training err. RA 2.96290 Valid. err. 2.56890
2018-02-03 20:41:57,074 training [INFO ] Epoch 20 Batch 4100 Training err. 2.56964 Training err. RA 2.96099 Valid. err. 2.56227
2018-02-03 20:41:57,489 training [INFO ] Epoch 20 Batch 4120 Training err. 2.51806 Training err. RA 2.95884 Valid. err. 2.56629
2018-02-03 20:41:58,113 training [INFO ] Epoch 20 Batch 4140 Training err. 2.55069 Training err. RA 2.95686 Valid. err. 2.56317
2018-02-03 20:41:58,528 training [INFO ] Epoch 20 Batch 4160 Training err. 2.56932 Training err. RA 2.95500 Valid. err. 2.54946
2018-02-03 20:41:58,806 __main__ [INFO ] End of training
2018-02-03 20:41:59,041 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 64,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:41:59,041 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:41:59,533 training [INFO ] Epoch  1 Batch   20 Training err. 3.63439 Training err. RA 3.63439 Valid. err. 3.26679
2018-02-03 20:41:59,986 training [INFO ] Epoch  1 Batch   40 Training err. 3.17670 Training err. RA 3.40554 Valid. err. 3.20674
2018-02-03 20:42:00,413 training [INFO ] Epoch  1 Batch   60 Training err. 3.12496 Training err. RA 3.31201 Valid. err. 3.28337
2018-02-03 20:42:00,823 training [INFO ] Epoch  1 Batch   80 Training err. 3.16651 Training err. RA 3.27564 Valid. err. 3.18450
2018-02-03 20:42:01,246 training [INFO ] Epoch  1 Batch  100 Training err. 3.12183 Training err. RA 3.24488 Valid. err. 3.18330
2018-02-03 20:42:01,699 training [INFO ] Epoch  1 Batch  120 Training err. 3.07591 Training err. RA 3.21671 Valid. err. 3.18733
2018-02-03 20:42:02,121 training [INFO ] Epoch  1 Batch  140 Training err. 3.15278 Training err. RA 3.20758 Valid. err. 3.22092
2018-02-03 20:42:02,526 training [INFO ] Epoch  1 Batch  160 Training err. 3.12301 Training err. RA 3.19701 Valid. err. 3.16062
2018-02-03 20:42:02,932 training [INFO ] Epoch  1 Batch  180 Training err. 3.12310 Training err. RA 3.18880 Valid. err. 3.15268
2018-02-03 20:42:03,333 training [INFO ] Epoch  1 Batch  200 Training err. 3.11659 Training err. RA 3.18158 Valid. err. 3.12673
2018-02-03 20:42:04,081 training [INFO ] Epoch  2 Batch  220 Training err. 3.09982 Training err. RA 3.17414 Valid. err. 3.10154
2018-02-03 20:42:04,485 training [INFO ] Epoch  2 Batch  240 Training err. 3.05758 Training err. RA 3.16443 Valid. err. 3.09701
2018-02-03 20:42:04,886 training [INFO ] Epoch  2 Batch  260 Training err. 2.99575 Training err. RA 3.15146 Valid. err. 3.06336
2018-02-03 20:42:05,289 training [INFO ] Epoch  2 Batch  280 Training err. 2.96300 Training err. RA 3.13799 Valid. err. 2.97253
2018-02-03 20:42:05,704 training [INFO ] Epoch  2 Batch  300 Training err. 2.93965 Training err. RA 3.12477 Valid. err. 2.96072
2018-02-03 20:42:06,136 training [INFO ] Epoch  2 Batch  320 Training err. 2.84371 Training err. RA 3.10721 Valid. err. 2.93000
2018-02-03 20:42:06,556 training [INFO ] Epoch  2 Batch  340 Training err. 2.84315 Training err. RA 3.09167 Valid. err. 2.83518
2018-02-03 20:42:06,978 training [INFO ] Epoch  2 Batch  360 Training err. 2.79877 Training err. RA 3.07540 Valid. err. 2.92191
2018-02-03 20:42:07,421 training [INFO ] Epoch  2 Batch  380 Training err. 2.78399 Training err. RA 3.06006 Valid. err. 2.76393
2018-02-03 20:42:07,845 training [INFO ] Epoch  2 Batch  400 Training err. 2.74764 Training err. RA 3.04444 Valid. err. 2.72474
2018-02-03 20:42:08,618 training [INFO ] Epoch  3 Batch  420 Training err. 2.74150 Training err. RA 3.03002 Valid. err. 2.69159
2018-02-03 20:42:09,038 training [INFO ] Epoch  3 Batch  440 Training err. 2.67987 Training err. RA 3.01410 Valid. err. 2.67018
2018-02-03 20:42:09,452 training [INFO ] Epoch  3 Batch  460 Training err. 2.65549 Training err. RA 2.99851 Valid. err. 2.63529
2018-02-03 20:42:09,866 training [INFO ] Epoch  3 Batch  480 Training err. 2.54806 Training err. RA 2.97974 Valid. err. 2.69130
2018-02-03 20:42:10,275 training [INFO ] Epoch  3 Batch  500 Training err. 2.63648 Training err. RA 2.96601 Valid. err. 2.60387
2018-02-03 20:42:10,688 training [INFO ] Epoch  3 Batch  520 Training err. 2.56073 Training err. RA 2.95042 Valid. err. 2.57227
2018-02-03 20:42:11,098 training [INFO ] Epoch  3 Batch  540 Training err. 2.49591 Training err. RA 2.93359 Valid. err. 2.54593
2018-02-03 20:42:11,509 training [INFO ] Epoch  3 Batch  560 Training err. 2.56641 Training err. RA 2.92048 Valid. err. 2.54667
2018-02-03 20:42:11,940 training [INFO ] Epoch  3 Batch  580 Training err. 2.49571 Training err. RA 2.90583 Valid. err. 2.51798
2018-02-03 20:42:12,351 training [INFO ] Epoch  3 Batch  600 Training err. 2.48517 Training err. RA 2.89181 Valid. err. 2.50117
2018-02-03 20:42:12,760 training [INFO ] Epoch  3 Batch  620 Training err. 2.51845 Training err. RA 2.87976 Valid. err. 2.47953
2018-02-03 20:42:13,542 training [INFO ] Epoch  4 Batch  640 Training err. 2.46678 Training err. RA 2.86686 Valid. err. 2.49393
2018-02-03 20:42:13,964 training [INFO ] Epoch  4 Batch  660 Training err. 2.45378 Training err. RA 2.85434 Valid. err. 2.45589
2018-02-03 20:42:14,384 training [INFO ] Epoch  4 Batch  680 Training err. 2.37494 Training err. RA 2.84024 Valid. err. 2.54487
2018-02-03 20:42:14,806 training [INFO ] Epoch  4 Batch  700 Training err. 2.40181 Training err. RA 2.82771 Valid. err. 2.42229
2018-02-03 20:42:15,229 training [INFO ] Epoch  4 Batch  720 Training err. 2.42166 Training err. RA 2.81643 Valid. err. 2.44172
2018-02-03 20:42:15,647 training [INFO ] Epoch  4 Batch  740 Training err. 2.34252 Training err. RA 2.80363 Valid. err. 2.48597
2018-02-03 20:42:16,061 training [INFO ] Epoch  4 Batch  760 Training err. 2.39211 Training err. RA 2.79280 Valid. err. 2.37126
2018-02-03 20:42:16,480 training [INFO ] Epoch  4 Batch  780 Training err. 2.33291 Training err. RA 2.78100 Valid. err. 2.37951
2018-02-03 20:42:16,896 training [INFO ] Epoch  4 Batch  800 Training err. 2.33254 Training err. RA 2.76979 Valid. err. 2.33730
2018-02-03 20:42:17,304 training [INFO ] Epoch  4 Batch  820 Training err. 2.32741 Training err. RA 2.75900 Valid. err. 2.33137
2018-02-03 20:42:18,053 training [INFO ] Epoch  5 Batch  840 Training err. 2.32116 Training err. RA 2.74858 Valid. err. 2.31677
2018-02-03 20:42:18,458 training [INFO ] Epoch  5 Batch  860 Training err. 2.34870 Training err. RA 2.73928 Valid. err. 2.32497
2018-02-03 20:42:18,859 training [INFO ] Epoch  5 Batch  880 Training err. 2.28146 Training err. RA 2.72887 Valid. err. 2.31835
2018-02-03 20:42:19,262 training [INFO ] Epoch  5 Batch  900 Training err. 2.23426 Training err. RA 2.71788 Valid. err. 2.30840
2018-02-03 20:42:19,666 training [INFO ] Epoch  5 Batch  920 Training err. 2.30305 Training err. RA 2.70886 Valid. err. 2.35187
2018-02-03 20:42:20,069 training [INFO ] Epoch  5 Batch  940 Training err. 2.23314 Training err. RA 2.69874 Valid. err. 2.27633
2018-02-03 20:42:20,472 training [INFO ] Epoch  5 Batch  960 Training err. 2.25982 Training err. RA 2.68960 Valid. err. 2.30384
2018-02-03 20:42:20,870 training [INFO ] Epoch  5 Batch  980 Training err. 2.26070 Training err. RA 2.68084 Valid. err. 2.25290
2018-02-03 20:42:21,277 training [INFO ] Epoch  5 Batch 1000 Training err. 2.20786 Training err. RA 2.67138 Valid. err. 2.24942
2018-02-03 20:42:21,697 training [INFO ] Epoch  5 Batch 1020 Training err. 2.20506 Training err. RA 2.66224 Valid. err. 2.23428
2018-02-03 20:42:22,120 training [INFO ] Epoch  5 Batch 1040 Training err. 2.23687 Training err. RA 2.65406 Valid. err. 2.22372
2018-02-03 20:42:22,898 training [INFO ] Epoch  6 Batch 1060 Training err. 2.26579 Training err. RA 2.64673 Valid. err. 2.22706
2018-02-03 20:42:23,313 training [INFO ] Epoch  6 Batch 1080 Training err. 2.21675 Training err. RA 2.63877 Valid. err. 2.21544
2018-02-03 20:42:23,730 training [INFO ] Epoch  6 Batch 1100 Training err. 2.14403 Training err. RA 2.62978 Valid. err. 2.26808
2018-02-03 20:42:24,157 training [INFO ] Epoch  6 Batch 1120 Training err. 2.16299 Training err. RA 2.62144 Valid. err. 2.22556
2018-02-03 20:42:24,580 training [INFO ] Epoch  6 Batch 1140 Training err. 2.19129 Training err. RA 2.61390 Valid. err. 2.20725
2018-02-03 20:42:25,003 training [INFO ] Epoch  6 Batch 1160 Training err. 2.13156 Training err. RA 2.60558 Valid. err. 2.18918
2018-02-03 20:42:25,415 training [INFO ] Epoch  6 Batch 1180 Training err. 2.19366 Training err. RA 2.59860 Valid. err. 2.20293
2018-02-03 20:42:25,825 training [INFO ] Epoch  6 Batch 1200 Training err. 2.13926 Training err. RA 2.59094 Valid. err. 2.18374
2018-02-03 20:42:26,237 training [INFO ] Epoch  6 Batch 1220 Training err. 2.14356 Training err. RA 2.58361 Valid. err. 2.21570
2018-02-03 20:42:26,649 training [INFO ] Epoch  6 Batch 1240 Training err. 2.13477 Training err. RA 2.57637 Valid. err. 2.17824
2018-02-03 20:42:27,407 training [INFO ] Epoch  7 Batch 1260 Training err. 2.13129 Training err. RA 2.56930 Valid. err. 2.19322
2018-02-03 20:42:27,805 training [INFO ] Epoch  7 Batch 1280 Training err. 2.18870 Training err. RA 2.56336 Valid. err. 2.14008
2018-02-03 20:42:28,207 training [INFO ] Epoch  7 Batch 1300 Training err. 2.09466 Training err. RA 2.55615 Valid. err. 2.14661
2018-02-03 20:42:28,621 training [INFO ] Epoch  7 Batch 1320 Training err. 2.08403 Training err. RA 2.54899 Valid. err. 2.13304
2018-02-03 20:42:29,039 training [INFO ] Epoch  7 Batch 1340 Training err. 2.12335 Training err. RA 2.54264 Valid. err. 2.17116
2018-02-03 20:42:29,453 training [INFO ] Epoch  7 Batch 1360 Training err. 2.07209 Training err. RA 2.53572 Valid. err. 2.12642
2018-02-03 20:42:29,878 training [INFO ] Epoch  7 Batch 1380 Training err. 2.11570 Training err. RA 2.52963 Valid. err. 2.12745
2018-02-03 20:42:30,299 training [INFO ] Epoch  7 Batch 1400 Training err. 2.08452 Training err. RA 2.52327 Valid. err. 2.12030
2018-02-03 20:42:30,728 training [INFO ] Epoch  7 Batch 1420 Training err. 2.08712 Training err. RA 2.51713 Valid. err. 2.09495
2018-02-03 20:42:31,153 training [INFO ] Epoch  7 Batch 1440 Training err. 2.06082 Training err. RA 2.51079 Valid. err. 2.11445
2018-02-03 20:42:31,963 training [INFO ] Epoch  8 Batch 1460 Training err. 2.09107 Training err. RA 2.50504 Valid. err. 2.09219
2018-02-03 20:42:32,391 training [INFO ] Epoch  8 Batch 1480 Training err. 2.11687 Training err. RA 2.49980 Valid. err. 2.08302
2018-02-03 20:42:32,817 training [INFO ] Epoch  8 Batch 1500 Training err. 2.07174 Training err. RA 2.49409 Valid. err. 2.09469
2018-02-03 20:42:33,270 training [INFO ] Epoch  8 Batch 1520 Training err. 1.98822 Training err. RA 2.48743 Valid. err. 2.08971
2018-02-03 20:42:33,684 training [INFO ] Epoch  8 Batch 1540 Training err. 2.05993 Training err. RA 2.48188 Valid. err. 2.08790
2018-02-03 20:42:34,094 training [INFO ] Epoch  8 Batch 1560 Training err. 2.03903 Training err. RA 2.47620 Valid. err. 2.08489
2018-02-03 20:42:34,506 training [INFO ] Epoch  8 Batch 1580 Training err. 2.01949 Training err. RA 2.47042 Valid. err. 2.05578
2018-02-03 20:42:34,909 training [INFO ] Epoch  8 Batch 1600 Training err. 2.07288 Training err. RA 2.46545 Valid. err. 2.06887
2018-02-03 20:42:35,310 training [INFO ] Epoch  8 Batch 1620 Training err. 2.01810 Training err. RA 2.45993 Valid. err. 2.06383
2018-02-03 20:42:35,706 training [INFO ] Epoch  8 Batch 1640 Training err. 2.01158 Training err. RA 2.45446 Valid. err. 2.04671
2018-02-03 20:42:36,110 training [INFO ] Epoch  8 Batch 1660 Training err. 2.02842 Training err. RA 2.44933 Valid. err. 2.03688
2018-02-03 20:42:36,868 training [INFO ] Epoch  9 Batch 1680 Training err. 2.03091 Training err. RA 2.44435 Valid. err. 2.08527
2018-02-03 20:42:37,266 training [INFO ] Epoch  9 Batch 1700 Training err. 2.05198 Training err. RA 2.43973 Valid. err. 2.05058
2018-02-03 20:42:37,679 training [INFO ] Epoch  9 Batch 1720 Training err. 1.96989 Training err. RA 2.43427 Valid. err. 2.05273
2018-02-03 20:42:38,093 training [INFO ] Epoch  9 Batch 1740 Training err. 1.97283 Training err. RA 2.42897 Valid. err. 2.04161
2018-02-03 20:42:38,506 training [INFO ] Epoch  9 Batch 1760 Training err. 2.01704 Training err. RA 2.42428 Valid. err. 2.04126
2018-02-03 20:42:38,921 training [INFO ] Epoch  9 Batch 1780 Training err. 1.96515 Training err. RA 2.41913 Valid. err. 2.04593
2018-02-03 20:42:39,339 training [INFO ] Epoch  9 Batch 1800 Training err. 2.04141 Training err. RA 2.41493 Valid. err. 2.03748
2018-02-03 20:42:39,752 training [INFO ] Epoch  9 Batch 1820 Training err. 1.96050 Training err. RA 2.40994 Valid. err. 2.01525
2018-02-03 20:42:40,169 training [INFO ] Epoch  9 Batch 1840 Training err. 1.98314 Training err. RA 2.40530 Valid. err. 1.99622
2018-02-03 20:42:40,585 training [INFO ] Epoch  9 Batch 1860 Training err. 1.95922 Training err. RA 2.40050 Valid. err. 1.98759
2018-02-03 20:42:41,348 training [INFO ] Epoch 10 Batch 1880 Training err. 1.97834 Training err. RA 2.39601 Valid. err. 1.98297
2018-02-03 20:42:41,745 training [INFO ] Epoch 10 Batch 1900 Training err. 2.01882 Training err. RA 2.39204 Valid. err. 2.02145
2018-02-03 20:42:42,148 training [INFO ] Epoch 10 Batch 1920 Training err. 1.95506 Training err. RA 2.38749 Valid. err. 1.99750
2018-02-03 20:42:42,545 training [INFO ] Epoch 10 Batch 1940 Training err. 1.90762 Training err. RA 2.38254 Valid. err. 2.00512
2018-02-03 20:42:42,944 training [INFO ] Epoch 10 Batch 1960 Training err. 1.97469 Training err. RA 2.37838 Valid. err. 1.97724
2018-02-03 20:42:43,345 training [INFO ] Epoch 10 Batch 1980 Training err. 1.92788 Training err. RA 2.37383 Valid. err. 1.99129
2018-02-03 20:42:43,741 training [INFO ] Epoch 10 Batch 2000 Training err. 1.96269 Training err. RA 2.36972 Valid. err. 2.07021
2018-02-03 20:42:44,142 training [INFO ] Epoch 10 Batch 2020 Training err. 1.96273 Training err. RA 2.36569 Valid. err. 1.96890
2018-02-03 20:42:44,543 training [INFO ] Epoch 10 Batch 2040 Training err. 1.92920 Training err. RA 2.36141 Valid. err. 1.98026
2018-02-03 20:42:44,941 training [INFO ] Epoch 10 Batch 2060 Training err. 1.92398 Training err. RA 2.35716 Valid. err. 1.95369
2018-02-03 20:42:45,340 training [INFO ] Epoch 10 Batch 2080 Training err. 1.94196 Training err. RA 2.35317 Valid. err. 1.96452
2018-02-03 20:42:46,108 training [INFO ] Epoch 11 Batch 2100 Training err. 2.01003 Training err. RA 2.34990 Valid. err. 1.96627
2018-02-03 20:42:46,523 training [INFO ] Epoch 11 Batch 2120 Training err. 1.94605 Training err. RA 2.34609 Valid. err. 1.95857
2018-02-03 20:42:46,936 training [INFO ] Epoch 11 Batch 2140 Training err. 1.88037 Training err. RA 2.34174 Valid. err. 1.98261
2018-02-03 20:42:47,352 training [INFO ] Epoch 11 Batch 2160 Training err. 1.88291 Training err. RA 2.33749 Valid. err. 1.97235
2018-02-03 20:42:47,766 training [INFO ] Epoch 11 Batch 2180 Training err. 1.93117 Training err. RA 2.33376 Valid. err. 1.99225
2018-02-03 20:42:48,184 training [INFO ] Epoch 11 Batch 2200 Training err. 1.88120 Training err. RA 2.32965 Valid. err. 1.95557
2018-02-03 20:42:48,600 training [INFO ] Epoch 11 Batch 2220 Training err. 1.95146 Training err. RA 2.32624 Valid. err. 1.94232
2018-02-03 20:42:49,016 training [INFO ] Epoch 11 Batch 2240 Training err. 1.88993 Training err. RA 2.32234 Valid. err. 1.93117
2018-02-03 20:42:49,419 training [INFO ] Epoch 11 Batch 2260 Training err. 1.90963 Training err. RA 2.31869 Valid. err. 1.95644
2018-02-03 20:42:49,818 training [INFO ] Epoch 11 Batch 2280 Training err. 1.89069 Training err. RA 2.31494 Valid. err. 1.91593
2018-02-03 20:42:50,551 training [INFO ] Epoch 12 Batch 2300 Training err. 1.89837 Training err. RA 2.31132 Valid. err. 1.92574
2018-02-03 20:42:50,950 training [INFO ] Epoch 12 Batch 2320 Training err. 1.94220 Training err. RA 2.30813 Valid. err. 1.91701
2018-02-03 20:42:51,351 training [INFO ] Epoch 12 Batch 2340 Training err. 1.87003 Training err. RA 2.30439 Valid. err. 1.92686
2018-02-03 20:42:51,747 training [INFO ] Epoch 12 Batch 2360 Training err. 1.85608 Training err. RA 2.30059 Valid. err. 1.93198
2018-02-03 20:42:52,149 training [INFO ] Epoch 12 Batch 2380 Training err. 1.89362 Training err. RA 2.29717 Valid. err. 1.93952
2018-02-03 20:42:52,552 training [INFO ] Epoch 12 Batch 2400 Training err. 1.85252 Training err. RA 2.29346 Valid. err. 1.92088
2018-02-03 20:42:52,952 training [INFO ] Epoch 12 Batch 2420 Training err. 1.90415 Training err. RA 2.29025 Valid. err. 1.91665
2018-02-03 20:42:53,352 training [INFO ] Epoch 12 Batch 2440 Training err. 1.87485 Training err. RA 2.28684 Valid. err. 1.90714
2018-02-03 20:42:53,783 training [INFO ] Epoch 12 Batch 2460 Training err. 1.87897 Training err. RA 2.28353 Valid. err. 1.89473
2018-02-03 20:42:54,201 training [INFO ] Epoch 12 Batch 2480 Training err. 1.85807 Training err. RA 2.28009 Valid. err. 1.91272
2018-02-03 20:42:55,097 training [INFO ] Epoch 13 Batch 2500 Training err. 1.88707 Training err. RA 2.27695 Valid. err. 1.89387
2018-02-03 20:42:55,582 training [INFO ] Epoch 13 Batch 2520 Training err. 1.90048 Training err. RA 2.27396 Valid. err. 1.88782
2018-02-03 20:42:56,026 training [INFO ] Epoch 13 Batch 2540 Training err. 1.86592 Training err. RA 2.27075 Valid. err. 1.90744
2018-02-03 20:42:56,456 training [INFO ] Epoch 13 Batch 2560 Training err. 1.80668 Training err. RA 2.26712 Valid. err. 1.90062
2018-02-03 20:42:56,893 training [INFO ] Epoch 13 Batch 2580 Training err. 1.85887 Training err. RA 2.26396 Valid. err. 1.91488
2018-02-03 20:42:57,323 training [INFO ] Epoch 13 Batch 2600 Training err. 1.83935 Training err. RA 2.26069 Valid. err. 1.91141
2018-02-03 20:42:57,733 training [INFO ] Epoch 13 Batch 2620 Training err. 1.83136 Training err. RA 2.25742 Valid. err. 1.88872
2018-02-03 20:42:58,155 training [INFO ] Epoch 13 Batch 2640 Training err. 1.89117 Training err. RA 2.25464 Valid. err. 1.89489
2018-02-03 20:42:58,598 training [INFO ] Epoch 13 Batch 2660 Training err. 1.83492 Training err. RA 2.25149 Valid. err. 1.89036
2018-02-03 20:42:59,016 training [INFO ] Epoch 13 Batch 2680 Training err. 1.83629 Training err. RA 2.24839 Valid. err. 1.87483
2018-02-03 20:42:59,433 training [INFO ] Epoch 13 Batch 2700 Training err. 1.84517 Training err. RA 2.24540 Valid. err. 1.86606
2018-02-03 20:43:00,277 training [INFO ] Epoch 14 Batch 2720 Training err. 1.85373 Training err. RA 2.24252 Valid. err. 1.89374
2018-02-03 20:43:00,697 training [INFO ] Epoch 14 Batch 2740 Training err. 1.86269 Training err. RA 2.23975 Valid. err. 1.87410
2018-02-03 20:43:01,158 training [INFO ] Epoch 14 Batch 2760 Training err. 1.80007 Training err. RA 2.23656 Valid. err. 1.88434
2018-02-03 20:43:01,639 training [INFO ] Epoch 14 Batch 2780 Training err. 1.80224 Training err. RA 2.23344 Valid. err. 1.89240
2018-02-03 20:43:02,057 training [INFO ] Epoch 14 Batch 2800 Training err. 1.84864 Training err. RA 2.23069 Valid. err. 1.87877
2018-02-03 20:43:02,510 training [INFO ] Epoch 14 Batch 2820 Training err. 1.79772 Training err. RA 2.22762 Valid. err. 1.85695
2018-02-03 20:43:02,976 training [INFO ] Epoch 14 Batch 2840 Training err. 1.86862 Training err. RA 2.22509 Valid. err. 1.87796
2018-02-03 20:43:03,413 training [INFO ] Epoch 14 Batch 2860 Training err. 1.80097 Training err. RA 2.22212 Valid. err. 1.84570
2018-02-03 20:43:03,910 training [INFO ] Epoch 14 Batch 2880 Training err. 1.82321 Training err. RA 2.21935 Valid. err. 1.85385
2018-02-03 20:43:04,428 training [INFO ] Epoch 14 Batch 2900 Training err. 1.80234 Training err. RA 2.21648 Valid. err. 1.83887
2018-02-03 20:43:05,227 training [INFO ] Epoch 15 Batch 2920 Training err. 1.82206 Training err. RA 2.21378 Valid. err. 1.84453
2018-02-03 20:43:05,643 training [INFO ] Epoch 15 Batch 2940 Training err. 1.85037 Training err. RA 2.21130 Valid. err. 1.85596
2018-02-03 20:43:06,060 training [INFO ] Epoch 15 Batch 2960 Training err. 1.79521 Training err. RA 2.20849 Valid. err. 1.86553
2018-02-03 20:43:06,478 training [INFO ] Epoch 15 Batch 2980 Training err. 1.76351 Training err. RA 2.20551 Valid. err. 1.86480
2018-02-03 20:43:06,895 training [INFO ] Epoch 15 Batch 3000 Training err. 1.82513 Training err. RA 2.20297 Valid. err. 1.85133
2018-02-03 20:43:07,313 training [INFO ] Epoch 15 Batch 3020 Training err. 1.77692 Training err. RA 2.20015 Valid. err. 1.85639
2018-02-03 20:43:07,731 training [INFO ] Epoch 15 Batch 3040 Training err. 1.81079 Training err. RA 2.19759 Valid. err. 1.86772
2018-02-03 20:43:08,147 training [INFO ] Epoch 15 Batch 3060 Training err. 1.81197 Training err. RA 2.19507 Valid. err. 1.83312
2018-02-03 20:43:08,566 training [INFO ] Epoch 15 Batch 3080 Training err. 1.78991 Training err. RA 2.19244 Valid. err. 1.84588
2018-02-03 20:43:08,989 training [INFO ] Epoch 15 Batch 3100 Training err. 1.78430 Training err. RA 2.18980 Valid. err. 1.82206
2018-02-03 20:43:09,406 training [INFO ] Epoch 15 Batch 3120 Training err. 1.80457 Training err. RA 2.18733 Valid. err. 1.83266
2018-02-03 20:43:10,144 training [INFO ] Epoch 16 Batch 3140 Training err. 1.83576 Training err. RA 2.18509 Valid. err. 1.82945
2018-02-03 20:43:10,544 training [INFO ] Epoch 16 Batch 3160 Training err. 1.79613 Training err. RA 2.18263 Valid. err. 1.82499
2018-02-03 20:43:10,943 training [INFO ] Epoch 16 Batch 3180 Training err. 1.74492 Training err. RA 2.17988 Valid. err. 1.85848
2018-02-03 20:43:11,348 training [INFO ] Epoch 16 Batch 3200 Training err. 1.75065 Training err. RA 2.17720 Valid. err. 1.83776
2018-02-03 20:43:11,762 training [INFO ] Epoch 16 Batch 3220 Training err. 1.79694 Training err. RA 2.17483 Valid. err. 1.84254
2018-02-03 20:43:12,188 training [INFO ] Epoch 16 Batch 3240 Training err. 1.75030 Training err. RA 2.17221 Valid. err. 1.83846
2018-02-03 20:43:12,664 training [INFO ] Epoch 16 Batch 3260 Training err. 1.81451 Training err. RA 2.17002 Valid. err. 1.82086
2018-02-03 20:43:13,146 training [INFO ] Epoch 16 Batch 3280 Training err. 1.75709 Training err. RA 2.16750 Valid. err. 1.80479
2018-02-03 20:43:13,580 training [INFO ] Epoch 16 Batch 3300 Training err. 1.78761 Training err. RA 2.16520 Valid. err. 1.82814
2018-02-03 20:43:14,018 training [INFO ] Epoch 16 Batch 3320 Training err. 1.76262 Training err. RA 2.16277 Valid. err. 1.80187
2018-02-03 20:43:14,885 training [INFO ] Epoch 17 Batch 3340 Training err. 1.76561 Training err. RA 2.16040 Valid. err. 1.80802
2018-02-03 20:43:15,310 training [INFO ] Epoch 17 Batch 3360 Training err. 1.80631 Training err. RA 2.15829 Valid. err. 1.80314
2018-02-03 20:43:15,732 training [INFO ] Epoch 17 Batch 3380 Training err. 1.74160 Training err. RA 2.15582 Valid. err. 1.81682
2018-02-03 20:43:16,147 training [INFO ] Epoch 17 Batch 3400 Training err. 1.73625 Training err. RA 2.15335 Valid. err. 1.82376
2018-02-03 20:43:16,562 training [INFO ] Epoch 17 Batch 3420 Training err. 1.77382 Training err. RA 2.15114 Valid. err. 1.82431
2018-02-03 20:43:16,976 training [INFO ] Epoch 17 Batch 3440 Training err. 1.73169 Training err. RA 2.14870 Valid. err. 1.81513
2018-02-03 20:43:17,384 training [INFO ] Epoch 17 Batch 3460 Training err. 1.77733 Training err. RA 2.14655 Valid. err. 1.80443
2018-02-03 20:43:17,790 training [INFO ] Epoch 17 Batch 3480 Training err. 1.75331 Training err. RA 2.14429 Valid. err. 1.80418
2018-02-03 20:43:18,200 training [INFO ] Epoch 17 Batch 3500 Training err. 1.76536 Training err. RA 2.14212 Valid. err. 1.80032
2018-02-03 20:43:18,607 training [INFO ] Epoch 17 Batch 3520 Training err. 1.74104 Training err. RA 2.13985 Valid. err. 1.80335
2018-02-03 20:43:19,464 training [INFO ] Epoch 18 Batch 3540 Training err. 1.76737 Training err. RA 2.13774 Valid. err. 1.80286
2018-02-03 20:43:19,900 training [INFO ] Epoch 18 Batch 3560 Training err. 1.77669 Training err. RA 2.13571 Valid. err. 1.78774
2018-02-03 20:43:20,372 training [INFO ] Epoch 18 Batch 3580 Training err. 1.74507 Training err. RA 2.13353 Valid. err. 1.79646
2018-02-03 20:43:20,838 training [INFO ] Epoch 18 Batch 3600 Training err. 1.69776 Training err. RA 2.13111 Valid. err. 1.80484
2018-02-03 20:43:21,250 training [INFO ] Epoch 18 Batch 3620 Training err. 1.74252 Training err. RA 2.12896 Valid. err. 1.81711
2018-02-03 20:43:21,691 training [INFO ] Epoch 18 Batch 3640 Training err. 1.72977 Training err. RA 2.12677 Valid. err. 1.81541
2018-02-03 20:43:22,165 training [INFO ] Epoch 18 Batch 3660 Training err. 1.72111 Training err. RA 2.12455 Valid. err. 1.78390
2018-02-03 20:43:22,647 training [INFO ] Epoch 18 Batch 3680 Training err. 1.77590 Training err. RA 2.12266 Valid. err. 1.79017
2018-02-03 20:43:23,122 training [INFO ] Epoch 18 Batch 3700 Training err. 1.72708 Training err. RA 2.12052 Valid. err. 1.78636
2018-02-03 20:43:23,584 training [INFO ] Epoch 18 Batch 3720 Training err. 1.73174 Training err. RA 2.11843 Valid. err. 1.79651
2018-02-03 20:43:24,077 training [INFO ] Epoch 18 Batch 3740 Training err. 1.73405 Training err. RA 2.11637 Valid. err. 1.77306
2018-02-03 20:43:24,970 training [INFO ] Epoch 19 Batch 3760 Training err. 1.73928 Training err. RA 2.11437 Valid. err. 1.78959
2018-02-03 20:43:25,431 training [INFO ] Epoch 19 Batch 3780 Training err. 1.75205 Training err. RA 2.11245 Valid. err. 1.77987
2018-02-03 20:43:25,894 training [INFO ] Epoch 19 Batch 3800 Training err. 1.69358 Training err. RA 2.11025 Valid. err. 1.78865
2018-02-03 20:43:26,375 training [INFO ] Epoch 19 Batch 3820 Training err. 1.69585 Training err. RA 2.10808 Valid. err. 1.79592
2018-02-03 20:43:26,830 training [INFO ] Epoch 19 Batch 3840 Training err. 1.74563 Training err. RA 2.10619 Valid. err. 1.77703
2018-02-03 20:43:27,242 training [INFO ] Epoch 19 Batch 3860 Training err. 1.69748 Training err. RA 2.10407 Valid. err. 1.77681
2018-02-03 20:43:27,654 training [INFO ] Epoch 19 Batch 3880 Training err. 1.76272 Training err. RA 2.10231 Valid. err. 1.78880
2018-02-03 20:43:28,066 training [INFO ] Epoch 19 Batch 3900 Training err. 1.69750 Training err. RA 2.10024 Valid. err. 1.76640
2018-02-03 20:43:28,482 training [INFO ] Epoch 19 Batch 3920 Training err. 1.72736 Training err. RA 2.09833 Valid. err. 1.77666
2018-02-03 20:43:28,891 training [INFO ] Epoch 19 Batch 3940 Training err. 1.69983 Training err. RA 2.09631 Valid. err. 1.75712
2018-02-03 20:43:29,650 training [INFO ] Epoch 20 Batch 3960 Training err. 1.71776 Training err. RA 2.09440 Valid. err. 1.76424
2018-02-03 20:43:30,071 training [INFO ] Epoch 20 Batch 3980 Training err. 1.74284 Training err. RA 2.09263 Valid. err. 1.77123
2018-02-03 20:43:30,495 training [INFO ] Epoch 20 Batch 4000 Training err. 1.69517 Training err. RA 2.09065 Valid. err. 1.78636
2018-02-03 20:43:30,917 training [INFO ] Epoch 20 Batch 4020 Training err. 1.66722 Training err. RA 2.08854 Valid. err. 1.77816
2018-02-03 20:43:31,340 training [INFO ] Epoch 20 Batch 4040 Training err. 1.72200 Training err. RA 2.08672 Valid. err. 1.77144
2018-02-03 20:43:31,762 training [INFO ] Epoch 20 Batch 4060 Training err. 1.68410 Training err. RA 2.08474 Valid. err. 1.78041
2018-02-03 20:43:32,182 training [INFO ] Epoch 20 Batch 4080 Training err. 1.71305 Training err. RA 2.08292 Valid. err. 1.78529
2018-02-03 20:43:32,606 training [INFO ] Epoch 20 Batch 4100 Training err. 1.71587 Training err. RA 2.08113 Valid. err. 1.75845
2018-02-03 20:43:33,028 training [INFO ] Epoch 20 Batch 4120 Training err. 1.69801 Training err. RA 2.07927 Valid. err. 1.76539
2018-02-03 20:43:33,442 training [INFO ] Epoch 20 Batch 4140 Training err. 1.69190 Training err. RA 2.07740 Valid. err. 1.74929
2018-02-03 20:43:33,850 training [INFO ] Epoch 20 Batch 4160 Training err. 1.70804 Training err. RA 2.07562 Valid. err. 1.75123
2018-02-03 20:43:34,119 __main__ [INFO ] End of training
2018-02-03 20:43:34,354 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:43:34,354 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:43:35,009 training [INFO ] Epoch  1 Batch   20 Training err. 4.21831 Training err. RA 4.21831 Valid. err. 4.14288
2018-02-03 20:43:35,504 training [INFO ] Epoch  1 Batch   40 Training err. 4.04405 Training err. RA 4.13118 Valid. err. 3.97780
2018-02-03 20:43:36,007 training [INFO ] Epoch  1 Batch   60 Training err. 3.87347 Training err. RA 4.04528 Valid. err. 3.79967
2018-02-03 20:43:36,504 training [INFO ] Epoch  1 Batch   80 Training err. 3.71535 Training err. RA 3.96279 Valid. err. 3.64281
2018-02-03 20:43:36,997 training [INFO ] Epoch  1 Batch  100 Training err. 3.56003 Training err. RA 3.88224 Valid. err. 3.52350
2018-02-03 20:43:37,809 training [INFO ] Epoch  2 Batch  120 Training err. 3.44372 Training err. RA 3.80916 Valid. err. 3.42780
2018-02-03 20:43:38,333 training [INFO ] Epoch  2 Batch  140 Training err. 3.32111 Training err. RA 3.73943 Valid. err. 3.35926
2018-02-03 20:43:38,829 training [INFO ] Epoch  2 Batch  160 Training err. 3.29113 Training err. RA 3.68340 Valid. err. 3.30437
2018-02-03 20:43:39,321 training [INFO ] Epoch  2 Batch  180 Training err. 3.25436 Training err. RA 3.63573 Valid. err. 3.27186
2018-02-03 20:43:39,813 training [INFO ] Epoch  2 Batch  200 Training err. 3.22798 Training err. RA 3.59495 Valid. err. 3.25065
2018-02-03 20:43:40,695 training [INFO ] Epoch  3 Batch  220 Training err. 3.22134 Training err. RA 3.56099 Valid. err. 3.23623
2018-02-03 20:43:41,189 training [INFO ] Epoch  3 Batch  240 Training err. 3.15023 Training err. RA 3.52676 Valid. err. 3.23335
2018-02-03 20:43:41,699 training [INFO ] Epoch  3 Batch  260 Training err. 3.18581 Training err. RA 3.50053 Valid. err. 3.21552
2018-02-03 20:43:42,208 training [INFO ] Epoch  3 Batch  280 Training err. 3.16066 Training err. RA 3.47625 Valid. err. 3.20856
2018-02-03 20:43:42,716 training [INFO ] Epoch  3 Batch  300 Training err. 3.16589 Training err. RA 3.45556 Valid. err. 3.20382
2018-02-03 20:43:43,589 training [INFO ] Epoch  4 Batch  320 Training err. 3.18150 Training err. RA 3.43843 Valid. err. 3.19848
2018-02-03 20:43:44,099 training [INFO ] Epoch  4 Batch  340 Training err. 3.12992 Training err. RA 3.42029 Valid. err. 3.20145
2018-02-03 20:43:44,612 training [INFO ] Epoch  4 Batch  360 Training err. 3.15011 Training err. RA 3.40528 Valid. err. 3.19301
2018-02-03 20:43:45,121 training [INFO ] Epoch  4 Batch  380 Training err. 3.13373 Training err. RA 3.39098 Valid. err. 3.19048
2018-02-03 20:43:45,612 training [INFO ] Epoch  4 Batch  400 Training err. 3.14281 Training err. RA 3.37858 Valid. err. 3.18943
2018-02-03 20:43:46,492 training [INFO ] Epoch  5 Batch  420 Training err. 3.16887 Training err. RA 3.36859 Valid. err. 3.18878
2018-02-03 20:43:46,989 training [INFO ] Epoch  5 Batch  440 Training err. 3.13743 Training err. RA 3.35808 Valid. err. 3.18875
2018-02-03 20:43:47,484 training [INFO ] Epoch  5 Batch  460 Training err. 3.12850 Training err. RA 3.34810 Valid. err. 3.18461
2018-02-03 20:43:47,991 training [INFO ] Epoch  5 Batch  480 Training err. 3.11084 Training err. RA 3.33821 Valid. err. 3.18408
2018-02-03 20:43:48,488 training [INFO ] Epoch  5 Batch  500 Training err. 3.14386 Training err. RA 3.33044 Valid. err. 3.18395
2018-02-03 20:43:48,983 training [INFO ] Epoch  5 Batch  520 Training err. 3.16351 Training err. RA 3.32402 Valid. err. 3.18120
2018-02-03 20:43:49,840 training [INFO ] Epoch  6 Batch  540 Training err. 3.13932 Training err. RA 3.31718 Valid. err. 3.18179
2018-02-03 20:43:50,355 training [INFO ] Epoch  6 Batch  560 Training err. 3.11438 Training err. RA 3.30994 Valid. err. 3.18180
2018-02-03 20:43:50,868 training [INFO ] Epoch  6 Batch  580 Training err. 3.09980 Training err. RA 3.30269 Valid. err. 3.18244
2018-02-03 20:43:51,383 training [INFO ] Epoch  6 Batch  600 Training err. 3.14844 Training err. RA 3.29755 Valid. err. 3.17968
2018-02-03 20:43:51,897 training [INFO ] Epoch  6 Batch  620 Training err. 3.14670 Training err. RA 3.29268 Valid. err. 3.17846
2018-02-03 20:43:52,838 training [INFO ] Epoch  7 Batch  640 Training err. 3.14939 Training err. RA 3.28820 Valid. err. 3.17863
2018-02-03 20:43:53,344 training [INFO ] Epoch  7 Batch  660 Training err. 3.10172 Training err. RA 3.28255 Valid. err. 3.17996
2018-02-03 20:43:53,835 training [INFO ] Epoch  7 Batch  680 Training err. 3.11569 Training err. RA 3.27765 Valid. err. 3.17853
2018-02-03 20:43:54,326 training [INFO ] Epoch  7 Batch  700 Training err. 3.13276 Training err. RA 3.27351 Valid. err. 3.17740
2018-02-03 20:43:54,824 training [INFO ] Epoch  7 Batch  720 Training err. 3.13524 Training err. RA 3.26967 Valid. err. 3.17689
2018-02-03 20:43:55,655 training [INFO ] Epoch  8 Batch  740 Training err. 3.15573 Training err. RA 3.26659 Valid. err. 3.17687
2018-02-03 20:43:56,148 training [INFO ] Epoch  8 Batch  760 Training err. 3.09095 Training err. RA 3.26196 Valid. err. 3.18701
2018-02-03 20:43:56,642 training [INFO ] Epoch  8 Batch  780 Training err. 3.13178 Training err. RA 3.25863 Valid. err. 3.17596
2018-02-03 20:43:57,133 training [INFO ] Epoch  8 Batch  800 Training err. 3.11862 Training err. RA 3.25513 Valid. err. 3.17541
2018-02-03 20:43:57,630 training [INFO ] Epoch  8 Batch  820 Training err. 3.13068 Training err. RA 3.25209 Valid. err. 3.17597
2018-02-03 20:43:58,569 training [INFO ] Epoch  9 Batch  840 Training err. 3.15361 Training err. RA 3.24975 Valid. err. 3.17341
2018-02-03 20:43:59,080 training [INFO ] Epoch  9 Batch  860 Training err. 3.10374 Training err. RA 3.24635 Valid. err. 3.18071
2018-02-03 20:43:59,594 training [INFO ] Epoch  9 Batch  880 Training err. 3.12453 Training err. RA 3.24358 Valid. err. 3.17370
2018-02-03 20:44:00,112 training [INFO ] Epoch  9 Batch  900 Training err. 3.11028 Training err. RA 3.24062 Valid. err. 3.17316
2018-02-03 20:44:00,620 training [INFO ] Epoch  9 Batch  920 Training err. 3.12338 Training err. RA 3.23807 Valid. err. 3.17349
2018-02-03 20:44:01,469 training [INFO ] Epoch 10 Batch  940 Training err. 3.15137 Training err. RA 3.23623 Valid. err. 3.17391
2018-02-03 20:44:01,958 training [INFO ] Epoch 10 Batch  960 Training err. 3.12009 Training err. RA 3.23381 Valid. err. 3.17525
2018-02-03 20:44:02,445 training [INFO ] Epoch 10 Batch  980 Training err. 3.11182 Training err. RA 3.23132 Valid. err. 3.17110
2018-02-03 20:44:02,934 training [INFO ] Epoch 10 Batch 1000 Training err. 3.09437 Training err. RA 3.22858 Valid. err. 3.17114
2018-02-03 20:44:03,421 training [INFO ] Epoch 10 Batch 1020 Training err. 3.12842 Training err. RA 3.22661 Valid. err. 3.17154
2018-02-03 20:44:03,908 training [INFO ] Epoch 10 Batch 1040 Training err. 3.14820 Training err. RA 3.22511 Valid. err. 3.16887
2018-02-03 20:44:04,828 training [INFO ] Epoch 11 Batch 1060 Training err. 3.12581 Training err. RA 3.22323 Valid. err. 3.16964
2018-02-03 20:44:05,320 training [INFO ] Epoch 11 Batch 1080 Training err. 3.10061 Training err. RA 3.22096 Valid. err. 3.16980
2018-02-03 20:44:05,831 training [INFO ] Epoch 11 Batch 1100 Training err. 3.08539 Training err. RA 3.21850 Valid. err. 3.17056
2018-02-03 20:44:06,347 training [INFO ] Epoch 11 Batch 1120 Training err. 3.13386 Training err. RA 3.21699 Valid. err. 3.16766
2018-02-03 20:44:06,860 training [INFO ] Epoch 11 Batch 1140 Training err. 3.13295 Training err. RA 3.21551 Valid. err. 3.16630
2018-02-03 20:44:07,732 training [INFO ] Epoch 12 Batch 1160 Training err. 3.13614 Training err. RA 3.21414 Valid. err. 3.16627
2018-02-03 20:44:08,245 training [INFO ] Epoch 12 Batch 1180 Training err. 3.08883 Training err. RA 3.21202 Valid. err. 3.16736
2018-02-03 20:44:08,756 training [INFO ] Epoch 12 Batch 1200 Training err. 3.10085 Training err. RA 3.21017 Valid. err. 3.16587
2018-02-03 20:44:09,264 training [INFO ] Epoch 12 Batch 1220 Training err. 3.11894 Training err. RA 3.20867 Valid. err. 3.16444
2018-02-03 20:44:09,758 training [INFO ] Epoch 12 Batch 1240 Training err. 3.12110 Training err. RA 3.20726 Valid. err. 3.16350
2018-02-03 20:44:10,689 training [INFO ] Epoch 13 Batch 1260 Training err. 3.14168 Training err. RA 3.20622 Valid. err. 3.16341
2018-02-03 20:44:11,189 training [INFO ] Epoch 13 Batch 1280 Training err. 3.07783 Training err. RA 3.20421 Valid. err. 3.17358
2018-02-03 20:44:11,687 training [INFO ] Epoch 13 Batch 1300 Training err. 3.11562 Training err. RA 3.20285 Valid. err. 3.16160
2018-02-03 20:44:12,186 training [INFO ] Epoch 13 Batch 1320 Training err. 3.10370 Training err. RA 3.20135 Valid. err. 3.16056
2018-02-03 20:44:12,683 training [INFO ] Epoch 13 Batch 1340 Training err. 3.11474 Training err. RA 3.20005 Valid. err. 3.16066
2018-02-03 20:44:13,527 training [INFO ] Epoch 14 Batch 1360 Training err. 3.13788 Training err. RA 3.19914 Valid. err. 3.15743
2018-02-03 20:44:14,024 training [INFO ] Epoch 14 Batch 1380 Training err. 3.08842 Training err. RA 3.19753 Valid. err. 3.16471
2018-02-03 20:44:14,522 training [INFO ] Epoch 14 Batch 1400 Training err. 3.10806 Training err. RA 3.19626 Valid. err. 3.15672
2018-02-03 20:44:15,014 training [INFO ] Epoch 14 Batch 1420 Training err. 3.09261 Training err. RA 3.19480 Valid. err. 3.15554
2018-02-03 20:44:15,505 training [INFO ] Epoch 14 Batch 1440 Training err. 3.10527 Training err. RA 3.19355 Valid. err. 3.15504
2018-02-03 20:44:16,423 training [INFO ] Epoch 15 Batch 1460 Training err. 3.13341 Training err. RA 3.19273 Valid. err. 3.15501
2018-02-03 20:44:16,909 training [INFO ] Epoch 15 Batch 1480 Training err. 3.10060 Training err. RA 3.19148 Valid. err. 3.15610
2018-02-03 20:44:17,397 training [INFO ] Epoch 15 Batch 1500 Training err. 3.09429 Training err. RA 3.19019 Valid. err. 3.15037
2018-02-03 20:44:17,886 training [INFO ] Epoch 15 Batch 1520 Training err. 3.07348 Training err. RA 3.18865 Valid. err. 3.14936
2018-02-03 20:44:18,372 training [INFO ] Epoch 15 Batch 1540 Training err. 3.10646 Training err. RA 3.18759 Valid. err. 3.14889
2018-02-03 20:44:18,858 training [INFO ] Epoch 15 Batch 1560 Training err. 3.12545 Training err. RA 3.18679 Valid. err. 3.14497
2018-02-03 20:44:19,694 training [INFO ] Epoch 16 Batch 1580 Training err. 3.10257 Training err. RA 3.18572 Valid. err. 3.14450
2018-02-03 20:44:20,185 training [INFO ] Epoch 16 Batch 1600 Training err. 3.08033 Training err. RA 3.18441 Valid. err. 3.14384
2018-02-03 20:44:20,676 training [INFO ] Epoch 16 Batch 1620 Training err. 3.05950 Training err. RA 3.18286 Valid. err. 3.14334
2018-02-03 20:44:21,169 training [INFO ] Epoch 16 Batch 1640 Training err. 3.10566 Training err. RA 3.18192 Valid. err. 3.13862
2018-02-03 20:44:21,680 training [INFO ] Epoch 16 Batch 1660 Training err. 3.10523 Training err. RA 3.18100 Valid. err. 3.13570
2018-02-03 20:44:22,547 training [INFO ] Epoch 17 Batch 1680 Training err. 3.10755 Training err. RA 3.18012 Valid. err. 3.13405
2018-02-03 20:44:23,054 training [INFO ] Epoch 17 Batch 1700 Training err. 3.06334 Training err. RA 3.17875 Valid. err. 3.13369
2018-02-03 20:44:23,563 training [INFO ] Epoch 17 Batch 1720 Training err. 3.06639 Training err. RA 3.17744 Valid. err. 3.13063
2018-02-03 20:44:24,077 training [INFO ] Epoch 17 Batch 1740 Training err. 3.08514 Training err. RA 3.17638 Valid. err. 3.12694
2018-02-03 20:44:24,587 training [INFO ] Epoch 17 Batch 1760 Training err. 3.08574 Training err. RA 3.17535 Valid. err. 3.12352
2018-02-03 20:44:25,434 training [INFO ] Epoch 18 Batch 1780 Training err. 3.10541 Training err. RA 3.17457 Valid. err. 3.12335
2018-02-03 20:44:25,928 training [INFO ] Epoch 18 Batch 1800 Training err. 3.04513 Training err. RA 3.17313 Valid. err. 3.13106
2018-02-03 20:44:26,420 training [INFO ] Epoch 18 Batch 1820 Training err. 3.07091 Training err. RA 3.17200 Valid. err. 3.11544
2018-02-03 20:44:26,913 training [INFO ] Epoch 18 Batch 1840 Training err. 3.06056 Training err. RA 3.17079 Valid. err. 3.11139
2018-02-03 20:44:27,408 training [INFO ] Epoch 18 Batch 1860 Training err. 3.06684 Training err. RA 3.16968 Valid. err. 3.10931
2018-02-03 20:44:28,259 training [INFO ] Epoch 19 Batch 1880 Training err. 3.09125 Training err. RA 3.16884 Valid. err. 3.10266
2018-02-03 20:44:28,752 training [INFO ] Epoch 19 Batch 1900 Training err. 3.04147 Training err. RA 3.16750 Valid. err. 3.10842
2018-02-03 20:44:29,249 training [INFO ] Epoch 19 Batch 1920 Training err. 3.05739 Training err. RA 3.16635 Valid. err. 3.09662
2018-02-03 20:44:29,745 training [INFO ] Epoch 19 Batch 1940 Training err. 3.03484 Training err. RA 3.16500 Valid. err. 3.09210
2018-02-03 20:44:30,237 training [INFO ] Epoch 19 Batch 1960 Training err. 3.04456 Training err. RA 3.16377 Valid. err. 3.08779
2018-02-03 20:44:31,056 training [INFO ] Epoch 20 Batch 1980 Training err. 3.07377 Training err. RA 3.16286 Valid. err. 3.08469
2018-02-03 20:44:31,555 training [INFO ] Epoch 20 Batch 2000 Training err. 3.03387 Training err. RA 3.16157 Valid. err. 3.08612
2018-02-03 20:44:32,054 training [INFO ] Epoch 20 Batch 2020 Training err. 3.03534 Training err. RA 3.16032 Valid. err. 3.07341
2018-02-03 20:44:32,549 training [INFO ] Epoch 20 Batch 2040 Training err. 3.00017 Training err. RA 3.15875 Valid. err. 3.06804
2018-02-03 20:44:33,045 training [INFO ] Epoch 20 Batch 2060 Training err. 3.02874 Training err. RA 3.15749 Valid. err. 3.06296
2018-02-03 20:44:33,541 training [INFO ] Epoch 20 Batch 2080 Training err. 3.04534 Training err. RA 3.15641 Valid. err. 3.05485
2018-02-03 20:44:33,786 __main__ [INFO ] End of training
2018-02-03 20:44:34,011 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:44:34,011 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 20:44:34,622 training [INFO ] Epoch  1 Batch   20 Training err. 3.62631 Training err. RA 3.62631 Valid. err. 3.25300
2018-02-03 20:44:35,118 training [INFO ] Epoch  1 Batch   40 Training err. 3.17181 Training err. RA 3.39906 Valid. err. 3.19779
2018-02-03 20:44:35,614 training [INFO ] Epoch  1 Batch   60 Training err. 3.14277 Training err. RA 3.31363 Valid. err. 3.33592
2018-02-03 20:44:36,110 training [INFO ] Epoch  1 Batch   80 Training err. 3.16449 Training err. RA 3.27634 Valid. err. 3.18570
2018-02-03 20:44:36,604 training [INFO ] Epoch  1 Batch  100 Training err. 3.14944 Training err. RA 3.25096 Valid. err. 3.17327
2018-02-03 20:44:37,430 training [INFO ] Epoch  2 Batch  120 Training err. 3.15263 Training err. RA 3.23457 Valid. err. 3.18141
2018-02-03 20:44:37,926 training [INFO ] Epoch  2 Batch  140 Training err. 3.10283 Training err. RA 3.21575 Valid. err. 3.16783
2018-02-03 20:44:38,419 training [INFO ] Epoch  2 Batch  160 Training err. 3.09729 Training err. RA 3.20095 Valid. err. 3.16925
2018-02-03 20:44:38,914 training [INFO ] Epoch  2 Batch  180 Training err. 3.12992 Training err. RA 3.19305 Valid. err. 3.14944
2018-02-03 20:44:39,407 training [INFO ] Epoch  2 Batch  200 Training err. 3.10152 Training err. RA 3.18390 Valid. err. 3.13550
2018-02-03 20:44:40,260 training [INFO ] Epoch  3 Batch  220 Training err. 3.10990 Training err. RA 3.17717 Valid. err. 3.16555
2018-02-03 20:44:40,755 training [INFO ] Epoch  3 Batch  240 Training err. 3.03259 Training err. RA 3.16512 Valid. err. 3.12761
2018-02-03 20:44:41,249 training [INFO ] Epoch  3 Batch  260 Training err. 3.05252 Training err. RA 3.15646 Valid. err. 3.07108
2018-02-03 20:44:41,740 training [INFO ] Epoch  3 Batch  280 Training err. 3.01833 Training err. RA 3.14660 Valid. err. 3.01644
2018-02-03 20:44:42,234 training [INFO ] Epoch  3 Batch  300 Training err. 2.96444 Training err. RA 3.13445 Valid. err. 2.96586
2018-02-03 20:44:43,057 training [INFO ] Epoch  4 Batch  320 Training err. 2.94899 Training err. RA 3.12286 Valid. err. 2.91592
2018-02-03 20:44:43,557 training [INFO ] Epoch  4 Batch  340 Training err. 2.87012 Training err. RA 3.10799 Valid. err. 2.89437
2018-02-03 20:44:44,057 training [INFO ] Epoch  4 Batch  360 Training err. 2.84467 Training err. RA 3.09336 Valid. err. 2.87495
2018-02-03 20:44:44,558 training [INFO ] Epoch  4 Batch  380 Training err. 2.77406 Training err. RA 3.07656 Valid. err. 2.78498
2018-02-03 20:44:45,054 training [INFO ] Epoch  4 Batch  400 Training err. 2.73166 Training err. RA 3.05931 Valid. err. 2.86048
2018-02-03 20:44:45,913 training [INFO ] Epoch  5 Batch  420 Training err. 2.76430 Training err. RA 3.04526 Valid. err. 2.72785
2018-02-03 20:44:46,423 training [INFO ] Epoch  5 Batch  440 Training err. 2.67556 Training err. RA 3.02846 Valid. err. 2.71009
2018-02-03 20:44:46,933 training [INFO ] Epoch  5 Batch  460 Training err. 2.64846 Training err. RA 3.01194 Valid. err. 2.65693
2018-02-03 20:44:47,440 training [INFO ] Epoch  5 Batch  480 Training err. 2.58242 Training err. RA 2.99404 Valid. err. 2.63250
2018-02-03 20:44:47,957 training [INFO ] Epoch  5 Batch  500 Training err. 2.59856 Training err. RA 2.97822 Valid. err. 2.59998
2018-02-03 20:44:48,468 training [INFO ] Epoch  5 Batch  520 Training err. 2.59753 Training err. RA 2.96358 Valid. err. 2.58939
2018-02-03 20:44:49,313 training [INFO ] Epoch  6 Batch  540 Training err. 2.56419 Training err. RA 2.94879 Valid. err. 2.56643
2018-02-03 20:44:49,813 training [INFO ] Epoch  6 Batch  560 Training err. 2.50101 Training err. RA 2.93280 Valid. err. 2.53921
2018-02-03 20:44:50,309 training [INFO ] Epoch  6 Batch  580 Training err. 2.49104 Training err. RA 2.91756 Valid. err. 2.50840
2018-02-03 20:44:50,801 training [INFO ] Epoch  6 Batch  600 Training err. 2.49029 Training err. RA 2.90332 Valid. err. 2.52217
2018-02-03 20:44:51,297 training [INFO ] Epoch  6 Batch  620 Training err. 2.47704 Training err. RA 2.88957 Valid. err. 2.48637
2018-02-03 20:44:52,146 training [INFO ] Epoch  7 Batch  640 Training err. 2.46355 Training err. RA 2.87626 Valid. err. 2.50631
2018-02-03 20:44:52,644 training [INFO ] Epoch  7 Batch  660 Training err. 2.39755 Training err. RA 2.86175 Valid. err. 2.50752
2018-02-03 20:44:53,141 training [INFO ] Epoch  7 Batch  680 Training err. 2.41281 Training err. RA 2.84855 Valid. err. 2.43280
2018-02-03 20:44:53,638 training [INFO ] Epoch  7 Batch  700 Training err. 2.38478 Training err. RA 2.83530 Valid. err. 2.49866
2018-02-03 20:44:54,133 training [INFO ] Epoch  7 Batch  720 Training err. 2.38558 Training err. RA 2.82280 Valid. err. 2.40613
2018-02-03 20:44:54,962 training [INFO ] Epoch  8 Batch  740 Training err. 2.38949 Training err. RA 2.81109 Valid. err. 2.39469
2018-02-03 20:44:55,458 training [INFO ] Epoch  8 Batch  760 Training err. 2.30663 Training err. RA 2.79782 Valid. err. 2.35987
2018-02-03 20:44:55,952 training [INFO ] Epoch  8 Batch  780 Training err. 2.34946 Training err. RA 2.78632 Valid. err. 2.34887
2018-02-03 20:44:56,449 training [INFO ] Epoch  8 Batch  800 Training err. 2.30476 Training err. RA 2.77428 Valid. err. 2.36343
2018-02-03 20:44:56,945 training [INFO ] Epoch  8 Batch  820 Training err. 2.29801 Training err. RA 2.76267 Valid. err. 2.32087
2018-02-03 20:44:57,797 training [INFO ] Epoch  9 Batch  840 Training err. 2.31397 Training err. RA 2.75198 Valid. err. 2.31985
2018-02-03 20:44:58,295 training [INFO ] Epoch  9 Batch  860 Training err. 2.26855 Training err. RA 2.74074 Valid. err. 2.30772
2018-02-03 20:44:58,794 training [INFO ] Epoch  9 Batch  880 Training err. 2.27336 Training err. RA 2.73012 Valid. err. 2.30075
2018-02-03 20:44:59,291 training [INFO ] Epoch  9 Batch  900 Training err. 2.24184 Training err. RA 2.71927 Valid. err. 2.31262
2018-02-03 20:44:59,788 training [INFO ] Epoch  9 Batch  920 Training err. 2.23088 Training err. RA 2.70865 Valid. err. 2.27104
2018-02-03 20:45:00,619 training [INFO ] Epoch 10 Batch  940 Training err. 2.24426 Training err. RA 2.69877 Valid. err. 2.30345
2018-02-03 20:45:01,114 training [INFO ] Epoch 10 Batch  960 Training err. 2.23494 Training err. RA 2.68911 Valid. err. 2.25242
2018-02-03 20:45:01,619 training [INFO ] Epoch 10 Batch  980 Training err. 2.19498 Training err. RA 2.67902 Valid. err. 2.22564
2018-02-03 20:45:02,130 training [INFO ] Epoch 10 Batch 1000 Training err. 2.20529 Training err. RA 2.66955 Valid. err. 2.20987
2018-02-03 20:45:02,640 training [INFO ] Epoch 10 Batch 1020 Training err. 2.18205 Training err. RA 2.65999 Valid. err. 2.21820
2018-02-03 20:45:03,155 training [INFO ] Epoch 10 Batch 1040 Training err. 2.19239 Training err. RA 2.65100 Valid. err. 2.21260
2018-02-03 20:45:04,023 training [INFO ] Epoch 11 Batch 1060 Training err. 2.20578 Training err. RA 2.64260 Valid. err. 2.19300
2018-02-03 20:45:04,533 training [INFO ] Epoch 11 Batch 1080 Training err. 2.12699 Training err. RA 2.63305 Valid. err. 2.23357
2018-02-03 20:45:05,043 training [INFO ] Epoch 11 Batch 1100 Training err. 2.16275 Training err. RA 2.62450 Valid. err. 2.18320
2018-02-03 20:45:05,546 training [INFO ] Epoch 11 Batch 1120 Training err. 2.15296 Training err. RA 2.61608 Valid. err. 2.17919
2018-02-03 20:45:06,050 training [INFO ] Epoch 11 Batch 1140 Training err. 2.13569 Training err. RA 2.60765 Valid. err. 2.21486
2018-02-03 20:45:06,874 training [INFO ] Epoch 12 Batch 1160 Training err. 2.24056 Training err. RA 2.60132 Valid. err. 2.17607
2018-02-03 20:45:07,370 training [INFO ] Epoch 12 Batch 1180 Training err. 2.09476 Training err. RA 2.59273 Valid. err. 2.17165
2018-02-03 20:45:07,871 training [INFO ] Epoch 12 Batch 1200 Training err. 2.11186 Training err. RA 2.58472 Valid. err. 2.17944
2018-02-03 20:45:08,367 training [INFO ] Epoch 12 Batch 1220 Training err. 2.12768 Training err. RA 2.57723 Valid. err. 2.17108
2018-02-03 20:45:08,860 training [INFO ] Epoch 12 Batch 1240 Training err. 2.09600 Training err. RA 2.56946 Valid. err. 2.13604
2018-02-03 20:45:09,717 training [INFO ] Epoch 13 Batch 1260 Training err. 2.13771 Training err. RA 2.56261 Valid. err. 2.13971
2018-02-03 20:45:10,232 training [INFO ] Epoch 13 Batch 1280 Training err. 2.06588 Training err. RA 2.55485 Valid. err. 2.14250
2018-02-03 20:45:10,748 training [INFO ] Epoch 13 Batch 1300 Training err. 2.09023 Training err. RA 2.54770 Valid. err. 2.18107
2018-02-03 20:45:11,261 training [INFO ] Epoch 13 Batch 1320 Training err. 2.09325 Training err. RA 2.54082 Valid. err. 2.11554
2018-02-03 20:45:11,776 training [INFO ] Epoch 13 Batch 1340 Training err. 2.05749 Training err. RA 2.53360 Valid. err. 2.09683
2018-02-03 20:45:12,631 training [INFO ] Epoch 14 Batch 1360 Training err. 2.08874 Training err. RA 2.52706 Valid. err. 2.09122
2018-02-03 20:45:13,147 training [INFO ] Epoch 14 Batch 1380 Training err. 2.06412 Training err. RA 2.52035 Valid. err. 2.11335
2018-02-03 20:45:13,644 training [INFO ] Epoch 14 Batch 1400 Training err. 2.04987 Training err. RA 2.51363 Valid. err. 2.08536
2018-02-03 20:45:14,137 training [INFO ] Epoch 14 Batch 1420 Training err. 2.06073 Training err. RA 2.50725 Valid. err. 2.09626
2018-02-03 20:45:14,632 training [INFO ] Epoch 14 Batch 1440 Training err. 2.03887 Training err. RA 2.50075 Valid. err. 2.09305
2018-02-03 20:45:15,475 training [INFO ] Epoch 15 Batch 1460 Training err. 2.03822 Training err. RA 2.49441 Valid. err. 2.09719
2018-02-03 20:45:15,968 training [INFO ] Epoch 15 Batch 1480 Training err. 2.05791 Training err. RA 2.48851 Valid. err. 2.07228
2018-02-03 20:45:16,461 training [INFO ] Epoch 15 Batch 1500 Training err. 2.00694 Training err. RA 2.48209 Valid. err. 2.11003
2018-02-03 20:45:16,955 training [INFO ] Epoch 15 Batch 1520 Training err. 2.02566 Training err. RA 2.47608 Valid. err. 2.05803
2018-02-03 20:45:17,450 training [INFO ] Epoch 15 Batch 1540 Training err. 2.01903 Training err. RA 2.47015 Valid. err. 2.05974
2018-02-03 20:45:17,948 training [INFO ] Epoch 15 Batch 1560 Training err. 2.01408 Training err. RA 2.46430 Valid. err. 2.04364
2018-02-03 20:45:18,770 training [INFO ] Epoch 16 Batch 1580 Training err. 2.05480 Training err. RA 2.45912 Valid. err. 2.03637
2018-02-03 20:45:19,266 training [INFO ] Epoch 16 Batch 1600 Training err. 1.96344 Training err. RA 2.45292 Valid. err. 2.06313
2018-02-03 20:45:19,764 training [INFO ] Epoch 16 Batch 1620 Training err. 1.99173 Training err. RA 2.44723 Valid. err. 2.04816
2018-02-03 20:45:20,262 training [INFO ] Epoch 16 Batch 1640 Training err. 2.00461 Training err. RA 2.44183 Valid. err. 2.04821
2018-02-03 20:45:20,759 training [INFO ] Epoch 16 Batch 1660 Training err. 1.98083 Training err. RA 2.43628 Valid. err. 2.06787
2018-02-03 20:45:21,616 training [INFO ] Epoch 17 Batch 1680 Training err. 2.02500 Training err. RA 2.43138 Valid. err. 2.01607
2018-02-03 20:45:22,133 training [INFO ] Epoch 17 Batch 1700 Training err. 1.95126 Training err. RA 2.42573 Valid. err. 2.01913
2018-02-03 20:45:22,648 training [INFO ] Epoch 17 Batch 1720 Training err. 1.96992 Training err. RA 2.42043 Valid. err. 2.03471
2018-02-03 20:45:23,158 training [INFO ] Epoch 17 Batch 1740 Training err. 1.97987 Training err. RA 2.41537 Valid. err. 2.00688
2018-02-03 20:45:23,671 training [INFO ] Epoch 17 Batch 1760 Training err. 1.95721 Training err. RA 2.41016 Valid. err. 2.00919
2018-02-03 20:45:24,525 training [INFO ] Epoch 18 Batch 1780 Training err. 1.99867 Training err. RA 2.40554 Valid. err. 1.99724
2018-02-03 20:45:25,037 training [INFO ] Epoch 18 Batch 1800 Training err. 1.93631 Training err. RA 2.40032 Valid. err. 2.00565
2018-02-03 20:45:25,539 training [INFO ] Epoch 18 Batch 1820 Training err. 1.94916 Training err. RA 2.39537 Valid. err. 2.00408
2018-02-03 20:45:26,037 training [INFO ] Epoch 18 Batch 1840 Training err. 1.95624 Training err. RA 2.39059 Valid. err. 2.01073
2018-02-03 20:45:26,537 training [INFO ] Epoch 18 Batch 1860 Training err. 1.93800 Training err. RA 2.38573 Valid. err. 1.97195
2018-02-03 20:45:27,388 training [INFO ] Epoch 19 Batch 1880 Training err. 2.04127 Training err. RA 2.38206 Valid. err. 2.07121
2018-02-03 20:45:27,879 training [INFO ] Epoch 19 Batch 1900 Training err. 1.95528 Training err. RA 2.37757 Valid. err. 1.99944
2018-02-03 20:45:28,374 training [INFO ] Epoch 19 Batch 1920 Training err. 1.92505 Training err. RA 2.37286 Valid. err. 1.97938
2018-02-03 20:45:28,869 training [INFO ] Epoch 19 Batch 1940 Training err. 1.93070 Training err. RA 2.36830 Valid. err. 1.97144
2018-02-03 20:45:29,364 training [INFO ] Epoch 19 Batch 1960 Training err. 1.91801 Training err. RA 2.36370 Valid. err. 1.97492
2018-02-03 20:45:30,192 training [INFO ] Epoch 20 Batch 1980 Training err. 1.91700 Training err. RA 2.35919 Valid. err. 1.96568
2018-02-03 20:45:30,687 training [INFO ] Epoch 20 Batch 2000 Training err. 1.93974 Training err. RA 2.35500 Valid. err. 1.96972
2018-02-03 20:45:31,182 training [INFO ] Epoch 20 Batch 2020 Training err. 1.89795 Training err. RA 2.35047 Valid. err. 1.96567
2018-02-03 20:45:31,680 training [INFO ] Epoch 20 Batch 2040 Training err. 1.89683 Training err. RA 2.34602 Valid. err. 1.96239
2018-02-03 20:45:32,172 training [INFO ] Epoch 20 Batch 2060 Training err. 1.91065 Training err. RA 2.34180 Valid. err. 1.96057
2018-02-03 20:45:32,672 training [INFO ] Epoch 20 Batch 2080 Training err. 1.89816 Training err. RA 2.33753 Valid. err. 1.94597
2018-02-03 20:45:32,919 __main__ [INFO ] End of training
2018-02-03 20:45:33,152 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 64,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:45:33,650 training [INFO ] Epoch  1 Batch   20 Training err. 4.22942 Training err. RA 4.22942 Valid. err. 4.15330
2018-02-03 20:45:34,044 training [INFO ] Epoch  1 Batch   40 Training err. 4.06830 Training err. RA 4.14886 Valid. err. 3.99261
2018-02-03 20:45:34,436 training [INFO ] Epoch  1 Batch   60 Training err. 3.79178 Training err. RA 4.02983 Valid. err. 3.77742
2018-02-03 20:45:34,833 training [INFO ] Epoch  1 Batch   80 Training err. 3.66950 Training err. RA 3.93975 Valid. err. 3.61872
2018-02-03 20:45:35,232 training [INFO ] Epoch  1 Batch  100 Training err. 3.54338 Training err. RA 3.86048 Valid. err. 3.47607
2018-02-03 20:45:35,631 training [INFO ] Epoch  1 Batch  120 Training err. 3.35592 Training err. RA 3.77638 Valid. err. 3.36103
2018-02-03 20:45:36,035 training [INFO ] Epoch  1 Batch  140 Training err. 3.29838 Training err. RA 3.70810 Valid. err. 3.30709
2018-02-03 20:45:36,437 training [INFO ] Epoch  1 Batch  160 Training err. 3.22360 Training err. RA 3.64753 Valid. err. 3.26595
2018-02-03 20:45:36,832 training [INFO ] Epoch  1 Batch  180 Training err. 3.22561 Training err. RA 3.60065 Valid. err. 3.24411
2018-02-03 20:45:37,235 training [INFO ] Epoch  1 Batch  200 Training err. 3.19084 Training err. RA 3.55967 Valid. err. 3.23048
2018-02-03 20:45:37,633 training [INFO ] Epoch  1 Batch  220 Training err. 3.21015 Training err. RA 3.52790 Valid. err. 3.22029
2018-02-03 20:45:38,042 training [INFO ] Epoch  1 Batch  240 Training err. 3.19773 Training err. RA 3.50038 Valid. err. 3.21581
2018-02-03 20:45:38,442 training [INFO ] Epoch  1 Batch  260 Training err. 3.15039 Training err. RA 3.47346 Valid. err. 3.21089
2018-02-03 20:45:38,844 training [INFO ] Epoch  1 Batch  280 Training err. 3.17760 Training err. RA 3.45233 Valid. err. 3.20568
2018-02-03 20:45:39,247 training [INFO ] Epoch  1 Batch  300 Training err. 3.13683 Training err. RA 3.43130 Valid. err. 3.20265
2018-02-03 20:45:39,648 training [INFO ] Epoch  1 Batch  320 Training err. 3.09771 Training err. RA 3.41045 Valid. err. 3.20323
2018-02-03 20:45:40,057 training [INFO ] Epoch  1 Batch  340 Training err. 3.16573 Training err. RA 3.39605 Valid. err. 3.19526
2018-02-03 20:45:40,461 training [INFO ] Epoch  1 Batch  360 Training err. 3.18164 Training err. RA 3.38414 Valid. err. 3.19419
2018-02-03 20:45:40,860 training [INFO ] Epoch  1 Batch  380 Training err. 3.17699 Training err. RA 3.37324 Valid. err. 3.19015
2018-02-03 20:45:41,265 training [INFO ] Epoch  1 Batch  400 Training err. 3.18507 Training err. RA 3.36383 Valid. err. 3.18816
2018-02-03 20:45:42,026 training [INFO ] Epoch  2 Batch  420 Training err. 3.18695 Training err. RA 3.35541 Valid. err. 3.19875
2018-02-03 20:45:42,425 training [INFO ] Epoch  2 Batch  440 Training err. 3.13167 Training err. RA 3.34524 Valid. err. 3.19776
2018-02-03 20:45:42,823 training [INFO ] Epoch  2 Batch  460 Training err. 3.13812 Training err. RA 3.33623 Valid. err. 3.18915
2018-02-03 20:45:43,219 training [INFO ] Epoch  2 Batch  480 Training err. 3.00850 Training err. RA 3.32258 Valid. err. 3.22985
2018-02-03 20:45:43,618 training [INFO ] Epoch  2 Batch  500 Training err. 3.20790 Training err. RA 3.31799 Valid. err. 3.18579
2018-02-03 20:45:44,019 training [INFO ] Epoch  2 Batch  520 Training err. 3.12395 Training err. RA 3.31053 Valid. err. 3.18895
2018-02-03 20:45:44,421 training [INFO ] Epoch  2 Batch  540 Training err. 3.12232 Training err. RA 3.30356 Valid. err. 3.18767
2018-02-03 20:45:44,818 training [INFO ] Epoch  2 Batch  560 Training err. 3.12937 Training err. RA 3.29733 Valid. err. 3.18861
2018-02-03 20:45:45,217 training [INFO ] Epoch  2 Batch  580 Training err. 3.10902 Training err. RA 3.29084 Valid. err. 3.19493
2018-02-03 20:45:45,616 training [INFO ] Epoch  2 Batch  600 Training err. 3.15184 Training err. RA 3.28621 Valid. err. 3.18913
2018-02-03 20:45:46,014 training [INFO ] Epoch  2 Batch  620 Training err. 3.16340 Training err. RA 3.28225 Valid. err. 3.18882
2018-02-03 20:45:46,409 training [INFO ] Epoch  2 Batch  640 Training err. 3.13712 Training err. RA 3.27771 Valid. err. 3.18362
2018-02-03 20:45:46,807 training [INFO ] Epoch  2 Batch  660 Training err. 3.15822 Training err. RA 3.27409 Valid. err. 3.18640
2018-02-03 20:45:47,208 training [INFO ] Epoch  2 Batch  680 Training err. 3.10760 Training err. RA 3.26919 Valid. err. 3.18766
2018-02-03 20:45:47,609 training [INFO ] Epoch  2 Batch  700 Training err. 3.15589 Training err. RA 3.26596 Valid. err. 3.18800
2018-02-03 20:45:48,014 training [INFO ] Epoch  2 Batch  720 Training err. 3.09110 Training err. RA 3.26110 Valid. err. 3.18579
2018-02-03 20:45:48,409 training [INFO ] Epoch  2 Batch  740 Training err. 3.08271 Training err. RA 3.25628 Valid. err. 3.19451
2018-02-03 20:45:48,807 training [INFO ] Epoch  2 Batch  760 Training err. 3.14812 Training err. RA 3.25343 Valid. err. 3.18335
2018-02-03 20:45:49,206 training [INFO ] Epoch  2 Batch  780 Training err. 3.16074 Training err. RA 3.25105 Valid. err. 3.18486
2018-02-03 20:45:49,607 training [INFO ] Epoch  2 Batch  800 Training err. 3.16430 Training err. RA 3.24889 Valid. err. 3.18003
2018-02-03 20:45:50,011 training [INFO ] Epoch  2 Batch  820 Training err. 3.17282 Training err. RA 3.24703 Valid. err. 3.17698
2018-02-03 20:45:50,812 training [INFO ] Epoch  3 Batch  840 Training err. 3.15410 Training err. RA 3.24482 Valid. err. 3.18717
2018-02-03 20:45:51,216 training [INFO ] Epoch  3 Batch  860 Training err. 3.13026 Training err. RA 3.24215 Valid. err. 3.17855
2018-02-03 20:45:51,622 training [INFO ] Epoch  3 Batch  880 Training err. 3.12131 Training err. RA 3.23941 Valid. err. 3.18873
2018-02-03 20:45:52,031 training [INFO ] Epoch  3 Batch  900 Training err. 3.01222 Training err. RA 3.23436 Valid. err. 3.18183
2018-02-03 20:45:52,435 training [INFO ] Epoch  3 Batch  920 Training err. 3.18530 Training err. RA 3.23329 Valid. err. 3.17739
2018-02-03 20:45:52,836 training [INFO ] Epoch  3 Batch  940 Training err. 3.09746 Training err. RA 3.23040 Valid. err. 3.18203
2018-02-03 20:45:53,242 training [INFO ] Epoch  3 Batch  960 Training err. 3.11927 Training err. RA 3.22809 Valid. err. 3.17987
2018-02-03 20:45:53,641 training [INFO ] Epoch  3 Batch  980 Training err. 3.12310 Training err. RA 3.22594 Valid. err. 3.17680
2018-02-03 20:45:54,043 training [INFO ] Epoch  3 Batch 1000 Training err. 3.08253 Training err. RA 3.22308 Valid. err. 3.18413
2018-02-03 20:45:54,441 training [INFO ] Epoch  3 Batch 1020 Training err. 3.12689 Training err. RA 3.22119 Valid. err. 3.21616
2018-02-03 20:45:54,839 training [INFO ] Epoch  3 Batch 1040 Training err. 3.17950 Training err. RA 3.22039 Valid. err. 3.17870
2018-02-03 20:45:55,238 training [INFO ] Epoch  3 Batch 1060 Training err. 3.13089 Training err. RA 3.21870 Valid. err. 3.17453
2018-02-03 20:45:55,637 training [INFO ] Epoch  3 Batch 1080 Training err. 3.14204 Training err. RA 3.21728 Valid. err. 3.17698
2018-02-03 20:45:56,037 training [INFO ] Epoch  3 Batch 1100 Training err. 3.08640 Training err. RA 3.21490 Valid. err. 3.17865
2018-02-03 20:45:56,440 training [INFO ] Epoch  3 Batch 1120 Training err. 3.13890 Training err. RA 3.21354 Valid. err. 3.17722
2018-02-03 20:45:56,838 training [INFO ] Epoch  3 Batch 1140 Training err. 3.07236 Training err. RA 3.21107 Valid. err. 3.17604
2018-02-03 20:45:57,240 training [INFO ] Epoch  3 Batch 1160 Training err. 3.07219 Training err. RA 3.20867 Valid. err. 3.17990
2018-02-03 20:45:57,642 training [INFO ] Epoch  3 Batch 1180 Training err. 3.14816 Training err. RA 3.20765 Valid. err. 3.17301
2018-02-03 20:45:58,052 training [INFO ] Epoch  3 Batch 1200 Training err. 3.14802 Training err. RA 3.20665 Valid. err. 3.16919
2018-02-03 20:45:58,461 training [INFO ] Epoch  3 Batch 1220 Training err. 3.14158 Training err. RA 3.20559 Valid. err. 3.16832
2018-02-03 20:45:58,863 training [INFO ] Epoch  3 Batch 1240 Training err. 3.16681 Training err. RA 3.20496 Valid. err. 3.16522
2018-02-03 20:45:59,645 training [INFO ] Epoch  4 Batch 1260 Training err. 3.13254 Training err. RA 3.20381 Valid. err. 3.16523
2018-02-03 20:46:00,049 training [INFO ] Epoch  4 Batch 1280 Training err. 3.12059 Training err. RA 3.20251 Valid. err. 3.16711
2018-02-03 20:46:00,459 training [INFO ] Epoch  4 Batch 1300 Training err. 3.08570 Training err. RA 3.20071 Valid. err. 3.18674
2018-02-03 20:46:00,860 training [INFO ] Epoch  4 Batch 1320 Training err. 3.03566 Training err. RA 3.19821 Valid. err. 3.16653
2018-02-03 20:46:01,261 training [INFO ] Epoch  4 Batch 1340 Training err. 3.15693 Training err. RA 3.19760 Valid. err. 3.16424
2018-02-03 20:46:01,659 training [INFO ] Epoch  4 Batch 1360 Training err. 3.08426 Training err. RA 3.19593 Valid. err. 3.16746
2018-02-03 20:46:02,061 training [INFO ] Epoch  4 Batch 1380 Training err. 3.10749 Training err. RA 3.19465 Valid. err. 3.16507
2018-02-03 20:46:02,459 training [INFO ] Epoch  4 Batch 1400 Training err. 3.10473 Training err. RA 3.19336 Valid. err. 3.16249
2018-02-03 20:46:02,857 training [INFO ] Epoch  4 Batch 1420 Training err. 3.06784 Training err. RA 3.19160 Valid. err. 3.16904
2018-02-03 20:46:03,260 training [INFO ] Epoch  4 Batch 1440 Training err. 3.11847 Training err. RA 3.19058 Valid. err. 3.16254
2018-02-03 20:46:03,662 training [INFO ] Epoch  4 Batch 1460 Training err. 3.16593 Training err. RA 3.19024 Valid. err. 3.16959
2018-02-03 20:46:04,063 training [INFO ] Epoch  4 Batch 1480 Training err. 3.11194 Training err. RA 3.18918 Valid. err. 3.15825
2018-02-03 20:46:04,463 training [INFO ] Epoch  4 Batch 1500 Training err. 3.12700 Training err. RA 3.18835 Valid. err. 3.15877
2018-02-03 20:46:04,861 training [INFO ] Epoch  4 Batch 1520 Training err. 3.05953 Training err. RA 3.18666 Valid. err. 3.15839
2018-02-03 20:46:05,260 training [INFO ] Epoch  4 Batch 1540 Training err. 3.12437 Training err. RA 3.18585 Valid. err. 3.15613
2018-02-03 20:46:05,657 training [INFO ] Epoch  4 Batch 1560 Training err. 3.04401 Training err. RA 3.18403 Valid. err. 3.15305
2018-02-03 20:46:06,059 training [INFO ] Epoch  4 Batch 1580 Training err. 3.05071 Training err. RA 3.18234 Valid. err. 3.15273
2018-02-03 20:46:06,458 training [INFO ] Epoch  4 Batch 1600 Training err. 3.13304 Training err. RA 3.18173 Valid. err. 3.14909
2018-02-03 20:46:06,857 training [INFO ] Epoch  4 Batch 1620 Training err. 3.13647 Training err. RA 3.18117 Valid. err. 3.14237
2018-02-03 20:46:07,258 training [INFO ] Epoch  4 Batch 1640 Training err. 3.09969 Training err. RA 3.18018 Valid. err. 3.14315
2018-02-03 20:46:07,655 training [INFO ] Epoch  4 Batch 1660 Training err. 3.13039 Training err. RA 3.17958 Valid. err. 3.13619
2018-02-03 20:46:08,443 training [INFO ] Epoch  5 Batch 1680 Training err. 3.10766 Training err. RA 3.17872 Valid. err. 3.13528
2018-02-03 20:46:08,841 training [INFO ] Epoch  5 Batch 1700 Training err. 3.08139 Training err. RA 3.17757 Valid. err. 3.13741
2018-02-03 20:46:09,242 training [INFO ] Epoch  5 Batch 1720 Training err. 3.04888 Training err. RA 3.17608 Valid. err. 3.15455
2018-02-03 20:46:09,639 training [INFO ] Epoch  5 Batch 1740 Training err. 3.06246 Training err. RA 3.17477 Valid. err. 3.14014
2018-02-03 20:46:10,041 training [INFO ] Epoch  5 Batch 1760 Training err. 3.12104 Training err. RA 3.17416 Valid. err. 3.13186
2018-02-03 20:46:10,444 training [INFO ] Epoch  5 Batch 1780 Training err. 3.04479 Training err. RA 3.17271 Valid. err. 3.14446
2018-02-03 20:46:10,844 training [INFO ] Epoch  5 Batch 1800 Training err. 3.08573 Training err. RA 3.17174 Valid. err. 3.12685
2018-02-03 20:46:11,243 training [INFO ] Epoch  5 Batch 1820 Training err. 3.07646 Training err. RA 3.17069 Valid. err. 3.12395
2018-02-03 20:46:11,642 training [INFO ] Epoch  5 Batch 1840 Training err. 3.02931 Training err. RA 3.16916 Valid. err. 3.12638
2018-02-03 20:46:12,043 training [INFO ] Epoch  5 Batch 1860 Training err. 3.07555 Training err. RA 3.16815 Valid. err. 3.12171
2018-02-03 20:46:12,447 training [INFO ] Epoch  5 Batch 1880 Training err. 3.13948 Training err. RA 3.16785 Valid. err. 3.11805
2018-02-03 20:46:12,845 training [INFO ] Epoch  5 Batch 1900 Training err. 3.06903 Training err. RA 3.16681 Valid. err. 3.11273
2018-02-03 20:46:13,244 training [INFO ] Epoch  5 Batch 1920 Training err. 3.07188 Training err. RA 3.16582 Valid. err. 3.11018
2018-02-03 20:46:13,646 training [INFO ] Epoch  5 Batch 1940 Training err. 3.03317 Training err. RA 3.16445 Valid. err. 3.11078
2018-02-03 20:46:14,054 training [INFO ] Epoch  5 Batch 1960 Training err. 3.06132 Training err. RA 3.16340 Valid. err. 3.10205
2018-02-03 20:46:14,457 training [INFO ] Epoch  5 Batch 1980 Training err. 2.98835 Training err. RA 3.16163 Valid. err. 3.09813
2018-02-03 20:46:14,857 training [INFO ] Epoch  5 Batch 2000 Training err. 3.02037 Training err. RA 3.16022 Valid. err. 3.09694
2018-02-03 20:46:15,263 training [INFO ] Epoch  5 Batch 2020 Training err. 3.08108 Training err. RA 3.15943 Valid. err. 3.09013
2018-02-03 20:46:15,666 training [INFO ] Epoch  5 Batch 2040 Training err. 3.07870 Training err. RA 3.15864 Valid. err. 3.08216
2018-02-03 20:46:16,075 training [INFO ] Epoch  5 Batch 2060 Training err. 3.04614 Training err. RA 3.15755 Valid. err. 3.08199
2018-02-03 20:46:16,481 training [INFO ] Epoch  5 Batch 2080 Training err. 3.06127 Training err. RA 3.15662 Valid. err. 3.08548
2018-02-03 20:46:17,263 training [INFO ] Epoch  6 Batch 2100 Training err. 3.06778 Training err. RA 3.15578 Valid. err. 3.06707
2018-02-03 20:46:17,662 training [INFO ] Epoch  6 Batch 2120 Training err. 2.99013 Training err. RA 3.15421 Valid. err. 3.06717
2018-02-03 20:46:18,066 training [INFO ] Epoch  6 Batch 2140 Training err. 3.00043 Training err. RA 3.15278 Valid. err. 3.11991
2018-02-03 20:46:18,467 training [INFO ] Epoch  6 Batch 2160 Training err. 3.03967 Training err. RA 3.15173 Valid. err. 3.06277
2018-02-03 20:46:18,862 training [INFO ] Epoch  6 Batch 2180 Training err. 3.03604 Training err. RA 3.15067 Valid. err. 3.05489
2018-02-03 20:46:19,264 training [INFO ] Epoch  6 Batch 2200 Training err. 2.97536 Training err. RA 3.14908 Valid. err. 3.05743
2018-02-03 20:46:19,663 training [INFO ] Epoch  6 Batch 2220 Training err. 3.02803 Training err. RA 3.14798 Valid. err. 3.04354
2018-02-03 20:46:20,061 training [INFO ] Epoch  6 Batch 2240 Training err. 2.98729 Training err. RA 3.14655 Valid. err. 3.04167
2018-02-03 20:46:20,461 training [INFO ] Epoch  6 Batch 2260 Training err. 2.96514 Training err. RA 3.14494 Valid. err. 3.03926
2018-02-03 20:46:20,857 training [INFO ] Epoch  6 Batch 2280 Training err. 3.00938 Training err. RA 3.14376 Valid. err. 3.03254
2018-02-03 20:46:21,261 training [INFO ] Epoch  6 Batch 2300 Training err. 3.03988 Training err. RA 3.14285 Valid. err. 3.03150
2018-02-03 20:46:21,662 training [INFO ] Epoch  6 Batch 2320 Training err. 3.00526 Training err. RA 3.14167 Valid. err. 3.01823
2018-02-03 20:46:22,070 training [INFO ] Epoch  6 Batch 2340 Training err. 2.95612 Training err. RA 3.14008 Valid. err. 3.02096
2018-02-03 20:46:22,481 training [INFO ] Epoch  6 Batch 2360 Training err. 2.94972 Training err. RA 3.13847 Valid. err. 3.00874
2018-02-03 20:46:22,883 training [INFO ] Epoch  6 Batch 2380 Training err. 2.94862 Training err. RA 3.13687 Valid. err. 3.00666
2018-02-03 20:46:23,288 training [INFO ] Epoch  6 Batch 2400 Training err. 2.89852 Training err. RA 3.13489 Valid. err. 2.99721
2018-02-03 20:46:23,691 training [INFO ] Epoch  6 Batch 2420 Training err. 2.93521 Training err. RA 3.13323 Valid. err. 2.99186
2018-02-03 20:46:24,104 training [INFO ] Epoch  6 Batch 2440 Training err. 2.97754 Training err. RA 3.13196 Valid. err. 2.98345
2018-02-03 20:46:24,513 training [INFO ] Epoch  6 Batch 2460 Training err. 2.97227 Training err. RA 3.13066 Valid. err. 2.97250
2018-02-03 20:46:24,914 training [INFO ] Epoch  6 Batch 2480 Training err. 2.95430 Training err. RA 3.12924 Valid. err. 2.96834
2018-02-03 20:46:25,313 training [INFO ] Epoch  6 Batch 2500 Training err. 2.96140 Training err. RA 3.12790 Valid. err. 2.95815
2018-02-03 20:46:26,095 training [INFO ] Epoch  7 Batch 2520 Training err. 2.93470 Training err. RA 3.12636 Valid. err. 2.95399
2018-02-03 20:46:26,494 training [INFO ] Epoch  7 Batch 2540 Training err. 2.88304 Training err. RA 3.12445 Valid. err. 2.95115
2018-02-03 20:46:26,894 training [INFO ] Epoch  7 Batch 2560 Training err. 2.87235 Training err. RA 3.12248 Valid. err. 2.98259
2018-02-03 20:46:27,297 training [INFO ] Epoch  7 Batch 2580 Training err. 2.92226 Training err. RA 3.12092 Valid. err. 2.94374
2018-02-03 20:46:27,693 training [INFO ] Epoch  7 Batch 2600 Training err. 2.92011 Training err. RA 3.11938 Valid. err. 2.93178
2018-02-03 20:46:28,096 training [INFO ] Epoch  7 Batch 2620 Training err. 2.84694 Training err. RA 3.11730 Valid. err. 2.92741
2018-02-03 20:46:28,496 training [INFO ] Epoch  7 Batch 2640 Training err. 2.91995 Training err. RA 3.11581 Valid. err. 2.96778
2018-02-03 20:46:28,896 training [INFO ] Epoch  7 Batch 2660 Training err. 2.83776 Training err. RA 3.11371 Valid. err. 2.92251
2018-02-03 20:46:29,297 training [INFO ] Epoch  7 Batch 2680 Training err. 2.85549 Training err. RA 3.11179 Valid. err. 2.90870
2018-02-03 20:46:29,692 training [INFO ] Epoch  7 Batch 2700 Training err. 2.86213 Training err. RA 3.10994 Valid. err. 2.90099
2018-02-03 20:46:30,096 training [INFO ] Epoch  7 Batch 2720 Training err. 2.89551 Training err. RA 3.10836 Valid. err. 2.89428
2018-02-03 20:46:30,506 training [INFO ] Epoch  7 Batch 2740 Training err. 2.87718 Training err. RA 3.10667 Valid. err. 2.88698
2018-02-03 20:46:30,907 training [INFO ] Epoch  7 Batch 2760 Training err. 2.83406 Training err. RA 3.10470 Valid. err. 2.88994
2018-02-03 20:46:31,310 training [INFO ] Epoch  7 Batch 2780 Training err. 2.82776 Training err. RA 3.10271 Valid. err. 2.87450
2018-02-03 20:46:31,709 training [INFO ] Epoch  7 Batch 2800 Training err. 2.81170 Training err. RA 3.10063 Valid. err. 2.87404
2018-02-03 20:46:32,115 training [INFO ] Epoch  7 Batch 2820 Training err. 2.75048 Training err. RA 3.09814 Valid. err. 2.86630
2018-02-03 20:46:32,524 training [INFO ] Epoch  7 Batch 2840 Training err. 2.82433 Training err. RA 3.09622 Valid. err. 2.86036
2018-02-03 20:46:32,928 training [INFO ] Epoch  7 Batch 2860 Training err. 2.84316 Training err. RA 3.09445 Valid. err. 2.85120
2018-02-03 20:46:33,332 training [INFO ] Epoch  7 Batch 2880 Training err. 2.83193 Training err. RA 3.09262 Valid. err. 2.86428
2018-02-03 20:46:33,725 training [INFO ] Epoch  7 Batch 2900 Training err. 2.84162 Training err. RA 3.09089 Valid. err. 2.84465
2018-02-03 20:46:34,489 training [INFO ] Epoch  8 Batch 2920 Training err. 2.83217 Training err. RA 3.08912 Valid. err. 2.86372
2018-02-03 20:46:34,894 training [INFO ] Epoch  8 Batch 2940 Training err. 2.76976 Training err. RA 3.08695 Valid. err. 2.84436
2018-02-03 20:46:35,291 training [INFO ] Epoch  8 Batch 2960 Training err. 2.75249 Training err. RA 3.08469 Valid. err. 2.81836
2018-02-03 20:46:35,686 training [INFO ] Epoch  8 Batch 2980 Training err. 2.65384 Training err. RA 3.08180 Valid. err. 2.83455
2018-02-03 20:46:36,087 training [INFO ] Epoch  8 Batch 3000 Training err. 2.84140 Training err. RA 3.08019 Valid. err. 2.80292
2018-02-03 20:46:36,483 training [INFO ] Epoch  8 Batch 3020 Training err. 2.76718 Training err. RA 3.07812 Valid. err. 2.81546
2018-02-03 20:46:36,882 training [INFO ] Epoch  8 Batch 3040 Training err. 2.71766 Training err. RA 3.07575 Valid. err. 2.79390
2018-02-03 20:46:37,280 training [INFO ] Epoch  8 Batch 3060 Training err. 2.80714 Training err. RA 3.07399 Valid. err. 2.95148
2018-02-03 20:46:37,676 training [INFO ] Epoch  8 Batch 3080 Training err. 2.69843 Training err. RA 3.07155 Valid. err. 2.81795
2018-02-03 20:46:38,074 training [INFO ] Epoch  8 Batch 3100 Training err. 2.75090 Training err. RA 3.06949 Valid. err. 2.78230
2018-02-03 20:46:38,470 training [INFO ] Epoch  8 Batch 3120 Training err. 2.73603 Training err. RA 3.06735 Valid. err. 2.77085
2018-02-03 20:46:38,873 training [INFO ] Epoch  8 Batch 3140 Training err. 2.74825 Training err. RA 3.06532 Valid. err. 2.78743
2018-02-03 20:46:39,274 training [INFO ] Epoch  8 Batch 3160 Training err. 2.78162 Training err. RA 3.06352 Valid. err. 2.76529
2018-02-03 20:46:39,669 training [INFO ] Epoch  8 Batch 3180 Training err. 2.69992 Training err. RA 3.06123 Valid. err. 2.75969
2018-02-03 20:46:40,069 training [INFO ] Epoch  8 Batch 3200 Training err. 2.72257 Training err. RA 3.05912 Valid. err. 2.75289
2018-02-03 20:46:40,466 training [INFO ] Epoch  8 Batch 3220 Training err. 2.67916 Training err. RA 3.05676 Valid. err. 2.76331
2018-02-03 20:46:40,871 training [INFO ] Epoch  8 Batch 3240 Training err. 2.65547 Training err. RA 3.05428 Valid. err. 2.75445
2018-02-03 20:46:41,270 training [INFO ] Epoch  8 Batch 3260 Training err. 2.70519 Training err. RA 3.05214 Valid. err. 2.74007
2018-02-03 20:46:41,667 training [INFO ] Epoch  8 Batch 3280 Training err. 2.71595 Training err. RA 3.05009 Valid. err. 2.73410
2018-02-03 20:46:42,071 training [INFO ] Epoch  8 Batch 3300 Training err. 2.72920 Training err. RA 3.04814 Valid. err. 2.77532
2018-02-03 20:46:42,475 training [INFO ] Epoch  8 Batch 3320 Training err. 2.73580 Training err. RA 3.04626 Valid. err. 2.72326
2018-02-03 20:46:43,274 training [INFO ] Epoch  9 Batch 3340 Training err. 2.71567 Training err. RA 3.04428 Valid. err. 2.71704
2018-02-03 20:46:43,675 training [INFO ] Epoch  9 Batch 3360 Training err. 2.65695 Training err. RA 3.04198 Valid. err. 2.71457
2018-02-03 20:46:44,082 training [INFO ] Epoch  9 Batch 3380 Training err. 2.66461 Training err. RA 3.03974 Valid. err. 2.71048
2018-02-03 20:46:44,489 training [INFO ] Epoch  9 Batch 3400 Training err. 2.50796 Training err. RA 3.03662 Valid. err. 2.71762
2018-02-03 20:46:44,895 training [INFO ] Epoch  9 Batch 3420 Training err. 2.78204 Training err. RA 3.03513 Valid. err. 2.71205
2018-02-03 20:46:45,295 training [INFO ] Epoch  9 Batch 3440 Training err. 2.64965 Training err. RA 3.03289 Valid. err. 2.71299
2018-02-03 20:46:45,688 training [INFO ] Epoch  9 Batch 3460 Training err. 2.65949 Training err. RA 3.03073 Valid. err. 2.69650
2018-02-03 20:46:46,087 training [INFO ] Epoch  9 Batch 3480 Training err. 2.65144 Training err. RA 3.02855 Valid. err. 2.69247
2018-02-03 20:46:46,482 training [INFO ] Epoch  9 Batch 3500 Training err. 2.60153 Training err. RA 3.02611 Valid. err. 2.70435
2018-02-03 20:46:46,880 training [INFO ] Epoch  9 Batch 3520 Training err. 2.64698 Training err. RA 3.02395 Valid. err. 2.70788
2018-02-03 20:46:47,318 training [INFO ] Epoch  9 Batch 3540 Training err. 2.68079 Training err. RA 3.02201 Valid. err. 2.69060
2018-02-03 20:46:47,715 training [INFO ] Epoch  9 Batch 3560 Training err. 2.64437 Training err. RA 3.01989 Valid. err. 2.67857
2018-02-03 20:46:48,120 training [INFO ] Epoch  9 Batch 3580 Training err. 2.70616 Training err. RA 3.01814 Valid. err. 2.68649
2018-02-03 20:46:48,515 training [INFO ] Epoch  9 Batch 3600 Training err. 2.61622 Training err. RA 3.01591 Valid. err. 2.68722
2018-02-03 20:46:48,917 training [INFO ] Epoch  9 Batch 3620 Training err. 2.65220 Training err. RA 3.01390 Valid. err. 2.67305
2018-02-03 20:46:49,319 training [INFO ] Epoch  9 Batch 3640 Training err. 2.57558 Training err. RA 3.01149 Valid. err. 2.68512
2018-02-03 20:46:49,718 training [INFO ] Epoch  9 Batch 3660 Training err. 2.57689 Training err. RA 3.00912 Valid. err. 2.65979
2018-02-03 20:46:50,122 training [INFO ] Epoch  9 Batch 3680 Training err. 2.64056 Training err. RA 3.00711 Valid. err. 2.68035
2018-02-03 20:46:50,524 training [INFO ] Epoch  9 Batch 3700 Training err. 2.61799 Training err. RA 3.00501 Valid. err. 2.67566
2018-02-03 20:46:50,930 training [INFO ] Epoch  9 Batch 3720 Training err. 2.65000 Training err. RA 3.00310 Valid. err. 2.64605
2018-02-03 20:46:51,332 training [INFO ] Epoch  9 Batch 3740 Training err. 2.65643 Training err. RA 3.00125 Valid. err. 2.64320
2018-02-03 20:46:52,111 training [INFO ] Epoch 10 Batch 3760 Training err. 2.62265 Training err. RA 2.99923 Valid. err. 2.63311
2018-02-03 20:46:52,511 training [INFO ] Epoch 10 Batch 3780 Training err. 2.59739 Training err. RA 2.99711 Valid. err. 2.66189
2018-02-03 20:46:52,916 training [INFO ] Epoch 10 Batch 3800 Training err. 2.58119 Training err. RA 2.99492 Valid. err. 2.63291
2018-02-03 20:46:53,321 training [INFO ] Epoch 10 Batch 3820 Training err. 2.46303 Training err. RA 2.99213 Valid. err. 2.63512
2018-02-03 20:46:53,716 training [INFO ] Epoch 10 Batch 3840 Training err. 2.68962 Training err. RA 2.99056 Valid. err. 2.63714
2018-02-03 20:46:54,111 training [INFO ] Epoch 10 Batch 3860 Training err. 2.57391 Training err. RA 2.98840 Valid. err. 2.65259
2018-02-03 20:46:54,508 training [INFO ] Epoch 10 Batch 3880 Training err. 2.60546 Training err. RA 2.98642 Valid. err. 2.63167
2018-02-03 20:46:54,910 training [INFO ] Epoch 10 Batch 3900 Training err. 2.59144 Training err. RA 2.98440 Valid. err. 2.61291
2018-02-03 20:46:55,312 training [INFO ] Epoch 10 Batch 3920 Training err. 2.51306 Training err. RA 2.98199 Valid. err. 2.62526
2018-02-03 20:46:55,708 training [INFO ] Epoch 10 Batch 3940 Training err. 2.55226 Training err. RA 2.97981 Valid. err. 2.63837
2018-02-03 20:46:56,107 training [INFO ] Epoch 10 Batch 3960 Training err. 2.64468 Training err. RA 2.97812 Valid. err. 2.61442
2018-02-03 20:46:56,503 training [INFO ] Epoch 10 Batch 3980 Training err. 2.59970 Training err. RA 2.97622 Valid. err. 2.61506
2018-02-03 20:46:56,903 training [INFO ] Epoch 10 Batch 4000 Training err. 2.64231 Training err. RA 2.97455 Valid. err. 2.60911
2018-02-03 20:46:57,300 training [INFO ] Epoch 10 Batch 4020 Training err. 2.54283 Training err. RA 2.97240 Valid. err. 2.60124
2018-02-03 20:46:57,695 training [INFO ] Epoch 10 Batch 4040 Training err. 2.57269 Training err. RA 2.97042 Valid. err. 2.60008
2018-02-03 20:46:58,094 training [INFO ] Epoch 10 Batch 4060 Training err. 2.51334 Training err. RA 2.96817 Valid. err. 2.60092
2018-02-03 20:46:58,491 training [INFO ] Epoch 10 Batch 4080 Training err. 2.50622 Training err. RA 2.96591 Valid. err. 2.61794
2018-02-03 20:46:58,893 training [INFO ] Epoch 10 Batch 4100 Training err. 2.59184 Training err. RA 2.96408 Valid. err. 2.58658
2018-02-03 20:46:59,291 training [INFO ] Epoch 10 Batch 4120 Training err. 2.54797 Training err. RA 2.96206 Valid. err. 2.57740
2018-02-03 20:46:59,687 training [INFO ] Epoch 10 Batch 4140 Training err. 2.57869 Training err. RA 2.96021 Valid. err. 2.59009
2018-02-03 20:47:00,087 training [INFO ] Epoch 10 Batch 4160 Training err. 2.58634 Training err. RA 2.95841 Valid. err. 2.58007
2018-02-03 20:47:00,870 training [INFO ] Epoch 11 Batch 4180 Training err. 2.53944 Training err. RA 2.95641 Valid. err. 2.57997
2018-02-03 20:47:01,268 training [INFO ] Epoch 11 Batch 4200 Training err. 2.55259 Training err. RA 2.95448 Valid. err. 2.58330
2018-02-03 20:47:01,664 training [INFO ] Epoch 11 Batch 4220 Training err. 2.48408 Training err. RA 2.95225 Valid. err. 2.57092
2018-02-03 20:47:02,065 training [INFO ] Epoch 11 Batch 4240 Training err. 2.46569 Training err. RA 2.94996 Valid. err. 2.56643
2018-02-03 20:47:02,470 training [INFO ] Epoch 11 Batch 4260 Training err. 2.61344 Training err. RA 2.94838 Valid. err. 2.57510
2018-02-03 20:47:02,873 training [INFO ] Epoch 11 Batch 4280 Training err. 2.50967 Training err. RA 2.94633 Valid. err. 2.57364
2018-02-03 20:47:03,274 training [INFO ] Epoch 11 Batch 4300 Training err. 2.55287 Training err. RA 2.94450 Valid. err. 2.57689
2018-02-03 20:47:03,676 training [INFO ] Epoch 11 Batch 4320 Training err. 2.51693 Training err. RA 2.94252 Valid. err. 2.55725
2018-02-03 20:47:04,079 training [INFO ] Epoch 11 Batch 4340 Training err. 2.46163 Training err. RA 2.94030 Valid. err. 2.56037
2018-02-03 20:47:04,481 training [INFO ] Epoch 11 Batch 4360 Training err. 2.51372 Training err. RA 2.93835 Valid. err. 2.56453
2018-02-03 20:47:04,887 training [INFO ] Epoch 11 Batch 4380 Training err. 2.56884 Training err. RA 2.93666 Valid. err. 2.54435
2018-02-03 20:47:05,288 training [INFO ] Epoch 11 Batch 4400 Training err. 2.57284 Training err. RA 2.93501 Valid. err. 2.55038
2018-02-03 20:47:05,685 training [INFO ] Epoch 11 Batch 4420 Training err. 2.56927 Training err. RA 2.93335 Valid. err. 2.54374
2018-02-03 20:47:06,084 training [INFO ] Epoch 11 Batch 4440 Training err. 2.48666 Training err. RA 2.93134 Valid. err. 2.54340
2018-02-03 20:47:06,482 training [INFO ] Epoch 11 Batch 4460 Training err. 2.52569 Training err. RA 2.92952 Valid. err. 2.53606
2018-02-03 20:47:06,880 training [INFO ] Epoch 11 Batch 4480 Training err. 2.44603 Training err. RA 2.92736 Valid. err. 2.54136
2018-02-03 20:47:07,293 training [INFO ] Epoch 11 Batch 4500 Training err. 2.45567 Training err. RA 2.92527 Valid. err. 2.53443
2018-02-03 20:47:07,695 training [INFO ] Epoch 11 Batch 4520 Training err. 2.54908 Training err. RA 2.92360 Valid. err. 2.54483
2018-02-03 20:47:08,091 training [INFO ] Epoch 11 Batch 4540 Training err. 2.49772 Training err. RA 2.92172 Valid. err. 2.53245
2018-02-03 20:47:08,486 training [INFO ] Epoch 11 Batch 4560 Training err. 2.50300 Training err. RA 2.91989 Valid. err. 2.53648
2018-02-03 20:47:08,885 training [INFO ] Epoch 11 Batch 4580 Training err. 2.53087 Training err. RA 2.91819 Valid. err. 2.52377
2018-02-03 20:47:09,653 training [INFO ] Epoch 12 Batch 4600 Training err. 2.49929 Training err. RA 2.91637 Valid. err. 2.51487
2018-02-03 20:47:10,059 training [INFO ] Epoch 12 Batch 4620 Training err. 2.47031 Training err. RA 2.91444 Valid. err. 2.52094
2018-02-03 20:47:10,464 training [INFO ] Epoch 12 Batch 4640 Training err. 2.42344 Training err. RA 2.91232 Valid. err. 2.52375
2018-02-03 20:47:10,870 training [INFO ] Epoch 12 Batch 4660 Training err. 2.45304 Training err. RA 2.91035 Valid. err. 2.51521
2018-02-03 20:47:11,270 training [INFO ] Epoch 12 Batch 4680 Training err. 2.54978 Training err. RA 2.90881 Valid. err. 2.53178
2018-02-03 20:47:11,669 training [INFO ] Epoch 12 Batch 4700 Training err. 2.43975 Training err. RA 2.90681 Valid. err. 2.51681
2018-02-03 20:47:12,081 training [INFO ] Epoch 12 Batch 4720 Training err. 2.52518 Training err. RA 2.90520 Valid. err. 2.50229
2018-02-03 20:47:12,485 training [INFO ] Epoch 12 Batch 4740 Training err. 2.46028 Training err. RA 2.90332 Valid. err. 2.51067
2018-02-03 20:47:12,891 training [INFO ] Epoch 12 Batch 4760 Training err. 2.41102 Training err. RA 2.90125 Valid. err. 2.53421
2018-02-03 20:47:13,289 training [INFO ] Epoch 12 Batch 4780 Training err. 2.47324 Training err. RA 2.89946 Valid. err. 2.52451
2018-02-03 20:47:13,685 training [INFO ] Epoch 12 Batch 4800 Training err. 2.49833 Training err. RA 2.89779 Valid. err. 2.49523
2018-02-03 20:47:14,084 training [INFO ] Epoch 12 Batch 4820 Training err. 2.54117 Training err. RA 2.89631 Valid. err. 2.49797
2018-02-03 20:47:14,483 training [INFO ] Epoch 12 Batch 4840 Training err. 2.49856 Training err. RA 2.89466 Valid. err. 2.49227
2018-02-03 20:47:14,886 training [INFO ] Epoch 12 Batch 4860 Training err. 2.46072 Training err. RA 2.89288 Valid. err. 2.49510
2018-02-03 20:47:15,279 training [INFO ] Epoch 12 Batch 4880 Training err. 2.46019 Training err. RA 2.89111 Valid. err. 2.50765
2018-02-03 20:47:15,674 training [INFO ] Epoch 12 Batch 4900 Training err. 2.40616 Training err. RA 2.88913 Valid. err. 2.51481
2018-02-03 20:47:16,071 training [INFO ] Epoch 12 Batch 4920 Training err. 2.40899 Training err. RA 2.88717 Valid. err. 2.47864
2018-02-03 20:47:16,468 training [INFO ] Epoch 12 Batch 4940 Training err. 2.49732 Training err. RA 2.88560 Valid. err. 2.47721
2018-02-03 20:47:16,869 training [INFO ] Epoch 12 Batch 4960 Training err. 2.45039 Training err. RA 2.88384 Valid. err. 2.47612
2018-02-03 20:47:17,264 training [INFO ] Epoch 12 Batch 4980 Training err. 2.45579 Training err. RA 2.88212 Valid. err. 2.51074
2018-02-03 20:47:17,660 training [INFO ] Epoch 12 Batch 5000 Training err. 2.46903 Training err. RA 2.88047 Valid. err. 2.47864
2018-02-03 20:47:18,446 training [INFO ] Epoch 13 Batch 5020 Training err. 2.46449 Training err. RA 2.87881 Valid. err. 2.47254
2018-02-03 20:47:18,848 training [INFO ] Epoch 13 Batch 5040 Training err. 2.39652 Training err. RA 2.87690 Valid. err. 2.46784
2018-02-03 20:47:19,242 training [INFO ] Epoch 13 Batch 5060 Training err. 2.36155 Training err. RA 2.87486 Valid. err. 2.46456
2018-02-03 20:47:19,639 training [INFO ] Epoch 13 Batch 5080 Training err. 2.43854 Training err. RA 2.87314 Valid. err. 2.46596
2018-02-03 20:47:20,035 training [INFO ] Epoch 13 Batch 5100 Training err. 2.49743 Training err. RA 2.87167 Valid. err. 2.46083
2018-02-03 20:47:20,435 training [INFO ] Epoch 13 Batch 5120 Training err. 2.38965 Training err. RA 2.86979 Valid. err. 2.47232
2018-02-03 20:47:20,838 training [INFO ] Epoch 13 Batch 5140 Training err. 2.49701 Training err. RA 2.86834 Valid. err. 2.45319
2018-02-03 20:47:21,232 training [INFO ] Epoch 13 Batch 5160 Training err. 2.39687 Training err. RA 2.86651 Valid. err. 2.46980
2018-02-03 20:47:21,630 training [INFO ] Epoch 13 Batch 5180 Training err. 2.38750 Training err. RA 2.86466 Valid. err. 2.45576
2018-02-03 20:47:22,034 training [INFO ] Epoch 13 Batch 5200 Training err. 2.42625 Training err. RA 2.86297 Valid. err. 2.45194
2018-02-03 20:47:22,438 training [INFO ] Epoch 13 Batch 5220 Training err. 2.43799 Training err. RA 2.86135 Valid. err. 2.47880
2018-02-03 20:47:22,848 training [INFO ] Epoch 13 Batch 5240 Training err. 2.51649 Training err. RA 2.86003 Valid. err. 2.48838
2018-02-03 20:47:23,247 training [INFO ] Epoch 13 Batch 5260 Training err. 2.43900 Training err. RA 2.85843 Valid. err. 2.45396
2018-02-03 20:47:23,650 training [INFO ] Epoch 13 Batch 5280 Training err. 2.40886 Training err. RA 2.85673 Valid. err. 2.44328
2018-02-03 20:47:24,060 training [INFO ] Epoch 13 Batch 5300 Training err. 2.41572 Training err. RA 2.85506 Valid. err. 2.44729
2018-02-03 20:47:24,461 training [INFO ] Epoch 13 Batch 5320 Training err. 2.36609 Training err. RA 2.85322 Valid. err. 2.43952
2018-02-03 20:47:24,870 training [INFO ] Epoch 13 Batch 5340 Training err. 2.37933 Training err. RA 2.85145 Valid. err. 2.44471
2018-02-03 20:47:25,271 training [INFO ] Epoch 13 Batch 5360 Training err. 2.43734 Training err. RA 2.84990 Valid. err. 2.43361
2018-02-03 20:47:25,668 training [INFO ] Epoch 13 Batch 5380 Training err. 2.40760 Training err. RA 2.84826 Valid. err. 2.43817
2018-02-03 20:47:26,069 training [INFO ] Epoch 13 Batch 5400 Training err. 2.41362 Training err. RA 2.84665 Valid. err. 2.43146
2018-02-03 20:47:26,466 training [INFO ] Epoch 13 Batch 5420 Training err. 2.43562 Training err. RA 2.84513 Valid. err. 2.42113
2018-02-03 20:47:27,224 training [INFO ] Epoch 14 Batch 5440 Training err. 2.42444 Training err. RA 2.84359 Valid. err. 2.45490
2018-02-03 20:47:27,621 training [INFO ] Epoch 14 Batch 5460 Training err. 2.34311 Training err. RA 2.84175 Valid. err. 2.44421
2018-02-03 20:47:28,018 training [INFO ] Epoch 14 Batch 5480 Training err. 2.30196 Training err. RA 2.83978 Valid. err. 2.42963
2018-02-03 20:47:28,415 training [INFO ] Epoch 14 Batch 5500 Training err. 2.41793 Training err. RA 2.83825 Valid. err. 2.42673
2018-02-03 20:47:28,811 training [INFO ] Epoch 14 Batch 5520 Training err. 2.43877 Training err. RA 2.83680 Valid. err. 2.43046
2018-02-03 20:47:29,205 training [INFO ] Epoch 14 Batch 5540 Training err. 2.35505 Training err. RA 2.83506 Valid. err. 2.42313
2018-02-03 20:47:29,602 training [INFO ] Epoch 14 Batch 5560 Training err. 2.43382 Training err. RA 2.83362 Valid. err. 2.41074
2018-02-03 20:47:30,000 training [INFO ] Epoch 14 Batch 5580 Training err. 2.34683 Training err. RA 2.83187 Valid. err. 2.42784
2018-02-03 20:47:30,398 training [INFO ] Epoch 14 Batch 5600 Training err. 2.38374 Training err. RA 2.83027 Valid. err. 2.40923
2018-02-03 20:47:30,795 training [INFO ] Epoch 14 Batch 5620 Training err. 2.36744 Training err. RA 2.82863 Valid. err. 2.40726
2018-02-03 20:47:31,194 training [INFO ] Epoch 14 Batch 5640 Training err. 2.41357 Training err. RA 2.82715 Valid. err. 2.40429
2018-02-03 20:47:31,589 training [INFO ] Epoch 14 Batch 5660 Training err. 2.48829 Training err. RA 2.82596 Valid. err. 2.41549
2018-02-03 20:47:31,989 training [INFO ] Epoch 14 Batch 5680 Training err. 2.38187 Training err. RA 2.82439 Valid. err. 2.43807
2018-02-03 20:47:32,386 training [INFO ] Epoch 14 Batch 5700 Training err. 2.37926 Training err. RA 2.82283 Valid. err. 2.41606
2018-02-03 20:47:32,782 training [INFO ] Epoch 14 Batch 5720 Training err. 2.37260 Training err. RA 2.82126 Valid. err. 2.39343
2018-02-03 20:47:33,180 training [INFO ] Epoch 14 Batch 5740 Training err. 2.31642 Training err. RA 2.81950 Valid. err. 2.39864
2018-02-03 20:47:33,577 training [INFO ] Epoch 14 Batch 5760 Training err. 2.35666 Training err. RA 2.81789 Valid. err. 2.39978
2018-02-03 20:47:33,973 training [INFO ] Epoch 14 Batch 5780 Training err. 2.37857 Training err. RA 2.81637 Valid. err. 2.38657
2018-02-03 20:47:34,370 training [INFO ] Epoch 14 Batch 5800 Training err. 2.37591 Training err. RA 2.81485 Valid. err. 2.40689
2018-02-03 20:47:34,767 training [INFO ] Epoch 14 Batch 5820 Training err. 2.37457 Training err. RA 2.81334 Valid. err. 2.38813
2018-02-03 20:47:35,552 training [INFO ] Epoch 15 Batch 5840 Training err. 2.39663 Training err. RA 2.81191 Valid. err. 2.42904
2018-02-03 20:47:35,955 training [INFO ] Epoch 15 Batch 5860 Training err. 2.34128 Training err. RA 2.81031 Valid. err. 2.38707
2018-02-03 20:47:36,354 training [INFO ] Epoch 15 Batch 5880 Training err. 2.33437 Training err. RA 2.80869 Valid. err. 2.39575
2018-02-03 20:47:36,753 training [INFO ] Epoch 15 Batch 5900 Training err. 2.21793 Training err. RA 2.80668 Valid. err. 2.38208
2018-02-03 20:47:37,151 training [INFO ] Epoch 15 Batch 5920 Training err. 2.43304 Training err. RA 2.80542 Valid. err. 2.37692
2018-02-03 20:47:37,548 training [INFO ] Epoch 15 Batch 5940 Training err. 2.36582 Training err. RA 2.80394 Valid. err. 2.37589
2018-02-03 20:47:37,951 training [INFO ] Epoch 15 Batch 5960 Training err. 2.34663 Training err. RA 2.80241 Valid. err. 2.37576
2018-02-03 20:47:38,351 training [INFO ] Epoch 15 Batch 5980 Training err. 2.37513 Training err. RA 2.80098 Valid. err. 2.37371
2018-02-03 20:47:38,749 training [INFO ] Epoch 15 Batch 6000 Training err. 2.30626 Training err. RA 2.79933 Valid. err. 2.37636
2018-02-03 20:47:39,146 training [INFO ] Epoch 15 Batch 6020 Training err. 2.36725 Training err. RA 2.79789 Valid. err. 2.37259
2018-02-03 20:47:39,543 training [INFO ] Epoch 15 Batch 6040 Training err. 2.34333 Training err. RA 2.79639 Valid. err. 2.37362
2018-02-03 20:47:39,940 training [INFO ] Epoch 15 Batch 6060 Training err. 2.35797 Training err. RA 2.79494 Valid. err. 2.39041
2018-02-03 20:47:40,345 training [INFO ] Epoch 15 Batch 6080 Training err. 2.45303 Training err. RA 2.79382 Valid. err. 2.36244
2018-02-03 20:47:40,742 training [INFO ] Epoch 15 Batch 6100 Training err. 2.34680 Training err. RA 2.79235 Valid. err. 2.37898
2018-02-03 20:47:41,141 training [INFO ] Epoch 15 Batch 6120 Training err. 2.33463 Training err. RA 2.79086 Valid. err. 2.36512
2018-02-03 20:47:41,539 training [INFO ] Epoch 15 Batch 6140 Training err. 2.32975 Training err. RA 2.78935 Valid. err. 2.36618
2018-02-03 20:47:41,936 training [INFO ] Epoch 15 Batch 6160 Training err. 2.29144 Training err. RA 2.78774 Valid. err. 2.36732
2018-02-03 20:47:42,337 training [INFO ] Epoch 15 Batch 6180 Training err. 2.32301 Training err. RA 2.78623 Valid. err. 2.35243
2018-02-03 20:47:42,734 training [INFO ] Epoch 15 Batch 6200 Training err. 2.32007 Training err. RA 2.78473 Valid. err. 2.35495
2018-02-03 20:47:43,132 training [INFO ] Epoch 15 Batch 6220 Training err. 2.35604 Training err. RA 2.78335 Valid. err. 2.35228
2018-02-03 20:47:43,530 training [INFO ] Epoch 15 Batch 6240 Training err. 2.33179 Training err. RA 2.78190 Valid. err. 2.34942
2018-02-03 20:47:44,299 training [INFO ] Epoch 16 Batch 6260 Training err. 2.34937 Training err. RA 2.78052 Valid. err. 2.35273
2018-02-03 20:47:44,697 training [INFO ] Epoch 16 Batch 6280 Training err. 2.30886 Training err. RA 2.77902 Valid. err. 2.37102
2018-02-03 20:47:45,095 training [INFO ] Epoch 16 Batch 6300 Training err. 2.29853 Training err. RA 2.77749 Valid. err. 2.35204
2018-02-03 20:47:45,493 training [INFO ] Epoch 16 Batch 6320 Training err. 2.18404 Training err. RA 2.77562 Valid. err. 2.39535
2018-02-03 20:47:45,887 training [INFO ] Epoch 16 Batch 6340 Training err. 2.40022 Training err. RA 2.77443 Valid. err. 2.34552
2018-02-03 20:47:46,286 training [INFO ] Epoch 16 Batch 6360 Training err. 2.31062 Training err. RA 2.77297 Valid. err. 2.34557
2018-02-03 20:47:46,684 training [INFO ] Epoch 16 Batch 6380 Training err. 2.33495 Training err. RA 2.77160 Valid. err. 2.34421
2018-02-03 20:47:47,079 training [INFO ] Epoch 16 Batch 6400 Training err. 2.32685 Training err. RA 2.77021 Valid. err. 2.35981
2018-02-03 20:47:47,478 training [INFO ] Epoch 16 Batch 6420 Training err. 2.26728 Training err. RA 2.76864 Valid. err. 2.34077
2018-02-03 20:47:47,875 training [INFO ] Epoch 16 Batch 6440 Training err. 2.31748 Training err. RA 2.76724 Valid. err. 2.33389
2018-02-03 20:47:48,272 training [INFO ] Epoch 16 Batch 6460 Training err. 2.34385 Training err. RA 2.76593 Valid. err. 2.36420
2018-02-03 20:47:48,670 training [INFO ] Epoch 16 Batch 6480 Training err. 2.33602 Training err. RA 2.76460 Valid. err. 2.37757
2018-02-03 20:47:49,067 training [INFO ] Epoch 16 Batch 6500 Training err. 2.40954 Training err. RA 2.76351 Valid. err. 2.34057
2018-02-03 20:47:49,463 training [INFO ] Epoch 16 Batch 6520 Training err. 2.30789 Training err. RA 2.76211 Valid. err. 2.33131
2018-02-03 20:47:49,861 training [INFO ] Epoch 16 Batch 6540 Training err. 2.29688 Training err. RA 2.76069 Valid. err. 2.33331
2018-02-03 20:47:50,258 training [INFO ] Epoch 16 Batch 6560 Training err. 2.27415 Training err. RA 2.75921 Valid. err. 2.34519
2018-02-03 20:47:50,655 training [INFO ] Epoch 16 Batch 6580 Training err. 2.25283 Training err. RA 2.75767 Valid. err. 2.33314
2018-02-03 20:47:51,054 training [INFO ] Epoch 16 Batch 6600 Training err. 2.31012 Training err. RA 2.75631 Valid. err. 2.32647
2018-02-03 20:47:51,455 training [INFO ] Epoch 16 Batch 6620 Training err. 2.27564 Training err. RA 2.75486 Valid. err. 2.31343
2018-02-03 20:47:51,853 training [INFO ] Epoch 16 Batch 6640 Training err. 2.31450 Training err. RA 2.75353 Valid. err. 2.31713
2018-02-03 20:47:52,252 training [INFO ] Epoch 16 Batch 6660 Training err. 2.30669 Training err. RA 2.75219 Valid. err. 2.30705
2018-02-03 20:47:53,029 training [INFO ] Epoch 17 Batch 6680 Training err. 2.30368 Training err. RA 2.75085 Valid. err. 2.31255
2018-02-03 20:47:53,432 training [INFO ] Epoch 17 Batch 6700 Training err. 2.29862 Training err. RA 2.74950 Valid. err. 2.33168
2018-02-03 20:47:53,831 training [INFO ] Epoch 17 Batch 6720 Training err. 2.24070 Training err. RA 2.74799 Valid. err. 2.30953
2018-02-03 20:47:54,234 training [INFO ] Epoch 17 Batch 6740 Training err. 2.18298 Training err. RA 2.74631 Valid. err. 2.31559
2018-02-03 20:47:54,633 training [INFO ] Epoch 17 Batch 6760 Training err. 2.35034 Training err. RA 2.74514 Valid. err. 2.31339
2018-02-03 20:47:55,029 training [INFO ] Epoch 17 Batch 6780 Training err. 2.28019 Training err. RA 2.74377 Valid. err. 2.36960
2018-02-03 20:47:55,428 training [INFO ] Epoch 17 Batch 6800 Training err. 2.30597 Training err. RA 2.74248 Valid. err. 2.30593
2018-02-03 20:47:55,827 training [INFO ] Epoch 17 Batch 6820 Training err. 2.29110 Training err. RA 2.74115 Valid. err. 2.30237
2018-02-03 20:47:56,227 training [INFO ] Epoch 17 Batch 6840 Training err. 2.23478 Training err. RA 2.73967 Valid. err. 2.32376
2018-02-03 20:47:56,623 training [INFO ] Epoch 17 Batch 6860 Training err. 2.26407 Training err. RA 2.73829 Valid. err. 2.30448
2018-02-03 20:47:57,022 training [INFO ] Epoch 17 Batch 6880 Training err. 2.32838 Training err. RA 2.73710 Valid. err. 2.29507
2018-02-03 20:47:57,420 training [INFO ] Epoch 17 Batch 6900 Training err. 2.33124 Training err. RA 2.73592 Valid. err. 2.30440
2018-02-03 20:47:57,825 training [INFO ] Epoch 17 Batch 6920 Training err. 2.37137 Training err. RA 2.73487 Valid. err. 2.29744
2018-02-03 20:47:58,226 training [INFO ] Epoch 17 Batch 6940 Training err. 2.26547 Training err. RA 2.73351 Valid. err. 2.30303
2018-02-03 20:47:58,628 training [INFO ] Epoch 17 Batch 6960 Training err. 2.27019 Training err. RA 2.73218 Valid. err. 2.32095
2018-02-03 20:47:59,030 training [INFO ] Epoch 17 Batch 6980 Training err. 2.22381 Training err. RA 2.73073 Valid. err. 2.29478
2018-02-03 20:47:59,432 training [INFO ] Epoch 17 Batch 7000 Training err. 2.21345 Training err. RA 2.72925 Valid. err. 2.30484
2018-02-03 20:47:59,836 training [INFO ] Epoch 17 Batch 7020 Training err. 2.29708 Training err. RA 2.72802 Valid. err. 2.28971
2018-02-03 20:48:00,244 training [INFO ] Epoch 17 Batch 7040 Training err. 2.24912 Training err. RA 2.72666 Valid. err. 2.28540
2018-02-03 20:48:00,645 training [INFO ] Epoch 17 Batch 7060 Training err. 2.26116 Training err. RA 2.72534 Valid. err. 2.28045
2018-02-03 20:48:01,045 training [INFO ] Epoch 17 Batch 7080 Training err. 2.27683 Training err. RA 2.72407 Valid. err. 2.29390
2018-02-03 20:48:01,819 training [INFO ] Epoch 18 Batch 7100 Training err. 2.27813 Training err. RA 2.72281 Valid. err. 2.28531
2018-02-03 20:48:02,219 training [INFO ] Epoch 18 Batch 7120 Training err. 2.25124 Training err. RA 2.72149 Valid. err. 2.29067
2018-02-03 20:48:02,617 training [INFO ] Epoch 18 Batch 7140 Training err. 2.19534 Training err. RA 2.72002 Valid. err. 2.28067
2018-02-03 20:48:03,014 training [INFO ] Epoch 18 Batch 7160 Training err. 2.19383 Training err. RA 2.71855 Valid. err. 2.29587
2018-02-03 20:48:03,412 training [INFO ] Epoch 18 Batch 7180 Training err. 2.31483 Training err. RA 2.71742 Valid. err. 2.30821
2018-02-03 20:48:03,810 training [INFO ] Epoch 18 Batch 7200 Training err. 2.24287 Training err. RA 2.71610 Valid. err. 2.29546
2018-02-03 20:48:04,205 training [INFO ] Epoch 18 Batch 7220 Training err. 2.27735 Training err. RA 2.71489 Valid. err. 2.27087
2018-02-03 20:48:04,604 training [INFO ] Epoch 18 Batch 7240 Training err. 2.24970 Training err. RA 2.71360 Valid. err. 2.28095
2018-02-03 20:48:05,006 training [INFO ] Epoch 18 Batch 7260 Training err. 2.21553 Training err. RA 2.71223 Valid. err. 2.29620
2018-02-03 20:48:05,404 training [INFO ] Epoch 18 Batch 7280 Training err. 2.23832 Training err. RA 2.71093 Valid. err. 2.27986
2018-02-03 20:48:05,802 training [INFO ] Epoch 18 Batch 7300 Training err. 2.29003 Training err. RA 2.70978 Valid. err. 2.26510
2018-02-03 20:48:06,203 training [INFO ] Epoch 18 Batch 7320 Training err. 2.32225 Training err. RA 2.70872 Valid. err. 2.28153
2018-02-03 20:48:06,606 training [INFO ] Epoch 18 Batch 7340 Training err. 2.31256 Training err. RA 2.70764 Valid. err. 2.27202
2018-02-03 20:48:07,008 training [INFO ] Epoch 18 Batch 7360 Training err. 2.24705 Training err. RA 2.70639 Valid. err. 2.26334
2018-02-03 20:48:07,410 training [INFO ] Epoch 18 Batch 7380 Training err. 2.24186 Training err. RA 2.70513 Valid. err. 2.28871
2018-02-03 20:48:07,813 training [INFO ] Epoch 18 Batch 7400 Training err. 2.18431 Training err. RA 2.70372 Valid. err. 2.27180
2018-02-03 20:48:08,216 training [INFO ] Epoch 18 Batch 7420 Training err. 2.19276 Training err. RA 2.70234 Valid. err. 2.27366
2018-02-03 20:48:08,617 training [INFO ] Epoch 18 Batch 7440 Training err. 2.27309 Training err. RA 2.70119 Valid. err. 2.25694
2018-02-03 20:48:09,018 training [INFO ] Epoch 18 Batch 7460 Training err. 2.22413 Training err. RA 2.69991 Valid. err. 2.25466
2018-02-03 20:48:09,418 training [INFO ] Epoch 18 Batch 7480 Training err. 2.22598 Training err. RA 2.69864 Valid. err. 2.26866
2018-02-03 20:48:09,816 training [INFO ] Epoch 18 Batch 7500 Training err. 2.23987 Training err. RA 2.69742 Valid. err. 2.24716
2018-02-03 20:48:10,598 training [INFO ] Epoch 19 Batch 7520 Training err. 2.27258 Training err. RA 2.69629 Valid. err. 2.25390
2018-02-03 20:48:10,999 training [INFO ] Epoch 19 Batch 7540 Training err. 2.18737 Training err. RA 2.69494 Valid. err. 2.26277
2018-02-03 20:48:11,400 training [INFO ] Epoch 19 Batch 7560 Training err. 2.15751 Training err. RA 2.69352 Valid. err. 2.24650
2018-02-03 20:48:11,797 training [INFO ] Epoch 19 Batch 7580 Training err. 2.20300 Training err. RA 2.69222 Valid. err. 2.25299
2018-02-03 20:48:12,193 training [INFO ] Epoch 19 Batch 7600 Training err. 2.27560 Training err. RA 2.69113 Valid. err. 2.25715
2018-02-03 20:48:12,593 training [INFO ] Epoch 19 Batch 7620 Training err. 2.19604 Training err. RA 2.68983 Valid. err. 2.25521
2018-02-03 20:48:12,990 training [INFO ] Epoch 19 Batch 7640 Training err. 2.28083 Training err. RA 2.68876 Valid. err. 2.27577
2018-02-03 20:48:13,391 training [INFO ] Epoch 19 Batch 7660 Training err. 2.21277 Training err. RA 2.68751 Valid. err. 2.24792
2018-02-03 20:48:13,789 training [INFO ] Epoch 19 Batch 7680 Training err. 2.19564 Training err. RA 2.68623 Valid. err. 2.24761
2018-02-03 20:48:14,189 training [INFO ] Epoch 19 Batch 7700 Training err. 2.21509 Training err. RA 2.68501 Valid. err. 2.24324
2018-02-03 20:48:14,585 training [INFO ] Epoch 19 Batch 7720 Training err. 2.24171 Training err. RA 2.68386 Valid. err. 2.24071
2018-02-03 20:48:14,984 training [INFO ] Epoch 19 Batch 7740 Training err. 2.32385 Training err. RA 2.68293 Valid. err. 2.23853
2018-02-03 20:48:15,381 training [INFO ] Epoch 19 Batch 7760 Training err. 2.25558 Training err. RA 2.68183 Valid. err. 2.24068
2018-02-03 20:48:15,778 training [INFO ] Epoch 19 Batch 7780 Training err. 2.20897 Training err. RA 2.68061 Valid. err. 2.23903
2018-02-03 20:48:16,179 training [INFO ] Epoch 19 Batch 7800 Training err. 2.21528 Training err. RA 2.67942 Valid. err. 2.25596
2018-02-03 20:48:16,574 training [INFO ] Epoch 19 Batch 7820 Training err. 2.16276 Training err. RA 2.67810 Valid. err. 2.24222
2018-02-03 20:48:16,974 training [INFO ] Epoch 19 Batch 7840 Training err. 2.17022 Training err. RA 2.67680 Valid. err. 2.23163
2018-02-03 20:48:17,372 training [INFO ] Epoch 19 Batch 7860 Training err. 2.23828 Training err. RA 2.67569 Valid. err. 2.23484
2018-02-03 20:48:17,774 training [INFO ] Epoch 19 Batch 7880 Training err. 2.20486 Training err. RA 2.67449 Valid. err. 2.22823
2018-02-03 20:48:18,178 training [INFO ] Epoch 19 Batch 7900 Training err. 2.20087 Training err. RA 2.67329 Valid. err. 2.24041
2018-02-03 20:48:18,580 training [INFO ] Epoch 19 Batch 7920 Training err. 2.20711 Training err. RA 2.67212 Valid. err. 2.24995
2018-02-03 20:48:19,356 training [INFO ] Epoch 20 Batch 7940 Training err. 2.24668 Training err. RA 2.67104 Valid. err. 2.22668
2018-02-03 20:48:19,757 training [INFO ] Epoch 20 Batch 7960 Training err. 2.15065 Training err. RA 2.66974 Valid. err. 2.25092
2018-02-03 20:48:20,162 training [INFO ] Epoch 20 Batch 7980 Training err. 2.13117 Training err. RA 2.66839 Valid. err. 2.23423
2018-02-03 20:48:20,560 training [INFO ] Epoch 20 Batch 8000 Training err. 2.18751 Training err. RA 2.66718 Valid. err. 2.23425
2018-02-03 20:48:20,962 training [INFO ] Epoch 20 Batch 8020 Training err. 2.25850 Training err. RA 2.66617 Valid. err. 2.23368
2018-02-03 20:48:21,360 training [INFO ] Epoch 20 Batch 8040 Training err. 2.15575 Training err. RA 2.66490 Valid. err. 2.23472
2018-02-03 20:48:21,761 training [INFO ] Epoch 20 Batch 8060 Training err. 2.28139 Training err. RA 2.66394 Valid. err. 2.22672
2018-02-03 20:48:22,162 training [INFO ] Epoch 20 Batch 8080 Training err. 2.16357 Training err. RA 2.66271 Valid. err. 2.24621
2018-02-03 20:48:22,559 training [INFO ] Epoch 20 Batch 8100 Training err. 2.17768 Training err. RA 2.66151 Valid. err. 2.22301
2018-02-03 20:48:22,959 training [INFO ] Epoch 20 Batch 8120 Training err. 2.18617 Training err. RA 2.66034 Valid. err. 2.21370
2018-02-03 20:48:23,355 training [INFO ] Epoch 20 Batch 8140 Training err. 2.21089 Training err. RA 2.65923 Valid. err. 2.21836
2018-02-03 20:48:23,758 training [INFO ] Epoch 20 Batch 8160 Training err. 2.30177 Training err. RA 2.65836 Valid. err. 2.24754
2018-02-03 20:48:24,169 training [INFO ] Epoch 20 Batch 8180 Training err. 2.22139 Training err. RA 2.65729 Valid. err. 2.24704
2018-02-03 20:48:24,568 training [INFO ] Epoch 20 Batch 8200 Training err. 2.19298 Training err. RA 2.65616 Valid. err. 2.21405
2018-02-03 20:48:24,966 training [INFO ] Epoch 20 Batch 8220 Training err. 2.19378 Training err. RA 2.65503 Valid. err. 2.21902
2018-02-03 20:48:25,363 training [INFO ] Epoch 20 Batch 8240 Training err. 2.13234 Training err. RA 2.65376 Valid. err. 2.22955
2018-02-03 20:48:25,770 training [INFO ] Epoch 20 Batch 8260 Training err. 2.16186 Training err. RA 2.65257 Valid. err. 2.21263
2018-02-03 20:48:26,178 training [INFO ] Epoch 20 Batch 8280 Training err. 2.20131 Training err. RA 2.65148 Valid. err. 2.23058
2018-02-03 20:48:26,581 training [INFO ] Epoch 20 Batch 8300 Training err. 2.17594 Training err. RA 2.65033 Valid. err. 2.20715
2018-02-03 20:48:26,990 training [INFO ] Epoch 20 Batch 8320 Training err. 2.17640 Training err. RA 2.64920 Valid. err. 2.22461
2018-02-03 20:48:27,391 training [INFO ] Epoch 20 Batch 8340 Training err. 2.20478 Training err. RA 2.64813 Valid. err. 2.21835
2018-02-03 20:48:27,689 __main__ [INFO ] End of training
2018-02-03 20:48:27,963 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 64,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:48:28,517 training [INFO ] Epoch  1 Batch   20 Training err. 3.60094 Training err. RA 3.60094 Valid. err. 3.38397
2018-02-03 20:48:28,919 training [INFO ] Epoch  1 Batch   40 Training err. 3.18841 Training err. RA 3.39467 Valid. err. 3.22766
2018-02-03 20:48:29,324 training [INFO ] Epoch  1 Batch   60 Training err. 3.10404 Training err. RA 3.29779 Valid. err. 3.20567
2018-02-03 20:48:29,723 training [INFO ] Epoch  1 Batch   80 Training err. 3.17114 Training err. RA 3.26613 Valid. err. 3.19169
2018-02-03 20:48:30,121 training [INFO ] Epoch  1 Batch  100 Training err. 3.13958 Training err. RA 3.24082 Valid. err. 3.21999
2018-02-03 20:48:30,521 training [INFO ] Epoch  1 Batch  120 Training err. 3.12388 Training err. RA 3.22133 Valid. err. 3.18170
2018-02-03 20:48:30,917 training [INFO ] Epoch  1 Batch  140 Training err. 3.13234 Training err. RA 3.20862 Valid. err. 3.26673
2018-02-03 20:48:31,319 training [INFO ] Epoch  1 Batch  160 Training err. 3.10267 Training err. RA 3.19537 Valid. err. 3.32465
2018-02-03 20:48:31,721 training [INFO ] Epoch  1 Batch  180 Training err. 3.13147 Training err. RA 3.18827 Valid. err. 3.15881
2018-02-03 20:48:32,117 training [INFO ] Epoch  1 Batch  200 Training err. 3.09227 Training err. RA 3.17867 Valid. err. 3.13391
2018-02-03 20:48:32,518 training [INFO ] Epoch  1 Batch  220 Training err. 3.11214 Training err. RA 3.17262 Valid. err. 3.12033
2018-02-03 20:48:32,910 training [INFO ] Epoch  1 Batch  240 Training err. 3.07836 Training err. RA 3.16477 Valid. err. 3.10914
2018-02-03 20:48:33,312 training [INFO ] Epoch  1 Batch  260 Training err. 3.01890 Training err. RA 3.15355 Valid. err. 3.06263
2018-02-03 20:48:33,717 training [INFO ] Epoch  1 Batch  280 Training err. 2.99534 Training err. RA 3.14225 Valid. err. 3.04889
2018-02-03 20:48:34,115 training [INFO ] Epoch  1 Batch  300 Training err. 2.95366 Training err. RA 3.12968 Valid. err. 2.96392
2018-02-03 20:48:34,520 training [INFO ] Epoch  1 Batch  320 Training err. 2.81938 Training err. RA 3.11028 Valid. err. 2.94732
2018-02-03 20:48:34,922 training [INFO ] Epoch  1 Batch  340 Training err. 2.90776 Training err. RA 3.09837 Valid. err. 2.86256
2018-02-03 20:48:35,328 training [INFO ] Epoch  1 Batch  360 Training err. 2.81305 Training err. RA 3.08252 Valid. err. 2.86224
2018-02-03 20:48:35,735 training [INFO ] Epoch  1 Batch  380 Training err. 2.80806 Training err. RA 3.06807 Valid. err. 2.81660
2018-02-03 20:48:36,138 training [INFO ] Epoch  1 Batch  400 Training err. 2.78222 Training err. RA 3.05378 Valid. err. 2.76105
2018-02-03 20:48:36,922 training [INFO ] Epoch  2 Batch  420 Training err. 2.76136 Training err. RA 3.03986 Valid. err. 2.83660
2018-02-03 20:48:37,327 training [INFO ] Epoch  2 Batch  440 Training err. 2.67849 Training err. RA 3.02343 Valid. err. 2.99769
2018-02-03 20:48:37,727 training [INFO ] Epoch  2 Batch  460 Training err. 2.65659 Training err. RA 3.00748 Valid. err. 2.68488
2018-02-03 20:48:38,124 training [INFO ] Epoch  2 Batch  480 Training err. 2.48599 Training err. RA 2.98575 Valid. err. 2.68146
2018-02-03 20:48:38,522 training [INFO ] Epoch  2 Batch  500 Training err. 2.70076 Training err. RA 2.97435 Valid. err. 2.60885
2018-02-03 20:48:38,919 training [INFO ] Epoch  2 Batch  520 Training err. 2.57601 Training err. RA 2.95903 Valid. err. 2.63505
2018-02-03 20:48:39,318 training [INFO ] Epoch  2 Batch  540 Training err. 2.54384 Training err. RA 2.94365 Valid. err. 2.57735
2018-02-03 20:48:39,718 training [INFO ] Epoch  2 Batch  560 Training err. 2.58660 Training err. RA 2.93090 Valid. err. 2.57610
2018-02-03 20:48:40,115 training [INFO ] Epoch  2 Batch  580 Training err. 2.47347 Training err. RA 2.91513 Valid. err. 2.54486
2018-02-03 20:48:40,513 training [INFO ] Epoch  2 Batch  600 Training err. 2.49608 Training err. RA 2.90116 Valid. err. 2.51320
2018-02-03 20:48:40,908 training [INFO ] Epoch  2 Batch  620 Training err. 2.49351 Training err. RA 2.88801 Valid. err. 2.50469
2018-02-03 20:48:41,310 training [INFO ] Epoch  2 Batch  640 Training err. 2.47051 Training err. RA 2.87496 Valid. err. 2.47364
2018-02-03 20:48:41,712 training [INFO ] Epoch  2 Batch  660 Training err. 2.52558 Training err. RA 2.86438 Valid. err. 2.46093
2018-02-03 20:48:42,117 training [INFO ] Epoch  2 Batch  680 Training err. 2.42282 Training err. RA 2.85139 Valid. err. 2.46056
2018-02-03 20:48:42,513 training [INFO ] Epoch  2 Batch  700 Training err. 2.40317 Training err. RA 2.83858 Valid. err. 2.43444
2018-02-03 20:48:42,909 training [INFO ] Epoch  2 Batch  720 Training err. 2.35302 Training err. RA 2.82509 Valid. err. 2.43477
2018-02-03 20:48:43,311 training [INFO ] Epoch  2 Batch  740 Training err. 2.33497 Training err. RA 2.81185 Valid. err. 2.39905
2018-02-03 20:48:43,711 training [INFO ] Epoch  2 Batch  760 Training err. 2.36139 Training err. RA 2.79999 Valid. err. 2.38370
2018-02-03 20:48:44,106 training [INFO ] Epoch  2 Batch  780 Training err. 2.33403 Training err. RA 2.78805 Valid. err. 2.38018
2018-02-03 20:48:44,507 training [INFO ] Epoch  2 Batch  800 Training err. 2.36365 Training err. RA 2.77744 Valid. err. 2.37564
2018-02-03 20:48:44,904 training [INFO ] Epoch  2 Batch  820 Training err. 2.31041 Training err. RA 2.76605 Valid. err. 2.33424
2018-02-03 20:48:45,689 training [INFO ] Epoch  3 Batch  840 Training err. 2.31317 Training err. RA 2.75526 Valid. err. 2.33096
2018-02-03 20:48:46,096 training [INFO ] Epoch  3 Batch  860 Training err. 2.28651 Training err. RA 2.74436 Valid. err. 2.41145
2018-02-03 20:48:46,500 training [INFO ] Epoch  3 Batch  880 Training err. 2.26925 Training err. RA 2.73356 Valid. err. 2.30209
2018-02-03 20:48:46,902 training [INFO ] Epoch  3 Batch  900 Training err. 2.12282 Training err. RA 2.71999 Valid. err. 2.31318
2018-02-03 20:48:47,302 training [INFO ] Epoch  3 Batch  920 Training err. 2.33161 Training err. RA 2.71155 Valid. err. 2.27807
2018-02-03 20:48:47,709 training [INFO ] Epoch  3 Batch  940 Training err. 2.24399 Training err. RA 2.70160 Valid. err. 2.27321
2018-02-03 20:48:48,113 training [INFO ] Epoch  3 Batch  960 Training err. 2.24979 Training err. RA 2.69219 Valid. err. 2.27113
2018-02-03 20:48:48,516 training [INFO ] Epoch  3 Batch  980 Training err. 2.25371 Training err. RA 2.68324 Valid. err. 2.27251
2018-02-03 20:48:48,917 training [INFO ] Epoch  3 Batch 1000 Training err. 2.18420 Training err. RA 2.67326 Valid. err. 2.32608
2018-02-03 20:48:49,322 training [INFO ] Epoch  3 Batch 1020 Training err. 2.20128 Training err. RA 2.66400 Valid. err. 2.24238
2018-02-03 20:48:49,723 training [INFO ] Epoch  3 Batch 1040 Training err. 2.26582 Training err. RA 2.65635 Valid. err. 2.26551
2018-02-03 20:48:50,122 training [INFO ] Epoch  3 Batch 1060 Training err. 2.24290 Training err. RA 2.64855 Valid. err. 2.26788
2018-02-03 20:48:50,525 training [INFO ] Epoch  3 Batch 1080 Training err. 2.27671 Training err. RA 2.64166 Valid. err. 2.21986
2018-02-03 20:48:50,921 training [INFO ] Epoch  3 Batch 1100 Training err. 2.18358 Training err. RA 2.63333 Valid. err. 2.22772
2018-02-03 20:48:51,321 training [INFO ] Epoch  3 Batch 1120 Training err. 2.15866 Training err. RA 2.62485 Valid. err. 2.21939
2018-02-03 20:48:51,722 training [INFO ] Epoch  3 Batch 1140 Training err. 2.11497 Training err. RA 2.61591 Valid. err. 2.21502
2018-02-03 20:48:52,119 training [INFO ] Epoch  3 Batch 1160 Training err. 2.12351 Training err. RA 2.60742 Valid. err. 2.20257
2018-02-03 20:48:52,520 training [INFO ] Epoch  3 Batch 1180 Training err. 2.16450 Training err. RA 2.59991 Valid. err. 2.20992
2018-02-03 20:48:52,915 training [INFO ] Epoch  3 Batch 1200 Training err. 2.13029 Training err. RA 2.59209 Valid. err. 2.15359
2018-02-03 20:48:53,319 training [INFO ] Epoch  3 Batch 1220 Training err. 2.15017 Training err. RA 2.58484 Valid. err. 2.17905
2018-02-03 20:48:53,722 training [INFO ] Epoch  3 Batch 1240 Training err. 2.11074 Training err. RA 2.57719 Valid. err. 2.17574
2018-02-03 20:48:54,511 training [INFO ] Epoch  4 Batch 1260 Training err. 2.10615 Training err. RA 2.56972 Valid. err. 2.13311
2018-02-03 20:48:54,913 training [INFO ] Epoch  4 Batch 1280 Training err. 2.12785 Training err. RA 2.56281 Valid. err. 2.13381
2018-02-03 20:48:55,320 training [INFO ] Epoch  4 Batch 1300 Training err. 2.05017 Training err. RA 2.55493 Valid. err. 2.14695
2018-02-03 20:48:55,725 training [INFO ] Epoch  4 Batch 1320 Training err. 2.00989 Training err. RA 2.54667 Valid. err. 2.15612
2018-02-03 20:48:56,129 training [INFO ] Epoch  4 Batch 1340 Training err. 2.12077 Training err. RA 2.54031 Valid. err. 2.12061
2018-02-03 20:48:56,533 training [INFO ] Epoch  4 Batch 1360 Training err. 2.08336 Training err. RA 2.53359 Valid. err. 2.13506
2018-02-03 20:48:56,937 training [INFO ] Epoch  4 Batch 1380 Training err. 2.11712 Training err. RA 2.52756 Valid. err. 2.10183
2018-02-03 20:48:57,341 training [INFO ] Epoch  4 Batch 1400 Training err. 2.07877 Training err. RA 2.52114 Valid. err. 2.10469
2018-02-03 20:48:57,744 training [INFO ] Epoch  4 Batch 1420 Training err. 2.05720 Training err. RA 2.51461 Valid. err. 2.12718
2018-02-03 20:48:58,144 training [INFO ] Epoch  4 Batch 1440 Training err. 2.04251 Training err. RA 2.50805 Valid. err. 2.10107
2018-02-03 20:48:58,545 training [INFO ] Epoch  4 Batch 1460 Training err. 2.08794 Training err. RA 2.50230 Valid. err. 2.08825
2018-02-03 20:48:58,941 training [INFO ] Epoch  4 Batch 1480 Training err. 2.12371 Training err. RA 2.49718 Valid. err. 2.08128
2018-02-03 20:48:59,345 training [INFO ] Epoch  4 Batch 1500 Training err. 2.13168 Training err. RA 2.49231 Valid. err. 2.08728
2018-02-03 20:48:59,742 training [INFO ] Epoch  4 Batch 1520 Training err. 2.04044 Training err. RA 2.48636 Valid. err. 2.08348
2018-02-03 20:49:00,149 training [INFO ] Epoch  4 Batch 1540 Training err. 2.02961 Training err. RA 2.48043 Valid. err. 2.09902
2018-02-03 20:49:00,548 training [INFO ] Epoch  4 Batch 1560 Training err. 1.97001 Training err. RA 2.47389 Valid. err. 2.11449
2018-02-03 20:49:00,946 training [INFO ] Epoch  4 Batch 1580 Training err. 1.99419 Training err. RA 2.46782 Valid. err. 2.05403
2018-02-03 20:49:01,345 training [INFO ] Epoch  4 Batch 1600 Training err. 2.05100 Training err. RA 2.46261 Valid. err. 2.06905
2018-02-03 20:49:01,744 training [INFO ] Epoch  4 Batch 1620 Training err. 1.99682 Training err. RA 2.45685 Valid. err. 2.19022
2018-02-03 20:49:02,142 training [INFO ] Epoch  4 Batch 1640 Training err. 1.99849 Training err. RA 2.45126 Valid. err. 2.04612
2018-02-03 20:49:02,540 training [INFO ] Epoch  4 Batch 1660 Training err. 1.98905 Training err. RA 2.44570 Valid. err. 2.04243
2018-02-03 20:49:03,300 training [INFO ] Epoch  5 Batch 1680 Training err. 1.99269 Training err. RA 2.44030 Valid. err. 2.03943
2018-02-03 20:49:03,701 training [INFO ] Epoch  5 Batch 1700 Training err. 1.98746 Training err. RA 2.43498 Valid. err. 2.03585
2018-02-03 20:49:04,099 training [INFO ] Epoch  5 Batch 1720 Training err. 1.93211 Training err. RA 2.42913 Valid. err. 2.06062
2018-02-03 20:49:04,497 training [INFO ] Epoch  5 Batch 1740 Training err. 1.91721 Training err. RA 2.42324 Valid. err. 2.02894
2018-02-03 20:49:04,896 training [INFO ] Epoch  5 Batch 1760 Training err. 2.03241 Training err. RA 2.41880 Valid. err. 2.05524
2018-02-03 20:49:05,296 training [INFO ] Epoch  5 Batch 1780 Training err. 1.94829 Training err. RA 2.41352 Valid. err. 2.04106
2018-02-03 20:49:05,734 training [INFO ] Epoch  5 Batch 1800 Training err. 2.03226 Training err. RA 2.40928 Valid. err. 2.02200
2018-02-03 20:49:06,132 training [INFO ] Epoch  5 Batch 1820 Training err. 1.97685 Training err. RA 2.40453 Valid. err. 2.06382
2018-02-03 20:49:06,531 training [INFO ] Epoch  5 Batch 1840 Training err. 1.93228 Training err. RA 2.39939 Valid. err. 2.02403
2018-02-03 20:49:06,928 training [INFO ] Epoch  5 Batch 1860 Training err. 1.93445 Training err. RA 2.39440 Valid. err. 2.00367
2018-02-03 20:49:07,332 training [INFO ] Epoch  5 Batch 1880 Training err. 1.97954 Training err. RA 2.38998 Valid. err. 1.99384
2018-02-03 20:49:07,735 training [INFO ] Epoch  5 Batch 1900 Training err. 2.03397 Training err. RA 2.38623 Valid. err. 1.99556
2018-02-03 20:49:08,133 training [INFO ] Epoch  5 Batch 1920 Training err. 2.00639 Training err. RA 2.38228 Valid. err. 1.98885
2018-02-03 20:49:08,535 training [INFO ] Epoch  5 Batch 1940 Training err. 1.94897 Training err. RA 2.37781 Valid. err. 1.98913
2018-02-03 20:49:08,931 training [INFO ] Epoch  5 Batch 1960 Training err. 1.92800 Training err. RA 2.37322 Valid. err. 2.00148
2018-02-03 20:49:09,333 training [INFO ] Epoch  5 Batch 1980 Training err. 1.87559 Training err. RA 2.36819 Valid. err. 1.99262
2018-02-03 20:49:09,733 training [INFO ] Epoch  5 Batch 2000 Training err. 1.91301 Training err. RA 2.36364 Valid. err. 1.99634
2018-02-03 20:49:10,132 training [INFO ] Epoch  5 Batch 2020 Training err. 1.93125 Training err. RA 2.35936 Valid. err. 1.97460
2018-02-03 20:49:10,533 training [INFO ] Epoch  5 Batch 2040 Training err. 1.93625 Training err. RA 2.35521 Valid. err. 1.97276
2018-02-03 20:49:10,929 training [INFO ] Epoch  5 Batch 2060 Training err. 1.89395 Training err. RA 2.35074 Valid. err. 1.95688
2018-02-03 20:49:11,332 training [INFO ] Epoch  5 Batch 2080 Training err. 1.87437 Training err. RA 2.34615 Valid. err. 1.97267
2018-02-03 20:49:12,093 training [INFO ] Epoch  6 Batch 2100 Training err. 1.94864 Training err. RA 2.34237 Valid. err. 1.94808
2018-02-03 20:49:12,495 training [INFO ] Epoch  6 Batch 2120 Training err. 1.85669 Training err. RA 2.33779 Valid. err. 1.96104
2018-02-03 20:49:12,894 training [INFO ] Epoch  6 Batch 2140 Training err. 1.83996 Training err. RA 2.33313 Valid. err. 1.95984
2018-02-03 20:49:13,295 training [INFO ] Epoch  6 Batch 2160 Training err. 1.85425 Training err. RA 2.32870 Valid. err. 1.94717
2018-02-03 20:49:13,692 training [INFO ] Epoch  6 Batch 2180 Training err. 1.93876 Training err. RA 2.32512 Valid. err. 1.94687
2018-02-03 20:49:14,092 training [INFO ] Epoch  6 Batch 2200 Training err. 1.86169 Training err. RA 2.32091 Valid. err. 1.94597
2018-02-03 20:49:14,494 training [INFO ] Epoch  6 Batch 2220 Training err. 1.96842 Training err. RA 2.31773 Valid. err. 1.95127
2018-02-03 20:49:14,893 training [INFO ] Epoch  6 Batch 2240 Training err. 1.88164 Training err. RA 2.31384 Valid. err. 1.94173
2018-02-03 20:49:15,296 training [INFO ] Epoch  6 Batch 2260 Training err. 1.86077 Training err. RA 2.30983 Valid. err. 1.94656
2018-02-03 20:49:15,696 training [INFO ] Epoch  6 Batch 2280 Training err. 1.85643 Training err. RA 2.30585 Valid. err. 1.95221
2018-02-03 20:49:16,092 training [INFO ] Epoch  6 Batch 2300 Training err. 1.89560 Training err. RA 2.30229 Valid. err. 1.91449
2018-02-03 20:49:16,490 training [INFO ] Epoch  6 Batch 2320 Training err. 1.96194 Training err. RA 2.29935 Valid. err. 1.91066
2018-02-03 20:49:16,893 training [INFO ] Epoch  6 Batch 2340 Training err. 1.89943 Training err. RA 2.29593 Valid. err. 1.92098
2018-02-03 20:49:17,295 training [INFO ] Epoch  6 Batch 2360 Training err. 1.85711 Training err. RA 2.29222 Valid. err. 1.90876
2018-02-03 20:49:17,693 training [INFO ] Epoch  6 Batch 2380 Training err. 1.86330 Training err. RA 2.28861 Valid. err. 1.92409
2018-02-03 20:49:18,100 training [INFO ] Epoch  6 Batch 2400 Training err. 1.78041 Training err. RA 2.28438 Valid. err. 1.91446
2018-02-03 20:49:18,500 training [INFO ] Epoch  6 Batch 2420 Training err. 1.85736 Training err. RA 2.28085 Valid. err. 1.92295
2018-02-03 20:49:18,900 training [INFO ] Epoch  6 Batch 2440 Training err. 1.85198 Training err. RA 2.27733 Valid. err. 1.90077
2018-02-03 20:49:19,302 training [INFO ] Epoch  6 Batch 2460 Training err. 1.85211 Training err. RA 2.27387 Valid. err. 1.89570
2018-02-03 20:49:19,700 training [INFO ] Epoch  6 Batch 2480 Training err. 1.81765 Training err. RA 2.27020 Valid. err. 1.89167
2018-02-03 20:49:20,102 training [INFO ] Epoch  6 Batch 2500 Training err. 1.82078 Training err. RA 2.26660 Valid. err. 1.88629
2018-02-03 20:49:20,884 training [INFO ] Epoch  7 Batch 2520 Training err. 1.87897 Training err. RA 2.26352 Valid. err. 1.86821
2018-02-03 20:49:21,291 training [INFO ] Epoch  7 Batch 2540 Training err. 1.78306 Training err. RA 2.25974 Valid. err. 1.89223
2018-02-03 20:49:21,688 training [INFO ] Epoch  7 Batch 2560 Training err. 1.77230 Training err. RA 2.25593 Valid. err. 1.89363
2018-02-03 20:49:22,086 training [INFO ] Epoch  7 Batch 2580 Training err. 1.78024 Training err. RA 2.25224 Valid. err. 1.87785
2018-02-03 20:49:22,486 training [INFO ] Epoch  7 Batch 2600 Training err. 1.88265 Training err. RA 2.24940 Valid. err. 1.88250
2018-02-03 20:49:22,885 training [INFO ] Epoch  7 Batch 2620 Training err. 1.79811 Training err. RA 2.24596 Valid. err. 1.90256
2018-02-03 20:49:23,287 training [INFO ] Epoch  7 Batch 2640 Training err. 1.91623 Training err. RA 2.24346 Valid. err. 1.88956
2018-02-03 20:49:23,686 training [INFO ] Epoch  7 Batch 2660 Training err. 1.79806 Training err. RA 2.24011 Valid. err. 1.87896
2018-02-03 20:49:24,095 training [INFO ] Epoch  7 Batch 2680 Training err. 1.78622 Training err. RA 2.23672 Valid. err. 1.87057
2018-02-03 20:49:24,496 training [INFO ] Epoch  7 Batch 2700 Training err. 1.80010 Training err. RA 2.23349 Valid. err. 1.86547
2018-02-03 20:49:24,893 training [INFO ] Epoch  7 Batch 2720 Training err. 1.83317 Training err. RA 2.23055 Valid. err. 1.88131
2018-02-03 20:49:25,291 training [INFO ] Epoch  7 Batch 2740 Training err. 1.88333 Training err. RA 2.22801 Valid. err. 1.86404
2018-02-03 20:49:25,687 training [INFO ] Epoch  7 Batch 2760 Training err. 1.83877 Training err. RA 2.22519 Valid. err. 1.84999
2018-02-03 20:49:26,087 training [INFO ] Epoch  7 Batch 2780 Training err. 1.79391 Training err. RA 2.22209 Valid. err. 1.88717
2018-02-03 20:49:26,495 training [INFO ] Epoch  7 Batch 2800 Training err. 1.79588 Training err. RA 2.21904 Valid. err. 1.86617
2018-02-03 20:49:26,894 training [INFO ] Epoch  7 Batch 2820 Training err. 1.73305 Training err. RA 2.21560 Valid. err. 1.87093
2018-02-03 20:49:27,302 training [INFO ] Epoch  7 Batch 2840 Training err. 1.80711 Training err. RA 2.21272 Valid. err. 1.86000
2018-02-03 20:49:27,703 training [INFO ] Epoch  7 Batch 2860 Training err. 1.77188 Training err. RA 2.20964 Valid. err. 1.85133
2018-02-03 20:49:28,110 training [INFO ] Epoch  7 Batch 2880 Training err. 1.77942 Training err. RA 2.20665 Valid. err. 1.82866
2018-02-03 20:49:28,520 training [INFO ] Epoch  7 Batch 2900 Training err. 1.76798 Training err. RA 2.20362 Valid. err. 1.84271
2018-02-03 20:49:29,306 training [INFO ] Epoch  8 Batch 2920 Training err. 1.78953 Training err. RA 2.20079 Valid. err. 2.08794
2018-02-03 20:49:29,706 training [INFO ] Epoch  8 Batch 2940 Training err. 1.81949 Training err. RA 2.19819 Valid. err. 1.83608
2018-02-03 20:49:30,105 training [INFO ] Epoch  8 Batch 2960 Training err. 1.75059 Training err. RA 2.19517 Valid. err. 1.82751
2018-02-03 20:49:30,507 training [INFO ] Epoch  8 Batch 2980 Training err. 1.67029 Training err. RA 2.19165 Valid. err. 1.83930
2018-02-03 20:49:30,903 training [INFO ] Epoch  8 Batch 3000 Training err. 1.77416 Training err. RA 2.18886 Valid. err. 1.85780
2018-02-03 20:49:31,305 training [INFO ] Epoch  8 Batch 3020 Training err. 1.80287 Training err. RA 2.18631 Valid. err. 1.84758
2018-02-03 20:49:31,703 training [INFO ] Epoch  8 Batch 3040 Training err. 1.76424 Training err. RA 2.18353 Valid. err. 1.83555
2018-02-03 20:49:32,101 training [INFO ] Epoch  8 Batch 3060 Training err. 1.84226 Training err. RA 2.18130 Valid. err. 1.82306
2018-02-03 20:49:32,501 training [INFO ] Epoch  8 Batch 3080 Training err. 1.73380 Training err. RA 2.17839 Valid. err. 1.85024
2018-02-03 20:49:32,898 training [INFO ] Epoch  8 Batch 3100 Training err. 1.75538 Training err. RA 2.17566 Valid. err. 1.84520
2018-02-03 20:49:33,298 training [INFO ] Epoch  8 Batch 3120 Training err. 1.75436 Training err. RA 2.17296 Valid. err. 1.81172
2018-02-03 20:49:33,698 training [INFO ] Epoch  8 Batch 3140 Training err. 1.76926 Training err. RA 2.17039 Valid. err. 1.81859
2018-02-03 20:49:34,102 training [INFO ] Epoch  8 Batch 3160 Training err. 1.84241 Training err. RA 2.16832 Valid. err. 1.81728
2018-02-03 20:49:34,501 training [INFO ] Epoch  8 Batch 3180 Training err. 1.76444 Training err. RA 2.16578 Valid. err. 1.83409
2018-02-03 20:49:34,895 training [INFO ] Epoch  8 Batch 3200 Training err. 1.73964 Training err. RA 2.16311 Valid. err. 1.80816
2018-02-03 20:49:35,300 training [INFO ] Epoch  8 Batch 3220 Training err. 1.73591 Training err. RA 2.16046 Valid. err. 1.81972
2018-02-03 20:49:35,698 training [INFO ] Epoch  8 Batch 3240 Training err. 1.70670 Training err. RA 2.15766 Valid. err. 1.79760
2018-02-03 20:49:36,099 training [INFO ] Epoch  8 Batch 3260 Training err. 1.74336 Training err. RA 2.15512 Valid. err. 1.83655
2018-02-03 20:49:36,498 training [INFO ] Epoch  8 Batch 3280 Training err. 1.70843 Training err. RA 2.15239 Valid. err. 1.78482
2018-02-03 20:49:36,896 training [INFO ] Epoch  8 Batch 3300 Training err. 1.73910 Training err. RA 2.14989 Valid. err. 1.82436
2018-02-03 20:49:37,299 training [INFO ] Epoch  8 Batch 3320 Training err. 1.71886 Training err. RA 2.14729 Valid. err. 1.79125
2018-02-03 20:49:38,082 training [INFO ] Epoch  9 Batch 3340 Training err. 1.73301 Training err. RA 2.14481 Valid. err. 1.79834
2018-02-03 20:49:38,490 training [INFO ] Epoch  9 Batch 3360 Training err. 1.71320 Training err. RA 2.14224 Valid. err. 1.77605
2018-02-03 20:49:38,890 training [INFO ] Epoch  9 Batch 3380 Training err. 1.70235 Training err. RA 2.13964 Valid. err. 1.78071
2018-02-03 20:49:39,294 training [INFO ] Epoch  9 Batch 3400 Training err. 1.62192 Training err. RA 2.13659 Valid. err. 1.77945
2018-02-03 20:49:39,696 training [INFO ] Epoch  9 Batch 3420 Training err. 1.75822 Training err. RA 2.13438 Valid. err. 1.78623
2018-02-03 20:49:40,104 training [INFO ] Epoch  9 Batch 3440 Training err. 1.72277 Training err. RA 2.13199 Valid. err. 1.79472
2018-02-03 20:49:40,512 training [INFO ] Epoch  9 Batch 3460 Training err. 1.75026 Training err. RA 2.12978 Valid. err. 1.78316
2018-02-03 20:49:40,916 training [INFO ] Epoch  9 Batch 3480 Training err. 1.76672 Training err. RA 2.12770 Valid. err. 1.77703
2018-02-03 20:49:41,320 training [INFO ] Epoch  9 Batch 3500 Training err. 1.70588 Training err. RA 2.12528 Valid. err. 1.80488
2018-02-03 20:49:41,721 training [INFO ] Epoch  9 Batch 3520 Training err. 1.70204 Training err. RA 2.12288 Valid. err. 1.78566
2018-02-03 20:49:42,121 training [INFO ] Epoch  9 Batch 3540 Training err. 1.70359 Training err. RA 2.12051 Valid. err. 1.77139
2018-02-03 20:49:42,521 training [INFO ] Epoch  9 Batch 3560 Training err. 1.74410 Training err. RA 2.11840 Valid. err. 1.78134
2018-02-03 20:49:42,918 training [INFO ] Epoch  9 Batch 3580 Training err. 1.78169 Training err. RA 2.11652 Valid. err. 1.79431
2018-02-03 20:49:43,319 training [INFO ] Epoch  9 Batch 3600 Training err. 1.71202 Training err. RA 2.11427 Valid. err. 1.79234
2018-02-03 20:49:43,716 training [INFO ] Epoch  9 Batch 3620 Training err. 1.68721 Training err. RA 2.11191 Valid. err. 1.78551
2018-02-03 20:49:44,115 training [INFO ] Epoch  9 Batch 3640 Training err. 1.68715 Training err. RA 2.10957 Valid. err. 1.78809
2018-02-03 20:49:44,517 training [INFO ] Epoch  9 Batch 3660 Training err. 1.66800 Training err. RA 2.10716 Valid. err. 1.77347
2018-02-03 20:49:44,914 training [INFO ] Epoch  9 Batch 3680 Training err. 1.68661 Training err. RA 2.10488 Valid. err. 1.77060
2018-02-03 20:49:45,313 training [INFO ] Epoch  9 Batch 3700 Training err. 1.66177 Training err. RA 2.10248 Valid. err. 1.76335
2018-02-03 20:49:45,713 training [INFO ] Epoch  9 Batch 3720 Training err. 1.70697 Training err. RA 2.10035 Valid. err. 1.74959
2018-02-03 20:49:46,111 training [INFO ] Epoch  9 Batch 3740 Training err. 1.65826 Training err. RA 2.09799 Valid. err. 1.75389
2018-02-03 20:49:46,882 training [INFO ] Epoch 10 Batch 3760 Training err. 1.66962 Training err. RA 2.09571 Valid. err. 1.75670
2018-02-03 20:49:47,283 training [INFO ] Epoch 10 Batch 3780 Training err. 1.69172 Training err. RA 2.09357 Valid. err. 1.75893
2018-02-03 20:49:47,681 training [INFO ] Epoch 10 Batch 3800 Training err. 1.64968 Training err. RA 2.09124 Valid. err. 1.74131
2018-02-03 20:49:48,090 training [INFO ] Epoch 10 Batch 3820 Training err. 1.58971 Training err. RA 2.08861 Valid. err. 1.76632
2018-02-03 20:49:48,487 training [INFO ] Epoch 10 Batch 3840 Training err. 1.70972 Training err. RA 2.08664 Valid. err. 1.77018
2018-02-03 20:49:48,883 training [INFO ] Epoch 10 Batch 3860 Training err. 1.67381 Training err. RA 2.08450 Valid. err. 1.76974
2018-02-03 20:49:49,282 training [INFO ] Epoch 10 Batch 3880 Training err. 1.73206 Training err. RA 2.08268 Valid. err. 1.74037
2018-02-03 20:49:49,680 training [INFO ] Epoch 10 Batch 3900 Training err. 1.70530 Training err. RA 2.08075 Valid. err. 1.75472
2018-02-03 20:49:50,080 training [INFO ] Epoch 10 Batch 3920 Training err. 1.66632 Training err. RA 2.07863 Valid. err. 1.75641
2018-02-03 20:49:50,477 training [INFO ] Epoch 10 Batch 3940 Training err. 1.63192 Training err. RA 2.07637 Valid. err. 1.74677
2018-02-03 20:49:50,876 training [INFO ] Epoch 10 Batch 3960 Training err. 1.70951 Training err. RA 2.07451 Valid. err. 1.72999
2018-02-03 20:49:51,279 training [INFO ] Epoch 10 Batch 3980 Training err. 1.70570 Training err. RA 2.07266 Valid. err. 1.74337
2018-02-03 20:49:51,680 training [INFO ] Epoch 10 Batch 4000 Training err. 1.74154 Training err. RA 2.07100 Valid. err. 1.75747
2018-02-03 20:49:52,079 training [INFO ] Epoch 10 Batch 4020 Training err. 1.65861 Training err. RA 2.06895 Valid. err. 1.73947
2018-02-03 20:49:52,480 training [INFO ] Epoch 10 Batch 4040 Training err. 1.64285 Training err. RA 2.06684 Valid. err. 1.74867
2018-02-03 20:49:52,881 training [INFO ] Epoch 10 Batch 4060 Training err. 1.62457 Training err. RA 2.06466 Valid. err. 1.74181
2018-02-03 20:49:53,285 training [INFO ] Epoch 10 Batch 4080 Training err. 1.63253 Training err. RA 2.06255 Valid. err. 1.75220
2018-02-03 20:49:53,685 training [INFO ] Epoch 10 Batch 4100 Training err. 1.66101 Training err. RA 2.06059 Valid. err. 1.73040
2018-02-03 20:49:54,087 training [INFO ] Epoch 10 Batch 4120 Training err. 1.62118 Training err. RA 2.05845 Valid. err. 1.72167
2018-02-03 20:49:54,487 training [INFO ] Epoch 10 Batch 4140 Training err. 1.66265 Training err. RA 2.05654 Valid. err. 1.72453
2018-02-03 20:49:54,885 training [INFO ] Epoch 10 Batch 4160 Training err. 1.62771 Training err. RA 2.05448 Valid. err. 1.72128
2018-02-03 20:49:55,662 training [INFO ] Epoch 11 Batch 4180 Training err. 1.60062 Training err. RA 2.05231 Valid. err. 1.72468
2018-02-03 20:49:56,060 training [INFO ] Epoch 11 Batch 4200 Training err. 1.65710 Training err. RA 2.05043 Valid. err. 1.74426
2018-02-03 20:49:56,458 training [INFO ] Epoch 11 Batch 4220 Training err. 1.59573 Training err. RA 2.04827 Valid. err. 1.73946
2018-02-03 20:49:56,859 training [INFO ] Epoch 11 Batch 4240 Training err. 1.56592 Training err. RA 2.04600 Valid. err. 1.71602
2018-02-03 20:49:57,259 training [INFO ] Epoch 11 Batch 4260 Training err. 1.68576 Training err. RA 2.04431 Valid. err. 1.72784
2018-02-03 20:49:57,662 training [INFO ] Epoch 11 Batch 4280 Training err. 1.63095 Training err. RA 2.04237 Valid. err. 1.73622
2018-02-03 20:49:58,066 training [INFO ] Epoch 11 Batch 4300 Training err. 1.71993 Training err. RA 2.04087 Valid. err. 1.71566
2018-02-03 20:49:58,469 training [INFO ] Epoch 11 Batch 4320 Training err. 1.64989 Training err. RA 2.03906 Valid. err. 1.71977
2018-02-03 20:49:58,868 training [INFO ] Epoch 11 Batch 4340 Training err. 1.63479 Training err. RA 2.03720 Valid. err. 1.73469
2018-02-03 20:49:59,273 training [INFO ] Epoch 11 Batch 4360 Training err. 1.59956 Training err. RA 2.03519 Valid. err. 1.70506
2018-02-03 20:49:59,678 training [INFO ] Epoch 11 Batch 4380 Training err. 1.65048 Training err. RA 2.03344 Valid. err. 1.71596
2018-02-03 20:50:00,085 training [INFO ] Epoch 11 Batch 4400 Training err. 1.68659 Training err. RA 2.03186 Valid. err. 1.72847
2018-02-03 20:50:00,495 training [INFO ] Epoch 11 Batch 4420 Training err. 1.68723 Training err. RA 2.03030 Valid. err. 1.72890
2018-02-03 20:50:00,896 training [INFO ] Epoch 11 Batch 4440 Training err. 1.62476 Training err. RA 2.02847 Valid. err. 1.72203
2018-02-03 20:50:01,304 training [INFO ] Epoch 11 Batch 4460 Training err. 1.60745 Training err. RA 2.02659 Valid. err. 1.72636
2018-02-03 20:50:01,705 training [INFO ] Epoch 11 Batch 4480 Training err. 1.58513 Training err. RA 2.02462 Valid. err. 1.71960
2018-02-03 20:50:02,103 training [INFO ] Epoch 11 Batch 4500 Training err. 1.59990 Training err. RA 2.02273 Valid. err. 1.69221
2018-02-03 20:50:02,504 training [INFO ] Epoch 11 Batch 4520 Training err. 1.62744 Training err. RA 2.02098 Valid. err. 1.69551
2018-02-03 20:50:02,900 training [INFO ] Epoch 11 Batch 4540 Training err. 1.58531 Training err. RA 2.01906 Valid. err. 1.68590
2018-02-03 20:50:03,303 training [INFO ] Epoch 11 Batch 4560 Training err. 1.61487 Training err. RA 2.01729 Valid. err. 1.70826
2018-02-03 20:50:03,697 training [INFO ] Epoch 11 Batch 4580 Training err. 1.59705 Training err. RA 2.01545 Valid. err. 1.68204
2018-02-03 20:50:04,474 training [INFO ] Epoch 12 Batch 4600 Training err. 1.60073 Training err. RA 2.01365 Valid. err. 1.68094
2018-02-03 20:50:04,872 training [INFO ] Epoch 12 Batch 4620 Training err. 1.58531 Training err. RA 2.01179 Valid. err. 1.70015
2018-02-03 20:50:05,276 training [INFO ] Epoch 12 Batch 4640 Training err. 1.56041 Training err. RA 2.00985 Valid. err. 1.72426
2018-02-03 20:50:05,675 training [INFO ] Epoch 12 Batch 4660 Training err. 1.55510 Training err. RA 2.00790 Valid. err. 1.70030
2018-02-03 20:50:06,078 training [INFO ] Epoch 12 Batch 4680 Training err. 1.65850 Training err. RA 2.00640 Valid. err. 1.69294
2018-02-03 20:50:06,487 training [INFO ] Epoch 12 Batch 4700 Training err. 1.57373 Training err. RA 2.00456 Valid. err. 1.70244
2018-02-03 20:50:06,888 training [INFO ] Epoch 12 Batch 4720 Training err. 1.70765 Training err. RA 2.00330 Valid. err. 1.69882
2018-02-03 20:50:07,293 training [INFO ] Epoch 12 Batch 4740 Training err. 1.62211 Training err. RA 2.00170 Valid. err. 1.69835
2018-02-03 20:50:07,696 training [INFO ] Epoch 12 Batch 4760 Training err. 1.58042 Training err. RA 1.99993 Valid. err. 1.70419
2018-02-03 20:50:08,101 training [INFO ] Epoch 12 Batch 4780 Training err. 1.56388 Training err. RA 1.99810 Valid. err. 1.69138
2018-02-03 20:50:08,508 training [INFO ] Epoch 12 Batch 4800 Training err. 1.61334 Training err. RA 1.99650 Valid. err. 1.68069
2018-02-03 20:50:08,911 training [INFO ] Epoch 12 Batch 4820 Training err. 1.66141 Training err. RA 1.99511 Valid. err. 1.69866
2018-02-03 20:50:09,315 training [INFO ] Epoch 12 Batch 4840 Training err. 1.63786 Training err. RA 1.99363 Valid. err. 1.70189
2018-02-03 20:50:09,710 training [INFO ] Epoch 12 Batch 4860 Training err. 1.59756 Training err. RA 1.99200 Valid. err. 1.68283
2018-02-03 20:50:10,112 training [INFO ] Epoch 12 Batch 4880 Training err. 1.59353 Training err. RA 1.99037 Valid. err. 1.68842
2018-02-03 20:50:10,511 training [INFO ] Epoch 12 Batch 4900 Training err. 1.53506 Training err. RA 1.98851 Valid. err. 1.69814
2018-02-03 20:50:10,909 training [INFO ] Epoch 12 Batch 4920 Training err. 1.57874 Training err. RA 1.98684 Valid. err. 1.72397
2018-02-03 20:50:11,311 training [INFO ] Epoch 12 Batch 4940 Training err. 1.57660 Training err. RA 1.98518 Valid. err. 1.69566
2018-02-03 20:50:11,710 training [INFO ] Epoch 12 Batch 4960 Training err. 1.56051 Training err. RA 1.98347 Valid. err. 1.66355
2018-02-03 20:50:12,118 training [INFO ] Epoch 12 Batch 4980 Training err. 1.58910 Training err. RA 1.98189 Valid. err. 1.67408
2018-02-03 20:50:12,517 training [INFO ] Epoch 12 Batch 5000 Training err. 1.55289 Training err. RA 1.98017 Valid. err. 1.68395
2018-02-03 20:50:13,276 training [INFO ] Epoch 13 Batch 5020 Training err. 1.57808 Training err. RA 1.97857 Valid. err. 1.65883
2018-02-03 20:50:13,676 training [INFO ] Epoch 13 Batch 5040 Training err. 1.54064 Training err. RA 1.97683 Valid. err. 1.67595
2018-02-03 20:50:14,078 training [INFO ] Epoch 13 Batch 5060 Training err. 1.52047 Training err. RA 1.97503 Valid. err. 1.70013
2018-02-03 20:50:14,476 training [INFO ] Epoch 13 Batch 5080 Training err. 1.52792 Training err. RA 1.97327 Valid. err. 1.69579
2018-02-03 20:50:14,878 training [INFO ] Epoch 13 Batch 5100 Training err. 1.62754 Training err. RA 1.97191 Valid. err. 1.66820
2018-02-03 20:50:15,286 training [INFO ] Epoch 13 Batch 5120 Training err. 1.56439 Training err. RA 1.97032 Valid. err. 1.69464
2018-02-03 20:50:15,687 training [INFO ] Epoch 13 Batch 5140 Training err. 1.68708 Training err. RA 1.96922 Valid. err. 1.67094
2018-02-03 20:50:16,095 training [INFO ] Epoch 13 Batch 5160 Training err. 1.56547 Training err. RA 1.96765 Valid. err. 1.68859
2018-02-03 20:50:16,499 training [INFO ] Epoch 13 Batch 5180 Training err. 1.55008 Training err. RA 1.96604 Valid. err. 1.68067
2018-02-03 20:50:16,902 training [INFO ] Epoch 13 Batch 5200 Training err. 1.54080 Training err. RA 1.96441 Valid. err. 1.67489
2018-02-03 20:50:17,309 training [INFO ] Epoch 13 Batch 5220 Training err. 1.58892 Training err. RA 1.96297 Valid. err. 1.66189
2018-02-03 20:50:17,707 training [INFO ] Epoch 13 Batch 5240 Training err. 1.62325 Training err. RA 1.96167 Valid. err. 1.66806
2018-02-03 20:50:18,106 training [INFO ] Epoch 13 Batch 5260 Training err. 1.60944 Training err. RA 1.96033 Valid. err. 1.66892
2018-02-03 20:50:18,506 training [INFO ] Epoch 13 Batch 5280 Training err. 1.54617 Training err. RA 1.95876 Valid. err. 1.66600
2018-02-03 20:50:18,905 training [INFO ] Epoch 13 Batch 5300 Training err. 1.56958 Training err. RA 1.95729 Valid. err. 1.66134
2018-02-03 20:50:19,309 training [INFO ] Epoch 13 Batch 5320 Training err. 1.51140 Training err. RA 1.95562 Valid. err. 1.67003
2018-02-03 20:50:19,707 training [INFO ] Epoch 13 Batch 5340 Training err. 1.54198 Training err. RA 1.95407 Valid. err. 1.66526
2018-02-03 20:50:20,110 training [INFO ] Epoch 13 Batch 5360 Training err. 1.54349 Training err. RA 1.95254 Valid. err. 1.65777
2018-02-03 20:50:20,508 training [INFO ] Epoch 13 Batch 5380 Training err. 1.53636 Training err. RA 1.95099 Valid. err. 1.65013
2018-02-03 20:50:20,906 training [INFO ] Epoch 13 Batch 5400 Training err. 1.55703 Training err. RA 1.94953 Valid. err. 1.65813
2018-02-03 20:50:21,307 training [INFO ] Epoch 13 Batch 5420 Training err. 1.53223 Training err. RA 1.94799 Valid. err. 1.63872
2018-02-03 20:50:22,082 training [INFO ] Epoch 14 Batch 5440 Training err. 1.56353 Training err. RA 1.94658 Valid. err. 1.64557
2018-02-03 20:50:22,488 training [INFO ] Epoch 14 Batch 5460 Training err. 1.50367 Training err. RA 1.94495 Valid. err. 1.65484
2018-02-03 20:50:22,890 training [INFO ] Epoch 14 Batch 5480 Training err. 1.47694 Training err. RA 1.94325 Valid. err. 1.65866
2018-02-03 20:50:23,295 training [INFO ] Epoch 14 Batch 5500 Training err. 1.50967 Training err. RA 1.94167 Valid. err. 1.66300
2018-02-03 20:50:23,699 training [INFO ] Epoch 14 Batch 5520 Training err. 1.60299 Training err. RA 1.94044 Valid. err. 1.65567
2018-02-03 20:50:24,110 training [INFO ] Epoch 14 Batch 5540 Training err. 1.54027 Training err. RA 1.93900 Valid. err. 1.67137
2018-02-03 20:50:24,519 training [INFO ] Epoch 14 Batch 5560 Training err. 1.63742 Training err. RA 1.93791 Valid. err. 1.66515
2018-02-03 20:50:24,918 training [INFO ] Epoch 14 Batch 5580 Training err. 1.53523 Training err. RA 1.93647 Valid. err. 1.66081
2018-02-03 20:50:25,324 training [INFO ] Epoch 14 Batch 5600 Training err. 1.52282 Training err. RA 1.93499 Valid. err. 1.65219
2018-02-03 20:50:25,726 training [INFO ] Epoch 14 Batch 5620 Training err. 1.52159 Training err. RA 1.93352 Valid. err. 1.65418
2018-02-03 20:50:26,125 training [INFO ] Epoch 14 Batch 5640 Training err. 1.56752 Training err. RA 1.93222 Valid. err. 1.64220
2018-02-03 20:50:26,526 training [INFO ] Epoch 14 Batch 5660 Training err. 1.59715 Training err. RA 1.93104 Valid. err. 1.66304
2018-02-03 20:50:26,924 training [INFO ] Epoch 14 Batch 5680 Training err. 1.56315 Training err. RA 1.92974 Valid. err. 1.66007
2018-02-03 20:50:27,326 training [INFO ] Epoch 14 Batch 5700 Training err. 1.53663 Training err. RA 1.92836 Valid. err. 1.64793
2018-02-03 20:50:27,725 training [INFO ] Epoch 14 Batch 5720 Training err. 1.52298 Training err. RA 1.92695 Valid. err. 1.64888
2018-02-03 20:50:28,122 training [INFO ] Epoch 14 Batch 5740 Training err. 1.49822 Training err. RA 1.92545 Valid. err. 1.65265
2018-02-03 20:50:28,521 training [INFO ] Epoch 14 Batch 5760 Training err. 1.52989 Training err. RA 1.92408 Valid. err. 1.64972
2018-02-03 20:50:28,919 training [INFO ] Epoch 14 Batch 5780 Training err. 1.48955 Training err. RA 1.92258 Valid. err. 1.63875
2018-02-03 20:50:29,317 training [INFO ] Epoch 14 Batch 5800 Training err. 1.51388 Training err. RA 1.92117 Valid. err. 1.63035
2018-02-03 20:50:29,716 training [INFO ] Epoch 14 Batch 5820 Training err. 1.52426 Training err. RA 1.91980 Valid. err. 1.62380
2018-02-03 20:50:30,512 training [INFO ] Epoch 15 Batch 5840 Training err. 1.52943 Training err. RA 1.91847 Valid. err. 1.63294
2018-02-03 20:50:30,916 training [INFO ] Epoch 15 Batch 5860 Training err. 1.48499 Training err. RA 1.91699 Valid. err. 1.62679
2018-02-03 20:50:31,323 training [INFO ] Epoch 15 Batch 5880 Training err. 1.50393 Training err. RA 1.91558 Valid. err. 1.64264
2018-02-03 20:50:31,724 training [INFO ] Epoch 15 Batch 5900 Training err. 1.42576 Training err. RA 1.91392 Valid. err. 1.63372
2018-02-03 20:50:32,132 training [INFO ] Epoch 15 Batch 5920 Training err. 1.53715 Training err. RA 1.91265 Valid. err. 1.64804
2018-02-03 20:50:32,539 training [INFO ] Epoch 15 Batch 5940 Training err. 1.54870 Training err. RA 1.91142 Valid. err. 1.65616
2018-02-03 20:50:32,939 training [INFO ] Epoch 15 Batch 5960 Training err. 1.52800 Training err. RA 1.91014 Valid. err. 1.64501
2018-02-03 20:50:33,346 training [INFO ] Epoch 15 Batch 5980 Training err. 1.59624 Training err. RA 1.90909 Valid. err. 1.65105
2018-02-03 20:50:33,744 training [INFO ] Epoch 15 Batch 6000 Training err. 1.51460 Training err. RA 1.90777 Valid. err. 1.65021
2018-02-03 20:50:34,145 training [INFO ] Epoch 15 Batch 6020 Training err. 1.50020 Training err. RA 1.90642 Valid. err. 1.64576
2018-02-03 20:50:34,547 training [INFO ] Epoch 15 Batch 6040 Training err. 1.49811 Training err. RA 1.90507 Valid. err. 1.64940
2018-02-03 20:50:34,942 training [INFO ] Epoch 15 Batch 6060 Training err. 1.53406 Training err. RA 1.90384 Valid. err. 1.63698
2018-02-03 20:50:35,343 training [INFO ] Epoch 15 Batch 6080 Training err. 1.57945 Training err. RA 1.90277 Valid. err. 1.66239
2018-02-03 20:50:35,740 training [INFO ] Epoch 15 Batch 6100 Training err. 1.53647 Training err. RA 1.90157 Valid. err. 1.63625
2018-02-03 20:50:36,141 training [INFO ] Epoch 15 Batch 6120 Training err. 1.48752 Training err. RA 1.90022 Valid. err. 1.66233
2018-02-03 20:50:36,538 training [INFO ] Epoch 15 Batch 6140 Training err. 1.49859 Training err. RA 1.89891 Valid. err. 1.64801
2018-02-03 20:50:36,935 training [INFO ] Epoch 15 Batch 6160 Training err. 1.48948 Training err. RA 1.89758 Valid. err. 1.63730
2018-02-03 20:50:37,336 training [INFO ] Epoch 15 Batch 6180 Training err. 1.48471 Training err. RA 1.89625 Valid. err. 1.62911
2018-02-03 20:50:37,734 training [INFO ] Epoch 15 Batch 6200 Training err. 1.45915 Training err. RA 1.89484 Valid. err. 1.62068
2018-02-03 20:50:38,132 training [INFO ] Epoch 15 Batch 6220 Training err. 1.50687 Training err. RA 1.89359 Valid. err. 1.63901
2018-02-03 20:50:38,531 training [INFO ] Epoch 15 Batch 6240 Training err. 1.49486 Training err. RA 1.89231 Valid. err. 1.60829
2018-02-03 20:50:39,318 training [INFO ] Epoch 16 Batch 6260 Training err. 1.47821 Training err. RA 1.89099 Valid. err. 1.62878
2018-02-03 20:50:39,719 training [INFO ] Epoch 16 Batch 6280 Training err. 1.46609 Training err. RA 1.88963 Valid. err. 1.64021
2018-02-03 20:50:40,122 training [INFO ] Epoch 16 Batch 6300 Training err. 1.48398 Training err. RA 1.88835 Valid. err. 1.65493
2018-02-03 20:50:40,526 training [INFO ] Epoch 16 Batch 6320 Training err. 1.41173 Training err. RA 1.88684 Valid. err. 1.63240
2018-02-03 20:50:40,931 training [INFO ] Epoch 16 Batch 6340 Training err. 1.51896 Training err. RA 1.88568 Valid. err. 1.63216
2018-02-03 20:50:41,333 training [INFO ] Epoch 16 Batch 6360 Training err. 1.50935 Training err. RA 1.88449 Valid. err. 1.63939
2018-02-03 20:50:41,728 training [INFO ] Epoch 16 Batch 6380 Training err. 1.52778 Training err. RA 1.88338 Valid. err. 1.63812
2018-02-03 20:50:42,125 training [INFO ] Epoch 16 Batch 6400 Training err. 1.55500 Training err. RA 1.88235 Valid. err. 1.63643
2018-02-03 20:50:42,521 training [INFO ] Epoch 16 Batch 6420 Training err. 1.49896 Training err. RA 1.88116 Valid. err. 1.63486
2018-02-03 20:50:42,922 training [INFO ] Epoch 16 Batch 6440 Training err. 1.45240 Training err. RA 1.87982 Valid. err. 1.63150
2018-02-03 20:50:43,319 training [INFO ] Epoch 16 Batch 6460 Training err. 1.50107 Training err. RA 1.87865 Valid. err. 1.62656
2018-02-03 20:50:43,713 training [INFO ] Epoch 16 Batch 6480 Training err. 1.52451 Training err. RA 1.87756 Valid. err. 1.62636
2018-02-03 20:50:44,109 training [INFO ] Epoch 16 Batch 6500 Training err. 1.55320 Training err. RA 1.87656 Valid. err. 1.64763
2018-02-03 20:50:44,506 training [INFO ] Epoch 16 Batch 6520 Training err. 1.49891 Training err. RA 1.87540 Valid. err. 1.62686
2018-02-03 20:50:44,911 training [INFO ] Epoch 16 Batch 6540 Training err. 1.44105 Training err. RA 1.87407 Valid. err. 1.63524
2018-02-03 20:50:45,309 training [INFO ] Epoch 16 Batch 6560 Training err. 1.47178 Training err. RA 1.87285 Valid. err. 1.61667
2018-02-03 20:50:45,706 training [INFO ] Epoch 16 Batch 6580 Training err. 1.46850 Training err. RA 1.87162 Valid. err. 1.64407
2018-02-03 20:50:46,109 training [INFO ] Epoch 16 Batch 6600 Training err. 1.45795 Training err. RA 1.87036 Valid. err. 1.61912
2018-02-03 20:50:46,513 training [INFO ] Epoch 16 Batch 6620 Training err. 1.43514 Training err. RA 1.86905 Valid. err. 1.61309
2018-02-03 20:50:46,919 training [INFO ] Epoch 16 Batch 6640 Training err. 1.49599 Training err. RA 1.86793 Valid. err. 1.64275
2018-02-03 20:50:47,322 training [INFO ] Epoch 16 Batch 6660 Training err. 1.46893 Training err. RA 1.86673 Valid. err. 1.60363
2018-02-03 20:50:48,085 training [INFO ] Epoch 17 Batch 6680 Training err. 1.42786 Training err. RA 1.86541 Valid. err. 1.62225
2018-02-03 20:50:48,490 training [INFO ] Epoch 17 Batch 6700 Training err. 1.48063 Training err. RA 1.86427 Valid. err. 1.62355
2018-02-03 20:50:48,894 training [INFO ] Epoch 17 Batch 6720 Training err. 1.44820 Training err. RA 1.86303 Valid. err. 1.61173
2018-02-03 20:50:49,297 training [INFO ] Epoch 17 Batch 6740 Training err. 1.39737 Training err. RA 1.86165 Valid. err. 1.63556
2018-02-03 20:50:49,694 training [INFO ] Epoch 17 Batch 6760 Training err. 1.49434 Training err. RA 1.86056 Valid. err. 1.62411
2018-02-03 20:50:50,089 training [INFO ] Epoch 17 Batch 6780 Training err. 1.48199 Training err. RA 1.85944 Valid. err. 1.64319
2018-02-03 20:50:50,486 training [INFO ] Epoch 17 Batch 6800 Training err. 1.52828 Training err. RA 1.85847 Valid. err. 1.62724
2018-02-03 20:50:50,887 training [INFO ] Epoch 17 Batch 6820 Training err. 1.50050 Training err. RA 1.85742 Valid. err. 1.64724
2018-02-03 20:50:51,280 training [INFO ] Epoch 17 Batch 6840 Training err. 1.48659 Training err. RA 1.85633 Valid. err. 1.63162
2018-02-03 20:50:51,677 training [INFO ] Epoch 17 Batch 6860 Training err. 1.40546 Training err. RA 1.85502 Valid. err. 1.61704
2018-02-03 20:50:52,074 training [INFO ] Epoch 17 Batch 6880 Training err. 1.50332 Training err. RA 1.85400 Valid. err. 1.60891
2018-02-03 20:50:52,471 training [INFO ] Epoch 17 Batch 6900 Training err. 1.49562 Training err. RA 1.85296 Valid. err. 1.63083
2018-02-03 20:50:52,868 training [INFO ] Epoch 17 Batch 6920 Training err. 1.53689 Training err. RA 1.85204 Valid. err. 1.63508
2018-02-03 20:50:53,263 training [INFO ] Epoch 17 Batch 6940 Training err. 1.47116 Training err. RA 1.85095 Valid. err. 1.63849
2018-02-03 20:50:53,661 training [INFO ] Epoch 17 Batch 6960 Training err. 1.43496 Training err. RA 1.84975 Valid. err. 1.64850
2018-02-03 20:50:54,076 training [INFO ] Epoch 17 Batch 6980 Training err. 1.40882 Training err. RA 1.84849 Valid. err. 1.64592
2018-02-03 20:50:54,477 training [INFO ] Epoch 17 Batch 7000 Training err. 1.44650 Training err. RA 1.84734 Valid. err. 1.62865
2018-02-03 20:50:54,884 training [INFO ] Epoch 17 Batch 7020 Training err. 1.44996 Training err. RA 1.84621 Valid. err. 1.62406
2018-02-03 20:50:55,283 training [INFO ] Epoch 17 Batch 7040 Training err. 1.40753 Training err. RA 1.84496 Valid. err. 1.60194
2018-02-03 20:50:55,685 training [INFO ] Epoch 17 Batch 7060 Training err. 1.47354 Training err. RA 1.84391 Valid. err. 1.60870
2018-02-03 20:50:56,089 training [INFO ] Epoch 17 Batch 7080 Training err. 1.44524 Training err. RA 1.84278 Valid. err. 1.61884
2018-02-03 20:50:56,858 training [INFO ] Epoch 18 Batch 7100 Training err. 1.41471 Training err. RA 1.84158 Valid. err. 1.60984
2018-02-03 20:50:57,258 training [INFO ] Epoch 18 Batch 7120 Training err. 1.44467 Training err. RA 1.84046 Valid. err. 1.61075
2018-02-03 20:50:57,659 training [INFO ] Epoch 18 Batch 7140 Training err. 1.41452 Training err. RA 1.83927 Valid. err. 1.62073
2018-02-03 20:50:58,052 training [INFO ] Epoch 18 Batch 7160 Training err. 1.39791 Training err. RA 1.83804 Valid. err. 1.65046
2018-02-03 20:50:58,453 training [INFO ] Epoch 18 Batch 7180 Training err. 1.49604 Training err. RA 1.83708 Valid. err. 1.61684
2018-02-03 20:50:58,851 training [INFO ] Epoch 18 Batch 7200 Training err. 1.43591 Training err. RA 1.83597 Valid. err. 1.63858
2018-02-03 20:50:59,243 training [INFO ] Epoch 18 Batch 7220 Training err. 1.52618 Training err. RA 1.83511 Valid. err. 1.61364
2018-02-03 20:50:59,640 training [INFO ] Epoch 18 Batch 7240 Training err. 1.47424 Training err. RA 1.83411 Valid. err. 1.63249
2018-02-03 20:51:00,037 training [INFO ] Epoch 18 Batch 7260 Training err. 1.43630 Training err. RA 1.83302 Valid. err. 1.62652
2018-02-03 20:51:00,446 training [INFO ] Epoch 18 Batch 7280 Training err. 1.40810 Training err. RA 1.83185 Valid. err. 1.60703
2018-02-03 20:51:00,840 training [INFO ] Epoch 18 Batch 7300 Training err. 1.46442 Training err. RA 1.83084 Valid. err. 1.60690
2018-02-03 20:51:01,236 training [INFO ] Epoch 18 Batch 7320 Training err. 1.49361 Training err. RA 1.82992 Valid. err. 1.63201
2018-02-03 20:51:01,635 training [INFO ] Epoch 18 Batch 7340 Training err. 1.49536 Training err. RA 1.82901 Valid. err. 1.64677
2018-02-03 20:51:02,036 training [INFO ] Epoch 18 Batch 7360 Training err. 1.44081 Training err. RA 1.82796 Valid. err. 1.62007
2018-02-03 20:51:02,441 training [INFO ] Epoch 18 Batch 7380 Training err. 1.42727 Training err. RA 1.82687 Valid. err. 1.62786
2018-02-03 20:51:02,843 training [INFO ] Epoch 18 Batch 7400 Training err. 1.37842 Training err. RA 1.82566 Valid. err. 1.62501
2018-02-03 20:51:03,243 training [INFO ] Epoch 18 Batch 7420 Training err. 1.43408 Training err. RA 1.82460 Valid. err. 1.60576
2018-02-03 20:51:03,647 training [INFO ] Epoch 18 Batch 7440 Training err. 1.41982 Training err. RA 1.82351 Valid. err. 1.59963
2018-02-03 20:51:04,051 training [INFO ] Epoch 18 Batch 7460 Training err. 1.39729 Training err. RA 1.82237 Valid. err. 1.59232
2018-02-03 20:51:04,455 training [INFO ] Epoch 18 Batch 7480 Training err. 1.45769 Training err. RA 1.82140 Valid. err. 1.60758
2018-02-03 20:51:04,857 training [INFO ] Epoch 18 Batch 7500 Training err. 1.41356 Training err. RA 1.82031 Valid. err. 1.58595
2018-02-03 20:51:05,622 training [INFO ] Epoch 19 Batch 7520 Training err. 1.41763 Training err. RA 1.81924 Valid. err. 1.61865
2018-02-03 20:51:06,019 training [INFO ] Epoch 19 Batch 7540 Training err. 1.40296 Training err. RA 1.81813 Valid. err. 1.60033
2018-02-03 20:51:06,421 training [INFO ] Epoch 19 Batch 7560 Training err. 1.38348 Training err. RA 1.81698 Valid. err. 1.65083
2018-02-03 20:51:06,817 training [INFO ] Epoch 19 Batch 7580 Training err. 1.39636 Training err. RA 1.81587 Valid. err. 1.60836
2018-02-03 20:51:07,212 training [INFO ] Epoch 19 Batch 7600 Training err. 1.47964 Training err. RA 1.81499 Valid. err. 1.60880
2018-02-03 20:51:07,607 training [INFO ] Epoch 19 Batch 7620 Training err. 1.40809 Training err. RA 1.81392 Valid. err. 1.62139
2018-02-03 20:51:08,004 training [INFO ] Epoch 19 Batch 7640 Training err. 1.52496 Training err. RA 1.81317 Valid. err. 1.61889
2018-02-03 20:51:08,403 training [INFO ] Epoch 19 Batch 7660 Training err. 1.44450 Training err. RA 1.81220 Valid. err. 1.62862
2018-02-03 20:51:08,797 training [INFO ] Epoch 19 Batch 7680 Training err. 1.41056 Training err. RA 1.81116 Valid. err. 1.64686
2018-02-03 20:51:09,191 training [INFO ] Epoch 19 Batch 7700 Training err. 1.38561 Training err. RA 1.81005 Valid. err. 1.62065
2018-02-03 20:51:09,589 training [INFO ] Epoch 19 Batch 7720 Training err. 1.44805 Training err. RA 1.80911 Valid. err. 1.62154
2018-02-03 20:51:09,992 training [INFO ] Epoch 19 Batch 7740 Training err. 1.48682 Training err. RA 1.80828 Valid. err. 1.62793
2018-02-03 20:51:10,398 training [INFO ] Epoch 19 Batch 7760 Training err. 1.45634 Training err. RA 1.80737 Valid. err. 1.61498
2018-02-03 20:51:10,797 training [INFO ] Epoch 19 Batch 7780 Training err. 1.40644 Training err. RA 1.80634 Valid. err. 1.61147
2018-02-03 20:51:11,200 training [INFO ] Epoch 19 Batch 7800 Training err. 1.41696 Training err. RA 1.80534 Valid. err. 1.60253
2018-02-03 20:51:11,603 training [INFO ] Epoch 19 Batch 7820 Training err. 1.36468 Training err. RA 1.80422 Valid. err. 1.61212
2018-02-03 20:51:12,006 training [INFO ] Epoch 19 Batch 7840 Training err. 1.40530 Training err. RA 1.80320 Valid. err. 1.63802
2018-02-03 20:51:12,411 training [INFO ] Epoch 19 Batch 7860 Training err. 1.40240 Training err. RA 1.80218 Valid. err. 1.60201
2018-02-03 20:51:12,811 training [INFO ] Epoch 19 Batch 7880 Training err. 1.38427 Training err. RA 1.80112 Valid. err. 1.60418
2018-02-03 20:51:13,211 training [INFO ] Epoch 19 Batch 7900 Training err. 1.43357 Training err. RA 1.80019 Valid. err. 1.59937
2018-02-03 20:51:13,612 training [INFO ] Epoch 19 Batch 7920 Training err. 1.39357 Training err. RA 1.79916 Valid. err. 1.60223
2018-02-03 20:51:14,370 training [INFO ] Epoch 20 Batch 7940 Training err. 1.41331 Training err. RA 1.79819 Valid. err. 1.58976
2018-02-03 20:51:14,766 training [INFO ] Epoch 20 Batch 7960 Training err. 1.37236 Training err. RA 1.79712 Valid. err. 1.60002
2018-02-03 20:51:15,162 training [INFO ] Epoch 20 Batch 7980 Training err. 1.36198 Training err. RA 1.79603 Valid. err. 1.63537
2018-02-03 20:51:15,559 training [INFO ] Epoch 20 Batch 8000 Training err. 1.37637 Training err. RA 1.79498 Valid. err. 1.61884
2018-02-03 20:51:15,958 training [INFO ] Epoch 20 Batch 8020 Training err. 1.47687 Training err. RA 1.79419 Valid. err. 1.60265
2018-02-03 20:51:16,356 training [INFO ] Epoch 20 Batch 8040 Training err. 1.38298 Training err. RA 1.79316 Valid. err. 1.63620
2018-02-03 20:51:16,751 training [INFO ] Epoch 20 Batch 8060 Training err. 1.53023 Training err. RA 1.79251 Valid. err. 1.62089
2018-02-03 20:51:17,148 training [INFO ] Epoch 20 Batch 8080 Training err. 1.40240 Training err. RA 1.79155 Valid. err. 1.61659
2018-02-03 20:51:17,545 training [INFO ] Epoch 20 Batch 8100 Training err. 1.37584 Training err. RA 1.79052 Valid. err. 1.62197
2018-02-03 20:51:17,955 training [INFO ] Epoch 20 Batch 8120 Training err. 1.37828 Training err. RA 1.78950 Valid. err. 1.62012
2018-02-03 20:51:18,354 training [INFO ] Epoch 20 Batch 8140 Training err. 1.43030 Training err. RA 1.78862 Valid. err. 1.62423
2018-02-03 20:51:18,754 training [INFO ] Epoch 20 Batch 8160 Training err. 1.45851 Training err. RA 1.78781 Valid. err. 1.63289
2018-02-03 20:51:19,157 training [INFO ] Epoch 20 Batch 8180 Training err. 1.44650 Training err. RA 1.78698 Valid. err. 1.61237
2018-02-03 20:51:19,559 training [INFO ] Epoch 20 Batch 8200 Training err. 1.39623 Training err. RA 1.78603 Valid. err. 1.61930
2018-02-03 20:51:19,965 training [INFO ] Epoch 20 Batch 8220 Training err. 1.39844 Training err. RA 1.78508 Valid. err. 1.60481
2018-02-03 20:51:20,365 training [INFO ] Epoch 20 Batch 8240 Training err. 1.35121 Training err. RA 1.78403 Valid. err. 1.62781
2018-02-03 20:51:20,763 training [INFO ] Epoch 20 Batch 8260 Training err. 1.37401 Training err. RA 1.78304 Valid. err. 1.60908
2018-02-03 20:51:21,167 training [INFO ] Epoch 20 Batch 8280 Training err. 1.38029 Training err. RA 1.78206 Valid. err. 1.62787
2018-02-03 20:51:21,566 training [INFO ] Epoch 20 Batch 8300 Training err. 1.37861 Training err. RA 1.78109 Valid. err. 1.59547
2018-02-03 20:51:21,967 training [INFO ] Epoch 20 Batch 8320 Training err. 1.41094 Training err. RA 1.78020 Valid. err. 1.59418
2018-02-03 20:51:22,366 training [INFO ] Epoch 20 Batch 8340 Training err. 1.38115 Training err. RA 1.77924 Valid. err. 1.59399
2018-02-03 20:51:22,642 __main__ [INFO ] End of training
2018-02-03 20:51:22,870 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:51:23,433 training [INFO ] Epoch  1 Batch   20 Training err. 4.21831 Training err. RA 4.21831 Valid. err. 4.14533
2018-02-03 20:51:23,912 training [INFO ] Epoch  1 Batch   40 Training err. 4.03896 Training err. RA 4.12864 Valid. err. 3.97826
2018-02-03 20:51:24,390 training [INFO ] Epoch  1 Batch   60 Training err. 3.87453 Training err. RA 4.04393 Valid. err. 3.79076
2018-02-03 20:51:24,875 training [INFO ] Epoch  1 Batch   80 Training err. 3.67993 Training err. RA 3.95293 Valid. err. 3.59885
2018-02-03 20:51:25,362 training [INFO ] Epoch  1 Batch  100 Training err. 3.48310 Training err. RA 3.85897 Valid. err. 3.45780
2018-02-03 20:51:25,849 training [INFO ] Epoch  1 Batch  120 Training err. 3.38405 Training err. RA 3.77981 Valid. err. 3.35363
2018-02-03 20:51:26,334 training [INFO ] Epoch  1 Batch  140 Training err. 3.27748 Training err. RA 3.70805 Valid. err. 3.29195
2018-02-03 20:51:26,817 training [INFO ] Epoch  1 Batch  160 Training err. 3.20591 Training err. RA 3.64529 Valid. err. 3.25839
2018-02-03 20:51:27,303 training [INFO ] Epoch  1 Batch  180 Training err. 3.22347 Training err. RA 3.59842 Valid. err. 3.23815
2018-02-03 20:51:27,791 training [INFO ] Epoch  1 Batch  200 Training err. 3.21626 Training err. RA 3.56020 Valid. err. 3.22206
2018-02-03 20:51:28,613 training [INFO ] Epoch  2 Batch  220 Training err. 3.18427 Training err. RA 3.52602 Valid. err. 3.22032
2018-02-03 20:51:29,098 training [INFO ] Epoch  2 Batch  240 Training err. 3.09996 Training err. RA 3.49052 Valid. err. 3.24123
2018-02-03 20:51:29,583 training [INFO ] Epoch  2 Batch  260 Training err. 3.18389 Training err. RA 3.46693 Valid. err. 3.20295
2018-02-03 20:51:30,077 training [INFO ] Epoch  2 Batch  280 Training err. 3.14018 Training err. RA 3.44359 Valid. err. 3.19929
2018-02-03 20:51:30,570 training [INFO ] Epoch  2 Batch  300 Training err. 3.13427 Training err. RA 3.42297 Valid. err. 3.20018
2018-02-03 20:51:31,063 training [INFO ] Epoch  2 Batch  320 Training err. 3.16760 Training err. RA 3.40701 Valid. err. 3.19302
2018-02-03 20:51:31,556 training [INFO ] Epoch  2 Batch  340 Training err. 3.14459 Training err. RA 3.39157 Valid. err. 3.19377
2018-02-03 20:51:32,045 training [INFO ] Epoch  2 Batch  360 Training err. 3.13095 Training err. RA 3.37710 Valid. err. 3.19188
2018-02-03 20:51:32,541 training [INFO ] Epoch  2 Batch  380 Training err. 3.12327 Training err. RA 3.36374 Valid. err. 3.18847
2018-02-03 20:51:33,033 training [INFO ] Epoch  2 Batch  400 Training err. 3.16836 Training err. RA 3.35397 Valid. err. 3.18606
2018-02-03 20:51:33,864 training [INFO ] Epoch  3 Batch  420 Training err. 3.16337 Training err. RA 3.34489 Valid. err. 3.18621
2018-02-03 20:51:34,349 training [INFO ] Epoch  3 Batch  440 Training err. 3.12579 Training err. RA 3.33493 Valid. err. 3.19222
2018-02-03 20:51:34,831 training [INFO ] Epoch  3 Batch  460 Training err. 3.11299 Training err. RA 3.32528 Valid. err. 3.18386
2018-02-03 20:51:35,315 training [INFO ] Epoch  3 Batch  480 Training err. 3.11934 Training err. RA 3.31670 Valid. err. 3.18497
2018-02-03 20:51:35,800 training [INFO ] Epoch  3 Batch  500 Training err. 3.10689 Training err. RA 3.30831 Valid. err. 3.19159
2018-02-03 20:51:36,287 training [INFO ] Epoch  3 Batch  520 Training err. 3.16170 Training err. RA 3.30267 Valid. err. 3.18650
2018-02-03 20:51:36,777 training [INFO ] Epoch  3 Batch  540 Training err. 3.15193 Training err. RA 3.29709 Valid. err. 3.18502
2018-02-03 20:51:37,263 training [INFO ] Epoch  3 Batch  560 Training err. 3.11859 Training err. RA 3.29071 Valid. err. 3.18457
2018-02-03 20:51:37,748 training [INFO ] Epoch  3 Batch  580 Training err. 3.08153 Training err. RA 3.28350 Valid. err. 3.18776
2018-02-03 20:51:38,232 training [INFO ] Epoch  3 Batch  600 Training err. 3.16207 Training err. RA 3.27945 Valid. err. 3.18139
2018-02-03 20:51:38,718 training [INFO ] Epoch  3 Batch  620 Training err. 3.16252 Training err. RA 3.27568 Valid. err. 3.17806
2018-02-03 20:51:39,544 training [INFO ] Epoch  4 Batch  640 Training err. 3.13446 Training err. RA 3.27127 Valid. err. 3.18120
2018-02-03 20:51:40,029 training [INFO ] Epoch  4 Batch  660 Training err. 3.07663 Training err. RA 3.26537 Valid. err. 3.18113
2018-02-03 20:51:40,519 training [INFO ] Epoch  4 Batch  680 Training err. 3.13434 Training err. RA 3.26151 Valid. err. 3.18130
2018-02-03 20:51:41,009 training [INFO ] Epoch  4 Batch  700 Training err. 3.11902 Training err. RA 3.25744 Valid. err. 3.18008
2018-02-03 20:51:41,498 training [INFO ] Epoch  4 Batch  720 Training err. 3.11060 Training err. RA 3.25336 Valid. err. 3.18228
2018-02-03 20:51:41,988 training [INFO ] Epoch  4 Batch  740 Training err. 3.16469 Training err. RA 3.25097 Valid. err. 3.17823
2018-02-03 20:51:42,479 training [INFO ] Epoch  4 Batch  760 Training err. 3.11243 Training err. RA 3.24732 Valid. err. 3.18105
2018-02-03 20:51:42,969 training [INFO ] Epoch  4 Batch  780 Training err. 3.11140 Training err. RA 3.24384 Valid. err. 3.17872
2018-02-03 20:51:43,459 training [INFO ] Epoch  4 Batch  800 Training err. 3.12051 Training err. RA 3.24075 Valid. err. 3.17818
2018-02-03 20:51:43,951 training [INFO ] Epoch  4 Batch  820 Training err. 3.14609 Training err. RA 3.23844 Valid. err. 3.17629
2018-02-03 20:51:44,785 training [INFO ] Epoch  5 Batch  840 Training err. 3.15518 Training err. RA 3.23646 Valid. err. 3.17344
2018-02-03 20:51:45,275 training [INFO ] Epoch  5 Batch  860 Training err. 3.07762 Training err. RA 3.23277 Valid. err. 3.20241
2018-02-03 20:51:45,764 training [INFO ] Epoch  5 Batch  880 Training err. 3.13133 Training err. RA 3.23046 Valid. err. 3.17547
2018-02-03 20:51:46,254 training [INFO ] Epoch  5 Batch  900 Training err. 3.11225 Training err. RA 3.22784 Valid. err. 3.17519
2018-02-03 20:51:46,739 training [INFO ] Epoch  5 Batch  920 Training err. 3.09001 Training err. RA 3.22484 Valid. err. 3.17942
2018-02-03 20:51:47,226 training [INFO ] Epoch  5 Batch  940 Training err. 3.15192 Training err. RA 3.22329 Valid. err. 3.17795
2018-02-03 20:51:47,712 training [INFO ] Epoch  5 Batch  960 Training err. 3.12339 Training err. RA 3.22121 Valid. err. 3.17854
2018-02-03 20:51:48,200 training [INFO ] Epoch  5 Batch  980 Training err. 3.11582 Training err. RA 3.21906 Valid. err. 3.17349
2018-02-03 20:51:48,685 training [INFO ] Epoch  5 Batch 1000 Training err. 3.07920 Training err. RA 3.21626 Valid. err. 3.17290
2018-02-03 20:51:49,210 training [INFO ] Epoch  5 Batch 1020 Training err. 3.15693 Training err. RA 3.21510 Valid. err. 3.17091
2018-02-03 20:51:49,695 training [INFO ] Epoch  5 Batch 1040 Training err. 3.14241 Training err. RA 3.21370 Valid. err. 3.16728
2018-02-03 20:51:50,524 training [INFO ] Epoch  6 Batch 1060 Training err. 3.10892 Training err. RA 3.21172 Valid. err. 3.17019
2018-02-03 20:51:51,013 training [INFO ] Epoch  6 Batch 1080 Training err. 3.08913 Training err. RA 3.20945 Valid. err. 3.16982
2018-02-03 20:51:51,502 training [INFO ] Epoch  6 Batch 1100 Training err. 3.09759 Training err. RA 3.20742 Valid. err. 3.17105
2018-02-03 20:51:51,992 training [INFO ] Epoch  6 Batch 1120 Training err. 3.11467 Training err. RA 3.20576 Valid. err. 3.17071
2018-02-03 20:51:52,478 training [INFO ] Epoch  6 Batch 1140 Training err. 3.11169 Training err. RA 3.20411 Valid. err. 3.16875
2018-02-03 20:51:52,963 training [INFO ] Epoch  6 Batch 1160 Training err. 3.14552 Training err. RA 3.20310 Valid. err. 3.16708
2018-02-03 20:51:53,450 training [INFO ] Epoch  6 Batch 1180 Training err. 3.10216 Training err. RA 3.20139 Valid. err. 3.16767
2018-02-03 20:51:53,935 training [INFO ] Epoch  6 Batch 1200 Training err. 3.07463 Training err. RA 3.19928 Valid. err. 3.16729
2018-02-03 20:51:54,420 training [INFO ] Epoch  6 Batch 1220 Training err. 3.12676 Training err. RA 3.19809 Valid. err. 3.16569
2018-02-03 20:51:54,910 training [INFO ] Epoch  6 Batch 1240 Training err. 3.13718 Training err. RA 3.19711 Valid. err. 3.16099
2018-02-03 20:51:55,732 training [INFO ] Epoch  7 Batch 1260 Training err. 3.12659 Training err. RA 3.19599 Valid. err. 3.17802
2018-02-03 20:51:56,216 training [INFO ] Epoch  7 Batch 1280 Training err. 3.04878 Training err. RA 3.19369 Valid. err. 3.20034
2018-02-03 20:51:56,700 training [INFO ] Epoch  7 Batch 1300 Training err. 3.12845 Training err. RA 3.19268 Valid. err. 3.16222
2018-02-03 20:51:57,184 training [INFO ] Epoch  7 Batch 1320 Training err. 3.09668 Training err. RA 3.19123 Valid. err. 3.15918
2018-02-03 20:51:57,670 training [INFO ] Epoch  7 Batch 1340 Training err. 3.09051 Training err. RA 3.18972 Valid. err. 3.16434
2018-02-03 20:51:58,156 training [INFO ] Epoch  7 Batch 1360 Training err. 3.13026 Training err. RA 3.18885 Valid. err. 3.15640
2018-02-03 20:51:58,642 training [INFO ] Epoch  7 Batch 1380 Training err. 3.10306 Training err. RA 3.18761 Valid. err. 3.15810
2018-02-03 20:51:59,126 training [INFO ] Epoch  7 Batch 1400 Training err. 3.08868 Training err. RA 3.18619 Valid. err. 3.15707
2018-02-03 20:51:59,609 training [INFO ] Epoch  7 Batch 1420 Training err. 3.08244 Training err. RA 3.18473 Valid. err. 3.15321
2018-02-03 20:52:00,098 training [INFO ] Epoch  7 Batch 1440 Training err. 3.12694 Training err. RA 3.18393 Valid. err. 3.14959
2018-02-03 20:52:00,920 training [INFO ] Epoch  8 Batch 1460 Training err. 3.12334 Training err. RA 3.18310 Valid. err. 3.14909
2018-02-03 20:52:01,408 training [INFO ] Epoch  8 Batch 1480 Training err. 3.08714 Training err. RA 3.18180 Valid. err. 3.16075
2018-02-03 20:52:01,894 training [INFO ] Epoch  8 Batch 1500 Training err. 3.08223 Training err. RA 3.18048 Valid. err. 3.14600
2018-02-03 20:52:02,378 training [INFO ] Epoch  8 Batch 1520 Training err. 3.07857 Training err. RA 3.17913 Valid. err. 3.14582
2018-02-03 20:52:02,861 training [INFO ] Epoch  8 Batch 1540 Training err. 3.06800 Training err. RA 3.17769 Valid. err. 3.15129
2018-02-03 20:52:03,346 training [INFO ] Epoch  8 Batch 1560 Training err. 3.12167 Training err. RA 3.17697 Valid. err. 3.14505
2018-02-03 20:52:03,835 training [INFO ] Epoch  8 Batch 1580 Training err. 3.10839 Training err. RA 3.17610 Valid. err. 3.14166
2018-02-03 20:52:04,321 training [INFO ] Epoch  8 Batch 1600 Training err. 3.07104 Training err. RA 3.17479 Valid. err. 3.13901
2018-02-03 20:52:04,806 training [INFO ] Epoch  8 Batch 1620 Training err. 3.03451 Training err. RA 3.17306 Valid. err. 3.13922
2018-02-03 20:52:05,292 training [INFO ] Epoch  8 Batch 1640 Training err. 3.11055 Training err. RA 3.17230 Valid. err. 3.13176
2018-02-03 20:52:05,778 training [INFO ] Epoch  8 Batch 1660 Training err. 3.11015 Training err. RA 3.17155 Valid. err. 3.12588
2018-02-03 20:52:06,613 training [INFO ] Epoch  9 Batch 1680 Training err. 3.08539 Training err. RA 3.17052 Valid. err. 3.12693
2018-02-03 20:52:07,097 training [INFO ] Epoch  9 Batch 1700 Training err. 3.04030 Training err. RA 3.16899 Valid. err. 3.12529
2018-02-03 20:52:07,592 training [INFO ] Epoch  9 Batch 1720 Training err. 3.07739 Training err. RA 3.16793 Valid. err. 3.12348
2018-02-03 20:52:08,079 training [INFO ] Epoch  9 Batch 1740 Training err. 3.06408 Training err. RA 3.16673 Valid. err. 3.11961
2018-02-03 20:52:08,569 training [INFO ] Epoch  9 Batch 1760 Training err. 3.05382 Training err. RA 3.16545 Valid. err. 3.11844
2018-02-03 20:52:09,058 training [INFO ] Epoch  9 Batch 1780 Training err. 3.10454 Training err. RA 3.16476 Valid. err. 3.11299
2018-02-03 20:52:09,546 training [INFO ] Epoch  9 Batch 1800 Training err. 3.04496 Training err. RA 3.16343 Valid. err. 3.11041
2018-02-03 20:52:10,031 training [INFO ] Epoch  9 Batch 1820 Training err. 3.03775 Training err. RA 3.16205 Valid. err. 3.10420
2018-02-03 20:52:10,520 training [INFO ] Epoch  9 Batch 1840 Training err. 3.04927 Training err. RA 3.16083 Valid. err. 3.10001
2018-02-03 20:52:11,009 training [INFO ] Epoch  9 Batch 1860 Training err. 3.06748 Training err. RA 3.15982 Valid. err. 3.09323
2018-02-03 20:52:11,844 training [INFO ] Epoch 10 Batch 1880 Training err. 3.07467 Training err. RA 3.15892 Valid. err. 3.08631
2018-02-03 20:52:12,332 training [INFO ] Epoch 10 Batch 1900 Training err. 3.00963 Training err. RA 3.15735 Valid. err. 3.12626
2018-02-03 20:52:12,818 training [INFO ] Epoch 10 Batch 1920 Training err. 3.05830 Training err. RA 3.15631 Valid. err. 3.08195
2018-02-03 20:52:13,303 training [INFO ] Epoch 10 Batch 1940 Training err. 3.02193 Training err. RA 3.15493 Valid. err. 3.07681
2018-02-03 20:52:13,789 training [INFO ] Epoch 10 Batch 1960 Training err. 2.99836 Training err. RA 3.15333 Valid. err. 3.07665
2018-02-03 20:52:14,274 training [INFO ] Epoch 10 Batch 1980 Training err. 3.06127 Training err. RA 3.15240 Valid. err. 3.07247
2018-02-03 20:52:14,759 training [INFO ] Epoch 10 Batch 2000 Training err. 3.01894 Training err. RA 3.15107 Valid. err. 3.06377
2018-02-03 20:52:15,245 training [INFO ] Epoch 10 Batch 2020 Training err. 2.99853 Training err. RA 3.14956 Valid. err. 3.05654
2018-02-03 20:52:15,732 training [INFO ] Epoch 10 Batch 2040 Training err. 2.96657 Training err. RA 3.14776 Valid. err. 3.04626
2018-02-03 20:52:16,218 training [INFO ] Epoch 10 Batch 2060 Training err. 3.02915 Training err. RA 3.14661 Valid. err. 3.03674
2018-02-03 20:52:16,703 training [INFO ] Epoch 10 Batch 2080 Training err. 3.01048 Training err. RA 3.14530 Valid. err. 3.02616
2018-02-03 20:52:17,525 training [INFO ] Epoch 11 Batch 2100 Training err. 2.98045 Training err. RA 3.14373 Valid. err. 3.02399
2018-02-03 20:52:18,024 training [INFO ] Epoch 11 Batch 2120 Training err. 2.99019 Training err. RA 3.14228 Valid. err. 3.02356
2018-02-03 20:52:18,515 training [INFO ] Epoch 11 Batch 2140 Training err. 2.95618 Training err. RA 3.14054 Valid. err. 3.01459
2018-02-03 20:52:19,010 training [INFO ] Epoch 11 Batch 2160 Training err. 2.96315 Training err. RA 3.13890 Valid. err. 3.01045
2018-02-03 20:52:19,504 training [INFO ] Epoch 11 Batch 2180 Training err. 2.96301 Training err. RA 3.13729 Valid. err. 2.99853
2018-02-03 20:52:19,992 training [INFO ] Epoch 11 Batch 2200 Training err. 2.99127 Training err. RA 3.13596 Valid. err. 2.99183
2018-02-03 20:52:20,482 training [INFO ] Epoch 11 Batch 2220 Training err. 2.93088 Training err. RA 3.13411 Valid. err. 2.98482
2018-02-03 20:52:20,972 training [INFO ] Epoch 11 Batch 2240 Training err. 2.89472 Training err. RA 3.13197 Valid. err. 2.98007
2018-02-03 20:52:21,461 training [INFO ] Epoch 11 Batch 2260 Training err. 2.95101 Training err. RA 3.13037 Valid. err. 2.97025
2018-02-03 20:52:21,949 training [INFO ] Epoch 11 Batch 2280 Training err. 2.94966 Training err. RA 3.12879 Valid. err. 2.96264
2018-02-03 20:52:22,775 training [INFO ] Epoch 12 Batch 2300 Training err. 2.93657 Training err. RA 3.12712 Valid. err. 3.01757
2018-02-03 20:52:23,261 training [INFO ] Epoch 12 Batch 2320 Training err. 2.87138 Training err. RA 3.12491 Valid. err. 3.01144
2018-02-03 20:52:23,747 training [INFO ] Epoch 12 Batch 2340 Training err. 2.93187 Training err. RA 3.12326 Valid. err. 2.94125
2018-02-03 20:52:24,234 training [INFO ] Epoch 12 Batch 2360 Training err. 2.89493 Training err. RA 3.12133 Valid. err. 2.93096
2018-02-03 20:52:24,720 training [INFO ] Epoch 12 Batch 2380 Training err. 2.86473 Training err. RA 3.11917 Valid. err. 2.94164
2018-02-03 20:52:25,205 training [INFO ] Epoch 12 Batch 2400 Training err. 2.91726 Training err. RA 3.11749 Valid. err. 2.91608
2018-02-03 20:52:25,691 training [INFO ] Epoch 12 Batch 2420 Training err. 2.87579 Training err. RA 3.11549 Valid. err. 2.91628
2018-02-03 20:52:26,177 training [INFO ] Epoch 12 Batch 2440 Training err. 2.85218 Training err. RA 3.11333 Valid. err. 2.90525
2018-02-03 20:52:26,664 training [INFO ] Epoch 12 Batch 2460 Training err. 2.84868 Training err. RA 3.11118 Valid. err. 2.89694
2018-02-03 20:52:27,150 training [INFO ] Epoch 12 Batch 2480 Training err. 2.87359 Training err. RA 3.10926 Valid. err. 2.89795
2018-02-03 20:52:27,970 training [INFO ] Epoch 13 Batch 2500 Training err. 2.87253 Training err. RA 3.10737 Valid. err. 2.88365
2018-02-03 20:52:28,456 training [INFO ] Epoch 13 Batch 2520 Training err. 2.82966 Training err. RA 3.10517 Valid. err. 2.88903
2018-02-03 20:52:28,943 training [INFO ] Epoch 13 Batch 2540 Training err. 2.85400 Training err. RA 3.10319 Valid. err. 2.86998
2018-02-03 20:52:29,429 training [INFO ] Epoch 13 Batch 2560 Training err. 2.81334 Training err. RA 3.10092 Valid. err. 2.86253
2018-02-03 20:52:29,917 training [INFO ] Epoch 13 Batch 2580 Training err. 2.79604 Training err. RA 3.09856 Valid. err. 2.86941
2018-02-03 20:52:30,406 training [INFO ] Epoch 13 Batch 2600 Training err. 2.84124 Training err. RA 3.09658 Valid. err. 2.87059
2018-02-03 20:52:30,893 training [INFO ] Epoch 13 Batch 2620 Training err. 2.83894 Training err. RA 3.09462 Valid. err. 2.84489
2018-02-03 20:52:31,383 training [INFO ] Epoch 13 Batch 2640 Training err. 2.78484 Training err. RA 3.09227 Valid. err. 2.84321
2018-02-03 20:52:31,870 training [INFO ] Epoch 13 Batch 2660 Training err. 2.74931 Training err. RA 3.08969 Valid. err. 2.88201
2018-02-03 20:52:32,359 training [INFO ] Epoch 13 Batch 2680 Training err. 2.81738 Training err. RA 3.08766 Valid. err. 2.82593
2018-02-03 20:52:32,849 training [INFO ] Epoch 13 Batch 2700 Training err. 2.82161 Training err. RA 3.08569 Valid. err. 2.81697
2018-02-03 20:52:33,694 training [INFO ] Epoch 14 Batch 2720 Training err. 2.78417 Training err. RA 3.08347 Valid. err. 2.81584
2018-02-03 20:52:34,180 training [INFO ] Epoch 14 Batch 2740 Training err. 2.74055 Training err. RA 3.08097 Valid. err. 2.82601
2018-02-03 20:52:34,664 training [INFO ] Epoch 14 Batch 2760 Training err. 2.79490 Training err. RA 3.07889 Valid. err. 2.80879
2018-02-03 20:52:35,150 training [INFO ] Epoch 14 Batch 2780 Training err. 2.75688 Training err. RA 3.07658 Valid. err. 2.80329
2018-02-03 20:52:35,637 training [INFO ] Epoch 14 Batch 2800 Training err. 2.71879 Training err. RA 3.07402 Valid. err. 2.79343
2018-02-03 20:52:36,123 training [INFO ] Epoch 14 Batch 2820 Training err. 2.80222 Training err. RA 3.07209 Valid. err. 2.79218
2018-02-03 20:52:36,607 training [INFO ] Epoch 14 Batch 2840 Training err. 2.73950 Training err. RA 3.06975 Valid. err. 2.80498
2018-02-03 20:52:37,090 training [INFO ] Epoch 14 Batch 2860 Training err. 2.72735 Training err. RA 3.06736 Valid. err. 2.78001
2018-02-03 20:52:37,576 training [INFO ] Epoch 14 Batch 2880 Training err. 2.73828 Training err. RA 3.06507 Valid. err. 2.77764
2018-02-03 20:52:38,065 training [INFO ] Epoch 14 Batch 2900 Training err. 2.74958 Training err. RA 3.06290 Valid. err. 2.76599
2018-02-03 20:52:38,903 training [INFO ] Epoch 15 Batch 2920 Training err. 2.75525 Training err. RA 3.06079 Valid. err. 2.76166
2018-02-03 20:52:39,390 training [INFO ] Epoch 15 Batch 2940 Training err. 2.66985 Training err. RA 3.05813 Valid. err. 2.77217
2018-02-03 20:52:39,881 training [INFO ] Epoch 15 Batch 2960 Training err. 2.74817 Training err. RA 3.05604 Valid. err. 2.76129
2018-02-03 20:52:40,371 training [INFO ] Epoch 15 Batch 2980 Training err. 2.70770 Training err. RA 3.05370 Valid. err. 2.76223
2018-02-03 20:52:40,861 training [INFO ] Epoch 15 Batch 3000 Training err. 2.66695 Training err. RA 3.05112 Valid. err. 2.75953
2018-02-03 20:52:41,351 training [INFO ] Epoch 15 Batch 3020 Training err. 2.72695 Training err. RA 3.04897 Valid. err. 2.77972
2018-02-03 20:52:41,838 training [INFO ] Epoch 15 Batch 3040 Training err. 2.71921 Training err. RA 3.04680 Valid. err. 2.73610
2018-02-03 20:52:42,326 training [INFO ] Epoch 15 Batch 3060 Training err. 2.70178 Training err. RA 3.04455 Valid. err. 2.74461
2018-02-03 20:52:42,812 training [INFO ] Epoch 15 Batch 3080 Training err. 2.64556 Training err. RA 3.04196 Valid. err. 2.74534
2018-02-03 20:52:43,298 training [INFO ] Epoch 15 Batch 3100 Training err. 2.71912 Training err. RA 3.03987 Valid. err. 2.72677
2018-02-03 20:52:43,784 training [INFO ] Epoch 15 Batch 3120 Training err. 2.71849 Training err. RA 3.03781 Valid. err. 2.72327
2018-02-03 20:52:44,615 training [INFO ] Epoch 16 Batch 3140 Training err. 2.66641 Training err. RA 3.03545 Valid. err. 2.71543
2018-02-03 20:52:45,100 training [INFO ] Epoch 16 Batch 3160 Training err. 2.64267 Training err. RA 3.03296 Valid. err. 2.71187
2018-02-03 20:52:45,585 training [INFO ] Epoch 16 Batch 3180 Training err. 2.66824 Training err. RA 3.03067 Valid. err. 2.70675
2018-02-03 20:52:46,080 training [INFO ] Epoch 16 Batch 3200 Training err. 2.66956 Training err. RA 3.02841 Valid. err. 2.70184
2018-02-03 20:52:46,573 training [INFO ] Epoch 16 Batch 3220 Training err. 2.64403 Training err. RA 3.02602 Valid. err. 2.70324
2018-02-03 20:52:47,065 training [INFO ] Epoch 16 Batch 3240 Training err. 2.70808 Training err. RA 3.02406 Valid. err. 2.71055
2018-02-03 20:52:47,558 training [INFO ] Epoch 16 Batch 3260 Training err. 2.65486 Training err. RA 3.02180 Valid. err. 2.70827
2018-02-03 20:52:48,061 training [INFO ] Epoch 16 Batch 3280 Training err. 2.62248 Training err. RA 3.01936 Valid. err. 2.70805
2018-02-03 20:52:48,553 training [INFO ] Epoch 16 Batch 3300 Training err. 2.65870 Training err. RA 3.01718 Valid. err. 2.68706
2018-02-03 20:52:49,042 training [INFO ] Epoch 16 Batch 3320 Training err. 2.66873 Training err. RA 3.01508 Valid. err. 2.68727
2018-02-03 20:52:49,873 training [INFO ] Epoch 17 Batch 3340 Training err. 2.65149 Training err. RA 3.01290 Valid. err. 2.74244
2018-02-03 20:52:50,359 training [INFO ] Epoch 17 Batch 3360 Training err. 2.55997 Training err. RA 3.01020 Valid. err. 2.68904
2018-02-03 20:52:50,846 training [INFO ] Epoch 17 Batch 3380 Training err. 2.68164 Training err. RA 3.00826 Valid. err. 2.66981
2018-02-03 20:52:51,332 training [INFO ] Epoch 17 Batch 3400 Training err. 2.62167 Training err. RA 3.00599 Valid. err. 2.68025
2018-02-03 20:52:51,820 training [INFO ] Epoch 17 Batch 3420 Training err. 2.60089 Training err. RA 3.00362 Valid. err. 2.67068
2018-02-03 20:52:52,305 training [INFO ] Epoch 17 Batch 3440 Training err. 2.64789 Training err. RA 3.00155 Valid. err. 2.65148
2018-02-03 20:52:52,793 training [INFO ] Epoch 17 Batch 3460 Training err. 2.64660 Training err. RA 2.99950 Valid. err. 2.66442
2018-02-03 20:52:53,279 training [INFO ] Epoch 17 Batch 3480 Training err. 2.60924 Training err. RA 2.99725 Valid. err. 2.64955
2018-02-03 20:52:53,767 training [INFO ] Epoch 17 Batch 3500 Training err. 2.59883 Training err. RA 2.99498 Valid. err. 2.65246
2018-02-03 20:52:54,260 training [INFO ] Epoch 17 Batch 3520 Training err. 2.61886 Training err. RA 2.99284 Valid. err. 2.65568
2018-02-03 20:52:55,087 training [INFO ] Epoch 18 Batch 3540 Training err. 2.63035 Training err. RA 2.99079 Valid. err. 2.63279
2018-02-03 20:52:55,577 training [INFO ] Epoch 18 Batch 3560 Training err. 2.58691 Training err. RA 2.98852 Valid. err. 2.63041
2018-02-03 20:52:56,065 training [INFO ] Epoch 18 Batch 3580 Training err. 2.57912 Training err. RA 2.98624 Valid. err. 2.64241
2018-02-03 20:52:56,552 training [INFO ] Epoch 18 Batch 3600 Training err. 2.59149 Training err. RA 2.98404 Valid. err. 2.62381
2018-02-03 20:52:57,041 training [INFO ] Epoch 18 Batch 3620 Training err. 2.56677 Training err. RA 2.98174 Valid. err. 2.65552
2018-02-03 20:52:57,529 training [INFO ] Epoch 18 Batch 3640 Training err. 2.60525 Training err. RA 2.97967 Valid. err. 2.63955
2018-02-03 20:52:58,020 training [INFO ] Epoch 18 Batch 3660 Training err. 2.63772 Training err. RA 2.97780 Valid. err. 2.62025
2018-02-03 20:52:58,508 training [INFO ] Epoch 18 Batch 3680 Training err. 2.56945 Training err. RA 2.97558 Valid. err. 2.61100
2018-02-03 20:52:59,001 training [INFO ] Epoch 18 Batch 3700 Training err. 2.53665 Training err. RA 2.97321 Valid. err. 2.61023
2018-02-03 20:52:59,490 training [INFO ] Epoch 18 Batch 3720 Training err. 2.58684 Training err. RA 2.97113 Valid. err. 2.60006
2018-02-03 20:52:59,981 training [INFO ] Epoch 18 Batch 3740 Training err. 2.59777 Training err. RA 2.96913 Valid. err. 2.60156
2018-02-03 20:53:00,825 training [INFO ] Epoch 19 Batch 3760 Training err. 2.57751 Training err. RA 2.96705 Valid. err. 2.59507
2018-02-03 20:53:01,317 training [INFO ] Epoch 19 Batch 3780 Training err. 2.49417 Training err. RA 2.96455 Valid. err. 2.59235
2018-02-03 20:53:01,803 training [INFO ] Epoch 19 Batch 3800 Training err. 2.59236 Training err. RA 2.96259 Valid. err. 2.61027
2018-02-03 20:53:02,291 training [INFO ] Epoch 19 Batch 3820 Training err. 2.56383 Training err. RA 2.96050 Valid. err. 2.58540
2018-02-03 20:53:02,780 training [INFO ] Epoch 19 Batch 3840 Training err. 2.51649 Training err. RA 2.95819 Valid. err. 2.58567
2018-02-03 20:53:03,266 training [INFO ] Epoch 19 Batch 3860 Training err. 2.61063 Training err. RA 2.95639 Valid. err. 2.60406
2018-02-03 20:53:03,751 training [INFO ] Epoch 19 Batch 3880 Training err. 2.55606 Training err. RA 2.95433 Valid. err. 2.59544
2018-02-03 20:53:04,236 training [INFO ] Epoch 19 Batch 3900 Training err. 2.53354 Training err. RA 2.95217 Valid. err. 2.57591
2018-02-03 20:53:04,721 training [INFO ] Epoch 19 Batch 3920 Training err. 2.54148 Training err. RA 2.95007 Valid. err. 2.57084
2018-02-03 20:53:05,207 training [INFO ] Epoch 19 Batch 3940 Training err. 2.53364 Training err. RA 2.94796 Valid. err. 2.56540
2018-02-03 20:53:06,050 training [INFO ] Epoch 20 Batch 3960 Training err. 2.56658 Training err. RA 2.94603 Valid. err. 2.56140
2018-02-03 20:53:06,540 training [INFO ] Epoch 20 Batch 3980 Training err. 2.47243 Training err. RA 2.94365 Valid. err. 2.56093
2018-02-03 20:53:07,029 training [INFO ] Epoch 20 Batch 4000 Training err. 2.55547 Training err. RA 2.94171 Valid. err. 2.56132
2018-02-03 20:53:07,521 training [INFO ] Epoch 20 Batch 4020 Training err. 2.52671 Training err. RA 2.93965 Valid. err. 2.55786
2018-02-03 20:53:08,014 training [INFO ] Epoch 20 Batch 4040 Training err. 2.49389 Training err. RA 2.93744 Valid. err. 2.56332
2018-02-03 20:53:08,504 training [INFO ] Epoch 20 Batch 4060 Training err. 2.53087 Training err. RA 2.93544 Valid. err. 2.58164
2018-02-03 20:53:08,995 training [INFO ] Epoch 20 Batch 4080 Training err. 2.56327 Training err. RA 2.93361 Valid. err. 2.54242
2018-02-03 20:53:09,485 training [INFO ] Epoch 20 Batch 4100 Training err. 2.52200 Training err. RA 2.93161 Valid. err. 2.56219
2018-02-03 20:53:09,974 training [INFO ] Epoch 20 Batch 4120 Training err. 2.46792 Training err. RA 2.92935 Valid. err. 2.54551
2018-02-03 20:53:10,457 training [INFO ] Epoch 20 Batch 4140 Training err. 2.52638 Training err. RA 2.92741 Valid. err. 2.53720
2018-02-03 20:53:10,940 training [INFO ] Epoch 20 Batch 4160 Training err. 2.52863 Training err. RA 2.92549 Valid. err. 2.53778
2018-02-03 20:53:11,211 __main__ [INFO ] End of training
2018-02-03 20:53:11,448 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:53:12,018 training [INFO ] Epoch  1 Batch   20 Training err. 3.59482 Training err. RA 3.59482 Valid. err. 3.24063
2018-02-03 20:53:12,503 training [INFO ] Epoch  1 Batch   40 Training err. 3.19661 Training err. RA 3.39571 Valid. err. 3.20541
2018-02-03 20:53:12,991 training [INFO ] Epoch  1 Batch   60 Training err. 3.15470 Training err. RA 3.31538 Valid. err. 3.19800
2018-02-03 20:53:13,477 training [INFO ] Epoch  1 Batch   80 Training err. 3.14489 Training err. RA 3.27275 Valid. err. 3.20019
2018-02-03 20:53:13,964 training [INFO ] Epoch  1 Batch  100 Training err. 3.13293 Training err. RA 3.24479 Valid. err. 3.18135
2018-02-03 20:53:14,445 training [INFO ] Epoch  1 Batch  120 Training err. 3.15870 Training err. RA 3.23044 Valid. err. 3.18115
2018-02-03 20:53:14,928 training [INFO ] Epoch  1 Batch  140 Training err. 3.11138 Training err. RA 3.21343 Valid. err. 3.17737
2018-02-03 20:53:15,414 training [INFO ] Epoch  1 Batch  160 Training err. 3.07448 Training err. RA 3.19606 Valid. err. 3.17870
2018-02-03 20:53:15,897 training [INFO ] Epoch  1 Batch  180 Training err. 3.13750 Training err. RA 3.18956 Valid. err. 3.15351
2018-02-03 20:53:16,384 training [INFO ] Epoch  1 Batch  200 Training err. 3.11446 Training err. RA 3.18205 Valid. err. 3.12796
2018-02-03 20:53:17,210 training [INFO ] Epoch  2 Batch  220 Training err. 3.09259 Training err. RA 3.17391 Valid. err. 3.25179
2018-02-03 20:53:17,695 training [INFO ] Epoch  2 Batch  240 Training err. 3.01126 Training err. RA 3.16036 Valid. err. 3.23696
2018-02-03 20:53:18,188 training [INFO ] Epoch  2 Batch  260 Training err. 3.05373 Training err. RA 3.15216 Valid. err. 3.06309
2018-02-03 20:53:18,672 training [INFO ] Epoch  2 Batch  280 Training err. 3.00177 Training err. RA 3.14142 Valid. err. 3.00817
2018-02-03 20:53:19,155 training [INFO ] Epoch  2 Batch  300 Training err. 2.92260 Training err. RA 3.12683 Valid. err. 2.96647
2018-02-03 20:53:19,640 training [INFO ] Epoch  2 Batch  320 Training err. 2.93071 Training err. RA 3.11457 Valid. err. 2.90015
2018-02-03 20:53:20,123 training [INFO ] Epoch  2 Batch  340 Training err. 2.85958 Training err. RA 3.09957 Valid. err. 2.93456
2018-02-03 20:53:20,607 training [INFO ] Epoch  2 Batch  360 Training err. 2.81003 Training err. RA 3.08349 Valid. err. 2.84067
2018-02-03 20:53:21,090 training [INFO ] Epoch  2 Batch  380 Training err. 2.78474 Training err. RA 3.06776 Valid. err. 2.79554
2018-02-03 20:53:21,580 training [INFO ] Epoch  2 Batch  400 Training err. 2.74969 Training err. RA 3.05186 Valid. err. 2.75814
2018-02-03 20:53:22,423 training [INFO ] Epoch  3 Batch  420 Training err. 2.74516 Training err. RA 3.03725 Valid. err. 2.71144
2018-02-03 20:53:22,913 training [INFO ] Epoch  3 Batch  440 Training err. 2.72386 Training err. RA 3.02301 Valid. err. 2.77083
2018-02-03 20:53:23,405 training [INFO ] Epoch  3 Batch  460 Training err. 2.70074 Training err. RA 3.00900 Valid. err. 2.69311
2018-02-03 20:53:23,895 training [INFO ] Epoch  3 Batch  480 Training err. 2.65421 Training err. RA 2.99421 Valid. err. 2.67435
2018-02-03 20:53:24,384 training [INFO ] Epoch  3 Batch  500 Training err. 2.60020 Training err. RA 2.97845 Valid. err. 2.68993
2018-02-03 20:53:24,873 training [INFO ] Epoch  3 Batch  520 Training err. 2.63255 Training err. RA 2.96515 Valid. err. 2.62020
2018-02-03 20:53:25,364 training [INFO ] Epoch  3 Batch  540 Training err. 2.62715 Training err. RA 2.95263 Valid. err. 2.59262
2018-02-03 20:53:25,850 training [INFO ] Epoch  3 Batch  560 Training err. 2.53333 Training err. RA 2.93766 Valid. err. 2.57564
2018-02-03 20:53:26,336 training [INFO ] Epoch  3 Batch  580 Training err. 2.50357 Training err. RA 2.92269 Valid. err. 2.54181
2018-02-03 20:53:26,821 training [INFO ] Epoch  3 Batch  600 Training err. 2.51673 Training err. RA 2.90916 Valid. err. 2.50739
2018-02-03 20:53:27,309 training [INFO ] Epoch  3 Batch  620 Training err. 2.51071 Training err. RA 2.89630 Valid. err. 2.49454
2018-02-03 20:53:28,135 training [INFO ] Epoch  4 Batch  640 Training err. 2.45392 Training err. RA 2.88248 Valid. err. 2.49347
2018-02-03 20:53:28,620 training [INFO ] Epoch  4 Batch  660 Training err. 2.38921 Training err. RA 2.86753 Valid. err. 2.58367
2018-02-03 20:53:29,104 training [INFO ] Epoch  4 Batch  680 Training err. 2.47344 Training err. RA 2.85594 Valid. err. 2.50591
2018-02-03 20:53:29,589 training [INFO ] Epoch  4 Batch  700 Training err. 2.41822 Training err. RA 2.84343 Valid. err. 2.44265
2018-02-03 20:53:30,078 training [INFO ] Epoch  4 Batch  720 Training err. 2.37941 Training err. RA 2.83054 Valid. err. 2.43490
2018-02-03 20:53:30,572 training [INFO ] Epoch  4 Batch  740 Training err. 2.44553 Training err. RA 2.82014 Valid. err. 2.42720
2018-02-03 20:53:31,064 training [INFO ] Epoch  4 Batch  760 Training err. 2.39435 Training err. RA 2.80893 Valid. err. 2.39323
2018-02-03 20:53:31,556 training [INFO ] Epoch  4 Batch  780 Training err. 2.33377 Training err. RA 2.79675 Valid. err. 2.37215
2018-02-03 20:53:32,049 training [INFO ] Epoch  4 Batch  800 Training err. 2.33656 Training err. RA 2.78524 Valid. err. 2.34457
2018-02-03 20:53:32,542 training [INFO ] Epoch  4 Batch  820 Training err. 2.31609 Training err. RA 2.77380 Valid. err. 2.34776
2018-02-03 20:53:33,381 training [INFO ] Epoch  5 Batch  840 Training err. 2.31792 Training err. RA 2.76295 Valid. err. 2.31385
2018-02-03 20:53:33,868 training [INFO ] Epoch  5 Batch  860 Training err. 2.22681 Training err. RA 2.75048 Valid. err. 2.31130
2018-02-03 20:53:34,353 training [INFO ] Epoch  5 Batch  880 Training err. 2.29682 Training err. RA 2.74017 Valid. err. 2.30748
2018-02-03 20:53:34,839 training [INFO ] Epoch  5 Batch  900 Training err. 2.28593 Training err. RA 2.73007 Valid. err. 2.28418
2018-02-03 20:53:35,326 training [INFO ] Epoch  5 Batch  920 Training err. 2.23949 Training err. RA 2.71941 Valid. err. 2.29732
2018-02-03 20:53:35,811 training [INFO ] Epoch  5 Batch  940 Training err. 2.24659 Training err. RA 2.70935 Valid. err. 2.35004
2018-02-03 20:53:36,298 training [INFO ] Epoch  5 Batch  960 Training err. 2.30835 Training err. RA 2.70100 Valid. err. 2.26070
2018-02-03 20:53:36,783 training [INFO ] Epoch  5 Batch  980 Training err. 2.22391 Training err. RA 2.69126 Valid. err. 2.29439
2018-02-03 20:53:37,269 training [INFO ] Epoch  5 Batch 1000 Training err. 2.19018 Training err. RA 2.68124 Valid. err. 2.23289
2018-02-03 20:53:37,754 training [INFO ] Epoch  5 Batch 1020 Training err. 2.20660 Training err. RA 2.67193 Valid. err. 2.21684
2018-02-03 20:53:38,239 training [INFO ] Epoch  5 Batch 1040 Training err. 2.18998 Training err. RA 2.66266 Valid. err. 2.23507
2018-02-03 20:53:39,062 training [INFO ] Epoch  6 Batch 1060 Training err. 2.17332 Training err. RA 2.65343 Valid. err. 2.25672
2018-02-03 20:53:39,550 training [INFO ] Epoch  6 Batch 1080 Training err. 2.11589 Training err. RA 2.64348 Valid. err. 2.24667
2018-02-03 20:53:40,034 training [INFO ] Epoch  6 Batch 1100 Training err. 2.17283 Training err. RA 2.63492 Valid. err. 2.19859
2018-02-03 20:53:40,521 training [INFO ] Epoch  6 Batch 1120 Training err. 2.17227 Training err. RA 2.62666 Valid. err. 2.21475
2018-02-03 20:53:41,005 training [INFO ] Epoch  6 Batch 1140 Training err. 2.14591 Training err. RA 2.61822 Valid. err. 2.18613
2018-02-03 20:53:41,490 training [INFO ] Epoch  6 Batch 1160 Training err. 2.20732 Training err. RA 2.61114 Valid. err. 2.16476
2018-02-03 20:53:41,980 training [INFO ] Epoch  6 Batch 1180 Training err. 2.13135 Training err. RA 2.60301 Valid. err. 2.17842
2018-02-03 20:53:42,463 training [INFO ] Epoch  6 Batch 1200 Training err. 2.10721 Training err. RA 2.59474 Valid. err. 2.21320
2018-02-03 20:53:42,947 training [INFO ] Epoch  6 Batch 1220 Training err. 2.11324 Training err. RA 2.58685 Valid. err. 2.17808
2018-02-03 20:53:43,433 training [INFO ] Epoch  6 Batch 1240 Training err. 2.08663 Training err. RA 2.57878 Valid. err. 2.12664
2018-02-03 20:53:44,274 training [INFO ] Epoch  7 Batch 1260 Training err. 2.10190 Training err. RA 2.57121 Valid. err. 2.12166
2018-02-03 20:53:44,761 training [INFO ] Epoch  7 Batch 1280 Training err. 2.01070 Training err. RA 2.56245 Valid. err. 2.12953
2018-02-03 20:53:45,248 training [INFO ] Epoch  7 Batch 1300 Training err. 2.10948 Training err. RA 2.55548 Valid. err. 2.12088
2018-02-03 20:53:45,734 training [INFO ] Epoch  7 Batch 1320 Training err. 2.08971 Training err. RA 2.54843 Valid. err. 2.15509
2018-02-03 20:53:46,220 training [INFO ] Epoch  7 Batch 1340 Training err. 2.04795 Training err. RA 2.54096 Valid. err. 2.10896
2018-02-03 20:53:46,705 training [INFO ] Epoch  7 Batch 1360 Training err. 2.08329 Training err. RA 2.53423 Valid. err. 2.12741
2018-02-03 20:53:47,189 training [INFO ] Epoch  7 Batch 1380 Training err. 2.11174 Training err. RA 2.52810 Valid. err. 2.12074
2018-02-03 20:53:47,673 training [INFO ] Epoch  7 Batch 1400 Training err. 2.03937 Training err. RA 2.52112 Valid. err. 2.08947
2018-02-03 20:53:48,167 training [INFO ] Epoch  7 Batch 1420 Training err. 2.03380 Training err. RA 2.51426 Valid. err. 2.08447
2018-02-03 20:53:48,649 training [INFO ] Epoch  7 Batch 1440 Training err. 2.01841 Training err. RA 2.50737 Valid. err. 2.09844
2018-02-03 20:53:49,477 training [INFO ] Epoch  8 Batch 1460 Training err. 2.01385 Training err. RA 2.50061 Valid. err. 2.11593
2018-02-03 20:53:49,959 training [INFO ] Epoch  8 Batch 1480 Training err. 1.99337 Training err. RA 2.49376 Valid. err. 2.06921
2018-02-03 20:53:50,444 training [INFO ] Epoch  8 Batch 1500 Training err. 1.98315 Training err. RA 2.48695 Valid. err. 2.06531
2018-02-03 20:53:50,931 training [INFO ] Epoch  8 Batch 1520 Training err. 2.02283 Training err. RA 2.48084 Valid. err. 2.04450
2018-02-03 20:53:51,417 training [INFO ] Epoch  8 Batch 1540 Training err. 1.99489 Training err. RA 2.47453 Valid. err. 2.13143
2018-02-03 20:53:51,902 training [INFO ] Epoch  8 Batch 1560 Training err. 2.00757 Training err. RA 2.46854 Valid. err. 2.06002
2018-02-03 20:53:52,390 training [INFO ] Epoch  8 Batch 1580 Training err. 2.07386 Training err. RA 2.46355 Valid. err. 2.04456
2018-02-03 20:53:52,876 training [INFO ] Epoch  8 Batch 1600 Training err. 1.96267 Training err. RA 2.45729 Valid. err. 2.05549
2018-02-03 20:53:53,361 training [INFO ] Epoch  8 Batch 1620 Training err. 1.96354 Training err. RA 2.45119 Valid. err. 2.05084
2018-02-03 20:53:53,849 training [INFO ] Epoch  8 Batch 1640 Training err. 1.96432 Training err. RA 2.44525 Valid. err. 2.02510
2018-02-03 20:53:54,335 training [INFO ] Epoch  8 Batch 1660 Training err. 1.95402 Training err. RA 2.43934 Valid. err. 2.02351
2018-02-03 20:53:55,191 training [INFO ] Epoch  9 Batch 1680 Training err. 1.95460 Training err. RA 2.43356 Valid. err. 2.01619
2018-02-03 20:53:55,676 training [INFO ] Epoch  9 Batch 1700 Training err. 1.88996 Training err. RA 2.42717 Valid. err. 2.00788
2018-02-03 20:53:56,161 training [INFO ] Epoch  9 Batch 1720 Training err. 1.96294 Training err. RA 2.42177 Valid. err. 2.00759
2018-02-03 20:53:56,644 training [INFO ] Epoch  9 Batch 1740 Training err. 1.96359 Training err. RA 2.41651 Valid. err. 2.00937
2018-02-03 20:53:57,129 training [INFO ] Epoch  9 Batch 1760 Training err. 1.92835 Training err. RA 2.41096 Valid. err. 2.02681
2018-02-03 20:53:57,613 training [INFO ] Epoch  9 Batch 1780 Training err. 1.99123 Training err. RA 2.40624 Valid. err. 2.02952
2018-02-03 20:53:58,099 training [INFO ] Epoch  9 Batch 1800 Training err. 1.95515 Training err. RA 2.40123 Valid. err. 1.97264
2018-02-03 20:53:58,590 training [INFO ] Epoch  9 Batch 1820 Training err. 1.90116 Training err. RA 2.39573 Valid. err. 1.98317
2018-02-03 20:53:59,076 training [INFO ] Epoch  9 Batch 1840 Training err. 1.91869 Training err. RA 2.39055 Valid. err. 1.97273
2018-02-03 20:53:59,564 training [INFO ] Epoch  9 Batch 1860 Training err. 1.89988 Training err. RA 2.38527 Valid. err. 1.96468
2018-02-03 20:54:00,403 training [INFO ] Epoch 10 Batch 1880 Training err. 1.90127 Training err. RA 2.38012 Valid. err. 1.95213
2018-02-03 20:54:00,889 training [INFO ] Epoch 10 Batch 1900 Training err. 1.84884 Training err. RA 2.37453 Valid. err. 1.96707
2018-02-03 20:54:01,374 training [INFO ] Epoch 10 Batch 1920 Training err. 1.90785 Training err. RA 2.36967 Valid. err. 1.95520
2018-02-03 20:54:01,859 training [INFO ] Epoch 10 Batch 1940 Training err. 1.92045 Training err. RA 2.36504 Valid. err. 1.96074
2018-02-03 20:54:02,344 training [INFO ] Epoch 10 Batch 1960 Training err. 1.87965 Training err. RA 2.36009 Valid. err. 1.96267
2018-02-03 20:54:02,829 training [INFO ] Epoch 10 Batch 1980 Training err. 1.87491 Training err. RA 2.35519 Valid. err. 1.98046
2018-02-03 20:54:03,315 training [INFO ] Epoch 10 Batch 2000 Training err. 1.97213 Training err. RA 2.35135 Valid. err. 1.93407
2018-02-03 20:54:03,801 training [INFO ] Epoch 10 Batch 2020 Training err. 1.87045 Training err. RA 2.34659 Valid. err. 1.94979
2018-02-03 20:54:04,286 training [INFO ] Epoch 10 Batch 2040 Training err. 1.84949 Training err. RA 2.34172 Valid. err. 1.92339
2018-02-03 20:54:04,772 training [INFO ] Epoch 10 Batch 2060 Training err. 1.86525 Training err. RA 2.33709 Valid. err. 1.92142
2018-02-03 20:54:05,257 training [INFO ] Epoch 10 Batch 2080 Training err. 1.83522 Training err. RA 2.33227 Valid. err. 1.93129
2018-02-03 20:54:06,138 training [INFO ] Epoch 11 Batch 2100 Training err. 1.86867 Training err. RA 2.32785 Valid. err. 1.90362
2018-02-03 20:54:06,628 training [INFO ] Epoch 11 Batch 2120 Training err. 1.79601 Training err. RA 2.32284 Valid. err. 1.95400
2018-02-03 20:54:07,116 training [INFO ] Epoch 11 Batch 2140 Training err. 1.86563 Training err. RA 2.31856 Valid. err. 1.93610
2018-02-03 20:54:07,604 training [INFO ] Epoch 11 Batch 2160 Training err. 1.87396 Training err. RA 2.31445 Valid. err. 1.91812
2018-02-03 20:54:08,095 training [INFO ] Epoch 11 Batch 2180 Training err. 1.82931 Training err. RA 2.31000 Valid. err. 1.91003
2018-02-03 20:54:08,585 training [INFO ] Epoch 11 Batch 2200 Training err. 1.90275 Training err. RA 2.30629 Valid. err. 1.90595
2018-02-03 20:54:09,076 training [INFO ] Epoch 11 Batch 2220 Training err. 1.84597 Training err. RA 2.30215 Valid. err. 1.90483
2018-02-03 20:54:09,565 training [INFO ] Epoch 11 Batch 2240 Training err. 1.81125 Training err. RA 2.29776 Valid. err. 1.93389
2018-02-03 20:54:10,053 training [INFO ] Epoch 11 Batch 2260 Training err. 1.81791 Training err. RA 2.29352 Valid. err. 1.91205
2018-02-03 20:54:10,542 training [INFO ] Epoch 11 Batch 2280 Training err. 1.80519 Training err. RA 2.28923 Valid. err. 1.88068
2018-02-03 20:54:11,369 training [INFO ] Epoch 12 Batch 2300 Training err. 1.98719 Training err. RA 2.28661 Valid. err. 1.95898
2018-02-03 20:54:11,855 training [INFO ] Epoch 12 Batch 2320 Training err. 1.78248 Training err. RA 2.28226 Valid. err. 1.91434
2018-02-03 20:54:12,341 training [INFO ] Epoch 12 Batch 2340 Training err. 1.85031 Training err. RA 2.27857 Valid. err. 1.90192
2018-02-03 20:54:12,827 training [INFO ] Epoch 12 Batch 2360 Training err. 1.86487 Training err. RA 2.27506 Valid. err. 1.92316
2018-02-03 20:54:13,313 training [INFO ] Epoch 12 Batch 2380 Training err. 1.80400 Training err. RA 2.27110 Valid. err. 1.92634
2018-02-03 20:54:13,800 training [INFO ] Epoch 12 Batch 2400 Training err. 1.84723 Training err. RA 2.26757 Valid. err. 1.91393
2018-02-03 20:54:14,286 training [INFO ] Epoch 12 Batch 2420 Training err. 1.87039 Training err. RA 2.26429 Valid. err. 1.89667
2018-02-03 20:54:14,768 training [INFO ] Epoch 12 Batch 2440 Training err. 1.79089 Training err. RA 2.26041 Valid. err. 1.86996
2018-02-03 20:54:15,251 training [INFO ] Epoch 12 Batch 2460 Training err. 1.79019 Training err. RA 2.25659 Valid. err. 1.86844
2018-02-03 20:54:15,737 training [INFO ] Epoch 12 Batch 2480 Training err. 1.78517 Training err. RA 2.25278 Valid. err. 1.84296
2018-02-03 20:54:16,621 training [INFO ] Epoch 13 Batch 2500 Training err. 1.77000 Training err. RA 2.24892 Valid. err. 1.86086
2018-02-03 20:54:17,108 training [INFO ] Epoch 13 Batch 2520 Training err. 1.76144 Training err. RA 2.24505 Valid. err. 1.85836
2018-02-03 20:54:17,598 training [INFO ] Epoch 13 Batch 2540 Training err. 1.76079 Training err. RA 2.24124 Valid. err. 1.85442
2018-02-03 20:54:18,091 training [INFO ] Epoch 13 Batch 2560 Training err. 1.80190 Training err. RA 2.23781 Valid. err. 1.86270
2018-02-03 20:54:18,581 training [INFO ] Epoch 13 Batch 2580 Training err. 1.78268 Training err. RA 2.23428 Valid. err. 1.91266
2018-02-03 20:54:19,069 training [INFO ] Epoch 13 Batch 2600 Training err. 1.77634 Training err. RA 2.23076 Valid. err. 1.83800
2018-02-03 20:54:19,558 training [INFO ] Epoch 13 Batch 2620 Training err. 1.84463 Training err. RA 2.22781 Valid. err. 1.85537
2018-02-03 20:54:20,046 training [INFO ] Epoch 13 Batch 2640 Training err. 1.75083 Training err. RA 2.22420 Valid. err. 1.84881
2018-02-03 20:54:20,533 training [INFO ] Epoch 13 Batch 2660 Training err. 1.73997 Training err. RA 2.22056 Valid. err. 1.86243
2018-02-03 20:54:21,019 training [INFO ] Epoch 13 Batch 2680 Training err. 1.74505 Training err. RA 2.21701 Valid. err. 1.83030
2018-02-03 20:54:21,504 training [INFO ] Epoch 13 Batch 2700 Training err. 1.73721 Training err. RA 2.21345 Valid. err. 1.81879
2018-02-03 20:54:22,352 training [INFO ] Epoch 14 Batch 2720 Training err. 1.73483 Training err. RA 2.20993 Valid. err. 1.82231
2018-02-03 20:54:22,840 training [INFO ] Epoch 14 Batch 2740 Training err. 1.69549 Training err. RA 2.20618 Valid. err. 1.82326
2018-02-03 20:54:23,325 training [INFO ] Epoch 14 Batch 2760 Training err. 1.75450 Training err. RA 2.20291 Valid. err. 1.82183
2018-02-03 20:54:23,812 training [INFO ] Epoch 14 Batch 2780 Training err. 1.77097 Training err. RA 2.19980 Valid. err. 1.83650
2018-02-03 20:54:24,300 training [INFO ] Epoch 14 Batch 2800 Training err. 1.72672 Training err. RA 2.19642 Valid. err. 1.85179
2018-02-03 20:54:24,787 training [INFO ] Epoch 14 Batch 2820 Training err. 1.78844 Training err. RA 2.19353 Valid. err. 1.82097
2018-02-03 20:54:25,274 training [INFO ] Epoch 14 Batch 2840 Training err. 1.75624 Training err. RA 2.19045 Valid. err. 1.81352
2018-02-03 20:54:25,759 training [INFO ] Epoch 14 Batch 2860 Training err. 1.70989 Training err. RA 2.18709 Valid. err. 1.82136
2018-02-03 20:54:26,244 training [INFO ] Epoch 14 Batch 2880 Training err. 1.71767 Training err. RA 2.18383 Valid. err. 1.79951
2018-02-03 20:54:26,728 training [INFO ] Epoch 14 Batch 2900 Training err. 1.70578 Training err. RA 2.18053 Valid. err. 1.79592
2018-02-03 20:54:27,615 training [INFO ] Epoch 15 Batch 2920 Training err. 1.69802 Training err. RA 2.17722 Valid. err. 1.79219
2018-02-03 20:54:28,098 training [INFO ] Epoch 15 Batch 2940 Training err. 1.66582 Training err. RA 2.17374 Valid. err. 1.80859
2018-02-03 20:54:28,583 training [INFO ] Epoch 15 Batch 2960 Training err. 1.72219 Training err. RA 2.17069 Valid. err. 1.78729
2018-02-03 20:54:29,072 training [INFO ] Epoch 15 Batch 2980 Training err. 1.74592 Training err. RA 2.16784 Valid. err. 1.79001
2018-02-03 20:54:29,561 training [INFO ] Epoch 15 Batch 3000 Training err. 1.69952 Training err. RA 2.16472 Valid. err. 1.80045
2018-02-03 20:54:30,049 training [INFO ] Epoch 15 Batch 3020 Training err. 1.69490 Training err. RA 2.16161 Valid. err. 1.80954
2018-02-03 20:54:30,541 training [INFO ] Epoch 15 Batch 3040 Training err. 1.76661 Training err. RA 2.15901 Valid. err. 1.78055
2018-02-03 20:54:31,025 training [INFO ] Epoch 15 Batch 3060 Training err. 1.69316 Training err. RA 2.15597 Valid. err. 1.78506
2018-02-03 20:54:31,506 training [INFO ] Epoch 15 Batch 3080 Training err. 1.67108 Training err. RA 2.15282 Valid. err. 1.77264
2018-02-03 20:54:31,991 training [INFO ] Epoch 15 Batch 3100 Training err. 1.68256 Training err. RA 2.14978 Valid. err. 1.74937
2018-02-03 20:54:32,477 training [INFO ] Epoch 15 Batch 3120 Training err. 1.65819 Training err. RA 2.14663 Valid. err. 1.77409
2018-02-03 20:54:33,345 training [INFO ] Epoch 16 Batch 3140 Training err. 1.67967 Training err. RA 2.14366 Valid. err. 1.75668
2018-02-03 20:54:33,830 training [INFO ] Epoch 16 Batch 3160 Training err. 1.63371 Training err. RA 2.14043 Valid. err. 1.79204
2018-02-03 20:54:34,315 training [INFO ] Epoch 16 Batch 3180 Training err. 1.69782 Training err. RA 2.13765 Valid. err. 1.80645
2018-02-03 20:54:34,801 training [INFO ] Epoch 16 Batch 3200 Training err. 1.71437 Training err. RA 2.13500 Valid. err. 1.78282
2018-02-03 20:54:35,292 training [INFO ] Epoch 16 Batch 3220 Training err. 1.66005 Training err. RA 2.13205 Valid. err. 1.77373
2018-02-03 20:54:35,801 training [INFO ] Epoch 16 Batch 3240 Training err. 1.72933 Training err. RA 2.12957 Valid. err. 1.76400
2018-02-03 20:54:36,354 training [INFO ] Epoch 16 Batch 3260 Training err. 1.68377 Training err. RA 2.12683 Valid. err. 1.77482
2018-02-03 20:54:36,860 training [INFO ] Epoch 16 Batch 3280 Training err. 1.64355 Training err. RA 2.12388 Valid. err. 1.77954
2018-02-03 20:54:37,365 training [INFO ] Epoch 16 Batch 3300 Training err. 1.65420 Training err. RA 2.12104 Valid. err. 1.75411
2018-02-03 20:54:38,015 training [INFO ] Epoch 16 Batch 3320 Training err. 1.65122 Training err. RA 2.11821 Valid. err. 1.73389
2018-02-03 20:54:39,037 training [INFO ] Epoch 17 Batch 3340 Training err. 1.64567 Training err. RA 2.11538 Valid. err. 1.73907
2018-02-03 20:54:39,557 training [INFO ] Epoch 17 Batch 3360 Training err. 1.59709 Training err. RA 2.11229 Valid. err. 1.75347
2018-02-03 20:54:40,071 training [INFO ] Epoch 17 Batch 3380 Training err. 1.67200 Training err. RA 2.10969 Valid. err. 1.74959
2018-02-03 20:54:40,579 training [INFO ] Epoch 17 Batch 3400 Training err. 1.69419 Training err. RA 2.10724 Valid. err. 1.76485
2018-02-03 20:54:41,075 training [INFO ] Epoch 17 Batch 3420 Training err. 1.63638 Training err. RA 2.10449 Valid. err. 1.75113
2018-02-03 20:54:41,600 training [INFO ] Epoch 17 Batch 3440 Training err. 1.66518 Training err. RA 2.10194 Valid. err. 1.75760
2018-02-03 20:54:42,099 training [INFO ] Epoch 17 Batch 3460 Training err. 1.70266 Training err. RA 2.09963 Valid. err. 1.75416
2018-02-03 20:54:42,622 training [INFO ] Epoch 17 Batch 3480 Training err. 1.62522 Training err. RA 2.09690 Valid. err. 1.73541
2018-02-03 20:54:43,123 training [INFO ] Epoch 17 Batch 3500 Training err. 1.63048 Training err. RA 2.09424 Valid. err. 1.73762
2018-02-03 20:54:43,626 training [INFO ] Epoch 17 Batch 3520 Training err. 1.62322 Training err. RA 2.09156 Valid. err. 1.71406
2018-02-03 20:54:44,549 training [INFO ] Epoch 18 Batch 3540 Training err. 1.60345 Training err. RA 2.08880 Valid. err. 1.74498
2018-02-03 20:54:45,069 training [INFO ] Epoch 18 Batch 3560 Training err. 1.60899 Training err. RA 2.08611 Valid. err. 1.74100
2018-02-03 20:54:45,568 training [INFO ] Epoch 18 Batch 3580 Training err. 1.61663 Training err. RA 2.08348 Valid. err. 1.73196
2018-02-03 20:54:46,059 training [INFO ] Epoch 18 Batch 3600 Training err. 1.65182 Training err. RA 2.08108 Valid. err. 1.75421
2018-02-03 20:54:46,578 training [INFO ] Epoch 18 Batch 3620 Training err. 1.64514 Training err. RA 2.07868 Valid. err. 1.76282
2018-02-03 20:54:47,080 training [INFO ] Epoch 18 Batch 3640 Training err. 1.62403 Training err. RA 2.07618 Valid. err. 1.71744
2018-02-03 20:54:47,581 training [INFO ] Epoch 18 Batch 3660 Training err. 1.69057 Training err. RA 2.07407 Valid. err. 1.73951
2018-02-03 20:54:48,070 training [INFO ] Epoch 18 Batch 3680 Training err. 1.60205 Training err. RA 2.07151 Valid. err. 1.73785
2018-02-03 20:54:48,623 training [INFO ] Epoch 18 Batch 3700 Training err. 1.59459 Training err. RA 2.06893 Valid. err. 1.76919
2018-02-03 20:54:49,255 training [INFO ] Epoch 18 Batch 3720 Training err. 1.60053 Training err. RA 2.06641 Valid. err. 1.69947
2018-02-03 20:54:49,787 training [INFO ] Epoch 18 Batch 3740 Training err. 1.60301 Training err. RA 2.06393 Valid. err. 1.69054
2018-02-03 20:54:50,793 training [INFO ] Epoch 19 Batch 3760 Training err. 1.58774 Training err. RA 2.06140 Valid. err. 1.72299
2018-02-03 20:54:51,309 training [INFO ] Epoch 19 Batch 3780 Training err. 1.56346 Training err. RA 2.05876 Valid. err. 1.72046
2018-02-03 20:54:51,808 training [INFO ] Epoch 19 Batch 3800 Training err. 1.61709 Training err. RA 2.05644 Valid. err. 1.71522
2018-02-03 20:54:52,387 training [INFO ] Epoch 19 Batch 3820 Training err. 1.64432 Training err. RA 2.05428 Valid. err. 1.74615
2018-02-03 20:54:52,930 training [INFO ] Epoch 19 Batch 3840 Training err. 1.59036 Training err. RA 2.05187 Valid. err. 1.75201
2018-02-03 20:54:53,478 training [INFO ] Epoch 19 Batch 3860 Training err. 1.65458 Training err. RA 2.04981 Valid. err. 1.71573
2018-02-03 20:54:53,995 training [INFO ] Epoch 19 Batch 3880 Training err. 1.61910 Training err. RA 2.04759 Valid. err. 1.71220
2018-02-03 20:54:54,490 training [INFO ] Epoch 19 Batch 3900 Training err. 1.57369 Training err. RA 2.04516 Valid. err. 1.72019
2018-02-03 20:54:55,019 training [INFO ] Epoch 19 Batch 3920 Training err. 1.58306 Training err. RA 2.04280 Valid. err. 1.69124
2018-02-03 20:54:55,519 training [INFO ] Epoch 19 Batch 3940 Training err. 1.58243 Training err. RA 2.04046 Valid. err. 1.70090
2018-02-03 20:54:56,445 training [INFO ] Epoch 20 Batch 3960 Training err. 1.56351 Training err. RA 2.03805 Valid. err. 1.69838
2018-02-03 20:54:56,936 training [INFO ] Epoch 20 Batch 3980 Training err. 1.54374 Training err. RA 2.03557 Valid. err. 1.71262
2018-02-03 20:54:57,428 training [INFO ] Epoch 20 Batch 4000 Training err. 1.59633 Training err. RA 2.03337 Valid. err. 1.69464
2018-02-03 20:54:57,942 training [INFO ] Epoch 20 Batch 4020 Training err. 1.62432 Training err. RA 2.03134 Valid. err. 1.69271
2018-02-03 20:54:58,448 training [INFO ] Epoch 20 Batch 4040 Training err. 1.58225 Training err. RA 2.02911 Valid. err. 1.70350
2018-02-03 20:54:58,950 training [INFO ] Epoch 20 Batch 4060 Training err. 1.57001 Training err. RA 2.02685 Valid. err. 1.71096
2018-02-03 20:54:59,455 training [INFO ] Epoch 20 Batch 4080 Training err. 1.63789 Training err. RA 2.02495 Valid. err. 1.69189
2018-02-03 20:55:00,032 training [INFO ] Epoch 20 Batch 4100 Training err. 1.56767 Training err. RA 2.02272 Valid. err. 1.70198
2018-02-03 20:55:00,538 training [INFO ] Epoch 20 Batch 4120 Training err. 1.54706 Training err. RA 2.02041 Valid. err. 1.68219
2018-02-03 20:55:01,041 training [INFO ] Epoch 20 Batch 4140 Training err. 1.56220 Training err. RA 2.01819 Valid. err. 1.66193
2018-02-03 20:55:01,566 training [INFO ] Epoch 20 Batch 4160 Training err. 1.54367 Training err. RA 2.01591 Valid. err. 1.68455
2018-02-03 20:55:01,846 __main__ [INFO ] End of training
2018-02-03 20:55:02,074 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 64,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:55:02,704 training [INFO ] Epoch  1 Batch   20 Training err. 4.21961 Training err. RA 4.21961 Valid. err. 4.14457
2018-02-03 20:55:03,130 training [INFO ] Epoch  1 Batch   40 Training err. 4.06074 Training err. RA 4.14018 Valid. err. 3.98664
2018-02-03 20:55:03,552 training [INFO ] Epoch  1 Batch   60 Training err. 3.83761 Training err. RA 4.03932 Valid. err. 3.78935
2018-02-03 20:55:03,972 training [INFO ] Epoch  1 Batch   80 Training err. 3.67973 Training err. RA 3.94942 Valid. err. 3.62409
2018-02-03 20:55:04,415 training [INFO ] Epoch  1 Batch  100 Training err. 3.53682 Training err. RA 3.86690 Valid. err. 3.48506
2018-02-03 20:55:04,863 training [INFO ] Epoch  1 Batch  120 Training err. 3.35226 Training err. RA 3.78113 Valid. err. 3.37068
2018-02-03 20:55:05,305 training [INFO ] Epoch  1 Batch  140 Training err. 3.33295 Training err. RA 3.71710 Valid. err. 3.30238
2018-02-03 20:55:05,725 training [INFO ] Epoch  1 Batch  160 Training err. 3.25628 Training err. RA 3.65950 Valid. err. 3.25997
2018-02-03 20:55:06,167 training [INFO ] Epoch  1 Batch  180 Training err. 3.22139 Training err. RA 3.61082 Valid. err. 3.23922
2018-02-03 20:55:06,661 training [INFO ] Epoch  1 Batch  200 Training err. 3.22078 Training err. RA 3.57182 Valid. err. 3.22296
2018-02-03 20:55:07,617 training [INFO ] Epoch  2 Batch  220 Training err. 3.19595 Training err. RA 3.53765 Valid. err. 3.21476
2018-02-03 20:55:08,102 training [INFO ] Epoch  2 Batch  240 Training err. 3.18299 Training err. RA 3.50809 Valid. err. 3.20932
2018-02-03 20:55:08,573 training [INFO ] Epoch  2 Batch  260 Training err. 3.13440 Training err. RA 3.47935 Valid. err. 3.21245
2018-02-03 20:55:09,046 training [INFO ] Epoch  2 Batch  280 Training err. 3.13224 Training err. RA 3.45455 Valid. err. 3.20020
2018-02-03 20:55:09,504 training [INFO ] Epoch  2 Batch  300 Training err. 3.17495 Training err. RA 3.43591 Valid. err. 3.19504
2018-02-03 20:55:09,937 training [INFO ] Epoch  2 Batch  320 Training err. 3.11015 Training err. RA 3.41555 Valid. err. 3.19659
2018-02-03 20:55:10,372 training [INFO ] Epoch  2 Batch  340 Training err. 3.15012 Training err. RA 3.39994 Valid. err. 3.19230
2018-02-03 20:55:10,805 training [INFO ] Epoch  2 Batch  360 Training err. 3.15659 Training err. RA 3.38642 Valid. err. 3.18994
2018-02-03 20:55:11,251 training [INFO ] Epoch  2 Batch  380 Training err. 3.14818 Training err. RA 3.37388 Valid. err. 3.19004
2018-02-03 20:55:11,672 training [INFO ] Epoch  2 Batch  400 Training err. 3.15799 Training err. RA 3.36309 Valid. err. 3.18648
2018-02-03 20:55:12,566 training [INFO ] Epoch  3 Batch  420 Training err. 3.19074 Training err. RA 3.35488 Valid. err. 3.19061
2018-02-03 20:55:12,990 training [INFO ] Epoch  3 Batch  440 Training err. 3.14522 Training err. RA 3.34535 Valid. err. 3.19180
2018-02-03 20:55:13,481 training [INFO ] Epoch  3 Batch  460 Training err. 3.14279 Training err. RA 3.33654 Valid. err. 3.18784
2018-02-03 20:55:13,918 training [INFO ] Epoch  3 Batch  480 Training err. 3.06301 Training err. RA 3.32515 Valid. err. 3.19926
2018-02-03 20:55:14,336 training [INFO ] Epoch  3 Batch  500 Training err. 3.17466 Training err. RA 3.31913 Valid. err. 3.18515
2018-02-03 20:55:14,758 training [INFO ] Epoch  3 Batch  520 Training err. 3.11311 Training err. RA 3.31120 Valid. err. 3.18545
2018-02-03 20:55:15,186 training [INFO ] Epoch  3 Batch  540 Training err. 3.09757 Training err. RA 3.30329 Valid. err. 3.18597
2018-02-03 20:55:15,613 training [INFO ] Epoch  3 Batch  560 Training err. 3.16110 Training err. RA 3.29821 Valid. err. 3.18315
2018-02-03 20:55:16,029 training [INFO ] Epoch  3 Batch  580 Training err. 3.14580 Training err. RA 3.29296 Valid. err. 3.18463
2018-02-03 20:55:16,459 training [INFO ] Epoch  3 Batch  600 Training err. 3.13783 Training err. RA 3.28779 Valid. err. 3.18570
2018-02-03 20:55:16,885 training [INFO ] Epoch  3 Batch  620 Training err. 3.17665 Training err. RA 3.28420 Valid. err. 3.18112
2018-02-03 20:55:17,782 training [INFO ] Epoch  4 Batch  640 Training err. 3.14570 Training err. RA 3.27987 Valid. err. 3.17903
2018-02-03 20:55:18,234 training [INFO ] Epoch  4 Batch  660 Training err. 3.12976 Training err. RA 3.27532 Valid. err. 3.18284
2018-02-03 20:55:18,671 training [INFO ] Epoch  4 Batch  680 Training err. 3.08964 Training err. RA 3.26986 Valid. err. 3.19215
2018-02-03 20:55:19,106 training [INFO ] Epoch  4 Batch  700 Training err. 3.13269 Training err. RA 3.26594 Valid. err. 3.18246
2018-02-03 20:55:19,541 training [INFO ] Epoch  4 Batch  720 Training err. 3.13040 Training err. RA 3.26218 Valid. err. 3.18044
2018-02-03 20:55:19,967 training [INFO ] Epoch  4 Batch  740 Training err. 3.08592 Training err. RA 3.25741 Valid. err. 3.18391
2018-02-03 20:55:20,414 training [INFO ] Epoch  4 Batch  760 Training err. 3.14882 Training err. RA 3.25456 Valid. err. 3.17938
2018-02-03 20:55:20,861 training [INFO ] Epoch  4 Batch  780 Training err. 3.13146 Training err. RA 3.25140 Valid. err. 3.17908
2018-02-03 20:55:21,294 training [INFO ] Epoch  4 Batch  800 Training err. 3.13000 Training err. RA 3.24837 Valid. err. 3.17933
2018-02-03 20:55:21,740 training [INFO ] Epoch  4 Batch  820 Training err. 3.14718 Training err. RA 3.24590 Valid. err. 3.17676
2018-02-03 20:55:22,584 training [INFO ] Epoch  5 Batch  840 Training err. 3.16335 Training err. RA 3.24393 Valid. err. 3.17902
2018-02-03 20:55:22,995 training [INFO ] Epoch  5 Batch  860 Training err. 3.13434 Training err. RA 3.24138 Valid. err. 3.17644
2018-02-03 20:55:23,405 training [INFO ] Epoch  5 Batch  880 Training err. 3.11258 Training err. RA 3.23846 Valid. err. 3.18724
2018-02-03 20:55:23,814 training [INFO ] Epoch  5 Batch  900 Training err. 3.07540 Training err. RA 3.23483 Valid. err. 3.17749
2018-02-03 20:55:24,233 training [INFO ] Epoch  5 Batch  920 Training err. 3.15491 Training err. RA 3.23310 Valid. err. 3.17403
2018-02-03 20:55:24,654 training [INFO ] Epoch  5 Batch  940 Training err. 3.08797 Training err. RA 3.23001 Valid. err. 3.17706
2018-02-03 20:55:25,070 training [INFO ] Epoch  5 Batch  960 Training err. 3.10755 Training err. RA 3.22746 Valid. err. 3.17538
2018-02-03 20:55:25,483 training [INFO ] Epoch  5 Batch  980 Training err. 3.13981 Training err. RA 3.22567 Valid. err. 3.17454
2018-02-03 20:55:25,898 training [INFO ] Epoch  5 Batch 1000 Training err. 3.12503 Training err. RA 3.22366 Valid. err. 3.17576
2018-02-03 20:55:26,318 training [INFO ] Epoch  5 Batch 1020 Training err. 3.13414 Training err. RA 3.22190 Valid. err. 3.17602
2018-02-03 20:55:26,739 training [INFO ] Epoch  5 Batch 1040 Training err. 3.16397 Training err. RA 3.22079 Valid. err. 3.16971
2018-02-03 20:55:27,580 training [INFO ] Epoch  6 Batch 1060 Training err. 3.13248 Training err. RA 3.21912 Valid. err. 3.16953
2018-02-03 20:55:28,000 training [INFO ] Epoch  6 Batch 1080 Training err. 3.11941 Training err. RA 3.21727 Valid. err. 3.17325
2018-02-03 20:55:28,423 training [INFO ] Epoch  6 Batch 1100 Training err. 3.06549 Training err. RA 3.21451 Valid. err. 3.18286
2018-02-03 20:55:28,841 training [INFO ] Epoch  6 Batch 1120 Training err. 3.13433 Training err. RA 3.21308 Valid. err. 3.17077
2018-02-03 20:55:29,265 training [INFO ] Epoch  6 Batch 1140 Training err. 3.10784 Training err. RA 3.21124 Valid. err. 3.16984
2018-02-03 20:55:29,687 training [INFO ] Epoch  6 Batch 1160 Training err. 3.06223 Training err. RA 3.20867 Valid. err. 3.17303
2018-02-03 20:55:30,104 training [INFO ] Epoch  6 Batch 1180 Training err. 3.14663 Training err. RA 3.20761 Valid. err. 3.17523
2018-02-03 20:55:30,519 training [INFO ] Epoch  6 Batch 1200 Training err. 3.12008 Training err. RA 3.20616 Valid. err. 3.16721
2018-02-03 20:55:30,933 training [INFO ] Epoch  6 Batch 1220 Training err. 3.12206 Training err. RA 3.20478 Valid. err. 3.16663
2018-02-03 20:55:31,349 training [INFO ] Epoch  6 Batch 1240 Training err. 3.13835 Training err. RA 3.20371 Valid. err. 3.16332
2018-02-03 20:55:32,187 training [INFO ] Epoch  7 Batch 1260 Training err. 3.13666 Training err. RA 3.20264 Valid. err. 3.16269
2018-02-03 20:55:32,602 training [INFO ] Epoch  7 Batch 1280 Training err. 3.12621 Training err. RA 3.20145 Valid. err. 3.16475
2018-02-03 20:55:33,015 training [INFO ] Epoch  7 Batch 1300 Training err. 3.08081 Training err. RA 3.19959 Valid. err. 3.17122
2018-02-03 20:55:33,429 training [INFO ] Epoch  7 Batch 1320 Training err. 3.08671 Training err. RA 3.19788 Valid. err. 3.16279
2018-02-03 20:55:33,844 training [INFO ] Epoch  7 Batch 1340 Training err. 3.12544 Training err. RA 3.19680 Valid. err. 3.16004
2018-02-03 20:55:34,264 training [INFO ] Epoch  7 Batch 1360 Training err. 3.06371 Training err. RA 3.19484 Valid. err. 3.16311
2018-02-03 20:55:34,691 training [INFO ] Epoch  7 Batch 1380 Training err. 3.10775 Training err. RA 3.19358 Valid. err. 3.15975
2018-02-03 20:55:35,118 training [INFO ] Epoch  7 Batch 1400 Training err. 3.11631 Training err. RA 3.19248 Valid. err. 3.15729
2018-02-03 20:55:35,538 training [INFO ] Epoch  7 Batch 1420 Training err. 3.10688 Training err. RA 3.19127 Valid. err. 3.15702
2018-02-03 20:55:35,959 training [INFO ] Epoch  7 Batch 1440 Training err. 3.11884 Training err. RA 3.19026 Valid. err. 3.15359
2018-02-03 20:55:36,802 training [INFO ] Epoch  8 Batch 1460 Training err. 3.15269 Training err. RA 3.18975 Valid. err. 3.15698
2018-02-03 20:55:37,225 training [INFO ] Epoch  8 Batch 1480 Training err. 3.10654 Training err. RA 3.18863 Valid. err. 3.15911
2018-02-03 20:55:37,648 training [INFO ] Epoch  8 Batch 1500 Training err. 3.09831 Training err. RA 3.18742 Valid. err. 3.15238
2018-02-03 20:55:38,067 training [INFO ] Epoch  8 Batch 1520 Training err. 3.03407 Training err. RA 3.18540 Valid. err. 3.16238
2018-02-03 20:55:38,480 training [INFO ] Epoch  8 Batch 1540 Training err. 3.13153 Training err. RA 3.18470 Valid. err. 3.14822
2018-02-03 20:55:38,891 training [INFO ] Epoch  8 Batch 1560 Training err. 3.06740 Training err. RA 3.18320 Valid. err. 3.14642
2018-02-03 20:55:39,308 training [INFO ] Epoch  8 Batch 1580 Training err. 3.05571 Training err. RA 3.18159 Valid. err. 3.14566
2018-02-03 20:55:39,726 training [INFO ] Epoch  8 Batch 1600 Training err. 3.11682 Training err. RA 3.18078 Valid. err. 3.14152
2018-02-03 20:55:40,144 training [INFO ] Epoch  8 Batch 1620 Training err. 3.09724 Training err. RA 3.17975 Valid. err. 3.14122
2018-02-03 20:55:40,558 training [INFO ] Epoch  8 Batch 1640 Training err. 3.09151 Training err. RA 3.17867 Valid. err. 3.14136
2018-02-03 20:55:40,973 training [INFO ] Epoch  8 Batch 1660 Training err. 3.12916 Training err. RA 3.17807 Valid. err. 3.13418
2018-02-03 20:55:41,822 training [INFO ] Epoch  9 Batch 1680 Training err. 3.09752 Training err. RA 3.17711 Valid. err. 3.12960
2018-02-03 20:55:42,245 training [INFO ] Epoch  9 Batch 1700 Training err. 3.07607 Training err. RA 3.17593 Valid. err. 3.13056
2018-02-03 20:55:42,668 training [INFO ] Epoch  9 Batch 1720 Training err. 3.04578 Training err. RA 3.17441 Valid. err. 3.14006
2018-02-03 20:55:43,089 training [INFO ] Epoch  9 Batch 1740 Training err. 3.08565 Training err. RA 3.17339 Valid. err. 3.12697
2018-02-03 20:55:43,511 training [INFO ] Epoch  9 Batch 1760 Training err. 3.07102 Training err. RA 3.17223 Valid. err. 3.12139
2018-02-03 20:55:43,930 training [INFO ] Epoch  9 Batch 1780 Training err. 3.02452 Training err. RA 3.17057 Valid. err. 3.12283
2018-02-03 20:55:44,348 training [INFO ] Epoch  9 Batch 1800 Training err. 3.08629 Training err. RA 3.16963 Valid. err. 3.11451
2018-02-03 20:55:44,765 training [INFO ] Epoch  9 Batch 1820 Training err. 3.06624 Training err. RA 3.16850 Valid. err. 3.11079
2018-02-03 20:55:45,189 training [INFO ] Epoch  9 Batch 1840 Training err. 3.06167 Training err. RA 3.16733 Valid. err. 3.10758
2018-02-03 20:55:45,607 training [INFO ] Epoch  9 Batch 1860 Training err. 3.07893 Training err. RA 3.16638 Valid. err. 3.10136
2018-02-03 20:55:46,426 training [INFO ] Epoch 10 Batch 1880 Training err. 3.09468 Training err. RA 3.16562 Valid. err. 3.10141
2018-02-03 20:55:46,842 training [INFO ] Epoch 10 Batch 1900 Training err. 3.05821 Training err. RA 3.16449 Valid. err. 3.09404
2018-02-03 20:55:47,256 training [INFO ] Epoch 10 Batch 1920 Training err. 3.03168 Training err. RA 3.16311 Valid. err. 3.10130
2018-02-03 20:55:47,666 training [INFO ] Epoch 10 Batch 1940 Training err. 3.01903 Training err. RA 3.16162 Valid. err. 3.09095
2018-02-03 20:55:48,073 training [INFO ] Epoch 10 Batch 1960 Training err. 3.06638 Training err. RA 3.16065 Valid. err. 3.08202
2018-02-03 20:55:48,481 training [INFO ] Epoch 10 Batch 1980 Training err. 2.99455 Training err. RA 3.15897 Valid. err. 3.07899
2018-02-03 20:55:48,890 training [INFO ] Epoch 10 Batch 2000 Training err. 3.01611 Training err. RA 3.15754 Valid. err. 3.07285
2018-02-03 20:55:49,300 training [INFO ] Epoch 10 Batch 2020 Training err. 3.04327 Training err. RA 3.15641 Valid. err. 3.06711
2018-02-03 20:55:49,708 training [INFO ] Epoch 10 Batch 2040 Training err. 3.01939 Training err. RA 3.15507 Valid. err. 3.06324
2018-02-03 20:55:50,120 training [INFO ] Epoch 10 Batch 2060 Training err. 3.03517 Training err. RA 3.15390 Valid. err. 3.05969
2018-02-03 20:55:50,537 training [INFO ] Epoch 10 Batch 2080 Training err. 3.04712 Training err. RA 3.15288 Valid. err. 3.04670
2018-02-03 20:55:51,402 training [INFO ] Epoch 11 Batch 2100 Training err. 3.02329 Training err. RA 3.15164 Valid. err. 3.04216
2018-02-03 20:55:51,826 training [INFO ] Epoch 11 Batch 2120 Training err. 2.99791 Training err. RA 3.15019 Valid. err. 3.04059
2018-02-03 20:55:52,245 training [INFO ] Epoch 11 Batch 2140 Training err. 2.97237 Training err. RA 3.14853 Valid. err. 3.06163
2018-02-03 20:55:52,668 training [INFO ] Epoch 11 Batch 2160 Training err. 3.01469 Training err. RA 3.14729 Valid. err. 3.03009
2018-02-03 20:55:53,093 training [INFO ] Epoch 11 Batch 2180 Training err. 2.96780 Training err. RA 3.14565 Valid. err. 3.02224
2018-02-03 20:55:53,516 training [INFO ] Epoch 11 Batch 2200 Training err. 2.92992 Training err. RA 3.14368 Valid. err. 3.02216
2018-02-03 20:55:53,933 training [INFO ] Epoch 11 Batch 2220 Training err. 3.00623 Training err. RA 3.14245 Valid. err. 3.02012
2018-02-03 20:55:54,351 training [INFO ] Epoch 11 Batch 2240 Training err. 2.95531 Training err. RA 3.14078 Valid. err. 3.00344
2018-02-03 20:55:54,767 training [INFO ] Epoch 11 Batch 2260 Training err. 2.97237 Training err. RA 3.13929 Valid. err. 3.00272
2018-02-03 20:55:55,190 training [INFO ] Epoch 11 Batch 2280 Training err. 2.98143 Training err. RA 3.13790 Valid. err. 2.98726
2018-02-03 20:55:56,026 training [INFO ] Epoch 12 Batch 2300 Training err. 2.98464 Training err. RA 3.13657 Valid. err. 2.98508
2018-02-03 20:55:56,439 training [INFO ] Epoch 12 Batch 2320 Training err. 2.95547 Training err. RA 3.13501 Valid. err. 2.97865
2018-02-03 20:55:56,852 training [INFO ] Epoch 12 Batch 2340 Training err. 2.91516 Training err. RA 3.13313 Valid. err. 2.98467
2018-02-03 20:55:57,268 training [INFO ] Epoch 12 Batch 2360 Training err. 2.93218 Training err. RA 3.13142 Valid. err. 2.96748
2018-02-03 20:55:57,688 training [INFO ] Epoch 12 Batch 2380 Training err. 2.93706 Training err. RA 3.12979 Valid. err. 2.95727
2018-02-03 20:55:58,116 training [INFO ] Epoch 12 Batch 2400 Training err. 2.86776 Training err. RA 3.12761 Valid. err. 2.95661
2018-02-03 20:55:58,528 training [INFO ] Epoch 12 Batch 2420 Training err. 2.91618 Training err. RA 3.12586 Valid. err. 2.94712
2018-02-03 20:55:58,943 training [INFO ] Epoch 12 Batch 2440 Training err. 2.91415 Training err. RA 3.12412 Valid. err. 2.93864
2018-02-03 20:55:59,363 training [INFO ] Epoch 12 Batch 2460 Training err. 2.89666 Training err. RA 3.12228 Valid. err. 2.93314
2018-02-03 20:55:59,790 training [INFO ] Epoch 12 Batch 2480 Training err. 2.91192 Training err. RA 3.12058 Valid. err. 2.92800
2018-02-03 20:56:00,667 training [INFO ] Epoch 13 Batch 2500 Training err. 2.94302 Training err. RA 3.11916 Valid. err. 2.92230
2018-02-03 20:56:01,089 training [INFO ] Epoch 13 Batch 2520 Training err. 2.89172 Training err. RA 3.11735 Valid. err. 2.92329
2018-02-03 20:56:01,506 training [INFO ] Epoch 13 Batch 2540 Training err. 2.85895 Training err. RA 3.11532 Valid. err. 2.91422
2018-02-03 20:56:01,921 training [INFO ] Epoch 13 Batch 2560 Training err. 2.83557 Training err. RA 3.11313 Valid. err. 2.92811
2018-02-03 20:56:02,336 training [INFO ] Epoch 13 Batch 2580 Training err. 2.89943 Training err. RA 3.11148 Valid. err. 2.89726
2018-02-03 20:56:02,748 training [INFO ] Epoch 13 Batch 2600 Training err. 2.82338 Training err. RA 3.10926 Valid. err. 2.89161
2018-02-03 20:56:03,170 training [INFO ] Epoch 13 Batch 2620 Training err. 2.81290 Training err. RA 3.10700 Valid. err. 2.89040
2018-02-03 20:56:03,588 training [INFO ] Epoch 13 Batch 2640 Training err. 2.87165 Training err. RA 3.10522 Valid. err. 2.87682
2018-02-03 20:56:04,002 training [INFO ] Epoch 13 Batch 2660 Training err. 2.83006 Training err. RA 3.10315 Valid. err. 2.87500
2018-02-03 20:56:04,413 training [INFO ] Epoch 13 Batch 2680 Training err. 2.83953 Training err. RA 3.10118 Valid. err. 2.87561
2018-02-03 20:56:04,828 training [INFO ] Epoch 13 Batch 2700 Training err. 2.87253 Training err. RA 3.09949 Valid. err. 2.85749
2018-02-03 20:56:05,675 training [INFO ] Epoch 14 Batch 2720 Training err. 2.83531 Training err. RA 3.09754 Valid. err. 2.85414
2018-02-03 20:56:06,096 training [INFO ] Epoch 14 Batch 2740 Training err. 2.80817 Training err. RA 3.09543 Valid. err. 2.85623
2018-02-03 20:56:06,518 training [INFO ] Epoch 14 Batch 2760 Training err. 2.78029 Training err. RA 3.09315 Valid. err. 2.85823
2018-02-03 20:56:06,938 training [INFO ] Epoch 14 Batch 2780 Training err. 2.82356 Training err. RA 3.09121 Valid. err. 2.84282
2018-02-03 20:56:07,358 training [INFO ] Epoch 14 Batch 2800 Training err. 2.80266 Training err. RA 3.08915 Valid. err. 2.83128
2018-02-03 20:56:07,776 training [INFO ] Epoch 14 Batch 2820 Training err. 2.74699 Training err. RA 3.08672 Valid. err. 2.83972
2018-02-03 20:56:08,199 training [INFO ] Epoch 14 Batch 2840 Training err. 2.80652 Training err. RA 3.08475 Valid. err. 2.81786
2018-02-03 20:56:08,623 training [INFO ] Epoch 14 Batch 2860 Training err. 2.77622 Training err. RA 3.08259 Valid. err. 2.81611
2018-02-03 20:56:09,047 training [INFO ] Epoch 14 Batch 2880 Training err. 2.78012 Training err. RA 3.08049 Valid. err. 2.80713
2018-02-03 20:56:09,466 training [INFO ] Epoch 14 Batch 2900 Training err. 2.79128 Training err. RA 3.07849 Valid. err. 2.80265
2018-02-03 20:56:10,313 training [INFO ] Epoch 15 Batch 2920 Training err. 2.79856 Training err. RA 3.07658 Valid. err. 2.80408
2018-02-03 20:56:10,728 training [INFO ] Epoch 15 Batch 2940 Training err. 2.77239 Training err. RA 3.07451 Valid. err. 2.78977
2018-02-03 20:56:11,147 training [INFO ] Epoch 15 Batch 2960 Training err. 2.73924 Training err. RA 3.07224 Valid. err. 2.79206
2018-02-03 20:56:11,567 training [INFO ] Epoch 15 Batch 2980 Training err. 2.72212 Training err. RA 3.06989 Valid. err. 2.79250
2018-02-03 20:56:11,978 training [INFO ] Epoch 15 Batch 3000 Training err. 2.78538 Training err. RA 3.06800 Valid. err. 2.78048
2018-02-03 20:56:12,392 training [INFO ] Epoch 15 Batch 3020 Training err. 2.69981 Training err. RA 3.06556 Valid. err. 2.79220
2018-02-03 20:56:12,805 training [INFO ] Epoch 15 Batch 3040 Training err. 2.72123 Training err. RA 3.06329 Valid. err. 2.77379
2018-02-03 20:56:13,220 training [INFO ] Epoch 15 Batch 3060 Training err. 2.76120 Training err. RA 3.06132 Valid. err. 2.76012
2018-02-03 20:56:13,639 training [INFO ] Epoch 15 Batch 3080 Training err. 2.72432 Training err. RA 3.05913 Valid. err. 2.76174
2018-02-03 20:56:14,058 training [INFO ] Epoch 15 Batch 3100 Training err. 2.73626 Training err. RA 3.05705 Valid. err. 2.75764
2018-02-03 20:56:14,468 training [INFO ] Epoch 15 Batch 3120 Training err. 2.75782 Training err. RA 3.05513 Valid. err. 2.74009
2018-02-03 20:56:15,315 training [INFO ] Epoch 16 Batch 3140 Training err. 2.72315 Training err. RA 3.05301 Valid. err. 2.73716
2018-02-03 20:56:15,729 training [INFO ] Epoch 16 Batch 3160 Training err. 2.71353 Training err. RA 3.05086 Valid. err. 2.74614
2018-02-03 20:56:16,147 training [INFO ] Epoch 16 Batch 3180 Training err. 2.65121 Training err. RA 3.04835 Valid. err. 2.75720
2018-02-03 20:56:16,564 training [INFO ] Epoch 16 Batch 3200 Training err. 2.73043 Training err. RA 3.04636 Valid. err. 2.72914
2018-02-03 20:56:16,976 training [INFO ] Epoch 16 Batch 3220 Training err. 2.68799 Training err. RA 3.04414 Valid. err. 2.72936
2018-02-03 20:56:17,390 training [INFO ] Epoch 16 Batch 3240 Training err. 2.64052 Training err. RA 3.04165 Valid. err. 2.73038
2018-02-03 20:56:17,804 training [INFO ] Epoch 16 Batch 3260 Training err. 2.73140 Training err. RA 3.03974 Valid. err. 2.82843
2018-02-03 20:56:18,222 training [INFO ] Epoch 16 Batch 3280 Training err. 2.67920 Training err. RA 3.03755 Valid. err. 2.71002
2018-02-03 20:56:18,652 training [INFO ] Epoch 16 Batch 3300 Training err. 2.69205 Training err. RA 3.03545 Valid. err. 2.72344
2018-02-03 20:56:19,077 training [INFO ] Epoch 16 Batch 3320 Training err. 2.70116 Training err. RA 3.03344 Valid. err. 2.70797
2018-02-03 20:56:19,942 training [INFO ] Epoch 17 Batch 3340 Training err. 2.68033 Training err. RA 3.03132 Valid. err. 2.70225
2018-02-03 20:56:20,361 training [INFO ] Epoch 17 Batch 3360 Training err. 2.69175 Training err. RA 3.02930 Valid. err. 2.69191
2018-02-03 20:56:20,784 training [INFO ] Epoch 17 Batch 3380 Training err. 2.63215 Training err. RA 3.02695 Valid. err. 2.69974
2018-02-03 20:56:21,209 training [INFO ] Epoch 17 Batch 3400 Training err. 2.65155 Training err. RA 3.02474 Valid. err. 2.68725
2018-02-03 20:56:21,637 training [INFO ] Epoch 17 Batch 3420 Training err. 2.68739 Training err. RA 3.02277 Valid. err. 2.67839
2018-02-03 20:56:22,059 training [INFO ] Epoch 17 Batch 3440 Training err. 2.61252 Training err. RA 3.02039 Valid. err. 2.68638
2018-02-03 20:56:22,469 training [INFO ] Epoch 17 Batch 3460 Training err. 2.64551 Training err. RA 3.01822 Valid. err. 2.67522
2018-02-03 20:56:22,886 training [INFO ] Epoch 17 Batch 3480 Training err. 2.67056 Training err. RA 3.01622 Valid. err. 2.67892
2018-02-03 20:56:23,301 training [INFO ] Epoch 17 Batch 3500 Training err. 2.63284 Training err. RA 3.01403 Valid. err. 2.67268
2018-02-03 20:56:23,720 training [INFO ] Epoch 17 Batch 3520 Training err. 2.64806 Training err. RA 3.01195 Valid. err. 2.65922
2018-02-03 20:56:24,519 training [INFO ] Epoch 18 Batch 3540 Training err. 2.67870 Training err. RA 3.01007 Valid. err. 2.65747
2018-02-03 20:56:24,934 training [INFO ] Epoch 18 Batch 3560 Training err. 2.64283 Training err. RA 3.00800 Valid. err. 2.65694
2018-02-03 20:56:25,348 training [INFO ] Epoch 18 Batch 3580 Training err. 2.63940 Training err. RA 3.00595 Valid. err. 2.65210
2018-02-03 20:56:25,762 training [INFO ] Epoch 18 Batch 3600 Training err. 2.55085 Training err. RA 3.00342 Valid. err. 2.69238
2018-02-03 20:56:26,183 training [INFO ] Epoch 18 Batch 3620 Training err. 2.66995 Training err. RA 3.00157 Valid. err. 2.64425
2018-02-03 20:56:26,609 training [INFO ] Epoch 18 Batch 3640 Training err. 2.59633 Training err. RA 2.99935 Valid. err. 2.65945
2018-02-03 20:56:27,027 training [INFO ] Epoch 18 Batch 3660 Training err. 2.57582 Training err. RA 2.99703 Valid. err. 2.65349
2018-02-03 20:56:27,446 training [INFO ] Epoch 18 Batch 3680 Training err. 2.66032 Training err. RA 2.99520 Valid. err. 2.65305
2018-02-03 20:56:27,867 training [INFO ] Epoch 18 Batch 3700 Training err. 2.60344 Training err. RA 2.99309 Valid. err. 2.63705
2018-02-03 20:56:28,288 training [INFO ] Epoch 18 Batch 3720 Training err. 2.60269 Training err. RA 2.99099 Valid. err. 2.63038
2018-02-03 20:56:28,712 training [INFO ] Epoch 18 Batch 3740 Training err. 2.64025 Training err. RA 2.98911 Valid. err. 2.62970
2018-02-03 20:56:29,522 training [INFO ] Epoch 19 Batch 3760 Training err. 2.60964 Training err. RA 2.98709 Valid. err. 2.66022
2018-02-03 20:56:29,940 training [INFO ] Epoch 19 Batch 3780 Training err. 2.60515 Training err. RA 2.98507 Valid. err. 2.65294
2018-02-03 20:56:30,352 training [INFO ] Epoch 19 Batch 3800 Training err. 2.55567 Training err. RA 2.98281 Valid. err. 2.62696
2018-02-03 20:56:30,767 training [INFO ] Epoch 19 Batch 3820 Training err. 2.58960 Training err. RA 2.98075 Valid. err. 2.62833
2018-02-03 20:56:31,183 training [INFO ] Epoch 19 Batch 3840 Training err. 2.60705 Training err. RA 2.97881 Valid. err. 2.62916
2018-02-03 20:56:31,600 training [INFO ] Epoch 19 Batch 3860 Training err. 2.55542 Training err. RA 2.97661 Valid. err. 2.62225
2018-02-03 20:56:32,012 training [INFO ] Epoch 19 Batch 3880 Training err. 2.60451 Training err. RA 2.97470 Valid. err. 2.63161
2018-02-03 20:56:32,427 training [INFO ] Epoch 19 Batch 3900 Training err. 2.57530 Training err. RA 2.97265 Valid. err. 2.63414
2018-02-03 20:56:32,845 training [INFO ] Epoch 19 Batch 3920 Training err. 2.57138 Training err. RA 2.97060 Valid. err. 2.59556
2018-02-03 20:56:33,260 training [INFO ] Epoch 19 Batch 3940 Training err. 2.58463 Training err. RA 2.96864 Valid. err. 2.59190
2018-02-03 20:56:34,053 training [INFO ] Epoch 20 Batch 3960 Training err. 2.58874 Training err. RA 2.96672 Valid. err. 2.58646
2018-02-03 20:56:34,469 training [INFO ] Epoch 20 Batch 3980 Training err. 2.59468 Training err. RA 2.96485 Valid. err. 2.58686
2018-02-03 20:56:34,886 training [INFO ] Epoch 20 Batch 4000 Training err. 2.56171 Training err. RA 2.96284 Valid. err. 2.60317
2018-02-03 20:56:35,297 training [INFO ] Epoch 20 Batch 4020 Training err. 2.50233 Training err. RA 2.96055 Valid. err. 2.59180
2018-02-03 20:56:35,716 training [INFO ] Epoch 20 Batch 4040 Training err. 2.60552 Training err. RA 2.95879 Valid. err. 2.57833
2018-02-03 20:56:36,135 training [INFO ] Epoch 20 Batch 4060 Training err. 2.52728 Training err. RA 2.95666 Valid. err. 2.59996
2018-02-03 20:56:36,547 training [INFO ] Epoch 20 Batch 4080 Training err. 2.54477 Training err. RA 2.95464 Valid. err. 2.59197
2018-02-03 20:56:36,963 training [INFO ] Epoch 20 Batch 4100 Training err. 2.58263 Training err. RA 2.95283 Valid. err. 2.56994
2018-02-03 20:56:37,377 training [INFO ] Epoch 20 Batch 4120 Training err. 2.52735 Training err. RA 2.95076 Valid. err. 2.56815
2018-02-03 20:56:37,792 training [INFO ] Epoch 20 Batch 4140 Training err. 2.54845 Training err. RA 2.94882 Valid. err. 2.57234
2018-02-03 20:56:38,214 training [INFO ] Epoch 20 Batch 4160 Training err. 2.57824 Training err. RA 2.94704 Valid. err. 2.56502
2018-02-03 20:56:38,489 __main__ [INFO ] End of training
2018-02-03 20:56:38,777 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 64,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:56:39,344 training [INFO ] Epoch  1 Batch   20 Training err. 3.60822 Training err. RA 3.60822 Valid. err. 3.24156
2018-02-03 20:56:39,767 training [INFO ] Epoch  1 Batch   40 Training err. 3.19370 Training err. RA 3.40096 Valid. err. 3.22693
2018-02-03 20:56:40,193 training [INFO ] Epoch  1 Batch   60 Training err. 3.13624 Training err. RA 3.31272 Valid. err. 3.27488
2018-02-03 20:56:40,616 training [INFO ] Epoch  1 Batch   80 Training err. 3.16599 Training err. RA 3.27604 Valid. err. 3.18565
2018-02-03 20:56:41,034 training [INFO ] Epoch  1 Batch  100 Training err. 3.12126 Training err. RA 3.24508 Valid. err. 3.18235
2018-02-03 20:56:41,455 training [INFO ] Epoch  1 Batch  120 Training err. 3.09123 Training err. RA 3.21944 Valid. err. 3.17990
2018-02-03 20:56:41,872 training [INFO ] Epoch  1 Batch  140 Training err. 3.15044 Training err. RA 3.20958 Valid. err. 3.21097
2018-02-03 20:56:42,282 training [INFO ] Epoch  1 Batch  160 Training err. 3.12053 Training err. RA 3.19845 Valid. err. 3.16000
2018-02-03 20:56:42,702 training [INFO ] Epoch  1 Batch  180 Training err. 3.12097 Training err. RA 3.18984 Valid. err. 3.15189
2018-02-03 20:56:43,118 training [INFO ] Epoch  1 Batch  200 Training err. 3.11657 Training err. RA 3.18251 Valid. err. 3.12590
2018-02-03 20:56:43,905 training [INFO ] Epoch  2 Batch  220 Training err. 3.09953 Training err. RA 3.17497 Valid. err. 3.10561
2018-02-03 20:56:44,321 training [INFO ] Epoch  2 Batch  240 Training err. 3.06156 Training err. RA 3.16552 Valid. err. 3.08760
2018-02-03 20:56:44,737 training [INFO ] Epoch  2 Batch  260 Training err. 3.01058 Training err. RA 3.15360 Valid. err. 3.05292
2018-02-03 20:56:45,156 training [INFO ] Epoch  2 Batch  280 Training err. 2.98187 Training err. RA 3.14133 Valid. err. 3.00001
2018-02-03 20:56:45,573 training [INFO ] Epoch  2 Batch  300 Training err. 2.96070 Training err. RA 3.12929 Valid. err. 2.96910
2018-02-03 20:56:45,985 training [INFO ] Epoch  2 Batch  320 Training err. 2.85901 Training err. RA 3.11240 Valid. err. 2.92001
2018-02-03 20:56:46,398 training [INFO ] Epoch  2 Batch  340 Training err. 2.85596 Training err. RA 3.09731 Valid. err. 2.85177
2018-02-03 20:56:46,814 training [INFO ] Epoch  2 Batch  360 Training err. 2.82391 Training err. RA 3.08213 Valid. err. 2.89264
2018-02-03 20:56:47,231 training [INFO ] Epoch  2 Batch  380 Training err. 2.79181 Training err. RA 3.06685 Valid. err. 2.79173
2018-02-03 20:56:47,648 training [INFO ] Epoch  2 Batch  400 Training err. 2.77351 Training err. RA 3.05218 Valid. err. 2.75461
2018-02-03 20:56:48,439 training [INFO ] Epoch  3 Batch  420 Training err. 2.74602 Training err. RA 3.03760 Valid. err. 2.71088
2018-02-03 20:56:48,855 training [INFO ] Epoch  3 Batch  440 Training err. 2.69263 Training err. RA 3.02192 Valid. err. 2.69873
2018-02-03 20:56:49,269 training [INFO ] Epoch  3 Batch  460 Training err. 2.67768 Training err. RA 3.00695 Valid. err. 2.65783
2018-02-03 20:56:49,691 training [INFO ] Epoch  3 Batch  480 Training err. 2.55851 Training err. RA 2.98827 Valid. err. 2.65067
2018-02-03 20:56:50,114 training [INFO ] Epoch  3 Batch  500 Training err. 2.65164 Training err. RA 2.97480 Valid. err. 2.62302
2018-02-03 20:56:50,532 training [INFO ] Epoch  3 Batch  520 Training err. 2.56731 Training err. RA 2.95913 Valid. err. 2.59004
2018-02-03 20:56:50,959 training [INFO ] Epoch  3 Batch  540 Training err. 2.51801 Training err. RA 2.94279 Valid. err. 2.58169
2018-02-03 20:56:51,382 training [INFO ] Epoch  3 Batch  560 Training err. 2.57482 Training err. RA 2.92965 Valid. err. 2.56801
2018-02-03 20:56:51,803 training [INFO ] Epoch  3 Batch  580 Training err. 2.51321 Training err. RA 2.91529 Valid. err. 2.54504
2018-02-03 20:56:52,229 training [INFO ] Epoch  3 Batch  600 Training err. 2.49277 Training err. RA 2.90121 Valid. err. 2.53526
2018-02-03 20:56:52,654 training [INFO ] Epoch  3 Batch  620 Training err. 2.52721 Training err. RA 2.88914 Valid. err. 2.51943
2018-02-03 20:56:53,468 training [INFO ] Epoch  4 Batch  640 Training err. 2.48196 Training err. RA 2.87642 Valid. err. 2.50711
2018-02-03 20:56:53,891 training [INFO ] Epoch  4 Batch  660 Training err. 2.46633 Training err. RA 2.86399 Valid. err. 2.46042
2018-02-03 20:56:54,307 training [INFO ] Epoch  4 Batch  680 Training err. 2.38215 Training err. RA 2.84982 Valid. err. 2.46017
2018-02-03 20:56:54,726 training [INFO ] Epoch  4 Batch  700 Training err. 2.39714 Training err. RA 2.83689 Valid. err. 2.47511
2018-02-03 20:56:55,145 training [INFO ] Epoch  4 Batch  720 Training err. 2.43109 Training err. RA 2.82561 Valid. err. 2.42506
2018-02-03 20:56:55,560 training [INFO ] Epoch  4 Batch  740 Training err. 2.35118 Training err. RA 2.81279 Valid. err. 2.39536
2018-02-03 20:56:55,975 training [INFO ] Epoch  4 Batch  760 Training err. 2.39548 Training err. RA 2.80181 Valid. err. 2.43247
2018-02-03 20:56:56,390 training [INFO ] Epoch  4 Batch  780 Training err. 2.32774 Training err. RA 2.78965 Valid. err. 2.37251
2018-02-03 20:56:56,805 training [INFO ] Epoch  4 Batch  800 Training err. 2.33281 Training err. RA 2.77823 Valid. err. 2.33004
2018-02-03 20:56:57,223 training [INFO ] Epoch  4 Batch  820 Training err. 2.33061 Training err. RA 2.76731 Valid. err. 2.32655
2018-02-03 20:56:58,020 training [INFO ] Epoch  5 Batch  840 Training err. 2.30866 Training err. RA 2.75639 Valid. err. 2.30468
2018-02-03 20:56:58,442 training [INFO ] Epoch  5 Batch  860 Training err. 2.33782 Training err. RA 2.74666 Valid. err. 2.30759
2018-02-03 20:56:58,867 training [INFO ] Epoch  5 Batch  880 Training err. 2.26906 Training err. RA 2.73581 Valid. err. 2.30049
2018-02-03 20:56:59,291 training [INFO ] Epoch  5 Batch  900 Training err. 2.20030 Training err. RA 2.72391 Valid. err. 2.28598
2018-02-03 20:56:59,714 training [INFO ] Epoch  5 Batch  920 Training err. 2.29153 Training err. RA 2.71451 Valid. err. 2.28259
2018-02-03 20:57:00,143 training [INFO ] Epoch  5 Batch  940 Training err. 2.21685 Training err. RA 2.70392 Valid. err. 2.27455
2018-02-03 20:57:00,566 training [INFO ] Epoch  5 Batch  960 Training err. 2.22836 Training err. RA 2.69401 Valid. err. 2.24014
2018-02-03 20:57:00,983 training [INFO ] Epoch  5 Batch  980 Training err. 2.24516 Training err. RA 2.68485 Valid. err. 2.23706
2018-02-03 20:57:01,405 training [INFO ] Epoch  5 Batch 1000 Training err. 2.18756 Training err. RA 2.67490 Valid. err. 2.23371
2018-02-03 20:57:01,830 training [INFO ] Epoch  5 Batch 1020 Training err. 2.20399 Training err. RA 2.66567 Valid. err. 2.20540
2018-02-03 20:57:02,248 training [INFO ] Epoch  5 Batch 1040 Training err. 2.20571 Training err. RA 2.65682 Valid. err. 2.19396
2018-02-03 20:57:03,035 training [INFO ] Epoch  6 Batch 1060 Training err. 2.23045 Training err. RA 2.64878 Valid. err. 2.21871
2018-02-03 20:57:03,450 training [INFO ] Epoch  6 Batch 1080 Training err. 2.19179 Training err. RA 2.64032 Valid. err. 2.19315
2018-02-03 20:57:03,863 training [INFO ] Epoch  6 Batch 1100 Training err. 2.10999 Training err. RA 2.63067 Valid. err. 2.21436
2018-02-03 20:57:04,276 training [INFO ] Epoch  6 Batch 1120 Training err. 2.13538 Training err. RA 2.62183 Valid. err. 2.19780
2018-02-03 20:57:04,694 training [INFO ] Epoch  6 Batch 1140 Training err. 2.16101 Training err. RA 2.61375 Valid. err. 2.18388
2018-02-03 20:57:05,114 training [INFO ] Epoch  6 Batch 1160 Training err. 2.09285 Training err. RA 2.60476 Valid. err. 2.20759
2018-02-03 20:57:05,524 training [INFO ] Epoch  6 Batch 1180 Training err. 2.17851 Training err. RA 2.59754 Valid. err. 2.14741
2018-02-03 20:57:05,937 training [INFO ] Epoch  6 Batch 1200 Training err. 2.09860 Training err. RA 2.58922 Valid. err. 2.14877
2018-02-03 20:57:06,351 training [INFO ] Epoch  6 Batch 1220 Training err. 2.11035 Training err. RA 2.58137 Valid. err. 2.13511
2018-02-03 20:57:06,768 training [INFO ] Epoch  6 Batch 1240 Training err. 2.12188 Training err. RA 2.57396 Valid. err. 2.13605
2018-02-03 20:57:07,597 training [INFO ] Epoch  7 Batch 1260 Training err. 2.08650 Training err. RA 2.56623 Valid. err. 2.15989
2018-02-03 20:57:08,032 training [INFO ] Epoch  7 Batch 1280 Training err. 2.15238 Training err. RA 2.55976 Valid. err. 2.11124
2018-02-03 20:57:08,447 training [INFO ] Epoch  7 Batch 1300 Training err. 2.06856 Training err. RA 2.55220 Valid. err. 2.11243
2018-02-03 20:57:08,859 training [INFO ] Epoch  7 Batch 1320 Training err. 2.03241 Training err. RA 2.54433 Valid. err. 2.10224
2018-02-03 20:57:09,273 training [INFO ] Epoch  7 Batch 1340 Training err. 2.08959 Training err. RA 2.53754 Valid. err. 2.13286
2018-02-03 20:57:09,690 training [INFO ] Epoch  7 Batch 1360 Training err. 2.02821 Training err. RA 2.53005 Valid. err. 2.10111
2018-02-03 20:57:10,112 training [INFO ] Epoch  7 Batch 1380 Training err. 2.07183 Training err. RA 2.52341 Valid. err. 2.08290
2018-02-03 20:57:10,530 training [INFO ] Epoch  7 Batch 1400 Training err. 2.04327 Training err. RA 2.51655 Valid. err. 2.08071
2018-02-03 20:57:10,951 training [INFO ] Epoch  7 Batch 1420 Training err. 2.04308 Training err. RA 2.50988 Valid. err. 2.06062
2018-02-03 20:57:11,377 training [INFO ] Epoch  7 Batch 1440 Training err. 2.02113 Training err. RA 2.50309 Valid. err. 2.05266
2018-02-03 20:57:12,192 training [INFO ] Epoch  8 Batch 1460 Training err. 2.03907 Training err. RA 2.49674 Valid. err. 2.04381
2018-02-03 20:57:12,615 training [INFO ] Epoch  8 Batch 1480 Training err. 2.07153 Training err. RA 2.49099 Valid. err. 2.05608
2018-02-03 20:57:13,034 training [INFO ] Epoch  8 Batch 1500 Training err. 2.03497 Training err. RA 2.48491 Valid. err. 2.05645
2018-02-03 20:57:13,466 training [INFO ] Epoch  8 Batch 1520 Training err. 1.94565 Training err. RA 2.47781 Valid. err. 2.04262
2018-02-03 20:57:13,897 training [INFO ] Epoch  8 Batch 1540 Training err. 2.00924 Training err. RA 2.47173 Valid. err. 2.05083
2018-02-03 20:57:14,310 training [INFO ] Epoch  8 Batch 1560 Training err. 1.98587 Training err. RA 2.46550 Valid. err. 2.05865
2018-02-03 20:57:14,729 training [INFO ] Epoch  8 Batch 1580 Training err. 1.96814 Training err. RA 2.45920 Valid. err. 2.01455
2018-02-03 20:57:15,148 training [INFO ] Epoch  8 Batch 1600 Training err. 2.02681 Training err. RA 2.45380 Valid. err. 2.03027
2018-02-03 20:57:15,563 training [INFO ] Epoch  8 Batch 1620 Training err. 1.96663 Training err. RA 2.44778 Valid. err. 2.03686
2018-02-03 20:57:15,977 training [INFO ] Epoch  8 Batch 1640 Training err. 1.95994 Training err. RA 2.44184 Valid. err. 2.01450
2018-02-03 20:57:16,395 training [INFO ] Epoch  8 Batch 1660 Training err. 1.96712 Training err. RA 2.43612 Valid. err. 1.99399
2018-02-03 20:57:17,194 training [INFO ] Epoch  9 Batch 1680 Training err. 2.15077 Training err. RA 2.43272 Valid. err. 2.04023
2018-02-03 20:57:17,611 training [INFO ] Epoch  9 Batch 1700 Training err. 2.00885 Training err. RA 2.42773 Valid. err. 2.05368
2018-02-03 20:57:18,031 training [INFO ] Epoch  9 Batch 1720 Training err. 1.93618 Training err. RA 2.42202 Valid. err. 2.01559
2018-02-03 20:57:18,446 training [INFO ] Epoch  9 Batch 1740 Training err. 1.92337 Training err. RA 2.41628 Valid. err. 2.02040
2018-02-03 20:57:18,862 training [INFO ] Epoch  9 Batch 1760 Training err. 1.97311 Training err. RA 2.41125 Valid. err. 2.00385
2018-02-03 20:57:19,281 training [INFO ] Epoch  9 Batch 1780 Training err. 1.90469 Training err. RA 2.40556 Valid. err. 1.98069
2018-02-03 20:57:19,695 training [INFO ] Epoch  9 Batch 1800 Training err. 1.98517 Training err. RA 2.40089 Valid. err. 1.98102
2018-02-03 20:57:20,112 training [INFO ] Epoch  9 Batch 1820 Training err. 1.90999 Training err. RA 2.39549 Valid. err. 1.97266
2018-02-03 20:57:20,522 training [INFO ] Epoch  9 Batch 1840 Training err. 1.92858 Training err. RA 2.39042 Valid. err. 1.97054
2018-02-03 20:57:20,936 training [INFO ] Epoch  9 Batch 1860 Training err. 1.90247 Training err. RA 2.38517 Valid. err. 1.95101
2018-02-03 20:57:21,716 training [INFO ] Epoch 10 Batch 1880 Training err. 1.92716 Training err. RA 2.38030 Valid. err. 1.93557
2018-02-03 20:57:22,131 training [INFO ] Epoch 10 Batch 1900 Training err. 1.95269 Training err. RA 2.37580 Valid. err. 1.95858
2018-02-03 20:57:22,550 training [INFO ] Epoch 10 Batch 1920 Training err. 1.91123 Training err. RA 2.37096 Valid. err. 1.96604
2018-02-03 20:57:22,976 training [INFO ] Epoch 10 Batch 1940 Training err. 1.84811 Training err. RA 2.36557 Valid. err. 1.94478
2018-02-03 20:57:23,400 training [INFO ] Epoch 10 Batch 1960 Training err. 1.92048 Training err. RA 2.36103 Valid. err. 1.94912
2018-02-03 20:57:23,823 training [INFO ] Epoch 10 Batch 1980 Training err. 1.86243 Training err. RA 2.35599 Valid. err. 1.94911
2018-02-03 20:57:24,250 training [INFO ] Epoch 10 Batch 2000 Training err. 1.90344 Training err. RA 2.35146 Valid. err. 1.94217
2018-02-03 20:57:24,675 training [INFO ] Epoch 10 Batch 2020 Training err. 1.89546 Training err. RA 2.34695 Valid. err. 1.92442
2018-02-03 20:57:25,099 training [INFO ] Epoch 10 Batch 2040 Training err. 1.86795 Training err. RA 2.34225 Valid. err. 1.93613
2018-02-03 20:57:25,517 training [INFO ] Epoch 10 Batch 2060 Training err. 1.86258 Training err. RA 2.33760 Valid. err. 1.90829
2018-02-03 20:57:25,936 training [INFO ] Epoch 10 Batch 2080 Training err. 1.87885 Training err. RA 2.33318 Valid. err. 1.90398
2018-02-03 20:57:26,719 training [INFO ] Epoch 11 Batch 2100 Training err. 1.90650 Training err. RA 2.32912 Valid. err. 1.91600
2018-02-03 20:57:27,138 training [INFO ] Epoch 11 Batch 2120 Training err. 1.88356 Training err. RA 2.32492 Valid. err. 1.89970
2018-02-03 20:57:27,554 training [INFO ] Epoch 11 Batch 2140 Training err. 1.81899 Training err. RA 2.32019 Valid. err. 1.91457
2018-02-03 20:57:27,966 training [INFO ] Epoch 11 Batch 2160 Training err. 1.82490 Training err. RA 2.31560 Valid. err. 1.91960
2018-02-03 20:57:28,382 training [INFO ] Epoch 11 Batch 2180 Training err. 1.86562 Training err. RA 2.31147 Valid. err. 1.89880
2018-02-03 20:57:28,800 training [INFO ] Epoch 11 Batch 2200 Training err. 1.81487 Training err. RA 2.30696 Valid. err. 1.89498
2018-02-03 20:57:29,218 training [INFO ] Epoch 11 Batch 2220 Training err. 1.88242 Training err. RA 2.30314 Valid. err. 1.89503
2018-02-03 20:57:29,638 training [INFO ] Epoch 11 Batch 2240 Training err. 1.81618 Training err. RA 2.29879 Valid. err. 1.88426
2018-02-03 20:57:30,050 training [INFO ] Epoch 11 Batch 2260 Training err. 1.84096 Training err. RA 2.29474 Valid. err. 1.90001
2018-02-03 20:57:30,465 training [INFO ] Epoch 11 Batch 2280 Training err. 1.82148 Training err. RA 2.29058 Valid. err. 1.86856
2018-02-03 20:57:31,250 training [INFO ] Epoch 12 Batch 2300 Training err. 1.81299 Training err. RA 2.28643 Valid. err. 1.85998
2018-02-03 20:57:31,669 training [INFO ] Epoch 12 Batch 2320 Training err. 1.86295 Training err. RA 2.28278 Valid. err. 1.87731
2018-02-03 20:57:32,083 training [INFO ] Epoch 12 Batch 2340 Training err. 1.81327 Training err. RA 2.27877 Valid. err. 1.87033
2018-02-03 20:57:32,495 training [INFO ] Epoch 12 Batch 2360 Training err. 1.78549 Training err. RA 2.27459 Valid. err. 1.86456
2018-02-03 20:57:32,906 training [INFO ] Epoch 12 Batch 2380 Training err. 1.82920 Training err. RA 2.27085 Valid. err. 1.88942
2018-02-03 20:57:33,319 training [INFO ] Epoch 12 Batch 2400 Training err. 1.78541 Training err. RA 2.26680 Valid. err. 1.88085
2018-02-03 20:57:33,740 training [INFO ] Epoch 12 Batch 2420 Training err. 1.82634 Training err. RA 2.26316 Valid. err. 1.84644
2018-02-03 20:57:34,157 training [INFO ] Epoch 12 Batch 2440 Training err. 1.79401 Training err. RA 2.25931 Valid. err. 1.84627
2018-02-03 20:57:34,572 training [INFO ] Epoch 12 Batch 2460 Training err. 1.80710 Training err. RA 2.25564 Valid. err. 1.84565
2018-02-03 20:57:34,985 training [INFO ] Epoch 12 Batch 2480 Training err. 1.77783 Training err. RA 2.25178 Valid. err. 1.84163
2018-02-03 20:57:35,768 training [INFO ] Epoch 13 Batch 2500 Training err. 1.80169 Training err. RA 2.24818 Valid. err. 1.83271
2018-02-03 20:57:36,187 training [INFO ] Epoch 13 Batch 2520 Training err. 1.81454 Training err. RA 2.24474 Valid. err. 1.83588
2018-02-03 20:57:36,602 training [INFO ] Epoch 13 Batch 2540 Training err. 1.80155 Training err. RA 2.24125 Valid. err. 1.85458
2018-02-03 20:57:37,013 training [INFO ] Epoch 13 Batch 2560 Training err. 1.72974 Training err. RA 2.23726 Valid. err. 1.82890
2018-02-03 20:57:37,428 training [INFO ] Epoch 13 Batch 2580 Training err. 1.78409 Training err. RA 2.23374 Valid. err. 1.84011
2018-02-03 20:57:37,843 training [INFO ] Epoch 13 Batch 2600 Training err. 1.76650 Training err. RA 2.23015 Valid. err. 1.85661
2018-02-03 20:57:38,267 training [INFO ] Epoch 13 Batch 2620 Training err. 1.76130 Training err. RA 2.22657 Valid. err. 1.83324
2018-02-03 20:57:38,689 training [INFO ] Epoch 13 Batch 2640 Training err. 1.80158 Training err. RA 2.22335 Valid. err. 1.83932
2018-02-03 20:57:39,110 training [INFO ] Epoch 13 Batch 2660 Training err. 1.75213 Training err. RA 2.21981 Valid. err. 1.82000
2018-02-03 20:57:39,527 training [INFO ] Epoch 13 Batch 2680 Training err. 1.75117 Training err. RA 2.21631 Valid. err. 1.83074
2018-02-03 20:57:39,946 training [INFO ] Epoch 13 Batch 2700 Training err. 1.76180 Training err. RA 2.21294 Valid. err. 1.79791
2018-02-03 20:57:40,747 training [INFO ] Epoch 14 Batch 2720 Training err. 1.75702 Training err. RA 2.20959 Valid. err. 1.80574
2018-02-03 20:57:41,171 training [INFO ] Epoch 14 Batch 2740 Training err. 1.77999 Training err. RA 2.20646 Valid. err. 1.83552
2018-02-03 20:57:41,593 training [INFO ] Epoch 14 Batch 2760 Training err. 1.72545 Training err. RA 2.20297 Valid. err. 1.81183
2018-02-03 20:57:42,011 training [INFO ] Epoch 14 Batch 2780 Training err. 1.71840 Training err. RA 2.19948 Valid. err. 1.82015
2018-02-03 20:57:42,427 training [INFO ] Epoch 14 Batch 2800 Training err. 1.77660 Training err. RA 2.19646 Valid. err. 1.82654
2018-02-03 20:57:42,842 training [INFO ] Epoch 14 Batch 2820 Training err. 1.71345 Training err. RA 2.19304 Valid. err. 1.80426
2018-02-03 20:57:43,260 training [INFO ] Epoch 14 Batch 2840 Training err. 1.78905 Training err. RA 2.19019 Valid. err. 1.79622
2018-02-03 20:57:43,676 training [INFO ] Epoch 14 Batch 2860 Training err. 1.70254 Training err. RA 2.18678 Valid. err. 1.78604
2018-02-03 20:57:44,093 training [INFO ] Epoch 14 Batch 2880 Training err. 1.74233 Training err. RA 2.18370 Valid. err. 1.78497
2018-02-03 20:57:44,507 training [INFO ] Epoch 14 Batch 2900 Training err. 1.70946 Training err. RA 2.18043 Valid. err. 1.78654
2018-02-03 20:57:45,289 training [INFO ] Epoch 15 Batch 2920 Training err. 1.72485 Training err. RA 2.17730 Valid. err. 1.76549
2018-02-03 20:57:45,709 training [INFO ] Epoch 15 Batch 2940 Training err. 1.75472 Training err. RA 2.17443 Valid. err. 1.80309
2018-02-03 20:57:46,126 training [INFO ] Epoch 15 Batch 2960 Training err. 1.71743 Training err. RA 2.17134 Valid. err. 1.80302
2018-02-03 20:57:46,538 training [INFO ] Epoch 15 Batch 2980 Training err. 1.67277 Training err. RA 2.16800 Valid. err. 1.80034
2018-02-03 20:57:46,952 training [INFO ] Epoch 15 Batch 3000 Training err. 1.73667 Training err. RA 2.16512 Valid. err. 1.78483
2018-02-03 20:57:47,367 training [INFO ] Epoch 15 Batch 3020 Training err. 1.69473 Training err. RA 2.16201 Valid. err. 1.79693
2018-02-03 20:57:47,784 training [INFO ] Epoch 15 Batch 3040 Training err. 1.72848 Training err. RA 2.15915 Valid. err. 1.78333
2018-02-03 20:57:48,202 training [INFO ] Epoch 15 Batch 3060 Training err. 1.71224 Training err. RA 2.15623 Valid. err. 1.77265
2018-02-03 20:57:48,616 training [INFO ] Epoch 15 Batch 3080 Training err. 1.70084 Training err. RA 2.15328 Valid. err. 1.76968
2018-02-03 20:57:49,030 training [INFO ] Epoch 15 Batch 3100 Training err. 1.68361 Training err. RA 2.15025 Valid. err. 1.74720
2018-02-03 20:57:49,442 training [INFO ] Epoch 15 Batch 3120 Training err. 1.71129 Training err. RA 2.14743 Valid. err. 1.74433
2018-02-03 20:57:50,237 training [INFO ] Epoch 16 Batch 3140 Training err. 1.72991 Training err. RA 2.14477 Valid. err. 1.76253
2018-02-03 20:57:50,664 training [INFO ] Epoch 16 Batch 3160 Training err. 1.70769 Training err. RA 2.14201 Valid. err. 1.74691
2018-02-03 20:57:51,084 training [INFO ] Epoch 16 Batch 3180 Training err. 1.65475 Training err. RA 2.13894 Valid. err. 1.75955
2018-02-03 20:57:51,503 training [INFO ] Epoch 16 Batch 3200 Training err. 1.65498 Training err. RA 2.13592 Valid. err. 1.78490
2018-02-03 20:57:51,923 training [INFO ] Epoch 16 Batch 3220 Training err. 1.70951 Training err. RA 2.13327 Valid. err. 1.76088
2018-02-03 20:57:52,348 training [INFO ] Epoch 16 Batch 3240 Training err. 1.65979 Training err. RA 2.13035 Valid. err. 1.76330
2018-02-03 20:57:52,772 training [INFO ] Epoch 16 Batch 3260 Training err. 1.71867 Training err. RA 2.12782 Valid. err. 1.75235
2018-02-03 20:57:53,194 training [INFO ] Epoch 16 Batch 3280 Training err. 1.65294 Training err. RA 2.12492 Valid. err. 1.78480
2018-02-03 20:57:53,612 training [INFO ] Epoch 16 Batch 3300 Training err. 1.68690 Training err. RA 2.12227 Valid. err. 1.75096
2018-02-03 20:57:54,028 training [INFO ] Epoch 16 Batch 3320 Training err. 1.66630 Training err. RA 2.11952 Valid. err. 1.73310
2018-02-03 20:57:54,812 training [INFO ] Epoch 17 Batch 3340 Training err. 1.65574 Training err. RA 2.11675 Valid. err. 1.72364
2018-02-03 20:57:55,231 training [INFO ] Epoch 17 Batch 3360 Training err. 1.70276 Training err. RA 2.11428 Valid. err. 1.74032
2018-02-03 20:57:55,649 training [INFO ] Epoch 17 Batch 3380 Training err. 1.65049 Training err. RA 2.11154 Valid. err. 1.74026
2018-02-03 20:57:56,062 training [INFO ] Epoch 17 Batch 3400 Training err. 1.63721 Training err. RA 2.10875 Valid. err. 1.74450
2018-02-03 20:57:56,475 training [INFO ] Epoch 17 Batch 3420 Training err. 1.67928 Training err. RA 2.10624 Valid. err. 1.74531
2018-02-03 20:57:56,890 training [INFO ] Epoch 17 Batch 3440 Training err. 1.63654 Training err. RA 2.10350 Valid. err. 1.74575
2018-02-03 20:57:57,308 training [INFO ] Epoch 17 Batch 3460 Training err. 1.68027 Training err. RA 2.10106 Valid. err. 1.72527
2018-02-03 20:57:57,727 training [INFO ] Epoch 17 Batch 3480 Training err. 1.64352 Training err. RA 2.09843 Valid. err. 1.72794
2018-02-03 20:57:58,147 training [INFO ] Epoch 17 Batch 3500 Training err. 1.66707 Training err. RA 2.09596 Valid. err. 1.73092
2018-02-03 20:57:58,559 training [INFO ] Epoch 17 Batch 3520 Training err. 1.63313 Training err. RA 2.09333 Valid. err. 1.71705
2018-02-03 20:57:59,345 training [INFO ] Epoch 18 Batch 3540 Training err. 1.66207 Training err. RA 2.09090 Valid. err. 1.71915
2018-02-03 20:57:59,759 training [INFO ] Epoch 18 Batch 3560 Training err. 1.66564 Training err. RA 2.08851 Valid. err. 1.72638
2018-02-03 20:58:00,185 training [INFO ] Epoch 18 Batch 3580 Training err. 1.65072 Training err. RA 2.08606 Valid. err. 1.71576
2018-02-03 20:58:00,601 training [INFO ] Epoch 18 Batch 3600 Training err. 1.59020 Training err. RA 2.08331 Valid. err. 1.71873
2018-02-03 20:58:01,018 training [INFO ] Epoch 18 Batch 3620 Training err. 1.64270 Training err. RA 2.08087 Valid. err. 1.73102
2018-02-03 20:58:01,435 training [INFO ] Epoch 18 Batch 3640 Training err. 1.62446 Training err. RA 2.07837 Valid. err. 1.72910
2018-02-03 20:58:01,847 training [INFO ] Epoch 18 Batch 3660 Training err. 1.62505 Training err. RA 2.07589 Valid. err. 1.72483
2018-02-03 20:58:02,264 training [INFO ] Epoch 18 Batch 3680 Training err. 1.66450 Training err. RA 2.07365 Valid. err. 1.72645
2018-02-03 20:58:02,682 training [INFO ] Epoch 18 Batch 3700 Training err. 1.61771 Training err. RA 2.07119 Valid. err. 1.71065
2018-02-03 20:58:03,096 training [INFO ] Epoch 18 Batch 3720 Training err. 1.61360 Training err. RA 2.06873 Valid. err. 1.73798
2018-02-03 20:58:03,511 training [INFO ] Epoch 18 Batch 3740 Training err. 1.63318 Training err. RA 2.06640 Valid. err. 1.69321
2018-02-03 20:58:04,301 training [INFO ] Epoch 19 Batch 3760 Training err. 1.61935 Training err. RA 2.06402 Valid. err. 1.70296
2018-02-03 20:58:04,720 training [INFO ] Epoch 19 Batch 3780 Training err. 1.64503 Training err. RA 2.06180 Valid. err. 1.71786
2018-02-03 20:58:05,136 training [INFO ] Epoch 19 Batch 3800 Training err. 1.58951 Training err. RA 2.05932 Valid. err. 1.70853
2018-02-03 20:58:05,548 training [INFO ] Epoch 19 Batch 3820 Training err. 1.58643 Training err. RA 2.05684 Valid. err. 1.71632
2018-02-03 20:58:05,968 training [INFO ] Epoch 19 Batch 3840 Training err. 1.64526 Training err. RA 2.05470 Valid. err. 1.70709
2018-02-03 20:58:06,386 training [INFO ] Epoch 19 Batch 3860 Training err. 1.58569 Training err. RA 2.05227 Valid. err. 1.70701
2018-02-03 20:58:06,812 training [INFO ] Epoch 19 Batch 3880 Training err. 1.66195 Training err. RA 2.05026 Valid. err. 1.71024
2018-02-03 20:58:07,239 training [INFO ] Epoch 19 Batch 3900 Training err. 1.57343 Training err. RA 2.04781 Valid. err. 1.68546
2018-02-03 20:58:07,663 training [INFO ] Epoch 19 Batch 3920 Training err. 1.61892 Training err. RA 2.04562 Valid. err. 1.68737
2018-02-03 20:58:08,083 training [INFO ] Epoch 19 Batch 3940 Training err. 1.58562 Training err. RA 2.04329 Valid. err. 1.68590
2018-02-03 20:58:08,881 training [INFO ] Epoch 20 Batch 3960 Training err. 1.60364 Training err. RA 2.04107 Valid. err. 1.69482
2018-02-03 20:58:09,304 training [INFO ] Epoch 20 Batch 3980 Training err. 1.62618 Training err. RA 2.03898 Valid. err. 1.68844
2018-02-03 20:58:09,723 training [INFO ] Epoch 20 Batch 4000 Training err. 1.59152 Training err. RA 2.03675 Valid. err. 1.70159
2018-02-03 20:58:10,142 training [INFO ] Epoch 20 Batch 4020 Training err. 1.55066 Training err. RA 2.03433 Valid. err. 1.72289
2018-02-03 20:58:10,552 training [INFO ] Epoch 20 Batch 4040 Training err. 1.61439 Training err. RA 2.03225 Valid. err. 1.68024
2018-02-03 20:58:10,966 training [INFO ] Epoch 20 Batch 4060 Training err. 1.57305 Training err. RA 2.02999 Valid. err. 1.70339
2018-02-03 20:58:11,377 training [INFO ] Epoch 20 Batch 4080 Training err. 1.60785 Training err. RA 2.02792 Valid. err. 1.68206
2018-02-03 20:58:11,798 training [INFO ] Epoch 20 Batch 4100 Training err. 1.59484 Training err. RA 2.02580 Valid. err. 1.68125
2018-02-03 20:58:12,216 training [INFO ] Epoch 20 Batch 4120 Training err. 1.58020 Training err. RA 2.02364 Valid. err. 1.69482
2018-02-03 20:58:12,631 training [INFO ] Epoch 20 Batch 4140 Training err. 1.56976 Training err. RA 2.02145 Valid. err. 1.66653
2018-02-03 20:58:13,044 training [INFO ] Epoch 20 Batch 4160 Training err. 1.59605 Training err. RA 2.01940 Valid. err. 1.66614
2018-02-03 20:58:13,314 __main__ [INFO ] End of training
2018-02-03 20:58:13,541 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:58:14,179 training [INFO ] Epoch  1 Batch   20 Training err. 4.21987 Training err. RA 4.21987 Valid. err. 4.14482
2018-02-03 20:58:14,681 training [INFO ] Epoch  1 Batch   40 Training err. 4.04491 Training err. RA 4.13239 Valid. err. 3.97838
2018-02-03 20:58:15,181 training [INFO ] Epoch  1 Batch   60 Training err. 3.86873 Training err. RA 4.04450 Valid. err. 3.78946
2018-02-03 20:58:15,686 training [INFO ] Epoch  1 Batch   80 Training err. 3.69348 Training err. RA 3.95675 Valid. err. 3.61082
2018-02-03 20:58:16,189 training [INFO ] Epoch  1 Batch  100 Training err. 3.51910 Training err. RA 3.86922 Valid. err. 3.47211
2018-02-03 20:58:17,034 training [INFO ] Epoch  2 Batch  120 Training err. 3.38361 Training err. RA 3.78828 Valid. err. 3.36141
2018-02-03 20:58:17,535 training [INFO ] Epoch  2 Batch  140 Training err. 3.25570 Training err. RA 3.71220 Valid. err. 3.29497
2018-02-03 20:58:18,036 training [INFO ] Epoch  2 Batch  160 Training err. 3.22762 Training err. RA 3.65163 Valid. err. 3.25332
2018-02-03 20:58:18,534 training [INFO ] Epoch  2 Batch  180 Training err. 3.20701 Training err. RA 3.60223 Valid. err. 3.23171
2018-02-03 20:58:19,033 training [INFO ] Epoch  2 Batch  200 Training err. 3.19033 Training err. RA 3.56104 Valid. err. 3.21754
2018-02-03 20:58:19,879 training [INFO ] Epoch  3 Batch  220 Training err. 3.19366 Training err. RA 3.52764 Valid. err. 3.20915
2018-02-03 20:58:20,383 training [INFO ] Epoch  3 Batch  240 Training err. 3.12589 Training err. RA 3.49416 Valid. err. 3.21335
2018-02-03 20:58:20,886 training [INFO ] Epoch  3 Batch  260 Training err. 3.16440 Training err. RA 3.46879 Valid. err. 3.19649
2018-02-03 20:58:21,393 training [INFO ] Epoch  3 Batch  280 Training err. 3.14392 Training err. RA 3.44559 Valid. err. 3.19235
2018-02-03 20:58:21,898 training [INFO ] Epoch  3 Batch  300 Training err. 3.15182 Training err. RA 3.42600 Valid. err. 3.19074
2018-02-03 20:58:22,750 training [INFO ] Epoch  4 Batch  320 Training err. 3.17144 Training err. RA 3.41009 Valid. err. 3.18612
2018-02-03 20:58:23,256 training [INFO ] Epoch  4 Batch  340 Training err. 3.12030 Training err. RA 3.39305 Valid. err. 3.19377
2018-02-03 20:58:23,764 training [INFO ] Epoch  4 Batch  360 Training err. 3.14178 Training err. RA 3.37909 Valid. err. 3.18433
2018-02-03 20:58:24,270 training [INFO ] Epoch  4 Batch  380 Training err. 3.12611 Training err. RA 3.36577 Valid. err. 3.18297
2018-02-03 20:58:24,775 training [INFO ] Epoch  4 Batch  400 Training err. 3.13714 Training err. RA 3.35434 Valid. err. 3.18300
2018-02-03 20:58:25,619 training [INFO ] Epoch  5 Batch  420 Training err. 3.16417 Training err. RA 3.34529 Valid. err. 3.18320
2018-02-03 20:58:26,122 training [INFO ] Epoch  5 Batch  440 Training err. 3.13256 Training err. RA 3.33562 Valid. err. 3.18629
2018-02-03 20:58:26,624 training [INFO ] Epoch  5 Batch  460 Training err. 3.12467 Training err. RA 3.32645 Valid. err. 3.17953
2018-02-03 20:58:27,127 training [INFO ] Epoch  5 Batch  480 Training err. 3.10681 Training err. RA 3.31729 Valid. err. 3.17981
2018-02-03 20:58:27,630 training [INFO ] Epoch  5 Batch  500 Training err. 3.14067 Training err. RA 3.31023 Valid. err. 3.18077
2018-02-03 20:58:28,134 training [INFO ] Epoch  5 Batch  520 Training err. 3.16035 Training err. RA 3.30446 Valid. err. 3.17728
2018-02-03 20:58:28,972 training [INFO ] Epoch  6 Batch  540 Training err. 3.13682 Training err. RA 3.29826 Valid. err. 3.17899
2018-02-03 20:58:29,473 training [INFO ] Epoch  6 Batch  560 Training err. 3.11183 Training err. RA 3.29160 Valid. err. 3.17884
2018-02-03 20:58:29,973 training [INFO ] Epoch  6 Batch  580 Training err. 3.09740 Training err. RA 3.28490 Valid. err. 3.18044
2018-02-03 20:58:30,482 training [INFO ] Epoch  6 Batch  600 Training err. 3.14614 Training err. RA 3.28028 Valid. err. 3.17703
2018-02-03 20:58:30,990 training [INFO ] Epoch  6 Batch  620 Training err. 3.14472 Training err. RA 3.27590 Valid. err. 3.17553
2018-02-03 20:58:31,857 training [INFO ] Epoch  7 Batch  640 Training err. 3.14756 Training err. RA 3.27189 Valid. err. 3.17636
2018-02-03 20:58:32,366 training [INFO ] Epoch  7 Batch  660 Training err. 3.09975 Training err. RA 3.26668 Valid. err. 3.17708
2018-02-03 20:58:32,877 training [INFO ] Epoch  7 Batch  680 Training err. 3.11358 Training err. RA 3.26217 Valid. err. 3.17672
2018-02-03 20:58:33,386 training [INFO ] Epoch  7 Batch  700 Training err. 3.13133 Training err. RA 3.25843 Valid. err. 3.17511
2018-02-03 20:58:33,894 training [INFO ] Epoch  7 Batch  720 Training err. 3.13363 Training err. RA 3.25497 Valid. err. 3.17407
2018-02-03 20:58:34,739 training [INFO ] Epoch  8 Batch  740 Training err. 3.15397 Training err. RA 3.25224 Valid. err. 3.17588
2018-02-03 20:58:35,243 training [INFO ] Epoch  8 Batch  760 Training err. 3.08935 Training err. RA 3.24795 Valid. err. 3.18635
2018-02-03 20:58:35,747 training [INFO ] Epoch  8 Batch  780 Training err. 3.12977 Training err. RA 3.24492 Valid. err. 3.17385
2018-02-03 20:58:36,250 training [INFO ] Epoch  8 Batch  800 Training err. 3.11710 Training err. RA 3.24173 Valid. err. 3.17302
2018-02-03 20:58:36,752 training [INFO ] Epoch  8 Batch  820 Training err. 3.12893 Training err. RA 3.23897 Valid. err. 3.17412
2018-02-03 20:58:37,589 training [INFO ] Epoch  9 Batch  840 Training err. 3.15188 Training err. RA 3.23690 Valid. err. 3.17051
2018-02-03 20:58:38,092 training [INFO ] Epoch  9 Batch  860 Training err. 3.10196 Training err. RA 3.23376 Valid. err. 3.18013
2018-02-03 20:58:38,594 training [INFO ] Epoch  9 Batch  880 Training err. 3.12283 Training err. RA 3.23124 Valid. err. 3.17122
2018-02-03 20:58:39,098 training [INFO ] Epoch  9 Batch  900 Training err. 3.10828 Training err. RA 3.22851 Valid. err. 3.17074
2018-02-03 20:58:39,602 training [INFO ] Epoch  9 Batch  920 Training err. 3.12179 Training err. RA 3.22619 Valid. err. 3.17104
2018-02-03 20:58:40,446 training [INFO ] Epoch 10 Batch  940 Training err. 3.14948 Training err. RA 3.22456 Valid. err. 3.17146
2018-02-03 20:58:40,948 training [INFO ] Epoch 10 Batch  960 Training err. 3.11774 Training err. RA 3.22233 Valid. err. 3.17558
2018-02-03 20:58:41,453 training [INFO ] Epoch 10 Batch  980 Training err. 3.11032 Training err. RA 3.22005 Valid. err. 3.16805
2018-02-03 20:58:41,963 training [INFO ] Epoch 10 Batch 1000 Training err. 3.09212 Training err. RA 3.21749 Valid. err. 3.16837
2018-02-03 20:58:42,469 training [INFO ] Epoch 10 Batch 1020 Training err. 3.12651 Training err. RA 3.21570 Valid. err. 3.16928
2018-02-03 20:58:42,976 training [INFO ] Epoch 10 Batch 1040 Training err. 3.14596 Training err. RA 3.21436 Valid. err. 3.16557
2018-02-03 20:58:43,833 training [INFO ] Epoch 11 Batch 1060 Training err. 3.12325 Training err. RA 3.21264 Valid. err. 3.16711
2018-02-03 20:58:44,343 training [INFO ] Epoch 11 Batch 1080 Training err. 3.09868 Training err. RA 3.21053 Valid. err. 3.16682
2018-02-03 20:58:44,853 training [INFO ] Epoch 11 Batch 1100 Training err. 3.08286 Training err. RA 3.20821 Valid. err. 3.16806
2018-02-03 20:58:45,369 training [INFO ] Epoch 11 Batch 1120 Training err. 3.13141 Training err. RA 3.20684 Valid. err. 3.16440
2018-02-03 20:58:45,880 training [INFO ] Epoch 11 Batch 1140 Training err. 3.13046 Training err. RA 3.20550 Valid. err. 3.16255
2018-02-03 20:58:46,726 training [INFO ] Epoch 12 Batch 1160 Training err. 3.13330 Training err. RA 3.20425 Valid. err. 3.16300
2018-02-03 20:58:47,231 training [INFO ] Epoch 12 Batch 1180 Training err. 3.08632 Training err. RA 3.20226 Valid. err. 3.16337
2018-02-03 20:58:47,735 training [INFO ] Epoch 12 Batch 1200 Training err. 3.09758 Training err. RA 3.20051 Valid. err. 3.16264
2018-02-03 20:58:48,250 training [INFO ] Epoch 12 Batch 1220 Training err. 3.11625 Training err. RA 3.19913 Valid. err. 3.16054
2018-02-03 20:58:48,754 training [INFO ] Epoch 12 Batch 1240 Training err. 3.11796 Training err. RA 3.19782 Valid. err. 3.15895
2018-02-03 20:58:49,595 training [INFO ] Epoch 13 Batch 1260 Training err. 3.13829 Training err. RA 3.19688 Valid. err. 3.16086
2018-02-03 20:58:50,104 training [INFO ] Epoch 13 Batch 1280 Training err. 3.07477 Training err. RA 3.19497 Valid. err. 3.17052
2018-02-03 20:58:50,616 training [INFO ] Epoch 13 Batch 1300 Training err. 3.11173 Training err. RA 3.19369 Valid. err. 3.15723
2018-02-03 20:58:51,127 training [INFO ] Epoch 13 Batch 1320 Training err. 3.10005 Training err. RA 3.19227 Valid. err. 3.15568
2018-02-03 20:58:51,640 training [INFO ] Epoch 13 Batch 1340 Training err. 3.11045 Training err. RA 3.19105 Valid. err. 3.15623
2018-02-03 20:58:52,501 training [INFO ] Epoch 14 Batch 1360 Training err. 3.13371 Training err. RA 3.19020 Valid. err. 3.15175
2018-02-03 20:58:53,015 training [INFO ] Epoch 14 Batch 1380 Training err. 3.08410 Training err. RA 3.18867 Valid. err. 3.16096
2018-02-03 20:58:53,526 training [INFO ] Epoch 14 Batch 1400 Training err. 3.10380 Training err. RA 3.18745 Valid. err. 3.15100
2018-02-03 20:58:54,038 training [INFO ] Epoch 14 Batch 1420 Training err. 3.08736 Training err. RA 3.18604 Valid. err. 3.14959
2018-02-03 20:58:54,538 training [INFO ] Epoch 14 Batch 1440 Training err. 3.10014 Training err. RA 3.18485 Valid. err. 3.14864
2018-02-03 20:58:55,389 training [INFO ] Epoch 15 Batch 1460 Training err. 3.12809 Training err. RA 3.18407 Valid. err. 3.14808
2018-02-03 20:58:55,891 training [INFO ] Epoch 15 Batch 1480 Training err. 3.09417 Training err. RA 3.18286 Valid. err. 3.15322
2018-02-03 20:58:56,393 training [INFO ] Epoch 15 Batch 1500 Training err. 3.08941 Training err. RA 3.18161 Valid. err. 3.14271
2018-02-03 20:58:56,897 training [INFO ] Epoch 15 Batch 1520 Training err. 3.06643 Training err. RA 3.18010 Valid. err. 3.14160
2018-02-03 20:58:57,401 training [INFO ] Epoch 15 Batch 1540 Training err. 3.09964 Training err. RA 3.17905 Valid. err. 3.14092
2018-02-03 20:58:57,918 training [INFO ] Epoch 15 Batch 1560 Training err. 3.11793 Training err. RA 3.17827 Valid. err. 3.13560
2018-02-03 20:58:58,816 training [INFO ] Epoch 16 Batch 1580 Training err. 3.09430 Training err. RA 3.17721 Valid. err. 3.13554
2018-02-03 20:58:59,342 training [INFO ] Epoch 16 Batch 1600 Training err. 3.07392 Training err. RA 3.17591 Valid. err. 3.13433
2018-02-03 20:58:59,889 training [INFO ] Epoch 16 Batch 1620 Training err. 3.05029 Training err. RA 3.17436 Valid. err. 3.13270
2018-02-03 20:59:00,403 training [INFO ] Epoch 16 Batch 1640 Training err. 3.09581 Training err. RA 3.17341 Valid. err. 3.12768
2018-02-03 20:59:00,917 training [INFO ] Epoch 16 Batch 1660 Training err. 3.09540 Training err. RA 3.17247 Valid. err. 3.12347
2018-02-03 20:59:01,788 training [INFO ] Epoch 17 Batch 1680 Training err. 3.09717 Training err. RA 3.17157 Valid. err. 3.12199
2018-02-03 20:59:02,417 training [INFO ] Epoch 17 Batch 1700 Training err. 3.05420 Training err. RA 3.17019 Valid. err. 3.12127
2018-02-03 20:59:03,090 training [INFO ] Epoch 17 Batch 1720 Training err. 3.05387 Training err. RA 3.16884 Valid. err. 3.11727
2018-02-03 20:59:03,766 training [INFO ] Epoch 17 Batch 1740 Training err. 3.07301 Training err. RA 3.16773 Valid. err. 3.11233
2018-02-03 20:59:04,433 training [INFO ] Epoch 17 Batch 1760 Training err. 3.07252 Training err. RA 3.16665 Valid. err. 3.10834
2018-02-03 20:59:05,592 training [INFO ] Epoch 18 Batch 1780 Training err. 3.09212 Training err. RA 3.16582 Valid. err. 3.11301
2018-02-03 20:59:06,226 training [INFO ] Epoch 18 Batch 1800 Training err. 3.03225 Training err. RA 3.16433 Valid. err. 3.11491
2018-02-03 20:59:06,790 training [INFO ] Epoch 18 Batch 1820 Training err. 3.05598 Training err. RA 3.16314 Valid. err. 3.09761
2018-02-03 20:59:07,353 training [INFO ] Epoch 18 Batch 1840 Training err. 3.04480 Training err. RA 3.16185 Valid. err. 3.09303
2018-02-03 20:59:07,914 training [INFO ] Epoch 18 Batch 1860 Training err. 3.04936 Training err. RA 3.16064 Valid. err. 3.09093
2018-02-03 20:59:08,781 training [INFO ] Epoch 19 Batch 1880 Training err. 3.07389 Training err. RA 3.15972 Valid. err. 3.08255
2018-02-03 20:59:09,284 training [INFO ] Epoch 19 Batch 1900 Training err. 3.02464 Training err. RA 3.15830 Valid. err. 3.09417
2018-02-03 20:59:09,785 training [INFO ] Epoch 19 Batch 1920 Training err. 3.04063 Training err. RA 3.15707 Valid. err. 3.07493
2018-02-03 20:59:10,289 training [INFO ] Epoch 19 Batch 1940 Training err. 3.01491 Training err. RA 3.15561 Valid. err. 3.06990
2018-02-03 20:59:10,790 training [INFO ] Epoch 19 Batch 1960 Training err. 3.02447 Training err. RA 3.15427 Valid. err. 3.06586
2018-02-03 20:59:11,634 training [INFO ] Epoch 20 Batch 1980 Training err. 3.05309 Training err. RA 3.15325 Valid. err. 3.06296
2018-02-03 20:59:12,133 training [INFO ] Epoch 20 Batch 2000 Training err. 3.01261 Training err. RA 3.15184 Valid. err. 3.06143
2018-02-03 20:59:12,634 training [INFO ] Epoch 20 Batch 2020 Training err. 3.01659 Training err. RA 3.15050 Valid. err. 3.05271
2018-02-03 20:59:13,135 training [INFO ] Epoch 20 Batch 2040 Training err. 2.97747 Training err. RA 3.14881 Valid. err. 3.04470
2018-02-03 20:59:13,635 training [INFO ] Epoch 20 Batch 2060 Training err. 3.00570 Training err. RA 3.14742 Valid. err. 3.03849
2018-02-03 20:59:14,135 training [INFO ] Epoch 20 Batch 2080 Training err. 3.02111 Training err. RA 3.14620 Valid. err. 3.03113
2018-02-03 20:59:14,381 __main__ [INFO ] End of training
2018-02-03 20:59:14,623 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 16 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 20,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 20:59:15,260 training [INFO ] Epoch  1 Batch   20 Training err. 3.61240 Training err. RA 3.61240 Valid. err. 3.23894
2018-02-03 20:59:15,762 training [INFO ] Epoch  1 Batch   40 Training err. 3.17362 Training err. RA 3.39301 Valid. err. 3.22147
2018-02-03 20:59:16,266 training [INFO ] Epoch  1 Batch   60 Training err. 3.13829 Training err. RA 3.30811 Valid. err. 3.19126
2018-02-03 20:59:16,771 training [INFO ] Epoch  1 Batch   80 Training err. 3.15799 Training err. RA 3.27058 Valid. err. 3.18313
2018-02-03 20:59:17,278 training [INFO ] Epoch  1 Batch  100 Training err. 3.15837 Training err. RA 3.24813 Valid. err. 3.17875
2018-02-03 20:59:18,127 training [INFO ] Epoch  2 Batch  120 Training err. 3.15755 Training err. RA 3.23304 Valid. err. 3.18134
2018-02-03 20:59:18,644 training [INFO ] Epoch  2 Batch  140 Training err. 3.10638 Training err. RA 3.21494 Valid. err. 3.16768
2018-02-03 20:59:19,160 training [INFO ] Epoch  2 Batch  160 Training err. 3.09836 Training err. RA 3.20037 Valid. err. 3.17608
2018-02-03 20:59:19,676 training [INFO ] Epoch  2 Batch  180 Training err. 3.13595 Training err. RA 3.19321 Valid. err. 3.14928
2018-02-03 20:59:20,197 training [INFO ] Epoch  2 Batch  200 Training err. 3.10231 Training err. RA 3.18412 Valid. err. 3.13573
2018-02-03 20:59:21,076 training [INFO ] Epoch  3 Batch  220 Training err. 3.11294 Training err. RA 3.17765 Valid. err. 3.18128
2018-02-03 20:59:21,593 training [INFO ] Epoch  3 Batch  240 Training err. 3.05190 Training err. RA 3.16717 Valid. err. 3.14892
2018-02-03 20:59:22,106 training [INFO ] Epoch  3 Batch  260 Training err. 3.04894 Training err. RA 3.15808 Valid. err. 3.11423
2018-02-03 20:59:22,608 training [INFO ] Epoch  3 Batch  280 Training err. 3.03367 Training err. RA 3.14919 Valid. err. 3.03236
2018-02-03 20:59:23,114 training [INFO ] Epoch  3 Batch  300 Training err. 2.98342 Training err. RA 3.13814 Valid. err. 2.97855
2018-02-03 20:59:23,962 training [INFO ] Epoch  4 Batch  320 Training err. 2.96287 Training err. RA 3.12719 Valid. err. 2.94086
2018-02-03 20:59:24,469 training [INFO ] Epoch  4 Batch  340 Training err. 2.88218 Training err. RA 3.11277 Valid. err. 2.93865
2018-02-03 20:59:24,975 training [INFO ] Epoch  4 Batch  360 Training err. 2.86092 Training err. RA 3.09878 Valid. err. 2.85750
2018-02-03 20:59:25,481 training [INFO ] Epoch  4 Batch  380 Training err. 2.78780 Training err. RA 3.08241 Valid. err. 2.80901
2018-02-03 20:59:25,990 training [INFO ] Epoch  4 Batch  400 Training err. 2.76623 Training err. RA 3.06660 Valid. err. 2.77344
2018-02-03 20:59:26,863 training [INFO ] Epoch  5 Batch  420 Training err. 2.74659 Training err. RA 3.05137 Valid. err. 2.75855
2018-02-03 20:59:27,382 training [INFO ] Epoch  5 Batch  440 Training err. 2.68438 Training err. RA 3.03469 Valid. err. 2.70717
2018-02-03 20:59:27,902 training [INFO ] Epoch  5 Batch  460 Training err. 2.66944 Training err. RA 3.01880 Valid. err. 2.71785
2018-02-03 20:59:28,423 training [INFO ] Epoch  5 Batch  480 Training err. 2.59790 Training err. RA 3.00127 Valid. err. 2.64094
2018-02-03 20:59:28,943 training [INFO ] Epoch  5 Batch  500 Training err. 2.59309 Training err. RA 2.98494 Valid. err. 2.59622
2018-02-03 20:59:29,463 training [INFO ] Epoch  5 Batch  520 Training err. 2.60188 Training err. RA 2.97021 Valid. err. 2.60165
2018-02-03 20:59:30,316 training [INFO ] Epoch  6 Batch  540 Training err. 2.56634 Training err. RA 2.95525 Valid. err. 2.58789
2018-02-03 20:59:30,820 training [INFO ] Epoch  6 Batch  560 Training err. 2.49692 Training err. RA 2.93888 Valid. err. 2.54360
2018-02-03 20:59:31,325 training [INFO ] Epoch  6 Batch  580 Training err. 2.52132 Training err. RA 2.92448 Valid. err. 2.52455
2018-02-03 20:59:31,831 training [INFO ] Epoch  6 Batch  600 Training err. 2.49170 Training err. RA 2.91005 Valid. err. 2.51627
2018-02-03 20:59:32,337 training [INFO ] Epoch  6 Batch  620 Training err. 2.46622 Training err. RA 2.89574 Valid. err. 2.46242
2018-02-03 20:59:33,183 training [INFO ] Epoch  7 Batch  640 Training err. 2.46252 Training err. RA 2.88220 Valid. err. 2.44188
2018-02-03 20:59:33,689 training [INFO ] Epoch  7 Batch  660 Training err. 2.38885 Training err. RA 2.86725 Valid. err. 2.46494
2018-02-03 20:59:34,197 training [INFO ] Epoch  7 Batch  680 Training err. 2.41597 Training err. RA 2.85398 Valid. err. 2.46711
2018-02-03 20:59:34,709 training [INFO ] Epoch  7 Batch  700 Training err. 2.40372 Training err. RA 2.84111 Valid. err. 2.40672
2018-02-03 20:59:35,222 training [INFO ] Epoch  7 Batch  720 Training err. 2.36639 Training err. RA 2.82793 Valid. err. 2.41004
2018-02-03 20:59:36,086 training [INFO ] Epoch  8 Batch  740 Training err. 2.38151 Training err. RA 2.81586 Valid. err. 2.38058
2018-02-03 20:59:36,597 training [INFO ] Epoch  8 Batch  760 Training err. 2.31534 Training err. RA 2.80269 Valid. err. 2.35164
2018-02-03 20:59:37,110 training [INFO ] Epoch  8 Batch  780 Training err. 2.34503 Training err. RA 2.79095 Valid. err. 2.34410
2018-02-03 20:59:37,621 training [INFO ] Epoch  8 Batch  800 Training err. 2.31427 Training err. RA 2.77904 Valid. err. 2.34111
2018-02-03 20:59:38,128 training [INFO ] Epoch  8 Batch  820 Training err. 2.27472 Training err. RA 2.76674 Valid. err. 2.30565
2018-02-03 20:59:38,979 training [INFO ] Epoch  9 Batch  840 Training err. 2.30115 Training err. RA 2.75565 Valid. err. 2.28224
2018-02-03 20:59:39,482 training [INFO ] Epoch  9 Batch  860 Training err. 2.27115 Training err. RA 2.74438 Valid. err. 2.29085
2018-02-03 20:59:39,989 training [INFO ] Epoch  9 Batch  880 Training err. 2.25709 Training err. RA 2.73331 Valid. err. 2.29423
2018-02-03 20:59:40,494 training [INFO ] Epoch  9 Batch  900 Training err. 2.24132 Training err. RA 2.72238 Valid. err. 2.31587
2018-02-03 20:59:40,997 training [INFO ] Epoch  9 Batch  920 Training err. 2.22447 Training err. RA 2.71155 Valid. err. 2.25209
2018-02-03 20:59:41,843 training [INFO ] Epoch 10 Batch  940 Training err. 2.22625 Training err. RA 2.70123 Valid. err. 2.25898
2018-02-03 20:59:42,356 training [INFO ] Epoch 10 Batch  960 Training err. 2.23425 Training err. RA 2.69150 Valid. err. 2.23140
2018-02-03 20:59:42,869 training [INFO ] Epoch 10 Batch  980 Training err. 2.17946 Training err. RA 2.68105 Valid. err. 2.23397
2018-02-03 20:59:43,384 training [INFO ] Epoch 10 Batch 1000 Training err. 2.17427 Training err. RA 2.67091 Valid. err. 2.19361
2018-02-03 20:59:43,907 training [INFO ] Epoch 10 Batch 1020 Training err. 2.17604 Training err. RA 2.66121 Valid. err. 2.21682
2018-02-03 20:59:44,424 training [INFO ] Epoch 10 Batch 1040 Training err. 2.17149 Training err. RA 2.65179 Valid. err. 2.18305
2018-02-03 20:59:45,295 training [INFO ] Epoch 11 Batch 1060 Training err. 2.19653 Training err. RA 2.64320 Valid. err. 2.19733
2018-02-03 20:59:45,815 training [INFO ] Epoch 11 Batch 1080 Training err. 2.11155 Training err. RA 2.63336 Valid. err. 2.20513
2018-02-03 20:59:46,324 training [INFO ] Epoch 11 Batch 1100 Training err. 2.12517 Training err. RA 2.62412 Valid. err. 2.17272
2018-02-03 20:59:46,830 training [INFO ] Epoch 11 Batch 1120 Training err. 2.13687 Training err. RA 2.61541 Valid. err. 2.17200
2018-02-03 20:59:47,334 training [INFO ] Epoch 11 Batch 1140 Training err. 2.12537 Training err. RA 2.60682 Valid. err. 2.13522
2018-02-03 20:59:48,176 training [INFO ] Epoch 12 Batch 1160 Training err. 2.24556 Training err. RA 2.60059 Valid. err. 2.17318
2018-02-03 20:59:48,687 training [INFO ] Epoch 12 Batch 1180 Training err. 2.09423 Training err. RA 2.59201 Valid. err. 2.16917
2018-02-03 20:59:49,193 training [INFO ] Epoch 12 Batch 1200 Training err. 2.09751 Training err. RA 2.58376 Valid. err. 2.17534
2018-02-03 20:59:49,701 training [INFO ] Epoch 12 Batch 1220 Training err. 2.10779 Training err. RA 2.57596 Valid. err. 2.14506
2018-02-03 20:59:50,206 training [INFO ] Epoch 12 Batch 1240 Training err. 2.08003 Training err. RA 2.56796 Valid. err. 2.14279
2018-02-03 20:59:51,053 training [INFO ] Epoch 13 Batch 1260 Training err. 2.11059 Training err. RA 2.56070 Valid. err. 2.10275
2018-02-03 20:59:51,556 training [INFO ] Epoch 13 Batch 1280 Training err. 2.04367 Training err. RA 2.55262 Valid. err. 2.12018
2018-02-03 20:59:52,061 training [INFO ] Epoch 13 Batch 1300 Training err. 2.06744 Training err. RA 2.54516 Valid. err. 2.11273
2018-02-03 20:59:52,564 training [INFO ] Epoch 13 Batch 1320 Training err. 2.06431 Training err. RA 2.53787 Valid. err. 2.10233
2018-02-03 20:59:53,068 training [INFO ] Epoch 13 Batch 1340 Training err. 2.02834 Training err. RA 2.53027 Valid. err. 2.07225
2018-02-03 20:59:53,911 training [INFO ] Epoch 14 Batch 1360 Training err. 2.05764 Training err. RA 2.52332 Valid. err. 2.06598
2018-02-03 20:59:54,418 training [INFO ] Epoch 14 Batch 1380 Training err. 2.03424 Training err. RA 2.51623 Valid. err. 2.07636
2018-02-03 20:59:54,924 training [INFO ] Epoch 14 Batch 1400 Training err. 2.02145 Training err. RA 2.50916 Valid. err. 2.07458
2018-02-03 20:59:55,431 training [INFO ] Epoch 14 Batch 1420 Training err. 2.01850 Training err. RA 2.50225 Valid. err. 2.14469
2018-02-03 20:59:55,937 training [INFO ] Epoch 14 Batch 1440 Training err. 2.00608 Training err. RA 2.49536 Valid. err. 2.04802
2018-02-03 20:59:56,789 training [INFO ] Epoch 15 Batch 1460 Training err. 1.99642 Training err. RA 2.48853 Valid. err. 2.07462
2018-02-03 20:59:57,294 training [INFO ] Epoch 15 Batch 1480 Training err. 2.02354 Training err. RA 2.48224 Valid. err. 2.04107
2018-02-03 20:59:57,800 training [INFO ] Epoch 15 Batch 1500 Training err. 1.97436 Training err. RA 2.47547 Valid. err. 2.04142
2018-02-03 20:59:58,315 training [INFO ] Epoch 15 Batch 1520 Training err. 1.97635 Training err. RA 2.46890 Valid. err. 2.02519
2018-02-03 20:59:58,834 training [INFO ] Epoch 15 Batch 1540 Training err. 1.97859 Training err. RA 2.46254 Valid. err. 2.02221
2018-02-03 20:59:59,351 training [INFO ] Epoch 15 Batch 1560 Training err. 1.97097 Training err. RA 2.45623 Valid. err. 2.08022
2018-02-03 21:00:00,220 training [INFO ] Epoch 16 Batch 1580 Training err. 2.00600 Training err. RA 2.45053 Valid. err. 2.00158
2018-02-03 21:00:00,739 training [INFO ] Epoch 16 Batch 1600 Training err. 1.92198 Training err. RA 2.44393 Valid. err. 2.00905
2018-02-03 21:00:01,255 training [INFO ] Epoch 16 Batch 1620 Training err. 1.94556 Training err. RA 2.43777 Valid. err. 2.00560
2018-02-03 21:00:01,777 training [INFO ] Epoch 16 Batch 1640 Training err. 1.96021 Training err. RA 2.43195 Valid. err. 1.99111
2018-02-03 21:00:02,289 training [INFO ] Epoch 16 Batch 1660 Training err. 1.93956 Training err. RA 2.42602 Valid. err. 1.97597
2018-02-03 21:00:03,121 training [INFO ] Epoch 17 Batch 1680 Training err. 1.96350 Training err. RA 2.42051 Valid. err. 1.97192
2018-02-03 21:00:03,627 training [INFO ] Epoch 17 Batch 1700 Training err. 1.90878 Training err. RA 2.41449 Valid. err. 1.99634
2018-02-03 21:00:04,130 training [INFO ] Epoch 17 Batch 1720 Training err. 1.92015 Training err. RA 2.40874 Valid. err. 2.01635
2018-02-03 21:00:04,632 training [INFO ] Epoch 17 Batch 1740 Training err. 1.92563 Training err. RA 2.40319 Valid. err. 1.98456
2018-02-03 21:00:05,134 training [INFO ] Epoch 17 Batch 1760 Training err. 1.91049 Training err. RA 2.39759 Valid. err. 1.95710
2018-02-03 21:00:05,968 training [INFO ] Epoch 18 Batch 1780 Training err. 1.94295 Training err. RA 2.39248 Valid. err. 1.95667
2018-02-03 21:00:06,484 training [INFO ] Epoch 18 Batch 1800 Training err. 1.88741 Training err. RA 2.38687 Valid. err. 1.95853
2018-02-03 21:00:07,003 training [INFO ] Epoch 18 Batch 1820 Training err. 1.89606 Training err. RA 2.38148 Valid. err. 1.96702
2018-02-03 21:00:07,519 training [INFO ] Epoch 18 Batch 1840 Training err. 1.90337 Training err. RA 2.37628 Valid. err. 1.93590
2018-02-03 21:00:08,038 training [INFO ] Epoch 18 Batch 1860 Training err. 1.87889 Training err. RA 2.37093 Valid. err. 1.96778
2018-02-03 21:00:08,915 training [INFO ] Epoch 19 Batch 1880 Training err. 1.90244 Training err. RA 2.36595 Valid. err. 1.95893
2018-02-03 21:00:09,429 training [INFO ] Epoch 19 Batch 1900 Training err. 1.88584 Training err. RA 2.36089 Valid. err. 1.93963
2018-02-03 21:00:09,941 training [INFO ] Epoch 19 Batch 1920 Training err. 1.87497 Training err. RA 2.35583 Valid. err. 1.93075
2018-02-03 21:00:10,445 training [INFO ] Epoch 19 Batch 1940 Training err. 1.87467 Training err. RA 2.35087 Valid. err. 1.93867
2018-02-03 21:00:10,953 training [INFO ] Epoch 19 Batch 1960 Training err. 1.86093 Training err. RA 2.34587 Valid. err. 1.92322
2018-02-03 21:00:11,802 training [INFO ] Epoch 20 Batch 1980 Training err. 1.85724 Training err. RA 2.34094 Valid. err. 1.92401
2018-02-03 21:00:12,307 training [INFO ] Epoch 20 Batch 2000 Training err. 1.88280 Training err. RA 2.33636 Valid. err. 1.90962
2018-02-03 21:00:12,811 training [INFO ] Epoch 20 Batch 2020 Training err. 1.83797 Training err. RA 2.33142 Valid. err. 1.90283
2018-02-03 21:00:13,314 training [INFO ] Epoch 20 Batch 2040 Training err. 1.84091 Training err. RA 2.32661 Valid. err. 1.92094
2018-02-03 21:00:13,818 training [INFO ] Epoch 20 Batch 2060 Training err. 1.84380 Training err. RA 2.32193 Valid. err. 1.89762
2018-02-03 21:00:14,335 training [INFO ] Epoch 20 Batch 2080 Training err. 1.84445 Training err. RA 2.31733 Valid. err. 1.90006
2018-02-03 21:00:14,579 __main__ [INFO ] End of training
2018-02-03 21:19:36,439 __main__ [INFO ] 
==============================
Starting experiment alice_test
==============================
2018-02-03 21:19:36,443 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/alice_test/out
2018-02-03 21:19:36,488 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:19:36,488 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 21:19:38,981 training [INFO ] Epoch  1 Batch   20 Training err. 4.24291 Training err. RA 4.24291 Valid. err. 4.17597
2018-02-03 21:19:39,475 training [INFO ] Epoch  1 Batch   40 Training err. 4.06445 Training err. RA 4.15368 Valid. err. 4.01769
2018-02-03 21:19:39,967 training [INFO ] Epoch  1 Batch   60 Training err. 3.92165 Training err. RA 4.07634 Valid. err. 3.85091
2018-02-03 21:19:40,456 training [INFO ] Epoch  1 Batch   80 Training err. 3.75395 Training err. RA 3.99574 Valid. err. 3.68171
2018-02-03 21:19:40,929 training [INFO ] Epoch  1 Batch  100 Training err. 3.56991 Training err. RA 3.91058 Valid. err. 3.54504
2018-02-03 21:19:41,397 training [INFO ] Epoch  1 Batch  120 Training err. 3.46706 Training err. RA 3.83666 Valid. err. 3.43103
2018-02-03 21:19:41,868 training [INFO ] Epoch  1 Batch  140 Training err. 3.34898 Training err. RA 3.76699 Valid. err. 3.34562
2018-02-03 21:19:42,338 training [INFO ] Epoch  1 Batch  160 Training err. 3.25863 Training err. RA 3.70344 Valid. err. 3.29236
2018-02-03 21:19:42,807 training [INFO ] Epoch  1 Batch  180 Training err. 3.25641 Training err. RA 3.65377 Valid. err. 3.26399
2018-02-03 21:19:43,273 training [INFO ] Epoch  1 Batch  200 Training err. 3.24037 Training err. RA 3.61243 Valid. err. 3.24385
2018-02-03 21:19:44,082 training [INFO ] Epoch  2 Batch  220 Training err. 3.20348 Training err. RA 3.57525 Valid. err. 3.23571
2018-02-03 21:19:44,550 training [INFO ] Epoch  2 Batch  240 Training err. 3.11630 Training err. RA 3.53701 Valid. err. 3.25211
2018-02-03 21:19:45,023 training [INFO ] Epoch  2 Batch  260 Training err. 3.19940 Training err. RA 3.51104 Valid. err. 3.21575
2018-02-03 21:19:45,503 training [INFO ] Epoch  2 Batch  280 Training err. 3.15183 Training err. RA 3.48538 Valid. err. 3.21103
2018-02-03 21:19:45,978 training [INFO ] Epoch  2 Batch  300 Training err. 3.14628 Training err. RA 3.46277 Valid. err. 3.20904
2018-02-03 21:19:46,457 training [INFO ] Epoch  2 Batch  320 Training err. 3.17536 Training err. RA 3.44481 Valid. err. 3.20243
2018-02-03 21:19:46,944 training [INFO ] Epoch  2 Batch  340 Training err. 3.15208 Training err. RA 3.42759 Valid. err. 3.20111
2018-02-03 21:19:47,430 training [INFO ] Epoch  2 Batch  360 Training err. 3.13853 Training err. RA 3.41153 Valid. err. 3.19833
2018-02-03 21:19:47,903 training [INFO ] Epoch  2 Batch  380 Training err. 3.13104 Training err. RA 3.39677 Valid. err. 3.19449
2018-02-03 21:19:48,376 training [INFO ] Epoch  2 Batch  400 Training err. 3.17365 Training err. RA 3.38561 Valid. err. 3.19201
2018-02-03 21:19:49,194 training [INFO ] Epoch  3 Batch  420 Training err. 3.16838 Training err. RA 3.37527 Valid. err. 3.19120
2018-02-03 21:19:49,699 training [INFO ] Epoch  3 Batch  440 Training err. 3.13045 Training err. RA 3.36414 Valid. err. 3.19385
2018-02-03 21:19:50,192 training [INFO ] Epoch  3 Batch  460 Training err. 3.11668 Training err. RA 3.35338 Valid. err. 3.18814
2018-02-03 21:19:50,676 training [INFO ] Epoch  3 Batch  480 Training err. 3.12332 Training err. RA 3.34380 Valid. err. 3.18864
2018-02-03 21:19:51,264 training [INFO ] Epoch  3 Batch  500 Training err. 3.11045 Training err. RA 3.33446 Valid. err. 3.19346
2018-02-03 21:19:51,788 training [INFO ] Epoch  3 Batch  520 Training err. 3.16507 Training err. RA 3.32795 Valid. err. 3.18988
2018-02-03 21:19:52,282 training [INFO ] Epoch  3 Batch  540 Training err. 3.15468 Training err. RA 3.32153 Valid. err. 3.18790
2018-02-03 21:19:52,754 training [INFO ] Epoch  3 Batch  560 Training err. 3.12209 Training err. RA 3.31441 Valid. err. 3.18770
2018-02-03 21:19:53,210 training [INFO ] Epoch  3 Batch  580 Training err. 3.08494 Training err. RA 3.30649 Valid. err. 3.18982
2018-02-03 21:19:53,666 training [INFO ] Epoch  3 Batch  600 Training err. 3.16518 Training err. RA 3.30178 Valid. err. 3.18463
2018-02-03 21:19:54,123 training [INFO ] Epoch  3 Batch  620 Training err. 3.16582 Training err. RA 3.29740 Valid. err. 3.18148
2018-02-03 21:19:54,914 training [INFO ] Epoch  4 Batch  640 Training err. 3.13650 Training err. RA 3.29237 Valid. err. 3.18385
2018-02-03 21:19:55,370 training [INFO ] Epoch  4 Batch  660 Training err. 3.07881 Training err. RA 3.28590 Valid. err. 3.18504
2018-02-03 21:19:55,825 training [INFO ] Epoch  4 Batch  680 Training err. 3.13742 Training err. RA 3.28153 Valid. err. 3.18392
2018-02-03 21:19:56,282 training [INFO ] Epoch  4 Batch  700 Training err. 3.12153 Training err. RA 3.27696 Valid. err. 3.18273
2018-02-03 21:19:56,758 training [INFO ] Epoch  4 Batch  720 Training err. 3.11345 Training err. RA 3.27242 Valid. err. 3.18560
2018-02-03 21:19:57,249 training [INFO ] Epoch  4 Batch  740 Training err. 3.16737 Training err. RA 3.26958 Valid. err. 3.18135
2018-02-03 21:19:57,934 training [INFO ] Epoch  4 Batch  760 Training err. 3.11524 Training err. RA 3.26552 Valid. err. 3.18374
2018-02-03 21:19:58,490 training [INFO ] Epoch  4 Batch  780 Training err. 3.11452 Training err. RA 3.26165 Valid. err. 3.18175
2018-02-03 21:19:58,978 training [INFO ] Epoch  4 Batch  800 Training err. 3.12356 Training err. RA 3.25819 Valid. err. 3.18111
2018-02-03 21:19:59,463 training [INFO ] Epoch  4 Batch  820 Training err. 3.14886 Training err. RA 3.25553 Valid. err. 3.17966
2018-02-03 21:20:00,397 training [INFO ] Epoch  5 Batch  840 Training err. 3.15786 Training err. RA 3.25320 Valid. err. 3.17705
2018-02-03 21:20:00,889 training [INFO ] Epoch  5 Batch  860 Training err. 3.07995 Training err. RA 3.24917 Valid. err. 3.20226
2018-02-03 21:21:14,485 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 21:21:14,488 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 21:21:14,493 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:21:14,493 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:21:16,686 training [INFO ] Epoch  1 Batch   50 Training err. 4.08652 Training err. RA 4.08652 Valid. err. 3.60385
2018-02-03 21:21:16,944 training [INFO ] Epoch  1 Batch  100 Training err. 3.43430 Training err. RA 3.76041 Valid. err. 3.31197
2018-02-03 21:21:17,194 training [INFO ] Epoch  1 Batch  150 Training err. 3.28465 Training err. RA 3.60182 Valid. err. 3.28744
2018-02-03 21:21:17,467 training [INFO ] Epoch  1 Batch  200 Training err. 3.26786 Training err. RA 3.51833 Valid. err. 3.25773
2018-02-03 21:21:17,715 training [INFO ] Epoch  1 Batch  250 Training err. 3.22296 Training err. RA 3.45926 Valid. err. 3.26072
2018-02-03 21:21:17,971 training [INFO ] Epoch  1 Batch  300 Training err. 3.27108 Training err. RA 3.42790 Valid. err. 3.22394
2018-02-03 21:21:18,345 training [INFO ] Epoch  2 Batch  350 Training err. 3.22695 Training err. RA 3.39919 Valid. err. 3.23794
2018-02-03 21:21:18,598 training [INFO ] Epoch  2 Batch  400 Training err. 3.22847 Training err. RA 3.37785 Valid. err. 3.24364
2018-02-03 21:21:18,850 training [INFO ] Epoch  2 Batch  450 Training err. 3.21849 Training err. RA 3.36014 Valid. err. 3.21305
2018-02-03 21:21:19,102 training [INFO ] Epoch  2 Batch  500 Training err. 3.20917 Training err. RA 3.34504 Valid. err. 3.22094
2018-02-03 21:21:19,353 training [INFO ] Epoch  2 Batch  550 Training err. 3.19342 Training err. RA 3.33126 Valid. err. 3.22455
2018-02-03 21:21:19,604 training [INFO ] Epoch  2 Batch  600 Training err. 3.21205 Training err. RA 3.32133 Valid. err. 3.17651
2018-02-03 21:21:19,966 training [INFO ] Epoch  3 Batch  650 Training err. 3.18541 Training err. RA 3.31087 Valid. err. 3.18027
2018-02-03 21:21:20,239 training [INFO ] Epoch  3 Batch  700 Training err. 3.17270 Training err. RA 3.30100 Valid. err. 3.16289
2018-02-03 21:21:20,498 training [INFO ] Epoch  3 Batch  750 Training err. 3.11846 Training err. RA 3.28883 Valid. err. 3.12373
2018-02-03 21:21:20,725 training [INFO ] Epoch  3 Batch  800 Training err. 3.11908 Training err. RA 3.27822 Valid. err. 3.08836
2018-02-03 21:21:20,965 training [INFO ] Epoch  3 Batch  850 Training err. 3.05155 Training err. RA 3.26489 Valid. err. 3.11124
2018-02-03 21:21:21,191 training [INFO ] Epoch  3 Batch  900 Training err. 3.09328 Training err. RA 3.25536 Valid. err. 3.01341
2018-02-03 21:21:21,530 training [INFO ] Epoch  4 Batch  950 Training err. 3.05933 Training err. RA 3.24504 Valid. err. 3.06408
2018-02-03 21:21:21,778 training [INFO ] Epoch  4 Batch 1000 Training err. 2.98853 Training err. RA 3.23221 Valid. err. 2.98207
2018-02-03 21:21:22,010 training [INFO ] Epoch  4 Batch 1050 Training err. 2.92693 Training err. RA 3.21768 Valid. err. 2.94853
2018-02-03 21:21:22,251 training [INFO ] Epoch  4 Batch 1100 Training err. 2.93264 Training err. RA 3.20472 Valid. err. 2.88910
2018-02-03 21:21:22,483 training [INFO ] Epoch  4 Batch 1150 Training err. 2.89494 Training err. RA 3.19125 Valid. err. 2.91092
2018-02-03 21:21:22,712 training [INFO ] Epoch  4 Batch 1200 Training err. 2.90053 Training err. RA 3.17914 Valid. err. 2.84638
2018-02-03 21:21:23,061 training [INFO ] Epoch  5 Batch 1250 Training err. 2.93208 Training err. RA 3.16926 Valid. err. 2.87250
2018-02-03 21:21:23,285 training [INFO ] Epoch  5 Batch 1300 Training err. 2.87700 Training err. RA 3.15801 Valid. err. 2.84635
2018-02-03 21:21:23,517 training [INFO ] Epoch  5 Batch 1350 Training err. 2.78240 Training err. RA 3.14410 Valid. err. 2.80989
2018-02-03 21:21:23,801 training [INFO ] Epoch  5 Batch 1400 Training err. 2.80733 Training err. RA 3.13208 Valid. err. 2.81194
2018-02-03 21:21:24,055 training [INFO ] Epoch  5 Batch 1450 Training err. 2.81520 Training err. RA 3.12115 Valid. err. 2.78846
2018-02-03 21:21:24,314 training [INFO ] Epoch  5 Batch 1500 Training err. 2.78168 Training err. RA 3.10983 Valid. err. 2.75545
2018-02-03 21:21:24,673 training [INFO ] Epoch  6 Batch 1550 Training err. 2.86253 Training err. RA 3.10186 Valid. err. 2.75465
2018-02-03 21:21:24,923 training [INFO ] Epoch  6 Batch 1600 Training err. 2.80201 Training err. RA 3.09249 Valid. err. 2.79232
2018-02-03 21:21:25,174 training [INFO ] Epoch  6 Batch 1650 Training err. 2.73447 Training err. RA 3.08164 Valid. err. 2.73748
2018-02-03 21:21:25,424 training [INFO ] Epoch  6 Batch 1700 Training err. 2.70195 Training err. RA 3.07047 Valid. err. 2.74823
2018-02-03 21:21:25,676 training [INFO ] Epoch  6 Batch 1750 Training err. 2.77809 Training err. RA 3.06212 Valid. err. 2.72491
2018-02-03 21:21:25,932 training [INFO ] Epoch  6 Batch 1800 Training err. 2.69493 Training err. RA 3.05192 Valid. err. 2.69931
2018-02-03 21:21:26,312 training [INFO ] Epoch  7 Batch 1850 Training err. 2.79711 Training err. RA 3.04503 Valid. err. 2.71199
2018-02-03 21:21:26,566 training [INFO ] Epoch  7 Batch 1900 Training err. 2.76612 Training err. RA 3.03769 Valid. err. 2.68136
2018-02-03 21:21:26,818 training [INFO ] Epoch  7 Batch 1950 Training err. 2.66185 Training err. RA 3.02805 Valid. err. 2.65971
2018-02-03 21:21:27,103 training [INFO ] Epoch  7 Batch 2000 Training err. 2.62609 Training err. RA 3.01800 Valid. err. 2.65393
2018-02-03 21:21:27,370 training [INFO ] Epoch  7 Batch 2050 Training err. 2.73244 Training err. RA 3.01104 Valid. err. 2.63310
2018-02-03 21:21:27,625 training [INFO ] Epoch  7 Batch 2100 Training err. 2.61474 Training err. RA 3.00160 Valid. err. 2.61172
2018-02-03 21:21:27,990 training [INFO ] Epoch  8 Batch 2150 Training err. 2.68380 Training err. RA 2.99421 Valid. err. 2.60411
2018-02-03 21:21:28,243 training [INFO ] Epoch  8 Batch 2200 Training err. 2.75109 Training err. RA 2.98869 Valid. err. 2.60345
2018-02-03 21:21:28,510 training [INFO ] Epoch  8 Batch 2250 Training err. 2.61347 Training err. RA 2.98035 Valid. err. 2.60475
2018-02-03 21:21:28,763 training [INFO ] Epoch  8 Batch 2300 Training err. 2.59414 Training err. RA 2.97195 Valid. err. 2.58229
2018-02-03 21:21:29,017 training [INFO ] Epoch  8 Batch 2350 Training err. 2.65070 Training err. RA 2.96512 Valid. err. 2.60053
2018-02-03 21:21:29,269 training [INFO ] Epoch  8 Batch 2400 Training err. 2.55161 Training err. RA 2.95650 Valid. err. 2.55964
2018-02-03 21:21:29,519 training [INFO ] Epoch  8 Batch 2450 Training err. 2.63221 Training err. RA 2.94988 Valid. err. 2.57322
2018-02-03 21:21:29,878 training [INFO ] Epoch  9 Batch 2500 Training err. 2.66568 Training err. RA 2.94420 Valid. err. 2.58572
2018-02-03 21:21:30,128 training [INFO ] Epoch  9 Batch 2550 Training err. 2.62300 Training err. RA 2.93790 Valid. err. 2.55158
2018-02-03 21:21:30,379 training [INFO ] Epoch  9 Batch 2600 Training err. 2.54574 Training err. RA 2.93036 Valid. err. 2.52231
2018-02-03 21:21:30,625 training [INFO ] Epoch  9 Batch 2650 Training err. 2.60145 Training err. RA 2.92415 Valid. err. 2.54871
2018-02-03 21:21:30,879 training [INFO ] Epoch  9 Batch 2700 Training err. 2.50288 Training err. RA 2.91635 Valid. err. 2.53165
2018-02-03 21:21:31,166 training [INFO ] Epoch  9 Batch 2750 Training err. 2.55765 Training err. RA 2.90983 Valid. err. 2.49620
2018-02-03 21:21:31,542 training [INFO ] Epoch 10 Batch 2800 Training err. 2.60069 Training err. RA 2.90431 Valid. err. 2.53053
2018-02-03 21:21:31,806 training [INFO ] Epoch 10 Batch 2850 Training err. 2.60063 Training err. RA 2.89898 Valid. err. 2.49945
2018-02-03 21:21:32,088 training [INFO ] Epoch 10 Batch 2900 Training err. 2.49138 Training err. RA 2.89196 Valid. err. 2.47118
2018-02-03 21:21:32,353 training [INFO ] Epoch 10 Batch 2950 Training err. 2.54494 Training err. RA 2.88607 Valid. err. 2.51932
2018-02-03 21:21:32,630 training [INFO ] Epoch 10 Batch 3000 Training err. 2.47208 Training err. RA 2.87917 Valid. err. 2.44812
2018-02-03 21:21:32,870 training [INFO ] Epoch 10 Batch 3050 Training err. 2.49906 Training err. RA 2.87294 Valid. err. 2.43973
2018-02-03 21:21:33,048 __main__ [INFO ] End of training
2018-02-03 21:21:33,344 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:21:33,344 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:21:33,646 training [INFO ] Epoch  1 Batch   50 Training err. 4.04214 Training err. RA 4.04214 Valid. err. 3.54833
2018-02-03 21:21:33,944 training [INFO ] Epoch  1 Batch  100 Training err. 3.39814 Training err. RA 3.72014 Valid. err. 3.31442
2018-02-03 21:21:34,220 training [INFO ] Epoch  1 Batch  150 Training err. 3.27816 Training err. RA 3.57281 Valid. err. 3.25355
2018-02-03 21:21:34,497 training [INFO ] Epoch  1 Batch  200 Training err. 3.25863 Training err. RA 3.49427 Valid. err. 3.23396
2018-02-03 21:21:34,878 training [INFO ] Epoch  2 Batch  250 Training err. 3.25330 Training err. RA 3.44608 Valid. err. 3.25586
2018-02-03 21:21:35,145 training [INFO ] Epoch  2 Batch  300 Training err. 3.21729 Training err. RA 3.40794 Valid. err. 3.22208
2018-02-03 21:21:35,459 training [INFO ] Epoch  2 Batch  350 Training err. 3.21434 Training err. RA 3.38029 Valid. err. 3.22708
2018-02-03 21:21:35,763 training [INFO ] Epoch  2 Batch  400 Training err. 3.22115 Training err. RA 3.36039 Valid. err. 3.20212
2018-02-03 21:21:36,154 training [INFO ] Epoch  3 Batch  450 Training err. 3.23364 Training err. RA 3.34631 Valid. err. 3.21623
2018-02-03 21:21:36,440 training [INFO ] Epoch  3 Batch  500 Training err. 3.17546 Training err. RA 3.32923 Valid. err. 3.19916
2018-02-03 21:21:36,708 training [INFO ] Epoch  3 Batch  550 Training err. 3.19734 Training err. RA 3.31724 Valid. err. 3.20025
2018-02-03 21:21:36,970 training [INFO ] Epoch  3 Batch  600 Training err. 3.18341 Training err. RA 3.30608 Valid. err. 3.16973
2018-02-03 21:21:37,349 training [INFO ] Epoch  4 Batch  650 Training err. 3.19104 Training err. RA 3.29724 Valid. err. 3.16960
2018-02-03 21:21:37,639 training [INFO ] Epoch  4 Batch  700 Training err. 3.11587 Training err. RA 3.28428 Valid. err. 3.13092
2018-02-03 21:21:37,925 training [INFO ] Epoch  4 Batch  750 Training err. 3.11660 Training err. RA 3.27310 Valid. err. 3.10533
2018-02-03 21:21:38,201 training [INFO ] Epoch  4 Batch  800 Training err. 3.08383 Training err. RA 3.26127 Valid. err. 3.10539
2018-02-03 21:21:38,572 training [INFO ] Epoch  5 Batch  850 Training err. 3.09290 Training err. RA 3.25137 Valid. err. 3.05708
2018-02-03 21:21:38,829 training [INFO ] Epoch  5 Batch  900 Training err. 3.01284 Training err. RA 3.23812 Valid. err. 3.00853
2018-02-03 21:21:39,081 training [INFO ] Epoch  5 Batch  950 Training err. 2.97486 Training err. RA 3.22426 Valid. err. 2.94603
2018-02-03 21:21:39,342 training [INFO ] Epoch  5 Batch 1000 Training err. 2.91668 Training err. RA 3.20888 Valid. err. 2.89707
2018-02-03 21:21:39,749 training [INFO ] Epoch  6 Batch 1050 Training err. 2.95081 Training err. RA 3.19659 Valid. err. 2.87833
2018-02-03 21:21:40,038 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88961 Training err. RA 3.18264 Valid. err. 2.85112
2018-02-03 21:21:40,308 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83982 Training err. RA 3.16773 Valid. err. 2.80937
2018-02-03 21:21:40,561 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81488 Training err. RA 3.15303 Valid. err. 2.79451
2018-02-03 21:21:40,919 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87542 Training err. RA 3.14193 Valid. err. 2.84760
2018-02-03 21:21:41,171 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80802 Training err. RA 3.12908 Valid. err. 2.76413
2018-02-03 21:21:41,429 training [INFO ] Epoch  7 Batch 1350 Training err. 2.74761 Training err. RA 3.11496 Valid. err. 2.73305
2018-02-03 21:21:41,700 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74546 Training err. RA 3.10176 Valid. err. 2.72217
2018-02-03 21:21:42,056 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80934 Training err. RA 3.09168 Valid. err. 2.80859
2018-02-03 21:21:42,313 training [INFO ] Epoch  8 Batch 1500 Training err. 2.75365 Training err. RA 3.08041 Valid. err. 2.70634
2018-02-03 21:21:42,572 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69065 Training err. RA 3.06784 Valid. err. 2.68305
2018-02-03 21:21:42,840 training [INFO ] Epoch  8 Batch 1600 Training err. 2.68488 Training err. RA 3.05587 Valid. err. 2.69275
2018-02-03 21:21:43,210 training [INFO ] Epoch  9 Batch 1650 Training err. 2.75326 Training err. RA 3.04670 Valid. err. 2.64619
2018-02-03 21:21:43,475 training [INFO ] Epoch  9 Batch 1700 Training err. 2.70388 Training err. RA 3.03662 Valid. err. 2.64884
2018-02-03 21:21:43,738 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62870 Training err. RA 3.02496 Valid. err. 2.64648
2018-02-03 21:21:44,006 training [INFO ] Epoch  9 Batch 1800 Training err. 2.64168 Training err. RA 3.01431 Valid. err. 2.63541
2018-02-03 21:21:44,377 training [INFO ] Epoch 10 Batch 1850 Training err. 2.69184 Training err. RA 3.00560 Valid. err. 2.62022
2018-02-03 21:21:44,642 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66928 Training err. RA 2.99675 Valid. err. 2.66894
2018-02-03 21:21:44,898 training [INFO ] Epoch 10 Batch 1950 Training err. 2.57763 Training err. RA 2.98600 Valid. err. 2.57420
2018-02-03 21:21:45,157 training [INFO ] Epoch 10 Batch 2000 Training err. 2.61542 Training err. RA 2.97674 Valid. err. 2.56837
2018-02-03 21:21:45,415 training [INFO ] Epoch 10 Batch 2050 Training err. 2.59956 Training err. RA 2.96754 Valid. err. 2.56084
2018-02-03 21:21:45,509 __main__ [INFO ] End of training
2018-02-03 21:21:45,754 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:21:45,754 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:21:46,029 training [INFO ] Epoch  1 Batch   50 Training err. 4.25089 Training err. RA 4.25089 Valid. err. 4.07388
2018-02-03 21:21:46,273 training [INFO ] Epoch  1 Batch  100 Training err. 3.91735 Training err. RA 4.08412 Valid. err. 3.66513
2018-02-03 21:21:46,518 training [INFO ] Epoch  1 Batch  150 Training err. 3.58519 Training err. RA 3.91781 Valid. err. 3.43050
2018-02-03 21:21:46,762 training [INFO ] Epoch  1 Batch  200 Training err. 3.43288 Training err. RA 3.79658 Valid. err. 3.35624
2018-02-03 21:21:47,006 training [INFO ] Epoch  1 Batch  250 Training err. 3.35662 Training err. RA 3.70859 Valid. err. 3.32507
2018-02-03 21:21:47,247 training [INFO ] Epoch  1 Batch  300 Training err. 3.34314 Training err. RA 3.64768 Valid. err. 3.29843
2018-02-03 21:21:47,599 training [INFO ] Epoch  2 Batch  350 Training err. 3.30636 Training err. RA 3.59892 Valid. err. 3.27696
2018-02-03 21:21:47,838 training [INFO ] Epoch  2 Batch  400 Training err. 3.29690 Training err. RA 3.56117 Valid. err. 3.26078
2018-02-03 21:21:48,085 training [INFO ] Epoch  2 Batch  450 Training err. 3.24770 Training err. RA 3.52634 Valid. err. 3.26687
2018-02-03 21:21:48,330 training [INFO ] Epoch  2 Batch  500 Training err. 3.22835 Training err. RA 3.49654 Valid. err. 3.26708
2018-02-03 21:21:48,576 training [INFO ] Epoch  2 Batch  550 Training err. 3.27238 Training err. RA 3.47616 Valid. err. 3.24858
2018-02-03 21:21:48,824 training [INFO ] Epoch  2 Batch  600 Training err. 3.25082 Training err. RA 3.45738 Valid. err. 3.23533
2018-02-03 21:21:49,177 training [INFO ] Epoch  3 Batch  650 Training err. 3.26233 Training err. RA 3.44238 Valid. err. 3.24370
2018-02-03 21:21:49,425 training [INFO ] Epoch  3 Batch  700 Training err. 3.21580 Training err. RA 3.42619 Valid. err. 3.23970
2018-02-03 21:21:49,669 training [INFO ] Epoch  3 Batch  750 Training err. 3.23215 Training err. RA 3.41326 Valid. err. 3.24591
2018-02-03 21:21:49,911 training [INFO ] Epoch  3 Batch  800 Training err. 3.20004 Training err. RA 3.39993 Valid. err. 3.24128
2018-02-03 21:21:50,158 training [INFO ] Epoch  3 Batch  850 Training err. 3.24595 Training err. RA 3.39087 Valid. err. 3.22805
2018-02-03 21:21:50,408 training [INFO ] Epoch  3 Batch  900 Training err. 3.22280 Training err. RA 3.38154 Valid. err. 3.21908
2018-02-03 21:21:50,763 training [INFO ] Epoch  4 Batch  950 Training err. 3.22606 Training err. RA 3.37335 Valid. err. 3.22369
2018-02-03 21:21:51,015 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19468 Training err. RA 3.36442 Valid. err. 3.22399
2018-02-03 21:21:51,261 training [INFO ] Epoch  4 Batch 1050 Training err. 3.23040 Training err. RA 3.35804 Valid. err. 3.23087
2018-02-03 21:21:51,509 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18838 Training err. RA 3.35033 Valid. err. 3.22223
2018-02-03 21:21:51,752 training [INFO ] Epoch  4 Batch 1150 Training err. 3.22367 Training err. RA 3.34482 Valid. err. 3.21680
2018-02-03 21:21:51,999 training [INFO ] Epoch  4 Batch 1200 Training err. 3.19536 Training err. RA 3.33859 Valid. err. 3.20280
2018-02-03 21:21:52,348 training [INFO ] Epoch  5 Batch 1250 Training err. 3.21777 Training err. RA 3.33376 Valid. err. 3.20317
2018-02-03 21:21:52,592 training [INFO ] Epoch  5 Batch 1300 Training err. 3.18430 Training err. RA 3.32801 Valid. err. 3.19901
2018-02-03 21:21:52,839 training [INFO ] Epoch  5 Batch 1350 Training err. 3.21200 Training err. RA 3.32371 Valid. err. 3.20791
2018-02-03 21:21:53,084 training [INFO ] Epoch  5 Batch 1400 Training err. 3.14681 Training err. RA 3.31740 Valid. err. 3.19795
2018-02-03 21:21:53,326 training [INFO ] Epoch  5 Batch 1450 Training err. 3.20256 Training err. RA 3.31344 Valid. err. 3.18935
2018-02-03 21:21:53,574 training [INFO ] Epoch  5 Batch 1500 Training err. 3.16935 Training err. RA 3.30863 Valid. err. 3.18520
2018-02-03 21:21:53,960 training [INFO ] Epoch  6 Batch 1550 Training err. 3.19318 Training err. RA 3.30491 Valid. err. 3.17755
2018-02-03 21:21:54,226 training [INFO ] Epoch  6 Batch 1600 Training err. 3.17147 Training err. RA 3.30074 Valid. err. 3.16673
2018-02-03 21:21:54,485 training [INFO ] Epoch  6 Batch 1650 Training err. 3.18570 Training err. RA 3.29725 Valid. err. 3.16049
2018-02-03 21:21:54,730 training [INFO ] Epoch  6 Batch 1700 Training err. 3.08802 Training err. RA 3.29110 Valid. err. 3.16645
2018-02-03 21:21:54,976 training [INFO ] Epoch  6 Batch 1750 Training err. 3.17645 Training err. RA 3.28782 Valid. err. 3.14035
2018-02-03 21:21:55,233 training [INFO ] Epoch  6 Batch 1800 Training err. 3.12448 Training err. RA 3.28329 Valid. err. 3.12810
2018-02-03 21:21:55,676 training [INFO ] Epoch  7 Batch 1850 Training err. 3.12511 Training err. RA 3.27901 Valid. err. 3.11594
2018-02-03 21:21:55,955 training [INFO ] Epoch  7 Batch 1900 Training err. 3.14539 Training err. RA 3.27549 Valid. err. 3.13017
2018-02-03 21:21:56,217 training [INFO ] Epoch  7 Batch 1950 Training err. 3.12510 Training err. RA 3.27164 Valid. err. 3.09729
2018-02-03 21:21:56,526 training [INFO ] Epoch  7 Batch 2000 Training err. 3.02967 Training err. RA 3.26559 Valid. err. 3.07700
2018-02-03 21:21:56,800 training [INFO ] Epoch  7 Batch 2050 Training err. 3.10658 Training err. RA 3.26171 Valid. err. 3.06112
2018-02-03 21:21:57,102 training [INFO ] Epoch  7 Batch 2100 Training err. 3.03572 Training err. RA 3.25633 Valid. err. 3.03671
2018-02-03 21:21:57,463 training [INFO ] Epoch  8 Batch 2150 Training err. 3.04055 Training err. RA 3.25131 Valid. err. 3.01571
2018-02-03 21:21:57,750 training [INFO ] Epoch  8 Batch 2200 Training err. 3.07181 Training err. RA 3.24723 Valid. err. 2.99929
2018-02-03 21:21:58,040 training [INFO ] Epoch  8 Batch 2250 Training err. 3.04324 Training err. RA 3.24270 Valid. err. 2.97431
2018-02-03 21:21:58,274 training [INFO ] Epoch  8 Batch 2300 Training err. 2.94324 Training err. RA 3.23619 Valid. err. 2.99403
2018-02-03 21:21:58,572 training [INFO ] Epoch  8 Batch 2350 Training err. 2.96055 Training err. RA 3.23032 Valid. err. 2.94005
2018-02-03 21:21:58,856 training [INFO ] Epoch  8 Batch 2400 Training err. 2.95367 Training err. RA 3.22456 Valid. err. 2.93758
2018-02-03 21:21:59,107 training [INFO ] Epoch  8 Batch 2450 Training err. 2.93826 Training err. RA 3.21872 Valid. err. 2.91751
2018-02-03 21:21:59,564 training [INFO ] Epoch  9 Batch 2500 Training err. 2.97622 Training err. RA 3.21387 Valid. err. 2.93166
2018-02-03 21:21:59,822 training [INFO ] Epoch  9 Batch 2550 Training err. 2.96011 Training err. RA 3.20889 Valid. err. 2.87569
2018-02-03 21:22:00,127 training [INFO ] Epoch  9 Batch 2600 Training err. 2.87883 Training err. RA 3.20255 Valid. err. 2.88209
2018-02-03 21:22:00,395 training [INFO ] Epoch  9 Batch 2650 Training err. 2.82910 Training err. RA 3.19550 Valid. err. 2.86312
2018-02-03 21:22:00,685 training [INFO ] Epoch  9 Batch 2700 Training err. 2.87590 Training err. RA 3.18958 Valid. err. 2.86603
2018-02-03 21:22:00,976 training [INFO ] Epoch  9 Batch 2750 Training err. 2.89185 Training err. RA 3.18417 Valid. err. 2.83468
2018-02-03 21:22:01,365 training [INFO ] Epoch 10 Batch 2800 Training err. 2.91581 Training err. RA 3.17938 Valid. err. 2.84438
2018-02-03 21:22:01,641 training [INFO ] Epoch 10 Batch 2850 Training err. 2.84987 Training err. RA 3.17359 Valid. err. 2.84183
2018-02-03 21:22:01,879 training [INFO ] Epoch 10 Batch 2900 Training err. 2.86559 Training err. RA 3.16828 Valid. err. 2.85923
2018-02-03 21:22:02,093 training [INFO ] Epoch 10 Batch 2950 Training err. 2.77927 Training err. RA 3.16169 Valid. err. 2.81609
2018-02-03 21:22:02,312 training [INFO ] Epoch 10 Batch 3000 Training err. 2.81512 Training err. RA 3.15591 Valid. err. 2.78541
2018-02-03 21:22:02,529 training [INFO ] Epoch 10 Batch 3050 Training err. 2.83377 Training err. RA 3.15063 Valid. err. 2.78474
2018-02-03 21:22:02,683 __main__ [INFO ] End of training
2018-02-03 21:22:23,590 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 21:22:23,592 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 21:22:23,598 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:22:23,598 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:22:25,758 training [INFO ] Epoch  1 Batch   50 Training err. 4.05880 Training err. RA 4.05880 Valid. err. 3.57151
2018-02-03 21:22:26,009 training [INFO ] Epoch  1 Batch  100 Training err. 3.41572 Training err. RA 3.73726 Valid. err. 3.31044
2018-02-03 21:22:26,261 training [INFO ] Epoch  1 Batch  150 Training err. 3.28214 Training err. RA 3.58556 Valid. err. 3.28601
2018-02-03 21:22:26,494 training [INFO ] Epoch  1 Batch  200 Training err. 3.26534 Training err. RA 3.50550 Valid. err. 3.25582
2018-02-03 21:22:26,725 training [INFO ] Epoch  1 Batch  250 Training err. 3.21962 Training err. RA 3.44833 Valid. err. 3.25865
2018-02-03 21:22:26,957 training [INFO ] Epoch  1 Batch  300 Training err. 3.26927 Training err. RA 3.41848 Valid. err. 3.22212
2018-02-03 21:22:27,311 training [INFO ] Epoch  2 Batch  350 Training err. 3.22529 Training err. RA 3.39088 Valid. err. 3.23593
2018-02-03 21:22:27,542 training [INFO ] Epoch  2 Batch  400 Training err. 3.22676 Training err. RA 3.37037 Valid. err. 3.24183
2018-02-03 21:22:27,775 training [INFO ] Epoch  2 Batch  450 Training err. 3.21585 Training err. RA 3.35320 Valid. err. 3.21069
2018-02-03 21:22:28,008 training [INFO ] Epoch  2 Batch  500 Training err. 3.20614 Training err. RA 3.33849 Valid. err. 3.21766
2018-02-03 21:22:28,237 training [INFO ] Epoch  2 Batch  550 Training err. 3.18786 Training err. RA 3.32480 Valid. err. 3.22025
2018-02-03 21:22:28,469 training [INFO ] Epoch  2 Batch  600 Training err. 3.20770 Training err. RA 3.31504 Valid. err. 3.17220
2018-02-03 21:22:28,814 training [INFO ] Epoch  3 Batch  650 Training err. 3.18077 Training err. RA 3.30471 Valid. err. 3.17343
2018-02-03 21:22:29,061 training [INFO ] Epoch  3 Batch  700 Training err. 3.17044 Training err. RA 3.29512 Valid. err. 3.15711
2018-02-03 21:22:29,294 training [INFO ] Epoch  3 Batch  750 Training err. 3.11770 Training err. RA 3.28329 Valid. err. 3.12737
2018-02-03 21:22:29,524 training [INFO ] Epoch  3 Batch  800 Training err. 3.12585 Training err. RA 3.27345 Valid. err. 3.10074
2018-02-03 21:22:29,759 training [INFO ] Epoch  3 Batch  850 Training err. 3.05654 Training err. RA 3.26069 Valid. err. 3.14854
2018-02-03 21:22:29,991 training [INFO ] Epoch  3 Batch  900 Training err. 3.09893 Training err. RA 3.25171 Valid. err. 3.01561
2018-02-03 21:22:30,342 training [INFO ] Epoch  4 Batch  950 Training err. 3.05973 Training err. RA 3.24160 Valid. err. 3.06554
2018-02-03 21:22:30,572 training [INFO ] Epoch  4 Batch 1000 Training err. 2.98342 Training err. RA 3.22869 Valid. err. 2.96801
2018-02-03 21:22:30,809 training [INFO ] Epoch  4 Batch 1050 Training err. 2.91658 Training err. RA 3.21383 Valid. err. 2.93383
2018-02-03 21:22:31,040 training [INFO ] Epoch  4 Batch 1100 Training err. 2.92067 Training err. RA 3.20051 Valid. err. 2.87569
2018-02-03 21:22:31,275 training [INFO ] Epoch  4 Batch 1150 Training err. 2.87675 Training err. RA 3.18643 Valid. err. 2.90652
2018-02-03 21:22:31,507 training [INFO ] Epoch  4 Batch 1200 Training err. 2.88804 Training err. RA 3.17400 Valid. err. 2.82835
2018-02-03 21:22:31,853 training [INFO ] Epoch  5 Batch 1250 Training err. 2.92245 Training err. RA 3.16393 Valid. err. 2.86867
2018-02-03 21:22:32,084 training [INFO ] Epoch  5 Batch 1300 Training err. 2.86236 Training err. RA 3.15234 Valid. err. 2.81886
2018-02-03 21:22:32,321 training [INFO ] Epoch  5 Batch 1350 Training err. 2.76661 Training err. RA 3.13805 Valid. err. 2.78887
2018-02-03 21:22:32,553 training [INFO ] Epoch  5 Batch 1400 Training err. 2.79578 Training err. RA 3.12583 Valid. err. 2.78632
2018-02-03 21:22:32,788 training [INFO ] Epoch  5 Batch 1450 Training err. 2.79698 Training err. RA 3.11449 Valid. err. 2.77546
2018-02-03 21:22:33,019 training [INFO ] Epoch  5 Batch 1500 Training err. 2.76115 Training err. RA 3.10271 Valid. err. 2.72874
2018-02-03 21:22:33,364 training [INFO ] Epoch  6 Batch 1550 Training err. 2.84729 Training err. RA 3.09447 Valid. err. 2.73142
2018-02-03 21:22:33,595 training [INFO ] Epoch  6 Batch 1600 Training err. 2.77920 Training err. RA 3.08462 Valid. err. 2.77349
2018-02-03 21:22:33,834 training [INFO ] Epoch  6 Batch 1650 Training err. 2.70358 Training err. RA 3.07307 Valid. err. 2.69606
2018-02-03 21:22:34,066 training [INFO ] Epoch  6 Batch 1700 Training err. 2.67647 Training err. RA 3.06141 Valid. err. 2.69809
2018-02-03 21:22:34,300 training [INFO ] Epoch  6 Batch 1750 Training err. 2.74770 Training err. RA 3.05244 Valid. err. 2.68407
2018-02-03 21:22:34,531 training [INFO ] Epoch  6 Batch 1800 Training err. 2.65168 Training err. RA 3.04131 Valid. err. 2.66043
2018-02-03 21:22:34,876 training [INFO ] Epoch  7 Batch 1850 Training err. 2.76017 Training err. RA 3.03371 Valid. err. 2.69331
2018-02-03 21:22:35,115 training [INFO ] Epoch  7 Batch 1900 Training err. 2.72717 Training err. RA 3.02564 Valid. err. 2.63233
2018-02-03 21:22:35,371 training [INFO ] Epoch  7 Batch 1950 Training err. 2.62272 Training err. RA 3.01531 Valid. err. 2.61533
2018-02-03 21:22:35,622 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59415 Training err. RA 3.00478 Valid. err. 2.60029
2018-02-03 21:22:35,871 training [INFO ] Epoch  7 Batch 2050 Training err. 2.69327 Training err. RA 2.99719 Valid. err. 2.58631
2018-02-03 21:22:36,105 training [INFO ] Epoch  7 Batch 2100 Training err. 2.56483 Training err. RA 2.98689 Valid. err. 2.56666
2018-02-03 21:22:36,470 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64529 Training err. RA 2.97895 Valid. err. 2.56016
2018-02-03 21:22:36,721 training [INFO ] Epoch  8 Batch 2200 Training err. 2.70971 Training err. RA 2.97283 Valid. err. 2.56491
2018-02-03 21:22:36,977 training [INFO ] Epoch  8 Batch 2250 Training err. 2.57874 Training err. RA 2.96407 Valid. err. 2.55390
2018-02-03 21:22:37,229 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55139 Training err. RA 2.95510 Valid. err. 2.55243
2018-02-03 21:22:37,482 training [INFO ] Epoch  8 Batch 2350 Training err. 2.60688 Training err. RA 2.94769 Valid. err. 2.55712
2018-02-03 21:22:37,735 training [INFO ] Epoch  8 Batch 2400 Training err. 2.49764 Training err. RA 2.93831 Valid. err. 2.51376
2018-02-03 21:22:37,989 training [INFO ] Epoch  8 Batch 2450 Training err. 2.58373 Training err. RA 2.93108 Valid. err. 2.54451
2018-02-03 21:22:38,354 training [INFO ] Epoch  9 Batch 2500 Training err. 2.62607 Training err. RA 2.92498 Valid. err. 2.55396
2018-02-03 21:22:38,606 training [INFO ] Epoch  9 Batch 2550 Training err. 2.58437 Training err. RA 2.91830 Valid. err. 2.50407
2018-02-03 21:22:38,861 training [INFO ] Epoch  9 Batch 2600 Training err. 2.50787 Training err. RA 2.91041 Valid. err. 2.47312
2018-02-03 21:22:39,112 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56033 Training err. RA 2.90380 Valid. err. 2.51576
2018-02-03 21:22:39,369 training [INFO ] Epoch  9 Batch 2700 Training err. 2.45092 Training err. RA 2.89541 Valid. err. 2.51172
2018-02-03 21:22:39,621 training [INFO ] Epoch  9 Batch 2750 Training err. 2.50908 Training err. RA 2.88839 Valid. err. 2.47379
2018-02-03 21:22:39,986 training [INFO ] Epoch 10 Batch 2800 Training err. 2.56208 Training err. RA 2.88256 Valid. err. 2.48689
2018-02-03 21:22:40,215 training [INFO ] Epoch 10 Batch 2850 Training err. 2.56889 Training err. RA 2.87706 Valid. err. 2.48109
2018-02-03 21:22:40,454 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46033 Training err. RA 2.86988 Valid. err. 2.43525
2018-02-03 21:22:40,686 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51236 Training err. RA 2.86382 Valid. err. 2.47321
2018-02-03 21:22:40,923 training [INFO ] Epoch 10 Batch 3000 Training err. 2.43281 Training err. RA 2.85663 Valid. err. 2.42056
2018-02-03 21:22:41,154 training [INFO ] Epoch 10 Batch 3050 Training err. 2.45752 Training err. RA 2.85009 Valid. err. 2.45173
2018-02-03 21:22:41,312 __main__ [INFO ] End of training
2018-02-03 21:22:41,604 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:22:41,604 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:22:41,908 training [INFO ] Epoch  1 Batch   50 Training err. 4.04214 Training err. RA 4.04214 Valid. err. 3.54833
2018-02-03 21:22:42,170 training [INFO ] Epoch  1 Batch  100 Training err. 3.39814 Training err. RA 3.72014 Valid. err. 3.31442
2018-02-03 21:22:42,439 training [INFO ] Epoch  1 Batch  150 Training err. 3.27816 Training err. RA 3.57281 Valid. err. 3.25355
2018-02-03 21:22:42,702 training [INFO ] Epoch  1 Batch  200 Training err. 3.25863 Training err. RA 3.49427 Valid. err. 3.23396
2018-02-03 21:22:43,071 training [INFO ] Epoch  2 Batch  250 Training err. 3.25330 Training err. RA 3.44608 Valid. err. 3.25586
2018-02-03 21:22:43,343 training [INFO ] Epoch  2 Batch  300 Training err. 3.21729 Training err. RA 3.40794 Valid. err. 3.22208
2018-02-03 21:22:43,608 training [INFO ] Epoch  2 Batch  350 Training err. 3.21434 Training err. RA 3.38029 Valid. err. 3.22708
2018-02-03 21:22:43,874 training [INFO ] Epoch  2 Batch  400 Training err. 3.22115 Training err. RA 3.36039 Valid. err. 3.20212
2018-02-03 21:22:44,242 training [INFO ] Epoch  3 Batch  450 Training err. 3.23364 Training err. RA 3.34631 Valid. err. 3.21623
2018-02-03 21:22:44,510 training [INFO ] Epoch  3 Batch  500 Training err. 3.17546 Training err. RA 3.32923 Valid. err. 3.19916
2018-02-03 21:22:44,778 training [INFO ] Epoch  3 Batch  550 Training err. 3.19734 Training err. RA 3.31724 Valid. err. 3.20025
2018-02-03 21:22:45,044 training [INFO ] Epoch  3 Batch  600 Training err. 3.18341 Training err. RA 3.30608 Valid. err. 3.16973
2018-02-03 21:22:45,412 training [INFO ] Epoch  4 Batch  650 Training err. 3.19104 Training err. RA 3.29724 Valid. err. 3.16960
2018-02-03 21:22:45,680 training [INFO ] Epoch  4 Batch  700 Training err. 3.11587 Training err. RA 3.28428 Valid. err. 3.13092
2018-02-03 21:22:45,949 training [INFO ] Epoch  4 Batch  750 Training err. 3.11660 Training err. RA 3.27310 Valid. err. 3.10533
2018-02-03 21:22:46,212 training [INFO ] Epoch  4 Batch  800 Training err. 3.08383 Training err. RA 3.26127 Valid. err. 3.10539
2018-02-03 21:22:46,586 training [INFO ] Epoch  5 Batch  850 Training err. 3.09290 Training err. RA 3.25137 Valid. err. 3.05708
2018-02-03 21:22:46,859 training [INFO ] Epoch  5 Batch  900 Training err. 3.01284 Training err. RA 3.23812 Valid. err. 3.00853
2018-02-03 21:22:47,129 training [INFO ] Epoch  5 Batch  950 Training err. 2.97486 Training err. RA 3.22426 Valid. err. 2.94603
2018-02-03 21:22:47,399 training [INFO ] Epoch  5 Batch 1000 Training err. 2.91668 Training err. RA 3.20888 Valid. err. 2.89707
2018-02-03 21:22:47,768 training [INFO ] Epoch  6 Batch 1050 Training err. 2.95081 Training err. RA 3.19659 Valid. err. 2.87833
2018-02-03 21:22:48,034 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88961 Training err. RA 3.18264 Valid. err. 2.85112
2018-02-03 21:22:48,297 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83982 Training err. RA 3.16773 Valid. err. 2.80937
2018-02-03 21:22:48,561 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81488 Training err. RA 3.15303 Valid. err. 2.79451
2018-02-03 21:22:48,924 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87542 Training err. RA 3.14193 Valid. err. 2.84760
2018-02-03 21:22:49,192 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80802 Training err. RA 3.12908 Valid. err. 2.76413
2018-02-03 21:22:49,459 training [INFO ] Epoch  7 Batch 1350 Training err. 2.74761 Training err. RA 3.11496 Valid. err. 2.73305
2018-02-03 21:22:49,727 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74546 Training err. RA 3.10176 Valid. err. 2.72217
2018-02-03 21:22:50,088 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80934 Training err. RA 3.09168 Valid. err. 2.80859
2018-02-03 21:22:50,354 training [INFO ] Epoch  8 Batch 1500 Training err. 2.75365 Training err. RA 3.08041 Valid. err. 2.70634
2018-02-03 21:22:50,620 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69065 Training err. RA 3.06784 Valid. err. 2.68305
2018-02-03 21:22:50,888 training [INFO ] Epoch  8 Batch 1600 Training err. 2.68488 Training err. RA 3.05587 Valid. err. 2.69275
2018-02-03 21:22:51,257 training [INFO ] Epoch  9 Batch 1650 Training err. 2.75326 Training err. RA 3.04670 Valid. err. 2.64619
2018-02-03 21:22:51,528 training [INFO ] Epoch  9 Batch 1700 Training err. 2.70388 Training err. RA 3.03662 Valid. err. 2.64884
2018-02-03 21:22:51,800 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62870 Training err. RA 3.02496 Valid. err. 2.64648
2018-02-03 21:22:52,070 training [INFO ] Epoch  9 Batch 1800 Training err. 2.64168 Training err. RA 3.01431 Valid. err. 2.63541
2018-02-03 21:22:52,441 training [INFO ] Epoch 10 Batch 1850 Training err. 2.69184 Training err. RA 3.00560 Valid. err. 2.62022
2018-02-03 21:22:52,709 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66928 Training err. RA 2.99675 Valid. err. 2.66894
2018-02-03 21:22:52,980 training [INFO ] Epoch 10 Batch 1950 Training err. 2.57763 Training err. RA 2.98600 Valid. err. 2.57420
2018-02-03 21:22:53,248 training [INFO ] Epoch 10 Batch 2000 Training err. 2.61542 Training err. RA 2.97674 Valid. err. 2.56837
2018-02-03 21:22:53,514 training [INFO ] Epoch 10 Batch 2050 Training err. 2.59956 Training err. RA 2.96754 Valid. err. 2.56084
2018-02-03 21:22:53,610 __main__ [INFO ] End of training
2018-02-03 21:22:53,883 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:22:53,884 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:22:54,164 training [INFO ] Epoch  1 Batch   50 Training err. 4.25089 Training err. RA 4.25089 Valid. err. 4.07388
2018-02-03 21:22:54,399 training [INFO ] Epoch  1 Batch  100 Training err. 3.91735 Training err. RA 4.08412 Valid. err. 3.66513
2018-02-03 21:22:54,627 training [INFO ] Epoch  1 Batch  150 Training err. 3.58519 Training err. RA 3.91781 Valid. err. 3.43050
2018-02-03 21:22:54,850 training [INFO ] Epoch  1 Batch  200 Training err. 3.43288 Training err. RA 3.79658 Valid. err. 3.35624
2018-02-03 21:22:55,078 training [INFO ] Epoch  1 Batch  250 Training err. 3.35662 Training err. RA 3.70859 Valid. err. 3.32507
2018-02-03 21:22:55,297 training [INFO ] Epoch  1 Batch  300 Training err. 3.34314 Training err. RA 3.64768 Valid. err. 3.29843
2018-02-03 21:22:55,637 training [INFO ] Epoch  2 Batch  350 Training err. 3.30636 Training err. RA 3.59892 Valid. err. 3.27696
2018-02-03 21:22:55,877 training [INFO ] Epoch  2 Batch  400 Training err. 3.29690 Training err. RA 3.56117 Valid. err. 3.26078
2018-02-03 21:22:56,126 training [INFO ] Epoch  2 Batch  450 Training err. 3.24770 Training err. RA 3.52634 Valid. err. 3.26687
2018-02-03 21:22:56,381 training [INFO ] Epoch  2 Batch  500 Training err. 3.22835 Training err. RA 3.49654 Valid. err. 3.26708
2018-02-03 21:22:56,632 training [INFO ] Epoch  2 Batch  550 Training err. 3.27238 Training err. RA 3.47616 Valid. err. 3.24858
2018-02-03 21:22:56,884 training [INFO ] Epoch  2 Batch  600 Training err. 3.25082 Training err. RA 3.45738 Valid. err. 3.23533
2018-02-03 21:22:57,249 training [INFO ] Epoch  3 Batch  650 Training err. 3.26233 Training err. RA 3.44238 Valid. err. 3.24370
2018-02-03 21:22:57,499 training [INFO ] Epoch  3 Batch  700 Training err. 3.21580 Training err. RA 3.42619 Valid. err. 3.23970
2018-02-03 21:22:57,751 training [INFO ] Epoch  3 Batch  750 Training err. 3.23215 Training err. RA 3.41326 Valid. err. 3.24591
2018-02-03 21:22:58,005 training [INFO ] Epoch  3 Batch  800 Training err. 3.20004 Training err. RA 3.39993 Valid. err. 3.24128
2018-02-03 21:22:58,255 training [INFO ] Epoch  3 Batch  850 Training err. 3.24595 Training err. RA 3.39087 Valid. err. 3.22805
2018-02-03 21:22:58,509 training [INFO ] Epoch  3 Batch  900 Training err. 3.22280 Training err. RA 3.38154 Valid. err. 3.21908
2018-02-03 21:22:58,866 training [INFO ] Epoch  4 Batch  950 Training err. 3.22606 Training err. RA 3.37335 Valid. err. 3.22369
2018-02-03 21:22:59,118 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19468 Training err. RA 3.36442 Valid. err. 3.22399
2018-02-03 21:22:59,369 training [INFO ] Epoch  4 Batch 1050 Training err. 3.23040 Training err. RA 3.35804 Valid. err. 3.23087
2018-02-03 21:22:59,619 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18838 Training err. RA 3.35033 Valid. err. 3.22223
2018-02-03 21:22:59,873 training [INFO ] Epoch  4 Batch 1150 Training err. 3.22367 Training err. RA 3.34482 Valid. err. 3.21680
2018-02-03 21:23:00,130 training [INFO ] Epoch  4 Batch 1200 Training err. 3.19536 Training err. RA 3.33859 Valid. err. 3.20280
2018-02-03 21:23:00,491 training [INFO ] Epoch  5 Batch 1250 Training err. 3.21777 Training err. RA 3.33376 Valid. err. 3.20317
2018-02-03 21:23:00,741 training [INFO ] Epoch  5 Batch 1300 Training err. 3.18430 Training err. RA 3.32801 Valid. err. 3.19901
2018-02-03 21:23:00,990 training [INFO ] Epoch  5 Batch 1350 Training err. 3.21200 Training err. RA 3.32371 Valid. err. 3.20791
2018-02-03 21:23:01,239 training [INFO ] Epoch  5 Batch 1400 Training err. 3.14681 Training err. RA 3.31740 Valid. err. 3.19795
2018-02-03 21:23:01,491 training [INFO ] Epoch  5 Batch 1450 Training err. 3.20256 Training err. RA 3.31344 Valid. err. 3.18935
2018-02-03 21:23:01,742 training [INFO ] Epoch  5 Batch 1500 Training err. 3.16935 Training err. RA 3.30863 Valid. err. 3.18520
2018-02-03 21:23:02,104 training [INFO ] Epoch  6 Batch 1550 Training err. 3.19318 Training err. RA 3.30491 Valid. err. 3.17755
2018-02-03 21:23:02,356 training [INFO ] Epoch  6 Batch 1600 Training err. 3.17147 Training err. RA 3.30074 Valid. err. 3.16673
2018-02-03 21:23:02,608 training [INFO ] Epoch  6 Batch 1650 Training err. 3.18570 Training err. RA 3.29725 Valid. err. 3.16049
2018-02-03 21:23:02,859 training [INFO ] Epoch  6 Batch 1700 Training err. 3.08802 Training err. RA 3.29110 Valid. err. 3.16645
2018-02-03 21:23:03,110 training [INFO ] Epoch  6 Batch 1750 Training err. 3.17645 Training err. RA 3.28782 Valid. err. 3.14035
2018-02-03 21:23:03,363 training [INFO ] Epoch  6 Batch 1800 Training err. 3.12448 Training err. RA 3.28329 Valid. err. 3.12810
2018-02-03 21:23:03,725 training [INFO ] Epoch  7 Batch 1850 Training err. 3.12511 Training err. RA 3.27901 Valid. err. 3.11594
2018-02-03 21:23:03,974 training [INFO ] Epoch  7 Batch 1900 Training err. 3.14539 Training err. RA 3.27549 Valid. err. 3.13017
2018-02-03 21:23:04,223 training [INFO ] Epoch  7 Batch 1950 Training err. 3.12510 Training err. RA 3.27164 Valid. err. 3.09729
2018-02-03 21:23:04,476 training [INFO ] Epoch  7 Batch 2000 Training err. 3.02967 Training err. RA 3.26559 Valid. err. 3.07700
2018-02-03 21:23:04,726 training [INFO ] Epoch  7 Batch 2050 Training err. 3.10658 Training err. RA 3.26171 Valid. err. 3.06112
2018-02-03 21:23:04,979 training [INFO ] Epoch  7 Batch 2100 Training err. 3.03572 Training err. RA 3.25633 Valid. err. 3.03671
2018-02-03 21:23:05,343 training [INFO ] Epoch  8 Batch 2150 Training err. 3.04055 Training err. RA 3.25131 Valid. err. 3.01571
2018-02-03 21:23:05,594 training [INFO ] Epoch  8 Batch 2200 Training err. 3.07181 Training err. RA 3.24723 Valid. err. 2.99929
2018-02-03 21:23:05,846 training [INFO ] Epoch  8 Batch 2250 Training err. 3.04324 Training err. RA 3.24270 Valid. err. 2.97431
2018-02-03 21:23:06,098 training [INFO ] Epoch  8 Batch 2300 Training err. 2.94324 Training err. RA 3.23619 Valid. err. 2.99403
2018-02-03 21:23:06,352 training [INFO ] Epoch  8 Batch 2350 Training err. 2.96055 Training err. RA 3.23032 Valid. err. 2.94005
2018-02-03 21:23:06,603 training [INFO ] Epoch  8 Batch 2400 Training err. 2.95367 Training err. RA 3.22456 Valid. err. 2.93758
2018-02-03 21:23:06,852 training [INFO ] Epoch  8 Batch 2450 Training err. 2.93826 Training err. RA 3.21872 Valid. err. 2.91751
2018-02-03 21:23:07,210 training [INFO ] Epoch  9 Batch 2500 Training err. 2.97622 Training err. RA 3.21387 Valid. err. 2.93166
2018-02-03 21:23:07,460 training [INFO ] Epoch  9 Batch 2550 Training err. 2.96011 Training err. RA 3.20889 Valid. err. 2.87569
2018-02-03 21:23:07,710 training [INFO ] Epoch  9 Batch 2600 Training err. 2.87883 Training err. RA 3.20255 Valid. err. 2.88209
2018-02-03 21:23:07,962 training [INFO ] Epoch  9 Batch 2650 Training err. 2.82910 Training err. RA 3.19550 Valid. err. 2.86312
2018-02-03 21:23:08,211 training [INFO ] Epoch  9 Batch 2700 Training err. 2.87590 Training err. RA 3.18958 Valid. err. 2.86603
2018-02-03 21:23:08,464 training [INFO ] Epoch  9 Batch 2750 Training err. 2.89185 Training err. RA 3.18417 Valid. err. 2.83468
2018-02-03 21:23:08,826 training [INFO ] Epoch 10 Batch 2800 Training err. 2.91581 Training err. RA 3.17938 Valid. err. 2.84438
2018-02-03 21:23:09,077 training [INFO ] Epoch 10 Batch 2850 Training err. 2.84987 Training err. RA 3.17359 Valid. err. 2.84183
2018-02-03 21:23:09,351 training [INFO ] Epoch 10 Batch 2900 Training err. 2.86559 Training err. RA 3.16828 Valid. err. 2.85923
2018-02-03 21:23:09,602 training [INFO ] Epoch 10 Batch 2950 Training err. 2.77927 Training err. RA 3.16169 Valid. err. 2.81609
2018-02-03 21:23:09,851 training [INFO ] Epoch 10 Batch 3000 Training err. 2.81512 Training err. RA 3.15591 Valid. err. 2.78541
2018-02-03 21:23:10,103 training [INFO ] Epoch 10 Batch 3050 Training err. 2.83377 Training err. RA 3.15063 Valid. err. 2.78474
2018-02-03 21:23:10,266 __main__ [INFO ] End of training
2018-02-03 21:23:40,793 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 21:23:40,796 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 21:23:40,801 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:23:40,801 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:23:43,016 training [INFO ] Epoch  1 Batch   50 Training err. 4.02838 Training err. RA 4.02838 Valid. err. 3.50166
2018-02-03 21:23:43,264 training [INFO ] Epoch  1 Batch  100 Training err. 3.39212 Training err. RA 3.71025 Valid. err. 3.29976
2018-02-03 21:23:43,515 training [INFO ] Epoch  1 Batch  150 Training err. 3.27779 Training err. RA 3.56610 Valid. err. 3.28327
2018-02-03 21:23:43,765 training [INFO ] Epoch  1 Batch  200 Training err. 3.26603 Training err. RA 3.49108 Valid. err. 3.25450
2018-02-03 21:23:44,017 training [INFO ] Epoch  1 Batch  250 Training err. 3.22028 Training err. RA 3.43692 Valid. err. 3.25834
2018-02-03 21:23:44,268 training [INFO ] Epoch  1 Batch  300 Training err. 3.26983 Training err. RA 3.40907 Valid. err. 3.22228
2018-02-03 21:23:44,643 training [INFO ] Epoch  2 Batch  350 Training err. 3.22674 Training err. RA 3.38303 Valid. err. 3.23562
2018-02-03 21:23:44,894 training [INFO ] Epoch  2 Batch  400 Training err. 3.22727 Training err. RA 3.36356 Valid. err. 3.24199
2018-02-03 21:23:45,147 training [INFO ] Epoch  2 Batch  450 Training err. 3.21761 Training err. RA 3.34734 Valid. err. 3.21250
2018-02-03 21:23:45,400 training [INFO ] Epoch  2 Batch  500 Training err. 3.20880 Training err. RA 3.33349 Valid. err. 3.21996
2018-02-03 21:23:45,652 training [INFO ] Epoch  2 Batch  550 Training err. 3.19131 Training err. RA 3.32056 Valid. err. 3.22208
2018-02-03 21:23:45,905 training [INFO ] Epoch  2 Batch  600 Training err. 3.21243 Training err. RA 3.31155 Valid. err. 3.17823
2018-02-03 21:23:46,270 training [INFO ] Epoch  3 Batch  650 Training err. 3.18743 Training err. RA 3.30200 Valid. err. 3.18554
2018-02-03 21:23:46,545 training [INFO ] Epoch  3 Batch  700 Training err. 3.17683 Training err. RA 3.29306 Valid. err. 3.16524
2018-02-03 21:23:46,795 training [INFO ] Epoch  3 Batch  750 Training err. 3.13188 Training err. RA 3.28232 Valid. err. 3.14365
2018-02-03 21:23:47,051 training [INFO ] Epoch  3 Batch  800 Training err. 3.13961 Training err. RA 3.27340 Valid. err. 3.11814
2018-02-03 21:23:47,300 training [INFO ] Epoch  3 Batch  850 Training err. 3.07812 Training err. RA 3.26191 Valid. err. 3.15325
2018-02-03 21:23:47,552 training [INFO ] Epoch  3 Batch  900 Training err. 3.12325 Training err. RA 3.25421 Valid. err. 3.05021
2018-02-03 21:23:47,915 training [INFO ] Epoch  4 Batch  950 Training err. 3.09059 Training err. RA 3.24560 Valid. err. 3.09924
2018-02-03 21:23:48,168 training [INFO ] Epoch  4 Batch 1000 Training err. 3.02035 Training err. RA 3.23433 Valid. err. 3.00918
2018-02-03 21:23:48,421 training [INFO ] Epoch  4 Batch 1050 Training err. 2.96302 Training err. RA 3.22141 Valid. err. 2.97998
2018-02-03 21:23:48,674 training [INFO ] Epoch  4 Batch 1100 Training err. 2.95698 Training err. RA 3.20939 Valid. err. 2.91156
2018-02-03 21:23:48,927 training [INFO ] Epoch  4 Batch 1150 Training err. 2.90802 Training err. RA 3.19629 Valid. err. 2.94043
2018-02-03 21:23:49,179 training [INFO ] Epoch  4 Batch 1200 Training err. 2.90996 Training err. RA 3.18436 Valid. err. 2.84904
2018-02-03 21:23:49,548 training [INFO ] Epoch  5 Batch 1250 Training err. 2.93774 Training err. RA 3.17450 Valid. err. 2.89803
2018-02-03 21:23:49,798 training [INFO ] Epoch  5 Batch 1300 Training err. 2.87664 Training err. RA 3.16304 Valid. err. 2.83356
2018-02-03 21:23:50,056 training [INFO ] Epoch  5 Batch 1350 Training err. 2.78030 Training err. RA 3.14886 Valid. err. 2.80761
2018-02-03 21:23:50,305 training [INFO ] Epoch  5 Batch 1400 Training err. 2.79828 Training err. RA 3.13634 Valid. err. 2.78421
2018-02-03 21:23:50,557 training [INFO ] Epoch  5 Batch 1450 Training err. 2.80301 Training err. RA 3.12485 Valid. err. 2.76948
2018-02-03 21:23:50,807 training [INFO ] Epoch  5 Batch 1500 Training err. 2.76171 Training err. RA 3.11274 Valid. err. 2.72791
2018-02-03 21:23:51,167 training [INFO ] Epoch  6 Batch 1550 Training err. 2.84553 Training err. RA 3.10412 Valid. err. 2.72987
2018-02-03 21:23:51,420 training [INFO ] Epoch  6 Batch 1600 Training err. 2.78023 Training err. RA 3.09400 Valid. err. 2.78478
2018-02-03 21:23:51,672 training [INFO ] Epoch  6 Batch 1650 Training err. 2.70801 Training err. RA 3.08231 Valid. err. 2.70293
2018-02-03 21:23:51,924 training [INFO ] Epoch  6 Batch 1700 Training err. 2.67635 Training err. RA 3.07037 Valid. err. 2.69940
2018-02-03 21:23:52,177 training [INFO ] Epoch  6 Batch 1750 Training err. 2.74894 Training err. RA 3.06118 Valid. err. 2.69358
2018-02-03 21:23:52,430 training [INFO ] Epoch  6 Batch 1800 Training err. 2.65693 Training err. RA 3.04995 Valid. err. 2.65138
2018-02-03 21:23:52,795 training [INFO ] Epoch  7 Batch 1850 Training err. 2.75778 Training err. RA 3.04206 Valid. err. 2.67661
2018-02-03 21:23:53,051 training [INFO ] Epoch  7 Batch 1900 Training err. 2.73289 Training err. RA 3.03392 Valid. err. 2.63698
2018-02-03 21:23:53,301 training [INFO ] Epoch  7 Batch 1950 Training err. 2.63009 Training err. RA 3.02357 Valid. err. 2.61772
2018-02-03 21:23:53,556 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59996 Training err. RA 3.01298 Valid. err. 2.61332
2018-02-03 21:23:53,807 training [INFO ] Epoch  7 Batch 2050 Training err. 2.69916 Training err. RA 3.00532 Valid. err. 2.58782
2018-02-03 21:23:54,060 training [INFO ] Epoch  7 Batch 2100 Training err. 2.57968 Training err. RA 2.99519 Valid. err. 2.57242
2018-02-03 21:23:54,422 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64759 Training err. RA 2.98710 Valid. err. 2.56540
2018-02-03 21:23:54,673 training [INFO ] Epoch  8 Batch 2200 Training err. 2.71489 Training err. RA 2.98092 Valid. err. 2.56458
2018-02-03 21:23:54,926 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58897 Training err. RA 2.97221 Valid. err. 2.56504
2018-02-03 21:23:55,178 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55979 Training err. RA 2.96324 Valid. err. 2.55550
2018-02-03 21:23:55,431 training [INFO ] Epoch  8 Batch 2350 Training err. 2.61846 Training err. RA 2.95591 Valid. err. 2.56015
2018-02-03 21:23:55,684 training [INFO ] Epoch  8 Batch 2400 Training err. 2.51326 Training err. RA 2.94668 Valid. err. 2.51969
2018-02-03 21:23:55,936 training [INFO ] Epoch  8 Batch 2450 Training err. 2.59464 Training err. RA 2.93950 Valid. err. 2.53159
2018-02-03 21:23:56,301 training [INFO ] Epoch  9 Batch 2500 Training err. 2.63014 Training err. RA 2.93331 Valid. err. 2.54333
2018-02-03 21:23:56,557 training [INFO ] Epoch  9 Batch 2550 Training err. 2.59256 Training err. RA 2.92663 Valid. err. 2.50970
2018-02-03 21:23:56,805 training [INFO ] Epoch  9 Batch 2600 Training err. 2.51496 Training err. RA 2.91871 Valid. err. 2.48758
2018-02-03 21:23:57,060 training [INFO ] Epoch  9 Batch 2650 Training err. 2.57334 Training err. RA 2.91220 Valid. err. 2.52852
2018-02-03 21:23:57,310 training [INFO ] Epoch  9 Batch 2700 Training err. 2.46686 Training err. RA 2.90395 Valid. err. 2.50096
2018-02-03 21:23:57,563 training [INFO ] Epoch  9 Batch 2750 Training err. 2.51905 Training err. RA 2.89695 Valid. err. 2.46521
2018-02-03 21:23:57,926 training [INFO ] Epoch 10 Batch 2800 Training err. 2.56737 Training err. RA 2.89107 Valid. err. 2.50902
2018-02-03 21:23:58,178 training [INFO ] Epoch 10 Batch 2850 Training err. 2.57596 Training err. RA 2.88554 Valid. err. 2.47296
2018-02-03 21:23:58,430 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46639 Training err. RA 2.87831 Valid. err. 2.44318
2018-02-03 21:23:58,683 training [INFO ] Epoch 10 Batch 2950 Training err. 2.52169 Training err. RA 2.87227 Valid. err. 2.49426
2018-02-03 21:23:58,935 training [INFO ] Epoch 10 Batch 3000 Training err. 2.44491 Training err. RA 2.86515 Valid. err. 2.42830
2018-02-03 21:23:59,188 training [INFO ] Epoch 10 Batch 3050 Training err. 2.46449 Training err. RA 2.85858 Valid. err. 2.43909
2018-02-03 21:23:59,352 __main__ [INFO ] End of training
2018-02-03 21:23:59,652 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:23:59,652 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:23:59,947 training [INFO ] Epoch  1 Batch   50 Training err. 4.04214 Training err. RA 4.04214 Valid. err. 3.54833
2018-02-03 21:24:00,224 training [INFO ] Epoch  1 Batch  100 Training err. 3.39814 Training err. RA 3.72014 Valid. err. 3.31442
2018-02-03 21:24:00,488 training [INFO ] Epoch  1 Batch  150 Training err. 3.27816 Training err. RA 3.57281 Valid. err. 3.25355
2018-02-03 21:24:00,760 training [INFO ] Epoch  1 Batch  200 Training err. 3.25863 Training err. RA 3.49427 Valid. err. 3.23396
2018-02-03 21:24:01,131 training [INFO ] Epoch  2 Batch  250 Training err. 3.25330 Training err. RA 3.44608 Valid. err. 3.25586
2018-02-03 21:24:01,393 training [INFO ] Epoch  2 Batch  300 Training err. 3.21729 Training err. RA 3.40794 Valid. err. 3.22208
2018-02-03 21:24:01,657 training [INFO ] Epoch  2 Batch  350 Training err. 3.21434 Training err. RA 3.38029 Valid. err. 3.22708
2018-02-03 21:24:01,921 training [INFO ] Epoch  2 Batch  400 Training err. 3.22115 Training err. RA 3.36039 Valid. err. 3.20212
2018-02-03 21:24:02,290 training [INFO ] Epoch  3 Batch  450 Training err. 3.23364 Training err. RA 3.34631 Valid. err. 3.21623
2018-02-03 21:24:02,556 training [INFO ] Epoch  3 Batch  500 Training err. 3.17546 Training err. RA 3.32923 Valid. err. 3.19916
2018-02-03 21:24:02,818 training [INFO ] Epoch  3 Batch  550 Training err. 3.19734 Training err. RA 3.31724 Valid. err. 3.20025
2018-02-03 21:24:03,082 training [INFO ] Epoch  3 Batch  600 Training err. 3.18341 Training err. RA 3.30608 Valid. err. 3.16973
2018-02-03 21:24:03,451 training [INFO ] Epoch  4 Batch  650 Training err. 3.19104 Training err. RA 3.29724 Valid. err. 3.16960
2018-02-03 21:24:03,722 training [INFO ] Epoch  4 Batch  700 Training err. 3.11587 Training err. RA 3.28428 Valid. err. 3.13092
2018-02-03 21:24:03,987 training [INFO ] Epoch  4 Batch  750 Training err. 3.11660 Training err. RA 3.27310 Valid. err. 3.10533
2018-02-03 21:24:04,252 training [INFO ] Epoch  4 Batch  800 Training err. 3.08383 Training err. RA 3.26127 Valid. err. 3.10539
2018-02-03 21:24:04,624 training [INFO ] Epoch  5 Batch  850 Training err. 3.09290 Training err. RA 3.25137 Valid. err. 3.05708
2018-02-03 21:24:04,887 training [INFO ] Epoch  5 Batch  900 Training err. 3.01284 Training err. RA 3.23812 Valid. err. 3.00853
2018-02-03 21:24:05,155 training [INFO ] Epoch  5 Batch  950 Training err. 2.97486 Training err. RA 3.22426 Valid. err. 2.94603
2018-02-03 21:24:05,419 training [INFO ] Epoch  5 Batch 1000 Training err. 2.91668 Training err. RA 3.20888 Valid. err. 2.89707
2018-02-03 21:24:05,792 training [INFO ] Epoch  6 Batch 1050 Training err. 2.95081 Training err. RA 3.19659 Valid. err. 2.87833
2018-02-03 21:24:06,062 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88961 Training err. RA 3.18264 Valid. err. 2.85112
2018-02-03 21:24:06,324 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83982 Training err. RA 3.16773 Valid. err. 2.80937
2018-02-03 21:24:06,590 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81488 Training err. RA 3.15303 Valid. err. 2.79451
2018-02-03 21:24:06,958 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87542 Training err. RA 3.14193 Valid. err. 2.84760
2018-02-03 21:24:07,223 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80802 Training err. RA 3.12908 Valid. err. 2.76413
2018-02-03 21:24:07,490 training [INFO ] Epoch  7 Batch 1350 Training err. 2.74761 Training err. RA 3.11496 Valid. err. 2.73305
2018-02-03 21:24:07,755 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74546 Training err. RA 3.10176 Valid. err. 2.72217
2018-02-03 21:24:08,121 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80934 Training err. RA 3.09168 Valid. err. 2.80859
2018-02-03 21:24:08,383 training [INFO ] Epoch  8 Batch 1500 Training err. 2.75365 Training err. RA 3.08041 Valid. err. 2.70634
2018-02-03 21:24:08,647 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69065 Training err. RA 3.06784 Valid. err. 2.68305
2018-02-03 21:24:08,909 training [INFO ] Epoch  8 Batch 1600 Training err. 2.68488 Training err. RA 3.05587 Valid. err. 2.69275
2018-02-03 21:24:09,276 training [INFO ] Epoch  9 Batch 1650 Training err. 2.75326 Training err. RA 3.04670 Valid. err. 2.64619
2018-02-03 21:24:09,540 training [INFO ] Epoch  9 Batch 1700 Training err. 2.70388 Training err. RA 3.03662 Valid. err. 2.64884
2018-02-03 21:24:09,805 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62870 Training err. RA 3.02496 Valid. err. 2.64648
2018-02-03 21:24:10,075 training [INFO ] Epoch  9 Batch 1800 Training err. 2.64168 Training err. RA 3.01431 Valid. err. 2.63541
2018-02-03 21:24:10,447 training [INFO ] Epoch 10 Batch 1850 Training err. 2.69184 Training err. RA 3.00560 Valid. err. 2.62022
2018-02-03 21:24:10,715 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66928 Training err. RA 2.99675 Valid. err. 2.66894
2018-02-03 21:24:10,985 training [INFO ] Epoch 10 Batch 1950 Training err. 2.57763 Training err. RA 2.98600 Valid. err. 2.57420
2018-02-03 21:24:11,250 training [INFO ] Epoch 10 Batch 2000 Training err. 2.61542 Training err. RA 2.97674 Valid. err. 2.56837
2018-02-03 21:24:11,517 training [INFO ] Epoch 10 Batch 2050 Training err. 2.59956 Training err. RA 2.96754 Valid. err. 2.56084
2018-02-03 21:24:11,617 __main__ [INFO ] End of training
2018-02-03 21:24:11,873 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:24:11,873 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:24:12,123 training [INFO ] Epoch  1 Batch   50 Training err. 4.25089 Training err. RA 4.25089 Valid. err. 4.07388
2018-02-03 21:24:12,357 training [INFO ] Epoch  1 Batch  100 Training err. 3.91735 Training err. RA 4.08412 Valid. err. 3.66513
2018-02-03 21:24:12,579 training [INFO ] Epoch  1 Batch  150 Training err. 3.58519 Training err. RA 3.91781 Valid. err. 3.43050
2018-02-03 21:24:12,821 training [INFO ] Epoch  1 Batch  200 Training err. 3.43288 Training err. RA 3.79658 Valid. err. 3.35624
2018-02-03 21:24:13,043 training [INFO ] Epoch  1 Batch  250 Training err. 3.35662 Training err. RA 3.70859 Valid. err. 3.32507
2018-02-03 21:24:13,270 training [INFO ] Epoch  1 Batch  300 Training err. 3.34314 Training err. RA 3.64768 Valid. err. 3.29843
2018-02-03 21:24:13,614 training [INFO ] Epoch  2 Batch  350 Training err. 3.30636 Training err. RA 3.59892 Valid. err. 3.27696
2018-02-03 21:24:13,838 training [INFO ] Epoch  2 Batch  400 Training err. 3.29690 Training err. RA 3.56117 Valid. err. 3.26078
2018-02-03 21:24:14,061 training [INFO ] Epoch  2 Batch  450 Training err. 3.24770 Training err. RA 3.52634 Valid. err. 3.26687
2018-02-03 21:24:14,286 training [INFO ] Epoch  2 Batch  500 Training err. 3.22835 Training err. RA 3.49654 Valid. err. 3.26708
2018-02-03 21:24:14,510 training [INFO ] Epoch  2 Batch  550 Training err. 3.27238 Training err. RA 3.47616 Valid. err. 3.24858
2018-02-03 21:24:14,736 training [INFO ] Epoch  2 Batch  600 Training err. 3.25082 Training err. RA 3.45738 Valid. err. 3.23533
2018-02-03 21:24:15,081 training [INFO ] Epoch  3 Batch  650 Training err. 3.26233 Training err. RA 3.44238 Valid. err. 3.24370
2018-02-03 21:24:15,300 training [INFO ] Epoch  3 Batch  700 Training err. 3.21580 Training err. RA 3.42619 Valid. err. 3.23970
2018-02-03 21:24:15,553 training [INFO ] Epoch  3 Batch  750 Training err. 3.23215 Training err. RA 3.41326 Valid. err. 3.24591
2018-02-03 21:24:15,805 training [INFO ] Epoch  3 Batch  800 Training err. 3.20004 Training err. RA 3.39993 Valid. err. 3.24128
2018-02-03 21:24:16,056 training [INFO ] Epoch  3 Batch  850 Training err. 3.24595 Training err. RA 3.39087 Valid. err. 3.22805
2018-02-03 21:24:16,309 training [INFO ] Epoch  3 Batch  900 Training err. 3.22280 Training err. RA 3.38154 Valid. err. 3.21908
2018-02-03 21:24:16,676 training [INFO ] Epoch  4 Batch  950 Training err. 3.22606 Training err. RA 3.37335 Valid. err. 3.22369
2018-02-03 21:24:16,928 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19468 Training err. RA 3.36442 Valid. err. 3.22399
2018-02-03 21:24:17,181 training [INFO ] Epoch  4 Batch 1050 Training err. 3.23040 Training err. RA 3.35804 Valid. err. 3.23087
2018-02-03 21:24:17,434 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18838 Training err. RA 3.35033 Valid. err. 3.22223
2018-02-03 21:24:17,689 training [INFO ] Epoch  4 Batch 1150 Training err. 3.22367 Training err. RA 3.34482 Valid. err. 3.21680
2018-02-03 21:24:17,944 training [INFO ] Epoch  4 Batch 1200 Training err. 3.19536 Training err. RA 3.33859 Valid. err. 3.20280
2018-02-03 21:24:18,305 training [INFO ] Epoch  5 Batch 1250 Training err. 3.21777 Training err. RA 3.33376 Valid. err. 3.20317
2018-02-03 21:24:18,552 training [INFO ] Epoch  5 Batch 1300 Training err. 3.18430 Training err. RA 3.32801 Valid. err. 3.19901
2018-02-03 21:24:18,804 training [INFO ] Epoch  5 Batch 1350 Training err. 3.21200 Training err. RA 3.32371 Valid. err. 3.20791
2018-02-03 21:24:19,059 training [INFO ] Epoch  5 Batch 1400 Training err. 3.14681 Training err. RA 3.31740 Valid. err. 3.19795
2018-02-03 21:24:19,311 training [INFO ] Epoch  5 Batch 1450 Training err. 3.20256 Training err. RA 3.31344 Valid. err. 3.18935
2018-02-03 21:24:19,565 training [INFO ] Epoch  5 Batch 1500 Training err. 3.16935 Training err. RA 3.30863 Valid. err. 3.18520
2018-02-03 21:24:19,924 training [INFO ] Epoch  6 Batch 1550 Training err. 3.19318 Training err. RA 3.30491 Valid. err. 3.17755
2018-02-03 21:24:20,176 training [INFO ] Epoch  6 Batch 1600 Training err. 3.17147 Training err. RA 3.30074 Valid. err. 3.16673
2018-02-03 21:24:20,430 training [INFO ] Epoch  6 Batch 1650 Training err. 3.18570 Training err. RA 3.29725 Valid. err. 3.16049
2018-02-03 21:24:20,681 training [INFO ] Epoch  6 Batch 1700 Training err. 3.08802 Training err. RA 3.29110 Valid. err. 3.16645
2018-02-03 21:24:20,933 training [INFO ] Epoch  6 Batch 1750 Training err. 3.17645 Training err. RA 3.28782 Valid. err. 3.14035
2018-02-03 21:24:21,183 training [INFO ] Epoch  6 Batch 1800 Training err. 3.12448 Training err. RA 3.28329 Valid. err. 3.12810
2018-02-03 21:24:21,543 training [INFO ] Epoch  7 Batch 1850 Training err. 3.12511 Training err. RA 3.27901 Valid. err. 3.11594
2018-02-03 21:24:21,795 training [INFO ] Epoch  7 Batch 1900 Training err. 3.14539 Training err. RA 3.27549 Valid. err. 3.13017
2018-02-03 21:24:22,047 training [INFO ] Epoch  7 Batch 1950 Training err. 3.12510 Training err. RA 3.27164 Valid. err. 3.09729
2018-02-03 21:24:22,300 training [INFO ] Epoch  7 Batch 2000 Training err. 3.02967 Training err. RA 3.26559 Valid. err. 3.07700
2018-02-03 21:24:22,552 training [INFO ] Epoch  7 Batch 2050 Training err. 3.10658 Training err. RA 3.26171 Valid. err. 3.06112
2018-02-03 21:24:22,806 training [INFO ] Epoch  7 Batch 2100 Training err. 3.03572 Training err. RA 3.25633 Valid. err. 3.03671
2018-02-03 21:24:23,174 training [INFO ] Epoch  8 Batch 2150 Training err. 3.04055 Training err. RA 3.25131 Valid. err. 3.01571
2018-02-03 21:24:23,424 training [INFO ] Epoch  8 Batch 2200 Training err. 3.07181 Training err. RA 3.24723 Valid. err. 2.99929
2018-02-03 21:24:23,674 training [INFO ] Epoch  8 Batch 2250 Training err. 3.04324 Training err. RA 3.24270 Valid. err. 2.97431
2018-02-03 21:24:23,927 training [INFO ] Epoch  8 Batch 2300 Training err. 2.94324 Training err. RA 3.23619 Valid. err. 2.99403
2018-02-03 21:24:24,180 training [INFO ] Epoch  8 Batch 2350 Training err. 2.96055 Training err. RA 3.23032 Valid. err. 2.94005
2018-02-03 21:24:24,428 training [INFO ] Epoch  8 Batch 2400 Training err. 2.95367 Training err. RA 3.22456 Valid. err. 2.93758
2018-02-03 21:24:24,682 training [INFO ] Epoch  8 Batch 2450 Training err. 2.93826 Training err. RA 3.21872 Valid. err. 2.91751
2018-02-03 21:24:25,042 training [INFO ] Epoch  9 Batch 2500 Training err. 2.97622 Training err. RA 3.21387 Valid. err. 2.93166
2018-02-03 21:24:25,289 training [INFO ] Epoch  9 Batch 2550 Training err. 2.96011 Training err. RA 3.20889 Valid. err. 2.87569
2018-02-03 21:24:25,544 training [INFO ] Epoch  9 Batch 2600 Training err. 2.87883 Training err. RA 3.20255 Valid. err. 2.88209
2018-02-03 21:24:25,810 training [INFO ] Epoch  9 Batch 2650 Training err. 2.82910 Training err. RA 3.19550 Valid. err. 2.86312
2018-02-03 21:24:26,061 training [INFO ] Epoch  9 Batch 2700 Training err. 2.87590 Training err. RA 3.18958 Valid. err. 2.86603
2018-02-03 21:24:26,324 training [INFO ] Epoch  9 Batch 2750 Training err. 2.89185 Training err. RA 3.18417 Valid. err. 2.83468
2018-02-03 21:24:26,694 training [INFO ] Epoch 10 Batch 2800 Training err. 2.91581 Training err. RA 3.17938 Valid. err. 2.84438
2018-02-03 21:24:27,381 training [INFO ] Epoch 10 Batch 2850 Training err. 2.84987 Training err. RA 3.17359 Valid. err. 2.84183
2018-02-03 21:24:27,688 training [INFO ] Epoch 10 Batch 2900 Training err. 2.86559 Training err. RA 3.16828 Valid. err. 2.85923
2018-02-03 21:24:27,955 training [INFO ] Epoch 10 Batch 2950 Training err. 2.77927 Training err. RA 3.16169 Valid. err. 2.81609
2018-02-03 21:24:28,202 training [INFO ] Epoch 10 Batch 3000 Training err. 2.81512 Training err. RA 3.15591 Valid. err. 2.78541
2018-02-03 21:24:28,454 training [INFO ] Epoch 10 Batch 3050 Training err. 2.83377 Training err. RA 3.15063 Valid. err. 2.78474
2018-02-03 21:24:28,630 __main__ [INFO ] End of training
2018-02-03 21:28:40,590 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 21:28:40,592 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 21:28:40,597 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:28:40,597 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:28:40,598 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 117, in <module>
    hyperparams.dump_to_json(os.path.join(out_dir, 'hyperparams.json'), 'w+')
TypeError: dump_to_json() takes 2 positional arguments but 3 were given
2018-02-03 21:28:40,598 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:28:40,599 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:28:40,599 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 117, in <module>
    hyperparams.dump_to_json(os.path.join(out_dir, 'hyperparams.json'), 'w+')
TypeError: dump_to_json() takes 2 positional arguments but 3 were given
2018-02-03 21:28:40,599 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:28:40,600 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:28:40,600 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 117, in <module>
    hyperparams.dump_to_json(os.path.join(out_dir, 'hyperparams.json'), 'w+')
TypeError: dump_to_json() takes 2 positional arguments but 3 were given
2018-02-03 21:28:52,585 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 21:28:52,587 __main__ [INFO ] Removing old results directory /media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiments/test_small/out
2018-02-03 21:28:52,588 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:28:52,588 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:28:54,803 training [INFO ] Epoch  1 Batch   50 Training err. 4.05000 Training err. RA 4.05000 Valid. err. 3.56189
2018-02-03 21:28:55,060 training [INFO ] Epoch  1 Batch  100 Training err. 3.42050 Training err. RA 3.73525 Valid. err. 3.30818
2018-02-03 21:28:55,308 training [INFO ] Epoch  1 Batch  150 Training err. 3.27944 Training err. RA 3.58331 Valid. err. 3.28649
2018-02-03 21:28:55,561 training [INFO ] Epoch  1 Batch  200 Training err. 3.26583 Training err. RA 3.50394 Valid. err. 3.25725
2018-02-03 21:28:55,814 training [INFO ] Epoch  1 Batch  250 Training err. 3.22099 Training err. RA 3.44735 Valid. err. 3.26015
2018-02-03 21:28:56,097 training [INFO ] Epoch  1 Batch  300 Training err. 3.27020 Training err. RA 3.41783 Valid. err. 3.22436
2018-02-03 21:28:56,486 training [INFO ] Epoch  2 Batch  350 Training err. 3.22664 Training err. RA 3.39051 Valid. err. 3.23783
2018-02-03 21:28:56,738 training [INFO ] Epoch  2 Batch  400 Training err. 3.22865 Training err. RA 3.37028 Valid. err. 3.24516
2018-02-03 21:28:56,991 training [INFO ] Epoch  2 Batch  450 Training err. 3.21921 Training err. RA 3.35350 Valid. err. 3.21581
2018-02-03 21:28:57,243 training [INFO ] Epoch  2 Batch  500 Training err. 3.21164 Training err. RA 3.33931 Valid. err. 3.22501
2018-02-03 21:28:57,496 training [INFO ] Epoch  2 Batch  550 Training err. 3.19712 Training err. RA 3.32638 Valid. err. 3.22925
2018-02-03 21:28:57,748 training [INFO ] Epoch  2 Batch  600 Training err. 3.21907 Training err. RA 3.31744 Valid. err. 3.18828
2018-02-03 21:28:58,112 training [INFO ] Epoch  3 Batch  650 Training err. 3.19651 Training err. RA 3.30814 Valid. err. 3.20030
2018-02-03 21:28:58,381 training [INFO ] Epoch  3 Batch  700 Training err. 3.19100 Training err. RA 3.29977 Valid. err. 3.18686
2018-02-03 21:28:58,636 training [INFO ] Epoch  3 Batch  750 Training err. 3.15458 Training err. RA 3.29009 Valid. err. 3.17103
2018-02-03 21:28:58,890 training [INFO ] Epoch  3 Batch  800 Training err. 3.16591 Training err. RA 3.28233 Valid. err. 3.14455
2018-02-03 21:28:59,141 training [INFO ] Epoch  3 Batch  850 Training err. 3.11714 Training err. RA 3.27261 Valid. err. 3.15556
2018-02-03 21:28:59,394 training [INFO ] Epoch  3 Batch  900 Training err. 3.16110 Training err. RA 3.26642 Valid. err. 3.10216
2018-02-03 21:28:59,762 training [INFO ] Epoch  4 Batch  950 Training err. 3.12787 Training err. RA 3.25913 Valid. err. 3.13625
2018-02-03 21:29:00,020 training [INFO ] Epoch  4 Batch 1000 Training err. 3.06962 Training err. RA 3.24965 Valid. err. 3.06798
2018-02-03 21:29:00,279 training [INFO ] Epoch  4 Batch 1050 Training err. 3.02872 Training err. RA 3.23913 Valid. err. 3.04735
2018-02-03 21:29:00,530 training [INFO ] Epoch  4 Batch 1100 Training err. 3.02082 Training err. RA 3.22921 Valid. err. 2.98371
2018-02-03 21:29:00,781 training [INFO ] Epoch  4 Batch 1150 Training err. 2.97566 Training err. RA 3.21818 Valid. err. 2.99852
2018-02-03 21:29:01,038 training [INFO ] Epoch  4 Batch 1200 Training err. 2.97275 Training err. RA 3.20796 Valid. err. 2.91533
2018-02-03 21:29:01,405 training [INFO ] Epoch  5 Batch 1250 Training err. 2.98917 Training err. RA 3.19921 Valid. err. 2.93727
2018-02-03 21:29:01,679 training [INFO ] Epoch  5 Batch 1300 Training err. 2.92408 Training err. RA 3.18862 Valid. err. 2.88066
2018-02-03 21:29:01,939 training [INFO ] Epoch  5 Batch 1350 Training err. 2.82481 Training err. RA 3.17515 Valid. err. 2.84189
2018-02-03 21:29:02,193 training [INFO ] Epoch  5 Batch 1400 Training err. 2.83687 Training err. RA 3.16307 Valid. err. 2.83458
2018-02-03 21:29:02,444 training [INFO ] Epoch  5 Batch 1450 Training err. 2.83853 Training err. RA 3.15188 Valid. err. 2.81844
2018-02-03 21:29:02,694 training [INFO ] Epoch  5 Batch 1500 Training err. 2.80075 Training err. RA 3.14017 Valid. err. 2.76633
2018-02-03 21:29:03,051 training [INFO ] Epoch  6 Batch 1550 Training err. 2.88077 Training err. RA 3.13181 Valid. err. 2.77342
2018-02-03 21:29:03,300 training [INFO ] Epoch  6 Batch 1600 Training err. 2.80900 Training err. RA 3.12172 Valid. err. 2.80776
2018-02-03 21:29:03,548 training [INFO ] Epoch  6 Batch 1650 Training err. 2.73898 Training err. RA 3.11012 Valid. err. 2.73096
2018-02-03 21:29:03,792 training [INFO ] Epoch  6 Batch 1700 Training err. 2.70814 Training err. RA 3.09830 Valid. err. 2.75228
2018-02-03 21:29:04,023 training [INFO ] Epoch  6 Batch 1750 Training err. 2.77901 Training err. RA 3.08917 Valid. err. 2.72487
2018-02-03 21:29:04,249 training [INFO ] Epoch  6 Batch 1800 Training err. 2.68449 Training err. RA 3.07793 Valid. err. 2.68511
2018-02-03 21:29:04,593 training [INFO ] Epoch  7 Batch 1850 Training err. 2.78550 Training err. RA 3.07003 Valid. err. 2.69777
2018-02-03 21:29:04,820 training [INFO ] Epoch  7 Batch 1900 Training err. 2.75006 Training err. RA 3.06161 Valid. err. 2.66556
2018-02-03 21:29:05,053 training [INFO ] Epoch  7 Batch 1950 Training err. 2.64177 Training err. RA 3.05084 Valid. err. 2.63759
2018-02-03 21:29:05,280 training [INFO ] Epoch  7 Batch 2000 Training err. 2.61448 Training err. RA 3.03993 Valid. err. 2.62152
2018-02-03 21:29:05,509 training [INFO ] Epoch  7 Batch 2050 Training err. 2.71436 Training err. RA 3.03199 Valid. err. 2.61149
2018-02-03 21:29:05,738 training [INFO ] Epoch  7 Batch 2100 Training err. 2.58393 Training err. RA 3.02133 Valid. err. 2.58236
2018-02-03 21:29:06,079 training [INFO ] Epoch  8 Batch 2150 Training err. 2.65825 Training err. RA 3.01288 Valid. err. 2.57475
2018-02-03 21:29:06,308 training [INFO ] Epoch  8 Batch 2200 Training err. 2.71891 Training err. RA 3.00620 Valid. err. 2.57641
2018-02-03 21:29:06,535 training [INFO ] Epoch  8 Batch 2250 Training err. 2.59095 Training err. RA 2.99697 Valid. err. 2.57781
2018-02-03 21:29:06,781 training [INFO ] Epoch  8 Batch 2300 Training err. 2.56387 Training err. RA 2.98756 Valid. err. 2.56449
2018-02-03 21:29:07,029 training [INFO ] Epoch  8 Batch 2350 Training err. 2.62057 Training err. RA 2.97975 Valid. err. 2.57002
2018-02-03 21:29:07,279 training [INFO ] Epoch  8 Batch 2400 Training err. 2.50697 Training err. RA 2.96990 Valid. err. 2.51879
2018-02-03 21:29:07,530 training [INFO ] Epoch  8 Batch 2450 Training err. 2.59386 Training err. RA 2.96223 Valid. err. 2.53810
2018-02-03 21:29:07,890 training [INFO ] Epoch  9 Batch 2500 Training err. 2.62533 Training err. RA 2.95549 Valid. err. 2.55813
2018-02-03 21:29:08,140 training [INFO ] Epoch  9 Batch 2550 Training err. 2.59718 Training err. RA 2.94846 Valid. err. 2.50697
2018-02-03 21:29:08,391 training [INFO ] Epoch  9 Batch 2600 Training err. 2.51079 Training err. RA 2.94005 Valid. err. 2.48562
2018-02-03 21:29:08,644 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56975 Training err. RA 2.93306 Valid. err. 2.53081
2018-02-03 21:29:08,898 training [INFO ] Epoch  9 Batch 2700 Training err. 2.45265 Training err. RA 2.92416 Valid. err. 2.52313
2018-02-03 21:29:09,149 training [INFO ] Epoch  9 Batch 2750 Training err. 2.51568 Training err. RA 2.91673 Valid. err. 2.46410
2018-02-03 21:29:09,507 training [INFO ] Epoch 10 Batch 2800 Training err. 2.55994 Training err. RA 2.91036 Valid. err. 2.51199
2018-02-03 21:29:09,757 training [INFO ] Epoch 10 Batch 2850 Training err. 2.57282 Training err. RA 2.90444 Valid. err. 2.46622
2018-02-03 21:29:10,008 training [INFO ] Epoch 10 Batch 2900 Training err. 2.45955 Training err. RA 2.89677 Valid. err. 2.44002
2018-02-03 21:29:10,257 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51416 Training err. RA 2.89029 Valid. err. 2.47389
2018-02-03 21:29:10,515 training [INFO ] Epoch 10 Batch 3000 Training err. 2.42949 Training err. RA 2.88261 Valid. err. 2.42083
2018-02-03 21:29:10,774 training [INFO ] Epoch 10 Batch 3050 Training err. 2.46132 Training err. RA 2.87570 Valid. err. 2.42477
2018-02-03 21:29:10,950 __main__ [INFO ] End of training
2018-02-03 21:29:11,250 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:29:11,250 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:29:11,541 training [INFO ] Epoch  1 Batch   50 Training err. 4.04214 Training err. RA 4.04214 Valid. err. 3.54833
2018-02-03 21:29:11,806 training [INFO ] Epoch  1 Batch  100 Training err. 3.39814 Training err. RA 3.72014 Valid. err. 3.31442
2018-02-03 21:29:12,070 training [INFO ] Epoch  1 Batch  150 Training err. 3.27816 Training err. RA 3.57281 Valid. err. 3.25355
2018-02-03 21:29:12,347 training [INFO ] Epoch  1 Batch  200 Training err. 3.25863 Training err. RA 3.49427 Valid. err. 3.23396
2018-02-03 21:29:12,716 training [INFO ] Epoch  2 Batch  250 Training err. 3.25330 Training err. RA 3.44608 Valid. err. 3.25586
2018-02-03 21:29:12,982 training [INFO ] Epoch  2 Batch  300 Training err. 3.21729 Training err. RA 3.40794 Valid. err. 3.22208
2018-02-03 21:29:13,244 training [INFO ] Epoch  2 Batch  350 Training err. 3.21434 Training err. RA 3.38029 Valid. err. 3.22708
2018-02-03 21:29:13,510 training [INFO ] Epoch  2 Batch  400 Training err. 3.22115 Training err. RA 3.36039 Valid. err. 3.20212
2018-02-03 21:29:13,878 training [INFO ] Epoch  3 Batch  450 Training err. 3.23364 Training err. RA 3.34631 Valid. err. 3.21623
2018-02-03 21:29:14,144 training [INFO ] Epoch  3 Batch  500 Training err. 3.17546 Training err. RA 3.32923 Valid. err. 3.19916
2018-02-03 21:29:14,412 training [INFO ] Epoch  3 Batch  550 Training err. 3.19734 Training err. RA 3.31724 Valid. err. 3.20025
2018-02-03 21:29:14,676 training [INFO ] Epoch  3 Batch  600 Training err. 3.18341 Training err. RA 3.30608 Valid. err. 3.16973
2018-02-03 21:29:15,045 training [INFO ] Epoch  4 Batch  650 Training err. 3.19104 Training err. RA 3.29724 Valid. err. 3.16960
2018-02-03 21:29:15,308 training [INFO ] Epoch  4 Batch  700 Training err. 3.11587 Training err. RA 3.28428 Valid. err. 3.13092
2018-02-03 21:29:15,576 training [INFO ] Epoch  4 Batch  750 Training err. 3.11660 Training err. RA 3.27310 Valid. err. 3.10533
2018-02-03 21:29:15,839 training [INFO ] Epoch  4 Batch  800 Training err. 3.08383 Training err. RA 3.26127 Valid. err. 3.10539
2018-02-03 21:29:16,215 training [INFO ] Epoch  5 Batch  850 Training err. 3.09290 Training err. RA 3.25137 Valid. err. 3.05708
2018-02-03 21:29:16,478 training [INFO ] Epoch  5 Batch  900 Training err. 3.01284 Training err. RA 3.23812 Valid. err. 3.00853
2018-02-03 21:29:16,744 training [INFO ] Epoch  5 Batch  950 Training err. 2.97486 Training err. RA 3.22426 Valid. err. 2.94603
2018-02-03 21:29:17,010 training [INFO ] Epoch  5 Batch 1000 Training err. 2.91668 Training err. RA 3.20888 Valid. err. 2.89707
2018-02-03 21:29:17,379 training [INFO ] Epoch  6 Batch 1050 Training err. 2.95081 Training err. RA 3.19659 Valid. err. 2.87833
2018-02-03 21:29:17,643 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88961 Training err. RA 3.18264 Valid. err. 2.85112
2018-02-03 21:29:17,910 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83982 Training err. RA 3.16773 Valid. err. 2.80937
2018-02-03 21:29:18,172 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81488 Training err. RA 3.15303 Valid. err. 2.79451
2018-02-03 21:29:18,537 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87542 Training err. RA 3.14193 Valid. err. 2.84760
2018-02-03 21:29:18,814 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80802 Training err. RA 3.12908 Valid. err. 2.76413
2018-02-03 21:29:19,083 training [INFO ] Epoch  7 Batch 1350 Training err. 2.74761 Training err. RA 3.11496 Valid. err. 2.73305
2018-02-03 21:29:19,745 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74546 Training err. RA 3.10176 Valid. err. 2.72217
2018-02-03 21:29:20,120 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80934 Training err. RA 3.09168 Valid. err. 2.80859
2018-02-03 21:29:20,379 training [INFO ] Epoch  8 Batch 1500 Training err. 2.75365 Training err. RA 3.08041 Valid. err. 2.70634
2018-02-03 21:29:20,666 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69065 Training err. RA 3.06784 Valid. err. 2.68305
2018-02-03 21:29:20,968 training [INFO ] Epoch  8 Batch 1600 Training err. 2.68488 Training err. RA 3.05587 Valid. err. 2.69275
2018-02-03 21:29:21,387 training [INFO ] Epoch  9 Batch 1650 Training err. 2.75326 Training err. RA 3.04670 Valid. err. 2.64619
2018-02-03 21:29:21,647 training [INFO ] Epoch  9 Batch 1700 Training err. 2.70388 Training err. RA 3.03662 Valid. err. 2.64884
2018-02-03 21:29:21,931 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62870 Training err. RA 3.02496 Valid. err. 2.64648
2018-02-03 21:29:22,236 training [INFO ] Epoch  9 Batch 1800 Training err. 2.64168 Training err. RA 3.01431 Valid. err. 2.63541
2018-02-03 21:29:22,624 training [INFO ] Epoch 10 Batch 1850 Training err. 2.69184 Training err. RA 3.00560 Valid. err. 2.62022
2018-02-03 21:29:22,892 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66928 Training err. RA 2.99675 Valid. err. 2.66894
2018-02-03 21:29:23,156 training [INFO ] Epoch 10 Batch 1950 Training err. 2.57763 Training err. RA 2.98600 Valid. err. 2.57420
2018-02-03 21:29:23,538 training [INFO ] Epoch 10 Batch 2000 Training err. 2.61542 Training err. RA 2.97674 Valid. err. 2.56837
2018-02-03 21:29:23,867 training [INFO ] Epoch 10 Batch 2050 Training err. 2.59956 Training err. RA 2.96754 Valid. err. 2.56084
2018-02-03 21:29:23,975 __main__ [INFO ] End of training
2018-02-03 21:29:24,221 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:29:24,221 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:29:24,487 training [INFO ] Epoch  1 Batch   50 Training err. 4.25089 Training err. RA 4.25089 Valid. err. 4.07388
2018-02-03 21:29:24,734 training [INFO ] Epoch  1 Batch  100 Training err. 3.91735 Training err. RA 4.08412 Valid. err. 3.66513
2018-02-03 21:29:25,024 training [INFO ] Epoch  1 Batch  150 Training err. 3.58519 Training err. RA 3.91781 Valid. err. 3.43050
2018-02-03 21:29:25,329 training [INFO ] Epoch  1 Batch  200 Training err. 3.43288 Training err. RA 3.79658 Valid. err. 3.35624
2018-02-03 21:29:25,571 training [INFO ] Epoch  1 Batch  250 Training err. 3.35662 Training err. RA 3.70859 Valid. err. 3.32507
2018-02-03 21:29:25,860 training [INFO ] Epoch  1 Batch  300 Training err. 3.34314 Training err. RA 3.64768 Valid. err. 3.29843
2018-02-03 21:29:26,286 training [INFO ] Epoch  2 Batch  350 Training err. 3.30636 Training err. RA 3.59892 Valid. err. 3.27696
2018-02-03 21:29:26,532 training [INFO ] Epoch  2 Batch  400 Training err. 3.29690 Training err. RA 3.56117 Valid. err. 3.26078
2018-02-03 21:29:26,754 training [INFO ] Epoch  2 Batch  450 Training err. 3.24770 Training err. RA 3.52634 Valid. err. 3.26687
2018-02-03 21:29:27,010 training [INFO ] Epoch  2 Batch  500 Training err. 3.22835 Training err. RA 3.49654 Valid. err. 3.26708
2018-02-03 21:29:27,254 training [INFO ] Epoch  2 Batch  550 Training err. 3.27238 Training err. RA 3.47616 Valid. err. 3.24858
2018-02-03 21:29:27,501 training [INFO ] Epoch  2 Batch  600 Training err. 3.25082 Training err. RA 3.45738 Valid. err. 3.23533
2018-02-03 21:29:27,857 training [INFO ] Epoch  3 Batch  650 Training err. 3.26233 Training err. RA 3.44238 Valid. err. 3.24370
2018-02-03 21:29:28,103 training [INFO ] Epoch  3 Batch  700 Training err. 3.21580 Training err. RA 3.42619 Valid. err. 3.23970
2018-02-03 21:29:28,350 training [INFO ] Epoch  3 Batch  750 Training err. 3.23215 Training err. RA 3.41326 Valid. err. 3.24591
2018-02-03 21:29:28,592 training [INFO ] Epoch  3 Batch  800 Training err. 3.20004 Training err. RA 3.39993 Valid. err. 3.24128
2018-02-03 21:29:28,837 training [INFO ] Epoch  3 Batch  850 Training err. 3.24595 Training err. RA 3.39087 Valid. err. 3.22805
2018-02-03 21:29:29,085 training [INFO ] Epoch  3 Batch  900 Training err. 3.22280 Training err. RA 3.38154 Valid. err. 3.21908
2018-02-03 21:29:29,448 training [INFO ] Epoch  4 Batch  950 Training err. 3.22606 Training err. RA 3.37335 Valid. err. 3.22369
2018-02-03 21:29:29,696 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19468 Training err. RA 3.36442 Valid. err. 3.22399
2018-02-03 21:29:29,995 training [INFO ] Epoch  4 Batch 1050 Training err. 3.23040 Training err. RA 3.35804 Valid. err. 3.23087
2018-02-03 21:29:30,361 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18838 Training err. RA 3.35033 Valid. err. 3.22223
2018-02-03 21:29:30,688 training [INFO ] Epoch  4 Batch 1150 Training err. 3.22367 Training err. RA 3.34482 Valid. err. 3.21680
2018-02-03 21:29:30,962 training [INFO ] Epoch  4 Batch 1200 Training err. 3.19536 Training err. RA 3.33859 Valid. err. 3.20280
2018-02-03 21:29:31,315 training [INFO ] Epoch  5 Batch 1250 Training err. 3.21777 Training err. RA 3.33376 Valid. err. 3.20317
2018-02-03 21:29:31,571 training [INFO ] Epoch  5 Batch 1300 Training err. 3.18430 Training err. RA 3.32801 Valid. err. 3.19901
2018-02-03 21:29:31,841 training [INFO ] Epoch  5 Batch 1350 Training err. 3.21200 Training err. RA 3.32371 Valid. err. 3.20791
2018-02-03 21:29:32,091 training [INFO ] Epoch  5 Batch 1400 Training err. 3.14681 Training err. RA 3.31740 Valid. err. 3.19795
2018-02-03 21:29:32,327 training [INFO ] Epoch  5 Batch 1450 Training err. 3.20256 Training err. RA 3.31344 Valid. err. 3.18935
2018-02-03 21:29:32,547 training [INFO ] Epoch  5 Batch 1500 Training err. 3.16935 Training err. RA 3.30863 Valid. err. 3.18520
2018-02-03 21:29:32,911 training [INFO ] Epoch  6 Batch 1550 Training err. 3.19318 Training err. RA 3.30491 Valid. err. 3.17755
2018-02-03 21:29:33,160 training [INFO ] Epoch  6 Batch 1600 Training err. 3.17147 Training err. RA 3.30074 Valid. err. 3.16673
2018-02-03 21:29:33,410 training [INFO ] Epoch  6 Batch 1650 Training err. 3.18570 Training err. RA 3.29725 Valid. err. 3.16049
2018-02-03 21:29:33,662 training [INFO ] Epoch  6 Batch 1700 Training err. 3.08802 Training err. RA 3.29110 Valid. err. 3.16645
2018-02-03 21:29:33,906 training [INFO ] Epoch  6 Batch 1750 Training err. 3.17645 Training err. RA 3.28782 Valid. err. 3.14035
2018-02-03 21:29:34,153 training [INFO ] Epoch  6 Batch 1800 Training err. 3.12448 Training err. RA 3.28329 Valid. err. 3.12810
2018-02-03 21:29:34,509 training [INFO ] Epoch  7 Batch 1850 Training err. 3.12511 Training err. RA 3.27901 Valid. err. 3.11594
2018-02-03 21:29:34,737 training [INFO ] Epoch  7 Batch 1900 Training err. 3.14539 Training err. RA 3.27549 Valid. err. 3.13017
2018-02-03 21:29:34,961 training [INFO ] Epoch  7 Batch 1950 Training err. 3.12510 Training err. RA 3.27164 Valid. err. 3.09729
2018-02-03 21:29:35,183 training [INFO ] Epoch  7 Batch 2000 Training err. 3.02967 Training err. RA 3.26559 Valid. err. 3.07700
2018-02-03 21:29:35,401 training [INFO ] Epoch  7 Batch 2050 Training err. 3.10658 Training err. RA 3.26171 Valid. err. 3.06112
2018-02-03 21:29:35,622 training [INFO ] Epoch  7 Batch 2100 Training err. 3.03572 Training err. RA 3.25633 Valid. err. 3.03671
2018-02-03 21:29:35,952 training [INFO ] Epoch  8 Batch 2150 Training err. 3.04055 Training err. RA 3.25131 Valid. err. 3.01571
2018-02-03 21:29:36,175 training [INFO ] Epoch  8 Batch 2200 Training err. 3.07181 Training err. RA 3.24723 Valid. err. 2.99929
2018-02-03 21:29:36,395 training [INFO ] Epoch  8 Batch 2250 Training err. 3.04324 Training err. RA 3.24270 Valid. err. 2.97431
2018-02-03 21:29:36,620 training [INFO ] Epoch  8 Batch 2300 Training err. 2.94324 Training err. RA 3.23619 Valid. err. 2.99403
2018-02-03 21:29:36,841 training [INFO ] Epoch  8 Batch 2350 Training err. 2.96055 Training err. RA 3.23032 Valid. err. 2.94005
2018-02-03 21:29:37,110 training [INFO ] Epoch  8 Batch 2400 Training err. 2.95367 Training err. RA 3.22456 Valid. err. 2.93758
2018-02-03 21:29:37,375 training [INFO ] Epoch  8 Batch 2450 Training err. 2.93826 Training err. RA 3.21872 Valid. err. 2.91751
2018-02-03 21:29:37,737 training [INFO ] Epoch  9 Batch 2500 Training err. 2.97622 Training err. RA 3.21387 Valid. err. 2.93166
2018-02-03 21:29:37,981 training [INFO ] Epoch  9 Batch 2550 Training err. 2.96011 Training err. RA 3.20889 Valid. err. 2.87569
2018-02-03 21:29:38,233 training [INFO ] Epoch  9 Batch 2600 Training err. 2.87883 Training err. RA 3.20255 Valid. err. 2.88209
2018-02-03 21:29:38,482 training [INFO ] Epoch  9 Batch 2650 Training err. 2.82910 Training err. RA 3.19550 Valid. err. 2.86312
2018-02-03 21:29:38,731 training [INFO ] Epoch  9 Batch 2700 Training err. 2.87590 Training err. RA 3.18958 Valid. err. 2.86603
2018-02-03 21:29:38,982 training [INFO ] Epoch  9 Batch 2750 Training err. 2.89185 Training err. RA 3.18417 Valid. err. 2.83468
2018-02-03 21:29:39,347 training [INFO ] Epoch 10 Batch 2800 Training err. 2.91581 Training err. RA 3.17938 Valid. err. 2.84438
2018-02-03 21:29:39,594 training [INFO ] Epoch 10 Batch 2850 Training err. 2.84987 Training err. RA 3.17359 Valid. err. 2.84183
2018-02-03 21:29:39,839 training [INFO ] Epoch 10 Batch 2900 Training err. 2.86559 Training err. RA 3.16828 Valid. err. 2.85923
2018-02-03 21:29:40,090 training [INFO ] Epoch 10 Batch 2950 Training err. 2.77927 Training err. RA 3.16169 Valid. err. 2.81609
2018-02-03 21:29:40,335 training [INFO ] Epoch 10 Batch 3000 Training err. 2.81512 Training err. RA 3.15591 Valid. err. 2.78541
2018-02-03 21:29:40,580 training [INFO ] Epoch 10 Batch 3050 Training err. 2.83377 Training err. RA 3.15063 Valid. err. 2.78474
2018-02-03 21:29:40,742 __main__ [INFO ] End of training
2018-02-03 21:31:23,585 __main__ [INFO ] 
==============================
Starting experiment alice_test
==============================
2018-02-03 21:31:23,588 __main__ [INFO ] Removing old results directory ./experiments/alice_test/out
2018-02-03 21:31:23,590 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:31:23,590 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 21:31:37,368 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-03 21:31:37,370 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-03 21:31:37,376 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:31:37,376 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:31:39,598 training [INFO ] Epoch  1 Batch   50 Training err. 4.05564 Training err. RA 4.05564 Valid. err. 3.56279
2018-02-03 21:31:39,848 training [INFO ] Epoch  1 Batch  100 Training err. 3.42185 Training err. RA 3.73874 Valid. err. 3.30558
2018-02-03 21:31:40,098 training [INFO ] Epoch  1 Batch  150 Training err. 3.28235 Training err. RA 3.58661 Valid. err. 3.28468
2018-02-03 21:31:40,352 training [INFO ] Epoch  1 Batch  200 Training err. 3.26621 Training err. RA 3.50651 Valid. err. 3.25518
2018-02-03 21:31:40,602 training [INFO ] Epoch  1 Batch  250 Training err. 3.22003 Training err. RA 3.44922 Valid. err. 3.25711
2018-02-03 21:31:40,855 training [INFO ] Epoch  1 Batch  300 Training err. 3.27002 Training err. RA 3.41935 Valid. err. 3.22044
2018-02-03 21:31:41,226 training [INFO ] Epoch  2 Batch  350 Training err. 3.22405 Training err. RA 3.39145 Valid. err. 3.23302
2018-02-03 21:31:41,483 training [INFO ] Epoch  2 Batch  400 Training err. 3.22557 Training err. RA 3.37072 Valid. err. 3.23962
2018-02-03 21:31:41,743 training [INFO ] Epoch  2 Batch  450 Training err. 3.21323 Training err. RA 3.35322 Valid. err. 3.20651
2018-02-03 21:31:41,999 training [INFO ] Epoch  2 Batch  500 Training err. 3.20234 Training err. RA 3.33813 Valid. err. 3.21120
2018-02-03 21:31:42,253 training [INFO ] Epoch  2 Batch  550 Training err. 3.18223 Training err. RA 3.32396 Valid. err. 3.21701
2018-02-03 21:31:42,508 training [INFO ] Epoch  2 Batch  600 Training err. 3.20040 Training err. RA 3.31366 Valid. err. 3.16536
2018-02-03 21:31:42,871 training [INFO ] Epoch  3 Batch  650 Training err. 3.17101 Training err. RA 3.30269 Valid. err. 3.15641
2018-02-03 21:31:43,142 training [INFO ] Epoch  3 Batch  700 Training err. 3.15918 Training err. RA 3.29244 Valid. err. 3.13861
2018-02-03 21:31:43,400 training [INFO ] Epoch  3 Batch  750 Training err. 3.09888 Training err. RA 3.27953 Valid. err. 3.10423
2018-02-03 21:31:43,651 training [INFO ] Epoch  3 Batch  800 Training err. 3.10362 Training err. RA 3.26854 Valid. err. 3.07094
2018-02-03 21:31:43,911 training [INFO ] Epoch  3 Batch  850 Training err. 3.03295 Training err. RA 3.25468 Valid. err. 3.09428
2018-02-03 21:31:44,158 training [INFO ] Epoch  3 Batch  900 Training err. 3.07254 Training err. RA 3.24456 Valid. err. 2.98534
2018-02-03 21:31:44,527 training [INFO ] Epoch  4 Batch  950 Training err. 3.04103 Training err. RA 3.23385 Valid. err. 3.02577
2018-02-03 21:31:44,783 training [INFO ] Epoch  4 Batch 1000 Training err. 2.96387 Training err. RA 3.22035 Valid. err. 2.94764
2018-02-03 21:31:45,036 training [INFO ] Epoch  4 Batch 1050 Training err. 2.89043 Training err. RA 3.20464 Valid. err. 2.91516
2018-02-03 21:31:45,290 training [INFO ] Epoch  4 Batch 1100 Training err. 2.90409 Training err. RA 3.19098 Valid. err. 2.85796
2018-02-03 21:31:45,541 training [INFO ] Epoch  4 Batch 1150 Training err. 2.86535 Training err. RA 3.17682 Valid. err. 2.87805
2018-02-03 21:31:45,795 training [INFO ] Epoch  4 Batch 1200 Training err. 2.87094 Training err. RA 3.16408 Valid. err. 2.81163
2018-02-03 21:31:46,164 training [INFO ] Epoch  5 Batch 1250 Training err. 2.91260 Training err. RA 3.15402 Valid. err. 2.84526
2018-02-03 21:31:46,428 training [INFO ] Epoch  5 Batch 1300 Training err. 2.85643 Training err. RA 3.14257 Valid. err. 2.82204
2018-02-03 21:31:46,678 training [INFO ] Epoch  5 Batch 1350 Training err. 2.75690 Training err. RA 3.12829 Valid. err. 2.78780
2018-02-03 21:31:46,941 training [INFO ] Epoch  5 Batch 1400 Training err. 2.78929 Training err. RA 3.11618 Valid. err. 2.77208
2018-02-03 21:31:47,197 training [INFO ] Epoch  5 Batch 1450 Training err. 2.79331 Training err. RA 3.10505 Valid. err. 2.76631
2018-02-03 21:31:47,457 training [INFO ] Epoch  5 Batch 1500 Training err. 2.75964 Training err. RA 3.09353 Valid. err. 2.72868
2018-02-03 21:31:47,818 training [INFO ] Epoch  6 Batch 1550 Training err. 2.84130 Training err. RA 3.08540 Valid. err. 2.73883
2018-02-03 21:31:48,073 training [INFO ] Epoch  6 Batch 1600 Training err. 2.78230 Training err. RA 3.07592 Valid. err. 2.76134
2018-02-03 21:31:48,324 training [INFO ] Epoch  6 Batch 1650 Training err. 2.70426 Training err. RA 3.06466 Valid. err. 2.70370
2018-02-03 21:31:48,575 training [INFO ] Epoch  6 Batch 1700 Training err. 2.67980 Training err. RA 3.05334 Valid. err. 2.72407
2018-02-03 21:31:48,829 training [INFO ] Epoch  6 Batch 1750 Training err. 2.75362 Training err. RA 3.04478 Valid. err. 2.69459
2018-02-03 21:31:49,081 training [INFO ] Epoch  6 Batch 1800 Training err. 2.66490 Training err. RA 3.03423 Valid. err. 2.66435
2018-02-03 21:31:49,451 training [INFO ] Epoch  7 Batch 1850 Training err. 2.76321 Training err. RA 3.02690 Valid. err. 2.67073
2018-02-03 21:31:49,707 training [INFO ] Epoch  7 Batch 1900 Training err. 2.73817 Training err. RA 3.01930 Valid. err. 2.64120
2018-02-03 21:31:49,980 training [INFO ] Epoch  7 Batch 1950 Training err. 2.62623 Training err. RA 3.00923 Valid. err. 2.62391
2018-02-03 21:31:50,247 training [INFO ] Epoch  7 Batch 2000 Training err. 2.60183 Training err. RA 2.99904 Valid. err. 2.61274
2018-02-03 21:31:50,524 training [INFO ] Epoch  7 Batch 2050 Training err. 2.70195 Training err. RA 2.99179 Valid. err. 2.59214
2018-02-03 21:31:50,787 training [INFO ] Epoch  7 Batch 2100 Training err. 2.58617 Training err. RA 2.98214 Valid. err. 2.57744
2018-02-03 21:31:51,143 training [INFO ] Epoch  8 Batch 2150 Training err. 2.65587 Training err. RA 2.97455 Valid. err. 2.56368
2018-02-03 21:31:51,377 training [INFO ] Epoch  8 Batch 2200 Training err. 2.72208 Training err. RA 2.96881 Valid. err. 2.56588
2018-02-03 21:31:51,614 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58636 Training err. RA 2.96031 Valid. err. 2.56354
2018-02-03 21:31:51,848 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55916 Training err. RA 2.95159 Valid. err. 2.56297
2018-02-03 21:31:52,083 training [INFO ] Epoch  8 Batch 2350 Training err. 2.61683 Training err. RA 2.94447 Valid. err. 2.57064
2018-02-03 21:31:52,320 training [INFO ] Epoch  8 Batch 2400 Training err. 2.52191 Training err. RA 2.93567 Valid. err. 2.52353
2018-02-03 21:31:52,552 training [INFO ] Epoch  8 Batch 2450 Training err. 2.60607 Training err. RA 2.92894 Valid. err. 2.54005
2018-02-03 21:31:52,914 training [INFO ] Epoch  9 Batch 2500 Training err. 2.63665 Training err. RA 2.92309 Valid. err. 2.56247
2018-02-03 21:31:53,165 training [INFO ] Epoch  9 Batch 2550 Training err. 2.59826 Training err. RA 2.91672 Valid. err. 2.51595
2018-02-03 21:31:53,416 training [INFO ] Epoch  9 Batch 2600 Training err. 2.51052 Training err. RA 2.90891 Valid. err. 2.49033
2018-02-03 21:31:53,672 training [INFO ] Epoch  9 Batch 2650 Training err. 2.57251 Training err. RA 2.90257 Valid. err. 2.51264
2018-02-03 21:31:53,927 training [INFO ] Epoch  9 Batch 2700 Training err. 2.47471 Training err. RA 2.89464 Valid. err. 2.52154
2018-02-03 21:31:54,177 training [INFO ] Epoch  9 Batch 2750 Training err. 2.53351 Training err. RA 2.88808 Valid. err. 2.46151
2018-02-03 21:31:54,544 training [INFO ] Epoch 10 Batch 2800 Training err. 2.57434 Training err. RA 2.88247 Valid. err. 2.49400
2018-02-03 21:31:54,795 training [INFO ] Epoch 10 Batch 2850 Training err. 2.58366 Training err. RA 2.87723 Valid. err. 2.48207
2018-02-03 21:31:55,054 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46346 Training err. RA 2.87010 Valid. err. 2.44738
2018-02-03 21:31:55,309 training [INFO ] Epoch 10 Batch 2950 Training err. 2.52152 Training err. RA 2.86419 Valid. err. 2.48032
2018-02-03 21:31:55,559 training [INFO ] Epoch 10 Batch 3000 Training err. 2.45057 Training err. RA 2.85730 Valid. err. 2.42290
2018-02-03 21:31:55,812 training [INFO ] Epoch 10 Batch 3050 Training err. 2.47810 Training err. RA 2.85108 Valid. err. 2.42218
2018-02-03 21:31:55,978 __main__ [INFO ] End of training
2018-02-03 21:31:56,292 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:31:56,292 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:31:56,580 training [INFO ] Epoch  1 Batch   50 Training err. 4.04214 Training err. RA 4.04214 Valid. err. 3.54833
2018-02-03 21:31:56,839 training [INFO ] Epoch  1 Batch  100 Training err. 3.39814 Training err. RA 3.72014 Valid. err. 3.31442
2018-02-03 21:31:57,091 training [INFO ] Epoch  1 Batch  150 Training err. 3.27816 Training err. RA 3.57281 Valid. err. 3.25355
2018-02-03 21:31:57,333 training [INFO ] Epoch  1 Batch  200 Training err. 3.25863 Training err. RA 3.49427 Valid. err. 3.23396
2018-02-03 21:31:57,689 training [INFO ] Epoch  2 Batch  250 Training err. 3.25330 Training err. RA 3.44608 Valid. err. 3.25586
2018-02-03 21:31:57,937 training [INFO ] Epoch  2 Batch  300 Training err. 3.21729 Training err. RA 3.40794 Valid. err. 3.22208
2018-02-03 21:31:58,187 training [INFO ] Epoch  2 Batch  350 Training err. 3.21434 Training err. RA 3.38029 Valid. err. 3.22708
2018-02-03 21:31:58,439 training [INFO ] Epoch  2 Batch  400 Training err. 3.22115 Training err. RA 3.36039 Valid. err. 3.20212
2018-02-03 21:31:58,791 training [INFO ] Epoch  3 Batch  450 Training err. 3.23364 Training err. RA 3.34631 Valid. err. 3.21623
2018-02-03 21:31:59,038 training [INFO ] Epoch  3 Batch  500 Training err. 3.17546 Training err. RA 3.32923 Valid. err. 3.19916
2018-02-03 21:31:59,298 training [INFO ] Epoch  3 Batch  550 Training err. 3.19734 Training err. RA 3.31724 Valid. err. 3.20025
2018-02-03 21:31:59,566 training [INFO ] Epoch  3 Batch  600 Training err. 3.18341 Training err. RA 3.30608 Valid. err. 3.16973
2018-02-03 21:31:59,940 training [INFO ] Epoch  4 Batch  650 Training err. 3.19104 Training err. RA 3.29724 Valid. err. 3.16960
2018-02-03 21:32:00,192 training [INFO ] Epoch  4 Batch  700 Training err. 3.11587 Training err. RA 3.28428 Valid. err. 3.13092
2018-02-03 21:32:00,440 training [INFO ] Epoch  4 Batch  750 Training err. 3.11660 Training err. RA 3.27310 Valid. err. 3.10533
2018-02-03 21:32:00,685 training [INFO ] Epoch  4 Batch  800 Training err. 3.08383 Training err. RA 3.26127 Valid. err. 3.10539
2018-02-03 21:32:01,038 training [INFO ] Epoch  5 Batch  850 Training err. 3.09290 Training err. RA 3.25137 Valid. err. 3.05708
2018-02-03 21:32:01,286 training [INFO ] Epoch  5 Batch  900 Training err. 3.01284 Training err. RA 3.23812 Valid. err. 3.00853
2018-02-03 21:32:01,544 training [INFO ] Epoch  5 Batch  950 Training err. 2.97486 Training err. RA 3.22426 Valid. err. 2.94603
2018-02-03 21:32:01,805 training [INFO ] Epoch  5 Batch 1000 Training err. 2.91668 Training err. RA 3.20888 Valid. err. 2.89707
2018-02-03 21:32:02,174 training [INFO ] Epoch  6 Batch 1050 Training err. 2.95081 Training err. RA 3.19659 Valid. err. 2.87833
2018-02-03 21:32:02,432 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88961 Training err. RA 3.18264 Valid. err. 2.85112
2018-02-03 21:32:02,682 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83982 Training err. RA 3.16773 Valid. err. 2.80937
2018-02-03 21:32:02,931 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81488 Training err. RA 3.15303 Valid. err. 2.79451
2018-02-03 21:32:03,282 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87542 Training err. RA 3.14193 Valid. err. 2.84760
2018-02-03 21:32:03,530 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80802 Training err. RA 3.12908 Valid. err. 2.76413
2018-02-03 21:32:03,778 training [INFO ] Epoch  7 Batch 1350 Training err. 2.74761 Training err. RA 3.11496 Valid. err. 2.73305
2018-02-03 21:32:04,034 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74546 Training err. RA 3.10176 Valid. err. 2.72217
2018-02-03 21:32:04,492 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80934 Training err. RA 3.09168 Valid. err. 2.80859
2018-02-03 21:32:04,826 training [INFO ] Epoch  8 Batch 1500 Training err. 2.75365 Training err. RA 3.08041 Valid. err. 2.70634
2018-02-03 21:32:05,090 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69065 Training err. RA 3.06784 Valid. err. 2.68305
2018-02-03 21:32:05,359 training [INFO ] Epoch  8 Batch 1600 Training err. 2.68488 Training err. RA 3.05587 Valid. err. 2.69275
2018-02-03 21:32:05,752 training [INFO ] Epoch  9 Batch 1650 Training err. 2.75326 Training err. RA 3.04670 Valid. err. 2.64619
2018-02-03 21:32:06,019 training [INFO ] Epoch  9 Batch 1700 Training err. 2.70388 Training err. RA 3.03662 Valid. err. 2.64884
2018-02-03 21:32:06,280 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62870 Training err. RA 3.02496 Valid. err. 2.64648
2018-02-03 21:32:06,535 training [INFO ] Epoch  9 Batch 1800 Training err. 2.64168 Training err. RA 3.01431 Valid. err. 2.63541
2018-02-03 21:32:06,901 training [INFO ] Epoch 10 Batch 1850 Training err. 2.69184 Training err. RA 3.00560 Valid. err. 2.62022
2018-02-03 21:32:07,161 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66928 Training err. RA 2.99675 Valid. err. 2.66894
2018-02-03 21:32:07,434 training [INFO ] Epoch 10 Batch 1950 Training err. 2.57763 Training err. RA 2.98600 Valid. err. 2.57420
2018-02-03 21:32:07,712 training [INFO ] Epoch 10 Batch 2000 Training err. 2.61542 Training err. RA 2.97674 Valid. err. 2.56837
2018-02-03 21:32:07,987 training [INFO ] Epoch 10 Batch 2050 Training err. 2.59956 Training err. RA 2.96754 Valid. err. 2.56084
2018-02-03 21:32:08,087 __main__ [INFO ] End of training
2018-02-03 21:32:08,347 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:32:08,347 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-03 21:32:08,634 training [INFO ] Epoch  1 Batch   50 Training err. 4.25089 Training err. RA 4.25089 Valid. err. 4.07388
2018-02-03 21:32:08,902 training [INFO ] Epoch  1 Batch  100 Training err. 3.91735 Training err. RA 4.08412 Valid. err. 3.66513
2018-02-03 21:32:09,146 training [INFO ] Epoch  1 Batch  150 Training err. 3.58519 Training err. RA 3.91781 Valid. err. 3.43050
2018-02-03 21:32:09,437 training [INFO ] Epoch  1 Batch  200 Training err. 3.43288 Training err. RA 3.79658 Valid. err. 3.35624
2018-02-03 21:32:09,714 training [INFO ] Epoch  1 Batch  250 Training err. 3.35662 Training err. RA 3.70859 Valid. err. 3.32507
2018-02-03 21:32:09,956 training [INFO ] Epoch  1 Batch  300 Training err. 3.34314 Training err. RA 3.64768 Valid. err. 3.29843
2018-02-03 21:32:10,304 training [INFO ] Epoch  2 Batch  350 Training err. 3.30636 Training err. RA 3.59892 Valid. err. 3.27696
2018-02-03 21:32:10,617 training [INFO ] Epoch  2 Batch  400 Training err. 3.29690 Training err. RA 3.56117 Valid. err. 3.26078
2018-02-03 21:32:10,932 training [INFO ] Epoch  2 Batch  450 Training err. 3.24770 Training err. RA 3.52634 Valid. err. 3.26687
2018-02-03 21:32:11,178 training [INFO ] Epoch  2 Batch  500 Training err. 3.22835 Training err. RA 3.49654 Valid. err. 3.26708
2018-02-03 21:32:11,393 training [INFO ] Epoch  2 Batch  550 Training err. 3.27238 Training err. RA 3.47616 Valid. err. 3.24858
2018-02-03 21:32:11,641 training [INFO ] Epoch  2 Batch  600 Training err. 3.25082 Training err. RA 3.45738 Valid. err. 3.23533
2018-02-03 21:32:12,059 training [INFO ] Epoch  3 Batch  650 Training err. 3.26233 Training err. RA 3.44238 Valid. err. 3.24370
2018-02-03 21:32:12,313 training [INFO ] Epoch  3 Batch  700 Training err. 3.21580 Training err. RA 3.42619 Valid. err. 3.23970
2018-02-03 21:32:12,537 training [INFO ] Epoch  3 Batch  750 Training err. 3.23215 Training err. RA 3.41326 Valid. err. 3.24591
2018-02-03 21:32:12,794 training [INFO ] Epoch  3 Batch  800 Training err. 3.20004 Training err. RA 3.39993 Valid. err. 3.24128
2018-02-03 21:32:13,045 training [INFO ] Epoch  3 Batch  850 Training err. 3.24595 Training err. RA 3.39087 Valid. err. 3.22805
2018-02-03 21:32:13,295 training [INFO ] Epoch  3 Batch  900 Training err. 3.22280 Training err. RA 3.38154 Valid. err. 3.21908
2018-02-03 21:32:13,652 training [INFO ] Epoch  4 Batch  950 Training err. 3.22606 Training err. RA 3.37335 Valid. err. 3.22369
2018-02-03 21:32:13,903 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19468 Training err. RA 3.36442 Valid. err. 3.22399
2018-02-03 21:32:14,147 training [INFO ] Epoch  4 Batch 1050 Training err. 3.23040 Training err. RA 3.35804 Valid. err. 3.23087
2018-02-03 21:32:14,394 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18838 Training err. RA 3.35033 Valid. err. 3.22223
2018-02-03 21:32:14,648 training [INFO ] Epoch  4 Batch 1150 Training err. 3.22367 Training err. RA 3.34482 Valid. err. 3.21680
2018-02-03 21:32:14,895 training [INFO ] Epoch  4 Batch 1200 Training err. 3.19536 Training err. RA 3.33859 Valid. err. 3.20280
2018-02-03 21:32:15,255 training [INFO ] Epoch  5 Batch 1250 Training err. 3.21777 Training err. RA 3.33376 Valid. err. 3.20317
2018-02-03 21:32:15,501 training [INFO ] Epoch  5 Batch 1300 Training err. 3.18430 Training err. RA 3.32801 Valid. err. 3.19901
2018-02-03 21:32:15,757 training [INFO ] Epoch  5 Batch 1350 Training err. 3.21200 Training err. RA 3.32371 Valid. err. 3.20791
2018-02-03 21:32:16,004 training [INFO ] Epoch  5 Batch 1400 Training err. 3.14681 Training err. RA 3.31740 Valid. err. 3.19795
2018-02-03 21:32:16,251 training [INFO ] Epoch  5 Batch 1450 Training err. 3.20256 Training err. RA 3.31344 Valid. err. 3.18935
2018-02-03 21:32:16,500 training [INFO ] Epoch  5 Batch 1500 Training err. 3.16935 Training err. RA 3.30863 Valid. err. 3.18520
2018-02-03 21:32:16,856 training [INFO ] Epoch  6 Batch 1550 Training err. 3.19318 Training err. RA 3.30491 Valid. err. 3.17755
2018-02-03 21:32:17,106 training [INFO ] Epoch  6 Batch 1600 Training err. 3.17147 Training err. RA 3.30074 Valid. err. 3.16673
2018-02-03 21:32:17,347 training [INFO ] Epoch  6 Batch 1650 Training err. 3.18570 Training err. RA 3.29725 Valid. err. 3.16049
2018-02-03 21:32:17,599 training [INFO ] Epoch  6 Batch 1700 Training err. 3.08802 Training err. RA 3.29110 Valid. err. 3.16645
2018-02-03 21:32:17,823 training [INFO ] Epoch  6 Batch 1750 Training err. 3.17645 Training err. RA 3.28782 Valid. err. 3.14035
2018-02-03 21:32:18,041 training [INFO ] Epoch  6 Batch 1800 Training err. 3.12448 Training err. RA 3.28329 Valid. err. 3.12810
2018-02-03 21:32:18,374 training [INFO ] Epoch  7 Batch 1850 Training err. 3.12511 Training err. RA 3.27901 Valid. err. 3.11594
2018-02-03 21:32:18,588 training [INFO ] Epoch  7 Batch 1900 Training err. 3.14539 Training err. RA 3.27549 Valid. err. 3.13017
2018-02-03 21:32:18,806 training [INFO ] Epoch  7 Batch 1950 Training err. 3.12510 Training err. RA 3.27164 Valid. err. 3.09729
2018-02-03 21:32:19,024 training [INFO ] Epoch  7 Batch 2000 Training err. 3.02967 Training err. RA 3.26559 Valid. err. 3.07700
2018-02-03 21:32:19,264 training [INFO ] Epoch  7 Batch 2050 Training err. 3.10658 Training err. RA 3.26171 Valid. err. 3.06112
2018-02-03 21:32:19,485 training [INFO ] Epoch  7 Batch 2100 Training err. 3.03572 Training err. RA 3.25633 Valid. err. 3.03671
2018-02-03 21:32:19,831 training [INFO ] Epoch  8 Batch 2150 Training err. 3.04055 Training err. RA 3.25131 Valid. err. 3.01571
2018-02-03 21:32:20,046 training [INFO ] Epoch  8 Batch 2200 Training err. 3.07181 Training err. RA 3.24723 Valid. err. 2.99929
2018-02-03 21:32:20,271 training [INFO ] Epoch  8 Batch 2250 Training err. 3.04324 Training err. RA 3.24270 Valid. err. 2.97431
2018-02-03 21:32:20,489 training [INFO ] Epoch  8 Batch 2300 Training err. 2.94324 Training err. RA 3.23619 Valid. err. 2.99403
2018-02-03 21:32:20,702 training [INFO ] Epoch  8 Batch 2350 Training err. 2.96055 Training err. RA 3.23032 Valid. err. 2.94005
2018-02-03 21:32:20,957 training [INFO ] Epoch  8 Batch 2400 Training err. 2.95367 Training err. RA 3.22456 Valid. err. 2.93758
2018-02-03 21:32:21,178 training [INFO ] Epoch  8 Batch 2450 Training err. 2.93826 Training err. RA 3.21872 Valid. err. 2.91751
2018-02-03 21:32:21,516 training [INFO ] Epoch  9 Batch 2500 Training err. 2.97622 Training err. RA 3.21387 Valid. err. 2.93166
2018-02-03 21:32:21,731 training [INFO ] Epoch  9 Batch 2550 Training err. 2.96011 Training err. RA 3.20889 Valid. err. 2.87569
2018-02-03 21:32:21,955 training [INFO ] Epoch  9 Batch 2600 Training err. 2.87883 Training err. RA 3.20255 Valid. err. 2.88209
2018-02-03 21:32:22,170 training [INFO ] Epoch  9 Batch 2650 Training err. 2.82910 Training err. RA 3.19550 Valid. err. 2.86312
2018-02-03 21:32:22,419 training [INFO ] Epoch  9 Batch 2700 Training err. 2.87590 Training err. RA 3.18958 Valid. err. 2.86603
2018-02-03 21:32:22,673 training [INFO ] Epoch  9 Batch 2750 Training err. 2.89185 Training err. RA 3.18417 Valid. err. 2.83468
2018-02-03 21:32:23,043 training [INFO ] Epoch 10 Batch 2800 Training err. 2.91581 Training err. RA 3.17938 Valid. err. 2.84438
2018-02-03 21:32:23,290 training [INFO ] Epoch 10 Batch 2850 Training err. 2.84987 Training err. RA 3.17359 Valid. err. 2.84183
2018-02-03 21:32:23,537 training [INFO ] Epoch 10 Batch 2900 Training err. 2.86559 Training err. RA 3.16828 Valid. err. 2.85923
2018-02-03 21:32:23,778 training [INFO ] Epoch 10 Batch 2950 Training err. 2.77927 Training err. RA 3.16169 Valid. err. 2.81609
2018-02-03 21:32:24,000 training [INFO ] Epoch 10 Batch 3000 Training err. 2.81512 Training err. RA 3.15591 Valid. err. 2.78541
2018-02-03 21:32:24,230 training [INFO ] Epoch 10 Batch 3050 Training err. 2.83377 Training err. RA 3.15063 Valid. err. 2.78474
2018-02-03 21:32:24,387 __main__ [INFO ] End of training
2018-02-03 21:33:30,652 __main__ [INFO ] 
==============================
Starting experiment alice_test
==============================
2018-02-03 21:33:30,655 __main__ [INFO ] Removing old results directory ./experiments/alice_test/out
2018-02-03 21:33:30,656 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:33:30,656 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 21:33:33,152 training [INFO ] Epoch  1 Batch   20 Training err. 4.22633 Training err. RA 4.22633 Valid. err. 4.15259
2018-02-03 21:33:33,648 training [INFO ] Epoch  1 Batch   40 Training err. 4.04117 Training err. RA 4.13375 Valid. err. 3.98858
2018-02-03 21:33:34,156 training [INFO ] Epoch  1 Batch   60 Training err. 3.89334 Training err. RA 4.05361 Valid. err. 3.82472
2018-02-03 21:33:34,675 training [INFO ] Epoch  1 Batch   80 Training err. 3.73240 Training err. RA 3.97331 Valid. err. 3.66878
2018-02-03 21:33:35,149 training [INFO ] Epoch  1 Batch  100 Training err. 3.56283 Training err. RA 3.89121 Valid. err. 3.54625
2018-02-03 21:33:35,622 training [INFO ] Epoch  1 Batch  120 Training err. 3.47247 Training err. RA 3.82142 Valid. err. 3.44712
2018-02-03 21:33:36,095 training [INFO ] Epoch  1 Batch  140 Training err. 3.36349 Training err. RA 3.75600 Valid. err. 3.36684
2018-02-03 21:33:36,570 training [INFO ] Epoch  1 Batch  160 Training err. 3.27797 Training err. RA 3.69625 Valid. err. 3.31042
2018-02-03 21:33:37,042 training [INFO ] Epoch  1 Batch  180 Training err. 3.27189 Training err. RA 3.64910 Valid. err. 3.27818
2018-02-03 21:33:37,514 training [INFO ] Epoch  1 Batch  200 Training err. 3.25228 Training err. RA 3.60942 Valid. err. 3.25528
2018-02-03 21:33:38,325 training [INFO ] Epoch  2 Batch  220 Training err. 3.21240 Training err. RA 3.57332 Valid. err. 3.24406
2018-02-03 21:33:38,794 training [INFO ] Epoch  2 Batch  240 Training err. 3.12382 Training err. RA 3.53587 Valid. err. 3.25690
2018-02-03 21:33:39,262 training [INFO ] Epoch  2 Batch  260 Training err. 3.20607 Training err. RA 3.51050 Valid. err. 3.22074
2018-02-03 21:33:39,733 training [INFO ] Epoch  2 Batch  280 Training err. 3.15531 Training err. RA 3.48513 Valid. err. 3.21478
2018-02-03 21:33:40,202 training [INFO ] Epoch  2 Batch  300 Training err. 3.14957 Training err. RA 3.46276 Valid. err. 3.21110
2018-02-03 21:33:40,670 training [INFO ] Epoch  2 Batch  320 Training err. 3.17665 Training err. RA 3.44487 Valid. err. 3.20420
2018-02-03 21:33:41,142 training [INFO ] Epoch  2 Batch  340 Training err. 3.15342 Training err. RA 3.42773 Valid. err. 3.20210
2018-02-03 21:33:41,618 training [INFO ] Epoch  2 Batch  360 Training err. 3.14025 Training err. RA 3.41176 Valid. err. 3.19876
2018-02-03 21:33:42,088 training [INFO ] Epoch  2 Batch  380 Training err. 3.13118 Training err. RA 3.39699 Valid. err. 3.19467
2018-02-03 21:33:42,556 training [INFO ] Epoch  2 Batch  400 Training err. 3.17348 Training err. RA 3.38582 Valid. err. 3.19213
2018-02-03 21:33:43,362 training [INFO ] Epoch  3 Batch  420 Training err. 3.16838 Training err. RA 3.37546 Valid. err. 3.19105
2018-02-03 21:33:43,834 training [INFO ] Epoch  3 Batch  440 Training err. 3.13040 Training err. RA 3.36432 Valid. err. 3.19317
2018-02-03 21:33:44,303 training [INFO ] Epoch  3 Batch  460 Training err. 3.11693 Training err. RA 3.35357 Valid. err. 3.18782
2018-02-03 21:33:44,772 training [INFO ] Epoch  3 Batch  480 Training err. 3.12317 Training err. RA 3.34397 Valid. err. 3.18828
2018-02-03 21:33:45,288 training [INFO ] Epoch  3 Batch  500 Training err. 3.10962 Training err. RA 3.33459 Valid. err. 3.19269
2018-02-03 21:33:45,757 training [INFO ] Epoch  3 Batch  520 Training err. 3.16396 Training err. RA 3.32803 Valid. err. 3.18922
2018-02-03 21:33:46,225 training [INFO ] Epoch  3 Batch  540 Training err. 3.15439 Training err. RA 3.32160 Valid. err. 3.18718
2018-02-03 21:33:46,693 training [INFO ] Epoch  3 Batch  560 Training err. 3.12157 Training err. RA 3.31446 Valid. err. 3.18695
2018-02-03 21:33:47,163 training [INFO ] Epoch  3 Batch  580 Training err. 3.08400 Training err. RA 3.30651 Valid. err. 3.18878
2018-02-03 21:33:47,649 training [INFO ] Epoch  3 Batch  600 Training err. 3.16479 Training err. RA 3.30178 Valid. err. 3.18389
2018-02-03 21:33:48,118 training [INFO ] Epoch  3 Batch  620 Training err. 3.16494 Training err. RA 3.29737 Valid. err. 3.18075
2018-02-03 21:33:48,932 training [INFO ] Epoch  4 Batch  640 Training err. 3.13584 Training err. RA 3.29232 Valid. err. 3.18301
2018-02-03 21:33:49,399 training [INFO ] Epoch  4 Batch  660 Training err. 3.07848 Training err. RA 3.28584 Valid. err. 3.18460
2018-02-03 21:33:49,871 training [INFO ] Epoch  4 Batch  680 Training err. 3.13691 Training err. RA 3.28146 Valid. err. 3.18301
2018-02-03 21:33:50,338 training [INFO ] Epoch  4 Batch  700 Training err. 3.12036 Training err. RA 3.27686 Valid. err. 3.18189
2018-02-03 21:33:50,805 training [INFO ] Epoch  4 Batch  720 Training err. 3.11178 Training err. RA 3.27227 Valid. err. 3.18488
2018-02-03 21:33:51,307 training [INFO ] Epoch  4 Batch  740 Training err. 3.16657 Training err. RA 3.26942 Valid. err. 3.18042
2018-02-03 21:33:51,787 training [INFO ] Epoch  4 Batch  760 Training err. 3.11423 Training err. RA 3.26533 Valid. err. 3.18277
2018-02-03 21:33:52,259 training [INFO ] Epoch  4 Batch  780 Training err. 3.11378 Training err. RA 3.26145 Valid. err. 3.18075
2018-02-03 21:33:52,731 training [INFO ] Epoch  4 Batch  800 Training err. 3.12253 Training err. RA 3.25797 Valid. err. 3.18001
2018-02-03 21:33:53,200 training [INFO ] Epoch  4 Batch  820 Training err. 3.14776 Training err. RA 3.25529 Valid. err. 3.17860
2018-02-03 21:33:54,015 training [INFO ] Epoch  5 Batch  840 Training err. 3.15730 Training err. RA 3.25295 Valid. err. 3.17612
2018-02-03 21:33:54,538 training [INFO ] Epoch  5 Batch  860 Training err. 3.07888 Training err. RA 3.24890 Valid. err. 3.19996
2018-02-03 21:33:55,071 training [INFO ] Epoch  5 Batch  880 Training err. 3.13328 Training err. RA 3.24628 Valid. err. 3.17753
2018-02-03 21:33:55,564 training [INFO ] Epoch  5 Batch  900 Training err. 3.11411 Training err. RA 3.24334 Valid. err. 3.17748
2018-02-03 21:33:56,042 training [INFO ] Epoch  5 Batch  920 Training err. 3.09137 Training err. RA 3.24004 Valid. err. 3.18093
2018-02-03 21:33:56,522 training [INFO ] Epoch  5 Batch  940 Training err. 3.15301 Training err. RA 3.23818 Valid. err. 3.18027
2018-02-03 21:33:56,992 training [INFO ] Epoch  5 Batch  960 Training err. 3.12564 Training err. RA 3.23584 Valid. err. 3.17985
2018-02-03 21:33:57,476 training [INFO ] Epoch  5 Batch  980 Training err. 3.11835 Training err. RA 3.23344 Valid. err. 3.17614
2018-02-03 21:33:57,949 training [INFO ] Epoch  5 Batch 1000 Training err. 3.08128 Training err. RA 3.23040 Valid. err. 3.17546
2018-02-03 21:33:58,422 training [INFO ] Epoch  5 Batch 1020 Training err. 3.15928 Training err. RA 3.22900 Valid. err. 3.17372
2018-02-03 21:33:58,891 training [INFO ] Epoch  5 Batch 1040 Training err. 3.14482 Training err. RA 3.22739 Valid. err. 3.17035
2018-02-03 21:33:59,707 training [INFO ] Epoch  6 Batch 1060 Training err. 3.11066 Training err. RA 3.22518 Valid. err. 3.17239
2018-02-03 21:34:00,190 training [INFO ] Epoch  6 Batch 1080 Training err. 3.09018 Training err. RA 3.22268 Valid. err. 3.17218
2018-02-03 21:34:00,664 training [INFO ] Epoch  6 Batch 1100 Training err. 3.09969 Training err. RA 3.22045 Valid. err. 3.17347
2018-02-03 21:34:01,169 training [INFO ] Epoch  6 Batch 1120 Training err. 3.11681 Training err. RA 3.21860 Valid. err. 3.17272
2018-02-03 21:34:01,682 training [INFO ] Epoch  6 Batch 1140 Training err. 3.11327 Training err. RA 3.21675 Valid. err. 3.17172
2018-02-03 21:34:02,292 training [INFO ] Epoch  6 Batch 1160 Training err. 3.14770 Training err. RA 3.21556 Valid. err. 3.16974
2018-02-03 21:34:02,831 training [INFO ] Epoch  6 Batch 1180 Training err. 3.10465 Training err. RA 3.21368 Valid. err. 3.17035
2018-02-03 21:34:03,407 training [INFO ] Epoch  6 Batch 1200 Training err. 3.07762 Training err. RA 3.21141 Valid. err. 3.16928
2018-02-03 21:34:03,884 training [INFO ] Epoch  6 Batch 1220 Training err. 3.12866 Training err. RA 3.21005 Valid. err. 3.16810
2018-02-03 21:34:04,371 training [INFO ] Epoch  6 Batch 1240 Training err. 3.13923 Training err. RA 3.20891 Valid. err. 3.16398
2018-02-03 21:34:05,213 training [INFO ] Epoch  7 Batch 1260 Training err. 3.12854 Training err. RA 3.20764 Valid. err. 3.17496
2018-02-03 21:34:05,707 training [INFO ] Epoch  7 Batch 1280 Training err. 3.04982 Training err. RA 3.20517 Valid. err. 3.20002
2018-02-03 21:34:06,187 training [INFO ] Epoch  7 Batch 1300 Training err. 3.13110 Training err. RA 3.20403 Valid. err. 3.16433
2018-02-03 21:34:06,661 training [INFO ] Epoch  7 Batch 1320 Training err. 3.09761 Training err. RA 3.20242 Valid. err. 3.16239
2018-02-03 21:34:07,143 training [INFO ] Epoch  7 Batch 1340 Training err. 3.09298 Training err. RA 3.20078 Valid. err. 3.16583
2018-02-03 21:34:07,633 training [INFO ] Epoch  7 Batch 1360 Training err. 3.13168 Training err. RA 3.19977 Valid. err. 3.15931
2018-02-03 21:34:08,240 training [INFO ] Epoch  7 Batch 1380 Training err. 3.10523 Training err. RA 3.19840 Valid. err. 3.16005
2018-02-03 21:34:08,789 training [INFO ] Epoch  7 Batch 1400 Training err. 3.09100 Training err. RA 3.19686 Valid. err. 3.15882
2018-02-03 21:34:09,313 training [INFO ] Epoch  7 Batch 1420 Training err. 3.08402 Training err. RA 3.19527 Valid. err. 3.15489
2018-02-03 21:34:09,838 training [INFO ] Epoch  7 Batch 1440 Training err. 3.12812 Training err. RA 3.19434 Valid. err. 3.15168
2018-02-03 21:34:10,643 training [INFO ] Epoch  8 Batch 1460 Training err. 3.12428 Training err. RA 3.19338 Valid. err. 3.15041
2018-02-03 21:34:11,108 training [INFO ] Epoch  8 Batch 1480 Training err. 3.08772 Training err. RA 3.19195 Valid. err. 3.16006
2018-02-03 21:34:11,574 training [INFO ] Epoch  8 Batch 1500 Training err. 3.08333 Training err. RA 3.19051 Valid. err. 3.14741
2018-02-03 21:34:12,051 training [INFO ] Epoch  8 Batch 1520 Training err. 3.07904 Training err. RA 3.18904 Valid. err. 3.14663
2018-02-03 21:34:12,511 training [INFO ] Epoch  8 Batch 1540 Training err. 3.06834 Training err. RA 3.18747 Valid. err. 3.15040
2018-02-03 21:34:12,990 training [INFO ] Epoch  8 Batch 1560 Training err. 3.12156 Training err. RA 3.18663 Valid. err. 3.14531
2018-02-03 21:34:13,455 training [INFO ] Epoch  8 Batch 1580 Training err. 3.10854 Training err. RA 3.18564 Valid. err. 3.14111
2018-02-03 21:34:13,922 training [INFO ] Epoch  8 Batch 1600 Training err. 3.07070 Training err. RA 3.18420 Valid. err. 3.13827
2018-02-03 21:34:14,387 training [INFO ] Epoch  8 Batch 1620 Training err. 3.03409 Training err. RA 3.18235 Valid. err. 3.13667
2018-02-03 21:34:14,852 training [INFO ] Epoch  8 Batch 1640 Training err. 3.10903 Training err. RA 3.18145 Valid. err. 3.13038
2018-02-03 21:34:15,317 training [INFO ] Epoch  8 Batch 1660 Training err. 3.10754 Training err. RA 3.18056 Valid. err. 3.12403
2018-02-03 21:34:16,129 training [INFO ] Epoch  9 Batch 1680 Training err. 3.08320 Training err. RA 3.17940 Valid. err. 3.12490
2018-02-03 21:34:16,593 training [INFO ] Epoch  9 Batch 1700 Training err. 3.04036 Training err. RA 3.17777 Valid. err. 3.12625
2018-02-03 21:34:17,062 training [INFO ] Epoch  9 Batch 1720 Training err. 3.07601 Training err. RA 3.17659 Valid. err. 3.12086
2018-02-03 21:34:17,521 training [INFO ] Epoch  9 Batch 1740 Training err. 3.06183 Training err. RA 3.17527 Valid. err. 3.11685
2018-02-03 21:34:17,991 training [INFO ] Epoch  9 Batch 1760 Training err. 3.05167 Training err. RA 3.17386 Valid. err. 3.11622
2018-02-03 21:34:18,459 training [INFO ] Epoch  9 Batch 1780 Training err. 3.10239 Training err. RA 3.17306 Valid. err. 3.11034
2018-02-03 21:34:18,927 training [INFO ] Epoch  9 Batch 1800 Training err. 3.04253 Training err. RA 3.17161 Valid. err. 3.10736
2018-02-03 21:34:19,392 training [INFO ] Epoch  9 Batch 1820 Training err. 3.03643 Training err. RA 3.17012 Valid. err. 3.10073
2018-02-03 21:34:19,856 training [INFO ] Epoch  9 Batch 1840 Training err. 3.04807 Training err. RA 3.16880 Valid. err. 3.09744
2018-02-03 21:34:20,431 training [INFO ] Epoch  9 Batch 1860 Training err. 3.06445 Training err. RA 3.16767 Valid. err. 3.09038
2018-02-03 21:34:21,404 training [INFO ] Epoch 10 Batch 1880 Training err. 3.07264 Training err. RA 3.16666 Valid. err. 3.08527
2018-02-03 21:34:21,936 training [INFO ] Epoch 10 Batch 1900 Training err. 3.00906 Training err. RA 3.16500 Valid. err. 3.11510
2018-02-03 21:34:22,482 training [INFO ] Epoch 10 Batch 1920 Training err. 3.05607 Training err. RA 3.16387 Valid. err. 3.08296
2018-02-03 21:34:23,016 training [INFO ] Epoch 10 Batch 1940 Training err. 3.02266 Training err. RA 3.16241 Valid. err. 3.07847
2018-02-03 21:34:23,480 training [INFO ] Epoch 10 Batch 1960 Training err. 3.00025 Training err. RA 3.16076 Valid. err. 3.07589
2018-02-03 21:34:24,002 training [INFO ] Epoch 10 Batch 1980 Training err. 3.05937 Training err. RA 3.15973 Valid. err. 3.07058
2018-02-03 21:34:24,493 training [INFO ] Epoch 10 Batch 2000 Training err. 3.02391 Training err. RA 3.15838 Valid. err. 3.06498
2018-02-03 21:34:24,964 training [INFO ] Epoch 10 Batch 2020 Training err. 3.00866 Training err. RA 3.15689 Valid. err. 3.06059
2018-02-03 21:34:25,449 training [INFO ] Epoch 10 Batch 2040 Training err. 2.97266 Training err. RA 3.15509 Valid. err. 3.05472
2018-02-03 21:34:25,924 training [INFO ] Epoch 10 Batch 2060 Training err. 3.03731 Training err. RA 3.15394 Valid. err. 3.04588
2018-02-03 21:34:26,487 training [INFO ] Epoch 10 Batch 2080 Training err. 3.01938 Training err. RA 3.15265 Valid. err. 3.03766
2018-02-03 21:34:27,309 training [INFO ] Epoch 11 Batch 2100 Training err. 2.98542 Training err. RA 3.15106 Valid. err. 3.03439
2018-02-03 21:34:27,842 training [INFO ] Epoch 11 Batch 2120 Training err. 2.99503 Training err. RA 3.14959 Valid. err. 3.03891
2018-02-03 21:34:28,391 training [INFO ] Epoch 11 Batch 2140 Training err. 2.96831 Training err. RA 3.14789 Valid. err. 3.02813
2018-02-03 21:34:28,925 training [INFO ] Epoch 11 Batch 2160 Training err. 2.97666 Training err. RA 3.14631 Valid. err. 3.02355
2018-02-03 21:34:29,428 training [INFO ] Epoch 11 Batch 2180 Training err. 2.96892 Training err. RA 3.14468 Valid. err. 3.01522
2018-02-03 21:34:29,905 training [INFO ] Epoch 11 Batch 2200 Training err. 3.00494 Training err. RA 3.14341 Valid. err. 3.00822
2018-02-03 21:34:30,375 training [INFO ] Epoch 11 Batch 2220 Training err. 2.95250 Training err. RA 3.14169 Valid. err. 3.00369
2018-02-03 21:34:30,850 training [INFO ] Epoch 11 Batch 2240 Training err. 2.91970 Training err. RA 3.13971 Valid. err. 3.00089
2018-02-03 21:34:31,322 training [INFO ] Epoch 11 Batch 2260 Training err. 2.96750 Training err. RA 3.13818 Valid. err. 2.99217
2018-02-03 21:34:31,799 training [INFO ] Epoch 11 Batch 2280 Training err. 2.97150 Training err. RA 3.13672 Valid. err. 2.98269
2018-02-03 21:34:32,620 training [INFO ] Epoch 12 Batch 2300 Training err. 2.94931 Training err. RA 3.13509 Valid. err. 2.99649
2018-02-03 21:34:33,088 training [INFO ] Epoch 12 Batch 2320 Training err. 2.89138 Training err. RA 3.13299 Valid. err. 2.99639
2018-02-03 21:34:33,621 training [INFO ] Epoch 12 Batch 2340 Training err. 2.95348 Training err. RA 3.13146 Valid. err. 2.96982
2018-02-03 21:34:34,209 training [INFO ] Epoch 12 Batch 2360 Training err. 2.90810 Training err. RA 3.12956 Valid. err. 2.96143
2018-02-03 21:34:34,678 training [INFO ] Epoch 12 Batch 2380 Training err. 2.89050 Training err. RA 3.12755 Valid. err. 2.95876
2018-02-03 21:34:35,150 training [INFO ] Epoch 12 Batch 2400 Training err. 2.92728 Training err. RA 3.12588 Valid. err. 2.94618
2018-02-03 21:34:35,673 training [INFO ] Epoch 12 Batch 2420 Training err. 2.90987 Training err. RA 3.12410 Valid. err. 2.94752
2018-02-03 21:34:36,207 training [INFO ] Epoch 12 Batch 2440 Training err. 2.88667 Training err. RA 3.12215 Valid. err. 2.93516
2018-02-03 21:34:36,678 training [INFO ] Epoch 12 Batch 2460 Training err. 2.87314 Training err. RA 3.12013 Valid. err. 2.93094
2018-02-03 21:34:37,244 training [INFO ] Epoch 12 Batch 2480 Training err. 2.90735 Training err. RA 3.11841 Valid. err. 2.92031
2018-02-03 21:34:38,082 training [INFO ] Epoch 13 Batch 2500 Training err. 2.89842 Training err. RA 3.11665 Valid. err. 2.91281
2018-02-03 21:34:38,574 training [INFO ] Epoch 13 Batch 2520 Training err. 2.84860 Training err. RA 3.11453 Valid. err. 2.92141
2018-02-03 21:34:39,179 training [INFO ] Epoch 13 Batch 2540 Training err. 2.87029 Training err. RA 3.11260 Valid. err. 2.90454
2018-02-03 21:34:39,708 training [INFO ] Epoch 13 Batch 2560 Training err. 2.84158 Training err. RA 3.11049 Valid. err. 2.89610
2018-02-03 21:34:40,211 training [INFO ] Epoch 13 Batch 2580 Training err. 2.81550 Training err. RA 3.10820 Valid. err. 2.90248
2018-02-03 21:34:40,810 training [INFO ] Epoch 13 Batch 2600 Training err. 2.86118 Training err. RA 3.10630 Valid. err. 2.88694
2018-02-03 21:34:41,338 training [INFO ] Epoch 13 Batch 2620 Training err. 2.86971 Training err. RA 3.10449 Valid. err. 2.87917
2018-02-03 21:34:41,874 training [INFO ] Epoch 13 Batch 2640 Training err. 2.81822 Training err. RA 3.10232 Valid. err. 2.87214
2018-02-03 21:34:42,352 training [INFO ] Epoch 13 Batch 2660 Training err. 2.77346 Training err. RA 3.09985 Valid. err. 2.86840
2018-02-03 21:34:42,894 training [INFO ] Epoch 13 Batch 2680 Training err. 2.84628 Training err. RA 3.09796 Valid. err. 2.85559
2018-02-03 21:34:43,435 training [INFO ] Epoch 13 Batch 2700 Training err. 2.84784 Training err. RA 3.09611 Valid. err. 2.84581
2018-02-03 21:34:44,330 training [INFO ] Epoch 14 Batch 2720 Training err. 2.79719 Training err. RA 3.09391 Valid. err. 2.85057
2018-02-03 21:34:44,796 training [INFO ] Epoch 14 Batch 2740 Training err. 2.73615 Training err. RA 3.09130 Valid. err. 2.85609
2018-02-03 21:34:45,347 training [INFO ] Epoch 14 Batch 2760 Training err. 2.81425 Training err. RA 3.08929 Valid. err. 2.84331
2018-02-03 21:34:45,856 training [INFO ] Epoch 14 Batch 2780 Training err. 2.77963 Training err. RA 3.08706 Valid. err. 2.83179
2018-02-03 21:34:46,351 training [INFO ] Epoch 14 Batch 2800 Training err. 2.74063 Training err. RA 3.08459 Valid. err. 2.82276
2018-02-03 21:34:46,849 training [INFO ] Epoch 14 Batch 2820 Training err. 2.81980 Training err. RA 3.08271 Valid. err. 2.82367
2018-02-03 21:34:47,368 training [INFO ] Epoch 14 Batch 2840 Training err. 2.76524 Training err. RA 3.08047 Valid. err. 2.81560
2018-02-03 21:34:47,886 training [INFO ] Epoch 14 Batch 2860 Training err. 2.74841 Training err. RA 3.07815 Valid. err. 2.80310
2018-02-03 21:34:48,393 training [INFO ] Epoch 14 Batch 2880 Training err. 2.76195 Training err. RA 3.07596 Valid. err. 2.79747
2018-02-03 21:34:48,862 training [INFO ] Epoch 14 Batch 2900 Training err. 2.76308 Training err. RA 3.07380 Valid. err. 2.78490
2018-02-03 21:34:49,774 training [INFO ] Epoch 15 Batch 2920 Training err. 2.77170 Training err. RA 3.07173 Valid. err. 2.78095
2018-02-03 21:34:50,284 training [INFO ] Epoch 15 Batch 2940 Training err. 2.67513 Training err. RA 3.06903 Valid. err. 2.80850
2018-02-03 21:34:50,755 training [INFO ] Epoch 15 Batch 2960 Training err. 2.77128 Training err. RA 3.06702 Valid. err. 2.77974
2018-02-03 21:34:51,288 training [INFO ] Epoch 15 Batch 2980 Training err. 2.73005 Training err. RA 3.06476 Valid. err. 2.77618
2018-02-03 21:34:51,845 training [INFO ] Epoch 15 Batch 3000 Training err. 2.67985 Training err. RA 3.06219 Valid. err. 2.77026
2018-02-03 21:34:52,347 training [INFO ] Epoch 15 Batch 3020 Training err. 2.73225 Training err. RA 3.06001 Valid. err. 2.76922
2018-02-03 21:34:52,819 training [INFO ] Epoch 15 Batch 3040 Training err. 2.74085 Training err. RA 3.05791 Valid. err. 2.75970
2018-02-03 21:34:53,331 training [INFO ] Epoch 15 Batch 3060 Training err. 2.71180 Training err. RA 3.05564 Valid. err. 2.76022
2018-02-03 21:34:53,798 training [INFO ] Epoch 15 Batch 3080 Training err. 2.66310 Training err. RA 3.05310 Valid. err. 2.75947
2018-02-03 21:34:54,317 training [INFO ] Epoch 15 Batch 3100 Training err. 2.73420 Training err. RA 3.05104 Valid. err. 2.73511
2018-02-03 21:34:54,867 training [INFO ] Epoch 15 Batch 3120 Training err. 2.72296 Training err. RA 3.04893 Valid. err. 2.73973
2018-02-03 21:34:55,904 training [INFO ] Epoch 16 Batch 3140 Training err. 2.66573 Training err. RA 3.04649 Valid. err. 2.72950
2018-02-03 21:34:56,383 training [INFO ] Epoch 16 Batch 3160 Training err. 2.65114 Training err. RA 3.04399 Valid. err. 2.72782
2018-02-03 21:34:56,904 training [INFO ] Epoch 16 Batch 3180 Training err. 2.67852 Training err. RA 3.04169 Valid. err. 2.72245
2018-02-03 21:34:57,368 training [INFO ] Epoch 16 Batch 3200 Training err. 2.67916 Training err. RA 3.03943 Valid. err. 2.71905
2018-02-03 21:34:57,968 training [INFO ] Epoch 16 Batch 3220 Training err. 2.65659 Training err. RA 3.03705 Valid. err. 2.71659
2018-02-03 21:34:58,505 training [INFO ] Epoch 16 Batch 3240 Training err. 2.71304 Training err. RA 3.03505 Valid. err. 2.72310
2018-02-03 21:34:58,997 training [INFO ] Epoch 16 Batch 3260 Training err. 2.66547 Training err. RA 3.03278 Valid. err. 2.71105
2018-02-03 21:34:59,463 training [INFO ] Epoch 16 Batch 3280 Training err. 2.62916 Training err. RA 3.03032 Valid. err. 2.73592
2018-02-03 21:34:59,936 training [INFO ] Epoch 16 Batch 3300 Training err. 2.67232 Training err. RA 3.02815 Valid. err. 2.69172
2018-02-03 21:35:00,411 training [INFO ] Epoch 16 Batch 3320 Training err. 2.66885 Training err. RA 3.02599 Valid. err. 2.69788
2018-02-03 21:35:01,323 training [INFO ] Epoch 17 Batch 3340 Training err. 2.65506 Training err. RA 3.02377 Valid. err. 2.68916
2018-02-03 21:35:01,795 training [INFO ] Epoch 17 Batch 3360 Training err. 2.55602 Training err. RA 3.02098 Valid. err. 2.70723
2018-02-03 21:35:02,263 training [INFO ] Epoch 17 Batch 3380 Training err. 2.68668 Training err. RA 3.01900 Valid. err. 2.69325
2018-02-03 21:35:02,740 training [INFO ] Epoch 17 Batch 3400 Training err. 2.63678 Training err. RA 3.01675 Valid. err. 2.67131
2018-02-03 21:35:03,323 training [INFO ] Epoch 17 Batch 3420 Training err. 2.60733 Training err. RA 3.01436 Valid. err. 2.68625
2018-02-03 21:35:03,866 training [INFO ] Epoch 17 Batch 3440 Training err. 2.64911 Training err. RA 3.01224 Valid. err. 2.68575
2018-02-03 21:35:04,355 training [INFO ] Epoch 17 Batch 3460 Training err. 2.66108 Training err. RA 3.01021 Valid. err. 2.68634
2018-02-03 21:35:04,877 training [INFO ] Epoch 17 Batch 3480 Training err. 2.61109 Training err. RA 3.00791 Valid. err. 2.65861
2018-02-03 21:35:05,512 training [INFO ] Epoch 17 Batch 3500 Training err. 2.61063 Training err. RA 3.00564 Valid. err. 2.65926
2018-02-03 21:35:06,015 training [INFO ] Epoch 17 Batch 3520 Training err. 2.62652 Training err. RA 3.00349 Valid. err. 2.65226
2018-02-03 21:35:06,867 training [INFO ] Epoch 18 Batch 3540 Training err. 2.63072 Training err. RA 3.00138 Valid. err. 2.64261
2018-02-03 21:35:07,340 training [INFO ] Epoch 18 Batch 3560 Training err. 2.58647 Training err. RA 2.99905 Valid. err. 2.64763
2018-02-03 21:35:07,821 training [INFO ] Epoch 18 Batch 3580 Training err. 2.57932 Training err. RA 2.99671 Valid. err. 2.68058
2018-02-03 21:35:08,298 training [INFO ] Epoch 18 Batch 3600 Training err. 2.61213 Training err. RA 2.99457 Valid. err. 2.63904
2018-02-03 21:35:08,772 training [INFO ] Epoch 18 Batch 3620 Training err. 2.56782 Training err. RA 2.99221 Valid. err. 2.68446
2018-02-03 21:35:09,285 training [INFO ] Epoch 18 Batch 3640 Training err. 2.61555 Training err. RA 2.99014 Valid. err. 2.63564
2018-02-03 21:35:09,796 training [INFO ] Epoch 18 Batch 3660 Training err. 2.64842 Training err. RA 2.98828 Valid. err. 2.65580
2018-02-03 21:35:10,315 training [INFO ] Epoch 18 Batch 3680 Training err. 2.57485 Training err. RA 2.98603 Valid. err. 2.62676
2018-02-03 21:35:10,835 training [INFO ] Epoch 18 Batch 3700 Training err. 2.54449 Training err. RA 2.98364 Valid. err. 2.62483
2018-02-03 21:35:11,325 training [INFO ] Epoch 18 Batch 3720 Training err. 2.60267 Training err. RA 2.98159 Valid. err. 2.61465
2018-02-03 21:35:11,823 training [INFO ] Epoch 18 Batch 3740 Training err. 2.60569 Training err. RA 2.97958 Valid. err. 2.61490
2018-02-03 21:35:12,865 training [INFO ] Epoch 19 Batch 3760 Training err. 2.57343 Training err. RA 2.97742 Valid. err. 2.65184
2018-02-03 21:35:13,413 training [INFO ] Epoch 19 Batch 3780 Training err. 2.50279 Training err. RA 2.97491 Valid. err. 2.60510
2018-02-03 21:35:13,892 training [INFO ] Epoch 19 Batch 3800 Training err. 2.61081 Training err. RA 2.97300 Valid. err. 2.62987
2018-02-03 21:35:14,416 training [INFO ] Epoch 19 Batch 3820 Training err. 2.57002 Training err. RA 2.97089 Valid. err. 2.61239
2018-02-03 21:35:14,945 training [INFO ] Epoch 19 Batch 3840 Training err. 2.53175 Training err. RA 2.96860 Valid. err. 2.62357
2018-02-03 21:35:15,516 training [INFO ] Epoch 19 Batch 3860 Training err. 2.61860 Training err. RA 2.96679 Valid. err. 2.60935
2018-02-03 21:35:16,013 training [INFO ] Epoch 19 Batch 3880 Training err. 2.57070 Training err. RA 2.96474 Valid. err. 2.60301
2018-02-03 21:35:16,502 training [INFO ] Epoch 19 Batch 3900 Training err. 2.54096 Training err. RA 2.96257 Valid. err. 2.59109
2018-02-03 21:35:17,008 training [INFO ] Epoch 19 Batch 3920 Training err. 2.55858 Training err. RA 2.96051 Valid. err. 2.58743
2018-02-03 21:35:17,564 training [INFO ] Epoch 19 Batch 3940 Training err. 2.54840 Training err. RA 2.95842 Valid. err. 2.57806
2018-02-03 21:35:18,527 training [INFO ] Epoch 20 Batch 3960 Training err. 2.57331 Training err. RA 2.95647 Valid. err. 2.57841
2018-02-03 21:35:19,097 training [INFO ] Epoch 20 Batch 3980 Training err. 2.48420 Training err. RA 2.95410 Valid. err. 2.57694
2018-02-03 21:35:19,581 training [INFO ] Epoch 20 Batch 4000 Training err. 2.57617 Training err. RA 2.95221 Valid. err. 2.58422
2018-02-03 21:35:20,117 training [INFO ] Epoch 20 Batch 4020 Training err. 2.54433 Training err. RA 2.95018 Valid. err. 2.56938
2018-02-03 21:35:20,659 training [INFO ] Epoch 20 Batch 4040 Training err. 2.50234 Training err. RA 2.94796 Valid. err. 2.58113
2018-02-03 21:35:21,117 training [INFO ] Epoch 20 Batch 4060 Training err. 2.54830 Training err. RA 2.94599 Valid. err. 2.60707
2018-02-03 21:35:21,574 training [INFO ] Epoch 20 Batch 4080 Training err. 2.58180 Training err. RA 2.94421 Valid. err. 2.56923
2018-02-03 21:35:22,032 training [INFO ] Epoch 20 Batch 4100 Training err. 2.52818 Training err. RA 2.94218 Valid. err. 2.58576
2018-02-03 21:35:22,491 training [INFO ] Epoch 20 Batch 4120 Training err. 2.48615 Training err. RA 2.93997 Valid. err. 2.57434
2018-02-03 21:35:22,949 training [INFO ] Epoch 20 Batch 4140 Training err. 2.54924 Training err. RA 2.93808 Valid. err. 2.55363
2018-02-03 21:35:23,407 training [INFO ] Epoch 20 Batch 4160 Training err. 2.54094 Training err. RA 2.93617 Valid. err. 2.56019
2018-02-03 21:35:24,212 training [INFO ] Epoch 21 Batch 4180 Training err. 2.50601 Training err. RA 2.93411 Valid. err. 2.55652
2018-02-03 21:35:24,677 training [INFO ] Epoch 21 Batch 4200 Training err. 2.47477 Training err. RA 2.93192 Valid. err. 2.55106
2018-02-03 21:35:25,141 training [INFO ] Epoch 21 Batch 4220 Training err. 2.52103 Training err. RA 2.92998 Valid. err. 2.54687
2018-02-03 21:35:25,604 training [INFO ] Epoch 21 Batch 4240 Training err. 2.52196 Training err. RA 2.92805 Valid. err. 2.54509
2018-02-03 21:35:26,068 training [INFO ] Epoch 21 Batch 4260 Training err. 2.49960 Training err. RA 2.92604 Valid. err. 2.54285
2018-02-03 21:35:26,533 training [INFO ] Epoch 21 Batch 4280 Training err. 2.56030 Training err. RA 2.92433 Valid. err. 2.55774
2018-02-03 21:35:26,996 training [INFO ] Epoch 21 Batch 4300 Training err. 2.50718 Training err. RA 2.92239 Valid. err. 2.54192
2018-02-03 21:35:27,461 training [INFO ] Epoch 21 Batch 4320 Training err. 2.47362 Training err. RA 2.92031 Valid. err. 2.57498
2018-02-03 21:35:27,926 training [INFO ] Epoch 21 Batch 4340 Training err. 2.50958 Training err. RA 2.91842 Valid. err. 2.53184
2018-02-03 21:35:28,385 training [INFO ] Epoch 21 Batch 4360 Training err. 2.50234 Training err. RA 2.91651 Valid. err. 2.55089
2018-02-03 21:35:29,182 training [INFO ] Epoch 22 Batch 4380 Training err. 2.50221 Training err. RA 2.91462 Valid. err. 2.55533
2018-02-03 21:35:29,640 training [INFO ] Epoch 22 Batch 4400 Training err. 2.41176 Training err. RA 2.91233 Valid. err. 2.53214
2018-02-03 21:35:30,099 training [INFO ] Epoch 22 Batch 4420 Training err. 2.53963 Training err. RA 2.91065 Valid. err. 2.51870
2018-02-03 21:35:30,557 training [INFO ] Epoch 22 Batch 4440 Training err. 2.48998 Training err. RA 2.90875 Valid. err. 2.51787
2018-02-03 21:35:31,017 training [INFO ] Epoch 22 Batch 4460 Training err. 2.46150 Training err. RA 2.90675 Valid. err. 2.52203
2018-02-03 21:35:31,477 training [INFO ] Epoch 22 Batch 4480 Training err. 2.50484 Training err. RA 2.90495 Valid. err. 2.53567
2018-02-03 21:35:31,935 training [INFO ] Epoch 22 Batch 4500 Training err. 2.52821 Training err. RA 2.90328 Valid. err. 2.51969
2018-02-03 21:35:32,395 training [INFO ] Epoch 22 Batch 4520 Training err. 2.46543 Training err. RA 2.90134 Valid. err. 2.50854
2018-02-03 21:35:32,859 training [INFO ] Epoch 22 Batch 4540 Training err. 2.46635 Training err. RA 2.89943 Valid. err. 2.51501
2018-02-03 21:35:33,322 training [INFO ] Epoch 22 Batch 4560 Training err. 2.47542 Training err. RA 2.89757 Valid. err. 2.50976
2018-02-03 21:35:34,137 training [INFO ] Epoch 23 Batch 4580 Training err. 2.48313 Training err. RA 2.89576 Valid. err. 2.49710
2018-02-03 21:35:34,600 training [INFO ] Epoch 23 Batch 4600 Training err. 2.44993 Training err. RA 2.89382 Valid. err. 2.50399
2018-02-03 21:35:35,064 training [INFO ] Epoch 23 Batch 4620 Training err. 2.44627 Training err. RA 2.89188 Valid. err. 2.50449
2018-02-03 21:35:35,527 training [INFO ] Epoch 23 Batch 4640 Training err. 2.47105 Training err. RA 2.89007 Valid. err. 2.50110
2018-02-03 21:35:35,998 training [INFO ] Epoch 23 Batch 4660 Training err. 2.43836 Training err. RA 2.88813 Valid. err. 2.54272
2018-02-03 21:35:36,458 training [INFO ] Epoch 23 Batch 4680 Training err. 2.47852 Training err. RA 2.88638 Valid. err. 2.50456
2018-02-03 21:35:36,915 training [INFO ] Epoch 23 Batch 4700 Training err. 2.52505 Training err. RA 2.88484 Valid. err. 2.51200
2018-02-03 21:35:37,375 training [INFO ] Epoch 23 Batch 4720 Training err. 2.43654 Training err. RA 2.88294 Valid. err. 2.48447
2018-02-03 21:35:37,837 training [INFO ] Epoch 23 Batch 4740 Training err. 2.41892 Training err. RA 2.88098 Valid. err. 2.48321
2018-02-03 21:35:38,296 training [INFO ] Epoch 23 Batch 4760 Training err. 2.45814 Training err. RA 2.87921 Valid. err. 2.47698
2018-02-03 21:35:38,758 training [INFO ] Epoch 23 Batch 4780 Training err. 2.46484 Training err. RA 2.87747 Valid. err. 2.48115
2018-02-03 21:35:39,559 training [INFO ] Epoch 24 Batch 4800 Training err. 2.44324 Training err. RA 2.87566 Valid. err. 2.51922
2018-02-03 21:35:40,020 training [INFO ] Epoch 24 Batch 4820 Training err. 2.37988 Training err. RA 2.87360 Valid. err. 2.46997
2018-02-03 21:35:40,482 training [INFO ] Epoch 24 Batch 4840 Training err. 2.47403 Training err. RA 2.87195 Valid. err. 2.48544
2018-02-03 21:35:40,946 training [INFO ] Epoch 24 Batch 4860 Training err. 2.44455 Training err. RA 2.87020 Valid. err. 2.47443
2018-02-03 21:35:41,411 training [INFO ] Epoch 24 Batch 4880 Training err. 2.40912 Training err. RA 2.86831 Valid. err. 2.48911
2018-02-03 21:35:41,881 training [INFO ] Epoch 24 Batch 4900 Training err. 2.49251 Training err. RA 2.86677 Valid. err. 2.49041
2018-02-03 21:35:42,345 training [INFO ] Epoch 24 Batch 4920 Training err. 2.45045 Training err. RA 2.86508 Valid. err. 2.47363
2018-02-03 21:35:42,810 training [INFO ] Epoch 24 Batch 4940 Training err. 2.41507 Training err. RA 2.86326 Valid. err. 2.46018
2018-02-03 21:35:43,274 training [INFO ] Epoch 24 Batch 4960 Training err. 2.42984 Training err. RA 2.86151 Valid. err. 2.45507
2018-02-03 21:35:43,738 training [INFO ] Epoch 24 Batch 4980 Training err. 2.41618 Training err. RA 2.85972 Valid. err. 2.44853
2018-02-03 21:35:44,539 training [INFO ] Epoch 25 Batch 5000 Training err. 2.44303 Training err. RA 2.85805 Valid. err. 2.45366
2018-02-03 21:35:44,997 training [INFO ] Epoch 25 Batch 5020 Training err. 2.36495 Training err. RA 2.85609 Valid. err. 2.44786
2018-02-03 21:35:45,457 training [INFO ] Epoch 25 Batch 5040 Training err. 2.44598 Training err. RA 2.85446 Valid. err. 2.45968
2018-02-03 21:35:45,916 training [INFO ] Epoch 25 Batch 5060 Training err. 2.42539 Training err. RA 2.85277 Valid. err. 2.44313
2018-02-03 21:35:46,374 training [INFO ] Epoch 25 Batch 5080 Training err. 2.38364 Training err. RA 2.85092 Valid. err. 2.46081
2018-02-03 21:35:46,832 training [INFO ] Epoch 25 Batch 5100 Training err. 2.42582 Training err. RA 2.84925 Valid. err. 2.47568
2018-02-03 21:35:47,291 training [INFO ] Epoch 25 Batch 5120 Training err. 2.47045 Training err. RA 2.84777 Valid. err. 2.44162
2018-02-03 21:35:47,750 training [INFO ] Epoch 25 Batch 5140 Training err. 2.40825 Training err. RA 2.84606 Valid. err. 2.46393
2018-02-03 21:35:48,210 training [INFO ] Epoch 25 Batch 5160 Training err. 2.37110 Training err. RA 2.84422 Valid. err. 2.43661
2018-02-03 21:35:48,668 training [INFO ] Epoch 25 Batch 5180 Training err. 2.41860 Training err. RA 2.84258 Valid. err. 2.43456
2018-02-03 21:35:49,129 training [INFO ] Epoch 25 Batch 5200 Training err. 2.41311 Training err. RA 2.84093 Valid. err. 2.43333
2018-02-03 21:35:49,926 training [INFO ] Epoch 26 Batch 5220 Training err. 2.39073 Training err. RA 2.83920 Valid. err. 2.44398
2018-02-03 21:35:50,385 training [INFO ] Epoch 26 Batch 5240 Training err. 2.35554 Training err. RA 2.83736 Valid. err. 2.42749
2018-02-03 21:35:50,845 training [INFO ] Epoch 26 Batch 5260 Training err. 2.40301 Training err. RA 2.83570 Valid. err. 2.42507
2018-02-03 21:35:51,304 training [INFO ] Epoch 26 Batch 5280 Training err. 2.40898 Training err. RA 2.83409 Valid. err. 2.42603
2018-02-03 21:35:51,762 training [INFO ] Epoch 26 Batch 5300 Training err. 2.38530 Training err. RA 2.83239 Valid. err. 2.42195
2018-02-03 21:35:52,220 training [INFO ] Epoch 26 Batch 5320 Training err. 2.44901 Training err. RA 2.83095 Valid. err. 2.44372
2018-02-03 21:35:52,680 training [INFO ] Epoch 26 Batch 5340 Training err. 2.39443 Training err. RA 2.82932 Valid. err. 2.41930
2018-02-03 21:35:53,139 training [INFO ] Epoch 26 Batch 5360 Training err. 2.36369 Training err. RA 2.82758 Valid. err. 2.46959
2018-02-03 21:35:53,599 training [INFO ] Epoch 26 Batch 5380 Training err. 2.38928 Training err. RA 2.82595 Valid. err. 2.41724
2018-02-03 21:35:54,064 training [INFO ] Epoch 26 Batch 5400 Training err. 2.38398 Training err. RA 2.82431 Valid. err. 2.42619
2018-02-03 21:35:54,864 training [INFO ] Epoch 27 Batch 5420 Training err. 2.38923 Training err. RA 2.82271 Valid. err. 2.42933
2018-02-03 21:35:55,323 training [INFO ] Epoch 27 Batch 5440 Training err. 2.30077 Training err. RA 2.82079 Valid. err. 2.41449
2018-02-03 21:35:55,782 training [INFO ] Epoch 27 Batch 5460 Training err. 2.42102 Training err. RA 2.81933 Valid. err. 2.40407
2018-02-03 21:35:56,239 training [INFO ] Epoch 27 Batch 5480 Training err. 2.38244 Training err. RA 2.81773 Valid. err. 2.40359
2018-02-03 21:35:56,698 training [INFO ] Epoch 27 Batch 5500 Training err. 2.34946 Training err. RA 2.81603 Valid. err. 2.41029
2018-02-03 21:35:57,155 training [INFO ] Epoch 27 Batch 5520 Training err. 2.39503 Training err. RA 2.81450 Valid. err. 2.39880
2018-02-03 21:35:57,615 training [INFO ] Epoch 27 Batch 5540 Training err. 2.42685 Training err. RA 2.81310 Valid. err. 2.40450
2018-02-03 21:35:58,076 training [INFO ] Epoch 27 Batch 5560 Training err. 2.35884 Training err. RA 2.81147 Valid. err. 2.39752
2018-02-03 21:35:58,536 training [INFO ] Epoch 27 Batch 5580 Training err. 2.35598 Training err. RA 2.80984 Valid. err. 2.40768
2018-02-03 21:35:58,995 training [INFO ] Epoch 27 Batch 5600 Training err. 2.36447 Training err. RA 2.80825 Valid. err. 2.39959
2018-02-03 21:35:59,794 training [INFO ] Epoch 28 Batch 5620 Training err. 2.37035 Training err. RA 2.80669 Valid. err. 2.38565
2018-02-03 21:36:00,259 training [INFO ] Epoch 28 Batch 5640 Training err. 2.33785 Training err. RA 2.80503 Valid. err. 2.39778
2018-02-03 21:36:00,719 training [INFO ] Epoch 28 Batch 5660 Training err. 2.33997 Training err. RA 2.80338 Valid. err. 2.39201
2018-02-03 21:36:01,177 training [INFO ] Epoch 28 Batch 5680 Training err. 2.36732 Training err. RA 2.80185 Valid. err. 2.40098
2018-02-03 21:36:01,636 training [INFO ] Epoch 28 Batch 5700 Training err. 2.33632 Training err. RA 2.80021 Valid. err. 2.40959
2018-02-03 21:36:02,095 training [INFO ] Epoch 28 Batch 5720 Training err. 2.37423 Training err. RA 2.79872 Valid. err. 2.39748
2018-02-03 21:36:02,552 training [INFO ] Epoch 28 Batch 5740 Training err. 2.42287 Training err. RA 2.79741 Valid. err. 2.41265
2018-02-03 21:36:03,011 training [INFO ] Epoch 28 Batch 5760 Training err. 2.33486 Training err. RA 2.79581 Valid. err. 2.37866
2018-02-03 21:36:03,471 training [INFO ] Epoch 28 Batch 5780 Training err. 2.32099 Training err. RA 2.79417 Valid. err. 2.37870
2018-02-03 21:36:03,930 training [INFO ] Epoch 28 Batch 5800 Training err. 2.34964 Training err. RA 2.79263 Valid. err. 2.37557
2018-02-03 21:36:04,389 training [INFO ] Epoch 28 Batch 5820 Training err. 2.35808 Training err. RA 2.79114 Valid. err. 2.37351
2018-02-03 21:36:05,188 training [INFO ] Epoch 29 Batch 5840 Training err. 2.34015 Training err. RA 2.78959 Valid. err. 2.39376
2018-02-03 21:36:05,647 training [INFO ] Epoch 29 Batch 5860 Training err. 2.27806 Training err. RA 2.78785 Valid. err. 2.37514
2018-02-03 21:36:06,106 training [INFO ] Epoch 29 Batch 5880 Training err. 2.37118 Training err. RA 2.78643 Valid. err. 2.37860
2018-02-03 21:36:06,563 training [INFO ] Epoch 29 Batch 5900 Training err. 2.34526 Training err. RA 2.78494 Valid. err. 2.37529
2018-02-03 21:36:07,022 training [INFO ] Epoch 29 Batch 5920 Training err. 2.31499 Training err. RA 2.78335 Valid. err. 2.39257
2018-02-03 21:36:07,478 training [INFO ] Epoch 29 Batch 5940 Training err. 2.38959 Training err. RA 2.78202 Valid. err. 2.36976
2018-02-03 21:36:07,936 training [INFO ] Epoch 29 Batch 5960 Training err. 2.35928 Training err. RA 2.78060 Valid. err. 2.37566
2018-02-03 21:36:08,394 training [INFO ] Epoch 29 Batch 5980 Training err. 2.31821 Training err. RA 2.77906 Valid. err. 2.36322
2018-02-03 21:36:08,856 training [INFO ] Epoch 29 Batch 6000 Training err. 2.33170 Training err. RA 2.77757 Valid. err. 2.35695
2018-02-03 21:36:09,314 training [INFO ] Epoch 29 Batch 6020 Training err. 2.31806 Training err. RA 2.77604 Valid. err. 2.35201
2018-02-03 21:36:10,109 training [INFO ] Epoch 30 Batch 6040 Training err. 2.34223 Training err. RA 2.77460 Valid. err. 2.35818
2018-02-03 21:36:10,567 training [INFO ] Epoch 30 Batch 6060 Training err. 2.26644 Training err. RA 2.77293 Valid. err. 2.35234
2018-02-03 21:36:11,027 training [INFO ] Epoch 30 Batch 6080 Training err. 2.34688 Training err. RA 2.77152 Valid. err. 2.36876
2018-02-03 21:36:11,485 training [INFO ] Epoch 30 Batch 6100 Training err. 2.33439 Training err. RA 2.77009 Valid. err. 2.35078
2018-02-03 21:36:11,952 training [INFO ] Epoch 30 Batch 6120 Training err. 2.29027 Training err. RA 2.76852 Valid. err. 2.36188
2018-02-03 21:36:12,411 training [INFO ] Epoch 30 Batch 6140 Training err. 2.33257 Training err. RA 2.76710 Valid. err. 2.37792
2018-02-03 21:36:12,870 training [INFO ] Epoch 30 Batch 6160 Training err. 2.37981 Training err. RA 2.76585 Valid. err. 2.35212
2018-02-03 21:36:13,330 training [INFO ] Epoch 30 Batch 6180 Training err. 2.31714 Training err. RA 2.76439 Valid. err. 2.38176
2018-02-03 21:36:13,791 training [INFO ] Epoch 30 Batch 6200 Training err. 2.28318 Training err. RA 2.76284 Valid. err. 2.34214
2018-02-03 21:36:14,251 training [INFO ] Epoch 30 Batch 6220 Training err. 2.32271 Training err. RA 2.76143 Valid. err. 2.34413
2018-02-03 21:36:14,709 training [INFO ] Epoch 30 Batch 6240 Training err. 2.31629 Training err. RA 2.76000 Valid. err. 2.33989
2018-02-03 21:36:15,503 training [INFO ] Epoch 31 Batch 6260 Training err. 2.29910 Training err. RA 2.75853 Valid. err. 2.35084
2018-02-03 21:36:15,964 training [INFO ] Epoch 31 Batch 6280 Training err. 2.26248 Training err. RA 2.75695 Valid. err. 2.34072
2018-02-03 21:36:16,422 training [INFO ] Epoch 31 Batch 6300 Training err. 2.31374 Training err. RA 2.75554 Valid. err. 2.33451
2018-02-03 21:36:16,882 training [INFO ] Epoch 31 Batch 6320 Training err. 2.32259 Training err. RA 2.75417 Valid. err. 2.33821
2018-02-03 21:36:17,341 training [INFO ] Epoch 31 Batch 6340 Training err. 2.29668 Training err. RA 2.75273 Valid. err. 2.33311
2018-02-03 21:36:17,802 training [INFO ] Epoch 31 Batch 6360 Training err. 2.35848 Training err. RA 2.75149 Valid. err. 2.33244
2018-02-03 21:36:18,268 training [INFO ] Epoch 31 Batch 6380 Training err. 2.31088 Training err. RA 2.75011 Valid. err. 2.32976
2018-02-03 21:36:18,727 training [INFO ] Epoch 31 Batch 6400 Training err. 2.27937 Training err. RA 2.74863 Valid. err. 2.39372
2018-02-03 21:36:19,187 training [INFO ] Epoch 31 Batch 6420 Training err. 2.30100 Training err. RA 2.74724 Valid. err. 2.33186
2018-02-03 21:36:19,648 training [INFO ] Epoch 31 Batch 6440 Training err. 2.29664 Training err. RA 2.74584 Valid. err. 2.33779
2018-02-03 21:36:20,451 training [INFO ] Epoch 32 Batch 6460 Training err. 2.30061 Training err. RA 2.74446 Valid. err. 2.33758
2018-02-03 21:36:20,911 training [INFO ] Epoch 32 Batch 6480 Training err. 2.21357 Training err. RA 2.74282 Valid. err. 2.32738
2018-02-03 21:36:21,370 training [INFO ] Epoch 32 Batch 6500 Training err. 2.33023 Training err. RA 2.74155 Valid. err. 2.32058
2018-02-03 21:36:21,828 training [INFO ] Epoch 32 Batch 6520 Training err. 2.30255 Training err. RA 2.74021 Valid. err. 2.32106
2018-02-03 21:36:22,287 training [INFO ] Epoch 32 Batch 6540 Training err. 2.26501 Training err. RA 2.73875 Valid. err. 2.33090
2018-02-03 21:36:22,745 training [INFO ] Epoch 32 Batch 6560 Training err. 2.31204 Training err. RA 2.73745 Valid. err. 2.31242
2018-02-03 21:36:23,203 training [INFO ] Epoch 32 Batch 6580 Training err. 2.34425 Training err. RA 2.73626 Valid. err. 2.32531
2018-02-03 21:36:23,662 training [INFO ] Epoch 32 Batch 6600 Training err. 2.27665 Training err. RA 2.73487 Valid. err. 2.31394
2018-02-03 21:36:24,128 training [INFO ] Epoch 32 Batch 6620 Training err. 2.27586 Training err. RA 2.73348 Valid. err. 2.32242
2018-02-03 21:36:24,587 training [INFO ] Epoch 32 Batch 6640 Training err. 2.28117 Training err. RA 2.73212 Valid. err. 2.31365
2018-02-03 21:36:25,383 training [INFO ] Epoch 33 Batch 6660 Training err. 2.28412 Training err. RA 2.73077 Valid. err. 2.30329
2018-02-03 21:36:25,841 training [INFO ] Epoch 33 Batch 6680 Training err. 2.25208 Training err. RA 2.72934 Valid. err. 2.31366
2018-02-03 21:36:26,300 training [INFO ] Epoch 33 Batch 6700 Training err. 2.25915 Training err. RA 2.72793 Valid. err. 2.31168
2018-02-03 21:36:26,759 training [INFO ] Epoch 33 Batch 6720 Training err. 2.28796 Training err. RA 2.72663 Valid. err. 2.32735
2018-02-03 21:36:27,219 training [INFO ] Epoch 33 Batch 6740 Training err. 2.25841 Training err. RA 2.72524 Valid. err. 2.32520
2018-02-03 21:36:27,678 training [INFO ] Epoch 33 Batch 6760 Training err. 2.29401 Training err. RA 2.72396 Valid. err. 2.31604
2018-02-03 21:36:28,138 training [INFO ] Epoch 33 Batch 6780 Training err. 2.34300 Training err. RA 2.72284 Valid. err. 2.32373
2018-02-03 21:36:28,597 training [INFO ] Epoch 33 Batch 6800 Training err. 2.25737 Training err. RA 2.72147 Valid. err. 2.29881
2018-02-03 21:36:29,056 training [INFO ] Epoch 33 Batch 6820 Training err. 2.24680 Training err. RA 2.72008 Valid. err. 2.30170
2018-02-03 21:36:29,514 training [INFO ] Epoch 33 Batch 6840 Training err. 2.26970 Training err. RA 2.71876 Valid. err. 2.29741
2018-02-03 21:36:29,982 training [INFO ] Epoch 33 Batch 6860 Training err. 2.27739 Training err. RA 2.71747 Valid. err. 2.29149
2018-02-03 21:36:30,780 training [INFO ] Epoch 34 Batch 6880 Training err. 2.25997 Training err. RA 2.71614 Valid. err. 2.30969
2018-02-03 21:36:31,237 training [INFO ] Epoch 34 Batch 6900 Training err. 2.20032 Training err. RA 2.71465 Valid. err. 2.29623
2018-02-03 21:36:31,695 training [INFO ] Epoch 34 Batch 6920 Training err. 2.29015 Training err. RA 2.71342 Valid. err. 2.30272
2018-02-03 21:36:32,154 training [INFO ] Epoch 34 Batch 6940 Training err. 2.26985 Training err. RA 2.71214 Valid. err. 2.30114
2018-02-03 21:36:32,611 training [INFO ] Epoch 34 Batch 6960 Training err. 2.24278 Training err. RA 2.71079 Valid. err. 2.32017
2018-02-03 21:36:33,071 training [INFO ] Epoch 34 Batch 6980 Training err. 2.31540 Training err. RA 2.70966 Valid. err. 2.29506
2018-02-03 21:36:33,529 training [INFO ] Epoch 34 Batch 7000 Training err. 2.28412 Training err. RA 2.70844 Valid. err. 2.30339
2018-02-03 21:36:33,987 training [INFO ] Epoch 34 Batch 7020 Training err. 2.24298 Training err. RA 2.70712 Valid. err. 2.29701
2018-02-03 21:36:34,445 training [INFO ] Epoch 34 Batch 7040 Training err. 2.25911 Training err. RA 2.70584 Valid. err. 2.28331
2018-02-03 21:36:34,903 training [INFO ] Epoch 34 Batch 7060 Training err. 2.24371 Training err. RA 2.70454 Valid. err. 2.27995
2018-02-03 21:36:35,700 training [INFO ] Epoch 35 Batch 7080 Training err. 2.26383 Training err. RA 2.70329 Valid. err. 2.28167
2018-02-03 21:36:36,160 training [INFO ] Epoch 35 Batch 7100 Training err. 2.19122 Training err. RA 2.70185 Valid. err. 2.27937
2018-02-03 21:36:36,619 training [INFO ] Epoch 35 Batch 7120 Training err. 2.27069 Training err. RA 2.70064 Valid. err. 2.28970
2018-02-03 21:36:37,080 training [INFO ] Epoch 35 Batch 7140 Training err. 2.26155 Training err. RA 2.69941 Valid. err. 2.28085
2018-02-03 21:36:37,539 training [INFO ] Epoch 35 Batch 7160 Training err. 2.21984 Training err. RA 2.69807 Valid. err. 2.28529
2018-02-03 21:36:37,997 training [INFO ] Epoch 35 Batch 7180 Training err. 2.25872 Training err. RA 2.69684 Valid. err. 2.30149
2018-02-03 21:36:38,456 training [INFO ] Epoch 35 Batch 7200 Training err. 2.31182 Training err. RA 2.69577 Valid. err. 2.27765
2018-02-03 21:36:38,916 training [INFO ] Epoch 35 Batch 7220 Training err. 2.24507 Training err. RA 2.69453 Valid. err. 2.30435
2018-02-03 21:36:39,375 training [INFO ] Epoch 35 Batch 7240 Training err. 2.21573 Training err. RA 2.69320 Valid. err. 2.27069
2018-02-03 21:36:39,835 training [INFO ] Epoch 35 Batch 7260 Training err. 2.25009 Training err. RA 2.69198 Valid. err. 2.27179
2018-02-03 21:36:40,294 training [INFO ] Epoch 35 Batch 7280 Training err. 2.24022 Training err. RA 2.69074 Valid. err. 2.26747
2018-02-03 21:36:41,093 training [INFO ] Epoch 36 Batch 7300 Training err. 2.22848 Training err. RA 2.68947 Valid. err. 2.27835
2018-02-03 21:36:41,553 training [INFO ] Epoch 36 Batch 7320 Training err. 2.19113 Training err. RA 2.68811 Valid. err. 2.27305
2018-02-03 21:36:42,013 training [INFO ] Epoch 36 Batch 7340 Training err. 2.24263 Training err. RA 2.68690 Valid. err. 2.26559
2018-02-03 21:36:42,472 training [INFO ] Epoch 36 Batch 7360 Training err. 2.25332 Training err. RA 2.68572 Valid. err. 2.27062
2018-02-03 21:36:42,932 training [INFO ] Epoch 36 Batch 7380 Training err. 2.22820 Training err. RA 2.68448 Valid. err. 2.26343
2018-02-03 21:36:43,392 training [INFO ] Epoch 36 Batch 7400 Training err. 2.29287 Training err. RA 2.68342 Valid. err. 2.26239
2018-02-03 21:36:43,851 training [INFO ] Epoch 36 Batch 7420 Training err. 2.24256 Training err. RA 2.68223 Valid. err. 2.26100
2018-02-03 21:36:44,311 training [INFO ] Epoch 36 Batch 7440 Training err. 2.21304 Training err. RA 2.68097 Valid. err. 2.31781
2018-02-03 21:36:44,771 training [INFO ] Epoch 36 Batch 7460 Training err. 2.23239 Training err. RA 2.67977 Valid. err. 2.26624
2018-02-03 21:36:45,229 training [INFO ] Epoch 36 Batch 7480 Training err. 2.22798 Training err. RA 2.67856 Valid. err. 2.26500
2018-02-03 21:36:46,027 training [INFO ] Epoch 37 Batch 7500 Training err. 2.23162 Training err. RA 2.67737 Valid. err. 2.26642
2018-02-03 21:36:46,485 training [INFO ] Epoch 37 Batch 7520 Training err. 2.14700 Training err. RA 2.67596 Valid. err. 2.26211
2018-02-03 21:36:46,944 training [INFO ] Epoch 37 Batch 7540 Training err. 2.25736 Training err. RA 2.67485 Valid. err. 2.25360
2018-02-03 21:36:47,403 training [INFO ] Epoch 37 Batch 7560 Training err. 2.23624 Training err. RA 2.67369 Valid. err. 2.25657
2018-02-03 21:36:47,870 training [INFO ] Epoch 37 Batch 7580 Training err. 2.20085 Training err. RA 2.67244 Valid. err. 2.26552
2018-02-03 21:36:48,334 training [INFO ] Epoch 37 Batch 7600 Training err. 2.24526 Training err. RA 2.67132 Valid. err. 2.25053
2018-02-03 21:36:48,797 training [INFO ] Epoch 37 Batch 7620 Training err. 2.28288 Training err. RA 2.67030 Valid. err. 2.25387
2018-02-03 21:36:49,261 training [INFO ] Epoch 37 Batch 7640 Training err. 2.20889 Training err. RA 2.66909 Valid. err. 2.24821
2018-02-03 21:36:49,726 training [INFO ] Epoch 37 Batch 7660 Training err. 2.21433 Training err. RA 2.66790 Valid. err. 2.25929
2018-02-03 21:36:50,189 training [INFO ] Epoch 37 Batch 7680 Training err. 2.21609 Training err. RA 2.66673 Valid. err. 2.24766
2018-02-03 21:36:51,001 training [INFO ] Epoch 38 Batch 7700 Training err. 2.21645 Training err. RA 2.66556 Valid. err. 2.24015
2018-02-03 21:36:51,464 training [INFO ] Epoch 38 Batch 7720 Training err. 2.18628 Training err. RA 2.66432 Valid. err. 2.24495
2018-02-03 21:36:51,929 training [INFO ] Epoch 38 Batch 7740 Training err. 2.19492 Training err. RA 2.66310 Valid. err. 2.24692
2018-02-03 21:36:52,387 training [INFO ] Epoch 38 Batch 7760 Training err. 2.22406 Training err. RA 2.66197 Valid. err. 2.25432
2018-02-03 21:36:52,846 training [INFO ] Epoch 38 Batch 7780 Training err. 2.19492 Training err. RA 2.66077 Valid. err. 2.25999
2018-02-03 21:36:53,304 training [INFO ] Epoch 38 Batch 7800 Training err. 2.22852 Training err. RA 2.65966 Valid. err. 2.24921
2018-02-03 21:36:53,763 training [INFO ] Epoch 38 Batch 7820 Training err. 2.28469 Training err. RA 2.65870 Valid. err. 2.24863
2018-02-03 21:36:54,228 training [INFO ] Epoch 38 Batch 7840 Training err. 2.19358 Training err. RA 2.65752 Valid. err. 2.23516
2018-02-03 21:36:54,686 training [INFO ] Epoch 38 Batch 7860 Training err. 2.18644 Training err. RA 2.65632 Valid. err. 2.24037
2018-02-03 21:36:55,145 training [INFO ] Epoch 38 Batch 7880 Training err. 2.20771 Training err. RA 2.65518 Valid. err. 2.23433
2018-02-03 21:36:55,604 training [INFO ] Epoch 38 Batch 7900 Training err. 2.21267 Training err. RA 2.65406 Valid. err. 2.23008
2018-02-03 21:36:56,403 training [INFO ] Epoch 39 Batch 7920 Training err. 2.19910 Training err. RA 2.65291 Valid. err. 2.24107
2018-02-03 21:36:56,862 training [INFO ] Epoch 39 Batch 7940 Training err. 2.14035 Training err. RA 2.65162 Valid. err. 2.23154
2018-02-03 21:36:57,322 training [INFO ] Epoch 39 Batch 7960 Training err. 2.22474 Training err. RA 2.65055 Valid. err. 2.24006
2018-02-03 21:36:57,780 training [INFO ] Epoch 39 Batch 7980 Training err. 2.20631 Training err. RA 2.64943 Valid. err. 2.24260
2018-02-03 21:36:58,240 training [INFO ] Epoch 39 Batch 8000 Training err. 2.18587 Training err. RA 2.64827 Valid. err. 2.26359
2018-02-03 21:36:58,699 training [INFO ] Epoch 39 Batch 8020 Training err. 2.25489 Training err. RA 2.64729 Valid. err. 2.24730
2018-02-03 21:36:59,160 training [INFO ] Epoch 39 Batch 8040 Training err. 2.22596 Training err. RA 2.64624 Valid. err. 2.23825
2018-02-03 21:36:59,618 training [INFO ] Epoch 39 Batch 8060 Training err. 2.18217 Training err. RA 2.64509 Valid. err. 2.24575
2018-02-03 21:37:00,078 training [INFO ] Epoch 39 Batch 8080 Training err. 2.20150 Training err. RA 2.64400 Valid. err. 2.22351
2018-02-03 21:37:00,543 training [INFO ] Epoch 39 Batch 8100 Training err. 2.18458 Training err. RA 2.64286 Valid. err. 2.22027
2018-02-03 21:37:01,342 training [INFO ] Epoch 40 Batch 8120 Training err. 2.20315 Training err. RA 2.64178 Valid. err. 2.22149
2018-02-03 21:37:01,801 training [INFO ] Epoch 40 Batch 8140 Training err. 2.13295 Training err. RA 2.64053 Valid. err. 2.22011
2018-02-03 21:37:02,261 training [INFO ] Epoch 40 Batch 8160 Training err. 2.20921 Training err. RA 2.63947 Valid. err. 2.22967
2018-02-03 21:37:02,719 training [INFO ] Epoch 40 Batch 8180 Training err. 2.20167 Training err. RA 2.63840 Valid. err. 2.22587
2018-02-03 21:37:03,179 training [INFO ] Epoch 40 Batch 8200 Training err. 2.16409 Training err. RA 2.63724 Valid. err. 2.22404
2018-02-03 21:37:03,639 training [INFO ] Epoch 40 Batch 8220 Training err. 2.19638 Training err. RA 2.63617 Valid. err. 2.24204
2018-02-03 21:37:04,098 training [INFO ] Epoch 40 Batch 8240 Training err. 2.25822 Training err. RA 2.63525 Valid. err. 2.21805
2018-02-03 21:37:04,559 training [INFO ] Epoch 40 Batch 8260 Training err. 2.18771 Training err. RA 2.63417 Valid. err. 2.23744
2018-02-03 21:37:05,023 training [INFO ] Epoch 40 Batch 8280 Training err. 2.16026 Training err. RA 2.63302 Valid. err. 2.21367
2018-02-03 21:37:05,486 training [INFO ] Epoch 40 Batch 8300 Training err. 2.19360 Training err. RA 2.63197 Valid. err. 2.21187
2018-02-03 21:37:05,951 training [INFO ] Epoch 40 Batch 8320 Training err. 2.17924 Training err. RA 2.63088 Valid. err. 2.21156
2018-02-03 21:37:06,761 training [INFO ] Epoch 41 Batch 8340 Training err. 2.17481 Training err. RA 2.62978 Valid. err. 2.21593
2018-02-03 21:37:07,233 training [INFO ] Epoch 41 Batch 8360 Training err. 2.13405 Training err. RA 2.62860 Valid. err. 2.21658
2018-02-03 21:37:07,698 training [INFO ] Epoch 41 Batch 8380 Training err. 2.18589 Training err. RA 2.62754 Valid. err. 2.20967
2018-02-03 21:37:08,159 training [INFO ] Epoch 41 Batch 8400 Training err. 2.19554 Training err. RA 2.62651 Valid. err. 2.21409
2018-02-03 21:37:08,618 training [INFO ] Epoch 41 Batch 8420 Training err. 2.17188 Training err. RA 2.62543 Valid. err. 2.20654
2018-02-03 21:37:09,077 training [INFO ] Epoch 41 Batch 8440 Training err. 2.23832 Training err. RA 2.62452 Valid. err. 2.21023
2018-02-03 21:37:09,536 training [INFO ] Epoch 41 Batch 8460 Training err. 2.18923 Training err. RA 2.62349 Valid. err. 2.20536
2018-02-03 21:37:09,996 training [INFO ] Epoch 41 Batch 8480 Training err. 2.15898 Training err. RA 2.62239 Valid. err. 2.25609
2018-02-03 21:37:10,456 training [INFO ] Epoch 41 Batch 8500 Training err. 2.17773 Training err. RA 2.62134 Valid. err. 2.21248
2018-02-03 21:37:10,916 training [INFO ] Epoch 41 Batch 8520 Training err. 2.17149 Training err. RA 2.62029 Valid. err. 2.20716
2018-02-03 21:37:11,723 training [INFO ] Epoch 42 Batch 8540 Training err. 2.17957 Training err. RA 2.61926 Valid. err. 2.20863
2018-02-03 21:37:12,189 training [INFO ] Epoch 42 Batch 8560 Training err. 2.09460 Training err. RA 2.61803 Valid. err. 2.20659
2018-02-03 21:37:12,654 training [INFO ] Epoch 42 Batch 8580 Training err. 2.19852 Training err. RA 2.61705 Valid. err. 2.19803
2018-02-03 21:37:13,118 training [INFO ] Epoch 42 Batch 8600 Training err. 2.18169 Training err. RA 2.61604 Valid. err. 2.20331
2018-02-03 21:37:13,581 training [INFO ] Epoch 42 Batch 8620 Training err. 2.14922 Training err. RA 2.61496 Valid. err. 2.20830
2018-02-03 21:37:14,046 training [INFO ] Epoch 42 Batch 8640 Training err. 2.18880 Training err. RA 2.61397 Valid. err. 2.19978
2018-02-03 21:37:14,509 training [INFO ] Epoch 42 Batch 8660 Training err. 2.23331 Training err. RA 2.61309 Valid. err. 2.19981
2018-02-03 21:37:14,972 training [INFO ] Epoch 42 Batch 8680 Training err. 2.15548 Training err. RA 2.61204 Valid. err. 2.19502
2018-02-03 21:37:15,436 training [INFO ] Epoch 42 Batch 8700 Training err. 2.16326 Training err. RA 2.61101 Valid. err. 2.21209
2018-02-03 21:37:15,900 training [INFO ] Epoch 42 Batch 8720 Training err. 2.16271 Training err. RA 2.60998 Valid. err. 2.19493
2018-02-03 21:37:16,698 training [INFO ] Epoch 43 Batch 8740 Training err. 2.16357 Training err. RA 2.60896 Valid. err. 2.18801
2018-02-03 21:37:17,156 training [INFO ] Epoch 43 Batch 8760 Training err. 2.13389 Training err. RA 2.60787 Valid. err. 2.19057
2018-02-03 21:37:17,616 training [INFO ] Epoch 43 Batch 8780 Training err. 2.14246 Training err. RA 2.60681 Valid. err. 2.19179
2018-02-03 21:37:18,076 training [INFO ] Epoch 43 Batch 8800 Training err. 2.17260 Training err. RA 2.60582 Valid. err. 2.19489
2018-02-03 21:37:18,535 training [INFO ] Epoch 43 Batch 8820 Training err. 2.14369 Training err. RA 2.60478 Valid. err. 2.20645
2018-02-03 21:37:18,993 training [INFO ] Epoch 43 Batch 8840 Training err. 2.17329 Training err. RA 2.60380 Valid. err. 2.19531
2018-02-03 21:37:19,451 training [INFO ] Epoch 43 Batch 8860 Training err. 2.23587 Training err. RA 2.60297 Valid. err. 2.19261
2018-02-03 21:37:19,910 training [INFO ] Epoch 43 Batch 8880 Training err. 2.14362 Training err. RA 2.60194 Valid. err. 2.18289
2018-02-03 21:37:20,371 training [INFO ] Epoch 43 Batch 8900 Training err. 2.13683 Training err. RA 2.60089 Valid. err. 2.18836
2018-02-03 21:37:20,830 training [INFO ] Epoch 43 Batch 8920 Training err. 2.15711 Training err. RA 2.59990 Valid. err. 2.18247
2018-02-03 21:37:21,291 training [INFO ] Epoch 43 Batch 8940 Training err. 2.15867 Training err. RA 2.59891 Valid. err. 2.18106
2018-02-03 21:37:22,095 training [INFO ] Epoch 44 Batch 8960 Training err. 2.15009 Training err. RA 2.59791 Valid. err. 2.18781
2018-02-03 21:37:22,557 training [INFO ] Epoch 44 Batch 8980 Training err. 2.09302 Training err. RA 2.59678 Valid. err. 2.18073
2018-02-03 21:37:23,015 training [INFO ] Epoch 44 Batch 9000 Training err. 2.17167 Training err. RA 2.59584 Valid. err. 2.18682
2018-02-03 21:37:23,475 training [INFO ] Epoch 44 Batch 9020 Training err. 2.15653 Training err. RA 2.59486 Valid. err. 2.18683
2018-02-03 21:37:23,941 training [INFO ] Epoch 44 Batch 9040 Training err. 2.13721 Training err. RA 2.59385 Valid. err. 2.20755
2018-02-03 21:37:24,399 training [INFO ] Epoch 44 Batch 9060 Training err. 2.20399 Training err. RA 2.59299 Valid. err. 2.20365
2018-02-03 21:37:24,858 training [INFO ] Epoch 44 Batch 9080 Training err. 2.17902 Training err. RA 2.59208 Valid. err. 2.18699
2018-02-03 21:37:25,317 training [INFO ] Epoch 44 Batch 9100 Training err. 2.13364 Training err. RA 2.59107 Valid. err. 2.19494
2018-02-03 21:37:25,776 training [INFO ] Epoch 44 Batch 9120 Training err. 2.15305 Training err. RA 2.59011 Valid. err. 2.17316
2018-02-03 21:37:26,233 training [INFO ] Epoch 44 Batch 9140 Training err. 2.13418 Training err. RA 2.58911 Valid. err. 2.17092
2018-02-03 21:37:27,030 training [INFO ] Epoch 45 Batch 9160 Training err. 2.15471 Training err. RA 2.58816 Valid. err. 2.17132
2018-02-03 21:37:27,490 training [INFO ] Epoch 45 Batch 9180 Training err. 2.08435 Training err. RA 2.58707 Valid. err. 2.17137
2018-02-03 21:37:27,949 training [INFO ] Epoch 45 Batch 9200 Training err. 2.15965 Training err. RA 2.58614 Valid. err. 2.18044
2018-02-03 21:37:28,408 training [INFO ] Epoch 45 Batch 9220 Training err. 2.15490 Training err. RA 2.58520 Valid. err. 2.19108
2018-02-03 21:37:28,868 training [INFO ] Epoch 45 Batch 9240 Training err. 2.11800 Training err. RA 2.58419 Valid. err. 2.17374
2018-02-03 21:37:29,326 training [INFO ] Epoch 45 Batch 9260 Training err. 2.14442 Training err. RA 2.58324 Valid. err. 2.19299
2018-02-03 21:37:29,785 training [INFO ] Epoch 45 Batch 9280 Training err. 2.21232 Training err. RA 2.58244 Valid. err. 2.16974
2018-02-03 21:37:30,244 training [INFO ] Epoch 45 Batch 9300 Training err. 2.14252 Training err. RA 2.58149 Valid. err. 2.18278
2018-02-03 21:37:30,703 training [INFO ] Epoch 45 Batch 9320 Training err. 2.11319 Training err. RA 2.58049 Valid. err. 2.16535
2018-02-03 21:37:31,162 training [INFO ] Epoch 45 Batch 9340 Training err. 2.14544 Training err. RA 2.57956 Valid. err. 2.16227
2018-02-03 21:37:31,622 training [INFO ] Epoch 45 Batch 9360 Training err. 2.12896 Training err. RA 2.57860 Valid. err. 2.16439
2018-02-03 21:37:32,418 training [INFO ] Epoch 46 Batch 9380 Training err. 2.12876 Training err. RA 2.57764 Valid. err. 2.16707
2018-02-03 21:37:32,883 training [INFO ] Epoch 46 Batch 9400 Training err. 2.08835 Training err. RA 2.57660 Valid. err. 2.16895
2018-02-03 21:37:33,342 training [INFO ] Epoch 46 Batch 9420 Training err. 2.14029 Training err. RA 2.57567 Valid. err. 2.16364
2018-02-03 21:37:33,801 training [INFO ] Epoch 46 Batch 9440 Training err. 2.15054 Training err. RA 2.57477 Valid. err. 2.16700
2018-02-03 21:37:34,259 training [INFO ] Epoch 46 Batch 9460 Training err. 2.12386 Training err. RA 2.57382 Valid. err. 2.16009
2018-02-03 21:37:34,718 training [INFO ] Epoch 46 Batch 9480 Training err. 2.19165 Training err. RA 2.57301 Valid. err. 2.16542
2018-02-03 21:37:35,177 training [INFO ] Epoch 46 Batch 9500 Training err. 2.14618 Training err. RA 2.57211 Valid. err. 2.16035
2018-02-03 21:37:35,636 training [INFO ] Epoch 46 Batch 9520 Training err. 2.11357 Training err. RA 2.57115 Valid. err. 2.21301
2018-02-03 21:37:36,101 training [INFO ] Epoch 46 Batch 9540 Training err. 2.13227 Training err. RA 2.57023 Valid. err. 2.16840
2018-02-03 21:37:36,560 training [INFO ] Epoch 46 Batch 9560 Training err. 2.12341 Training err. RA 2.56929 Valid. err. 2.16154
2018-02-03 21:37:37,360 training [INFO ] Epoch 47 Batch 9580 Training err. 2.13388 Training err. RA 2.56838 Valid. err. 2.15717
2018-02-03 21:37:37,820 training [INFO ] Epoch 47 Batch 9600 Training err. 2.05210 Training err. RA 2.56731 Valid. err. 2.16111
2018-02-03 21:37:38,280 training [INFO ] Epoch 47 Batch 9620 Training err. 2.15177 Training err. RA 2.56644 Valid. err. 2.15207
2018-02-03 21:37:38,739 training [INFO ] Epoch 47 Batch 9640 Training err. 2.13959 Training err. RA 2.56556 Valid. err. 2.15953
2018-02-03 21:37:39,198 training [INFO ] Epoch 47 Batch 9660 Training err. 2.10628 Training err. RA 2.56461 Valid. err. 2.16049
2018-02-03 21:37:39,658 training [INFO ] Epoch 47 Batch 9680 Training err. 2.14175 Training err. RA 2.56373 Valid. err. 2.15612
2018-02-03 21:37:40,118 training [INFO ] Epoch 47 Batch 9700 Training err. 2.19028 Training err. RA 2.56296 Valid. err. 2.15415
2018-02-03 21:37:40,578 training [INFO ] Epoch 47 Batch 9720 Training err. 2.11280 Training err. RA 2.56204 Valid. err. 2.15221
2018-02-03 21:37:41,038 training [INFO ] Epoch 47 Batch 9740 Training err. 2.11901 Training err. RA 2.56113 Valid. err. 2.17150
2018-02-03 21:37:41,497 training [INFO ] Epoch 47 Batch 9760 Training err. 2.11700 Training err. RA 2.56022 Valid. err. 2.15237
2018-02-03 21:37:42,298 training [INFO ] Epoch 48 Batch 9780 Training err. 2.11991 Training err. RA 2.55932 Valid. err. 2.14436
2018-02-03 21:37:42,756 training [INFO ] Epoch 48 Batch 9800 Training err. 2.08797 Training err. RA 2.55836 Valid. err. 2.14620
2018-02-03 21:37:43,217 training [INFO ] Epoch 48 Batch 9820 Training err. 2.10051 Training err. RA 2.55742 Valid. err. 2.14778
2018-02-03 21:37:43,675 training [INFO ] Epoch 48 Batch 9840 Training err. 2.13095 Training err. RA 2.55656 Valid. err. 2.15314
2018-02-03 21:37:44,133 training [INFO ] Epoch 48 Batch 9860 Training err. 2.10403 Training err. RA 2.55564 Valid. err. 2.15826
2018-02-03 21:37:44,592 training [INFO ] Epoch 48 Batch 9880 Training err. 2.12715 Training err. RA 2.55477 Valid. err. 2.15188
2018-02-03 21:37:45,052 training [INFO ] Epoch 48 Batch 9900 Training err. 2.19330 Training err. RA 2.55404 Valid. err. 2.14963
2018-02-03 21:37:45,510 training [INFO ] Epoch 48 Batch 9920 Training err. 2.10277 Training err. RA 2.55313 Valid. err. 2.14038
2018-02-03 21:37:45,966 training [INFO ] Epoch 48 Batch 9940 Training err. 2.09493 Training err. RA 2.55221 Valid. err. 2.14482
2018-02-03 21:37:46,425 training [INFO ] Epoch 48 Batch 9960 Training err. 2.11402 Training err. RA 2.55133 Valid. err. 2.14083
2018-02-03 21:37:46,883 training [INFO ] Epoch 48 Batch 9980 Training err. 2.11352 Training err. RA 2.55045 Valid. err. 2.14182
2018-02-03 21:37:47,682 training [INFO ] Epoch 49 Batch10000 Training err. 2.10708 Training err. RA 2.54956 Valid. err. 2.14558
2018-02-03 21:37:48,142 training [INFO ] Epoch 49 Batch10020 Training err. 2.05470 Training err. RA 2.54858 Valid. err. 2.13979
2018-02-03 21:37:48,603 training [INFO ] Epoch 49 Batch10040 Training err. 2.12926 Training err. RA 2.54774 Valid. err. 2.14435
2018-02-03 21:37:49,067 training [INFO ] Epoch 49 Batch10060 Training err. 2.11767 Training err. RA 2.54689 Valid. err. 2.14481
2018-02-03 21:37:49,530 training [INFO ] Epoch 49 Batch10080 Training err. 2.09651 Training err. RA 2.54599 Valid. err. 2.15656
2018-02-03 21:37:49,993 training [INFO ] Epoch 49 Batch10100 Training err. 2.16120 Training err. RA 2.54523 Valid. err. 2.16503
2018-02-03 21:37:50,455 training [INFO ] Epoch 49 Batch10120 Training err. 2.13937 Training err. RA 2.54443 Valid. err. 2.14645
2018-02-03 21:37:50,919 training [INFO ] Epoch 49 Batch10140 Training err. 2.09316 Training err. RA 2.54354 Valid. err. 2.15030
2018-02-03 21:37:51,382 training [INFO ] Epoch 49 Batch10160 Training err. 2.11109 Training err. RA 2.54269 Valid. err. 2.13206
2018-02-03 21:37:51,846 training [INFO ] Epoch 49 Batch10180 Training err. 2.09150 Training err. RA 2.54180 Valid. err. 2.13137
2018-02-03 21:37:52,645 training [INFO ] Epoch 50 Batch10200 Training err. 2.11503 Training err. RA 2.54096 Valid. err. 2.13015
2018-02-03 21:37:53,104 training [INFO ] Epoch 50 Batch10220 Training err. 2.04311 Training err. RA 2.53999 Valid. err. 2.13187
2018-02-03 21:37:53,562 training [INFO ] Epoch 50 Batch10240 Training err. 2.12014 Training err. RA 2.53917 Valid. err. 2.13897
2018-02-03 21:37:54,021 training [INFO ] Epoch 50 Batch10260 Training err. 2.11728 Training err. RA 2.53835 Valid. err. 2.15322
2018-02-03 21:37:54,480 training [INFO ] Epoch 50 Batch10280 Training err. 2.08018 Training err. RA 2.53746 Valid. err. 2.13317
2018-02-03 21:37:54,939 training [INFO ] Epoch 50 Batch10300 Training err. 2.10186 Training err. RA 2.53661 Valid. err. 2.15083
2018-02-03 21:37:55,396 training [INFO ] Epoch 50 Batch10320 Training err. 2.17291 Training err. RA 2.53591 Valid. err. 2.13001
2018-02-03 21:37:55,856 training [INFO ] Epoch 50 Batch10340 Training err. 2.10465 Training err. RA 2.53507 Valid. err. 2.13882
2018-02-03 21:37:56,315 training [INFO ] Epoch 50 Batch10360 Training err. 2.07272 Training err. RA 2.53418 Valid. err. 2.12618
2018-02-03 21:37:56,772 training [INFO ] Epoch 50 Batch10380 Training err. 2.10431 Training err. RA 2.53335 Valid. err. 2.12302
2018-02-03 21:37:57,231 training [INFO ] Epoch 50 Batch10400 Training err. 2.08731 Training err. RA 2.53249 Valid. err. 2.12503
2018-02-03 21:37:58,028 training [INFO ] Epoch 51 Batch10420 Training err. 2.09130 Training err. RA 2.53165 Valid. err. 2.12840
2018-02-03 21:37:58,489 training [INFO ] Epoch 51 Batch10440 Training err. 2.05115 Training err. RA 2.53073 Valid. err. 2.12931
2018-02-03 21:37:58,950 training [INFO ] Epoch 51 Batch10460 Training err. 2.10302 Training err. RA 2.52991 Valid. err. 2.12652
2018-02-03 21:37:59,409 training [INFO ] Epoch 51 Batch10480 Training err. 2.11437 Training err. RA 2.52911 Valid. err. 2.12851
2018-02-03 21:37:59,876 training [INFO ] Epoch 51 Batch10500 Training err. 2.08364 Training err. RA 2.52827 Valid. err. 2.12239
2018-02-03 21:38:00,343 training [INFO ] Epoch 51 Batch10520 Training err. 2.15246 Training err. RA 2.52755 Valid. err. 2.13064
2018-02-03 21:38:00,802 training [INFO ] Epoch 51 Batch10540 Training err. 2.10961 Training err. RA 2.52676 Valid. err. 2.12277
2018-02-03 21:38:01,261 training [INFO ] Epoch 51 Batch10560 Training err. 2.07467 Training err. RA 2.52590 Valid. err. 2.17741
2018-02-03 21:38:01,720 training [INFO ] Epoch 51 Batch10580 Training err. 2.09254 Training err. RA 2.52508 Valid. err. 2.13241
2018-02-03 21:38:02,179 training [INFO ] Epoch 51 Batch10600 Training err. 2.08358 Training err. RA 2.52425 Valid. err. 2.12523
2018-02-03 21:38:02,982 training [INFO ] Epoch 52 Batch10620 Training err. 2.09792 Training err. RA 2.52345 Valid. err. 2.11738
2018-02-03 21:38:03,442 training [INFO ] Epoch 52 Batch10640 Training err. 2.01685 Training err. RA 2.52249 Valid. err. 2.12471
2018-02-03 21:38:03,902 training [INFO ] Epoch 52 Batch10660 Training err. 2.11402 Training err. RA 2.52173 Valid. err. 2.11459
2018-02-03 21:38:04,363 training [INFO ] Epoch 52 Batch10680 Training err. 2.10433 Training err. RA 2.52095 Valid. err. 2.12438
2018-02-03 21:38:04,824 training [INFO ] Epoch 52 Batch10700 Training err. 2.07065 Training err. RA 2.52011 Valid. err. 2.12151
2018-02-03 21:38:05,289 training [INFO ] Epoch 52 Batch10720 Training err. 2.10290 Training err. RA 2.51933 Valid. err. 2.12059
2018-02-03 21:38:05,755 training [INFO ] Epoch 52 Batch10740 Training err. 2.15336 Training err. RA 2.51865 Valid. err. 2.11701
2018-02-03 21:38:06,223 training [INFO ] Epoch 52 Batch10760 Training err. 2.07642 Training err. RA 2.51782 Valid. err. 2.11867
2018-02-03 21:38:06,682 training [INFO ] Epoch 52 Batch10780 Training err. 2.08002 Training err. RA 2.51701 Valid. err. 2.13427
2018-02-03 21:38:07,141 training [INFO ] Epoch 52 Batch10800 Training err. 2.07833 Training err. RA 2.51620 Valid. err. 2.11690
2018-02-03 21:38:07,943 training [INFO ] Epoch 53 Batch10820 Training err. 2.08503 Training err. RA 2.51540 Valid. err. 2.10992
2018-02-03 21:38:08,403 training [INFO ] Epoch 53 Batch10840 Training err. 2.05160 Training err. RA 2.51455 Valid. err. 2.10993
2018-02-03 21:38:08,866 training [INFO ] Epoch 53 Batch10860 Training err. 2.06575 Training err. RA 2.51372 Valid. err. 2.11182
2018-02-03 21:38:09,335 training [INFO ] Epoch 53 Batch10880 Training err. 2.09636 Training err. RA 2.51295 Valid. err. 2.11923
2018-02-03 21:38:09,800 training [INFO ] Epoch 53 Batch10900 Training err. 2.07050 Training err. RA 2.51214 Valid. err. 2.11873
2018-02-03 21:38:10,263 training [INFO ] Epoch 53 Batch10920 Training err. 2.08886 Training err. RA 2.51137 Valid. err. 2.11706
2018-02-03 21:38:10,726 training [INFO ] Epoch 53 Batch10940 Training err. 2.15721 Training err. RA 2.51072 Valid. err. 2.11255
2018-02-03 21:38:11,189 training [INFO ] Epoch 53 Batch10960 Training err. 2.06726 Training err. RA 2.50991 Valid. err. 2.10602
2018-02-03 21:38:11,653 training [INFO ] Epoch 53 Batch10980 Training err. 2.05845 Training err. RA 2.50909 Valid. err. 2.10920
2018-02-03 21:38:12,116 training [INFO ] Epoch 53 Batch11000 Training err. 2.07626 Training err. RA 2.50830 Valid. err. 2.10643
2018-02-03 21:38:12,576 training [INFO ] Epoch 53 Batch11020 Training err. 2.07605 Training err. RA 2.50751 Valid. err. 2.10902
2018-02-03 21:38:13,376 training [INFO ] Epoch 54 Batch11040 Training err. 2.07462 Training err. RA 2.50673 Valid. err. 2.11096
2018-02-03 21:38:13,836 training [INFO ] Epoch 54 Batch11060 Training err. 2.02215 Training err. RA 2.50585 Valid. err. 2.10703
2018-02-03 21:38:14,297 training [INFO ] Epoch 54 Batch11080 Training err. 2.09409 Training err. RA 2.50511 Valid. err. 2.10977
2018-02-03 21:38:14,757 training [INFO ] Epoch 54 Batch11100 Training err. 2.08441 Training err. RA 2.50435 Valid. err. 2.11074
2018-02-03 21:38:15,216 training [INFO ] Epoch 54 Batch11120 Training err. 2.06176 Training err. RA 2.50356 Valid. err. 2.11492
2018-02-03 21:38:15,676 training [INFO ] Epoch 54 Batch11140 Training err. 2.12510 Training err. RA 2.50288 Valid. err. 2.12813
2018-02-03 21:38:16,136 training [INFO ] Epoch 54 Batch11160 Training err. 2.10531 Training err. RA 2.50216 Valid. err. 2.11162
2018-02-03 21:38:16,599 training [INFO ] Epoch 54 Batch11180 Training err. 2.05808 Training err. RA 2.50137 Valid. err. 2.11288
2018-02-03 21:38:17,063 training [INFO ] Epoch 54 Batch11200 Training err. 2.07344 Training err. RA 2.50061 Valid. err. 2.09853
2018-02-03 21:38:17,528 training [INFO ] Epoch 54 Batch11220 Training err. 2.05573 Training err. RA 2.49981 Valid. err. 2.09861
2018-02-03 21:38:18,343 training [INFO ] Epoch 55 Batch11240 Training err. 2.08073 Training err. RA 2.49907 Valid. err. 2.09716
2018-02-03 21:38:18,806 training [INFO ] Epoch 55 Batch11260 Training err. 2.00980 Training err. RA 2.49820 Valid. err. 2.09946
2018-02-03 21:38:19,271 training [INFO ] Epoch 55 Batch11280 Training err. 2.08712 Training err. RA 2.49747 Valid. err. 2.10350
2018-02-03 21:38:19,734 training [INFO ] Epoch 55 Batch11300 Training err. 2.08512 Training err. RA 2.49674 Valid. err. 2.11266
2018-02-03 21:38:20,195 training [INFO ] Epoch 55 Batch11320 Training err. 2.04731 Training err. RA 2.49595 Valid. err. 2.09995
2018-02-03 21:38:20,656 training [INFO ] Epoch 55 Batch11340 Training err. 2.06611 Training err. RA 2.49519 Valid. err. 2.11503
2018-02-03 21:38:21,115 training [INFO ] Epoch 55 Batch11360 Training err. 2.13921 Training err. RA 2.49456 Valid. err. 2.09623
2018-02-03 21:38:21,573 training [INFO ] Epoch 55 Batch11380 Training err. 2.07114 Training err. RA 2.49382 Valid. err. 2.10187
2018-02-03 21:38:22,031 training [INFO ] Epoch 55 Batch11400 Training err. 2.03712 Training err. RA 2.49302 Valid. err. 2.09400
2018-02-03 21:38:22,490 training [INFO ] Epoch 55 Batch11420 Training err. 2.06872 Training err. RA 2.49227 Valid. err. 2.09009
2018-02-03 21:38:22,950 training [INFO ] Epoch 55 Batch11440 Training err. 2.05197 Training err. RA 2.49150 Valid. err. 2.09207
2018-02-03 21:38:23,751 training [INFO ] Epoch 56 Batch11460 Training err. 2.05488 Training err. RA 2.49074 Valid. err. 2.09602
2018-02-03 21:38:24,211 training [INFO ] Epoch 56 Batch11480 Training err. 2.01953 Training err. RA 2.48992 Valid. err. 2.09650
2018-02-03 21:38:24,669 training [INFO ] Epoch 56 Batch11500 Training err. 2.07130 Training err. RA 2.48919 Valid. err. 2.09518
2018-02-03 21:38:25,128 training [INFO ] Epoch 56 Batch11520 Training err. 2.08259 Training err. RA 2.48849 Valid. err. 2.09640
2018-02-03 21:38:25,588 training [INFO ] Epoch 56 Batch11540 Training err. 2.04928 Training err. RA 2.48772 Valid. err. 2.09130
2018-02-03 21:38:26,048 training [INFO ] Epoch 56 Batch11560 Training err. 2.11913 Training err. RA 2.48709 Valid. err. 2.10299
2018-02-03 21:38:26,508 training [INFO ] Epoch 56 Batch11580 Training err. 2.07757 Training err. RA 2.48638 Valid. err. 2.09121
2018-02-03 21:38:26,969 training [INFO ] Epoch 56 Batch11600 Training err. 2.04053 Training err. RA 2.48561 Valid. err. 2.14345
2018-02-03 21:38:27,428 training [INFO ] Epoch 56 Batch11620 Training err. 2.05710 Training err. RA 2.48487 Valid. err. 2.10208
2018-02-03 21:38:27,888 training [INFO ] Epoch 56 Batch11640 Training err. 2.05023 Training err. RA 2.48413 Valid. err. 2.09426
2018-02-03 21:38:28,693 training [INFO ] Epoch 57 Batch11660 Training err. 2.05729 Training err. RA 2.48339 Valid. err. 2.08639
2018-02-03 21:38:29,151 training [INFO ] Epoch 57 Batch11680 Training err. 1.98696 Training err. RA 2.48254 Valid. err. 2.09407
2018-02-03 21:38:29,608 training [INFO ] Epoch 57 Batch11700 Training err. 2.08213 Training err. RA 2.48186 Valid. err. 2.08290
2018-02-03 21:38:30,067 training [INFO ] Epoch 57 Batch11720 Training err. 2.07329 Training err. RA 2.48116 Valid. err. 2.09620
2018-02-03 21:38:30,526 training [INFO ] Epoch 57 Batch11740 Training err. 2.03942 Training err. RA 2.48041 Valid. err. 2.08830
2018-02-03 21:38:30,985 training [INFO ] Epoch 57 Batch11760 Training err. 2.07007 Training err. RA 2.47971 Valid. err. 2.09006
2018-02-03 21:38:31,443 training [INFO ] Epoch 57 Batch11780 Training err. 2.12119 Training err. RA 2.47910 Valid. err. 2.08601
2018-02-03 21:38:31,903 training [INFO ] Epoch 57 Batch11800 Training err. 2.04452 Training err. RA 2.47837 Valid. err. 2.09115
2018-02-03 21:38:32,361 training [INFO ] Epoch 57 Batch11820 Training err. 2.04549 Training err. RA 2.47763 Valid. err. 2.10078
2018-02-03 21:38:32,824 training [INFO ] Epoch 57 Batch11840 Training err. 2.04551 Training err. RA 2.47690 Valid. err. 2.08632
2018-02-03 21:38:33,640 training [INFO ] Epoch 58 Batch11860 Training err. 2.04129 Training err. RA 2.47617 Valid. err. 2.07802
2018-02-03 21:38:34,103 training [INFO ] Epoch 58 Batch11880 Training err. 2.02138 Training err. RA 2.47540 Valid. err. 2.07920
2018-02-03 21:38:34,567 training [INFO ] Epoch 58 Batch11900 Training err. 2.03600 Training err. RA 2.47467 Valid. err. 2.08189
2018-02-03 21:38:35,030 training [INFO ] Epoch 58 Batch11920 Training err. 2.06650 Training err. RA 2.47398 Valid. err. 2.08826
2018-02-03 21:38:35,492 training [INFO ] Epoch 58 Batch11940 Training err. 2.04092 Training err. RA 2.47326 Valid. err. 2.08666
2018-02-03 21:38:35,956 training [INFO ] Epoch 58 Batch11960 Training err. 2.05596 Training err. RA 2.47256 Valid. err. 2.08727
2018-02-03 21:38:36,416 training [INFO ] Epoch 58 Batch11980 Training err. 2.12620 Training err. RA 2.47198 Valid. err. 2.08141
2018-02-03 21:38:36,875 training [INFO ] Epoch 58 Batch12000 Training err. 2.03559 Training err. RA 2.47125 Valid. err. 2.07736
2018-02-03 21:38:37,334 training [INFO ] Epoch 58 Batch12020 Training err. 2.02650 Training err. RA 2.47051 Valid. err. 2.07888
2018-02-03 21:38:37,793 training [INFO ] Epoch 58 Batch12040 Training err. 2.04346 Training err. RA 2.46980 Valid. err. 2.07721
2018-02-03 21:38:38,253 training [INFO ] Epoch 58 Batch12060 Training err. 2.04425 Training err. RA 2.46910 Valid. err. 2.08112
2018-02-03 21:38:39,057 training [INFO ] Epoch 59 Batch12080 Training err. 2.03251 Training err. RA 2.46837 Valid. err. 2.08233
2018-02-03 21:38:39,516 training [INFO ] Epoch 59 Batch12100 Training err. 1.99362 Training err. RA 2.46759 Valid. err. 2.07775
2018-02-03 21:38:39,976 training [INFO ] Epoch 59 Batch12120 Training err. 2.06430 Training err. RA 2.46692 Valid. err. 2.08046
2018-02-03 21:38:40,438 training [INFO ] Epoch 59 Batch12140 Training err. 2.05497 Training err. RA 2.46625 Valid. err. 2.08239
2018-02-03 21:38:40,901 training [INFO ] Epoch 59 Batch12160 Training err. 2.03160 Training err. RA 2.46553 Valid. err. 2.08150
2018-02-03 21:38:41,366 training [INFO ] Epoch 59 Batch12180 Training err. 2.09383 Training err. RA 2.46492 Valid. err. 2.10253
2018-02-03 21:38:41,828 training [INFO ] Epoch 59 Batch12200 Training err. 2.07512 Training err. RA 2.46428 Valid. err. 2.08112
2018-02-03 21:38:42,292 training [INFO ] Epoch 59 Batch12220 Training err. 2.02723 Training err. RA 2.46357 Valid. err. 2.08147
2018-02-03 21:38:42,755 training [INFO ] Epoch 59 Batch12240 Training err. 2.04031 Training err. RA 2.46287 Valid. err. 2.06981
2018-02-03 21:38:43,218 training [INFO ] Epoch 59 Batch12260 Training err. 2.02571 Training err. RA 2.46216 Valid. err. 2.07006
2018-02-03 21:38:44,037 training [INFO ] Epoch 60 Batch12280 Training err. 2.03921 Training err. RA 2.46147 Valid. err. 2.06771
2018-02-03 21:38:44,495 training [INFO ] Epoch 60 Batch12300 Training err. 1.98173 Training err. RA 2.46069 Valid. err. 2.07161
2018-02-03 21:38:44,954 training [INFO ] Epoch 60 Batch12320 Training err. 2.05873 Training err. RA 2.46004 Valid. err. 2.07307
2018-02-03 21:38:45,415 training [INFO ] Epoch 60 Batch12340 Training err. 2.05656 Training err. RA 2.45939 Valid. err. 2.07955
2018-02-03 21:38:45,875 training [INFO ] Epoch 60 Batch12360 Training err. 2.01880 Training err. RA 2.45867 Valid. err. 2.07168
2018-02-03 21:38:46,332 training [INFO ] Epoch 60 Batch12380 Training err. 2.03471 Training err. RA 2.45799 Valid. err. 2.08503
2018-02-03 21:38:46,789 training [INFO ] Epoch 60 Batch12400 Training err. 2.10968 Training err. RA 2.45743 Valid. err. 2.06704
2018-02-03 21:38:47,248 training [INFO ] Epoch 60 Batch12420 Training err. 2.04074 Training err. RA 2.45676 Valid. err. 2.07094
2018-02-03 21:38:47,707 training [INFO ] Epoch 60 Batch12440 Training err. 2.00597 Training err. RA 2.45603 Valid. err. 2.06600
2018-02-03 21:38:48,167 training [INFO ] Epoch 60 Batch12460 Training err. 2.03828 Training err. RA 2.45536 Valid. err. 2.06083
2018-02-03 21:38:48,630 training [INFO ] Epoch 60 Batch12480 Training err. 2.02140 Training err. RA 2.45466 Valid. err. 2.06372
2018-02-03 21:38:48,902 __main__ [INFO ] End of training
2018-02-03 21:38:49,183 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:38:49,184 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 21:38:49,755 training [INFO ] Epoch  1 Batch   20 Training err. 3.65322 Training err. RA 3.65322 Valid. err. 3.27628
2018-02-03 21:38:50,219 training [INFO ] Epoch  1 Batch   40 Training err. 3.16764 Training err. RA 3.41043 Valid. err. 3.20910
2018-02-03 21:38:50,682 training [INFO ] Epoch  1 Batch   60 Training err. 3.14395 Training err. RA 3.32160 Valid. err. 3.21643
2018-02-03 21:38:51,147 training [INFO ] Epoch  1 Batch   80 Training err. 3.14547 Training err. RA 3.27757 Valid. err. 3.19968
2018-02-03 21:38:51,611 training [INFO ] Epoch  1 Batch  100 Training err. 3.13214 Training err. RA 3.24849 Valid. err. 3.18242
2018-02-03 21:38:52,075 training [INFO ] Epoch  1 Batch  120 Training err. 3.15972 Training err. RA 3.23369 Valid. err. 3.18190
2018-02-03 21:38:52,534 training [INFO ] Epoch  1 Batch  140 Training err. 3.11113 Training err. RA 3.21618 Valid. err. 3.17737
2018-02-03 21:38:52,995 training [INFO ] Epoch  1 Batch  160 Training err. 3.07327 Training err. RA 3.19832 Valid. err. 3.17784
2018-02-03 21:38:53,456 training [INFO ] Epoch  1 Batch  180 Training err. 3.13668 Training err. RA 3.19147 Valid. err. 3.15026
2018-02-03 21:38:53,916 training [INFO ] Epoch  1 Batch  200 Training err. 3.10858 Training err. RA 3.18318 Valid. err. 3.12066
2018-02-03 21:38:54,723 training [INFO ] Epoch  2 Batch  220 Training err. 3.08051 Training err. RA 3.17385 Valid. err. 3.24873
2018-02-03 21:38:55,186 training [INFO ] Epoch  2 Batch  240 Training err. 3.01157 Training err. RA 3.16032 Valid. err. 3.18497
2018-02-03 21:38:55,646 training [INFO ] Epoch  2 Batch  260 Training err. 3.02153 Training err. RA 3.14965 Valid. err. 3.01883
2018-02-03 21:38:56,105 training [INFO ] Epoch  2 Batch  280 Training err. 2.96308 Training err. RA 3.13632 Valid. err. 2.96882
2018-02-03 21:38:56,565 training [INFO ] Epoch  2 Batch  300 Training err. 2.88361 Training err. RA 3.11947 Valid. err. 2.94984
2018-02-03 21:38:57,024 training [INFO ] Epoch  2 Batch  320 Training err. 2.91151 Training err. RA 3.10648 Valid. err. 2.88021
2018-02-03 21:38:57,484 training [INFO ] Epoch  2 Batch  340 Training err. 2.83766 Training err. RA 3.09066 Valid. err. 2.88853
2018-02-03 21:38:57,944 training [INFO ] Epoch  2 Batch  360 Training err. 2.78663 Training err. RA 3.07377 Valid. err. 2.88545
2018-02-03 21:38:58,404 training [INFO ] Epoch  2 Batch  380 Training err. 2.75827 Training err. RA 3.05717 Valid. err. 2.76307
2018-02-03 21:38:58,863 training [INFO ] Epoch  2 Batch  400 Training err. 2.73259 Training err. RA 3.04094 Valid. err. 2.75285
2018-02-03 21:38:59,658 training [INFO ] Epoch  3 Batch  420 Training err. 2.71836 Training err. RA 3.02558 Valid. err. 2.72696
2018-02-03 21:39:00,125 training [INFO ] Epoch  3 Batch  440 Training err. 2.67309 Training err. RA 3.00955 Valid. err. 2.71406
2018-02-03 21:39:00,585 training [INFO ] Epoch  3 Batch  460 Training err. 2.69291 Training err. RA 2.99579 Valid. err. 2.66489
2018-02-03 21:39:01,045 training [INFO ] Epoch  3 Batch  480 Training err. 2.60278 Training err. RA 2.97941 Valid. err. 2.62056
2018-02-03 21:39:01,506 training [INFO ] Epoch  3 Batch  500 Training err. 2.58572 Training err. RA 2.96366 Valid. err. 2.67709
2018-02-03 21:39:01,966 training [INFO ] Epoch  3 Batch  520 Training err. 2.58118 Training err. RA 2.94895 Valid. err. 2.61297
2018-02-03 21:39:02,426 training [INFO ] Epoch  3 Batch  540 Training err. 2.59817 Training err. RA 2.93596 Valid. err. 2.57167
2018-02-03 21:39:02,887 training [INFO ] Epoch  3 Batch  560 Training err. 2.50583 Training err. RA 2.92060 Valid. err. 2.53910
2018-02-03 21:39:03,348 training [INFO ] Epoch  3 Batch  580 Training err. 2.46404 Training err. RA 2.90486 Valid. err. 2.52215
2018-02-03 21:39:03,808 training [INFO ] Epoch  3 Batch  600 Training err. 2.49202 Training err. RA 2.89110 Valid. err. 2.49525
2018-02-03 21:39:04,267 training [INFO ] Epoch  3 Batch  620 Training err. 2.49212 Training err. RA 2.87823 Valid. err. 2.47727
2018-02-03 21:39:05,068 training [INFO ] Epoch  4 Batch  640 Training err. 2.43745 Training err. RA 2.86445 Valid. err. 2.46655
2018-02-03 21:39:05,528 training [INFO ] Epoch  4 Batch  660 Training err. 2.35405 Training err. RA 2.84898 Valid. err. 2.44568
2018-02-03 21:39:05,987 training [INFO ] Epoch  4 Batch  680 Training err. 2.44897 Training err. RA 2.83722 Valid. err. 2.44638
2018-02-03 21:39:06,448 training [INFO ] Epoch  4 Batch  700 Training err. 2.40657 Training err. RA 2.82492 Valid. err. 2.44347
2018-02-03 21:39:06,909 training [INFO ] Epoch  4 Batch  720 Training err. 2.36502 Training err. RA 2.81214 Valid. err. 2.41249
2018-02-03 21:39:07,371 training [INFO ] Epoch  4 Batch  740 Training err. 2.43651 Training err. RA 2.80199 Valid. err. 2.41857
2018-02-03 21:39:07,832 training [INFO ] Epoch  4 Batch  760 Training err. 2.37542 Training err. RA 2.79076 Valid. err. 2.38307
2018-02-03 21:39:08,293 training [INFO ] Epoch  4 Batch  780 Training err. 2.32910 Training err. RA 2.77892 Valid. err. 2.37424
2018-02-03 21:39:08,753 training [INFO ] Epoch  4 Batch  800 Training err. 2.33126 Training err. RA 2.76773 Valid. err. 2.34123
2018-02-03 21:39:09,213 training [INFO ] Epoch  4 Batch  820 Training err. 2.29745 Training err. RA 2.75626 Valid. err. 2.35513
2018-02-03 21:39:10,013 training [INFO ] Epoch  5 Batch  840 Training err. 2.32140 Training err. RA 2.74591 Valid. err. 2.33160
2018-02-03 21:39:10,471 training [INFO ] Epoch  5 Batch  860 Training err. 2.22596 Training err. RA 2.73382 Valid. err. 2.32278
2018-02-03 21:39:10,932 training [INFO ] Epoch  5 Batch  880 Training err. 2.29262 Training err. RA 2.72379 Valid. err. 2.31597
2018-02-03 21:39:11,391 training [INFO ] Epoch  5 Batch  900 Training err. 2.30090 Training err. RA 2.71439 Valid. err. 2.31114
2018-02-03 21:39:11,851 training [INFO ] Epoch  5 Batch  920 Training err. 2.22540 Training err. RA 2.70376 Valid. err. 2.32693
2018-02-03 21:39:12,311 training [INFO ] Epoch  5 Batch  940 Training err. 2.26098 Training err. RA 2.69434 Valid. err. 2.34131
2018-02-03 21:39:12,771 training [INFO ] Epoch  5 Batch  960 Training err. 2.31011 Training err. RA 2.68634 Valid. err. 2.25922
2018-02-03 21:39:13,232 training [INFO ] Epoch  5 Batch  980 Training err. 2.22809 Training err. RA 2.67698 Valid. err. 2.38329
2018-02-03 21:39:13,691 training [INFO ] Epoch  5 Batch 1000 Training err. 2.20798 Training err. RA 2.66760 Valid. err. 2.24146
2018-02-03 21:39:14,150 training [INFO ] Epoch  5 Batch 1020 Training err. 2.21054 Training err. RA 2.65864 Valid. err. 2.24074
2018-02-03 21:39:14,610 training [INFO ] Epoch  5 Batch 1040 Training err. 2.18678 Training err. RA 2.64957 Valid. err. 2.23833
2018-02-03 21:39:15,404 training [INFO ] Epoch  6 Batch 1060 Training err. 2.18627 Training err. RA 2.64083 Valid. err. 2.22324
2018-02-03 21:39:15,865 training [INFO ] Epoch  6 Batch 1080 Training err. 2.11847 Training err. RA 2.63115 Valid. err. 2.24861
2018-02-03 21:39:16,324 training [INFO ] Epoch  6 Batch 1100 Training err. 2.20632 Training err. RA 2.62343 Valid. err. 2.20532
2018-02-03 21:39:16,800 training [INFO ] Epoch  6 Batch 1120 Training err. 2.19060 Training err. RA 2.61570 Valid. err. 2.21188
2018-02-03 21:39:17,271 training [INFO ] Epoch  6 Batch 1140 Training err. 2.14871 Training err. RA 2.60751 Valid. err. 2.18807
2018-02-03 21:39:17,763 training [INFO ] Epoch  6 Batch 1160 Training err. 2.22672 Training err. RA 2.60094 Valid. err. 2.18390
2018-02-03 21:39:18,356 training [INFO ] Epoch  6 Batch 1180 Training err. 2.13756 Training err. RA 2.59309 Valid. err. 2.18648
2018-02-03 21:39:18,989 training [INFO ] Epoch  6 Batch 1200 Training err. 2.10517 Training err. RA 2.58496 Valid. err. 2.40745
2018-02-03 21:39:19,497 training [INFO ] Epoch  6 Batch 1220 Training err. 2.13931 Training err. RA 2.57765 Valid. err. 2.18847
2018-02-03 21:39:19,976 training [INFO ] Epoch  6 Batch 1240 Training err. 2.11206 Training err. RA 2.57014 Valid. err. 2.19983
2018-02-03 21:39:20,810 training [INFO ] Epoch  7 Batch 1260 Training err. 2.12091 Training err. RA 2.56301 Valid. err. 2.16370
2018-02-03 21:39:21,345 training [INFO ] Epoch  7 Batch 1280 Training err. 2.02200 Training err. RA 2.55456 Valid. err. 2.14955
2018-02-03 21:39:21,841 training [INFO ] Epoch  7 Batch 1300 Training err. 2.13761 Training err. RA 2.54814 Valid. err. 2.12518
2018-02-03 21:39:22,339 training [INFO ] Epoch  7 Batch 1320 Training err. 2.11738 Training err. RA 2.54162 Valid. err. 2.13384
2018-02-03 21:39:22,823 training [INFO ] Epoch  7 Batch 1340 Training err. 2.06835 Training err. RA 2.53455 Valid. err. 2.13033
2018-02-03 21:39:23,295 training [INFO ] Epoch  7 Batch 1360 Training err. 2.11365 Training err. RA 2.52836 Valid. err. 2.15202
2018-02-03 21:39:23,766 training [INFO ] Epoch  7 Batch 1380 Training err. 2.13393 Training err. RA 2.52265 Valid. err. 2.12365
2018-02-03 21:39:24,253 training [INFO ] Epoch  7 Batch 1400 Training err. 2.04244 Training err. RA 2.51579 Valid. err. 2.13175
2018-02-03 21:39:24,780 training [INFO ] Epoch  7 Batch 1420 Training err. 2.07203 Training err. RA 2.50954 Valid. err. 2.10448
2018-02-03 21:39:25,269 training [INFO ] Epoch  7 Batch 1440 Training err. 2.04482 Training err. RA 2.50308 Valid. err. 2.07731
2018-02-03 21:39:26,164 training [INFO ] Epoch  8 Batch 1460 Training err. 2.04333 Training err. RA 2.49678 Valid. err. 2.11347
2018-02-03 21:39:26,689 training [INFO ] Epoch  8 Batch 1480 Training err. 2.01488 Training err. RA 2.49027 Valid. err. 2.07814
2018-02-03 21:39:27,237 training [INFO ] Epoch  8 Batch 1500 Training err. 2.00810 Training err. RA 2.48384 Valid. err. 2.06844
2018-02-03 21:39:27,752 training [INFO ] Epoch  8 Batch 1520 Training err. 2.05401 Training err. RA 2.47819 Valid. err. 2.07073
2018-02-03 21:39:28,251 training [INFO ] Epoch  8 Batch 1540 Training err. 2.02520 Training err. RA 2.47230 Valid. err. 2.09883
2018-02-03 21:39:28,919 training [INFO ] Epoch  8 Batch 1560 Training err. 2.04816 Training err. RA 2.46687 Valid. err. 2.17362
2018-02-03 21:39:29,545 training [INFO ] Epoch  8 Batch 1580 Training err. 2.10656 Training err. RA 2.46230 Valid. err. 2.05718
2018-02-03 21:39:30,056 training [INFO ] Epoch  8 Batch 1600 Training err. 1.98246 Training err. RA 2.45631 Valid. err. 2.07477
2018-02-03 21:39:30,572 training [INFO ] Epoch  8 Batch 1620 Training err. 1.98779 Training err. RA 2.45052 Valid. err. 2.06894
2018-02-03 21:39:31,122 training [INFO ] Epoch  8 Batch 1640 Training err. 1.99299 Training err. RA 2.44494 Valid. err. 2.04103
2018-02-03 21:39:31,601 training [INFO ] Epoch  8 Batch 1660 Training err. 1.98773 Training err. RA 2.43943 Valid. err. 2.02887
2018-02-03 21:39:32,465 training [INFO ] Epoch  9 Batch 1680 Training err. 1.99532 Training err. RA 2.43415 Valid. err. 2.04130
2018-02-03 21:39:32,945 training [INFO ] Epoch  9 Batch 1700 Training err. 1.92332 Training err. RA 2.42814 Valid. err. 2.04387
2018-02-03 21:39:33,416 training [INFO ] Epoch  9 Batch 1720 Training err. 2.00076 Training err. RA 2.42317 Valid. err. 2.02832
2018-02-03 21:39:33,887 training [INFO ] Epoch  9 Batch 1740 Training err. 2.00128 Training err. RA 2.41832 Valid. err. 2.05228
2018-02-03 21:39:34,359 training [INFO ] Epoch  9 Batch 1760 Training err. 1.96069 Training err. RA 2.41312 Valid. err. 2.07162
2018-02-03 21:39:34,832 training [INFO ] Epoch  9 Batch 1780 Training err. 2.03703 Training err. RA 2.40889 Valid. err. 2.07928
2018-02-03 21:39:35,303 training [INFO ] Epoch  9 Batch 1800 Training err. 1.99012 Training err. RA 2.40424 Valid. err. 2.01046
2018-02-03 21:39:35,773 training [INFO ] Epoch  9 Batch 1820 Training err. 1.92994 Training err. RA 2.39903 Valid. err. 2.00685
2018-02-03 21:39:36,256 training [INFO ] Epoch  9 Batch 1840 Training err. 1.96038 Training err. RA 2.39426 Valid. err. 1.99502
2018-02-03 21:39:36,741 training [INFO ] Epoch  9 Batch 1860 Training err. 1.93850 Training err. RA 2.38936 Valid. err. 2.01409
2018-02-03 21:39:37,589 training [INFO ] Epoch 10 Batch 1880 Training err. 1.96113 Training err. RA 2.38480 Valid. err. 1.99250
2018-02-03 21:39:38,103 training [INFO ] Epoch 10 Batch 1900 Training err. 1.88523 Training err. RA 2.37954 Valid. err. 1.99352
2018-02-03 21:39:38,611 training [INFO ] Epoch 10 Batch 1920 Training err. 1.95257 Training err. RA 2.37510 Valid. err. 2.00865
2018-02-03 21:39:39,138 training [INFO ] Epoch 10 Batch 1940 Training err. 1.96274 Training err. RA 2.37085 Valid. err. 2.00060
2018-02-03 21:39:39,631 training [INFO ] Epoch 10 Batch 1960 Training err. 1.91578 Training err. RA 2.36620 Valid. err. 2.00007
2018-02-03 21:39:40,102 training [INFO ] Epoch 10 Batch 1980 Training err. 1.92721 Training err. RA 2.36177 Valid. err. 2.01323
2018-02-03 21:39:40,600 training [INFO ] Epoch 10 Batch 2000 Training err. 2.01289 Training err. RA 2.35828 Valid. err. 1.97205
2018-02-03 21:39:41,140 training [INFO ] Epoch 10 Batch 2020 Training err. 1.91036 Training err. RA 2.35384 Valid. err. 1.97535
2018-02-03 21:39:41,642 training [INFO ] Epoch 10 Batch 2040 Training err. 1.88434 Training err. RA 2.34924 Valid. err. 1.96889
2018-02-03 21:39:42,144 training [INFO ] Epoch 10 Batch 2060 Training err. 1.91951 Training err. RA 2.34507 Valid. err. 1.96343
2018-02-03 21:39:42,677 training [INFO ] Epoch 10 Batch 2080 Training err. 1.89159 Training err. RA 2.34071 Valid. err. 1.97471
2018-02-03 21:39:43,572 training [INFO ] Epoch 11 Batch 2100 Training err. 1.90794 Training err. RA 2.33659 Valid. err. 1.94574
2018-02-03 21:39:44,090 training [INFO ] Epoch 11 Batch 2120 Training err. 1.84721 Training err. RA 2.33197 Valid. err. 1.96764
2018-02-03 21:39:44,579 training [INFO ] Epoch 11 Batch 2140 Training err. 1.91536 Training err. RA 2.32808 Valid. err. 1.95772
2018-02-03 21:39:45,050 training [INFO ] Epoch 11 Batch 2160 Training err. 1.92473 Training err. RA 2.32434 Valid. err. 1.94893
2018-02-03 21:39:45,527 training [INFO ] Epoch 11 Batch 2180 Training err. 1.87467 Training err. RA 2.32022 Valid. err. 1.93307
2018-02-03 21:39:46,044 training [INFO ] Epoch 11 Batch 2200 Training err. 1.97331 Training err. RA 2.31706 Valid. err. 1.95999
2018-02-03 21:39:46,531 training [INFO ] Epoch 11 Batch 2220 Training err. 1.89413 Training err. RA 2.31325 Valid. err. 1.94730
2018-02-03 21:39:47,024 training [INFO ] Epoch 11 Batch 2240 Training err. 1.84740 Training err. RA 2.30909 Valid. err. 1.98006
2018-02-03 21:39:47,509 training [INFO ] Epoch 11 Batch 2260 Training err. 1.87561 Training err. RA 2.30526 Valid. err. 1.94090
2018-02-03 21:39:47,986 training [INFO ] Epoch 11 Batch 2280 Training err. 1.87399 Training err. RA 2.30147 Valid. err. 1.92238
2018-02-03 21:39:48,934 training [INFO ] Epoch 12 Batch 2300 Training err. 1.87505 Training err. RA 2.29777 Valid. err. 1.94262
2018-02-03 21:39:49,397 training [INFO ] Epoch 12 Batch 2320 Training err. 1.79828 Training err. RA 2.29346 Valid. err. 1.93879
2018-02-03 21:39:49,857 training [INFO ] Epoch 12 Batch 2340 Training err. 1.88651 Training err. RA 2.28998 Valid. err. 1.91421
2018-02-03 21:39:50,319 training [INFO ] Epoch 12 Batch 2360 Training err. 1.89562 Training err. RA 2.28664 Valid. err. 1.92862
2018-02-03 21:39:50,780 training [INFO ] Epoch 12 Batch 2380 Training err. 1.83414 Training err. RA 2.28284 Valid. err. 1.91716
2018-02-03 21:39:51,241 training [INFO ] Epoch 12 Batch 2400 Training err. 1.87725 Training err. RA 2.27946 Valid. err. 1.93663
2018-02-03 21:39:51,701 training [INFO ] Epoch 12 Batch 2420 Training err. 1.92674 Training err. RA 2.27654 Valid. err. 1.92050
2018-02-03 21:39:52,160 training [INFO ] Epoch 12 Batch 2440 Training err. 1.83035 Training err. RA 2.27289 Valid. err. 1.90388
2018-02-03 21:39:52,623 training [INFO ] Epoch 12 Batch 2460 Training err. 1.83631 Training err. RA 2.26934 Valid. err. 1.92537
2018-02-03 21:39:53,086 training [INFO ] Epoch 12 Batch 2480 Training err. 1.83891 Training err. RA 2.26586 Valid. err. 1.88376
2018-02-03 21:39:53,899 training [INFO ] Epoch 13 Batch 2500 Training err. 1.83177 Training err. RA 2.26239 Valid. err. 1.89208
2018-02-03 21:39:54,363 training [INFO ] Epoch 13 Batch 2520 Training err. 1.80837 Training err. RA 2.25879 Valid. err. 1.89167
2018-02-03 21:39:54,827 training [INFO ] Epoch 13 Batch 2540 Training err. 1.80920 Training err. RA 2.25525 Valid. err. 1.89246
2018-02-03 21:39:55,292 training [INFO ] Epoch 13 Batch 2560 Training err. 1.85999 Training err. RA 2.25216 Valid. err. 1.89226
2018-02-03 21:39:55,756 training [INFO ] Epoch 13 Batch 2580 Training err. 1.82789 Training err. RA 2.24887 Valid. err. 1.90930
2018-02-03 21:39:56,272 training [INFO ] Epoch 13 Batch 2600 Training err. 1.83214 Training err. RA 2.24567 Valid. err. 1.91914
2018-02-03 21:39:56,731 training [INFO ] Epoch 13 Batch 2620 Training err. 1.91167 Training err. RA 2.24312 Valid. err. 1.89053
2018-02-03 21:39:57,190 training [INFO ] Epoch 13 Batch 2640 Training err. 1.79997 Training err. RA 2.23976 Valid. err. 1.90545
2018-02-03 21:39:57,648 training [INFO ] Epoch 13 Batch 2660 Training err. 1.79052 Training err. RA 2.23638 Valid. err. 1.89414
2018-02-03 21:39:58,107 training [INFO ] Epoch 13 Batch 2680 Training err. 1.81092 Training err. RA 2.23321 Valid. err. 1.86689
2018-02-03 21:39:58,568 training [INFO ] Epoch 13 Batch 2700 Training err. 1.81496 Training err. RA 2.23011 Valid. err. 1.87504
2018-02-03 21:39:59,368 training [INFO ] Epoch 14 Batch 2720 Training err. 1.79761 Training err. RA 2.22693 Valid. err. 1.88503
2018-02-03 21:39:59,827 training [INFO ] Epoch 14 Batch 2740 Training err. 1.75093 Training err. RA 2.22345 Valid. err. 1.87515
2018-02-03 21:40:00,295 training [INFO ] Epoch 14 Batch 2760 Training err. 1.81873 Training err. RA 2.22052 Valid. err. 1.88180
2018-02-03 21:40:00,755 training [INFO ] Epoch 14 Batch 2780 Training err. 1.83855 Training err. RA 2.21777 Valid. err. 1.86952
2018-02-03 21:40:01,217 training [INFO ] Epoch 14 Batch 2800 Training err. 1.78031 Training err. RA 2.21465 Valid. err. 1.90025
2018-02-03 21:40:01,682 training [INFO ] Epoch 14 Batch 2820 Training err. 1.85811 Training err. RA 2.21212 Valid. err. 1.93146
2018-02-03 21:40:02,145 training [INFO ] Epoch 14 Batch 2840 Training err. 1.82687 Training err. RA 2.20941 Valid. err. 1.86604
2018-02-03 21:40:02,610 training [INFO ] Epoch 14 Batch 2860 Training err. 1.76505 Training err. RA 2.20630 Valid. err. 1.85771
2018-02-03 21:40:03,075 training [INFO ] Epoch 14 Batch 2880 Training err. 1.78808 Training err. RA 2.20339 Valid. err. 1.85633
2018-02-03 21:40:03,539 training [INFO ] Epoch 14 Batch 2900 Training err. 1.77773 Training err. RA 2.20046 Valid. err. 1.89080
2018-02-03 21:40:04,351 training [INFO ] Epoch 15 Batch 2920 Training err. 1.78105 Training err. RA 2.19759 Valid. err. 1.84492
2018-02-03 21:40:04,810 training [INFO ] Epoch 15 Batch 2940 Training err. 1.72976 Training err. RA 2.19440 Valid. err. 1.86021
2018-02-03 21:40:05,268 training [INFO ] Epoch 15 Batch 2960 Training err. 1.78876 Training err. RA 2.19166 Valid. err. 1.87043
2018-02-03 21:40:05,727 training [INFO ] Epoch 15 Batch 2980 Training err. 1.81678 Training err. RA 2.18915 Valid. err. 1.85938
2018-02-03 21:40:06,193 training [INFO ] Epoch 15 Batch 3000 Training err. 1.75919 Training err. RA 2.18628 Valid. err. 1.86823
2018-02-03 21:40:06,654 training [INFO ] Epoch 15 Batch 3020 Training err. 1.76837 Training err. RA 2.18351 Valid. err. 1.87738
2018-02-03 21:40:07,114 training [INFO ] Epoch 15 Batch 3040 Training err. 1.85075 Training err. RA 2.18132 Valid. err. 1.84034
2018-02-03 21:40:07,574 training [INFO ] Epoch 15 Batch 3060 Training err. 1.76281 Training err. RA 2.17859 Valid. err. 1.83947
2018-02-03 21:40:08,032 training [INFO ] Epoch 15 Batch 3080 Training err. 1.73840 Training err. RA 2.17573 Valid. err. 1.83769
2018-02-03 21:40:08,491 training [INFO ] Epoch 15 Batch 3100 Training err. 1.76227 Training err. RA 2.17306 Valid. err. 1.83973
2018-02-03 21:40:08,952 training [INFO ] Epoch 15 Batch 3120 Training err. 1.75443 Training err. RA 2.17038 Valid. err. 1.83092
2018-02-03 21:40:09,759 training [INFO ] Epoch 16 Batch 3140 Training err. 1.74356 Training err. RA 2.16766 Valid. err. 1.83014
2018-02-03 21:40:10,224 training [INFO ] Epoch 16 Batch 3160 Training err. 1.70349 Training err. RA 2.16472 Valid. err. 1.84749
2018-02-03 21:40:10,689 training [INFO ] Epoch 16 Batch 3180 Training err. 1.77405 Training err. RA 2.16227 Valid. err. 1.84195
2018-02-03 21:40:11,154 training [INFO ] Epoch 16 Batch 3200 Training err. 1.79188 Training err. RA 2.15995 Valid. err. 1.83349
2018-02-03 21:40:11,619 training [INFO ] Epoch 16 Batch 3220 Training err. 1.73257 Training err. RA 2.15730 Valid. err. 1.82428
2018-02-03 21:40:12,084 training [INFO ] Epoch 16 Batch 3240 Training err. 1.81453 Training err. RA 2.15518 Valid. err. 1.83560
2018-02-03 21:40:12,544 training [INFO ] Epoch 16 Batch 3260 Training err. 1.76393 Training err. RA 2.15278 Valid. err. 1.83587
2018-02-03 21:40:13,004 training [INFO ] Epoch 16 Batch 3280 Training err. 1.71513 Training err. RA 2.15011 Valid. err. 1.84111
2018-02-03 21:40:13,462 training [INFO ] Epoch 16 Batch 3300 Training err. 1.73845 Training err. RA 2.14762 Valid. err. 1.82483
2018-02-03 21:40:13,922 training [INFO ] Epoch 16 Batch 3320 Training err. 1.73824 Training err. RA 2.14515 Valid. err. 1.81991
2018-02-03 21:40:14,719 training [INFO ] Epoch 17 Batch 3340 Training err. 1.73342 Training err. RA 2.14269 Valid. err. 1.81500
2018-02-03 21:40:15,178 training [INFO ] Epoch 17 Batch 3360 Training err. 1.67512 Training err. RA 2.13990 Valid. err. 1.82126
2018-02-03 21:40:15,640 training [INFO ] Epoch 17 Batch 3380 Training err. 1.74849 Training err. RA 2.13759 Valid. err. 1.80723
2018-02-03 21:40:16,100 training [INFO ] Epoch 17 Batch 3400 Training err. 1.77702 Training err. RA 2.13547 Valid. err. 1.81841
2018-02-03 21:40:16,561 training [INFO ] Epoch 17 Batch 3420 Training err. 1.71294 Training err. RA 2.13299 Valid. err. 1.81326
2018-02-03 21:40:17,026 training [INFO ] Epoch 17 Batch 3440 Training err. 1.74254 Training err. RA 2.13072 Valid. err. 1.81946
2018-02-03 21:40:17,491 training [INFO ] Epoch 17 Batch 3460 Training err. 1.79288 Training err. RA 2.12877 Valid. err. 1.81534
2018-02-03 21:40:17,963 training [INFO ] Epoch 17 Batch 3480 Training err. 1.71179 Training err. RA 2.12637 Valid. err. 1.80854
2018-02-03 21:40:18,428 training [INFO ] Epoch 17 Batch 3500 Training err. 1.71324 Training err. RA 2.12401 Valid. err. 1.81089
2018-02-03 21:40:18,892 training [INFO ] Epoch 17 Batch 3520 Training err. 1.70917 Training err. RA 2.12166 Valid. err. 1.78875
2018-02-03 21:40:19,705 training [INFO ] Epoch 18 Batch 3540 Training err. 1.71107 Training err. RA 2.11934 Valid. err. 1.79032
2018-02-03 21:40:20,168 training [INFO ] Epoch 18 Batch 3560 Training err. 1.68535 Training err. RA 2.11690 Valid. err. 1.79292
2018-02-03 21:40:20,629 training [INFO ] Epoch 18 Batch 3580 Training err. 1.69100 Training err. RA 2.11452 Valid. err. 1.80816
2018-02-03 21:40:21,090 training [INFO ] Epoch 18 Batch 3600 Training err. 1.74308 Training err. RA 2.11246 Valid. err. 1.79977
2018-02-03 21:40:21,550 training [INFO ] Epoch 18 Batch 3620 Training err. 1.72399 Training err. RA 2.11031 Valid. err. 1.81461
2018-02-03 21:40:22,010 training [INFO ] Epoch 18 Batch 3640 Training err. 1.71177 Training err. RA 2.10812 Valid. err. 1.79598
2018-02-03 21:40:22,470 training [INFO ] Epoch 18 Batch 3660 Training err. 1.78568 Training err. RA 2.10636 Valid. err. 1.79599
2018-02-03 21:40:22,929 training [INFO ] Epoch 18 Batch 3680 Training err. 1.69317 Training err. RA 2.10411 Valid. err. 1.80968
2018-02-03 21:40:23,390 training [INFO ] Epoch 18 Batch 3700 Training err. 1.67807 Training err. RA 2.10181 Valid. err. 1.81295
2018-02-03 21:40:23,852 training [INFO ] Epoch 18 Batch 3720 Training err. 1.69130 Training err. RA 2.09960 Valid. err. 1.78046
2018-02-03 21:40:24,312 training [INFO ] Epoch 18 Batch 3740 Training err. 1.70332 Training err. RA 2.09748 Valid. err. 1.79431
2018-02-03 21:40:25,125 training [INFO ] Epoch 19 Batch 3760 Training err. 1.68146 Training err. RA 2.09527 Valid. err. 1.79618
2018-02-03 21:40:25,589 training [INFO ] Epoch 19 Batch 3780 Training err. 1.64650 Training err. RA 2.09290 Valid. err. 1.78440
2018-02-03 21:40:26,054 training [INFO ] Epoch 19 Batch 3800 Training err. 1.70774 Training err. RA 2.09087 Valid. err. 1.79956
2018-02-03 21:40:26,519 training [INFO ] Epoch 19 Batch 3820 Training err. 1.73913 Training err. RA 2.08903 Valid. err. 1.78362
2018-02-03 21:40:26,982 training [INFO ] Epoch 19 Batch 3840 Training err. 1.67999 Training err. RA 2.08690 Valid. err. 1.80296
2018-02-03 21:40:27,446 training [INFO ] Epoch 19 Batch 3860 Training err. 1.74206 Training err. RA 2.08511 Valid. err. 1.79477
2018-02-03 21:40:27,910 training [INFO ] Epoch 19 Batch 3880 Training err. 1.71833 Training err. RA 2.08322 Valid. err. 1.77848
2018-02-03 21:40:28,372 training [INFO ] Epoch 19 Batch 3900 Training err. 1.66463 Training err. RA 2.08107 Valid. err. 1.77577
2018-02-03 21:40:28,833 training [INFO ] Epoch 19 Batch 3920 Training err. 1.67993 Training err. RA 2.07903 Valid. err. 1.76584
2018-02-03 21:40:29,292 training [INFO ] Epoch 19 Batch 3940 Training err. 1.67469 Training err. RA 2.07697 Valid. err. 1.78748
2018-02-03 21:40:30,095 training [INFO ] Epoch 20 Batch 3960 Training err. 1.67277 Training err. RA 2.07493 Valid. err. 1.75904
2018-02-03 21:40:30,555 training [INFO ] Epoch 20 Batch 3980 Training err. 1.63228 Training err. RA 2.07271 Valid. err. 1.77735
2018-02-03 21:40:31,014 training [INFO ] Epoch 20 Batch 4000 Training err. 1.68567 Training err. RA 2.07077 Valid. err. 1.77637
2018-02-03 21:40:31,473 training [INFO ] Epoch 20 Batch 4020 Training err. 1.72287 Training err. RA 2.06904 Valid. err. 1.77847
2018-02-03 21:40:31,932 training [INFO ] Epoch 20 Batch 4040 Training err. 1.67013 Training err. RA 2.06707 Valid. err. 1.79167
2018-02-03 21:40:32,395 training [INFO ] Epoch 20 Batch 4060 Training err. 1.66654 Training err. RA 2.06509 Valid. err. 1.79024
2018-02-03 21:40:32,859 training [INFO ] Epoch 20 Batch 4080 Training err. 1.73892 Training err. RA 2.06350 Valid. err. 1.76585
2018-02-03 21:40:33,323 training [INFO ] Epoch 20 Batch 4100 Training err. 1.67037 Training err. RA 2.06158 Valid. err. 1.76163
2018-02-03 21:40:33,788 training [INFO ] Epoch 20 Batch 4120 Training err. 1.64200 Training err. RA 2.05954 Valid. err. 1.76348
2018-02-03 21:40:34,253 training [INFO ] Epoch 20 Batch 4140 Training err. 1.65891 Training err. RA 2.05761 Valid. err. 1.75211
2018-02-03 21:40:34,717 training [INFO ] Epoch 20 Batch 4160 Training err. 1.65873 Training err. RA 2.05569 Valid. err. 1.75040
2018-02-03 21:40:35,526 training [INFO ] Epoch 21 Batch 4180 Training err. 1.64975 Training err. RA 2.05375 Valid. err. 1.75611
2018-02-03 21:40:35,992 training [INFO ] Epoch 21 Batch 4200 Training err. 1.61158 Training err. RA 2.05164 Valid. err. 1.77527
2018-02-03 21:40:36,452 training [INFO ] Epoch 21 Batch 4220 Training err. 1.68318 Training err. RA 2.04989 Valid. err. 1.76504
2018-02-03 21:40:36,911 training [INFO ] Epoch 21 Batch 4240 Training err. 1.70752 Training err. RA 2.04828 Valid. err. 1.77153
2018-02-03 21:40:37,369 training [INFO ] Epoch 21 Batch 4260 Training err. 1.64163 Training err. RA 2.04637 Valid. err. 1.75447
2018-02-03 21:40:37,829 training [INFO ] Epoch 21 Batch 4280 Training err. 1.71206 Training err. RA 2.04481 Valid. err. 1.75703
2018-02-03 21:40:38,288 training [INFO ] Epoch 21 Batch 4300 Training err. 1.67651 Training err. RA 2.04309 Valid. err. 1.77381
2018-02-03 21:40:38,747 training [INFO ] Epoch 21 Batch 4320 Training err. 1.62917 Training err. RA 2.04118 Valid. err. 1.76507
2018-02-03 21:40:39,207 training [INFO ] Epoch 21 Batch 4340 Training err. 1.64021 Training err. RA 2.03933 Valid. err. 1.74865
2018-02-03 21:40:39,668 training [INFO ] Epoch 21 Batch 4360 Training err. 1.65557 Training err. RA 2.03757 Valid. err. 1.74722
2018-02-03 21:40:40,470 training [INFO ] Epoch 22 Batch 4380 Training err. 1.63568 Training err. RA 2.03574 Valid. err. 1.73858
2018-02-03 21:40:40,933 training [INFO ] Epoch 22 Batch 4400 Training err. 1.59522 Training err. RA 2.03373 Valid. err. 1.74985
2018-02-03 21:40:41,397 training [INFO ] Epoch 22 Batch 4420 Training err. 1.65953 Training err. RA 2.03204 Valid. err. 1.74646
2018-02-03 21:40:41,865 training [INFO ] Epoch 22 Batch 4440 Training err. 1.69701 Training err. RA 2.03053 Valid. err. 1.75054
2018-02-03 21:40:42,329 training [INFO ] Epoch 22 Batch 4460 Training err. 1.63262 Training err. RA 2.02875 Valid. err. 1.74096
2018-02-03 21:40:42,794 training [INFO ] Epoch 22 Batch 4480 Training err. 1.65371 Training err. RA 2.02707 Valid. err. 1.74389
2018-02-03 21:40:43,259 training [INFO ] Epoch 22 Batch 4500 Training err. 1.70089 Training err. RA 2.02562 Valid. err. 1.75029
2018-02-03 21:40:43,722 training [INFO ] Epoch 22 Batch 4520 Training err. 1.63121 Training err. RA 2.02388 Valid. err. 1.74473
2018-02-03 21:40:44,185 training [INFO ] Epoch 22 Batch 4540 Training err. 1.63007 Training err. RA 2.02214 Valid. err. 1.74548
2018-02-03 21:40:44,645 training [INFO ] Epoch 22 Batch 4560 Training err. 1.62264 Training err. RA 2.02039 Valid. err. 1.72523
2018-02-03 21:40:45,443 training [INFO ] Epoch 23 Batch 4580 Training err. 1.62539 Training err. RA 2.01866 Valid. err. 1.73150
2018-02-03 21:40:45,900 training [INFO ] Epoch 23 Batch 4600 Training err. 1.60532 Training err. RA 2.01687 Valid. err. 1.73266
2018-02-03 21:40:46,361 training [INFO ] Epoch 23 Batch 4620 Training err. 1.61270 Training err. RA 2.01512 Valid. err. 1.74924
2018-02-03 21:40:46,830 training [INFO ] Epoch 23 Batch 4640 Training err. 1.66508 Training err. RA 2.01361 Valid. err. 1.73949
2018-02-03 21:40:47,299 training [INFO ] Epoch 23 Batch 4660 Training err. 1.65060 Training err. RA 2.01205 Valid. err. 1.75562
2018-02-03 21:40:47,760 training [INFO ] Epoch 23 Batch 4680 Training err. 1.62834 Training err. RA 2.01041 Valid. err. 1.71980
2018-02-03 21:40:48,226 training [INFO ] Epoch 23 Batch 4700 Training err. 1.69930 Training err. RA 2.00909 Valid. err. 1.73405
2018-02-03 21:40:48,687 training [INFO ] Epoch 23 Batch 4720 Training err. 1.61807 Training err. RA 2.00743 Valid. err. 1.73868
2018-02-03 21:40:49,145 training [INFO ] Epoch 23 Batch 4740 Training err. 1.59938 Training err. RA 2.00571 Valid. err. 1.75583
2018-02-03 21:40:49,606 training [INFO ] Epoch 23 Batch 4760 Training err. 1.60586 Training err. RA 2.00403 Valid. err. 1.71109
2018-02-03 21:40:50,067 training [INFO ] Epoch 23 Batch 4780 Training err. 1.63267 Training err. RA 2.00248 Valid. err. 1.72538
2018-02-03 21:40:50,866 training [INFO ] Epoch 24 Batch 4800 Training err. 1.59393 Training err. RA 2.00077 Valid. err. 1.73700
2018-02-03 21:40:51,326 training [INFO ] Epoch 24 Batch 4820 Training err. 1.57717 Training err. RA 1.99902 Valid. err. 1.72082
2018-02-03 21:40:51,787 training [INFO ] Epoch 24 Batch 4840 Training err. 1.63261 Training err. RA 1.99750 Valid. err. 1.74574
2018-02-03 21:40:52,250 training [INFO ] Epoch 24 Batch 4860 Training err. 1.66755 Training err. RA 1.99614 Valid. err. 1.72315
2018-02-03 21:40:52,715 training [INFO ] Epoch 24 Batch 4880 Training err. 1.60734 Training err. RA 1.99455 Valid. err. 1.74358
2018-02-03 21:40:53,179 training [INFO ] Epoch 24 Batch 4900 Training err. 1.66014 Training err. RA 1.99318 Valid. err. 1.71836
2018-02-03 21:40:53,643 training [INFO ] Epoch 24 Batch 4920 Training err. 1.64499 Training err. RA 1.99177 Valid. err. 1.72233
2018-02-03 21:40:54,111 training [INFO ] Epoch 24 Batch 4940 Training err. 1.59036 Training err. RA 1.99014 Valid. err. 1.71975
2018-02-03 21:40:54,575 training [INFO ] Epoch 24 Batch 4960 Training err. 1.60298 Training err. RA 1.98858 Valid. err. 1.70645
2018-02-03 21:40:55,038 training [INFO ] Epoch 24 Batch 4980 Training err. 1.60701 Training err. RA 1.98705 Valid. err. 1.72206
2018-02-03 21:40:55,849 training [INFO ] Epoch 25 Batch 5000 Training err. 1.59016 Training err. RA 1.98546 Valid. err. 1.70822
2018-02-03 21:40:56,309 training [INFO ] Epoch 25 Batch 5020 Training err. 1.56310 Training err. RA 1.98378 Valid. err. 1.72522
2018-02-03 21:40:56,767 training [INFO ] Epoch 25 Batch 5040 Training err. 1.61533 Training err. RA 1.98232 Valid. err. 1.71007
2018-02-03 21:40:57,227 training [INFO ] Epoch 25 Batch 5060 Training err. 1.65482 Training err. RA 1.98102 Valid. err. 1.72110
2018-02-03 21:40:57,687 training [INFO ] Epoch 25 Batch 5080 Training err. 1.60168 Training err. RA 1.97953 Valid. err. 1.74031
2018-02-03 21:40:58,146 training [INFO ] Epoch 25 Batch 5100 Training err. 1.59400 Training err. RA 1.97802 Valid. err. 1.72862
2018-02-03 21:40:58,604 training [INFO ] Epoch 25 Batch 5120 Training err. 1.66357 Training err. RA 1.97679 Valid. err. 1.71290
2018-02-03 21:40:59,063 training [INFO ] Epoch 25 Batch 5140 Training err. 1.60016 Training err. RA 1.97532 Valid. err. 1.71092
2018-02-03 21:40:59,520 training [INFO ] Epoch 25 Batch 5160 Training err. 1.57319 Training err. RA 1.97377 Valid. err. 1.70620
2018-02-03 21:40:59,978 training [INFO ] Epoch 25 Batch 5180 Training err. 1.58856 Training err. RA 1.97228 Valid. err. 1.69844
2018-02-03 21:41:00,444 training [INFO ] Epoch 25 Batch 5200 Training err. 1.58756 Training err. RA 1.97080 Valid. err. 1.69310
2018-02-03 21:41:01,238 training [INFO ] Epoch 26 Batch 5220 Training err. 1.57780 Training err. RA 1.96929 Valid. err. 1.70710
2018-02-03 21:41:01,697 training [INFO ] Epoch 26 Batch 5240 Training err. 1.54720 Training err. RA 1.96768 Valid. err. 1.72107
2018-02-03 21:41:02,154 training [INFO ] Epoch 26 Batch 5260 Training err. 1.61606 Training err. RA 1.96635 Valid. err. 1.71526
2018-02-03 21:41:02,613 training [INFO ] Epoch 26 Batch 5280 Training err. 1.64465 Training err. RA 1.96513 Valid. err. 1.71824
2018-02-03 21:41:03,084 training [INFO ] Epoch 26 Batch 5300 Training err. 1.57192 Training err. RA 1.96364 Valid. err. 1.71001
2018-02-03 21:41:03,557 training [INFO ] Epoch 26 Batch 5320 Training err. 1.63793 Training err. RA 1.96242 Valid. err. 1.70296
2018-02-03 21:41:04,128 training [INFO ] Epoch 26 Batch 5340 Training err. 1.61178 Training err. RA 1.96111 Valid. err. 1.71543
2018-02-03 21:41:04,701 training [INFO ] Epoch 26 Batch 5360 Training err. 1.56368 Training err. RA 1.95962 Valid. err. 1.71769
2018-02-03 21:41:05,292 training [INFO ] Epoch 26 Batch 5380 Training err. 1.57038 Training err. RA 1.95818 Valid. err. 1.70054
2018-02-03 21:41:05,868 training [INFO ] Epoch 26 Batch 5400 Training err. 1.59745 Training err. RA 1.95684 Valid. err. 1.68621
2018-02-03 21:41:06,900 training [INFO ] Epoch 27 Batch 5420 Training err. 1.55918 Training err. RA 1.95537 Valid. err. 1.68744
2018-02-03 21:41:07,515 training [INFO ] Epoch 27 Batch 5440 Training err. 1.53369 Training err. RA 1.95382 Valid. err. 1.70861
2018-02-03 21:41:08,059 training [INFO ] Epoch 27 Batch 5460 Training err. 1.59559 Training err. RA 1.95251 Valid. err. 1.69802
2018-02-03 21:41:08,526 training [INFO ] Epoch 27 Batch 5480 Training err. 1.63528 Training err. RA 1.95135 Valid. err. 1.70065
2018-02-03 21:41:09,025 training [INFO ] Epoch 27 Batch 5500 Training err. 1.56944 Training err. RA 1.94996 Valid. err. 1.69330
2018-02-03 21:41:09,514 training [INFO ] Epoch 27 Batch 5520 Training err. 1.58642 Training err. RA 1.94865 Valid. err. 1.69884
2018-02-03 21:41:10,031 training [INFO ] Epoch 27 Batch 5540 Training err. 1.63348 Training err. RA 1.94751 Valid. err. 1.71195
2018-02-03 21:41:10,655 training [INFO ] Epoch 27 Batch 5560 Training err. 1.56523 Training err. RA 1.94613 Valid. err. 1.70319
2018-02-03 21:41:11,143 training [INFO ] Epoch 27 Batch 5580 Training err. 1.56829 Training err. RA 1.94478 Valid. err. 1.69641
2018-02-03 21:41:11,628 training [INFO ] Epoch 27 Batch 5600 Training err. 1.56316 Training err. RA 1.94342 Valid. err. 1.67845
2018-02-03 21:41:12,585 training [INFO ] Epoch 28 Batch 5620 Training err. 1.55756 Training err. RA 1.94204 Valid. err. 1.68759
2018-02-03 21:41:13,174 training [INFO ] Epoch 28 Batch 5640 Training err. 1.54177 Training err. RA 1.94062 Valid. err. 1.69021
2018-02-03 21:41:13,754 training [INFO ] Epoch 28 Batch 5660 Training err. 1.55333 Training err. RA 1.93925 Valid. err. 1.69479
2018-02-03 21:41:14,297 training [INFO ] Epoch 28 Batch 5680 Training err. 1.60569 Training err. RA 1.93808 Valid. err. 1.69442
2018-02-03 21:41:14,837 training [INFO ] Epoch 28 Batch 5700 Training err. 1.59183 Training err. RA 1.93687 Valid. err. 1.70864
2018-02-03 21:41:15,388 training [INFO ] Epoch 28 Batch 5720 Training err. 1.56333 Training err. RA 1.93556 Valid. err. 1.67440
2018-02-03 21:41:15,993 training [INFO ] Epoch 28 Batch 5740 Training err. 1.63525 Training err. RA 1.93451 Valid. err. 1.68998
2018-02-03 21:41:16,622 training [INFO ] Epoch 28 Batch 5760 Training err. 1.55642 Training err. RA 1.93320 Valid. err. 1.69103
2018-02-03 21:41:17,226 training [INFO ] Epoch 28 Batch 5780 Training err. 1.54104 Training err. RA 1.93184 Valid. err. 1.70718
2018-02-03 21:41:17,797 training [INFO ] Epoch 28 Batch 5800 Training err. 1.54262 Training err. RA 1.93050 Valid. err. 1.66830
2018-02-03 21:41:18,502 training [INFO ] Epoch 28 Batch 5820 Training err. 1.57747 Training err. RA 1.92929 Valid. err. 1.67973
2018-02-03 21:41:19,589 training [INFO ] Epoch 29 Batch 5840 Training err. 1.52900 Training err. RA 1.92792 Valid. err. 1.69108
2018-02-03 21:41:20,146 training [INFO ] Epoch 29 Batch 5860 Training err. 1.51987 Training err. RA 1.92652 Valid. err. 1.68422
2018-02-03 21:41:20,713 training [INFO ] Epoch 29 Batch 5880 Training err. 1.57479 Training err. RA 1.92533 Valid. err. 1.69659
2018-02-03 21:41:21,255 training [INFO ] Epoch 29 Batch 5900 Training err. 1.61196 Training err. RA 1.92427 Valid. err. 1.67889
2018-02-03 21:41:21,856 training [INFO ] Epoch 29 Batch 5920 Training err. 1.54672 Training err. RA 1.92299 Valid. err. 1.69845
2018-02-03 21:41:22,463 training [INFO ] Epoch 29 Batch 5940 Training err. 1.59631 Training err. RA 1.92189 Valid. err. 1.67097
2018-02-03 21:41:23,031 training [INFO ] Epoch 29 Batch 5960 Training err. 1.58904 Training err. RA 1.92077 Valid. err. 1.68161
2018-02-03 21:41:23,677 training [INFO ] Epoch 29 Batch 5980 Training err. 1.52984 Training err. RA 1.91947 Valid. err. 1.68116
2018-02-03 21:41:24,349 training [INFO ] Epoch 29 Batch 6000 Training err. 1.54354 Training err. RA 1.91821 Valid. err. 1.66649
2018-02-03 21:41:24,944 training [INFO ] Epoch 29 Batch 6020 Training err. 1.55624 Training err. RA 1.91701 Valid. err. 1.67221
2018-02-03 21:41:25,978 training [INFO ] Epoch 30 Batch 6040 Training err. 1.52773 Training err. RA 1.91572 Valid. err. 1.67554
2018-02-03 21:41:26,463 training [INFO ] Epoch 30 Batch 6060 Training err. 1.50757 Training err. RA 1.91437 Valid. err. 1.68891
2018-02-03 21:41:27,004 training [INFO ] Epoch 30 Batch 6080 Training err. 1.56158 Training err. RA 1.91321 Valid. err. 1.67137
2018-02-03 21:41:27,600 training [INFO ] Epoch 30 Batch 6100 Training err. 1.60068 Training err. RA 1.91219 Valid. err. 1.67836
2018-02-03 21:41:28,220 training [INFO ] Epoch 30 Batch 6120 Training err. 1.54653 Training err. RA 1.91099 Valid. err. 1.69563
2018-02-03 21:41:29,002 training [INFO ] Epoch 30 Batch 6140 Training err. 1.53507 Training err. RA 1.90977 Valid. err. 1.68066
2018-02-03 21:41:29,576 training [INFO ] Epoch 30 Batch 6160 Training err. 1.60662 Training err. RA 1.90879 Valid. err. 1.67257
2018-02-03 21:41:30,050 training [INFO ] Epoch 30 Batch 6180 Training err. 1.54148 Training err. RA 1.90760 Valid. err. 1.67304
2018-02-03 21:41:30,562 training [INFO ] Epoch 30 Batch 6200 Training err. 1.51763 Training err. RA 1.90634 Valid. err. 1.66913
2018-02-03 21:41:31,207 training [INFO ] Epoch 30 Batch 6220 Training err. 1.53338 Training err. RA 1.90514 Valid. err. 1.66058
2018-02-03 21:41:32,022 training [INFO ] Epoch 30 Batch 6240 Training err. 1.53366 Training err. RA 1.90395 Valid. err. 1.65744
2018-02-03 21:41:32,869 training [INFO ] Epoch 31 Batch 6260 Training err. 1.52461 Training err. RA 1.90274 Valid. err. 1.66524
2018-02-03 21:41:33,336 training [INFO ] Epoch 31 Batch 6280 Training err. 1.49275 Training err. RA 1.90143 Valid. err. 1.68260
2018-02-03 21:41:33,812 training [INFO ] Epoch 31 Batch 6300 Training err. 1.56343 Training err. RA 1.90036 Valid. err. 1.67913
2018-02-03 21:41:34,282 training [INFO ] Epoch 31 Batch 6320 Training err. 1.59443 Training err. RA 1.89939 Valid. err. 1.67381
2018-02-03 21:41:34,761 training [INFO ] Epoch 31 Batch 6340 Training err. 1.51608 Training err. RA 1.89818 Valid. err. 1.66999
2018-02-03 21:41:35,236 training [INFO ] Epoch 31 Batch 6360 Training err. 1.57955 Training err. RA 1.89718 Valid. err. 1.67045
2018-02-03 21:41:35,706 training [INFO ] Epoch 31 Batch 6380 Training err. 1.56121 Training err. RA 1.89613 Valid. err. 1.67598
2018-02-03 21:41:36,187 training [INFO ] Epoch 31 Batch 6400 Training err. 1.51007 Training err. RA 1.89492 Valid. err. 1.68815
2018-02-03 21:41:36,651 training [INFO ] Epoch 31 Batch 6420 Training err. 1.51515 Training err. RA 1.89374 Valid. err. 1.66785
2018-02-03 21:41:37,115 training [INFO ] Epoch 31 Batch 6440 Training err. 1.55151 Training err. RA 1.89267 Valid. err. 1.65162
2018-02-03 21:41:37,938 training [INFO ] Epoch 32 Batch 6460 Training err. 1.50622 Training err. RA 1.89148 Valid. err. 1.65392
2018-02-03 21:41:38,417 training [INFO ] Epoch 32 Batch 6480 Training err. 1.48376 Training err. RA 1.89022 Valid. err. 1.68889
2018-02-03 21:41:38,891 training [INFO ] Epoch 32 Batch 6500 Training err. 1.54607 Training err. RA 1.88916 Valid. err. 1.66453
2018-02-03 21:41:39,370 training [INFO ] Epoch 32 Batch 6520 Training err. 1.58511 Training err. RA 1.88823 Valid. err. 1.66635
2018-02-03 21:41:39,829 training [INFO ] Epoch 32 Batch 6540 Training err. 1.51824 Training err. RA 1.88710 Valid. err. 1.65882
2018-02-03 21:41:40,293 training [INFO ] Epoch 32 Batch 6560 Training err. 1.53247 Training err. RA 1.88601 Valid. err. 1.66190
2018-02-03 21:41:40,847 training [INFO ] Epoch 32 Batch 6580 Training err. 1.58347 Training err. RA 1.88509 Valid. err. 1.67152
2018-02-03 21:41:41,318 training [INFO ] Epoch 32 Batch 6600 Training err. 1.51247 Training err. RA 1.88397 Valid. err. 1.67801
2018-02-03 21:41:41,791 training [INFO ] Epoch 32 Batch 6620 Training err. 1.51673 Training err. RA 1.88286 Valid. err. 1.66043
2018-02-03 21:41:42,267 training [INFO ] Epoch 32 Batch 6640 Training err. 1.51415 Training err. RA 1.88175 Valid. err. 1.65381
2018-02-03 21:41:43,111 training [INFO ] Epoch 33 Batch 6660 Training err. 1.50678 Training err. RA 1.88062 Valid. err. 1.65984
2018-02-03 21:41:43,703 training [INFO ] Epoch 33 Batch 6680 Training err. 1.49295 Training err. RA 1.87946 Valid. err. 1.66010
2018-02-03 21:41:44,169 training [INFO ] Epoch 33 Batch 6700 Training err. 1.50375 Training err. RA 1.87834 Valid. err. 1.66157
2018-02-03 21:41:44,627 training [INFO ] Epoch 33 Batch 6720 Training err. 1.55812 Training err. RA 1.87738 Valid. err. 1.65951
2018-02-03 21:41:45,088 training [INFO ] Epoch 33 Batch 6740 Training err. 1.54341 Training err. RA 1.87639 Valid. err. 1.67802
2018-02-03 21:41:45,547 training [INFO ] Epoch 33 Batch 6760 Training err. 1.51214 Training err. RA 1.87532 Valid. err. 1.64630
2018-02-03 21:41:46,006 training [INFO ] Epoch 33 Batch 6780 Training err. 1.58420 Training err. RA 1.87446 Valid. err. 1.66081
2018-02-03 21:41:46,465 training [INFO ] Epoch 33 Batch 6800 Training err. 1.50677 Training err. RA 1.87338 Valid. err. 1.66391
2018-02-03 21:41:46,924 training [INFO ] Epoch 33 Batch 6820 Training err. 1.49358 Training err. RA 1.87226 Valid. err. 1.67133
2018-02-03 21:41:47,382 training [INFO ] Epoch 33 Batch 6840 Training err. 1.48986 Training err. RA 1.87114 Valid. err. 1.64467
2018-02-03 21:41:47,843 training [INFO ] Epoch 33 Batch 6860 Training err. 1.53247 Training err. RA 1.87016 Valid. err. 1.65152
2018-02-03 21:41:48,659 training [INFO ] Epoch 34 Batch 6880 Training err. 1.48212 Training err. RA 1.86903 Valid. err. 1.66669
2018-02-03 21:41:49,124 training [INFO ] Epoch 34 Batch 6900 Training err. 1.47232 Training err. RA 1.86788 Valid. err. 1.66154
2018-02-03 21:41:49,589 training [INFO ] Epoch 34 Batch 6920 Training err. 1.52995 Training err. RA 1.86690 Valid. err. 1.66593
2018-02-03 21:41:50,054 training [INFO ] Epoch 34 Batch 6940 Training err. 1.56541 Training err. RA 1.86603 Valid. err. 1.64935
2018-02-03 21:41:50,519 training [INFO ] Epoch 34 Batch 6960 Training err. 1.49853 Training err. RA 1.86498 Valid. err. 1.67060
2018-02-03 21:41:50,984 training [INFO ] Epoch 34 Batch 6980 Training err. 1.54631 Training err. RA 1.86406 Valid. err. 1.64282
2018-02-03 21:41:51,448 training [INFO ] Epoch 34 Batch 7000 Training err. 1.54330 Training err. RA 1.86315 Valid. err. 1.64770
2018-02-03 21:41:51,920 training [INFO ] Epoch 34 Batch 7020 Training err. 1.48163 Training err. RA 1.86206 Valid. err. 1.65496
2018-02-03 21:41:52,452 training [INFO ] Epoch 34 Batch 7040 Training err. 1.49384 Training err. RA 1.86101 Valid. err. 1.64314
2018-02-03 21:41:52,930 training [INFO ] Epoch 34 Batch 7060 Training err. 1.51281 Training err. RA 1.86003 Valid. err. 1.63986
2018-02-03 21:41:53,781 training [INFO ] Epoch 35 Batch 7080 Training err. 1.48032 Training err. RA 1.85895 Valid. err. 1.64801
2018-02-03 21:41:54,250 training [INFO ] Epoch 35 Batch 7100 Training err. 1.46404 Training err. RA 1.85784 Valid. err. 1.65838
2018-02-03 21:41:54,720 training [INFO ] Epoch 35 Batch 7120 Training err. 1.51618 Training err. RA 1.85688 Valid. err. 1.64975
2018-02-03 21:41:55,207 training [INFO ] Epoch 35 Batch 7140 Training err. 1.55491 Training err. RA 1.85604 Valid. err. 1.64851
2018-02-03 21:41:55,694 training [INFO ] Epoch 35 Batch 7160 Training err. 1.50119 Training err. RA 1.85505 Valid. err. 1.66901
2018-02-03 21:41:56,189 training [INFO ] Epoch 35 Batch 7180 Training err. 1.49013 Training err. RA 1.85403 Valid. err. 1.65301
2018-02-03 21:41:56,667 training [INFO ] Epoch 35 Batch 7200 Training err. 1.55978 Training err. RA 1.85321 Valid. err. 1.64456
2018-02-03 21:41:57,140 training [INFO ] Epoch 35 Batch 7220 Training err. 1.49393 Training err. RA 1.85222 Valid. err. 1.65549
2018-02-03 21:41:57,621 training [INFO ] Epoch 35 Batch 7240 Training err. 1.47199 Training err. RA 1.85117 Valid. err. 1.65535
2018-02-03 21:41:58,100 training [INFO ] Epoch 35 Batch 7260 Training err. 1.48652 Training err. RA 1.85016 Valid. err. 1.63351
2018-02-03 21:41:58,585 training [INFO ] Epoch 35 Batch 7280 Training err. 1.49158 Training err. RA 1.84918 Valid. err. 1.63713
2018-02-03 21:41:59,437 training [INFO ] Epoch 36 Batch 7300 Training err. 1.48417 Training err. RA 1.84818 Valid. err. 1.63846
2018-02-03 21:41:59,919 training [INFO ] Epoch 36 Batch 7320 Training err. 1.44666 Training err. RA 1.84708 Valid. err. 1.66016
2018-02-03 21:42:00,403 training [INFO ] Epoch 36 Batch 7340 Training err. 1.52008 Training err. RA 1.84619 Valid. err. 1.65284
2018-02-03 21:42:00,883 training [INFO ] Epoch 36 Batch 7360 Training err. 1.55102 Training err. RA 1.84539 Valid. err. 1.64911
2018-02-03 21:42:01,356 training [INFO ] Epoch 36 Batch 7380 Training err. 1.47150 Training err. RA 1.84437 Valid. err. 1.64885
2018-02-03 21:42:01,859 training [INFO ] Epoch 36 Batch 7400 Training err. 1.53366 Training err. RA 1.84353 Valid. err. 1.64965
2018-02-03 21:42:02,331 training [INFO ] Epoch 36 Batch 7420 Training err. 1.51850 Training err. RA 1.84266 Valid. err. 1.65047
2018-02-03 21:42:02,802 training [INFO ] Epoch 36 Batch 7440 Training err. 1.46710 Training err. RA 1.84165 Valid. err. 1.66020
2018-02-03 21:42:03,262 training [INFO ] Epoch 36 Batch 7460 Training err. 1.46419 Training err. RA 1.84064 Valid. err. 1.64402
2018-02-03 21:42:03,721 training [INFO ] Epoch 36 Batch 7480 Training err. 1.50763 Training err. RA 1.83975 Valid. err. 1.63155
2018-02-03 21:42:04,595 training [INFO ] Epoch 37 Batch 7500 Training err. 1.46394 Training err. RA 1.83874 Valid. err. 1.63308
2018-02-03 21:42:05,062 training [INFO ] Epoch 37 Batch 7520 Training err. 1.44207 Training err. RA 1.83769 Valid. err. 1.67779
2018-02-03 21:42:05,525 training [INFO ] Epoch 37 Batch 7540 Training err. 1.50521 Training err. RA 1.83681 Valid. err. 1.65270
2018-02-03 21:42:05,995 training [INFO ] Epoch 37 Batch 7560 Training err. 1.54347 Training err. RA 1.83603 Valid. err. 1.64673
2018-02-03 21:42:06,464 training [INFO ] Epoch 37 Batch 7580 Training err. 1.47394 Training err. RA 1.83507 Valid. err. 1.63551
2018-02-03 21:42:06,971 training [INFO ] Epoch 37 Batch 7600 Training err. 1.49093 Training err. RA 1.83417 Valid. err. 1.62906
2018-02-03 21:42:07,455 training [INFO ] Epoch 37 Batch 7620 Training err. 1.53993 Training err. RA 1.83340 Valid. err. 1.64985
2018-02-03 21:42:07,945 training [INFO ] Epoch 37 Batch 7640 Training err. 1.46901 Training err. RA 1.83244 Valid. err. 1.66048
2018-02-03 21:42:08,414 training [INFO ] Epoch 37 Batch 7660 Training err. 1.47425 Training err. RA 1.83151 Valid. err. 1.63875
2018-02-03 21:42:08,881 training [INFO ] Epoch 37 Batch 7680 Training err. 1.47219 Training err. RA 1.83057 Valid. err. 1.63874
2018-02-03 21:42:09,742 training [INFO ] Epoch 38 Batch 7700 Training err. 1.46627 Training err. RA 1.82963 Valid. err. 1.64443
2018-02-03 21:42:10,208 training [INFO ] Epoch 38 Batch 7720 Training err. 1.45464 Training err. RA 1.82865 Valid. err. 1.63914
2018-02-03 21:42:10,693 training [INFO ] Epoch 38 Batch 7740 Training err. 1.46177 Training err. RA 1.82771 Valid. err. 1.64343
2018-02-03 21:42:11,167 training [INFO ] Epoch 38 Batch 7760 Training err. 1.51780 Training err. RA 1.82691 Valid. err. 1.64623
2018-02-03 21:42:11,643 training [INFO ] Epoch 38 Batch 7780 Training err. 1.50106 Training err. RA 1.82607 Valid. err. 1.65939
2018-02-03 21:42:12,109 training [INFO ] Epoch 38 Batch 7800 Training err. 1.47078 Training err. RA 1.82516 Valid. err. 1.62477
2018-02-03 21:42:12,572 training [INFO ] Epoch 38 Batch 7820 Training err. 1.54244 Training err. RA 1.82444 Valid. err. 1.64277
2018-02-03 21:42:13,037 training [INFO ] Epoch 38 Batch 7840 Training err. 1.46469 Training err. RA 1.82352 Valid. err. 1.64487
2018-02-03 21:42:13,503 training [INFO ] Epoch 38 Batch 7860 Training err. 1.45415 Training err. RA 1.82258 Valid. err. 1.65989
2018-02-03 21:42:13,969 training [INFO ] Epoch 38 Batch 7880 Training err. 1.44782 Training err. RA 1.82163 Valid. err. 1.62753
2018-02-03 21:42:14,433 training [INFO ] Epoch 38 Batch 7900 Training err. 1.49291 Training err. RA 1.82080 Valid. err. 1.63733
2018-02-03 21:42:15,336 training [INFO ] Epoch 39 Batch 7920 Training err. 1.44325 Training err. RA 1.81984 Valid. err. 1.64880
2018-02-03 21:42:15,800 training [INFO ] Epoch 39 Batch 7940 Training err. 1.43398 Training err. RA 1.81887 Valid. err. 1.64726
2018-02-03 21:42:16,265 training [INFO ] Epoch 39 Batch 7960 Training err. 1.49191 Training err. RA 1.81805 Valid. err. 1.64706
2018-02-03 21:42:16,724 training [INFO ] Epoch 39 Batch 7980 Training err. 1.52427 Training err. RA 1.81731 Valid. err. 1.63259
2018-02-03 21:42:17,185 training [INFO ] Epoch 39 Batch 8000 Training err. 1.45681 Training err. RA 1.81641 Valid. err. 1.64149
2018-02-03 21:42:17,654 training [INFO ] Epoch 39 Batch 8020 Training err. 1.50745 Training err. RA 1.81564 Valid. err. 1.62716
2018-02-03 21:42:18,195 training [INFO ] Epoch 39 Batch 8040 Training err. 1.50499 Training err. RA 1.81487 Valid. err. 1.62567
2018-02-03 21:42:18,655 training [INFO ] Epoch 39 Batch 8060 Training err. 1.44120 Training err. RA 1.81394 Valid. err. 1.63804
2018-02-03 21:42:19,116 training [INFO ] Epoch 39 Batch 8080 Training err. 1.45528 Training err. RA 1.81305 Valid. err. 1.63117
2018-02-03 21:42:19,574 training [INFO ] Epoch 39 Batch 8100 Training err. 1.47490 Training err. RA 1.81222 Valid. err. 1.61994
2018-02-03 21:42:20,398 training [INFO ] Epoch 40 Batch 8120 Training err. 1.44035 Training err. RA 1.81130 Valid. err. 1.63369
2018-02-03 21:42:20,862 training [INFO ] Epoch 40 Batch 8140 Training err. 1.42824 Training err. RA 1.81036 Valid. err. 1.64300
2018-02-03 21:42:21,326 training [INFO ] Epoch 40 Batch 8160 Training err. 1.47890 Training err. RA 1.80955 Valid. err. 1.63526
2018-02-03 21:42:21,791 training [INFO ] Epoch 40 Batch 8180 Training err. 1.51632 Training err. RA 1.80883 Valid. err. 1.62900
2018-02-03 21:42:22,255 training [INFO ] Epoch 40 Batch 8200 Training err. 1.45951 Training err. RA 1.80798 Valid. err. 1.65043
2018-02-03 21:42:22,720 training [INFO ] Epoch 40 Batch 8220 Training err. 1.45330 Training err. RA 1.80712 Valid. err. 1.62967
2018-02-03 21:42:23,185 training [INFO ] Epoch 40 Batch 8240 Training err. 1.52083 Training err. RA 1.80642 Valid. err. 1.62731
2018-02-03 21:42:23,649 training [INFO ] Epoch 40 Batch 8260 Training err. 1.45496 Training err. RA 1.80557 Valid. err. 1.64078
2018-02-03 21:42:24,113 training [INFO ] Epoch 40 Batch 8280 Training err. 1.43615 Training err. RA 1.80468 Valid. err. 1.64418
2018-02-03 21:42:24,573 training [INFO ] Epoch 40 Batch 8300 Training err. 1.44808 Training err. RA 1.80382 Valid. err. 1.61569
2018-02-03 21:42:25,078 training [INFO ] Epoch 40 Batch 8320 Training err. 1.45748 Training err. RA 1.80299 Valid. err. 1.61748
2018-02-03 21:42:25,948 training [INFO ] Epoch 41 Batch 8340 Training err. 1.44696 Training err. RA 1.80213 Valid. err. 1.62003
2018-02-03 21:42:26,430 training [INFO ] Epoch 41 Batch 8360 Training err. 1.40916 Training err. RA 1.80119 Valid. err. 1.66330
2018-02-03 21:42:26,892 training [INFO ] Epoch 41 Batch 8380 Training err. 1.48536 Training err. RA 1.80044 Valid. err. 1.63702
2018-02-03 21:42:27,355 training [INFO ] Epoch 41 Batch 8400 Training err. 1.51192 Training err. RA 1.79975 Valid. err. 1.63239
2018-02-03 21:42:27,816 training [INFO ] Epoch 41 Batch 8420 Training err. 1.43256 Training err. RA 1.79888 Valid. err. 1.63461
2018-02-03 21:42:28,297 training [INFO ] Epoch 41 Batch 8440 Training err. 1.49566 Training err. RA 1.79816 Valid. err. 1.63584
2018-02-03 21:42:28,765 training [INFO ] Epoch 41 Batch 8460 Training err. 1.48386 Training err. RA 1.79742 Valid. err. 1.63805
2018-02-03 21:42:29,241 training [INFO ] Epoch 41 Batch 8480 Training err. 1.43134 Training err. RA 1.79655 Valid. err. 1.64327
2018-02-03 21:42:29,706 training [INFO ] Epoch 41 Batch 8500 Training err. 1.42823 Training err. RA 1.79569 Valid. err. 1.62439
2018-02-03 21:42:30,171 training [INFO ] Epoch 41 Batch 8520 Training err. 1.47220 Training err. RA 1.79493 Valid. err. 1.61889
2018-02-03 21:42:31,001 training [INFO ] Epoch 42 Batch 8540 Training err. 1.42686 Training err. RA 1.79407 Valid. err. 1.62192
2018-02-03 21:42:31,466 training [INFO ] Epoch 42 Batch 8560 Training err. 1.40912 Training err. RA 1.79317 Valid. err. 1.65770
2018-02-03 21:42:31,932 training [INFO ] Epoch 42 Batch 8580 Training err. 1.47068 Training err. RA 1.79242 Valid. err. 1.63475
2018-02-03 21:42:32,394 training [INFO ] Epoch 42 Batch 8600 Training err. 1.50570 Training err. RA 1.79175 Valid. err. 1.63040
2018-02-03 21:42:32,854 training [INFO ] Epoch 42 Batch 8620 Training err. 1.43454 Training err. RA 1.79092 Valid. err. 1.62380
2018-02-03 21:42:33,314 training [INFO ] Epoch 42 Batch 8640 Training err. 1.45474 Training err. RA 1.79014 Valid. err. 1.61020
2018-02-03 21:42:33,775 training [INFO ] Epoch 42 Batch 8660 Training err. 1.50384 Training err. RA 1.78948 Valid. err. 1.63370
2018-02-03 21:42:34,235 training [INFO ] Epoch 42 Batch 8680 Training err. 1.43332 Training err. RA 1.78866 Valid. err. 1.64699
2018-02-03 21:42:34,694 training [INFO ] Epoch 42 Batch 8700 Training err. 1.43968 Training err. RA 1.78786 Valid. err. 1.63195
2018-02-03 21:42:35,156 training [INFO ] Epoch 42 Batch 8720 Training err. 1.43876 Training err. RA 1.78706 Valid. err. 1.62280
2018-02-03 21:42:35,992 training [INFO ] Epoch 43 Batch 8740 Training err. 1.43277 Training err. RA 1.78625 Valid. err. 1.62621
2018-02-03 21:42:36,451 training [INFO ] Epoch 43 Batch 8760 Training err. 1.42160 Training err. RA 1.78541 Valid. err. 1.61958
2018-02-03 21:42:36,915 training [INFO ] Epoch 43 Batch 8780 Training err. 1.42557 Training err. RA 1.78459 Valid. err. 1.63503
2018-02-03 21:42:37,380 training [INFO ] Epoch 43 Batch 8800 Training err. 1.48510 Training err. RA 1.78391 Valid. err. 1.64191
2018-02-03 21:42:37,843 training [INFO ] Epoch 43 Batch 8820 Training err. 1.46340 Training err. RA 1.78319 Valid. err. 1.64483
2018-02-03 21:42:38,307 training [INFO ] Epoch 43 Batch 8840 Training err. 1.43532 Training err. RA 1.78240 Valid. err. 1.61388
2018-02-03 21:42:38,771 training [INFO ] Epoch 43 Batch 8860 Training err. 1.50591 Training err. RA 1.78178 Valid. err. 1.63158
2018-02-03 21:42:39,235 training [INFO ] Epoch 43 Batch 8880 Training err. 1.43138 Training err. RA 1.78099 Valid. err. 1.63309
2018-02-03 21:42:39,699 training [INFO ] Epoch 43 Batch 8900 Training err. 1.42126 Training err. RA 1.78018 Valid. err. 1.65902
2018-02-03 21:42:40,177 training [INFO ] Epoch 43 Batch 8920 Training err. 1.41384 Training err. RA 1.77936 Valid. err. 1.61475
2018-02-03 21:42:40,773 training [INFO ] Epoch 43 Batch 8940 Training err. 1.46159 Training err. RA 1.77865 Valid. err. 1.62461
2018-02-03 21:42:41,598 training [INFO ] Epoch 44 Batch 8960 Training err. 1.40851 Training err. RA 1.77782 Valid. err. 1.63808
2018-02-03 21:42:42,077 training [INFO ] Epoch 44 Batch 8980 Training err. 1.40070 Training err. RA 1.77698 Valid. err. 1.63919
2018-02-03 21:42:42,551 training [INFO ] Epoch 44 Batch 9000 Training err. 1.45984 Training err. RA 1.77627 Valid. err. 1.63353
2018-02-03 21:42:43,012 training [INFO ] Epoch 44 Batch 9020 Training err. 1.48857 Training err. RA 1.77564 Valid. err. 1.62162
2018-02-03 21:42:43,485 training [INFO ] Epoch 44 Batch 9040 Training err. 1.42041 Training err. RA 1.77485 Valid. err. 1.62677
2018-02-03 21:42:43,962 training [INFO ] Epoch 44 Batch 9060 Training err. 1.47180 Training err. RA 1.77418 Valid. err. 1.61850
2018-02-03 21:42:44,450 training [INFO ] Epoch 44 Batch 9080 Training err. 1.47231 Training err. RA 1.77352 Valid. err. 1.61706
2018-02-03 21:42:44,911 training [INFO ] Epoch 44 Batch 9100 Training err. 1.40750 Training err. RA 1.77271 Valid. err. 1.62578
2018-02-03 21:42:45,388 training [INFO ] Epoch 44 Batch 9120 Training err. 1.42334 Training err. RA 1.77195 Valid. err. 1.62177
2018-02-03 21:42:45,880 training [INFO ] Epoch 44 Batch 9140 Training err. 1.44299 Training err. RA 1.77123 Valid. err. 1.60714
2018-02-03 21:42:46,858 training [INFO ] Epoch 45 Batch 9160 Training err. 1.40757 Training err. RA 1.77043 Valid. err. 1.61634
2018-02-03 21:42:47,327 training [INFO ] Epoch 45 Batch 9180 Training err. 1.39680 Training err. RA 1.76962 Valid. err. 1.63367
2018-02-03 21:42:47,788 training [INFO ] Epoch 45 Batch 9200 Training err. 1.44602 Training err. RA 1.76891 Valid. err. 1.61577
2018-02-03 21:42:48,262 training [INFO ] Epoch 45 Batch 9220 Training err. 1.48386 Training err. RA 1.76830 Valid. err. 1.61594
2018-02-03 21:42:48,751 training [INFO ] Epoch 45 Batch 9240 Training err. 1.42366 Training err. RA 1.76755 Valid. err. 1.64035
2018-02-03 21:42:49,216 training [INFO ] Epoch 45 Batch 9260 Training err. 1.42126 Training err. RA 1.76680 Valid. err. 1.61311
2018-02-03 21:42:49,688 training [INFO ] Epoch 45 Batch 9280 Training err. 1.48657 Training err. RA 1.76620 Valid. err. 1.61573
2018-02-03 21:42:50,152 training [INFO ] Epoch 45 Batch 9300 Training err. 1.42222 Training err. RA 1.76546 Valid. err. 1.62843
2018-02-03 21:42:50,644 training [INFO ] Epoch 45 Batch 9320 Training err. 1.40470 Training err. RA 1.76468 Valid. err. 1.63122
2018-02-03 21:42:51,145 training [INFO ] Epoch 45 Batch 9340 Training err. 1.41654 Training err. RA 1.76394 Valid. err. 1.60821
2018-02-03 21:42:51,638 training [INFO ] Epoch 45 Batch 9360 Training err. 1.42785 Training err. RA 1.76322 Valid. err. 1.60345
2018-02-03 21:42:52,505 training [INFO ] Epoch 46 Batch 9380 Training err. 1.41261 Training err. RA 1.76247 Valid. err. 1.60771
2018-02-03 21:42:52,992 training [INFO ] Epoch 46 Batch 9400 Training err. 1.37694 Training err. RA 1.76165 Valid. err. 1.65010
2018-02-03 21:42:53,457 training [INFO ] Epoch 46 Batch 9420 Training err. 1.45520 Training err. RA 1.76100 Valid. err. 1.62583
2018-02-03 21:42:53,930 training [INFO ] Epoch 46 Batch 9440 Training err. 1.47884 Training err. RA 1.76040 Valid. err. 1.62339
2018-02-03 21:42:54,418 training [INFO ] Epoch 46 Batch 9460 Training err. 1.40030 Training err. RA 1.75964 Valid. err. 1.62441
2018-02-03 21:42:54,909 training [INFO ] Epoch 46 Batch 9480 Training err. 1.46261 Training err. RA 1.75902 Valid. err. 1.63279
2018-02-03 21:42:55,386 training [INFO ] Epoch 46 Batch 9500 Training err. 1.45391 Training err. RA 1.75837 Valid. err. 1.62918
2018-02-03 21:42:55,864 training [INFO ] Epoch 46 Batch 9520 Training err. 1.39977 Training err. RA 1.75762 Valid. err. 1.63019
2018-02-03 21:42:56,343 training [INFO ] Epoch 46 Batch 9540 Training err. 1.39733 Training err. RA 1.75687 Valid. err. 1.61218
2018-02-03 21:42:56,823 training [INFO ] Epoch 46 Batch 9560 Training err. 1.44079 Training err. RA 1.75620 Valid. err. 1.60778
2018-02-03 21:42:57,702 training [INFO ] Epoch 47 Batch 9580 Training err. 1.39981 Training err. RA 1.75546 Valid. err. 1.61445
2018-02-03 21:42:58,206 training [INFO ] Epoch 47 Batch 9600 Training err. 1.37994 Training err. RA 1.75468 Valid. err. 1.63889
2018-02-03 21:42:58,683 training [INFO ] Epoch 47 Batch 9620 Training err. 1.43952 Training err. RA 1.75402 Valid. err. 1.62032
2018-02-03 21:42:59,159 training [INFO ] Epoch 47 Batch 9640 Training err. 1.47277 Training err. RA 1.75344 Valid. err. 1.62090
2018-02-03 21:42:59,623 training [INFO ] Epoch 47 Batch 9660 Training err. 1.40248 Training err. RA 1.75271 Valid. err. 1.62013
2018-02-03 21:43:00,088 training [INFO ] Epoch 47 Batch 9680 Training err. 1.42253 Training err. RA 1.75203 Valid. err. 1.59856
2018-02-03 21:43:00,575 training [INFO ] Epoch 47 Batch 9700 Training err. 1.47304 Training err. RA 1.75146 Valid. err. 1.62458
2018-02-03 21:43:01,046 training [INFO ] Epoch 47 Batch 9720 Training err. 1.40130 Training err. RA 1.75073 Valid. err. 1.63360
2018-02-03 21:43:01,535 training [INFO ] Epoch 47 Batch 9740 Training err. 1.40743 Training err. RA 1.75003 Valid. err. 1.63321
2018-02-03 21:43:02,006 training [INFO ] Epoch 47 Batch 9760 Training err. 1.40918 Training err. RA 1.74933 Valid. err. 1.61228
2018-02-03 21:43:02,836 training [INFO ] Epoch 48 Batch 9780 Training err. 1.40366 Training err. RA 1.74862 Valid. err. 1.61208
2018-02-03 21:43:03,304 training [INFO ] Epoch 48 Batch 9800 Training err. 1.39164 Training err. RA 1.74790 Valid. err. 1.60933
2018-02-03 21:43:03,778 training [INFO ] Epoch 48 Batch 9820 Training err. 1.39470 Training err. RA 1.74718 Valid. err. 1.63181
2018-02-03 21:43:04,251 training [INFO ] Epoch 48 Batch 9840 Training err. 1.45711 Training err. RA 1.74659 Valid. err. 1.63274
2018-02-03 21:43:04,718 training [INFO ] Epoch 48 Batch 9860 Training err. 1.43226 Training err. RA 1.74595 Valid. err. 1.63083
2018-02-03 21:43:05,205 training [INFO ] Epoch 48 Batch 9880 Training err. 1.40487 Training err. RA 1.74526 Valid. err. 1.60752
2018-02-03 21:43:05,671 training [INFO ] Epoch 48 Batch 9900 Training err. 1.47385 Training err. RA 1.74471 Valid. err. 1.62714
2018-02-03 21:43:06,167 training [INFO ] Epoch 48 Batch 9920 Training err. 1.40129 Training err. RA 1.74402 Valid. err. 1.62361
2018-02-03 21:43:06,636 training [INFO ] Epoch 48 Batch 9940 Training err. 1.39028 Training err. RA 1.74331 Valid. err. 1.65423
2018-02-03 21:43:07,100 training [INFO ] Epoch 48 Batch 9960 Training err. 1.38380 Training err. RA 1.74258 Valid. err. 1.60346
2018-02-03 21:43:07,565 training [INFO ] Epoch 48 Batch 9980 Training err. 1.43458 Training err. RA 1.74197 Valid. err. 1.61626
2018-02-03 21:43:08,424 training [INFO ] Epoch 49 Batch10000 Training err. 1.38054 Training err. RA 1.74124 Valid. err. 1.62932
2018-02-03 21:43:08,901 training [INFO ] Epoch 49 Batch10020 Training err. 1.37066 Training err. RA 1.74050 Valid. err. 1.62953
2018-02-03 21:43:09,396 training [INFO ] Epoch 49 Batch10040 Training err. 1.43128 Training err. RA 1.73989 Valid. err. 1.62846
2018-02-03 21:43:09,891 training [INFO ] Epoch 49 Batch10060 Training err. 1.45899 Training err. RA 1.73933 Valid. err. 1.61156
2018-02-03 21:43:10,356 training [INFO ] Epoch 49 Batch10080 Training err. 1.39078 Training err. RA 1.73864 Valid. err. 1.62063
2018-02-03 21:43:10,816 training [INFO ] Epoch 49 Batch10100 Training err. 1.43975 Training err. RA 1.73805 Valid. err. 1.61469
2018-02-03 21:43:11,308 training [INFO ] Epoch 49 Batch10120 Training err. 1.44309 Training err. RA 1.73746 Valid. err. 1.61305
2018-02-03 21:43:11,768 training [INFO ] Epoch 49 Batch10140 Training err. 1.37774 Training err. RA 1.73675 Valid. err. 1.61677
2018-02-03 21:43:12,261 training [INFO ] Epoch 49 Batch10160 Training err. 1.39358 Training err. RA 1.73608 Valid. err. 1.61372
2018-02-03 21:43:12,742 training [INFO ] Epoch 49 Batch10180 Training err. 1.41467 Training err. RA 1.73545 Valid. err. 1.59963
2018-02-03 21:43:13,558 training [INFO ] Epoch 50 Batch10200 Training err. 1.38119 Training err. RA 1.73475 Valid. err. 1.60740
2018-02-03 21:43:14,022 training [INFO ] Epoch 50 Batch10220 Training err. 1.37135 Training err. RA 1.73404 Valid. err. 1.62397
2018-02-03 21:43:14,514 training [INFO ] Epoch 50 Batch10240 Training err. 1.41737 Training err. RA 1.73342 Valid. err. 1.60511
2018-02-03 21:43:14,974 training [INFO ] Epoch 50 Batch10260 Training err. 1.45486 Training err. RA 1.73288 Valid. err. 1.60882
2018-02-03 21:43:15,436 training [INFO ] Epoch 50 Batch10280 Training err. 1.39412 Training err. RA 1.73222 Valid. err. 1.63084
2018-02-03 21:43:15,933 training [INFO ] Epoch 50 Batch10300 Training err. 1.39183 Training err. RA 1.73156 Valid. err. 1.60661
2018-02-03 21:43:16,404 training [INFO ] Epoch 50 Batch10320 Training err. 1.45644 Training err. RA 1.73103 Valid. err. 1.61352
2018-02-03 21:43:16,905 training [INFO ] Epoch 50 Batch10340 Training err. 1.39150 Training err. RA 1.73037 Valid. err. 1.61519
2018-02-03 21:43:17,409 training [INFO ] Epoch 50 Batch10360 Training err. 1.37534 Training err. RA 1.72968 Valid. err. 1.63287
2018-02-03 21:43:17,905 training [INFO ] Epoch 50 Batch10380 Training err. 1.38901 Training err. RA 1.72903 Valid. err. 1.60853
2018-02-03 21:43:18,386 training [INFO ] Epoch 50 Batch10400 Training err. 1.40295 Training err. RA 1.72840 Valid. err. 1.59792
2018-02-03 21:43:19,229 training [INFO ] Epoch 51 Batch10420 Training err. 1.38881 Training err. RA 1.72775 Valid. err. 1.60033
2018-02-03 21:43:19,727 training [INFO ] Epoch 51 Batch10440 Training err. 1.35011 Training err. RA 1.72703 Valid. err. 1.64195
2018-02-03 21:43:20,197 training [INFO ] Epoch 51 Batch10460 Training err. 1.42858 Training err. RA 1.72646 Valid. err. 1.62210
2018-02-03 21:43:20,698 training [INFO ] Epoch 51 Batch10480 Training err. 1.45062 Training err. RA 1.72593 Valid. err. 1.61963
2018-02-03 21:43:21,176 training [INFO ] Epoch 51 Batch10500 Training err. 1.37266 Training err. RA 1.72526 Valid. err. 1.61291
2018-02-03 21:43:21,637 training [INFO ] Epoch 51 Batch10520 Training err. 1.43073 Training err. RA 1.72470 Valid. err. 1.62737
2018-02-03 21:43:22,096 training [INFO ] Epoch 51 Batch10540 Training err. 1.42691 Training err. RA 1.72413 Valid. err. 1.62189
2018-02-03 21:43:22,592 training [INFO ] Epoch 51 Batch10560 Training err. 1.37190 Training err. RA 1.72346 Valid. err. 1.62046
2018-02-03 21:43:23,078 training [INFO ] Epoch 51 Batch10580 Training err. 1.36725 Training err. RA 1.72279 Valid. err. 1.59919
2018-02-03 21:43:23,564 training [INFO ] Epoch 51 Batch10600 Training err. 1.41532 Training err. RA 1.72221 Valid. err. 1.60029
2018-02-03 21:43:24,420 training [INFO ] Epoch 52 Batch10620 Training err. 1.36977 Training err. RA 1.72155 Valid. err. 1.61071
2018-02-03 21:43:24,938 training [INFO ] Epoch 52 Batch10640 Training err. 1.35623 Training err. RA 1.72086 Valid. err. 1.63499
2018-02-03 21:43:25,444 training [INFO ] Epoch 52 Batch10660 Training err. 1.41241 Training err. RA 1.72028 Valid. err. 1.61890
2018-02-03 21:43:25,927 training [INFO ] Epoch 52 Batch10680 Training err. 1.44445 Training err. RA 1.71977 Valid. err. 1.61600
2018-02-03 21:43:26,423 training [INFO ] Epoch 52 Batch10700 Training err. 1.37404 Training err. RA 1.71912 Valid. err. 1.61569
2018-02-03 21:43:26,907 training [INFO ] Epoch 52 Batch10720 Training err. 1.39497 Training err. RA 1.71851 Valid. err. 1.60362
2018-02-03 21:43:27,401 training [INFO ] Epoch 52 Batch10740 Training err. 1.44758 Training err. RA 1.71801 Valid. err. 1.61655
2018-02-03 21:43:27,915 training [INFO ] Epoch 52 Batch10760 Training err. 1.37309 Training err. RA 1.71737 Valid. err. 1.61948
2018-02-03 21:43:28,405 training [INFO ] Epoch 52 Batch10780 Training err. 1.38164 Training err. RA 1.71675 Valid. err. 1.62993
2018-02-03 21:43:28,894 training [INFO ] Epoch 52 Batch10800 Training err. 1.38300 Training err. RA 1.71613 Valid. err. 1.61243
2018-02-03 21:43:29,780 training [INFO ] Epoch 53 Batch10820 Training err. 1.38067 Training err. RA 1.71551 Valid. err. 1.60826
2018-02-03 21:43:30,277 training [INFO ] Epoch 53 Batch10840 Training err. 1.36920 Training err. RA 1.71487 Valid. err. 1.59598
2018-02-03 21:43:30,768 training [INFO ] Epoch 53 Batch10860 Training err. 1.37015 Training err. RA 1.71423 Valid. err. 1.62209
2018-02-03 21:43:31,263 training [INFO ] Epoch 53 Batch10880 Training err. 1.42968 Training err. RA 1.71371 Valid. err. 1.63322
2018-02-03 21:43:31,739 training [INFO ] Epoch 53 Batch10900 Training err. 1.40589 Training err. RA 1.71315 Valid. err. 1.62464
2018-02-03 21:43:32,258 training [INFO ] Epoch 53 Batch10920 Training err. 1.37735 Training err. RA 1.71253 Valid. err. 1.60394
2018-02-03 21:43:32,751 training [INFO ] Epoch 53 Batch10940 Training err. 1.44597 Training err. RA 1.71204 Valid. err. 1.62388
2018-02-03 21:43:33,244 training [INFO ] Epoch 53 Batch10960 Training err. 1.37578 Training err. RA 1.71143 Valid. err. 1.62087
2018-02-03 21:43:33,717 training [INFO ] Epoch 53 Batch10980 Training err. 1.36470 Training err. RA 1.71080 Valid. err. 1.64570
2018-02-03 21:43:34,206 training [INFO ] Epoch 53 Batch11000 Training err. 1.35543 Training err. RA 1.71015 Valid. err. 1.60093
2018-02-03 21:43:34,703 training [INFO ] Epoch 53 Batch11020 Training err. 1.41506 Training err. RA 1.70962 Valid. err. 1.60234
2018-02-03 21:43:35,545 training [INFO ] Epoch 54 Batch11040 Training err. 1.35346 Training err. RA 1.70897 Valid. err. 1.62050
2018-02-03 21:43:36,037 training [INFO ] Epoch 54 Batch11060 Training err. 1.34937 Training err. RA 1.70832 Valid. err. 1.64231
2018-02-03 21:43:36,530 training [INFO ] Epoch 54 Batch11080 Training err. 1.41256 Training err. RA 1.70779 Valid. err. 1.62642
2018-02-03 21:43:36,995 training [INFO ] Epoch 54 Batch11100 Training err. 1.43246 Training err. RA 1.70729 Valid. err. 1.60339
2018-02-03 21:43:37,460 training [INFO ] Epoch 54 Batch11120 Training err. 1.36644 Training err. RA 1.70668 Valid. err. 1.61768
2018-02-03 21:43:37,925 training [INFO ] Epoch 54 Batch11140 Training err. 1.41170 Training err. RA 1.70615 Valid. err. 1.61702
2018-02-03 21:43:38,389 training [INFO ] Epoch 54 Batch11160 Training err. 1.41922 Training err. RA 1.70563 Valid. err. 1.60832
2018-02-03 21:43:38,853 training [INFO ] Epoch 54 Batch11180 Training err. 1.35282 Training err. RA 1.70500 Valid. err. 1.61440
2018-02-03 21:43:39,318 training [INFO ] Epoch 54 Batch11200 Training err. 1.36750 Training err. RA 1.70440 Valid. err. 1.61329
2018-02-03 21:43:39,794 training [INFO ] Epoch 54 Batch11220 Training err. 1.39080 Training err. RA 1.70384 Valid. err. 1.59566
2018-02-03 21:43:40,700 training [INFO ] Epoch 55 Batch11240 Training err. 1.35960 Training err. RA 1.70323 Valid. err. 1.59657
2018-02-03 21:43:41,292 training [INFO ] Epoch 55 Batch11260 Training err. 1.34828 Training err. RA 1.70260 Valid. err. 1.62828
2018-02-03 21:43:41,875 training [INFO ] Epoch 55 Batch11280 Training err. 1.39386 Training err. RA 1.70205 Valid. err. 1.59593
2018-02-03 21:43:42,452 training [INFO ] Epoch 55 Batch11300 Training err. 1.42832 Training err. RA 1.70157 Valid. err. 1.60879
2018-02-03 21:43:43,070 training [INFO ] Epoch 55 Batch11320 Training err. 1.36889 Training err. RA 1.70098 Valid. err. 1.62766
2018-02-03 21:43:43,684 training [INFO ] Epoch 55 Batch11340 Training err. 1.37032 Training err. RA 1.70040 Valid. err. 1.60833
2018-02-03 21:43:44,285 training [INFO ] Epoch 55 Batch11360 Training err. 1.43254 Training err. RA 1.69992 Valid. err. 1.61392
2018-02-03 21:43:44,804 training [INFO ] Epoch 55 Batch11380 Training err. 1.36812 Training err. RA 1.69934 Valid. err. 1.61682
2018-02-03 21:43:45,329 training [INFO ] Epoch 55 Batch11400 Training err. 1.35125 Training err. RA 1.69873 Valid. err. 1.62236
2018-02-03 21:43:45,857 training [INFO ] Epoch 55 Batch11420 Training err. 1.36143 Training err. RA 1.69814 Valid. err. 1.61731
2018-02-03 21:43:46,401 training [INFO ] Epoch 55 Batch11440 Training err. 1.37710 Training err. RA 1.69758 Valid. err. 1.60331
2018-02-03 21:43:47,334 training [INFO ] Epoch 56 Batch11460 Training err. 1.37102 Training err. RA 1.69701 Valid. err. 1.60107
2018-02-03 21:43:47,852 training [INFO ] Epoch 56 Batch11480 Training err. 1.32995 Training err. RA 1.69637 Valid. err. 1.64060
2018-02-03 21:43:48,353 training [INFO ] Epoch 56 Batch11500 Training err. 1.40329 Training err. RA 1.69586 Valid. err. 1.61949
2018-02-03 21:43:48,848 training [INFO ] Epoch 56 Batch11520 Training err. 1.42264 Training err. RA 1.69538 Valid. err. 1.61705
2018-02-03 21:43:49,335 training [INFO ] Epoch 56 Batch11540 Training err. 1.34884 Training err. RA 1.69478 Valid. err. 1.61182
2018-02-03 21:43:49,814 training [INFO ] Epoch 56 Batch11560 Training err. 1.40635 Training err. RA 1.69429 Valid. err. 1.62199
2018-02-03 21:43:50,305 training [INFO ] Epoch 56 Batch11580 Training err. 1.40441 Training err. RA 1.69378 Valid. err. 1.61884
2018-02-03 21:43:50,776 training [INFO ] Epoch 56 Batch11600 Training err. 1.34804 Training err. RA 1.69319 Valid. err. 1.61839
2018-02-03 21:43:51,242 training [INFO ] Epoch 56 Batch11620 Training err. 1.34300 Training err. RA 1.69259 Valid. err. 1.59892
2018-02-03 21:43:51,706 training [INFO ] Epoch 56 Batch11640 Training err. 1.39487 Training err. RA 1.69207 Valid. err. 1.59737
2018-02-03 21:43:52,552 training [INFO ] Epoch 57 Batch11660 Training err. 1.34309 Training err. RA 1.69148 Valid. err. 1.61101
2018-02-03 21:43:53,013 training [INFO ] Epoch 57 Batch11680 Training err. 1.33585 Training err. RA 1.69087 Valid. err. 1.63830
2018-02-03 21:43:53,472 training [INFO ] Epoch 57 Batch11700 Training err. 1.38830 Training err. RA 1.69035 Valid. err. 1.61217
2018-02-03 21:43:53,939 training [INFO ] Epoch 57 Batch11720 Training err. 1.41716 Training err. RA 1.68988 Valid. err. 1.61336
2018-02-03 21:43:54,400 training [INFO ] Epoch 57 Batch11740 Training err. 1.35046 Training err. RA 1.68930 Valid. err. 1.61836
2018-02-03 21:43:54,861 training [INFO ] Epoch 57 Batch11760 Training err. 1.37549 Training err. RA 1.68877 Valid. err. 1.60464
2018-02-03 21:43:55,321 training [INFO ] Epoch 57 Batch11780 Training err. 1.42461 Training err. RA 1.68832 Valid. err. 1.61178
2018-02-03 21:43:55,781 training [INFO ] Epoch 57 Batch11800 Training err. 1.35025 Training err. RA 1.68775 Valid. err. 1.61466
2018-02-03 21:43:56,241 training [INFO ] Epoch 57 Batch11820 Training err. 1.35818 Training err. RA 1.68719 Valid. err. 1.62550
2018-02-03 21:43:56,701 training [INFO ] Epoch 57 Batch11840 Training err. 1.35795 Training err. RA 1.68664 Valid. err. 1.61307
2018-02-03 21:43:57,533 training [INFO ] Epoch 58 Batch11860 Training err. 1.35656 Training err. RA 1.68608 Valid. err. 1.62391
2018-02-03 21:43:57,998 training [INFO ] Epoch 58 Batch11880 Training err. 1.34780 Training err. RA 1.68551 Valid. err. 1.59896
2018-02-03 21:43:58,463 training [INFO ] Epoch 58 Batch11900 Training err. 1.34781 Training err. RA 1.68494 Valid. err. 1.61921
2018-02-03 21:43:58,927 training [INFO ] Epoch 58 Batch11920 Training err. 1.40407 Training err. RA 1.68447 Valid. err. 1.63032
2018-02-03 21:43:59,393 training [INFO ] Epoch 58 Batch11940 Training err. 1.38322 Training err. RA 1.68397 Valid. err. 1.62624
2018-02-03 21:43:59,861 training [INFO ] Epoch 58 Batch11960 Training err. 1.35249 Training err. RA 1.68341 Valid. err. 1.60858
2018-02-03 21:44:00,330 training [INFO ] Epoch 58 Batch11980 Training err. 1.42309 Training err. RA 1.68298 Valid. err. 1.62673
2018-02-03 21:44:00,791 training [INFO ] Epoch 58 Batch12000 Training err. 1.35631 Training err. RA 1.68243 Valid. err. 1.61811
2018-02-03 21:44:01,251 training [INFO ] Epoch 58 Batch12020 Training err. 1.34321 Training err. RA 1.68187 Valid. err. 1.64297
2018-02-03 21:44:01,711 training [INFO ] Epoch 58 Batch12040 Training err. 1.32870 Training err. RA 1.68128 Valid. err. 1.60220
2018-02-03 21:44:02,172 training [INFO ] Epoch 58 Batch12060 Training err. 1.38840 Training err. RA 1.68080 Valid. err. 1.59956
2018-02-03 21:44:03,003 training [INFO ] Epoch 59 Batch12080 Training err. 1.33759 Training err. RA 1.68023 Valid. err. 1.61941
2018-02-03 21:44:03,462 training [INFO ] Epoch 59 Batch12100 Training err. 1.33136 Training err. RA 1.67965 Valid. err. 1.63924
2018-02-03 21:44:03,923 training [INFO ] Epoch 59 Batch12120 Training err. 1.39107 Training err. RA 1.67918 Valid. err. 1.62271
2018-02-03 21:44:04,383 training [INFO ] Epoch 59 Batch12140 Training err. 1.40886 Training err. RA 1.67873 Valid. err. 1.60760
2018-02-03 21:44:04,849 training [INFO ] Epoch 59 Batch12160 Training err. 1.34405 Training err. RA 1.67818 Valid. err. 1.62186
2018-02-03 21:44:05,312 training [INFO ] Epoch 59 Batch12180 Training err. 1.38959 Training err. RA 1.67771 Valid. err. 1.61264
2018-02-03 21:44:05,778 training [INFO ] Epoch 59 Batch12200 Training err. 1.39582 Training err. RA 1.67724 Valid. err. 1.60623
2018-02-03 21:44:06,249 training [INFO ] Epoch 59 Batch12220 Training err. 1.33116 Training err. RA 1.67668 Valid. err. 1.61493
2018-02-03 21:44:06,714 training [INFO ] Epoch 59 Batch12240 Training err. 1.34316 Training err. RA 1.67613 Valid. err. 1.61305
2018-02-03 21:44:07,179 training [INFO ] Epoch 59 Batch12260 Training err. 1.36456 Training err. RA 1.67562 Valid. err. 1.59256
2018-02-03 21:44:08,012 training [INFO ] Epoch 60 Batch12280 Training err. 1.33849 Training err. RA 1.67507 Valid. err. 1.59409
2018-02-03 21:44:08,472 training [INFO ] Epoch 60 Batch12300 Training err. 1.32952 Training err. RA 1.67451 Valid. err. 1.62528
2018-02-03 21:44:08,932 training [INFO ] Epoch 60 Batch12320 Training err. 1.37446 Training err. RA 1.67403 Valid. err. 1.59422
2018-02-03 21:44:09,392 training [INFO ] Epoch 60 Batch12340 Training err. 1.40868 Training err. RA 1.67360 Valid. err. 1.60890
2018-02-03 21:44:09,852 training [INFO ] Epoch 60 Batch12360 Training err. 1.34986 Training err. RA 1.67307 Valid. err. 1.62595
2018-02-03 21:44:10,310 training [INFO ] Epoch 60 Batch12380 Training err. 1.34887 Training err. RA 1.67255 Valid. err. 1.60679
2018-02-03 21:44:10,769 training [INFO ] Epoch 60 Batch12400 Training err. 1.40861 Training err. RA 1.67212 Valid. err. 1.61604
2018-02-03 21:44:11,228 training [INFO ] Epoch 60 Batch12420 Training err. 1.35010 Training err. RA 1.67160 Valid. err. 1.60697
2018-02-03 21:44:11,687 training [INFO ] Epoch 60 Batch12440 Training err. 1.32967 Training err. RA 1.67105 Valid. err. 1.61334
2018-02-03 21:44:12,154 training [INFO ] Epoch 60 Batch12460 Training err. 1.33935 Training err. RA 1.67052 Valid. err. 1.61048
2018-02-03 21:44:12,617 training [INFO ] Epoch 60 Batch12480 Training err. 1.35521 Training err. RA 1.67002 Valid. err. 1.60271
2018-02-03 21:44:12,890 __main__ [INFO ] End of training
2018-02-03 21:44:13,159 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 10,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:44:13,159 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 21:44:13,739 training [INFO ] Epoch  1 Batch   20 Training err. 4.50536 Training err. RA 4.50536 Valid. err. 8.04659
2018-02-03 21:44:14,202 training [INFO ] Epoch  1 Batch   40 Training err. 4.10560 Training err. RA 4.30548 Valid. err. 3.21016
2018-02-03 21:44:14,665 training [INFO ] Epoch  1 Batch   60 Training err. 3.13285 Training err. RA 3.91460 Valid. err. 3.20579
2018-02-03 21:44:15,129 training [INFO ] Epoch  1 Batch   80 Training err. 3.13868 Training err. RA 3.72062 Valid. err. 3.19088
2018-02-03 21:44:15,592 training [INFO ] Epoch  1 Batch  100 Training err. 3.10709 Training err. RA 3.59792 Valid. err. 3.17294
2018-02-03 21:44:16,057 training [INFO ] Epoch  1 Batch  120 Training err. 3.13171 Training err. RA 3.52021 Valid. err. 3.11960
2018-02-03 21:44:16,519 training [INFO ] Epoch  1 Batch  140 Training err. 2.97888 Training err. RA 3.44288 Valid. err. 3.08469
2018-02-03 21:44:16,980 training [INFO ] Epoch  1 Batch  160 Training err. 2.88042 Training err. RA 3.37257 Valid. err. 3.01061
2018-02-03 21:44:17,439 training [INFO ] Epoch  1 Batch  180 Training err. 2.92412 Training err. RA 3.32275 Valid. err. 2.95232
2018-02-03 21:44:17,899 training [INFO ] Epoch  1 Batch  200 Training err. 2.81129 Training err. RA 3.27160 Valid. err. 2.79013
2018-02-03 21:44:18,707 training [INFO ] Epoch  2 Batch  220 Training err. 2.79437 Training err. RA 3.22822 Valid. err. 2.82825
2018-02-03 21:44:19,167 training [INFO ] Epoch  2 Batch  240 Training err. 2.70165 Training err. RA 3.18434 Valid. err. 2.95434
2018-02-03 21:44:19,628 training [INFO ] Epoch  2 Batch  260 Training err. 2.73964 Training err. RA 3.15013 Valid. err. 2.73555
2018-02-03 21:44:20,089 training [INFO ] Epoch  2 Batch  280 Training err. 2.67031 Training err. RA 3.11586 Valid. err. 2.77918
2018-02-03 21:44:20,553 training [INFO ] Epoch  2 Batch  300 Training err. 2.62133 Training err. RA 3.08289 Valid. err. 2.65550
2018-02-03 21:44:21,013 training [INFO ] Epoch  2 Batch  320 Training err. 2.64085 Training err. RA 3.05526 Valid. err. 2.57893
2018-02-03 21:44:21,499 training [INFO ] Epoch  2 Batch  340 Training err. 2.60222 Training err. RA 3.02861 Valid. err. 2.57855
2018-02-03 21:44:22,008 training [INFO ] Epoch  2 Batch  360 Training err. 2.47647 Training err. RA 2.99794 Valid. err. 2.51613
2018-02-03 21:44:22,508 training [INFO ] Epoch  2 Batch  380 Training err. 2.52145 Training err. RA 2.97286 Valid. err. 2.49799
2018-02-03 21:44:22,986 training [INFO ] Epoch  2 Batch  400 Training err. 2.44343 Training err. RA 2.94639 Valid. err. 2.48033
2018-02-03 21:44:23,874 training [INFO ] Epoch  3 Batch  420 Training err. 2.40539 Training err. RA 2.92062 Valid. err. 2.51607
2018-02-03 21:44:24,368 training [INFO ] Epoch  3 Batch  440 Training err. 2.40254 Training err. RA 2.89708 Valid. err. 2.46163
2018-02-03 21:44:24,864 training [INFO ] Epoch  3 Batch  460 Training err. 2.37293 Training err. RA 2.87429 Valid. err. 2.52748
2018-02-03 21:44:25,345 training [INFO ] Epoch  3 Batch  480 Training err. 2.41464 Training err. RA 2.85513 Valid. err. 2.40565
2018-02-03 21:44:25,825 training [INFO ] Epoch  3 Batch  500 Training err. 2.36589 Training err. RA 2.83556 Valid. err. 2.38844
2018-02-03 21:44:26,289 training [INFO ] Epoch  3 Batch  520 Training err. 2.35941 Training err. RA 2.81725 Valid. err. 2.35798
2018-02-03 21:44:26,794 training [INFO ] Epoch  3 Batch  540 Training err. 2.40468 Training err. RA 2.80197 Valid. err. 2.37197
2018-02-03 21:44:27,274 training [INFO ] Epoch  3 Batch  560 Training err. 2.28984 Training err. RA 2.78368 Valid. err. 2.34845
2018-02-03 21:44:27,748 training [INFO ] Epoch  3 Batch  580 Training err. 2.24059 Training err. RA 2.76495 Valid. err. 2.39523
2018-02-03 21:44:28,214 training [INFO ] Epoch  3 Batch  600 Training err. 2.28950 Training err. RA 2.74910 Valid. err. 2.27368
2018-02-03 21:44:28,702 training [INFO ] Epoch  3 Batch  620 Training err. 2.26627 Training err. RA 2.73353 Valid. err. 2.37877
2018-02-03 21:44:29,574 training [INFO ] Epoch  4 Batch  640 Training err. 2.24651 Training err. RA 2.71831 Valid. err. 2.29922
2018-02-03 21:44:30,079 training [INFO ] Epoch  4 Batch  660 Training err. 2.21312 Training err. RA 2.70300 Valid. err. 2.30506
2018-02-03 21:44:30,566 training [INFO ] Epoch  4 Batch  680 Training err. 2.25374 Training err. RA 2.68979 Valid. err. 2.24382
2018-02-03 21:44:31,069 training [INFO ] Epoch  4 Batch  700 Training err. 2.36447 Training err. RA 2.68049 Valid. err. 2.33529
2018-02-03 21:44:31,580 training [INFO ] Epoch  4 Batch  720 Training err. 2.20069 Training err. RA 2.66716 Valid. err. 2.27002
2018-02-03 21:44:32,085 training [INFO ] Epoch  4 Batch  740 Training err. 2.24120 Training err. RA 2.65565 Valid. err. 2.24741
2018-02-03 21:44:32,590 training [INFO ] Epoch  4 Batch  760 Training err. 2.21455 Training err. RA 2.64404 Valid. err. 2.20023
2018-02-03 21:44:33,059 training [INFO ] Epoch  4 Batch  780 Training err. 2.11843 Training err. RA 2.63057 Valid. err. 2.19276
2018-02-03 21:44:33,523 training [INFO ] Epoch  4 Batch  800 Training err. 2.16310 Training err. RA 2.61888 Valid. err. 2.18580
2018-02-03 21:44:33,988 training [INFO ] Epoch  4 Batch  820 Training err. 2.11496 Training err. RA 2.60659 Valid. err. 2.17482
2018-02-03 21:44:34,828 training [INFO ] Epoch  5 Batch  840 Training err. 2.13154 Training err. RA 2.59528 Valid. err. 2.19607
2018-02-03 21:44:35,321 training [INFO ] Epoch  5 Batch  860 Training err. 2.06446 Training err. RA 2.58293 Valid. err. 2.16924
2018-02-03 21:44:35,838 training [INFO ] Epoch  5 Batch  880 Training err. 2.17556 Training err. RA 2.57368 Valid. err. 2.16106
2018-02-03 21:44:36,317 training [INFO ] Epoch  5 Batch  900 Training err. 2.13003 Training err. RA 2.56382 Valid. err. 2.15836
2018-02-03 21:44:36,796 training [INFO ] Epoch  5 Batch  920 Training err. 2.07244 Training err. RA 2.55313 Valid. err. 2.13615
2018-02-03 21:44:37,278 training [INFO ] Epoch  5 Batch  940 Training err. 2.08110 Training err. RA 2.54309 Valid. err. 2.13793
2018-02-03 21:44:37,768 training [INFO ] Epoch  5 Batch  960 Training err. 2.15442 Training err. RA 2.53499 Valid. err. 2.12750
2018-02-03 21:44:38,228 training [INFO ] Epoch  5 Batch  980 Training err. 2.05998 Training err. RA 2.52530 Valid. err. 2.14654
2018-02-03 21:44:38,732 training [INFO ] Epoch  5 Batch 1000 Training err. 2.02820 Training err. RA 2.51536 Valid. err. 2.10543
2018-02-03 21:44:39,218 training [INFO ] Epoch  5 Batch 1020 Training err. 2.06499 Training err. RA 2.50653 Valid. err. 2.11193
2018-02-03 21:44:39,690 training [INFO ] Epoch  5 Batch 1040 Training err. 2.02084 Training err. RA 2.49719 Valid. err. 2.10763
2018-02-03 21:44:40,547 training [INFO ] Epoch  6 Batch 1060 Training err. 2.03903 Training err. RA 2.48854 Valid. err. 2.07306
2018-02-03 21:44:41,015 training [INFO ] Epoch  6 Batch 1080 Training err. 2.01503 Training err. RA 2.47977 Valid. err. 2.14022
2018-02-03 21:44:41,474 training [INFO ] Epoch  6 Batch 1100 Training err. 2.05636 Training err. RA 2.47208 Valid. err. 2.08171
2018-02-03 21:44:41,962 training [INFO ] Epoch  6 Batch 1120 Training err. 2.04983 Training err. RA 2.46454 Valid. err. 2.09709
2018-02-03 21:44:42,450 training [INFO ] Epoch  6 Batch 1140 Training err. 2.01653 Training err. RA 2.45668 Valid. err. 2.06928
2018-02-03 21:44:42,921 training [INFO ] Epoch  6 Batch 1160 Training err. 2.08391 Training err. RA 2.45025 Valid. err. 2.07742
2018-02-03 21:44:43,392 training [INFO ] Epoch  6 Batch 1180 Training err. 2.00507 Training err. RA 2.44270 Valid. err. 2.07309
2018-02-03 21:44:43,861 training [INFO ] Epoch  6 Batch 1200 Training err. 1.97391 Training err. RA 2.43489 Valid. err. 2.11683
2018-02-03 21:44:44,320 training [INFO ] Epoch  6 Batch 1220 Training err. 1.99481 Training err. RA 2.42768 Valid. err. 2.05841
2018-02-03 21:44:44,783 training [INFO ] Epoch  6 Batch 1240 Training err. 1.97004 Training err. RA 2.42029 Valid. err. 2.03331
2018-02-03 21:44:45,633 training [INFO ] Epoch  7 Batch 1260 Training err. 1.99708 Training err. RA 2.41358 Valid. err. 2.03738
2018-02-03 21:44:46,097 training [INFO ] Epoch  7 Batch 1280 Training err. 1.91951 Training err. RA 2.40586 Valid. err. 2.11980
2018-02-03 21:44:46,561 training [INFO ] Epoch  7 Batch 1300 Training err. 2.01163 Training err. RA 2.39979 Valid. err. 2.01924
2018-02-03 21:44:47,024 training [INFO ] Epoch  7 Batch 1320 Training err. 2.01878 Training err. RA 2.39402 Valid. err. 2.02641
2018-02-03 21:44:47,505 training [INFO ] Epoch  7 Batch 1340 Training err. 1.95951 Training err. RA 2.38753 Valid. err. 2.05868
2018-02-03 21:44:47,985 training [INFO ] Epoch  7 Batch 1360 Training err. 2.00423 Training err. RA 2.38190 Valid. err. 2.02207
2018-02-03 21:44:48,463 training [INFO ] Epoch  7 Batch 1380 Training err. 2.01343 Training err. RA 2.37656 Valid. err. 2.02836
2018-02-03 21:44:48,951 training [INFO ] Epoch  7 Batch 1400 Training err. 1.92416 Training err. RA 2.37009 Valid. err. 2.01477
2018-02-03 21:44:49,425 training [INFO ] Epoch  7 Batch 1420 Training err. 1.95705 Training err. RA 2.36428 Valid. err. 2.00725
2018-02-03 21:44:49,896 training [INFO ] Epoch  7 Batch 1440 Training err. 1.93027 Training err. RA 2.35825 Valid. err. 1.98106
2018-02-03 21:44:50,723 training [INFO ] Epoch  8 Batch 1460 Training err. 1.92753 Training err. RA 2.35235 Valid. err. 1.99467
2018-02-03 21:44:51,183 training [INFO ] Epoch  8 Batch 1480 Training err. 1.93009 Training err. RA 2.34664 Valid. err. 1.98683
2018-02-03 21:44:51,657 training [INFO ] Epoch  8 Batch 1500 Training err. 1.92102 Training err. RA 2.34097 Valid. err. 1.98512
2018-02-03 21:44:52,129 training [INFO ] Epoch  8 Batch 1520 Training err. 1.96460 Training err. RA 2.33601 Valid. err. 1.97463
2018-02-03 21:44:52,619 training [INFO ] Epoch  8 Batch 1540 Training err. 1.93466 Training err. RA 2.33080 Valid. err. 2.01267
2018-02-03 21:44:53,100 training [INFO ] Epoch  8 Batch 1560 Training err. 1.95268 Training err. RA 2.32595 Valid. err. 2.01295
2018-02-03 21:44:53,560 training [INFO ] Epoch  8 Batch 1580 Training err. 1.99431 Training err. RA 2.32176 Valid. err. 1.97459
2018-02-03 21:44:54,019 training [INFO ] Epoch  8 Batch 1600 Training err. 1.89065 Training err. RA 2.31637 Valid. err. 1.98973
2018-02-03 21:44:54,479 training [INFO ] Epoch  8 Batch 1620 Training err. 1.89780 Training err. RA 2.31120 Valid. err. 1.97739
2018-02-03 21:44:54,971 training [INFO ] Epoch  8 Batch 1640 Training err. 1.90388 Training err. RA 2.30623 Valid. err. 1.94019
2018-02-03 21:44:55,431 training [INFO ] Epoch  8 Batch 1660 Training err. 1.89229 Training err. RA 2.30125 Valid. err. 1.96586
2018-02-03 21:44:56,256 training [INFO ] Epoch  9 Batch 1680 Training err. 1.90610 Training err. RA 2.29654 Valid. err. 1.98147
2018-02-03 21:44:56,717 training [INFO ] Epoch  9 Batch 1700 Training err. 1.85404 Training err. RA 2.29134 Valid. err. 1.95786
2018-02-03 21:44:57,178 training [INFO ] Epoch  9 Batch 1720 Training err. 1.90976 Training err. RA 2.28690 Valid. err. 1.97044
2018-02-03 21:44:57,639 training [INFO ] Epoch  9 Batch 1740 Training err. 1.93040 Training err. RA 2.28280 Valid. err. 1.96035
2018-02-03 21:44:58,099 training [INFO ] Epoch  9 Batch 1760 Training err. 1.88846 Training err. RA 2.27832 Valid. err. 1.99969
2018-02-03 21:44:58,561 training [INFO ] Epoch  9 Batch 1780 Training err. 1.95360 Training err. RA 2.27467 Valid. err. 1.93901
2018-02-03 21:44:59,020 training [INFO ] Epoch  9 Batch 1800 Training err. 1.90495 Training err. RA 2.27056 Valid. err. 1.94023
2018-02-03 21:44:59,480 training [INFO ] Epoch  9 Batch 1820 Training err. 1.85528 Training err. RA 2.26600 Valid. err. 1.98137
2018-02-03 21:44:59,940 training [INFO ] Epoch  9 Batch 1840 Training err. 1.87659 Training err. RA 2.26177 Valid. err. 1.95220
2018-02-03 21:45:00,406 training [INFO ] Epoch  9 Batch 1860 Training err. 1.93198 Training err. RA 2.25822 Valid. err. 1.94497
2018-02-03 21:45:01,262 training [INFO ] Epoch 10 Batch 1880 Training err. 1.85342 Training err. RA 2.25391 Valid. err. 1.93343
2018-02-03 21:45:01,762 training [INFO ] Epoch 10 Batch 1900 Training err. 1.82779 Training err. RA 2.24943 Valid. err. 1.93045
2018-02-03 21:45:02,229 training [INFO ] Epoch 10 Batch 1920 Training err. 1.88047 Training err. RA 2.24559 Valid. err. 1.92442
2018-02-03 21:45:02,705 training [INFO ] Epoch 10 Batch 1940 Training err. 1.90032 Training err. RA 2.24203 Valid. err. 1.91854
2018-02-03 21:45:03,193 training [INFO ] Epoch 10 Batch 1960 Training err. 1.84893 Training err. RA 2.23802 Valid. err. 1.92295
2018-02-03 21:45:03,682 training [INFO ] Epoch 10 Batch 1980 Training err. 1.87051 Training err. RA 2.23430 Valid. err. 1.93805
2018-02-03 21:45:04,143 training [INFO ] Epoch 10 Batch 2000 Training err. 1.92701 Training err. RA 2.23123 Valid. err. 1.89597
2018-02-03 21:45:04,608 training [INFO ] Epoch 10 Batch 2020 Training err. 1.83241 Training err. RA 2.22728 Valid. err. 1.92781
2018-02-03 21:45:05,073 training [INFO ] Epoch 10 Batch 2040 Training err. 1.83164 Training err. RA 2.22340 Valid. err. 1.91231
2018-02-03 21:45:05,537 training [INFO ] Epoch 10 Batch 2060 Training err. 1.84890 Training err. RA 2.21977 Valid. err. 1.91652
2018-02-03 21:45:06,001 training [INFO ] Epoch 10 Batch 2080 Training err. 1.81389 Training err. RA 2.21586 Valid. err. 1.90833
2018-02-03 21:45:06,840 training [INFO ] Epoch 11 Batch 2100 Training err. 1.84321 Training err. RA 2.21231 Valid. err. 1.88594
2018-02-03 21:45:07,305 training [INFO ] Epoch 11 Batch 2120 Training err. 1.79204 Training err. RA 2.20835 Valid. err. 1.94659
2018-02-03 21:45:07,770 training [INFO ] Epoch 11 Batch 2140 Training err. 1.86577 Training err. RA 2.20515 Valid. err. 1.90540
2018-02-03 21:45:08,236 training [INFO ] Epoch 11 Batch 2160 Training err. 1.86918 Training err. RA 2.20204 Valid. err. 1.92951
2018-02-03 21:45:08,713 training [INFO ] Epoch 11 Batch 2180 Training err. 1.82875 Training err. RA 2.19861 Valid. err. 1.89413
2018-02-03 21:45:09,172 training [INFO ] Epoch 11 Batch 2200 Training err. 1.89117 Training err. RA 2.19582 Valid. err. 1.88281
2018-02-03 21:45:09,662 training [INFO ] Epoch 11 Batch 2220 Training err. 1.83398 Training err. RA 2.19256 Valid. err. 1.90197
2018-02-03 21:45:10,142 training [INFO ] Epoch 11 Batch 2240 Training err. 1.80398 Training err. RA 2.18909 Valid. err. 1.92093
2018-02-03 21:45:10,603 training [INFO ] Epoch 11 Batch 2260 Training err. 1.81721 Training err. RA 2.18580 Valid. err. 1.90699
2018-02-03 21:45:11,063 training [INFO ] Epoch 11 Batch 2280 Training err. 1.80721 Training err. RA 2.18248 Valid. err. 1.88179
2018-02-03 21:45:11,877 training [INFO ] Epoch 12 Batch 2300 Training err. 1.81149 Training err. RA 2.17925 Valid. err. 1.87886
2018-02-03 21:45:12,338 training [INFO ] Epoch 12 Batch 2320 Training err. 1.75758 Training err. RA 2.17562 Valid. err. 1.87271
2018-02-03 21:45:12,816 training [INFO ] Epoch 12 Batch 2340 Training err. 1.83994 Training err. RA 2.17275 Valid. err. 1.88591
2018-02-03 21:45:13,319 training [INFO ] Epoch 12 Batch 2360 Training err. 1.85436 Training err. RA 2.17005 Valid. err. 1.89216
2018-02-03 21:45:13,803 training [INFO ] Epoch 12 Batch 2380 Training err. 1.79883 Training err. RA 2.16693 Valid. err. 1.92327
2018-02-03 21:45:14,267 training [INFO ] Epoch 12 Batch 2400 Training err. 1.83746 Training err. RA 2.16418 Valid. err. 1.90510
2018-02-03 21:45:14,747 training [INFO ] Epoch 12 Batch 2420 Training err. 1.86486 Training err. RA 2.16171 Valid. err. 1.89709
2018-02-03 21:45:15,238 training [INFO ] Epoch 12 Batch 2440 Training err. 1.77429 Training err. RA 2.15853 Valid. err. 1.87886
2018-02-03 21:45:15,724 training [INFO ] Epoch 12 Batch 2460 Training err. 1.80621 Training err. RA 2.15567 Valid. err. 1.87407
2018-02-03 21:45:16,200 training [INFO ] Epoch 12 Batch 2480 Training err. 1.78524 Training err. RA 2.15268 Valid. err. 1.86861
2018-02-03 21:45:17,062 training [INFO ] Epoch 13 Batch 2500 Training err. 1.77109 Training err. RA 2.14963 Valid. err. 1.85859
2018-02-03 21:45:17,520 training [INFO ] Epoch 13 Batch 2520 Training err. 1.76500 Training err. RA 2.14658 Valid. err. 1.86708
2018-02-03 21:45:17,992 training [INFO ] Epoch 13 Batch 2540 Training err. 1.77894 Training err. RA 2.14368 Valid. err. 1.86204
2018-02-03 21:45:18,452 training [INFO ] Epoch 13 Batch 2560 Training err. 1.81845 Training err. RA 2.14114 Valid. err. 1.85505
2018-02-03 21:45:18,921 training [INFO ] Epoch 13 Batch 2580 Training err. 1.80249 Training err. RA 2.13852 Valid. err. 1.88173
2018-02-03 21:45:19,398 training [INFO ] Epoch 13 Batch 2600 Training err. 1.80222 Training err. RA 2.13593 Valid. err. 1.84549
2018-02-03 21:45:19,894 training [INFO ] Epoch 13 Batch 2620 Training err. 1.85406 Training err. RA 2.13378 Valid. err. 1.86288
2018-02-03 21:45:20,401 training [INFO ] Epoch 13 Batch 2640 Training err. 1.75837 Training err. RA 2.13093 Valid. err. 1.87081
2018-02-03 21:45:20,904 training [INFO ] Epoch 13 Batch 2660 Training err. 1.76694 Training err. RA 2.12820 Valid. err. 1.86206
2018-02-03 21:45:21,394 training [INFO ] Epoch 13 Batch 2680 Training err. 1.76867 Training err. RA 2.12551 Valid. err. 1.84274
2018-02-03 21:45:21,856 training [INFO ] Epoch 13 Batch 2700 Training err. 1.76552 Training err. RA 2.12285 Valid. err. 1.84740
2018-02-03 21:45:22,686 training [INFO ] Epoch 14 Batch 2720 Training err. 1.74595 Training err. RA 2.12008 Valid. err. 1.86194
2018-02-03 21:45:23,165 training [INFO ] Epoch 14 Batch 2740 Training err. 1.72739 Training err. RA 2.11721 Valid. err. 1.85640
2018-02-03 21:45:23,665 training [INFO ] Epoch 14 Batch 2760 Training err. 1.78705 Training err. RA 2.11482 Valid. err. 1.86551
2018-02-03 21:45:24,164 training [INFO ] Epoch 14 Batch 2780 Training err. 1.80540 Training err. RA 2.11259 Valid. err. 1.85238
2018-02-03 21:45:24,635 training [INFO ] Epoch 14 Batch 2800 Training err. 1.76347 Training err. RA 2.11010 Valid. err. 1.88705
2018-02-03 21:45:25,132 training [INFO ] Epoch 14 Batch 2820 Training err. 1.81960 Training err. RA 2.10804 Valid. err. 1.83591
2018-02-03 21:45:25,626 training [INFO ] Epoch 14 Batch 2840 Training err. 1.78604 Training err. RA 2.10577 Valid. err. 1.83801
2018-02-03 21:45:26,086 training [INFO ] Epoch 14 Batch 2860 Training err. 1.73996 Training err. RA 2.10321 Valid. err. 1.87237
2018-02-03 21:45:26,547 training [INFO ] Epoch 14 Batch 2880 Training err. 1.75858 Training err. RA 2.10082 Valid. err. 1.82466
2018-02-03 21:45:27,006 training [INFO ] Epoch 14 Batch 2900 Training err. 1.74388 Training err. RA 2.09836 Valid. err. 1.83714
2018-02-03 21:45:27,832 training [INFO ] Epoch 15 Batch 2920 Training err. 1.72102 Training err. RA 2.09577 Valid. err. 1.81764
2018-02-03 21:45:28,292 training [INFO ] Epoch 15 Batch 2940 Training err. 1.70452 Training err. RA 2.09311 Valid. err. 1.82431
2018-02-03 21:45:28,763 training [INFO ] Epoch 15 Batch 2960 Training err. 1.77044 Training err. RA 2.09093 Valid. err. 1.84096
2018-02-03 21:45:29,260 training [INFO ] Epoch 15 Batch 2980 Training err. 1.78367 Training err. RA 2.08887 Valid. err. 1.82553
2018-02-03 21:45:29,759 training [INFO ] Epoch 15 Batch 3000 Training err. 1.74327 Training err. RA 2.08656 Valid. err. 1.84483
2018-02-03 21:45:30,251 training [INFO ] Epoch 15 Batch 3020 Training err. 1.75505 Training err. RA 2.08437 Valid. err. 1.86137
2018-02-03 21:45:30,737 training [INFO ] Epoch 15 Batch 3040 Training err. 1.80921 Training err. RA 2.08256 Valid. err. 1.81998
2018-02-03 21:45:31,232 training [INFO ] Epoch 15 Batch 3060 Training err. 1.73042 Training err. RA 2.08026 Valid. err. 1.85802
2018-02-03 21:45:31,701 training [INFO ] Epoch 15 Batch 3080 Training err. 1.72091 Training err. RA 2.07792 Valid. err. 1.82860
2018-02-03 21:45:32,173 training [INFO ] Epoch 15 Batch 3100 Training err. 1.73610 Training err. RA 2.07572 Valid. err. 1.80458
2018-02-03 21:45:32,668 training [INFO ] Epoch 15 Batch 3120 Training err. 1.71514 Training err. RA 2.07341 Valid. err. 1.81040
2018-02-03 21:45:33,511 training [INFO ] Epoch 16 Batch 3140 Training err. 1.71581 Training err. RA 2.07113 Valid. err. 1.79307
2018-02-03 21:45:33,977 training [INFO ] Epoch 16 Batch 3160 Training err. 1.68717 Training err. RA 2.06870 Valid. err. 1.82155
2018-02-03 21:45:34,444 training [INFO ] Epoch 16 Batch 3180 Training err. 1.75356 Training err. RA 2.06672 Valid. err. 1.83837
2018-02-03 21:45:34,922 training [INFO ] Epoch 16 Batch 3200 Training err. 1.77832 Training err. RA 2.06491 Valid. err. 1.82601
2018-02-03 21:45:35,429 training [INFO ] Epoch 16 Batch 3220 Training err. 1.72068 Training err. RA 2.06278 Valid. err. 1.83736
2018-02-03 21:45:35,921 training [INFO ] Epoch 16 Batch 3240 Training err. 1.77627 Training err. RA 2.06101 Valid. err. 1.81369
2018-02-03 21:45:36,400 training [INFO ] Epoch 16 Batch 3260 Training err. 1.74136 Training err. RA 2.05905 Valid. err. 1.82187
2018-02-03 21:45:36,880 training [INFO ] Epoch 16 Batch 3280 Training err. 1.70852 Training err. RA 2.05691 Valid. err. 1.85058
2018-02-03 21:45:37,342 training [INFO ] Epoch 16 Batch 3300 Training err. 1.70922 Training err. RA 2.05480 Valid. err. 1.83533
2018-02-03 21:45:37,814 training [INFO ] Epoch 16 Batch 3320 Training err. 1.72093 Training err. RA 2.05279 Valid. err. 1.79991
2018-02-03 21:45:38,654 training [INFO ] Epoch 17 Batch 3340 Training err. 1.69715 Training err. RA 2.05066 Valid. err. 1.79296
2018-02-03 21:45:39,128 training [INFO ] Epoch 17 Batch 3360 Training err. 1.65865 Training err. RA 2.04833 Valid. err. 1.80738
2018-02-03 21:45:39,621 training [INFO ] Epoch 17 Batch 3380 Training err. 1.74205 Training err. RA 2.04652 Valid. err. 1.79311
2018-02-03 21:45:40,109 training [INFO ] Epoch 17 Batch 3400 Training err. 1.75388 Training err. RA 2.04479 Valid. err. 1.82867
2018-02-03 21:45:40,577 training [INFO ] Epoch 17 Batch 3420 Training err. 1.70465 Training err. RA 2.04280 Valid. err. 1.82416
2018-02-03 21:45:41,049 training [INFO ] Epoch 17 Batch 3440 Training err. 1.73345 Training err. RA 2.04101 Valid. err. 1.82274
2018-02-03 21:45:41,540 training [INFO ] Epoch 17 Batch 3460 Training err. 1.76748 Training err. RA 2.03943 Valid. err. 1.81612
2018-02-03 21:45:42,020 training [INFO ] Epoch 17 Batch 3480 Training err. 1.68986 Training err. RA 2.03742 Valid. err. 1.81303
2018-02-03 21:45:42,485 training [INFO ] Epoch 17 Batch 3500 Training err. 1.71096 Training err. RA 2.03555 Valid. err. 1.81458
2018-02-03 21:45:42,966 training [INFO ] Epoch 17 Batch 3520 Training err. 1.69815 Training err. RA 2.03363 Valid. err. 1.79917
2018-02-03 21:45:43,804 training [INFO ] Epoch 18 Batch 3540 Training err. 1.68151 Training err. RA 2.03164 Valid. err. 1.78332
2018-02-03 21:45:44,280 training [INFO ] Epoch 18 Batch 3560 Training err. 1.66890 Training err. RA 2.02961 Valid. err. 1.78933
2018-02-03 21:45:44,765 training [INFO ] Epoch 18 Batch 3580 Training err. 1.68673 Training err. RA 2.02769 Valid. err. 1.79901
2018-02-03 21:45:45,252 training [INFO ] Epoch 18 Batch 3600 Training err. 1.72542 Training err. RA 2.02601 Valid. err. 1.78918
2018-02-03 21:45:45,727 training [INFO ] Epoch 18 Batch 3620 Training err. 1.72436 Training err. RA 2.02435 Valid. err. 1.80512
2018-02-03 21:45:46,229 training [INFO ] Epoch 18 Batch 3640 Training err. 1.70496 Training err. RA 2.02259 Valid. err. 1.78501
2018-02-03 21:45:46,717 training [INFO ] Epoch 18 Batch 3660 Training err. 1.76006 Training err. RA 2.02116 Valid. err. 1.79744
2018-02-03 21:45:47,182 training [INFO ] Epoch 18 Batch 3680 Training err. 1.68144 Training err. RA 2.01931 Valid. err. 1.79670
2018-02-03 21:45:47,651 training [INFO ] Epoch 18 Batch 3700 Training err. 1.68290 Training err. RA 2.01749 Valid. err. 1.80276
2018-02-03 21:45:48,151 training [INFO ] Epoch 18 Batch 3720 Training err. 1.68455 Training err. RA 2.01570 Valid. err. 1.77598
2018-02-03 21:45:48,611 training [INFO ] Epoch 18 Batch 3740 Training err. 1.69007 Training err. RA 2.01396 Valid. err. 1.81098
2018-02-03 21:45:49,488 training [INFO ] Epoch 19 Batch 3760 Training err. 1.66098 Training err. RA 2.01208 Valid. err. 1.81304
2018-02-03 21:45:49,984 training [INFO ] Epoch 19 Batch 3780 Training err. 1.64408 Training err. RA 2.01013 Valid. err. 1.79063
2018-02-03 21:45:50,464 training [INFO ] Epoch 19 Batch 3800 Training err. 1.70101 Training err. RA 2.00851 Valid. err. 1.79815
2018-02-03 21:45:50,926 training [INFO ] Epoch 19 Batch 3820 Training err. 1.73150 Training err. RA 2.00706 Valid. err. 1.78112
2018-02-03 21:45:51,418 training [INFO ] Epoch 19 Batch 3840 Training err. 1.68118 Training err. RA 2.00536 Valid. err. 1.86578
2018-02-03 21:45:51,911 training [INFO ] Epoch 19 Batch 3860 Training err. 1.73429 Training err. RA 2.00396 Valid. err. 1.78777
2018-02-03 21:45:52,384 training [INFO ] Epoch 19 Batch 3880 Training err. 1.71205 Training err. RA 2.00245 Valid. err. 1.80258
2018-02-03 21:45:52,855 training [INFO ] Epoch 19 Batch 3900 Training err. 1.66599 Training err. RA 2.00073 Valid. err. 1.80486
2018-02-03 21:45:53,354 training [INFO ] Epoch 19 Batch 3920 Training err. 1.68064 Training err. RA 1.99909 Valid. err. 1.77693
2018-02-03 21:45:53,855 training [INFO ] Epoch 19 Batch 3940 Training err. 1.68040 Training err. RA 1.99747 Valid. err. 1.77235
2018-02-03 21:45:54,672 training [INFO ] Epoch 20 Batch 3960 Training err. 1.65499 Training err. RA 1.99575 Valid. err. 1.76491
2018-02-03 21:45:55,150 training [INFO ] Epoch 20 Batch 3980 Training err. 1.62819 Training err. RA 1.99390 Valid. err. 1.77752
2018-02-03 21:45:55,642 training [INFO ] Epoch 20 Batch 4000 Training err. 1.68709 Training err. RA 1.99236 Valid. err. 1.77195
2018-02-03 21:45:56,117 training [INFO ] Epoch 20 Batch 4020 Training err. 1.70871 Training err. RA 1.99095 Valid. err. 1.78075
2018-02-03 21:45:56,577 training [INFO ] Epoch 20 Batch 4040 Training err. 1.67406 Training err. RA 1.98938 Valid. err. 1.78122
2018-02-03 21:45:57,081 training [INFO ] Epoch 20 Batch 4060 Training err. 1.67595 Training err. RA 1.98784 Valid. err. 1.77990
2018-02-03 21:45:57,579 training [INFO ] Epoch 20 Batch 4080 Training err. 1.73696 Training err. RA 1.98661 Valid. err. 1.77159
2018-02-03 21:45:58,067 training [INFO ] Epoch 20 Batch 4100 Training err. 1.66528 Training err. RA 1.98504 Valid. err. 1.79843
2018-02-03 21:45:58,545 training [INFO ] Epoch 20 Batch 4120 Training err. 1.65396 Training err. RA 1.98344 Valid. err. 1.77171
2018-02-03 21:45:59,010 training [INFO ] Epoch 20 Batch 4140 Training err. 1.66477 Training err. RA 1.98190 Valid. err. 1.75249
2018-02-03 21:45:59,475 training [INFO ] Epoch 20 Batch 4160 Training err. 1.65902 Training err. RA 1.98034 Valid. err. 1.76525
2018-02-03 21:46:00,322 training [INFO ] Epoch 21 Batch 4180 Training err. 1.64950 Training err. RA 1.97876 Valid. err. 1.74927
2018-02-03 21:46:00,786 training [INFO ] Epoch 21 Batch 4200 Training err. 1.60593 Training err. RA 1.97699 Valid. err. 1.75947
2018-02-03 21:46:01,259 training [INFO ] Epoch 21 Batch 4220 Training err. 1.68429 Training err. RA 1.97560 Valid. err. 1.77929
2018-02-03 21:46:01,732 training [INFO ] Epoch 21 Batch 4240 Training err. 1.71337 Training err. RA 1.97436 Valid. err. 1.77588
2018-02-03 21:46:02,192 training [INFO ] Epoch 21 Batch 4260 Training err. 1.64755 Training err. RA 1.97283 Valid. err. 1.77632
2018-02-03 21:46:02,654 training [INFO ] Epoch 21 Batch 4280 Training err. 1.70774 Training err. RA 1.97159 Valid. err. 1.76113
2018-02-03 21:46:03,131 training [INFO ] Epoch 21 Batch 4300 Training err. 1.67862 Training err. RA 1.97023 Valid. err. 1.76716
2018-02-03 21:46:03,601 training [INFO ] Epoch 21 Batch 4320 Training err. 1.64478 Training err. RA 1.96872 Valid. err. 1.80218
2018-02-03 21:46:04,091 training [INFO ] Epoch 21 Batch 4340 Training err. 1.65293 Training err. RA 1.96726 Valid. err. 1.78257
2018-02-03 21:46:04,585 training [INFO ] Epoch 21 Batch 4360 Training err. 1.65732 Training err. RA 1.96584 Valid. err. 1.74136
2018-02-03 21:46:05,458 training [INFO ] Epoch 22 Batch 4380 Training err. 1.64464 Training err. RA 1.96438 Valid. err. 1.74396
2018-02-03 21:46:05,953 training [INFO ] Epoch 22 Batch 4400 Training err. 1.59410 Training err. RA 1.96269 Valid. err. 1.76289
2018-02-03 21:46:06,446 training [INFO ] Epoch 22 Batch 4420 Training err. 1.67177 Training err. RA 1.96138 Valid. err. 1.74792
2018-02-03 21:46:06,958 training [INFO ] Epoch 22 Batch 4440 Training err. 1.69462 Training err. RA 1.96017 Valid. err. 1.77498
2018-02-03 21:46:07,464 training [INFO ] Epoch 22 Batch 4460 Training err. 1.64130 Training err. RA 1.95874 Valid. err. 1.77300
2018-02-03 21:46:07,970 training [INFO ] Epoch 22 Batch 4480 Training err. 1.67279 Training err. RA 1.95747 Valid. err. 1.75241
2018-02-03 21:46:08,447 training [INFO ] Epoch 22 Batch 4500 Training err. 1.70604 Training err. RA 1.95635 Valid. err. 1.77020
2018-02-03 21:46:08,922 training [INFO ] Epoch 22 Batch 4520 Training err. 1.63692 Training err. RA 1.95494 Valid. err. 1.76068
2018-02-03 21:46:09,390 training [INFO ] Epoch 22 Batch 4540 Training err. 1.65658 Training err. RA 1.95362 Valid. err. 1.75675
2018-02-03 21:46:09,877 training [INFO ] Epoch 22 Batch 4560 Training err. 1.63915 Training err. RA 1.95224 Valid. err. 1.75463
2018-02-03 21:46:10,723 training [INFO ] Epoch 23 Batch 4580 Training err. 1.63157 Training err. RA 1.95084 Valid. err. 1.74605
2018-02-03 21:46:11,182 training [INFO ] Epoch 23 Batch 4600 Training err. 1.61199 Training err. RA 1.94937 Valid. err. 1.75413
2018-02-03 21:46:11,644 training [INFO ] Epoch 23 Batch 4620 Training err. 1.62350 Training err. RA 1.94796 Valid. err. 1.75218
2018-02-03 21:46:12,112 training [INFO ] Epoch 23 Batch 4640 Training err. 1.66755 Training err. RA 1.94675 Valid. err. 1.74645
2018-02-03 21:46:12,582 training [INFO ] Epoch 23 Batch 4660 Training err. 1.66296 Training err. RA 1.94553 Valid. err. 1.77183
2018-02-03 21:46:13,047 training [INFO ] Epoch 23 Batch 4680 Training err. 1.65180 Training err. RA 1.94428 Valid. err. 1.75487
2018-02-03 21:46:13,512 training [INFO ] Epoch 23 Batch 4700 Training err. 1.69908 Training err. RA 1.94323 Valid. err. 1.76502
2018-02-03 21:46:13,978 training [INFO ] Epoch 23 Batch 4720 Training err. 1.63221 Training err. RA 1.94192 Valid. err. 1.76182
2018-02-03 21:46:14,443 training [INFO ] Epoch 23 Batch 4740 Training err. 1.62848 Training err. RA 1.94059 Valid. err. 1.75834
2018-02-03 21:46:14,932 training [INFO ] Epoch 23 Batch 4760 Training err. 1.63197 Training err. RA 1.93930 Valid. err. 1.73369
2018-02-03 21:46:15,418 training [INFO ] Epoch 23 Batch 4780 Training err. 1.64269 Training err. RA 1.93806 Valid. err. 1.76041
2018-02-03 21:46:16,291 training [INFO ] Epoch 24 Batch 4800 Training err. 1.61177 Training err. RA 1.93670 Valid. err. 1.76792
2018-02-03 21:46:16,771 training [INFO ] Epoch 24 Batch 4820 Training err. 1.58464 Training err. RA 1.93524 Valid. err. 1.75181
2018-02-03 21:46:17,242 training [INFO ] Epoch 24 Batch 4840 Training err. 1.64705 Training err. RA 1.93404 Valid. err. 1.75492
2018-02-03 21:46:17,760 training [INFO ] Epoch 24 Batch 4860 Training err. 1.67465 Training err. RA 1.93298 Valid. err. 1.74778
2018-02-03 21:46:18,268 training [INFO ] Epoch 24 Batch 4880 Training err. 1.62543 Training err. RA 1.93172 Valid. err. 1.82601
2018-02-03 21:46:18,753 training [INFO ] Epoch 24 Batch 4900 Training err. 1.68424 Training err. RA 1.93071 Valid. err. 1.75829
2018-02-03 21:46:19,241 training [INFO ] Epoch 24 Batch 4920 Training err. 1.65805 Training err. RA 1.92960 Valid. err. 1.78039
2018-02-03 21:46:19,728 training [INFO ] Epoch 24 Batch 4940 Training err. 1.61140 Training err. RA 1.92831 Valid. err. 1.75446
2018-02-03 21:46:20,213 training [INFO ] Epoch 24 Batch 4960 Training err. 1.63200 Training err. RA 1.92711 Valid. err. 1.74743
2018-02-03 21:46:20,707 training [INFO ] Epoch 24 Batch 4980 Training err. 1.62826 Training err. RA 1.92591 Valid. err. 1.74057
2018-02-03 21:46:21,605 training [INFO ] Epoch 25 Batch 5000 Training err. 1.60750 Training err. RA 1.92464 Valid. err. 1.73927
2018-02-03 21:46:22,101 training [INFO ] Epoch 25 Batch 5020 Training err. 1.57971 Training err. RA 1.92327 Valid. err. 1.74850
2018-02-03 21:46:22,590 training [INFO ] Epoch 25 Batch 5040 Training err. 1.63690 Training err. RA 1.92213 Valid. err. 1.73752
2018-02-03 21:46:23,082 training [INFO ] Epoch 25 Batch 5060 Training err. 1.66030 Training err. RA 1.92110 Valid. err. 1.73543
2018-02-03 21:46:23,586 training [INFO ] Epoch 25 Batch 5080 Training err. 1.62108 Training err. RA 1.91991 Valid. err. 1.76372
2018-02-03 21:46:24,072 training [INFO ] Epoch 25 Batch 5100 Training err. 1.63353 Training err. RA 1.91879 Valid. err. 1.76149
2018-02-03 21:46:24,558 training [INFO ] Epoch 25 Batch 5120 Training err. 1.68115 Training err. RA 1.91786 Valid. err. 1.74760
2018-02-03 21:46:25,073 training [INFO ] Epoch 25 Batch 5140 Training err. 1.61568 Training err. RA 1.91669 Valid. err. 1.80476
2018-02-03 21:46:25,570 training [INFO ] Epoch 25 Batch 5160 Training err. 1.60611 Training err. RA 1.91548 Valid. err. 1.75303
2018-02-03 21:46:26,031 training [INFO ] Epoch 25 Batch 5180 Training err. 1.61622 Training err. RA 1.91433 Valid. err. 1.72015
2018-02-03 21:46:26,504 training [INFO ] Epoch 25 Batch 5200 Training err. 1.61375 Training err. RA 1.91317 Valid. err. 1.74455
2018-02-03 21:46:27,350 training [INFO ] Epoch 26 Batch 5220 Training err. 1.60325 Training err. RA 1.91198 Valid. err. 1.73677
2018-02-03 21:46:27,825 training [INFO ] Epoch 26 Batch 5240 Training err. 1.56088 Training err. RA 1.91064 Valid. err. 1.75022
2018-02-03 21:46:28,287 training [INFO ] Epoch 26 Batch 5260 Training err. 1.64020 Training err. RA 1.90962 Valid. err. 1.75029
2018-02-03 21:46:28,791 training [INFO ] Epoch 26 Batch 5280 Training err. 1.66258 Training err. RA 1.90868 Valid. err. 1.75846
2018-02-03 21:46:29,286 training [INFO ] Epoch 26 Batch 5300 Training err. 1.60070 Training err. RA 1.90752 Valid. err. 1.75316
2018-02-03 21:46:29,746 training [INFO ] Epoch 26 Batch 5320 Training err. 1.66474 Training err. RA 1.90661 Valid. err. 1.73511
2018-02-03 21:46:30,216 training [INFO ] Epoch 26 Batch 5340 Training err. 1.63096 Training err. RA 1.90557 Valid. err. 1.72954
2018-02-03 21:46:30,684 training [INFO ] Epoch 26 Batch 5360 Training err. 1.59626 Training err. RA 1.90442 Valid. err. 1.76586
2018-02-03 21:46:31,150 training [INFO ] Epoch 26 Batch 5380 Training err. 1.60338 Training err. RA 1.90330 Valid. err. 1.74346
2018-02-03 21:46:31,617 training [INFO ] Epoch 26 Batch 5400 Training err. 1.61610 Training err. RA 1.90224 Valid. err. 1.71853
2018-02-03 21:46:32,482 training [INFO ] Epoch 27 Batch 5420 Training err. 1.59805 Training err. RA 1.90111 Valid. err. 1.71782
2018-02-03 21:46:32,954 training [INFO ] Epoch 27 Batch 5440 Training err. 1.54858 Training err. RA 1.89982 Valid. err. 1.74788
2018-02-03 21:46:33,418 training [INFO ] Epoch 27 Batch 5460 Training err. 1.62883 Training err. RA 1.89882 Valid. err. 1.73622
2018-02-03 21:46:33,884 training [INFO ] Epoch 27 Batch 5480 Training err. 1.65121 Training err. RA 1.89792 Valid. err. 1.75004
2018-02-03 21:46:34,370 training [INFO ] Epoch 27 Batch 5500 Training err. 1.59267 Training err. RA 1.89681 Valid. err. 1.73862
2018-02-03 21:46:34,840 training [INFO ] Epoch 27 Batch 5520 Training err. 1.62476 Training err. RA 1.89583 Valid. err. 1.72206
2018-02-03 21:46:35,305 training [INFO ] Epoch 27 Batch 5540 Training err. 1.65960 Training err. RA 1.89497 Valid. err. 1.73874
2018-02-03 21:46:35,770 training [INFO ] Epoch 27 Batch 5560 Training err. 1.59246 Training err. RA 1.89388 Valid. err. 1.74599
2018-02-03 21:46:36,248 training [INFO ] Epoch 27 Batch 5580 Training err. 1.60473 Training err. RA 1.89285 Valid. err. 1.71888
2018-02-03 21:46:36,711 training [INFO ] Epoch 27 Batch 5600 Training err. 1.59497 Training err. RA 1.89178 Valid. err. 1.72836
2018-02-03 21:46:37,551 training [INFO ] Epoch 28 Batch 5620 Training err. 1.58865 Training err. RA 1.89071 Valid. err. 1.72045
2018-02-03 21:46:38,041 training [INFO ] Epoch 28 Batch 5640 Training err. 1.56409 Training err. RA 1.88955 Valid. err. 1.73202
2018-02-03 21:46:38,510 training [INFO ] Epoch 28 Batch 5660 Training err. 1.58060 Training err. RA 1.88846 Valid. err. 1.71856
2018-02-03 21:46:38,982 training [INFO ] Epoch 28 Batch 5680 Training err. 1.62317 Training err. RA 1.88752 Valid. err. 1.72912
2018-02-03 21:46:39,447 training [INFO ] Epoch 28 Batch 5700 Training err. 1.62222 Training err. RA 1.88659 Valid. err. 1.75660
2018-02-03 21:46:39,918 training [INFO ] Epoch 28 Batch 5720 Training err. 1.61324 Training err. RA 1.88563 Valid. err. 1.73280
2018-02-03 21:46:40,387 training [INFO ] Epoch 28 Batch 5740 Training err. 1.65640 Training err. RA 1.88484 Valid. err. 1.73784
2018-02-03 21:46:40,862 training [INFO ] Epoch 28 Batch 5760 Training err. 1.59042 Training err. RA 1.88381 Valid. err. 1.76386
2018-02-03 21:46:41,357 training [INFO ] Epoch 28 Batch 5780 Training err. 1.57911 Training err. RA 1.88276 Valid. err. 1.72956
2018-02-03 21:46:41,838 training [INFO ] Epoch 28 Batch 5800 Training err. 1.58728 Training err. RA 1.88174 Valid. err. 1.71213
2018-02-03 21:46:42,319 training [INFO ] Epoch 28 Batch 5820 Training err. 1.60598 Training err. RA 1.88079 Valid. err. 1.72743
2018-02-03 21:46:43,180 training [INFO ] Epoch 29 Batch 5840 Training err. 1.56779 Training err. RA 1.87972 Valid. err. 1.74409
2018-02-03 21:46:43,643 training [INFO ] Epoch 29 Batch 5860 Training err. 1.53928 Training err. RA 1.87856 Valid. err. 1.73187
2018-02-03 21:46:44,108 training [INFO ] Epoch 29 Batch 5880 Training err. 1.60813 Training err. RA 1.87764 Valid. err. 1.72833
2018-02-03 21:46:44,599 training [INFO ] Epoch 29 Batch 5900 Training err. 1.63383 Training err. RA 1.87681 Valid. err. 1.72251
2018-02-03 21:46:45,067 training [INFO ] Epoch 29 Batch 5920 Training err. 1.58091 Training err. RA 1.87581 Valid. err. 1.80423
2018-02-03 21:46:45,574 training [INFO ] Epoch 29 Batch 5940 Training err. 1.64756 Training err. RA 1.87504 Valid. err. 1.73237
2018-02-03 21:46:46,040 training [INFO ] Epoch 29 Batch 5960 Training err. 1.61606 Training err. RA 1.87418 Valid. err. 1.76327
2018-02-03 21:46:46,523 training [INFO ] Epoch 29 Batch 5980 Training err. 1.57143 Training err. RA 1.87316 Valid. err. 1.73835
2018-02-03 21:46:46,994 training [INFO ] Epoch 29 Batch 6000 Training err. 1.58235 Training err. RA 1.87219 Valid. err. 1.70827
2018-02-03 21:46:47,459 training [INFO ] Epoch 29 Batch 6020 Training err. 1.58885 Training err. RA 1.87125 Valid. err. 1.71348
2018-02-03 21:46:48,288 training [INFO ] Epoch 30 Batch 6040 Training err. 1.56288 Training err. RA 1.87023 Valid. err. 1.72196
2018-02-03 21:46:48,751 training [INFO ] Epoch 30 Batch 6060 Training err. 1.53373 Training err. RA 1.86912 Valid. err. 1.72058
2018-02-03 21:46:49,215 training [INFO ] Epoch 30 Batch 6080 Training err. 1.59623 Training err. RA 1.86822 Valid. err. 1.72980
2018-02-03 21:46:49,680 training [INFO ] Epoch 30 Batch 6100 Training err. 1.62468 Training err. RA 1.86742 Valid. err. 1.70829
2018-02-03 21:46:50,173 training [INFO ] Epoch 30 Batch 6120 Training err. 1.58044 Training err. RA 1.86649 Valid. err. 1.73980
2018-02-03 21:46:50,658 training [INFO ] Epoch 30 Batch 6140 Training err. 1.59348 Training err. RA 1.86560 Valid. err. 1.72971
2018-02-03 21:46:51,161 training [INFO ] Epoch 30 Batch 6160 Training err. 1.63951 Training err. RA 1.86486 Valid. err. 1.71405
2018-02-03 21:46:51,637 training [INFO ] Epoch 30 Batch 6180 Training err. 1.58008 Training err. RA 1.86394 Valid. err. 1.74960
2018-02-03 21:46:52,121 training [INFO ] Epoch 30 Batch 6200 Training err. 1.55811 Training err. RA 1.86296 Valid. err. 1.73117
2018-02-03 21:46:52,606 training [INFO ] Epoch 30 Batch 6220 Training err. 1.57646 Training err. RA 1.86203 Valid. err. 1.68961
2018-02-03 21:46:53,094 training [INFO ] Epoch 30 Batch 6240 Training err. 1.57622 Training err. RA 1.86112 Valid. err. 1.71228
2018-02-03 21:46:53,923 training [INFO ] Epoch 31 Batch 6260 Training err. 1.56074 Training err. RA 1.86016 Valid. err. 1.71196
2018-02-03 21:46:54,383 training [INFO ] Epoch 31 Batch 6280 Training err. 1.51622 Training err. RA 1.85906 Valid. err. 1.72346
2018-02-03 21:46:54,844 training [INFO ] Epoch 31 Batch 6300 Training err. 1.60089 Training err. RA 1.85824 Valid. err. 1.72759
2018-02-03 21:46:55,304 training [INFO ] Epoch 31 Batch 6320 Training err. 1.63012 Training err. RA 1.85752 Valid. err. 1.73128
2018-02-03 21:46:55,763 training [INFO ] Epoch 31 Batch 6340 Training err. 1.56012 Training err. RA 1.85658 Valid. err. 1.72474
2018-02-03 21:46:56,223 training [INFO ] Epoch 31 Batch 6360 Training err. 1.62599 Training err. RA 1.85586 Valid. err. 1.70229
2018-02-03 21:46:56,685 training [INFO ] Epoch 31 Batch 6380 Training err. 1.59511 Training err. RA 1.85504 Valid. err. 1.70959
2018-02-03 21:46:57,151 training [INFO ] Epoch 31 Batch 6400 Training err. 1.55674 Training err. RA 1.85411 Valid. err. 1.75021
2018-02-03 21:46:57,627 training [INFO ] Epoch 31 Batch 6420 Training err. 1.56706 Training err. RA 1.85321 Valid. err. 1.72477
2018-02-03 21:46:58,092 training [INFO ] Epoch 31 Batch 6440 Training err. 1.58050 Training err. RA 1.85237 Valid. err. 1.68917
2018-02-03 21:46:58,934 training [INFO ] Epoch 32 Batch 6460 Training err. 1.55336 Training err. RA 1.85144 Valid. err. 1.69902
2018-02-03 21:46:59,400 training [INFO ] Epoch 32 Batch 6480 Training err. 1.51355 Training err. RA 1.85040 Valid. err. 1.71198
2018-02-03 21:46:59,875 training [INFO ] Epoch 32 Batch 6500 Training err. 1.58600 Training err. RA 1.84959 Valid. err. 1.69619
2018-02-03 21:47:00,346 training [INFO ] Epoch 32 Batch 6520 Training err. 1.61642 Training err. RA 1.84887 Valid. err. 1.73442
2018-02-03 21:47:00,817 training [INFO ] Epoch 32 Batch 6540 Training err. 1.55305 Training err. RA 1.84797 Valid. err. 1.71945
2018-02-03 21:47:01,298 training [INFO ] Epoch 32 Batch 6560 Training err. 1.58860 Training err. RA 1.84717 Valid. err. 1.71274
2018-02-03 21:47:01,799 training [INFO ] Epoch 32 Batch 6580 Training err. 1.61596 Training err. RA 1.84647 Valid. err. 1.72179
2018-02-03 21:47:02,309 training [INFO ] Epoch 32 Batch 6600 Training err. 1.56013 Training err. RA 1.84560 Valid. err. 1.71919
2018-02-03 21:47:02,778 training [INFO ] Epoch 32 Batch 6620 Training err. 1.56317 Training err. RA 1.84475 Valid. err. 1.69694
2018-02-03 21:47:03,267 training [INFO ] Epoch 32 Batch 6640 Training err. 1.55470 Training err. RA 1.84388 Valid. err. 1.71273
2018-02-03 21:47:04,159 training [INFO ] Epoch 33 Batch 6660 Training err. 1.55299 Training err. RA 1.84300 Valid. err. 1.69053
2018-02-03 21:47:04,664 training [INFO ] Epoch 33 Batch 6680 Training err. 1.52572 Training err. RA 1.84205 Valid. err. 1.70818
2018-02-03 21:47:05,126 training [INFO ] Epoch 33 Batch 6700 Training err. 1.54517 Training err. RA 1.84117 Valid. err. 1.69197
2018-02-03 21:47:05,601 training [INFO ] Epoch 33 Batch 6720 Training err. 1.59038 Training err. RA 1.84042 Valid. err. 1.71720
2018-02-03 21:47:06,080 training [INFO ] Epoch 33 Batch 6740 Training err. 1.60000 Training err. RA 1.83971 Valid. err. 1.71542
2018-02-03 21:47:06,564 training [INFO ] Epoch 33 Batch 6760 Training err. 1.57097 Training err. RA 1.83891 Valid. err. 1.69966
2018-02-03 21:47:07,033 training [INFO ] Epoch 33 Batch 6780 Training err. 1.62204 Training err. RA 1.83827 Valid. err. 1.71040
2018-02-03 21:47:07,512 training [INFO ] Epoch 33 Batch 6800 Training err. 1.55329 Training err. RA 1.83743 Valid. err. 1.70885
2018-02-03 21:47:07,973 training [INFO ] Epoch 33 Batch 6820 Training err. 1.54240 Training err. RA 1.83657 Valid. err. 1.72223
2018-02-03 21:47:08,476 training [INFO ] Epoch 33 Batch 6840 Training err. 1.54354 Training err. RA 1.83571 Valid. err. 1.68137
2018-02-03 21:47:08,964 training [INFO ] Epoch 33 Batch 6860 Training err. 1.56659 Training err. RA 1.83493 Valid. err. 1.69571
2018-02-03 21:47:09,841 training [INFO ] Epoch 34 Batch 6880 Training err. 1.52867 Training err. RA 1.83404 Valid. err. 1.71699
2018-02-03 21:47:10,311 training [INFO ] Epoch 34 Batch 6900 Training err. 1.51030 Training err. RA 1.83310 Valid. err. 1.68836
2018-02-03 21:47:10,796 training [INFO ] Epoch 34 Batch 6920 Training err. 1.57004 Training err. RA 1.83234 Valid. err. 1.71419
2018-02-03 21:47:11,304 training [INFO ] Epoch 34 Batch 6940 Training err. 1.59643 Training err. RA 1.83166 Valid. err. 1.69575
2018-02-03 21:47:11,778 training [INFO ] Epoch 34 Batch 6960 Training err. 1.53984 Training err. RA 1.83082 Valid. err. 1.76111
2018-02-03 21:47:12,266 training [INFO ] Epoch 34 Batch 6980 Training err. 1.60228 Training err. RA 1.83017 Valid. err. 1.70929
2018-02-03 21:47:12,742 training [INFO ] Epoch 34 Batch 7000 Training err. 1.58382 Training err. RA 1.82946 Valid. err. 1.73942
2018-02-03 21:47:13,215 training [INFO ] Epoch 34 Batch 7020 Training err. 1.53978 Training err. RA 1.82864 Valid. err. 1.71950
2018-02-03 21:47:13,674 training [INFO ] Epoch 34 Batch 7040 Training err. 1.54370 Training err. RA 1.82783 Valid. err. 1.69304
2018-02-03 21:47:14,162 training [INFO ] Epoch 34 Batch 7060 Training err. 1.55322 Training err. RA 1.82705 Valid. err. 1.69236
2018-02-03 21:47:15,006 training [INFO ] Epoch 35 Batch 7080 Training err. 1.52608 Training err. RA 1.82620 Valid. err. 1.70045
2018-02-03 21:47:15,479 training [INFO ] Epoch 35 Batch 7100 Training err. 1.50330 Training err. RA 1.82529 Valid. err. 1.68312
2018-02-03 21:47:15,978 training [INFO ] Epoch 35 Batch 7120 Training err. 1.56459 Training err. RA 1.82456 Valid. err. 1.68597
2018-02-03 21:47:16,480 training [INFO ] Epoch 35 Batch 7140 Training err. 1.58562 Training err. RA 1.82389 Valid. err. 1.68934
2018-02-03 21:47:16,974 training [INFO ] Epoch 35 Batch 7160 Training err. 1.54318 Training err. RA 1.82310 Valid. err. 1.71732
2018-02-03 21:47:17,472 training [INFO ] Epoch 35 Batch 7180 Training err. 1.54964 Training err. RA 1.82234 Valid. err. 1.70393
2018-02-03 21:47:17,967 training [INFO ] Epoch 35 Batch 7200 Training err. 1.60396 Training err. RA 1.82174 Valid. err. 1.69647
2018-02-03 21:47:18,446 training [INFO ] Epoch 35 Batch 7220 Training err. 1.54827 Training err. RA 1.82098 Valid. err. 1.72857
2018-02-03 21:47:18,910 training [INFO ] Epoch 35 Batch 7240 Training err. 1.51871 Training err. RA 1.82014 Valid. err. 1.70232
2018-02-03 21:47:19,375 training [INFO ] Epoch 35 Batch 7260 Training err. 1.53453 Training err. RA 1.81936 Valid. err. 1.67628
2018-02-03 21:47:19,847 training [INFO ] Epoch 35 Batch 7280 Training err. 1.54200 Training err. RA 1.81859 Valid. err. 1.69761
2018-02-03 21:47:20,703 training [INFO ] Epoch 36 Batch 7300 Training err. 1.53082 Training err. RA 1.81781 Valid. err. 1.67723
2018-02-03 21:47:21,164 training [INFO ] Epoch 36 Batch 7320 Training err. 1.48095 Training err. RA 1.81689 Valid. err. 1.69804
2018-02-03 21:47:21,625 training [INFO ] Epoch 36 Batch 7340 Training err. 1.57272 Training err. RA 1.81622 Valid. err. 1.69006
2018-02-03 21:47:22,085 training [INFO ] Epoch 36 Batch 7360 Training err. 1.59369 Training err. RA 1.81562 Valid. err. 1.69911
2018-02-03 21:47:22,564 training [INFO ] Epoch 36 Batch 7380 Training err. 1.52074 Training err. RA 1.81482 Valid. err. 1.70544
2018-02-03 21:47:23,053 training [INFO ] Epoch 36 Batch 7400 Training err. 1.58707 Training err. RA 1.81420 Valid. err. 1.67301
2018-02-03 21:47:23,514 training [INFO ] Epoch 36 Batch 7420 Training err. 1.55982 Training err. RA 1.81351 Valid. err. 1.68368
2018-02-03 21:47:23,985 training [INFO ] Epoch 36 Batch 7440 Training err. 1.52282 Training err. RA 1.81273 Valid. err. 1.71214
2018-02-03 21:47:24,460 training [INFO ] Epoch 36 Batch 7460 Training err. 1.52319 Training err. RA 1.81196 Valid. err. 1.70263
2018-02-03 21:47:24,923 training [INFO ] Epoch 36 Batch 7480 Training err. 1.54291 Training err. RA 1.81124 Valid. err. 1.67355
2018-02-03 21:47:25,779 training [INFO ] Epoch 37 Batch 7500 Training err. 1.51910 Training err. RA 1.81046 Valid. err. 1.67440
2018-02-03 21:47:26,244 training [INFO ] Epoch 37 Batch 7520 Training err. 1.48218 Training err. RA 1.80959 Valid. err. 1.67558
2018-02-03 21:47:26,716 training [INFO ] Epoch 37 Batch 7540 Training err. 1.55638 Training err. RA 1.80891 Valid. err. 1.66540
2018-02-03 21:47:27,189 training [INFO ] Epoch 37 Batch 7560 Training err. 1.57904 Training err. RA 1.80831 Valid. err. 1.71596
2018-02-03 21:47:27,685 training [INFO ] Epoch 37 Batch 7580 Training err. 1.51878 Training err. RA 1.80754 Valid. err. 1.70233
2018-02-03 21:47:28,163 training [INFO ] Epoch 37 Batch 7600 Training err. 1.55252 Training err. RA 1.80687 Valid. err. 1.69047
2018-02-03 21:47:28,660 training [INFO ] Epoch 37 Batch 7620 Training err. 1.58465 Training err. RA 1.80629 Valid. err. 1.70258
2018-02-03 21:47:29,157 training [INFO ] Epoch 37 Batch 7640 Training err. 1.52434 Training err. RA 1.80555 Valid. err. 1.70187
2018-02-03 21:47:29,632 training [INFO ] Epoch 37 Batch 7660 Training err. 1.52802 Training err. RA 1.80482 Valid. err. 1.66943
2018-02-03 21:47:30,123 training [INFO ] Epoch 37 Batch 7680 Training err. 1.51943 Training err. RA 1.80408 Valid. err. 1.68101
2018-02-03 21:47:30,985 training [INFO ] Epoch 38 Batch 7700 Training err. 1.51680 Training err. RA 1.80334 Valid. err. 1.66501
2018-02-03 21:47:31,462 training [INFO ] Epoch 38 Batch 7720 Training err. 1.50383 Training err. RA 1.80256 Valid. err. 1.67640
2018-02-03 21:47:31,921 training [INFO ] Epoch 38 Batch 7740 Training err. 1.51198 Training err. RA 1.80181 Valid. err. 1.66726
2018-02-03 21:47:32,380 training [INFO ] Epoch 38 Batch 7760 Training err. 1.55922 Training err. RA 1.80118 Valid. err. 1.70512
2018-02-03 21:47:32,843 training [INFO ] Epoch 38 Batch 7780 Training err. 1.54700 Training err. RA 1.80053 Valid. err. 1.69825
2018-02-03 21:47:33,317 training [INFO ] Epoch 38 Batch 7800 Training err. 1.52162 Training err. RA 1.79981 Valid. err. 1.68317
2018-02-03 21:47:33,798 training [INFO ] Epoch 38 Batch 7820 Training err. 1.58224 Training err. RA 1.79926 Valid. err. 1.69654
2018-02-03 21:47:34,269 training [INFO ] Epoch 38 Batch 7840 Training err. 1.52296 Training err. RA 1.79855 Valid. err. 1.69397
2018-02-03 21:47:34,749 training [INFO ] Epoch 38 Batch 7860 Training err. 1.50930 Training err. RA 1.79782 Valid. err. 1.68616
2018-02-03 21:47:35,218 training [INFO ] Epoch 38 Batch 7880 Training err. 1.51188 Training err. RA 1.79709 Valid. err. 1.68172
2018-02-03 21:47:35,797 training [INFO ] Epoch 38 Batch 7900 Training err. 1.53444 Training err. RA 1.79643 Valid. err. 1.66578
2018-02-03 21:47:36,857 training [INFO ] Epoch 39 Batch 7920 Training err. 1.50029 Training err. RA 1.79568 Valid. err. 1.68099
2018-02-03 21:47:37,356 training [INFO ] Epoch 39 Batch 7940 Training err. 1.47444 Training err. RA 1.79487 Valid. err. 1.66888
2018-02-03 21:47:37,821 training [INFO ] Epoch 39 Batch 7960 Training err. 1.54148 Training err. RA 1.79423 Valid. err. 1.70170
2018-02-03 21:47:38,281 training [INFO ] Epoch 39 Batch 7980 Training err. 1.57110 Training err. RA 1.79367 Valid. err. 1.67604
2018-02-03 21:47:38,743 training [INFO ] Epoch 39 Batch 8000 Training err. 1.50795 Training err. RA 1.79296 Valid. err. 1.72759
2018-02-03 21:47:39,205 training [INFO ] Epoch 39 Batch 8020 Training err. 1.68981 Training err. RA 1.79270 Valid. err. 1.68727
2018-02-03 21:47:39,666 training [INFO ] Epoch 39 Batch 8040 Training err. 1.54906 Training err. RA 1.79210 Valid. err. 1.70389
2018-02-03 21:47:40,127 training [INFO ] Epoch 39 Batch 8060 Training err. 1.51069 Training err. RA 1.79140 Valid. err. 1.69762
2018-02-03 21:47:40,589 training [INFO ] Epoch 39 Batch 8080 Training err. 1.51177 Training err. RA 1.79071 Valid. err. 1.67347
2018-02-03 21:47:41,052 training [INFO ] Epoch 39 Batch 8100 Training err. 1.52042 Training err. RA 1.79004 Valid. err. 1.67757
2018-02-03 21:47:41,894 training [INFO ] Epoch 40 Batch 8120 Training err. 1.49527 Training err. RA 1.78931 Valid. err. 1.67294
2018-02-03 21:47:42,357 training [INFO ] Epoch 40 Batch 8140 Training err. 1.47238 Training err. RA 1.78853 Valid. err. 1.66353
2018-02-03 21:47:42,820 training [INFO ] Epoch 40 Batch 8160 Training err. 1.53779 Training err. RA 1.78792 Valid. err. 1.66389
2018-02-03 21:47:43,285 training [INFO ] Epoch 40 Batch 8180 Training err. 1.55369 Training err. RA 1.78735 Valid. err. 1.66420
2018-02-03 21:47:43,748 training [INFO ] Epoch 40 Batch 8200 Training err. 1.50524 Training err. RA 1.78666 Valid. err. 1.69045
2018-02-03 21:47:44,211 training [INFO ] Epoch 40 Batch 8220 Training err. 1.51442 Training err. RA 1.78600 Valid. err. 1.67615
2018-02-03 21:47:44,672 training [INFO ] Epoch 40 Batch 8240 Training err. 1.57001 Training err. RA 1.78547 Valid. err. 1.68245
2018-02-03 21:47:45,131 training [INFO ] Epoch 40 Batch 8260 Training err. 1.51391 Training err. RA 1.78481 Valid. err. 1.70081
2018-02-03 21:47:45,591 training [INFO ] Epoch 40 Batch 8280 Training err. 1.49476 Training err. RA 1.78411 Valid. err. 1.70917
2018-02-03 21:47:46,051 training [INFO ] Epoch 40 Batch 8300 Training err. 1.50317 Training err. RA 1.78344 Valid. err. 1.65119
2018-02-03 21:47:46,512 training [INFO ] Epoch 40 Batch 8320 Training err. 1.50504 Training err. RA 1.78277 Valid. err. 1.67031
2018-02-03 21:47:47,344 training [INFO ] Epoch 41 Batch 8340 Training err. 1.49910 Training err. RA 1.78209 Valid. err. 1.65834
2018-02-03 21:47:47,805 training [INFO ] Epoch 41 Batch 8360 Training err. 1.45523 Training err. RA 1.78131 Valid. err. 1.67115
2018-02-03 21:47:48,263 training [INFO ] Epoch 41 Batch 8380 Training err. 1.53571 Training err. RA 1.78072 Valid. err. 1.68469
2018-02-03 21:47:48,723 training [INFO ] Epoch 41 Batch 8400 Training err. 1.55673 Training err. RA 1.78019 Valid. err. 1.69654
2018-02-03 21:47:49,183 training [INFO ] Epoch 41 Batch 8420 Training err. 1.48131 Training err. RA 1.77948 Valid. err. 1.69676
2018-02-03 21:47:49,643 training [INFO ] Epoch 41 Batch 8440 Training err. 1.56241 Training err. RA 1.77896 Valid. err. 1.68116
2018-02-03 21:47:50,102 training [INFO ] Epoch 41 Batch 8460 Training err. 1.53323 Training err. RA 1.77838 Valid. err. 1.66969
2018-02-03 21:47:50,560 training [INFO ] Epoch 41 Batch 8480 Training err. 1.49349 Training err. RA 1.77771 Valid. err. 1.69128
2018-02-03 21:47:51,028 training [INFO ] Epoch 41 Batch 8500 Training err. 1.49004 Training err. RA 1.77703 Valid. err. 1.67855
2018-02-03 21:47:51,489 training [INFO ] Epoch 41 Batch 8520 Training err. 1.50926 Training err. RA 1.77640 Valid. err. 1.65137
2018-02-03 21:47:52,322 training [INFO ] Epoch 42 Batch 8540 Training err. 1.48884 Training err. RA 1.77573 Valid. err. 1.66381
2018-02-03 21:47:52,793 training [INFO ] Epoch 42 Batch 8560 Training err. 1.45317 Training err. RA 1.77498 Valid. err. 1.67996
2018-02-03 21:47:53,291 training [INFO ] Epoch 42 Batch 8580 Training err. 1.53047 Training err. RA 1.77441 Valid. err. 1.66761
2018-02-03 21:47:53,755 training [INFO ] Epoch 42 Batch 8600 Training err. 1.55003 Training err. RA 1.77388 Valid. err. 1.69499
2018-02-03 21:47:54,221 training [INFO ] Epoch 42 Batch 8620 Training err. 1.48556 Training err. RA 1.77322 Valid. err. 1.68986
2018-02-03 21:47:54,686 training [INFO ] Epoch 42 Batch 8640 Training err. 1.51443 Training err. RA 1.77262 Valid. err. 1.67759
2018-02-03 21:47:55,150 training [INFO ] Epoch 42 Batch 8660 Training err. 1.55463 Training err. RA 1.77211 Valid. err. 1.70794
2018-02-03 21:47:55,613 training [INFO ] Epoch 42 Batch 8680 Training err. 1.49704 Training err. RA 1.77148 Valid. err. 1.69180
2018-02-03 21:47:56,078 training [INFO ] Epoch 42 Batch 8700 Training err. 1.50535 Training err. RA 1.77087 Valid. err. 1.66587
2018-02-03 21:47:56,540 training [INFO ] Epoch 42 Batch 8720 Training err. 1.49338 Training err. RA 1.77023 Valid. err. 1.67332
2018-02-03 21:47:57,400 training [INFO ] Epoch 43 Batch 8740 Training err. 1.48215 Training err. RA 1.76957 Valid. err. 1.64234
2018-02-03 21:47:57,884 training [INFO ] Epoch 43 Batch 8760 Training err. 1.47393 Training err. RA 1.76890 Valid. err. 1.66453
2018-02-03 21:47:58,355 training [INFO ] Epoch 43 Batch 8780 Training err. 1.48679 Training err. RA 1.76825 Valid. err. 1.65261
2018-02-03 21:47:58,846 training [INFO ] Epoch 43 Batch 8800 Training err. 1.52563 Training err. RA 1.76770 Valid. err. 1.68234
2018-02-03 21:47:59,318 training [INFO ] Epoch 43 Batch 8820 Training err. 1.52240 Training err. RA 1.76715 Valid. err. 1.68606
2018-02-03 21:47:59,779 training [INFO ] Epoch 43 Batch 8840 Training err. 1.48933 Training err. RA 1.76652 Valid. err. 1.66199
2018-02-03 21:48:00,292 training [INFO ] Epoch 43 Batch 8860 Training err. 1.55584 Training err. RA 1.76604 Valid. err. 1.67922
2018-02-03 21:48:00,760 training [INFO ] Epoch 43 Batch 8880 Training err. 1.49165 Training err. RA 1.76542 Valid. err. 1.67744
2018-02-03 21:48:01,226 training [INFO ] Epoch 43 Batch 8900 Training err. 1.47858 Training err. RA 1.76478 Valid. err. 1.68227
2018-02-03 21:48:01,687 training [INFO ] Epoch 43 Batch 8920 Training err. 1.48312 Training err. RA 1.76415 Valid. err. 1.65315
2018-02-03 21:48:02,149 training [INFO ] Epoch 43 Batch 8940 Training err. 1.50279 Training err. RA 1.76356 Valid. err. 1.66140
2018-02-03 21:48:02,985 training [INFO ] Epoch 44 Batch 8960 Training err. 1.47011 Training err. RA 1.76291 Valid. err. 1.66914
2018-02-03 21:48:03,461 training [INFO ] Epoch 44 Batch 8980 Training err. 1.44726 Training err. RA 1.76221 Valid. err. 1.65503
2018-02-03 21:48:03,926 training [INFO ] Epoch 44 Batch 9000 Training err. 1.51116 Training err. RA 1.76165 Valid. err. 1.68070
2018-02-03 21:48:04,406 training [INFO ] Epoch 44 Batch 9020 Training err. 1.53026 Training err. RA 1.76113 Valid. err. 1.67080
2018-02-03 21:48:04,878 training [INFO ] Epoch 44 Batch 9040 Training err. 1.47260 Training err. RA 1.76050 Valid. err. 1.69096
2018-02-03 21:48:05,359 training [INFO ] Epoch 44 Batch 9060 Training err. 1.52885 Training err. RA 1.75999 Valid. err. 1.69550
2018-02-03 21:48:05,821 training [INFO ] Epoch 44 Batch 9080 Training err. 1.52271 Training err. RA 1.75946 Valid. err. 1.68679
2018-02-03 21:48:06,290 training [INFO ] Epoch 44 Batch 9100 Training err. 1.47233 Training err. RA 1.75883 Valid. err. 1.66848
2018-02-03 21:48:06,751 training [INFO ] Epoch 44 Batch 9120 Training err. 1.48592 Training err. RA 1.75823 Valid. err. 1.65883
2018-02-03 21:48:07,213 training [INFO ] Epoch 44 Batch 9140 Training err. 1.49544 Training err. RA 1.75766 Valid. err. 1.65092
2018-02-03 21:48:08,097 training [INFO ] Epoch 45 Batch 9160 Training err. 1.46423 Training err. RA 1.75702 Valid. err. 1.65350
2018-02-03 21:48:08,596 training [INFO ] Epoch 45 Batch 9180 Training err. 1.44557 Training err. RA 1.75634 Valid. err. 1.65688
2018-02-03 21:48:09,066 training [INFO ] Epoch 45 Batch 9200 Training err. 1.50830 Training err. RA 1.75580 Valid. err. 1.64824
2018-02-03 21:48:09,545 training [INFO ] Epoch 45 Batch 9220 Training err. 1.52119 Training err. RA 1.75529 Valid. err. 1.64326
2018-02-03 21:48:10,031 training [INFO ] Epoch 45 Batch 9240 Training err. 1.48254 Training err. RA 1.75470 Valid. err. 1.68158
2018-02-03 21:48:10,521 training [INFO ] Epoch 45 Batch 9260 Training err. 1.47774 Training err. RA 1.75410 Valid. err. 1.67262
2018-02-03 21:48:10,992 training [INFO ] Epoch 45 Batch 9280 Training err. 1.55841 Training err. RA 1.75368 Valid. err. 1.65955
2018-02-03 21:48:11,479 training [INFO ] Epoch 45 Batch 9300 Training err. 1.48843 Training err. RA 1.75311 Valid. err. 1.67679
2018-02-03 21:48:11,984 training [INFO ] Epoch 45 Batch 9320 Training err. 1.45882 Training err. RA 1.75248 Valid. err. 1.69779
2018-02-03 21:48:12,474 training [INFO ] Epoch 45 Batch 9340 Training err. 1.47447 Training err. RA 1.75188 Valid. err. 1.63753
2018-02-03 21:48:12,954 training [INFO ] Epoch 45 Batch 9360 Training err. 1.47953 Training err. RA 1.75130 Valid. err. 1.63934
2018-02-03 21:48:13,853 training [INFO ] Epoch 46 Batch 9380 Training err. 1.46973 Training err. RA 1.75070 Valid. err. 1.64467
2018-02-03 21:48:14,331 training [INFO ] Epoch 46 Batch 9400 Training err. 1.43244 Training err. RA 1.75002 Valid. err. 1.65835
2018-02-03 21:48:14,828 training [INFO ] Epoch 46 Batch 9420 Training err. 1.51361 Training err. RA 1.74952 Valid. err. 1.67534
2018-02-03 21:48:15,323 training [INFO ] Epoch 46 Batch 9440 Training err. 1.52675 Training err. RA 1.74905 Valid. err. 1.69405
2018-02-03 21:48:15,811 training [INFO ] Epoch 46 Batch 9460 Training err. 1.46051 Training err. RA 1.74844 Valid. err. 1.66917
2018-02-03 21:48:16,308 training [INFO ] Epoch 46 Batch 9480 Training err. 1.51980 Training err. RA 1.74796 Valid. err. 1.64676
2018-02-03 21:48:16,780 training [INFO ] Epoch 46 Batch 9500 Training err. 1.50545 Training err. RA 1.74745 Valid. err. 1.64866
2018-02-03 21:48:17,241 training [INFO ] Epoch 46 Batch 9520 Training err. 1.46087 Training err. RA 1.74684 Valid. err. 1.66999
2018-02-03 21:48:17,716 training [INFO ] Epoch 46 Batch 9540 Training err. 1.45660 Training err. RA 1.74624 Valid. err. 1.65100
2018-02-03 21:48:18,194 training [INFO ] Epoch 46 Batch 9560 Training err. 1.48264 Training err. RA 1.74568 Valid. err. 1.65157
2018-02-03 21:48:19,065 training [INFO ] Epoch 47 Batch 9580 Training err. 1.46038 Training err. RA 1.74509 Valid. err. 1.63406
2018-02-03 21:48:19,570 training [INFO ] Epoch 47 Batch 9600 Training err. 1.42939 Training err. RA 1.74443 Valid. err. 1.66296
2018-02-03 21:48:20,058 training [INFO ] Epoch 47 Batch 9620 Training err. 1.50363 Training err. RA 1.74393 Valid. err. 1.65042
2018-02-03 21:48:20,545 training [INFO ] Epoch 47 Batch 9640 Training err. 1.51612 Training err. RA 1.74346 Valid. err. 1.66608
2018-02-03 21:48:21,011 training [INFO ] Epoch 47 Batch 9660 Training err. 1.45935 Training err. RA 1.74287 Valid. err. 1.68204
2018-02-03 21:48:21,475 training [INFO ] Epoch 47 Batch 9680 Training err. 1.48866 Training err. RA 1.74234 Valid. err. 1.64151
2018-02-03 21:48:21,941 training [INFO ] Epoch 47 Batch 9700 Training err. 1.52420 Training err. RA 1.74189 Valid. err. 1.68587
2018-02-03 21:48:22,406 training [INFO ] Epoch 47 Batch 9720 Training err. 1.47226 Training err. RA 1.74134 Valid. err. 1.66630
2018-02-03 21:48:22,871 training [INFO ] Epoch 47 Batch 9740 Training err. 1.45829 Training err. RA 1.74076 Valid. err. 1.63990
2018-02-03 21:48:23,335 training [INFO ] Epoch 47 Batch 9760 Training err. 1.46248 Training err. RA 1.74019 Valid. err. 1.65454
2018-02-03 21:48:24,187 training [INFO ] Epoch 48 Batch 9780 Training err. 1.45767 Training err. RA 1.73961 Valid. err. 1.63808
2018-02-03 21:48:24,661 training [INFO ] Epoch 48 Batch 9800 Training err. 1.44952 Training err. RA 1.73902 Valid. err. 1.63709
2018-02-03 21:48:25,146 training [INFO ] Epoch 48 Batch 9820 Training err. 1.46732 Training err. RA 1.73847 Valid. err. 1.64770
2018-02-03 21:48:25,638 training [INFO ] Epoch 48 Batch 9840 Training err. 1.49732 Training err. RA 1.73798 Valid. err. 1.67237
2018-02-03 21:48:26,129 training [INFO ] Epoch 48 Batch 9860 Training err. 1.49659 Training err. RA 1.73749 Valid. err. 1.68987
2018-02-03 21:48:26,595 training [INFO ] Epoch 48 Batch 9880 Training err. 1.47240 Training err. RA 1.73695 Valid. err. 1.64870
2018-02-03 21:48:27,055 training [INFO ] Epoch 48 Batch 9900 Training err. 1.52812 Training err. RA 1.73653 Valid. err. 1.67151
2018-02-03 21:48:27,528 training [INFO ] Epoch 48 Batch 9920 Training err. 1.46451 Training err. RA 1.73598 Valid. err. 1.66337
2018-02-03 21:48:28,010 training [INFO ] Epoch 48 Batch 9940 Training err. 1.45126 Training err. RA 1.73541 Valid. err. 1.65755
2018-02-03 21:48:28,476 training [INFO ] Epoch 48 Batch 9960 Training err. 1.43992 Training err. RA 1.73481 Valid. err. 1.63935
2018-02-03 21:48:28,940 training [INFO ] Epoch 48 Batch 9980 Training err. 1.48232 Training err. RA 1.73431 Valid. err. 1.63793
2018-02-03 21:48:29,794 training [INFO ] Epoch 49 Batch10000 Training err. 1.44219 Training err. RA 1.73372 Valid. err. 1.63663
2018-02-03 21:48:30,252 training [INFO ] Epoch 49 Batch10020 Training err. 1.42191 Training err. RA 1.73310 Valid. err. 1.63675
2018-02-03 21:48:30,712 training [INFO ] Epoch 49 Batch10040 Training err. 1.48648 Training err. RA 1.73261 Valid. err. 1.67894
2018-02-03 21:48:31,173 training [INFO ] Epoch 49 Batch10060 Training err. 1.50789 Training err. RA 1.73216 Valid. err. 1.64015
2018-02-03 21:48:31,633 training [INFO ] Epoch 49 Batch10080 Training err. 1.44695 Training err. RA 1.73160 Valid. err. 1.67023
2018-02-03 21:48:32,092 training [INFO ] Epoch 49 Batch10100 Training err. 1.50698 Training err. RA 1.73115 Valid. err. 1.64752
2018-02-03 21:48:32,552 training [INFO ] Epoch 49 Batch10120 Training err. 1.49403 Training err. RA 1.73068 Valid. err. 1.64815
2018-02-03 21:48:33,012 training [INFO ] Epoch 49 Batch10140 Training err. 1.45530 Training err. RA 1.73014 Valid. err. 1.68248
2018-02-03 21:48:33,472 training [INFO ] Epoch 49 Batch10160 Training err. 1.45299 Training err. RA 1.72959 Valid. err. 1.63989
2018-02-03 21:48:33,932 training [INFO ] Epoch 49 Batch10180 Training err. 1.45861 Training err. RA 1.72906 Valid. err. 1.65309
2018-02-03 21:48:34,768 training [INFO ] Epoch 50 Batch10200 Training err. 1.43983 Training err. RA 1.72849 Valid. err. 1.63111
2018-02-03 21:48:35,228 training [INFO ] Epoch 50 Batch10220 Training err. 1.42485 Training err. RA 1.72790 Valid. err. 1.64219
2018-02-03 21:48:35,689 training [INFO ] Epoch 50 Batch10240 Training err. 1.48653 Training err. RA 1.72743 Valid. err. 1.64269
2018-02-03 21:48:36,151 training [INFO ] Epoch 50 Batch10260 Training err. 1.49693 Training err. RA 1.72698 Valid. err. 1.63347
2018-02-03 21:48:36,612 training [INFO ] Epoch 50 Batch10280 Training err. 1.45425 Training err. RA 1.72645 Valid. err. 1.67145
2018-02-03 21:48:37,072 training [INFO ] Epoch 50 Batch10300 Training err. 1.46232 Training err. RA 1.72594 Valid. err. 1.67462
2018-02-03 21:48:37,531 training [INFO ] Epoch 50 Batch10320 Training err. 1.51934 Training err. RA 1.72554 Valid. err. 1.66014
2018-02-03 21:48:37,992 training [INFO ] Epoch 50 Batch10340 Training err. 1.46541 Training err. RA 1.72503 Valid. err. 1.68550
2018-02-03 21:48:38,452 training [INFO ] Epoch 50 Batch10360 Training err. 1.43121 Training err. RA 1.72447 Valid. err. 1.66089
2018-02-03 21:48:38,913 training [INFO ] Epoch 50 Batch10380 Training err. 1.44409 Training err. RA 1.72392 Valid. err. 1.63837
2018-02-03 21:48:39,373 training [INFO ] Epoch 50 Batch10400 Training err. 1.45433 Training err. RA 1.72341 Valid. err. 1.62653
2018-02-03 21:48:40,204 training [INFO ] Epoch 51 Batch10420 Training err. 1.44540 Training err. RA 1.72287 Valid. err. 1.63256
2018-02-03 21:48:40,666 training [INFO ] Epoch 51 Batch10440 Training err. 1.40737 Training err. RA 1.72227 Valid. err. 1.64902
2018-02-03 21:48:41,125 training [INFO ] Epoch 51 Batch10460 Training err. 1.48831 Training err. RA 1.72182 Valid. err. 1.66586
2018-02-03 21:48:41,587 training [INFO ] Epoch 51 Batch10480 Training err. 1.50563 Training err. RA 1.72141 Valid. err. 1.67054
2018-02-03 21:48:42,047 training [INFO ] Epoch 51 Batch10500 Training err. 1.43301 Training err. RA 1.72086 Valid. err. 1.64399
2018-02-03 21:48:42,521 training [INFO ] Epoch 51 Batch10520 Training err. 1.50789 Training err. RA 1.72045 Valid. err. 1.64649
2018-02-03 21:48:43,017 training [INFO ] Epoch 51 Batch10540 Training err. 1.48491 Training err. RA 1.72001 Valid. err. 1.64377
2018-02-03 21:48:43,513 training [INFO ] Epoch 51 Batch10560 Training err. 1.44394 Training err. RA 1.71948 Valid. err. 1.66403
2018-02-03 21:48:43,980 training [INFO ] Epoch 51 Batch10580 Training err. 1.42751 Training err. RA 1.71893 Valid. err. 1.63292
2018-02-03 21:48:44,441 training [INFO ] Epoch 51 Batch10600 Training err. 1.45985 Training err. RA 1.71844 Valid. err. 1.62944
2018-02-03 21:48:45,325 training [INFO ] Epoch 52 Batch10620 Training err. 1.43422 Training err. RA 1.71791 Valid. err. 1.62076
2018-02-03 21:48:45,814 training [INFO ] Epoch 52 Batch10640 Training err. 1.40762 Training err. RA 1.71733 Valid. err. 1.65104
2018-02-03 21:48:46,294 training [INFO ] Epoch 52 Batch10660 Training err. 1.48231 Training err. RA 1.71688 Valid. err. 1.64299
2018-02-03 21:48:46,753 training [INFO ] Epoch 52 Batch10680 Training err. 1.48756 Training err. RA 1.71645 Valid. err. 1.64686
2018-02-03 21:48:47,230 training [INFO ] Epoch 52 Batch10700 Training err. 1.43312 Training err. RA 1.71593 Valid. err. 1.65577
2018-02-03 21:48:47,729 training [INFO ] Epoch 52 Batch10720 Training err. 1.46864 Training err. RA 1.71546 Valid. err. 1.62796
2018-02-03 21:48:48,203 training [INFO ] Epoch 52 Batch10740 Training err. 1.49839 Training err. RA 1.71506 Valid. err. 1.65605
2018-02-03 21:48:48,663 training [INFO ] Epoch 52 Batch10760 Training err. 1.44437 Training err. RA 1.71456 Valid. err. 1.65874
2018-02-03 21:48:49,127 training [INFO ] Epoch 52 Batch10780 Training err. 1.44653 Training err. RA 1.71406 Valid. err. 1.62934
2018-02-03 21:48:49,591 training [INFO ] Epoch 52 Batch10800 Training err. 1.51698 Training err. RA 1.71369 Valid. err. 1.63784
2018-02-03 21:48:50,451 training [INFO ] Epoch 53 Batch10820 Training err. 1.45792 Training err. RA 1.71322 Valid. err. 1.62266
2018-02-03 21:48:50,980 training [INFO ] Epoch 53 Batch10840 Training err. 1.44221 Training err. RA 1.71272 Valid. err. 1.61567
2018-02-03 21:48:51,448 training [INFO ] Epoch 53 Batch10860 Training err. 1.44797 Training err. RA 1.71223 Valid. err. 1.65142
2018-02-03 21:48:51,915 training [INFO ] Epoch 53 Batch10880 Training err. 1.49010 Training err. RA 1.71183 Valid. err. 1.67892
2018-02-03 21:48:52,380 training [INFO ] Epoch 53 Batch10900 Training err. 1.47357 Training err. RA 1.71139 Valid. err. 1.64559
2018-02-03 21:48:52,842 training [INFO ] Epoch 53 Batch10920 Training err. 1.44620 Training err. RA 1.71090 Valid. err. 1.62307
2018-02-03 21:48:53,308 training [INFO ] Epoch 53 Batch10940 Training err. 1.50715 Training err. RA 1.71053 Valid. err. 1.65309
2018-02-03 21:48:53,768 training [INFO ] Epoch 53 Batch10960 Training err. 1.44352 Training err. RA 1.71004 Valid. err. 1.63277
2018-02-03 21:48:54,256 training [INFO ] Epoch 53 Batch10980 Training err. 1.42752 Training err. RA 1.70953 Valid. err. 1.65098
2018-02-03 21:48:54,743 training [INFO ] Epoch 53 Batch11000 Training err. 1.41891 Training err. RA 1.70900 Valid. err. 1.62744
2018-02-03 21:48:55,203 training [INFO ] Epoch 53 Batch11020 Training err. 1.46651 Training err. RA 1.70856 Valid. err. 1.60759
2018-02-03 21:48:56,069 training [INFO ] Epoch 54 Batch11040 Training err. 1.41674 Training err. RA 1.70803 Valid. err. 1.61939
2018-02-03 21:48:56,563 training [INFO ] Epoch 54 Batch11060 Training err. 1.40554 Training err. RA 1.70748 Valid. err. 1.62437
2018-02-03 21:48:57,054 training [INFO ] Epoch 54 Batch11080 Training err. 1.46679 Training err. RA 1.70705 Valid. err. 1.66056
2018-02-03 21:48:57,542 training [INFO ] Epoch 54 Batch11100 Training err. 1.48837 Training err. RA 1.70666 Valid. err. 1.64144
2018-02-03 21:48:58,030 training [INFO ] Epoch 54 Batch11120 Training err. 1.43010 Training err. RA 1.70616 Valid. err. 1.66277
2018-02-03 21:48:58,521 training [INFO ] Epoch 54 Batch11140 Training err. 1.48796 Training err. RA 1.70577 Valid. err. 1.63844
2018-02-03 21:48:59,026 training [INFO ] Epoch 54 Batch11160 Training err. 1.46922 Training err. RA 1.70534 Valid. err. 1.64054
2018-02-03 21:48:59,512 training [INFO ] Epoch 54 Batch11180 Training err. 1.43648 Training err. RA 1.70486 Valid. err. 1.66000
2018-02-03 21:49:00,000 training [INFO ] Epoch 54 Batch11200 Training err. 1.46643 Training err. RA 1.70444 Valid. err. 1.63343
2018-02-03 21:49:00,502 training [INFO ] Epoch 54 Batch11220 Training err. 1.44881 Training err. RA 1.70398 Valid. err. 1.62443
2018-02-03 21:49:01,376 training [INFO ] Epoch 55 Batch11240 Training err. 1.42085 Training err. RA 1.70348 Valid. err. 1.61116
2018-02-03 21:49:01,869 training [INFO ] Epoch 55 Batch11260 Training err. 1.40604 Training err. RA 1.70295 Valid. err. 1.62902
2018-02-03 21:49:02,359 training [INFO ] Epoch 55 Batch11280 Training err. 1.46750 Training err. RA 1.70253 Valid. err. 1.63266
2018-02-03 21:49:02,842 training [INFO ] Epoch 55 Batch11300 Training err. 1.47675 Training err. RA 1.70213 Valid. err. 1.61455
2018-02-03 21:49:03,353 training [INFO ] Epoch 55 Batch11320 Training err. 1.43748 Training err. RA 1.70166 Valid. err. 1.66682
2018-02-03 21:49:03,842 training [INFO ] Epoch 55 Batch11340 Training err. 1.45080 Training err. RA 1.70122 Valid. err. 1.63649
2018-02-03 21:49:04,340 training [INFO ] Epoch 55 Batch11360 Training err. 1.51809 Training err. RA 1.70090 Valid. err. 1.63080
2018-02-03 21:49:04,846 training [INFO ] Epoch 55 Batch11380 Training err. 1.45658 Training err. RA 1.70047 Valid. err. 1.65166
2018-02-03 21:49:05,330 training [INFO ] Epoch 55 Batch11400 Training err. 1.41342 Training err. RA 1.69997 Valid. err. 1.65815
2018-02-03 21:49:05,802 training [INFO ] Epoch 55 Batch11420 Training err. 1.42463 Training err. RA 1.69948 Valid. err. 1.62360
2018-02-03 21:49:06,297 training [INFO ] Epoch 55 Batch11440 Training err. 1.44097 Training err. RA 1.69903 Valid. err. 1.61557
2018-02-03 21:49:07,182 training [INFO ] Epoch 56 Batch11460 Training err. 1.43196 Training err. RA 1.69857 Valid. err. 1.61665
2018-02-03 21:49:07,649 training [INFO ] Epoch 56 Batch11480 Training err. 1.39494 Training err. RA 1.69804 Valid. err. 1.63012
2018-02-03 21:49:08,131 training [INFO ] Epoch 56 Batch11500 Training err. 1.46319 Training err. RA 1.69763 Valid. err. 1.64693
2018-02-03 21:49:08,604 training [INFO ] Epoch 56 Batch11520 Training err. 1.47767 Training err. RA 1.69725 Valid. err. 1.68111
2018-02-03 21:49:09,064 training [INFO ] Epoch 56 Batch11540 Training err. 1.42755 Training err. RA 1.69678 Valid. err. 1.64073
2018-02-03 21:49:09,525 training [INFO ] Epoch 56 Batch11560 Training err. 1.47802 Training err. RA 1.69640 Valid. err. 1.63263
2018-02-03 21:49:09,985 training [INFO ] Epoch 56 Batch11580 Training err. 1.45650 Training err. RA 1.69599 Valid. err. 1.61809
2018-02-03 21:49:10,478 training [INFO ] Epoch 56 Batch11600 Training err. 1.42349 Training err. RA 1.69552 Valid. err. 1.64532
2018-02-03 21:49:10,939 training [INFO ] Epoch 56 Batch11620 Training err. 1.40918 Training err. RA 1.69502 Valid. err. 1.62495
2018-02-03 21:49:11,422 training [INFO ] Epoch 56 Batch11640 Training err. 1.44479 Training err. RA 1.69459 Valid. err. 1.60755
2018-02-03 21:49:12,271 training [INFO ] Epoch 57 Batch11660 Training err. 1.41995 Training err. RA 1.69412 Valid. err. 1.61271
2018-02-03 21:49:12,732 training [INFO ] Epoch 57 Batch11680 Training err. 1.39389 Training err. RA 1.69361 Valid. err. 1.64777
2018-02-03 21:49:13,197 training [INFO ] Epoch 57 Batch11700 Training err. 1.46615 Training err. RA 1.69322 Valid. err. 1.64834
2018-02-03 21:49:13,697 training [INFO ] Epoch 57 Batch11720 Training err. 1.47471 Training err. RA 1.69285 Valid. err. 1.64740
2018-02-03 21:49:14,157 training [INFO ] Epoch 57 Batch11740 Training err. 1.41467 Training err. RA 1.69237 Valid. err. 1.63749
2018-02-03 21:49:14,616 training [INFO ] Epoch 57 Batch11760 Training err. 1.44826 Training err. RA 1.69196 Valid. err. 1.61678
2018-02-03 21:49:15,077 training [INFO ] Epoch 57 Batch11780 Training err. 1.48208 Training err. RA 1.69160 Valid. err. 1.65499
2018-02-03 21:49:15,566 training [INFO ] Epoch 57 Batch11800 Training err. 1.42236 Training err. RA 1.69114 Valid. err. 1.65332
2018-02-03 21:49:16,070 training [INFO ] Epoch 57 Batch11820 Training err. 1.44307 Training err. RA 1.69073 Valid. err. 1.62837
2018-02-03 21:49:16,581 training [INFO ] Epoch 57 Batch11840 Training err. 1.42893 Training err. RA 1.69028 Valid. err. 1.66982
2018-02-03 21:49:17,479 training [INFO ] Epoch 58 Batch11860 Training err. 1.43725 Training err. RA 1.68986 Valid. err. 1.61353
2018-02-03 21:49:17,943 training [INFO ] Epoch 58 Batch11880 Training err. 1.41305 Training err. RA 1.68939 Valid. err. 1.62420
2018-02-03 21:49:18,423 training [INFO ] Epoch 58 Batch11900 Training err. 1.42292 Training err. RA 1.68894 Valid. err. 1.62199
2018-02-03 21:49:18,909 training [INFO ] Epoch 58 Batch11920 Training err. 1.45334 Training err. RA 1.68855 Valid. err. 1.64178
2018-02-03 21:49:19,386 training [INFO ] Epoch 58 Batch11940 Training err. 1.44718 Training err. RA 1.68814 Valid. err. 1.64789
2018-02-03 21:49:19,856 training [INFO ] Epoch 58 Batch11960 Training err. 1.42749 Training err. RA 1.68771 Valid. err. 1.62172
2018-02-03 21:49:20,343 training [INFO ] Epoch 58 Batch11980 Training err. 1.47993 Training err. RA 1.68736 Valid. err. 1.64885
2018-02-03 21:49:20,805 training [INFO ] Epoch 58 Batch12000 Training err. 1.42424 Training err. RA 1.68692 Valid. err. 1.63257
2018-02-03 21:49:21,268 training [INFO ] Epoch 58 Batch12020 Training err. 1.40947 Training err. RA 1.68646 Valid. err. 1.64070
2018-02-03 21:49:21,729 training [INFO ] Epoch 58 Batch12040 Training err. 1.39828 Training err. RA 1.68598 Valid. err. 1.61536
2018-02-03 21:49:22,190 training [INFO ] Epoch 58 Batch12060 Training err. 1.44576 Training err. RA 1.68558 Valid. err. 1.59830
2018-02-03 21:49:23,039 training [INFO ] Epoch 59 Batch12080 Training err. 1.40193 Training err. RA 1.68511 Valid. err. 1.61096
2018-02-03 21:49:23,501 training [INFO ] Epoch 59 Batch12100 Training err. 1.39241 Training err. RA 1.68463 Valid. err. 1.63358
2018-02-03 21:49:23,973 training [INFO ] Epoch 59 Batch12120 Training err. 1.45155 Training err. RA 1.68424 Valid. err. 1.65836
2018-02-03 21:49:24,443 training [INFO ] Epoch 59 Batch12140 Training err. 1.47567 Training err. RA 1.68390 Valid. err. 1.63991
2018-02-03 21:49:24,915 training [INFO ] Epoch 59 Batch12160 Training err. 1.41122 Training err. RA 1.68345 Valid. err. 1.68193
2018-02-03 21:49:25,422 training [INFO ] Epoch 59 Batch12180 Training err. 1.47912 Training err. RA 1.68312 Valid. err. 1.62928
2018-02-03 21:49:25,920 training [INFO ] Epoch 59 Batch12200 Training err. 1.45340 Training err. RA 1.68274 Valid. err. 1.63122
2018-02-03 21:49:26,396 training [INFO ] Epoch 59 Batch12220 Training err. 1.40591 Training err. RA 1.68229 Valid. err. 1.65002
2018-02-03 21:49:26,857 training [INFO ] Epoch 59 Batch12240 Training err. 1.41354 Training err. RA 1.68185 Valid. err. 1.61585
2018-02-03 21:49:27,340 training [INFO ] Epoch 59 Batch12260 Training err. 1.42162 Training err. RA 1.68142 Valid. err. 1.62837
2018-02-03 21:49:28,224 training [INFO ] Epoch 60 Batch12280 Training err. 1.42571 Training err. RA 1.68101 Valid. err. 1.60041
2018-02-03 21:49:28,720 training [INFO ] Epoch 60 Batch12300 Training err. 1.39348 Training err. RA 1.68054 Valid. err. 1.65400
2018-02-03 21:49:29,202 training [INFO ] Epoch 60 Batch12320 Training err. 1.44420 Training err. RA 1.68016 Valid. err. 1.61201
2018-02-03 21:49:29,668 training [INFO ] Epoch 60 Batch12340 Training err. 1.45945 Training err. RA 1.67980 Valid. err. 1.61903
2018-02-03 21:49:30,144 training [INFO ] Epoch 60 Batch12360 Training err. 1.41287 Training err. RA 1.67937 Valid. err. 1.62852
2018-02-03 21:49:30,607 training [INFO ] Epoch 60 Batch12380 Training err. 1.43567 Training err. RA 1.67897 Valid. err. 1.62584
2018-02-03 21:49:31,071 training [INFO ] Epoch 60 Batch12400 Training err. 1.47558 Training err. RA 1.67864 Valid. err. 1.62811
2018-02-03 21:49:31,537 training [INFO ] Epoch 60 Batch12420 Training err. 1.42720 Training err. RA 1.67824 Valid. err. 1.65542
2018-02-03 21:49:32,008 training [INFO ] Epoch 60 Batch12440 Training err. 1.39207 Training err. RA 1.67778 Valid. err. 1.63903
2018-02-03 21:49:32,486 training [INFO ] Epoch 60 Batch12460 Training err. 1.39982 Training err. RA 1.67733 Valid. err. 1.61909
2018-02-03 21:49:32,960 training [INFO ] Epoch 60 Batch12480 Training err. 1.42668 Training err. RA 1.67693 Valid. err. 1.60669
2018-02-03 21:49:33,226 __main__ [INFO ] End of training
2018-02-03 21:49:33,464 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 10,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:49:33,465 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 21:49:34,066 training [INFO ] Epoch  1 Batch   20 Training err. 4.24151 Training err. RA 4.24151 Valid. err. 4.16857
2018-02-03 21:49:34,562 training [INFO ] Epoch  1 Batch   40 Training err. 4.07570 Training err. RA 4.15861 Valid. err. 4.01682
2018-02-03 21:49:35,067 training [INFO ] Epoch  1 Batch   60 Training err. 3.92384 Training err. RA 4.08035 Valid. err. 3.85700
2018-02-03 21:49:35,551 training [INFO ] Epoch  1 Batch   80 Training err. 3.77625 Training err. RA 4.00433 Valid. err. 3.70086
2018-02-03 21:49:36,038 training [INFO ] Epoch  1 Batch  100 Training err. 3.61321 Training err. RA 3.92610 Valid. err. 3.56961
2018-02-03 21:49:36,868 training [INFO ] Epoch  2 Batch  120 Training err. 3.48513 Training err. RA 3.85261 Valid. err. 3.46413
2018-02-03 21:49:37,356 training [INFO ] Epoch  2 Batch  140 Training err. 3.35223 Training err. RA 3.78112 Valid. err. 3.38368
2018-02-03 21:49:37,858 training [INFO ] Epoch  2 Batch  160 Training err. 3.31376 Training err. RA 3.72270 Valid. err. 3.31855
2018-02-03 21:49:38,368 training [INFO ] Epoch  2 Batch  180 Training err. 3.26718 Training err. RA 3.67209 Valid. err. 3.28047
2018-02-03 21:49:38,881 training [INFO ] Epoch  2 Batch  200 Training err. 3.23559 Training err. RA 3.62844 Valid. err. 3.25646
2018-02-03 21:49:39,715 training [INFO ] Epoch  3 Batch  220 Training err. 3.22615 Training err. RA 3.59187 Valid. err. 3.24062
2018-02-03 21:49:40,196 training [INFO ] Epoch  3 Batch  240 Training err. 3.15460 Training err. RA 3.55543 Valid. err. 3.23669
2018-02-03 21:49:40,677 training [INFO ] Epoch  3 Batch  260 Training err. 3.18947 Training err. RA 3.52728 Valid. err. 3.21821
2018-02-03 21:49:41,223 training [INFO ] Epoch  3 Batch  280 Training err. 3.16403 Training err. RA 3.50133 Valid. err. 3.21077
2018-02-03 21:49:41,720 training [INFO ] Epoch  3 Batch  300 Training err. 3.16789 Training err. RA 3.47910 Valid. err. 3.20573
2018-02-03 21:49:42,588 training [INFO ] Epoch  4 Batch  320 Training err. 3.18312 Training err. RA 3.46060 Valid. err. 3.20006
2018-02-03 21:49:43,091 training [INFO ] Epoch  4 Batch  340 Training err. 3.13096 Training err. RA 3.44121 Valid. err. 3.20283
2018-02-03 21:49:43,671 training [INFO ] Epoch  4 Batch  360 Training err. 3.15145 Training err. RA 3.42512 Valid. err. 3.19408
2018-02-03 21:49:44,176 training [INFO ] Epoch  4 Batch  380 Training err. 3.13492 Training err. RA 3.40984 Valid. err. 3.19133
2018-02-03 21:49:44,675 training [INFO ] Epoch  4 Batch  400 Training err. 3.14363 Training err. RA 3.39653 Valid. err. 3.19016
2018-02-03 21:49:45,498 training [INFO ] Epoch  5 Batch  420 Training err. 3.16916 Training err. RA 3.38570 Valid. err. 3.18941
2018-02-03 21:49:45,977 training [INFO ] Epoch  5 Batch  440 Training err. 3.13738 Training err. RA 3.37442 Valid. err. 3.18938
2018-02-03 21:49:46,456 training [INFO ] Epoch  5 Batch  460 Training err. 3.12894 Training err. RA 3.36374 Valid. err. 3.18500
2018-02-03 21:49:46,935 training [INFO ] Epoch  5 Batch  480 Training err. 3.11089 Training err. RA 3.35321 Valid. err. 3.18438
2018-02-03 21:49:47,436 training [INFO ] Epoch  5 Batch  500 Training err. 3.14414 Training err. RA 3.34485 Valid. err. 3.18424
2018-02-03 21:49:47,925 training [INFO ] Epoch  5 Batch  520 Training err. 3.16339 Training err. RA 3.33787 Valid. err. 3.18142
2018-02-03 21:49:48,756 training [INFO ] Epoch  6 Batch  540 Training err. 3.13903 Training err. RA 3.33050 Valid. err. 3.18198
2018-02-03 21:49:49,244 training [INFO ] Epoch  6 Batch  560 Training err. 3.11386 Training err. RA 3.32276 Valid. err. 3.18193
2018-02-03 21:49:49,730 training [INFO ] Epoch  6 Batch  580 Training err. 3.09968 Training err. RA 3.31507 Valid. err. 3.18257
2018-02-03 21:49:50,219 training [INFO ] Epoch  6 Batch  600 Training err. 3.14843 Training err. RA 3.30952 Valid. err. 3.17975
2018-02-03 21:49:50,708 training [INFO ] Epoch  6 Batch  620 Training err. 3.14655 Training err. RA 3.30426 Valid. err. 3.17850
2018-02-03 21:49:51,542 training [INFO ] Epoch  7 Batch  640 Training err. 3.14874 Training err. RA 3.29940 Valid. err. 3.17866
2018-02-03 21:49:52,031 training [INFO ] Epoch  7 Batch  660 Training err. 3.10093 Training err. RA 3.29339 Valid. err. 3.17988
2018-02-03 21:49:52,517 training [INFO ] Epoch  7 Batch  680 Training err. 3.11558 Training err. RA 3.28816 Valid. err. 3.17848
2018-02-03 21:49:53,019 training [INFO ] Epoch  7 Batch  700 Training err. 3.13240 Training err. RA 3.28371 Valid. err. 3.17732
2018-02-03 21:49:53,522 training [INFO ] Epoch  7 Batch  720 Training err. 3.13492 Training err. RA 3.27957 Valid. err. 3.17677
2018-02-03 21:49:54,383 training [INFO ] Epoch  8 Batch  740 Training err. 3.15492 Training err. RA 3.27620 Valid. err. 3.17684
2018-02-03 21:49:54,887 training [INFO ] Epoch  8 Batch  760 Training err. 3.09017 Training err. RA 3.27131 Valid. err. 3.18703
2018-02-03 21:49:55,391 training [INFO ] Epoch  8 Batch  780 Training err. 3.13137 Training err. RA 3.26772 Valid. err. 3.17575
2018-02-03 21:49:55,896 training [INFO ] Epoch  8 Batch  800 Training err. 3.11806 Training err. RA 3.26398 Valid. err. 3.17517
2018-02-03 21:49:56,400 training [INFO ] Epoch  8 Batch  820 Training err. 3.13017 Training err. RA 3.26072 Valid. err. 3.17572
2018-02-03 21:49:57,252 training [INFO ] Epoch  9 Batch  840 Training err. 3.15280 Training err. RA 3.25815 Valid. err. 3.17307
2018-02-03 21:49:57,741 training [INFO ] Epoch  9 Batch  860 Training err. 3.10277 Training err. RA 3.25453 Valid. err. 3.18054
2018-02-03 21:49:58,232 training [INFO ] Epoch  9 Batch  880 Training err. 3.12387 Training err. RA 3.25156 Valid. err. 3.17329
2018-02-03 21:49:58,720 training [INFO ] Epoch  9 Batch  900 Training err. 3.10945 Training err. RA 3.24841 Valid. err. 3.17271
2018-02-03 21:49:59,200 training [INFO ] Epoch  9 Batch  920 Training err. 3.12270 Training err. RA 3.24567 Valid. err. 3.17300
2018-02-03 21:50:00,032 training [INFO ] Epoch 10 Batch  940 Training err. 3.15039 Training err. RA 3.24364 Valid. err. 3.17345
2018-02-03 21:50:00,518 training [INFO ] Epoch 10 Batch  960 Training err. 3.11897 Training err. RA 3.24105 Valid. err. 3.17499
2018-02-03 21:50:01,011 training [INFO ] Epoch 10 Batch  980 Training err. 3.11090 Training err. RA 3.23839 Valid. err. 3.17046
2018-02-03 21:50:01,510 training [INFO ] Epoch 10 Batch 1000 Training err. 3.09317 Training err. RA 3.23549 Valid. err. 3.17043
2018-02-03 21:50:02,009 training [INFO ] Epoch 10 Batch 1020 Training err. 3.12758 Training err. RA 3.23337 Valid. err. 3.17089
2018-02-03 21:50:02,506 training [INFO ] Epoch 10 Batch 1040 Training err. 3.14711 Training err. RA 3.23171 Valid. err. 3.16812
2018-02-03 21:50:03,364 training [INFO ] Epoch 11 Batch 1060 Training err. 3.12462 Training err. RA 3.22969 Valid. err. 3.16883
2018-02-03 21:50:03,862 training [INFO ] Epoch 11 Batch 1080 Training err. 3.09895 Training err. RA 3.22727 Valid. err. 3.16889
2018-02-03 21:50:04,363 training [INFO ] Epoch 11 Batch 1100 Training err. 3.08410 Training err. RA 3.22467 Valid. err. 3.16971
2018-02-03 21:50:04,860 training [INFO ] Epoch 11 Batch 1120 Training err. 3.13282 Training err. RA 3.22303 Valid. err. 3.16668
2018-02-03 21:50:05,360 training [INFO ] Epoch 11 Batch 1140 Training err. 3.13163 Training err. RA 3.22142 Valid. err. 3.16525
2018-02-03 21:50:06,211 training [INFO ] Epoch 12 Batch 1160 Training err. 3.13455 Training err. RA 3.21993 Valid. err. 3.16518
2018-02-03 21:50:06,745 training [INFO ] Epoch 12 Batch 1180 Training err. 3.08672 Training err. RA 3.21767 Valid. err. 3.16606
2018-02-03 21:50:07,268 training [INFO ] Epoch 12 Batch 1200 Training err. 3.09952 Training err. RA 3.21570 Valid. err. 3.16467
2018-02-03 21:50:07,763 training [INFO ] Epoch 12 Batch 1220 Training err. 3.11749 Training err. RA 3.21409 Valid. err. 3.16315
2018-02-03 21:50:08,263 training [INFO ] Epoch 12 Batch 1240 Training err. 3.11936 Training err. RA 3.21256 Valid. err. 3.16211
2018-02-03 21:50:09,141 training [INFO ] Epoch 13 Batch 1260 Training err. 3.13963 Training err. RA 3.21140 Valid. err. 3.16218
2018-02-03 21:50:09,639 training [INFO ] Epoch 13 Batch 1280 Training err. 3.07543 Training err. RA 3.20928 Valid. err. 3.17213
2018-02-03 21:50:10,148 training [INFO ] Epoch 13 Batch 1300 Training err. 3.11401 Training err. RA 3.20781 Valid. err. 3.16008
2018-02-03 21:50:10,674 training [INFO ] Epoch 13 Batch 1320 Training err. 3.10190 Training err. RA 3.20621 Valid. err. 3.15897
2018-02-03 21:50:11,193 training [INFO ] Epoch 13 Batch 1340 Training err. 3.11261 Training err. RA 3.20481 Valid. err. 3.15903
2018-02-03 21:50:12,057 training [INFO ] Epoch 14 Batch 1360 Training err. 3.13546 Training err. RA 3.20379 Valid. err. 3.15567
2018-02-03 21:50:12,553 training [INFO ] Epoch 14 Batch 1380 Training err. 3.08597 Training err. RA 3.20208 Valid. err. 3.16303
2018-02-03 21:50:13,036 training [INFO ] Epoch 14 Batch 1400 Training err. 3.10568 Training err. RA 3.20071 Valid. err. 3.15488
2018-02-03 21:50:13,518 training [INFO ] Epoch 14 Batch 1420 Training err. 3.09043 Training err. RA 3.19915 Valid. err. 3.15364
2018-02-03 21:50:14,015 training [INFO ] Epoch 14 Batch 1440 Training err. 3.10278 Training err. RA 3.19782 Valid. err. 3.15302
2018-02-03 21:50:14,846 training [INFO ] Epoch 15 Batch 1460 Training err. 3.13053 Training err. RA 3.19689 Valid. err. 3.15310
2018-02-03 21:50:15,329 training [INFO ] Epoch 15 Batch 1480 Training err. 3.09817 Training err. RA 3.19556 Valid. err. 3.15452
2018-02-03 21:50:15,810 training [INFO ] Epoch 15 Batch 1500 Training err. 3.09095 Training err. RA 3.19416 Valid. err. 3.14818
2018-02-03 21:50:16,292 training [INFO ] Epoch 15 Batch 1520 Training err. 3.07061 Training err. RA 3.19254 Valid. err. 3.14704
2018-02-03 21:50:16,773 training [INFO ] Epoch 15 Batch 1540 Training err. 3.10392 Training err. RA 3.19139 Valid. err. 3.14672
2018-02-03 21:50:17,272 training [INFO ] Epoch 15 Batch 1560 Training err. 3.12258 Training err. RA 3.19051 Valid. err. 3.14270
2018-02-03 21:50:18,158 training [INFO ] Epoch 16 Batch 1580 Training err. 3.09965 Training err. RA 3.18936 Valid. err. 3.14213
2018-02-03 21:50:18,654 training [INFO ] Epoch 16 Batch 1600 Training err. 3.07534 Training err. RA 3.18793 Valid. err. 3.14135
2018-02-03 21:50:19,153 training [INFO ] Epoch 16 Batch 1620 Training err. 3.05639 Training err. RA 3.18631 Valid. err. 3.14104
2018-02-03 21:50:19,676 training [INFO ] Epoch 16 Batch 1640 Training err. 3.10328 Training err. RA 3.18529 Valid. err. 3.13611
2018-02-03 21:50:20,174 training [INFO ] Epoch 16 Batch 1660 Training err. 3.10149 Training err. RA 3.18428 Valid. err. 3.13307
2018-02-03 21:50:21,023 training [INFO ] Epoch 17 Batch 1680 Training err. 3.10362 Training err. RA 3.18332 Valid. err. 3.13137
2018-02-03 21:50:21,503 training [INFO ] Epoch 17 Batch 1700 Training err. 3.05679 Training err. RA 3.18184 Valid. err. 3.13079
2018-02-03 21:50:21,983 training [INFO ] Epoch 17 Batch 1720 Training err. 3.06374 Training err. RA 3.18046 Valid. err. 3.12780
2018-02-03 21:50:22,470 training [INFO ] Epoch 17 Batch 1740 Training err. 3.08153 Training err. RA 3.17933 Valid. err. 3.12382
2018-02-03 21:50:22,960 training [INFO ] Epoch 17 Batch 1760 Training err. 3.08052 Training err. RA 3.17820 Valid. err. 3.12019
2018-02-03 21:50:23,854 training [INFO ] Epoch 18 Batch 1780 Training err. 3.09989 Training err. RA 3.17732 Valid. err. 3.12053
2018-02-03 21:50:24,342 training [INFO ] Epoch 18 Batch 1800 Training err. 3.03650 Training err. RA 3.17576 Valid. err. 3.12594
2018-02-03 21:50:24,852 training [INFO ] Epoch 18 Batch 1820 Training err. 3.06759 Training err. RA 3.17457 Valid. err. 3.11148
2018-02-03 21:50:25,376 training [INFO ] Epoch 18 Batch 1840 Training err. 3.05510 Training err. RA 3.17327 Valid. err. 3.10705
2018-02-03 21:50:25,883 training [INFO ] Epoch 18 Batch 1860 Training err. 3.06061 Training err. RA 3.17206 Valid. err. 3.10472
2018-02-03 21:50:26,773 training [INFO ] Epoch 19 Batch 1880 Training err. 3.08290 Training err. RA 3.17111 Valid. err. 3.09752
2018-02-03 21:50:27,300 training [INFO ] Epoch 19 Batch 1900 Training err. 3.03220 Training err. RA 3.16965 Valid. err. 3.10256
2018-02-03 21:50:27,826 training [INFO ] Epoch 19 Batch 1920 Training err. 3.04839 Training err. RA 3.16839 Valid. err. 3.09093
2018-02-03 21:50:28,329 training [INFO ] Epoch 19 Batch 1940 Training err. 3.02732 Training err. RA 3.16693 Valid. err. 3.08551
2018-02-03 21:50:28,850 training [INFO ] Epoch 19 Batch 1960 Training err. 3.03472 Training err. RA 3.16558 Valid. err. 3.08018
2018-02-03 21:50:29,706 training [INFO ] Epoch 20 Batch 1980 Training err. 3.06161 Training err. RA 3.16453 Valid. err. 3.07854
2018-02-03 21:50:30,200 training [INFO ] Epoch 20 Batch 2000 Training err. 3.02383 Training err. RA 3.16312 Valid. err. 3.07801
2018-02-03 21:50:30,719 training [INFO ] Epoch 20 Batch 2020 Training err. 3.01888 Training err. RA 3.16170 Valid. err. 3.06331
2018-02-03 21:50:31,212 training [INFO ] Epoch 20 Batch 2040 Training err. 2.98765 Training err. RA 3.15999 Valid. err. 3.05737
2018-02-03 21:50:31,700 training [INFO ] Epoch 20 Batch 2060 Training err. 3.01623 Training err. RA 3.15859 Valid. err. 3.05236
2018-02-03 21:50:32,216 training [INFO ] Epoch 20 Batch 2080 Training err. 3.03188 Training err. RA 3.15738 Valid. err. 3.04484
2018-02-03 21:50:33,092 training [INFO ] Epoch 21 Batch 2100 Training err. 3.00559 Training err. RA 3.15593 Valid. err. 3.03774
2018-02-03 21:50:33,606 training [INFO ] Epoch 21 Batch 2120 Training err. 2.98358 Training err. RA 3.15430 Valid. err. 3.03405
2018-02-03 21:50:34,133 training [INFO ] Epoch 21 Batch 2140 Training err. 2.95219 Training err. RA 3.15242 Valid. err. 3.02749
2018-02-03 21:50:34,641 training [INFO ] Epoch 21 Batch 2160 Training err. 2.99212 Training err. RA 3.15093 Valid. err. 3.01753
2018-02-03 21:50:35,144 training [INFO ] Epoch 21 Batch 2180 Training err. 2.98816 Training err. RA 3.14944 Valid. err. 3.00882
2018-02-03 21:50:36,028 training [INFO ] Epoch 22 Batch 2200 Training err. 2.98863 Training err. RA 3.14798 Valid. err. 3.00497
2018-02-03 21:50:36,564 training [INFO ] Epoch 22 Batch 2220 Training err. 2.94118 Training err. RA 3.14611 Valid. err. 2.99935
2018-02-03 21:50:37,072 training [INFO ] Epoch 22 Batch 2240 Training err. 2.93542 Training err. RA 3.14423 Valid. err. 2.98953
2018-02-03 21:50:37,587 training [INFO ] Epoch 22 Batch 2260 Training err. 2.95349 Training err. RA 3.14254 Valid. err. 2.98034
2018-02-03 21:50:38,096 training [INFO ] Epoch 22 Batch 2280 Training err. 2.94234 Training err. RA 3.14079 Valid. err. 2.97249
2018-02-03 21:50:38,995 training [INFO ] Epoch 23 Batch 2300 Training err. 2.96276 Training err. RA 3.13924 Valid. err. 2.98255
2018-02-03 21:50:39,526 training [INFO ] Epoch 23 Batch 2320 Training err. 2.89810 Training err. RA 3.13716 Valid. err. 2.97190
2018-02-03 21:50:40,023 training [INFO ] Epoch 23 Batch 2340 Training err. 2.91819 Training err. RA 3.13529 Valid. err. 2.95042
2018-02-03 21:50:40,528 training [INFO ] Epoch 23 Batch 2360 Training err. 2.91111 Training err. RA 3.13339 Valid. err. 2.94497
2018-02-03 21:50:41,048 training [INFO ] Epoch 23 Batch 2380 Training err. 2.90047 Training err. RA 3.13143 Valid. err. 2.93720
2018-02-03 21:50:41,947 training [INFO ] Epoch 24 Batch 2400 Training err. 2.92601 Training err. RA 3.12972 Valid. err. 2.92802
2018-02-03 21:50:42,448 training [INFO ] Epoch 24 Batch 2420 Training err. 2.87533 Training err. RA 3.12762 Valid. err. 2.95395
2018-02-03 21:50:42,945 training [INFO ] Epoch 24 Batch 2440 Training err. 2.88771 Training err. RA 3.12565 Valid. err. 2.91490
2018-02-03 21:50:43,452 training [INFO ] Epoch 24 Batch 2460 Training err. 2.86793 Training err. RA 3.12356 Valid. err. 2.90841
2018-02-03 21:50:43,949 training [INFO ] Epoch 24 Batch 2480 Training err. 2.86180 Training err. RA 3.12145 Valid. err. 2.89917
2018-02-03 21:50:44,804 training [INFO ] Epoch 25 Batch 2500 Training err. 2.88832 Training err. RA 3.11958 Valid. err. 2.92353
2018-02-03 21:50:45,293 training [INFO ] Epoch 25 Batch 2520 Training err. 2.85717 Training err. RA 3.11750 Valid. err. 2.89337
2018-02-03 21:50:45,807 training [INFO ] Epoch 25 Batch 2540 Training err. 2.84929 Training err. RA 3.11539 Valid. err. 2.87914
2018-02-03 21:50:46,328 training [INFO ] Epoch 25 Batch 2560 Training err. 2.81560 Training err. RA 3.11304 Valid. err. 2.88677
2018-02-03 21:50:46,849 training [INFO ] Epoch 25 Batch 2580 Training err. 2.83705 Training err. RA 3.11090 Valid. err. 2.87242
2018-02-03 21:50:47,355 training [INFO ] Epoch 25 Batch 2600 Training err. 2.85209 Training err. RA 3.10891 Valid. err. 2.87787
2018-02-03 21:50:48,239 training [INFO ] Epoch 26 Batch 2620 Training err. 2.83829 Training err. RA 3.10685 Valid. err. 2.85383
2018-02-03 21:50:48,742 training [INFO ] Epoch 26 Batch 2640 Training err. 2.80560 Training err. RA 3.10457 Valid. err. 2.85912
2018-02-03 21:50:49,260 training [INFO ] Epoch 26 Batch 2660 Training err. 2.77394 Training err. RA 3.10208 Valid. err. 2.87470
2018-02-03 21:50:49,794 training [INFO ] Epoch 26 Batch 2680 Training err. 2.81683 Training err. RA 3.09995 Valid. err. 2.83412
2018-02-03 21:50:50,324 training [INFO ] Epoch 26 Batch 2700 Training err. 2.80610 Training err. RA 3.09777 Valid. err. 2.82602
2018-02-03 21:50:51,212 training [INFO ] Epoch 27 Batch 2720 Training err. 2.82154 Training err. RA 3.09574 Valid. err. 2.82825
2018-02-03 21:50:51,724 training [INFO ] Epoch 27 Batch 2740 Training err. 2.76824 Training err. RA 3.09335 Valid. err. 2.82685
2018-02-03 21:50:52,260 training [INFO ] Epoch 27 Batch 2760 Training err. 2.77303 Training err. RA 3.09103 Valid. err. 2.81678
2018-02-03 21:50:52,801 training [INFO ] Epoch 27 Batch 2780 Training err. 2.77872 Training err. RA 3.08878 Valid. err. 2.80792
2018-02-03 21:50:53,289 training [INFO ] Epoch 27 Batch 2800 Training err. 2.76238 Training err. RA 3.08645 Valid. err. 2.79957
2018-02-03 21:50:54,137 training [INFO ] Epoch 28 Batch 2820 Training err. 2.79836 Training err. RA 3.08441 Valid. err. 2.80437
2018-02-03 21:50:54,626 training [INFO ] Epoch 28 Batch 2840 Training err. 2.71721 Training err. RA 3.08182 Valid. err. 2.81479
2018-02-03 21:50:55,122 training [INFO ] Epoch 28 Batch 2860 Training err. 2.76031 Training err. RA 3.07958 Valid. err. 2.78370
2018-02-03 21:50:55,650 training [INFO ] Epoch 28 Batch 2880 Training err. 2.73575 Training err. RA 3.07719 Valid. err. 2.77779
2018-02-03 21:50:56,165 training [INFO ] Epoch 28 Batch 2900 Training err. 2.73363 Training err. RA 3.07482 Valid. err. 2.77409
2018-02-03 21:50:57,060 training [INFO ] Epoch 29 Batch 2920 Training err. 2.77043 Training err. RA 3.07273 Valid. err. 2.77456
2018-02-03 21:50:57,576 training [INFO ] Epoch 29 Batch 2940 Training err. 2.71081 Training err. RA 3.07027 Valid. err. 2.81388
2018-02-03 21:50:58,084 training [INFO ] Epoch 29 Batch 2960 Training err. 2.74305 Training err. RA 3.06806 Valid. err. 2.76342
2018-02-03 21:50:58,581 training [INFO ] Epoch 29 Batch 2980 Training err. 2.70525 Training err. RA 3.06563 Valid. err. 2.75642
2018-02-03 21:50:59,082 training [INFO ] Epoch 29 Batch 3000 Training err. 2.70249 Training err. RA 3.06320 Valid. err. 2.74761
2018-02-03 21:50:59,941 training [INFO ] Epoch 30 Batch 3020 Training err. 2.73434 Training err. RA 3.06103 Valid. err. 2.78059
2018-02-03 21:51:00,451 training [INFO ] Epoch 30 Batch 3040 Training err. 2.71120 Training err. RA 3.05873 Valid. err. 2.74121
2018-02-03 21:51:00,939 training [INFO ] Epoch 30 Batch 3060 Training err. 2.69625 Training err. RA 3.05636 Valid. err. 2.74719
2018-02-03 21:51:01,423 training [INFO ] Epoch 30 Batch 3080 Training err. 2.66482 Training err. RA 3.05381 Valid. err. 2.73333
2018-02-03 21:51:01,906 training [INFO ] Epoch 30 Batch 3100 Training err. 2.68997 Training err. RA 3.05147 Valid. err. 2.72600
2018-02-03 21:51:02,388 training [INFO ] Epoch 30 Batch 3120 Training err. 2.71393 Training err. RA 3.04930 Valid. err. 2.74933
2018-02-03 21:51:03,211 training [INFO ] Epoch 31 Batch 3140 Training err. 2.70320 Training err. RA 3.04710 Valid. err. 2.71674
2018-02-03 21:51:03,691 training [INFO ] Epoch 31 Batch 3160 Training err. 2.69079 Training err. RA 3.04484 Valid. err. 2.72936
2018-02-03 21:51:04,170 training [INFO ] Epoch 31 Batch 3180 Training err. 2.65625 Training err. RA 3.04240 Valid. err. 2.71879
2018-02-03 21:51:04,651 training [INFO ] Epoch 31 Batch 3200 Training err. 2.68831 Training err. RA 3.04019 Valid. err. 2.70734
2018-02-03 21:51:05,138 training [INFO ] Epoch 31 Batch 3220 Training err. 2.68222 Training err. RA 3.03796 Valid. err. 2.70095
2018-02-03 21:51:06,035 training [INFO ] Epoch 32 Batch 3240 Training err. 2.69941 Training err. RA 3.03587 Valid. err. 2.70926
2018-02-03 21:51:06,564 training [INFO ] Epoch 32 Batch 3260 Training err. 2.63226 Training err. RA 3.03340 Valid. err. 2.69828
2018-02-03 21:51:07,083 training [INFO ] Epoch 32 Batch 3280 Training err. 2.65466 Training err. RA 3.03109 Valid. err. 2.69126
2018-02-03 21:51:07,597 training [INFO ] Epoch 32 Batch 3300 Training err. 2.66003 Training err. RA 3.02884 Valid. err. 2.69260
2018-02-03 21:51:08,111 training [INFO ] Epoch 32 Batch 3320 Training err. 2.64440 Training err. RA 3.02652 Valid. err. 2.68758
2018-02-03 21:51:08,975 training [INFO ] Epoch 33 Batch 3340 Training err. 2.68490 Training err. RA 3.02448 Valid. err. 2.69317
2018-02-03 21:51:09,475 training [INFO ] Epoch 33 Batch 3360 Training err. 2.60594 Training err. RA 3.02199 Valid. err. 2.69326
2018-02-03 21:51:09,974 training [INFO ] Epoch 33 Batch 3380 Training err. 2.65325 Training err. RA 3.01980 Valid. err. 2.66843
2018-02-03 21:51:10,461 training [INFO ] Epoch 33 Batch 3400 Training err. 2.62666 Training err. RA 3.01749 Valid. err. 2.66659
2018-02-03 21:51:10,983 training [INFO ] Epoch 33 Batch 3420 Training err. 2.62394 Training err. RA 3.01519 Valid. err. 2.66369
2018-02-03 21:51:11,858 training [INFO ] Epoch 34 Batch 3440 Training err. 2.65613 Training err. RA 3.01310 Valid. err. 2.66057
2018-02-03 21:51:12,362 training [INFO ] Epoch 34 Batch 3460 Training err. 2.61164 Training err. RA 3.01078 Valid. err. 2.67288
2018-02-03 21:51:12,884 training [INFO ] Epoch 34 Batch 3480 Training err. 2.62939 Training err. RA 3.00859 Valid. err. 2.65389
2018-02-03 21:51:13,400 training [INFO ] Epoch 34 Batch 3500 Training err. 2.60419 Training err. RA 3.00628 Valid. err. 2.64959
2018-02-03 21:51:13,934 training [INFO ] Epoch 34 Batch 3520 Training err. 2.60100 Training err. RA 3.00398 Valid. err. 2.64207
2018-02-03 21:51:14,812 training [INFO ] Epoch 35 Batch 3540 Training err. 2.62797 Training err. RA 3.00185 Valid. err. 2.67202
2018-02-03 21:51:15,316 training [INFO ] Epoch 35 Batch 3560 Training err. 2.61671 Training err. RA 2.99969 Valid. err. 2.64045
2018-02-03 21:51:15,813 training [INFO ] Epoch 35 Batch 3580 Training err. 2.59693 Training err. RA 2.99744 Valid. err. 2.64536
2018-02-03 21:51:16,331 training [INFO ] Epoch 35 Batch 3600 Training err. 2.57259 Training err. RA 2.99508 Valid. err. 2.63664
2018-02-03 21:51:16,825 training [INFO ] Epoch 35 Batch 3620 Training err. 2.59540 Training err. RA 2.99287 Valid. err. 2.62712
2018-02-03 21:51:17,307 training [INFO ] Epoch 35 Batch 3640 Training err. 2.61287 Training err. RA 2.99078 Valid. err. 2.64877
2018-02-03 21:51:18,166 training [INFO ] Epoch 36 Batch 3660 Training err. 2.60991 Training err. RA 2.98870 Valid. err. 2.62884
2018-02-03 21:51:18,683 training [INFO ] Epoch 36 Batch 3680 Training err. 2.56238 Training err. RA 2.98638 Valid. err. 2.61931
2018-02-03 21:51:19,207 training [INFO ] Epoch 36 Batch 3700 Training err. 2.55978 Training err. RA 2.98408 Valid. err. 2.61148
2018-02-03 21:51:19,702 training [INFO ] Epoch 36 Batch 3720 Training err. 2.58996 Training err. RA 2.98196 Valid. err. 2.60656
2018-02-03 21:51:20,209 training [INFO ] Epoch 36 Batch 3740 Training err. 2.57917 Training err. RA 2.97980 Valid. err. 2.60162
2018-02-03 21:51:21,085 training [INFO ] Epoch 37 Batch 3760 Training err. 2.59915 Training err. RA 2.97778 Valid. err. 2.62270
2018-02-03 21:51:21,623 training [INFO ] Epoch 37 Batch 3780 Training err. 2.54121 Training err. RA 2.97547 Valid. err. 2.60030
2018-02-03 21:51:22,153 training [INFO ] Epoch 37 Batch 3800 Training err. 2.56923 Training err. RA 2.97333 Valid. err. 2.59756
2018-02-03 21:51:22,659 training [INFO ] Epoch 37 Batch 3820 Training err. 2.56467 Training err. RA 2.97119 Valid. err. 2.60357
2018-02-03 21:51:23,161 training [INFO ] Epoch 37 Batch 3840 Training err. 2.54938 Training err. RA 2.96900 Valid. err. 2.58781
2018-02-03 21:51:24,061 training [INFO ] Epoch 38 Batch 3860 Training err. 2.58951 Training err. RA 2.96703 Valid. err. 2.59048
2018-02-03 21:51:24,586 training [INFO ] Epoch 38 Batch 3880 Training err. 2.52321 Training err. RA 2.96474 Valid. err. 2.59572
2018-02-03 21:51:25,082 training [INFO ] Epoch 38 Batch 3900 Training err. 2.56975 Training err. RA 2.96272 Valid. err. 2.57970
2018-02-03 21:51:25,579 training [INFO ] Epoch 38 Batch 3920 Training err. 2.54036 Training err. RA 2.96056 Valid. err. 2.57537
2018-02-03 21:51:26,096 training [INFO ] Epoch 38 Batch 3940 Training err. 2.53410 Training err. RA 2.95840 Valid. err. 2.57798
2018-02-03 21:51:26,949 training [INFO ] Epoch 39 Batch 3960 Training err. 2.56668 Training err. RA 2.95642 Valid. err. 2.57075
2018-02-03 21:51:27,462 training [INFO ] Epoch 39 Batch 3980 Training err. 2.53279 Training err. RA 2.95429 Valid. err. 2.58352
2018-02-03 21:51:27,961 training [INFO ] Epoch 39 Batch 4000 Training err. 2.54838 Training err. RA 2.95226 Valid. err. 2.56912
2018-02-03 21:51:28,478 training [INFO ] Epoch 39 Batch 4020 Training err. 2.52404 Training err. RA 2.95013 Valid. err. 2.56852
2018-02-03 21:51:29,014 training [INFO ] Epoch 39 Batch 4040 Training err. 2.51665 Training err. RA 2.94798 Valid. err. 2.55796
2018-02-03 21:51:29,924 training [INFO ] Epoch 40 Batch 4060 Training err. 2.54116 Training err. RA 2.94598 Valid. err. 2.58277
2018-02-03 21:51:30,439 training [INFO ] Epoch 40 Batch 4080 Training err. 2.54093 Training err. RA 2.94399 Valid. err. 2.56117
2018-02-03 21:51:30,948 training [INFO ] Epoch 40 Batch 4100 Training err. 2.51735 Training err. RA 2.94191 Valid. err. 2.56788
2018-02-03 21:51:31,468 training [INFO ] Epoch 40 Batch 4120 Training err. 2.49828 Training err. RA 2.93976 Valid. err. 2.55586
2018-02-03 21:51:31,990 training [INFO ] Epoch 40 Batch 4140 Training err. 2.51510 Training err. RA 2.93771 Valid. err. 2.54598
2018-02-03 21:51:32,504 training [INFO ] Epoch 40 Batch 4160 Training err. 2.52977 Training err. RA 2.93575 Valid. err. 2.56454
2018-02-03 21:51:33,391 training [INFO ] Epoch 41 Batch 4180 Training err. 2.53716 Training err. RA 2.93384 Valid. err. 2.55600
2018-02-03 21:51:33,892 training [INFO ] Epoch 41 Batch 4200 Training err. 2.48488 Training err. RA 2.93170 Valid. err. 2.53972
2018-02-03 21:51:34,387 training [INFO ] Epoch 41 Batch 4220 Training err. 2.48884 Training err. RA 2.92960 Valid. err. 2.53353
2018-02-03 21:51:34,886 training [INFO ] Epoch 41 Batch 4240 Training err. 2.51345 Training err. RA 2.92764 Valid. err. 2.52902
2018-02-03 21:51:35,408 training [INFO ] Epoch 41 Batch 4260 Training err. 2.50115 Training err. RA 2.92564 Valid. err. 2.52478
2018-02-03 21:51:36,290 training [INFO ] Epoch 42 Batch 4280 Training err. 2.52498 Training err. RA 2.92376 Valid. err. 2.55149
2018-02-03 21:51:36,781 training [INFO ] Epoch 42 Batch 4300 Training err. 2.46986 Training err. RA 2.92165 Valid. err. 2.52410
2018-02-03 21:51:37,293 training [INFO ] Epoch 42 Batch 4320 Training err. 2.49874 Training err. RA 2.91970 Valid. err. 2.52354
2018-02-03 21:51:37,822 training [INFO ] Epoch 42 Batch 4340 Training err. 2.49110 Training err. RA 2.91772 Valid. err. 2.52459
2018-02-03 21:51:38,326 training [INFO ] Epoch 42 Batch 4360 Training err. 2.47508 Training err. RA 2.91569 Valid. err. 2.51392
2018-02-03 21:51:39,202 training [INFO ] Epoch 43 Batch 4380 Training err. 2.51624 Training err. RA 2.91387 Valid. err. 2.52324
2018-02-03 21:51:39,706 training [INFO ] Epoch 43 Batch 4400 Training err. 2.45603 Training err. RA 2.91179 Valid. err. 2.51933
2018-02-03 21:51:40,210 training [INFO ] Epoch 43 Batch 4420 Training err. 2.49921 Training err. RA 2.90992 Valid. err. 2.50914
2018-02-03 21:51:40,715 training [INFO ] Epoch 43 Batch 4440 Training err. 2.47231 Training err. RA 2.90795 Valid. err. 2.50148
2018-02-03 21:51:41,202 training [INFO ] Epoch 43 Batch 4460 Training err. 2.46049 Training err. RA 2.90594 Valid. err. 2.50806
2018-02-03 21:51:42,039 training [INFO ] Epoch 44 Batch 4480 Training err. 2.49330 Training err. RA 2.90410 Valid. err. 2.50031
2018-02-03 21:51:42,525 training [INFO ] Epoch 44 Batch 4500 Training err. 2.46998 Training err. RA 2.90217 Valid. err. 2.50787
2018-02-03 21:51:43,013 training [INFO ] Epoch 44 Batch 4520 Training err. 2.47960 Training err. RA 2.90030 Valid. err. 2.49910
2018-02-03 21:51:43,499 training [INFO ] Epoch 44 Batch 4540 Training err. 2.45797 Training err. RA 2.89835 Valid. err. 2.50935
2018-02-03 21:51:43,988 training [INFO ] Epoch 44 Batch 4560 Training err. 2.44746 Training err. RA 2.89637 Valid. err. 2.48864
2018-02-03 21:51:44,827 training [INFO ] Epoch 45 Batch 4580 Training err. 2.46928 Training err. RA 2.89451 Valid. err. 2.51064
2018-02-03 21:51:45,328 training [INFO ] Epoch 45 Batch 4600 Training err. 2.47994 Training err. RA 2.89271 Valid. err. 2.49137
2018-02-03 21:51:45,832 training [INFO ] Epoch 45 Batch 4620 Training err. 2.45008 Training err. RA 2.89079 Valid. err. 2.49810
2018-02-03 21:51:46,337 training [INFO ] Epoch 45 Batch 4640 Training err. 2.43467 Training err. RA 2.88882 Valid. err. 2.48509
2018-02-03 21:51:46,840 training [INFO ] Epoch 45 Batch 4660 Training err. 2.44837 Training err. RA 2.88693 Valid. err. 2.47839
2018-02-03 21:51:47,345 training [INFO ] Epoch 45 Batch 4680 Training err. 2.46096 Training err. RA 2.88511 Valid. err. 2.49081
2018-02-03 21:51:48,208 training [INFO ] Epoch 46 Batch 4700 Training err. 2.47861 Training err. RA 2.88338 Valid. err. 2.48882
2018-02-03 21:51:48,705 training [INFO ] Epoch 46 Batch 4720 Training err. 2.41856 Training err. RA 2.88141 Valid. err. 2.47036
2018-02-03 21:51:49,185 training [INFO ] Epoch 46 Batch 4740 Training err. 2.42620 Training err. RA 2.87949 Valid. err. 2.46660
2018-02-03 21:51:49,670 training [INFO ] Epoch 46 Batch 4760 Training err. 2.44869 Training err. RA 2.87768 Valid. err. 2.46299
2018-02-03 21:51:50,149 training [INFO ] Epoch 46 Batch 4780 Training err. 2.43712 Training err. RA 2.87584 Valid. err. 2.46082
2018-02-03 21:51:50,979 training [INFO ] Epoch 47 Batch 4800 Training err. 2.46422 Training err. RA 2.87412 Valid. err. 2.50374
2018-02-03 21:51:51,464 training [INFO ] Epoch 47 Batch 4820 Training err. 2.40771 Training err. RA 2.87219 Valid. err. 2.45852
2018-02-03 21:51:51,945 training [INFO ] Epoch 47 Batch 4840 Training err. 2.43569 Training err. RA 2.87038 Valid. err. 2.46111
2018-02-03 21:51:52,425 training [INFO ] Epoch 47 Batch 4860 Training err. 2.42899 Training err. RA 2.86857 Valid. err. 2.45875
2018-02-03 21:51:52,908 training [INFO ] Epoch 47 Batch 4880 Training err. 2.41372 Training err. RA 2.86670 Valid. err. 2.45293
2018-02-03 21:51:53,769 training [INFO ] Epoch 48 Batch 4900 Training err. 2.45412 Training err. RA 2.86502 Valid. err. 2.47432
2018-02-03 21:51:54,268 training [INFO ] Epoch 48 Batch 4920 Training err. 2.39878 Training err. RA 2.86312 Valid. err. 2.45408
2018-02-03 21:51:54,764 training [INFO ] Epoch 48 Batch 4940 Training err. 2.43648 Training err. RA 2.86140 Valid. err. 2.44837
2018-02-03 21:51:55,260 training [INFO ] Epoch 48 Batch 4960 Training err. 2.41330 Training err. RA 2.85959 Valid. err. 2.44177
2018-02-03 21:51:55,757 training [INFO ] Epoch 48 Batch 4980 Training err. 2.39931 Training err. RA 2.85774 Valid. err. 2.44863
2018-02-03 21:51:56,622 training [INFO ] Epoch 49 Batch 5000 Training err. 2.43034 Training err. RA 2.85603 Valid. err. 2.44136
2018-02-03 21:51:57,170 training [INFO ] Epoch 49 Batch 5020 Training err. 2.41594 Training err. RA 2.85428 Valid. err. 2.44112
2018-02-03 21:51:57,699 training [INFO ] Epoch 49 Batch 5040 Training err. 2.41802 Training err. RA 2.85255 Valid. err. 2.43773
2018-02-03 21:51:58,191 training [INFO ] Epoch 49 Batch 5060 Training err. 2.39902 Training err. RA 2.85076 Valid. err. 2.45697
2018-02-03 21:51:58,676 training [INFO ] Epoch 49 Batch 5080 Training err. 2.39008 Training err. RA 2.84894 Valid. err. 2.42893
2018-02-03 21:51:59,514 training [INFO ] Epoch 50 Batch 5100 Training err. 2.40818 Training err. RA 2.84721 Valid. err. 2.44096
2018-02-03 21:52:00,017 training [INFO ] Epoch 50 Batch 5120 Training err. 2.42719 Training err. RA 2.84557 Valid. err. 2.42996
2018-02-03 21:52:00,520 training [INFO ] Epoch 50 Batch 5140 Training err. 2.38952 Training err. RA 2.84380 Valid. err. 2.43340
2018-02-03 21:52:01,029 training [INFO ] Epoch 50 Batch 5160 Training err. 2.37776 Training err. RA 2.84199 Valid. err. 2.42140
2018-02-03 21:52:01,541 training [INFO ] Epoch 50 Batch 5180 Training err. 2.39175 Training err. RA 2.84025 Valid. err. 2.41932
2018-02-03 21:52:02,043 training [INFO ] Epoch 50 Batch 5200 Training err. 2.40228 Training err. RA 2.83857 Valid. err. 2.42335
2018-02-03 21:52:02,902 training [INFO ] Epoch 51 Batch 5220 Training err. 2.42586 Training err. RA 2.83699 Valid. err. 2.43256
2018-02-03 21:52:03,401 training [INFO ] Epoch 51 Batch 5240 Training err. 2.36001 Training err. RA 2.83517 Valid. err. 2.41287
2018-02-03 21:52:03,905 training [INFO ] Epoch 51 Batch 5260 Training err. 2.37020 Training err. RA 2.83340 Valid. err. 2.40952
2018-02-03 21:52:04,410 training [INFO ] Epoch 51 Batch 5280 Training err. 2.39413 Training err. RA 2.83174 Valid. err. 2.40760
2018-02-03 21:52:04,931 training [INFO ] Epoch 51 Batch 5300 Training err. 2.38203 Training err. RA 2.83004 Valid. err. 2.40610
2018-02-03 21:52:05,775 training [INFO ] Epoch 52 Batch 5320 Training err. 2.40894 Training err. RA 2.82846 Valid. err. 2.46026
2018-02-03 21:52:06,271 training [INFO ] Epoch 52 Batch 5340 Training err. 2.35353 Training err. RA 2.82668 Valid. err. 2.40246
2018-02-03 21:52:06,772 training [INFO ] Epoch 52 Batch 5360 Training err. 2.38004 Training err. RA 2.82501 Valid. err. 2.41031
2018-02-03 21:52:07,264 training [INFO ] Epoch 52 Batch 5380 Training err. 2.37596 Training err. RA 2.82334 Valid. err. 2.40623
2018-02-03 21:52:07,763 training [INFO ] Epoch 52 Batch 5400 Training err. 2.36135 Training err. RA 2.82163 Valid. err. 2.40119
2018-02-03 21:52:08,615 training [INFO ] Epoch 53 Batch 5420 Training err. 2.39958 Training err. RA 2.82007 Valid. err. 2.42795
2018-02-03 21:52:09,114 training [INFO ] Epoch 53 Batch 5440 Training err. 2.34741 Training err. RA 2.81833 Valid. err. 2.39929
2018-02-03 21:52:09,631 training [INFO ] Epoch 53 Batch 5460 Training err. 2.38218 Training err. RA 2.81674 Valid. err. 2.39614
2018-02-03 21:52:10,144 training [INFO ] Epoch 53 Batch 5480 Training err. 2.36241 Training err. RA 2.81508 Valid. err. 2.39312
2018-02-03 21:52:10,655 training [INFO ] Epoch 53 Batch 5500 Training err. 2.34779 Training err. RA 2.81338 Valid. err. 2.39634
2018-02-03 21:52:11,545 training [INFO ] Epoch 54 Batch 5520 Training err. 2.37607 Training err. RA 2.81179 Valid. err. 2.39188
2018-02-03 21:52:12,090 training [INFO ] Epoch 54 Batch 5540 Training err. 2.36785 Training err. RA 2.81019 Valid. err. 2.38740
2018-02-03 21:52:12,622 training [INFO ] Epoch 54 Batch 5560 Training err. 2.36487 Training err. RA 2.80859 Valid. err. 2.38549
2018-02-03 21:52:13,108 training [INFO ] Epoch 54 Batch 5580 Training err. 2.34823 Training err. RA 2.80694 Valid. err. 2.40759
2018-02-03 21:52:13,610 training [INFO ] Epoch 54 Batch 5600 Training err. 2.34128 Training err. RA 2.80528 Valid. err. 2.37821
2018-02-03 21:52:14,501 training [INFO ] Epoch 55 Batch 5620 Training err. 2.35666 Training err. RA 2.80368 Valid. err. 2.38502
2018-02-03 21:52:15,004 training [INFO ] Epoch 55 Batch 5640 Training err. 2.37835 Training err. RA 2.80217 Valid. err. 2.37933
2018-02-03 21:52:15,515 training [INFO ] Epoch 55 Batch 5660 Training err. 2.33933 Training err. RA 2.80054 Valid. err. 2.37973
2018-02-03 21:52:16,007 training [INFO ] Epoch 55 Batch 5680 Training err. 2.32897 Training err. RA 2.79888 Valid. err. 2.36855
2018-02-03 21:52:16,501 training [INFO ] Epoch 55 Batch 5700 Training err. 2.34249 Training err. RA 2.79728 Valid. err. 2.36859
2018-02-03 21:52:17,040 training [INFO ] Epoch 55 Batch 5720 Training err. 2.35188 Training err. RA 2.79572 Valid. err. 2.36867
2018-02-03 21:52:17,963 training [INFO ] Epoch 56 Batch 5740 Training err. 2.37854 Training err. RA 2.79426 Valid. err. 2.38326
2018-02-03 21:52:18,473 training [INFO ] Epoch 56 Batch 5760 Training err. 2.31177 Training err. RA 2.79259 Valid. err. 2.36458
2018-02-03 21:52:18,986 training [INFO ] Epoch 56 Batch 5780 Training err. 2.32195 Training err. RA 2.79096 Valid. err. 2.36089
2018-02-03 21:52:19,489 training [INFO ] Epoch 56 Batch 5800 Training err. 2.34591 Training err. RA 2.78943 Valid. err. 2.35920
2018-02-03 21:52:20,003 training [INFO ] Epoch 56 Batch 5820 Training err. 2.33470 Training err. RA 2.78786 Valid. err. 2.35954
2018-02-03 21:52:20,896 training [INFO ] Epoch 57 Batch 5840 Training err. 2.36191 Training err. RA 2.78640 Valid. err. 2.40421
2018-02-03 21:52:21,423 training [INFO ] Epoch 57 Batch 5860 Training err. 2.30710 Training err. RA 2.78477 Valid. err. 2.35482
2018-02-03 21:52:21,944 training [INFO ] Epoch 57 Batch 5880 Training err. 2.33147 Training err. RA 2.78323 Valid. err. 2.36779
2018-02-03 21:52:22,465 training [INFO ] Epoch 57 Batch 5900 Training err. 2.32896 Training err. RA 2.78169 Valid. err. 2.36133
2018-02-03 21:52:22,975 training [INFO ] Epoch 57 Batch 5920 Training err. 2.31598 Training err. RA 2.78011 Valid. err. 2.35878
2018-02-03 21:52:23,845 training [INFO ] Epoch 58 Batch 5940 Training err. 2.35428 Training err. RA 2.77868 Valid. err. 2.38592
2018-02-03 21:52:24,358 training [INFO ] Epoch 58 Batch 5960 Training err. 2.30128 Training err. RA 2.77708 Valid. err. 2.35457
2018-02-03 21:52:24,844 training [INFO ] Epoch 58 Batch 5980 Training err. 2.33456 Training err. RA 2.77560 Valid. err. 2.35180
2018-02-03 21:52:25,356 training [INFO ] Epoch 58 Batch 6000 Training err. 2.31709 Training err. RA 2.77407 Valid. err. 2.34851
2018-02-03 21:52:25,870 training [INFO ] Epoch 58 Batch 6020 Training err. 2.30283 Training err. RA 2.77250 Valid. err. 2.35203
2018-02-03 21:52:26,760 training [INFO ] Epoch 59 Batch 6040 Training err. 2.33033 Training err. RA 2.77104 Valid. err. 2.35224
2018-02-03 21:52:27,289 training [INFO ] Epoch 59 Batch 6060 Training err. 2.32450 Training err. RA 2.76957 Valid. err. 2.34253
2018-02-03 21:52:27,826 training [INFO ] Epoch 59 Batch 6080 Training err. 2.31825 Training err. RA 2.76808 Valid. err. 2.34069
2018-02-03 21:52:28,367 training [INFO ] Epoch 59 Batch 6100 Training err. 2.30462 Training err. RA 2.76656 Valid. err. 2.35594
2018-02-03 21:52:28,893 training [INFO ] Epoch 59 Batch 6120 Training err. 2.29699 Training err. RA 2.76503 Valid. err. 2.33363
2018-02-03 21:52:29,766 training [INFO ] Epoch 60 Batch 6140 Training err. 2.31243 Training err. RA 2.76355 Valid. err. 2.34143
2018-02-03 21:52:30,296 training [INFO ] Epoch 60 Batch 6160 Training err. 2.33533 Training err. RA 2.76216 Valid. err. 2.33605
2018-02-03 21:52:30,796 training [INFO ] Epoch 60 Batch 6180 Training err. 2.29490 Training err. RA 2.76065 Valid. err. 2.33474
2018-02-03 21:52:31,300 training [INFO ] Epoch 60 Batch 6200 Training err. 2.28704 Training err. RA 2.75912 Valid. err. 2.32571
2018-02-03 21:52:31,811 training [INFO ] Epoch 60 Batch 6220 Training err. 2.29741 Training err. RA 2.75764 Valid. err. 2.32582
2018-02-03 21:52:32,335 training [INFO ] Epoch 60 Batch 6240 Training err. 2.30842 Training err. RA 2.75620 Valid. err. 2.32514
2018-02-03 21:52:32,592 __main__ [INFO ] End of training
2018-02-03 21:52:32,845 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:52:32,845 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 21:52:33,486 training [INFO ] Epoch  1 Batch   20 Training err. 3.63755 Training err. RA 3.63755 Valid. err. 3.25904
2018-02-03 21:52:34,022 training [INFO ] Epoch  1 Batch   40 Training err. 3.16611 Training err. RA 3.40183 Valid. err. 3.19632
2018-02-03 21:52:34,540 training [INFO ] Epoch  1 Batch   60 Training err. 3.13805 Training err. RA 3.31390 Valid. err. 3.43535
2018-02-03 21:52:35,052 training [INFO ] Epoch  1 Batch   80 Training err. 3.16892 Training err. RA 3.27766 Valid. err. 3.18056
2018-02-03 21:52:35,570 training [INFO ] Epoch  1 Batch  100 Training err. 3.14478 Training err. RA 3.25108 Valid. err. 3.17009
2018-02-03 21:52:36,448 training [INFO ] Epoch  2 Batch  120 Training err. 3.14906 Training err. RA 3.23408 Valid. err. 3.17691
2018-02-03 21:52:36,961 training [INFO ] Epoch  2 Batch  140 Training err. 3.09824 Training err. RA 3.21467 Valid. err. 3.16151
2018-02-03 21:52:37,478 training [INFO ] Epoch  2 Batch  160 Training err. 3.09072 Training err. RA 3.19918 Valid. err. 3.17018
2018-02-03 21:52:38,007 training [INFO ] Epoch  2 Batch  180 Training err. 3.12133 Training err. RA 3.19053 Valid. err. 3.12922
2018-02-03 21:52:38,546 training [INFO ] Epoch  2 Batch  200 Training err. 3.08857 Training err. RA 3.18033 Valid. err. 3.10736
2018-02-03 21:52:39,473 training [INFO ] Epoch  3 Batch  220 Training err. 3.08259 Training err. RA 3.17145 Valid. err. 3.15071
2018-02-03 21:52:39,989 training [INFO ] Epoch  3 Batch  240 Training err. 2.99620 Training err. RA 3.15684 Valid. err. 3.05540
2018-02-03 21:52:40,501 training [INFO ] Epoch  3 Batch  260 Training err. 2.99777 Training err. RA 3.14461 Valid. err. 3.03677
2018-02-03 21:52:40,999 training [INFO ] Epoch  3 Batch  280 Training err. 2.96853 Training err. RA 3.13203 Valid. err. 2.96235
2018-02-03 21:52:41,487 training [INFO ] Epoch  3 Batch  300 Training err. 2.91161 Training err. RA 3.11734 Valid. err. 2.91293
2018-02-03 21:52:42,366 training [INFO ] Epoch  4 Batch  320 Training err. 2.90793 Training err. RA 3.10425 Valid. err. 2.87763
2018-02-03 21:52:42,853 training [INFO ] Epoch  4 Batch  340 Training err. 2.83310 Training err. RA 3.08830 Valid. err. 2.97606
2018-02-03 21:52:43,376 training [INFO ] Epoch  4 Batch  360 Training err. 2.82458 Training err. RA 3.07365 Valid. err. 2.81979
2018-02-03 21:52:43,857 training [INFO ] Epoch  4 Batch  380 Training err. 2.75418 Training err. RA 3.05683 Valid. err. 2.78565
2018-02-03 21:52:44,337 training [INFO ] Epoch  4 Batch  400 Training err. 2.74987 Training err. RA 3.04149 Valid. err. 2.75502
2018-02-03 21:52:45,290 training [INFO ] Epoch  5 Batch  420 Training err. 2.75280 Training err. RA 3.02774 Valid. err. 2.74763
2018-02-03 21:52:45,803 training [INFO ] Epoch  5 Batch  440 Training err. 2.70544 Training err. RA 3.01309 Valid. err. 2.71777
2018-02-03 21:52:46,313 training [INFO ] Epoch  5 Batch  460 Training err. 2.70332 Training err. RA 2.99962 Valid. err. 2.73810
2018-02-03 21:52:46,817 training [INFO ] Epoch  5 Batch  480 Training err. 2.64157 Training err. RA 2.98470 Valid. err. 2.66245
2018-02-03 21:52:47,324 training [INFO ] Epoch  5 Batch  500 Training err. 2.61860 Training err. RA 2.97006 Valid. err. 2.65164
2018-02-03 21:52:47,824 training [INFO ] Epoch  5 Batch  520 Training err. 2.63208 Training err. RA 2.95706 Valid. err. 2.62143
2018-02-03 21:52:48,684 training [INFO ] Epoch  6 Batch  540 Training err. 2.60688 Training err. RA 2.94409 Valid. err. 2.60355
2018-02-03 21:52:49,172 training [INFO ] Epoch  6 Batch  560 Training err. 2.54523 Training err. RA 2.92984 Valid. err. 2.62866
2018-02-03 21:52:49,652 training [INFO ] Epoch  6 Batch  580 Training err. 2.53066 Training err. RA 2.91608 Valid. err. 2.57609
2018-02-03 21:52:50,136 training [INFO ] Epoch  6 Batch  600 Training err. 2.52830 Training err. RA 2.90315 Valid. err. 2.53965
2018-02-03 21:52:50,620 training [INFO ] Epoch  6 Batch  620 Training err. 2.51798 Training err. RA 2.89073 Valid. err. 2.56140
2018-02-03 21:52:51,455 training [INFO ] Epoch  7 Batch  640 Training err. 2.52015 Training err. RA 2.87915 Valid. err. 2.51424
2018-02-03 21:52:51,935 training [INFO ] Epoch  7 Batch  660 Training err. 2.43928 Training err. RA 2.86582 Valid. err. 2.49881
2018-02-03 21:52:52,420 training [INFO ] Epoch  7 Batch  680 Training err. 2.45744 Training err. RA 2.85381 Valid. err. 2.52789
2018-02-03 21:52:52,904 training [INFO ] Epoch  7 Batch  700 Training err. 2.43957 Training err. RA 2.84197 Valid. err. 2.43521
2018-02-03 21:52:53,385 training [INFO ] Epoch  7 Batch  720 Training err. 2.41378 Training err. RA 2.83008 Valid. err. 2.41757
2018-02-03 21:52:54,219 training [INFO ] Epoch  8 Batch  740 Training err. 2.43268 Training err. RA 2.81934 Valid. err. 2.41210
2018-02-03 21:52:54,700 training [INFO ] Epoch  8 Batch  760 Training err. 2.35807 Training err. RA 2.80720 Valid. err. 2.39590
2018-02-03 21:52:55,181 training [INFO ] Epoch  8 Batch  780 Training err. 2.38950 Training err. RA 2.79649 Valid. err. 2.36992
2018-02-03 21:52:55,661 training [INFO ] Epoch  8 Batch  800 Training err. 2.33740 Training err. RA 2.78501 Valid. err. 2.38390
2018-02-03 21:52:56,142 training [INFO ] Epoch  8 Batch  820 Training err. 2.33047 Training err. RA 2.77392 Valid. err. 2.38838
2018-02-03 21:52:56,978 training [INFO ] Epoch  9 Batch  840 Training err. 2.35732 Training err. RA 2.76401 Valid. err. 2.33959
2018-02-03 21:52:57,465 training [INFO ] Epoch  9 Batch  860 Training err. 2.31463 Training err. RA 2.75355 Valid. err. 2.33092
2018-02-03 21:52:57,961 training [INFO ] Epoch  9 Batch  880 Training err. 2.29122 Training err. RA 2.74305 Valid. err. 2.33998
2018-02-03 21:52:58,464 training [INFO ] Epoch  9 Batch  900 Training err. 2.29966 Training err. RA 2.73319 Valid. err. 2.33486
2018-02-03 21:52:58,965 training [INFO ] Epoch  9 Batch  920 Training err. 2.26329 Training err. RA 2.72298 Valid. err. 2.30907
2018-02-03 21:52:59,850 training [INFO ] Epoch 10 Batch  940 Training err. 2.27156 Training err. RA 2.71337 Valid. err. 2.29023
2018-02-03 21:53:00,369 training [INFO ] Epoch 10 Batch  960 Training err. 2.27010 Training err. RA 2.70414 Valid. err. 2.27066
2018-02-03 21:53:00,880 training [INFO ] Epoch 10 Batch  980 Training err. 2.22113 Training err. RA 2.69428 Valid. err. 2.24822
2018-02-03 21:53:01,396 training [INFO ] Epoch 10 Batch 1000 Training err. 2.22316 Training err. RA 2.68486 Valid. err. 2.24544
2018-02-03 21:53:01,905 training [INFO ] Epoch 10 Batch 1020 Training err. 2.21864 Training err. RA 2.67572 Valid. err. 2.27207
2018-02-03 21:53:02,432 training [INFO ] Epoch 10 Batch 1040 Training err. 2.21759 Training err. RA 2.66691 Valid. err. 2.26161
2018-02-03 21:53:03,304 training [INFO ] Epoch 11 Batch 1060 Training err. 2.23793 Training err. RA 2.65881 Valid. err. 2.22159
2018-02-03 21:53:03,793 training [INFO ] Epoch 11 Batch 1080 Training err. 2.15248 Training err. RA 2.64944 Valid. err. 2.23826
2018-02-03 21:53:04,317 training [INFO ] Epoch 11 Batch 1100 Training err. 2.17383 Training err. RA 2.64079 Valid. err. 2.19597
2018-02-03 21:53:04,841 training [INFO ] Epoch 11 Batch 1120 Training err. 2.18792 Training err. RA 2.63270 Valid. err. 2.20054
2018-02-03 21:53:05,359 training [INFO ] Epoch 11 Batch 1140 Training err. 2.15340 Training err. RA 2.62429 Valid. err. 2.19170
2018-02-03 21:53:06,257 training [INFO ] Epoch 12 Batch 1160 Training err. 2.18452 Training err. RA 2.61671 Valid. err. 2.24879
2018-02-03 21:53:06,773 training [INFO ] Epoch 12 Batch 1180 Training err. 2.12680 Training err. RA 2.60841 Valid. err. 2.17470
2018-02-03 21:53:07,284 training [INFO ] Epoch 12 Batch 1200 Training err. 2.13387 Training err. RA 2.60050 Valid. err. 2.23508
2018-02-03 21:53:07,802 training [INFO ] Epoch 12 Batch 1220 Training err. 2.14269 Training err. RA 2.59299 Valid. err. 2.14943
2018-02-03 21:53:08,319 training [INFO ] Epoch 12 Batch 1240 Training err. 2.11267 Training err. RA 2.58525 Valid. err. 2.15468
2018-02-03 21:53:09,209 training [INFO ] Epoch 13 Batch 1260 Training err. 2.65615 Training err. RA 2.58637 Valid. err. 2.71053
2018-02-03 21:53:09,734 training [INFO ] Epoch 13 Batch 1280 Training err. 2.35619 Training err. RA 2.58278 Valid. err. 2.30433
2018-02-03 21:53:10,233 training [INFO ] Epoch 13 Batch 1300 Training err. 2.26791 Training err. RA 2.57793 Valid. err. 2.24232
2018-02-03 21:53:10,724 training [INFO ] Epoch 13 Batch 1320 Training err. 2.22823 Training err. RA 2.57263 Valid. err. 2.22191
2018-02-03 21:53:11,230 training [INFO ] Epoch 13 Batch 1340 Training err. 2.16964 Training err. RA 2.56662 Valid. err. 2.19254
2018-02-03 21:53:12,110 training [INFO ] Epoch 14 Batch 1360 Training err. 2.18602 Training err. RA 2.56102 Valid. err. 2.18995
2018-02-03 21:53:12,614 training [INFO ] Epoch 14 Batch 1380 Training err. 2.16609 Training err. RA 2.55530 Valid. err. 2.18029
2018-02-03 21:53:13,137 training [INFO ] Epoch 14 Batch 1400 Training err. 2.13880 Training err. RA 2.54935 Valid. err. 2.18278
2018-02-03 21:53:13,666 training [INFO ] Epoch 14 Batch 1420 Training err. 2.13977 Training err. RA 2.54358 Valid. err. 2.20063
2018-02-03 21:53:14,164 training [INFO ] Epoch 14 Batch 1440 Training err. 2.11390 Training err. RA 2.53761 Valid. err. 2.15728
2018-02-03 21:53:15,028 training [INFO ] Epoch 15 Batch 1460 Training err. 2.11157 Training err. RA 2.53178 Valid. err. 2.14000
2018-02-03 21:53:15,524 training [INFO ] Epoch 15 Batch 1480 Training err. 2.12755 Training err. RA 2.52631 Valid. err. 2.13887
2018-02-03 21:53:16,029 training [INFO ] Epoch 15 Batch 1500 Training err. 2.07584 Training err. RA 2.52031 Valid. err. 2.11530
2018-02-03 21:53:16,558 training [INFO ] Epoch 15 Batch 1520 Training err. 2.07890 Training err. RA 2.51450 Valid. err. 2.10236
2018-02-03 21:53:17,090 training [INFO ] Epoch 15 Batch 1540 Training err. 2.08116 Training err. RA 2.50887 Valid. err. 2.10499
2018-02-03 21:53:17,594 training [INFO ] Epoch 15 Batch 1560 Training err. 2.07640 Training err. RA 2.50333 Valid. err. 2.11644
2018-02-03 21:53:18,461 training [INFO ] Epoch 16 Batch 1580 Training err. 2.10183 Training err. RA 2.49824 Valid. err. 2.10055
2018-02-03 21:53:18,948 training [INFO ] Epoch 16 Batch 1600 Training err. 2.02248 Training err. RA 2.49230 Valid. err. 2.10140
2018-02-03 21:53:19,436 training [INFO ] Epoch 16 Batch 1620 Training err. 2.03637 Training err. RA 2.48667 Valid. err. 2.07697
2018-02-03 21:53:19,934 training [INFO ] Epoch 16 Batch 1640 Training err. 2.06098 Training err. RA 2.48148 Valid. err. 2.08921
2018-02-03 21:53:20,443 training [INFO ] Epoch 16 Batch 1660 Training err. 2.02654 Training err. RA 2.47600 Valid. err. 2.07631
2018-02-03 21:53:21,309 training [INFO ] Epoch 17 Batch 1680 Training err. 2.06413 Training err. RA 2.47109 Valid. err. 2.08294
2018-02-03 21:53:21,814 training [INFO ] Epoch 17 Batch 1700 Training err. 2.00876 Training err. RA 2.46565 Valid. err. 2.06851
2018-02-03 21:53:22,318 training [INFO ] Epoch 17 Batch 1720 Training err. 2.00953 Training err. RA 2.46035 Valid. err. 2.07739
2018-02-03 21:53:22,821 training [INFO ] Epoch 17 Batch 1740 Training err. 2.02658 Training err. RA 2.45536 Valid. err. 2.04256
2018-02-03 21:53:23,335 training [INFO ] Epoch 17 Batch 1760 Training err. 2.00183 Training err. RA 2.45021 Valid. err. 2.02848
2018-02-03 21:53:24,241 training [INFO ] Epoch 18 Batch 1780 Training err. 2.03577 Training err. RA 2.44555 Valid. err. 2.02386
2018-02-03 21:53:24,772 training [INFO ] Epoch 18 Batch 1800 Training err. 1.98365 Training err. RA 2.44042 Valid. err. 2.03389
2018-02-03 21:53:25,285 training [INFO ] Epoch 18 Batch 1820 Training err. 1.98803 Training err. RA 2.43545 Valid. err. 2.04095
2018-02-03 21:53:25,784 training [INFO ] Epoch 18 Batch 1840 Training err. 1.99988 Training err. RA 2.43072 Valid. err. 2.03081
2018-02-03 21:53:26,273 training [INFO ] Epoch 18 Batch 1860 Training err. 1.97268 Training err. RA 2.42579 Valid. err. 2.02287
2018-02-03 21:53:27,113 training [INFO ] Epoch 19 Batch 1880 Training err. 1.98748 Training err. RA 2.42113 Valid. err. 2.01960
2018-02-03 21:53:27,600 training [INFO ] Epoch 19 Batch 1900 Training err. 1.98576 Training err. RA 2.41654 Valid. err. 2.00335
2018-02-03 21:53:28,087 training [INFO ] Epoch 19 Batch 1920 Training err. 1.96103 Training err. RA 2.41180 Valid. err. 2.02104
2018-02-03 21:53:28,574 training [INFO ] Epoch 19 Batch 1940 Training err. 1.97108 Training err. RA 2.40726 Valid. err. 2.00170
2018-02-03 21:53:29,071 training [INFO ] Epoch 19 Batch 1960 Training err. 1.95739 Training err. RA 2.40267 Valid. err. 2.00137
2018-02-03 21:53:29,967 training [INFO ] Epoch 20 Batch 1980 Training err. 1.94676 Training err. RA 2.39806 Valid. err. 1.99730
2018-02-03 21:53:30,472 training [INFO ] Epoch 20 Batch 2000 Training err. 1.98032 Training err. RA 2.39388 Valid. err. 1.98373
2018-02-03 21:53:30,977 training [INFO ] Epoch 20 Batch 2020 Training err. 1.92836 Training err. RA 2.38927 Valid. err. 1.98806
2018-02-03 21:53:31,483 training [INFO ] Epoch 20 Batch 2040 Training err. 1.93418 Training err. RA 2.38481 Valid. err. 1.97100
2018-02-03 21:53:31,993 training [INFO ] Epoch 20 Batch 2060 Training err. 1.94322 Training err. RA 2.38052 Valid. err. 1.97231
2018-02-03 21:53:32,515 training [INFO ] Epoch 20 Batch 2080 Training err. 1.93132 Training err. RA 2.37621 Valid. err. 1.99758
2018-02-03 21:53:33,396 training [INFO ] Epoch 21 Batch 2100 Training err. 1.96753 Training err. RA 2.37231 Valid. err. 1.98076
2018-02-03 21:53:33,883 training [INFO ] Epoch 21 Batch 2120 Training err. 1.89088 Training err. RA 2.36777 Valid. err. 1.97425
2018-02-03 21:53:34,387 training [INFO ] Epoch 21 Batch 2140 Training err. 1.90914 Training err. RA 2.36349 Valid. err. 1.95839
2018-02-03 21:53:34,901 training [INFO ] Epoch 21 Batch 2160 Training err. 1.93455 Training err. RA 2.35951 Valid. err. 1.96062
2018-02-03 21:53:35,425 training [INFO ] Epoch 21 Batch 2180 Training err. 1.90236 Training err. RA 2.35532 Valid. err. 1.97287
2018-02-03 21:53:36,314 training [INFO ] Epoch 22 Batch 2200 Training err. 1.93358 Training err. RA 2.35149 Valid. err. 1.97461
2018-02-03 21:53:36,807 training [INFO ] Epoch 22 Batch 2220 Training err. 1.89126 Training err. RA 2.34734 Valid. err. 1.95846
2018-02-03 21:53:37,336 training [INFO ] Epoch 22 Batch 2240 Training err. 1.89094 Training err. RA 2.34326 Valid. err. 1.96887
2018-02-03 21:53:37,832 training [INFO ] Epoch 22 Batch 2260 Training err. 1.90952 Training err. RA 2.33943 Valid. err. 1.95199
2018-02-03 21:53:38,327 training [INFO ] Epoch 22 Batch 2280 Training err. 1.88650 Training err. RA 2.33545 Valid. err. 1.92762
2018-02-03 21:53:39,214 training [INFO ] Epoch 23 Batch 2300 Training err. 1.91434 Training err. RA 2.33179 Valid. err. 1.92425
2018-02-03 21:53:39,713 training [INFO ] Epoch 23 Batch 2320 Training err. 1.87216 Training err. RA 2.32783 Valid. err. 1.94729
2018-02-03 21:53:40,210 training [INFO ] Epoch 23 Batch 2340 Training err. 1.87793 Training err. RA 2.32398 Valid. err. 1.93603
2018-02-03 21:53:40,706 training [INFO ] Epoch 23 Batch 2360 Training err. 1.88894 Training err. RA 2.32030 Valid. err. 1.93904
2018-02-03 21:53:41,191 training [INFO ] Epoch 23 Batch 2380 Training err. 1.87257 Training err. RA 2.31653 Valid. err. 1.92322
2018-02-03 21:53:42,030 training [INFO ] Epoch 24 Batch 2400 Training err. 1.86857 Training err. RA 2.31280 Valid. err. 1.91990
2018-02-03 21:53:42,542 training [INFO ] Epoch 24 Batch 2420 Training err. 1.87587 Training err. RA 2.30919 Valid. err. 1.91670
2018-02-03 21:53:43,024 training [INFO ] Epoch 24 Batch 2440 Training err. 1.86397 Training err. RA 2.30554 Valid. err. 1.93550
2018-02-03 21:53:43,524 training [INFO ] Epoch 24 Batch 2460 Training err. 1.86928 Training err. RA 2.30199 Valid. err. 1.90953
2018-02-03 21:53:44,044 training [INFO ] Epoch 24 Batch 2480 Training err. 1.86005 Training err. RA 2.29843 Valid. err. 1.91207
2018-02-03 21:53:44,912 training [INFO ] Epoch 25 Batch 2500 Training err. 1.83862 Training err. RA 2.29475 Valid. err. 1.90154
2018-02-03 21:53:45,436 training [INFO ] Epoch 25 Batch 2520 Training err. 1.87203 Training err. RA 2.29140 Valid. err. 1.89985
2018-02-03 21:53:45,948 training [INFO ] Epoch 25 Batch 2540 Training err. 1.83678 Training err. RA 2.28782 Valid. err. 1.90620
2018-02-03 21:53:46,466 training [INFO ] Epoch 25 Batch 2560 Training err. 1.84148 Training err. RA 2.28433 Valid. err. 1.89680
2018-02-03 21:53:46,972 training [INFO ] Epoch 25 Batch 2580 Training err. 1.85439 Training err. RA 2.28100 Valid. err. 1.88772
2018-02-03 21:53:47,477 training [INFO ] Epoch 25 Batch 2600 Training err. 1.82649 Training err. RA 2.27750 Valid. err. 1.89524
2018-02-03 21:53:48,358 training [INFO ] Epoch 26 Batch 2620 Training err. 1.86717 Training err. RA 2.27437 Valid. err. 1.90421
2018-02-03 21:53:48,868 training [INFO ] Epoch 26 Batch 2640 Training err. 1.80266 Training err. RA 2.27079 Valid. err. 1.89588
2018-02-03 21:53:49,349 training [INFO ] Epoch 26 Batch 2660 Training err. 1.82510 Training err. RA 2.26744 Valid. err. 1.88632
2018-02-03 21:53:49,842 training [INFO ] Epoch 26 Batch 2680 Training err. 1.84790 Training err. RA 2.26431 Valid. err. 1.88781
2018-02-03 21:53:50,336 training [INFO ] Epoch 26 Batch 2700 Training err. 1.81194 Training err. RA 2.26096 Valid. err. 1.87127
2018-02-03 21:53:51,177 training [INFO ] Epoch 27 Batch 2720 Training err. 1.83700 Training err. RA 2.25784 Valid. err. 1.89032
2018-02-03 21:53:51,659 training [INFO ] Epoch 27 Batch 2740 Training err. 1.80367 Training err. RA 2.25453 Valid. err. 1.88689
2018-02-03 21:53:52,155 training [INFO ] Epoch 27 Batch 2760 Training err. 1.80998 Training err. RA 2.25131 Valid. err. 1.88370
2018-02-03 21:53:52,636 training [INFO ] Epoch 27 Batch 2780 Training err. 1.82551 Training err. RA 2.24824 Valid. err. 1.89124
2018-02-03 21:53:53,164 training [INFO ] Epoch 27 Batch 2800 Training err. 1.80427 Training err. RA 2.24507 Valid. err. 1.86030
2018-02-03 21:53:54,102 training [INFO ] Epoch 28 Batch 2820 Training err. 1.82278 Training err. RA 2.24208 Valid. err. 1.85702
2018-02-03 21:53:54,614 training [INFO ] Epoch 28 Batch 2840 Training err. 1.79039 Training err. RA 2.23890 Valid. err. 1.88248
2018-02-03 21:53:55,122 training [INFO ] Epoch 28 Batch 2860 Training err. 1.79970 Training err. RA 2.23583 Valid. err. 1.86700
2018-02-03 21:53:55,631 training [INFO ] Epoch 28 Batch 2880 Training err. 1.81001 Training err. RA 2.23287 Valid. err. 1.86542
2018-02-03 21:53:56,154 training [INFO ] Epoch 28 Batch 2900 Training err. 1.79140 Training err. RA 2.22982 Valid. err. 1.86324
2018-02-03 21:53:57,051 training [INFO ] Epoch 29 Batch 2920 Training err. 1.79198 Training err. RA 2.22683 Valid. err. 1.84812
2018-02-03 21:53:57,549 training [INFO ] Epoch 29 Batch 2940 Training err. 1.79330 Training err. RA 2.22388 Valid. err. 1.85536
2018-02-03 21:53:58,060 training [INFO ] Epoch 29 Batch 2960 Training err. 1.78868 Training err. RA 2.22094 Valid. err. 1.85794
2018-02-03 21:53:58,576 training [INFO ] Epoch 29 Batch 2980 Training err. 1.80040 Training err. RA 2.21811 Valid. err. 1.85550
2018-02-03 21:53:59,088 training [INFO ] Epoch 29 Batch 3000 Training err. 1.77917 Training err. RA 2.21519 Valid. err. 1.83825
2018-02-03 21:53:59,967 training [INFO ] Epoch 30 Batch 3020 Training err. 1.76424 Training err. RA 2.21220 Valid. err. 1.84178
2018-02-03 21:54:00,460 training [INFO ] Epoch 30 Batch 3040 Training err. 1.79399 Training err. RA 2.20945 Valid. err. 1.84017
2018-02-03 21:54:00,948 training [INFO ] Epoch 30 Batch 3060 Training err. 1.76459 Training err. RA 2.20654 Valid. err. 1.84605
2018-02-03 21:54:01,449 training [INFO ] Epoch 30 Batch 3080 Training err. 1.77120 Training err. RA 2.20372 Valid. err. 1.82919
2018-02-03 21:54:01,954 training [INFO ] Epoch 30 Batch 3100 Training err. 1.77749 Training err. RA 2.20097 Valid. err. 1.83716
2018-02-03 21:54:02,468 training [INFO ] Epoch 30 Batch 3120 Training err. 1.75797 Training err. RA 2.19813 Valid. err. 1.81881
2018-02-03 21:54:03,352 training [INFO ] Epoch 31 Batch 3140 Training err. 1.79257 Training err. RA 2.19554 Valid. err. 1.83624
2018-02-03 21:54:03,861 training [INFO ] Epoch 31 Batch 3160 Training err. 1.73028 Training err. RA 2.19260 Valid. err. 1.83625
2018-02-03 21:54:04,368 training [INFO ] Epoch 31 Batch 3180 Training err. 1.75690 Training err. RA 2.18986 Valid. err. 1.84285
2018-02-03 21:54:04,874 training [INFO ] Epoch 31 Batch 3200 Training err. 1.77329 Training err. RA 2.18725 Valid. err. 1.82432
2018-02-03 21:54:05,363 training [INFO ] Epoch 31 Batch 3220 Training err. 1.74962 Training err. RA 2.18454 Valid. err. 1.82212
2018-02-03 21:54:06,210 training [INFO ] Epoch 32 Batch 3240 Training err. 1.76561 Training err. RA 2.18195 Valid. err. 1.83215
2018-02-03 21:54:06,707 training [INFO ] Epoch 32 Batch 3260 Training err. 1.73445 Training err. RA 2.17920 Valid. err. 1.82915
2018-02-03 21:54:07,197 training [INFO ] Epoch 32 Batch 3280 Training err. 1.74098 Training err. RA 2.17653 Valid. err. 1.83029
2018-02-03 21:54:07,687 training [INFO ] Epoch 32 Batch 3300 Training err. 1.76089 Training err. RA 2.17401 Valid. err. 1.80887
2018-02-03 21:54:08,187 training [INFO ] Epoch 32 Batch 3320 Training err. 1.73945 Training err. RA 2.17140 Valid. err. 1.82130
2018-02-03 21:54:09,083 training [INFO ] Epoch 33 Batch 3340 Training err. 1.75771 Training err. RA 2.16892 Valid. err. 1.80922
2018-02-03 21:54:09,606 training [INFO ] Epoch 33 Batch 3360 Training err. 1.72482 Training err. RA 2.16627 Valid. err. 1.82342
2018-02-03 21:54:10,118 training [INFO ] Epoch 33 Batch 3380 Training err. 1.73295 Training err. RA 2.16371 Valid. err. 1.80988
2018-02-03 21:54:10,623 training [INFO ] Epoch 33 Batch 3400 Training err. 1.74865 Training err. RA 2.16127 Valid. err. 1.81198
2018-02-03 21:54:11,112 training [INFO ] Epoch 33 Batch 3420 Training err. 1.73054 Training err. RA 2.15875 Valid. err. 1.80234
2018-02-03 21:54:11,969 training [INFO ] Epoch 34 Batch 3440 Training err. 1.72514 Training err. RA 2.15623 Valid. err. 1.81998
2018-02-03 21:54:12,456 training [INFO ] Epoch 34 Batch 3460 Training err. 1.73670 Training err. RA 2.15380 Valid. err. 1.80602
2018-02-03 21:54:12,947 training [INFO ] Epoch 34 Batch 3480 Training err. 1.72567 Training err. RA 2.15134 Valid. err. 1.79901
2018-02-03 21:54:13,466 training [INFO ] Epoch 34 Batch 3500 Training err. 1.73565 Training err. RA 2.14897 Valid. err. 1.79296
2018-02-03 21:54:14,005 training [INFO ] Epoch 34 Batch 3520 Training err. 1.72394 Training err. RA 2.14655 Valid. err. 1.80904
2018-02-03 21:54:14,888 training [INFO ] Epoch 35 Batch 3540 Training err. 1.70588 Training err. RA 2.14406 Valid. err. 1.78751
2018-02-03 21:54:15,394 training [INFO ] Epoch 35 Batch 3560 Training err. 1.73353 Training err. RA 2.14176 Valid. err. 1.79166
2018-02-03 21:54:15,914 training [INFO ] Epoch 35 Batch 3580 Training err. 1.70464 Training err. RA 2.13932 Valid. err. 1.79329
2018-02-03 21:54:16,448 training [INFO ] Epoch 35 Batch 3600 Training err. 1.70983 Training err. RA 2.13693 Valid. err. 1.79402
2018-02-03 21:54:16,967 training [INFO ] Epoch 35 Batch 3620 Training err. 1.72364 Training err. RA 2.13465 Valid. err. 1.78868
2018-02-03 21:54:17,570 training [INFO ] Epoch 35 Batch 3640 Training err. 1.70247 Training err. RA 2.13227 Valid. err. 1.78553
2018-02-03 21:54:18,754 training [INFO ] Epoch 36 Batch 3660 Training err. 1.73382 Training err. RA 2.13009 Valid. err. 1.79503
2018-02-03 21:54:19,431 training [INFO ] Epoch 36 Batch 3680 Training err. 1.67269 Training err. RA 2.12761 Valid. err. 1.78858
2018-02-03 21:54:20,147 training [INFO ] Epoch 36 Batch 3700 Training err. 1.70013 Training err. RA 2.12530 Valid. err. 1.78582
2018-02-03 21:54:20,852 training [INFO ] Epoch 36 Batch 3720 Training err. 1.72202 Training err. RA 2.12313 Valid. err. 1.77994
2018-02-03 21:54:21,441 training [INFO ] Epoch 36 Batch 3740 Training err. 1.69542 Training err. RA 2.12084 Valid. err. 1.77551
2018-02-03 21:54:22,406 training [INFO ] Epoch 37 Batch 3760 Training err. 1.70885 Training err. RA 2.11865 Valid. err. 1.78848
2018-02-03 21:54:22,952 training [INFO ] Epoch 37 Batch 3780 Training err. 1.67985 Training err. RA 2.11633 Valid. err. 1.78404
2018-02-03 21:54:23,534 training [INFO ] Epoch 37 Batch 3800 Training err. 1.68819 Training err. RA 2.11408 Valid. err. 1.79030
2018-02-03 21:54:24,074 training [INFO ] Epoch 37 Batch 3820 Training err. 1.70548 Training err. RA 2.11194 Valid. err. 1.76462
2018-02-03 21:54:24,610 training [INFO ] Epoch 37 Batch 3840 Training err. 1.69402 Training err. RA 2.10976 Valid. err. 1.78237
2018-02-03 21:54:25,519 training [INFO ] Epoch 38 Batch 3860 Training err. 1.70385 Training err. RA 2.10766 Valid. err. 1.76900
2018-02-03 21:54:26,049 training [INFO ] Epoch 38 Batch 3880 Training err. 1.67121 Training err. RA 2.10541 Valid. err. 1.77826
2018-02-03 21:54:26,578 training [INFO ] Epoch 38 Batch 3900 Training err. 1.68108 Training err. RA 2.10323 Valid. err. 1.77294
2018-02-03 21:54:27,099 training [INFO ] Epoch 38 Batch 3920 Training err. 1.69942 Training err. RA 2.10117 Valid. err. 1.77896
2018-02-03 21:54:27,622 training [INFO ] Epoch 38 Batch 3940 Training err. 1.68478 Training err. RA 2.09906 Valid. err. 1.77181
2018-02-03 21:54:28,504 training [INFO ] Epoch 39 Batch 3960 Training err. 1.67379 Training err. RA 2.09691 Valid. err. 1.75900
2018-02-03 21:54:29,019 training [INFO ] Epoch 39 Batch 3980 Training err. 1.67768 Training err. RA 2.09480 Valid. err. 1.77007
2018-02-03 21:54:29,539 training [INFO ] Epoch 39 Batch 4000 Training err. 1.67657 Training err. RA 2.09271 Valid. err. 1.76564
2018-02-03 21:54:30,052 training [INFO ] Epoch 39 Batch 4020 Training err. 1.68683 Training err. RA 2.09069 Valid. err. 1.75708
2018-02-03 21:54:30,545 training [INFO ] Epoch 39 Batch 4040 Training err. 1.67382 Training err. RA 2.08863 Valid. err. 1.76446
2018-02-03 21:54:31,427 training [INFO ] Epoch 40 Batch 4060 Training err. 1.65594 Training err. RA 2.08650 Valid. err. 1.75292
2018-02-03 21:54:31,944 training [INFO ] Epoch 40 Batch 4080 Training err. 1.68198 Training err. RA 2.08451 Valid. err. 1.75530
2018-02-03 21:54:32,475 training [INFO ] Epoch 40 Batch 4100 Training err. 1.65895 Training err. RA 2.08244 Valid. err. 1.75123
2018-02-03 21:54:32,995 training [INFO ] Epoch 40 Batch 4120 Training err. 1.66270 Training err. RA 2.08040 Valid. err. 1.76400
2018-02-03 21:54:33,518 training [INFO ] Epoch 40 Batch 4140 Training err. 1.67388 Training err. RA 2.07844 Valid. err. 1.75233
2018-02-03 21:54:34,023 training [INFO ] Epoch 40 Batch 4160 Training err. 1.65547 Training err. RA 2.07640 Valid. err. 1.74289
2018-02-03 21:54:34,938 training [INFO ] Epoch 41 Batch 4180 Training err. 1.68544 Training err. RA 2.07453 Valid. err. 1.75853
2018-02-03 21:54:35,447 training [INFO ] Epoch 41 Batch 4200 Training err. 1.62822 Training err. RA 2.07241 Valid. err. 1.75282
2018-02-03 21:54:35,960 training [INFO ] Epoch 41 Batch 4220 Training err. 1.65675 Training err. RA 2.07044 Valid. err. 1.74884
2018-02-03 21:54:36,480 training [INFO ] Epoch 41 Batch 4240 Training err. 1.67225 Training err. RA 2.06856 Valid. err. 1.74137
2018-02-03 21:54:37,011 training [INFO ] Epoch 41 Batch 4260 Training err. 1.64865 Training err. RA 2.06659 Valid. err. 1.74308
2018-02-03 21:54:37,874 training [INFO ] Epoch 42 Batch 4280 Training err. 1.66394 Training err. RA 2.06471 Valid. err. 1.75002
2018-02-03 21:54:38,368 training [INFO ] Epoch 42 Batch 4300 Training err. 1.63752 Training err. RA 2.06272 Valid. err. 1.74827
2018-02-03 21:54:38,857 training [INFO ] Epoch 42 Batch 4320 Training err. 1.64729 Training err. RA 2.06080 Valid. err. 1.75253
2018-02-03 21:54:39,375 training [INFO ] Epoch 42 Batch 4340 Training err. 1.65997 Training err. RA 2.05895 Valid. err. 1.73636
2018-02-03 21:54:39,862 training [INFO ] Epoch 42 Batch 4360 Training err. 1.64440 Training err. RA 2.05705 Valid. err. 1.73531
2018-02-03 21:54:40,702 training [INFO ] Epoch 43 Batch 4380 Training err. 1.65713 Training err. RA 2.05522 Valid. err. 1.73880
2018-02-03 21:54:41,217 training [INFO ] Epoch 43 Batch 4400 Training err. 1.63185 Training err. RA 2.05330 Valid. err. 1.75088
2018-02-03 21:54:41,722 training [INFO ] Epoch 43 Batch 4420 Training err. 1.64010 Training err. RA 2.05143 Valid. err. 1.74099
2018-02-03 21:54:42,254 training [INFO ] Epoch 43 Batch 4440 Training err. 1.65225 Training err. RA 2.04963 Valid. err. 1.74425
2018-02-03 21:54:42,761 training [INFO ] Epoch 43 Batch 4460 Training err. 1.63742 Training err. RA 2.04778 Valid. err. 1.74364
2018-02-03 21:54:43,631 training [INFO ] Epoch 44 Batch 4480 Training err. 1.63207 Training err. RA 2.04592 Valid. err. 1.72057
2018-02-03 21:54:44,138 training [INFO ] Epoch 44 Batch 4500 Training err. 1.63532 Training err. RA 2.04410 Valid. err. 1.74099
2018-02-03 21:54:44,641 training [INFO ] Epoch 44 Batch 4520 Training err. 1.63640 Training err. RA 2.04230 Valid. err. 1.74407
2018-02-03 21:54:45,186 training [INFO ] Epoch 44 Batch 4540 Training err. 1.64541 Training err. RA 2.04055 Valid. err. 1.72744
2018-02-03 21:54:45,669 training [INFO ] Epoch 44 Batch 4560 Training err. 1.63032 Training err. RA 2.03875 Valid. err. 1.72701
2018-02-03 21:54:46,526 training [INFO ] Epoch 45 Batch 4580 Training err. 1.61427 Training err. RA 2.03689 Valid. err. 1.72579
2018-02-03 21:54:47,058 training [INFO ] Epoch 45 Batch 4600 Training err. 1.63968 Training err. RA 2.03517 Valid. err. 1.72367
2018-02-03 21:54:47,555 training [INFO ] Epoch 45 Batch 4620 Training err. 1.61978 Training err. RA 2.03337 Valid. err. 1.71822
2018-02-03 21:54:48,057 training [INFO ] Epoch 45 Batch 4640 Training err. 1.62233 Training err. RA 2.03160 Valid. err. 1.72447
2018-02-03 21:54:48,553 training [INFO ] Epoch 45 Batch 4660 Training err. 1.63189 Training err. RA 2.02988 Valid. err. 1.72672
2018-02-03 21:54:49,062 training [INFO ] Epoch 45 Batch 4680 Training err. 1.61359 Training err. RA 2.02810 Valid. err. 1.71454
2018-02-03 21:54:49,959 training [INFO ] Epoch 46 Batch 4700 Training err. 1.64741 Training err. RA 2.02648 Valid. err. 1.72564
2018-02-03 21:54:50,486 training [INFO ] Epoch 46 Batch 4720 Training err. 1.58895 Training err. RA 2.02463 Valid. err. 1.72465
2018-02-03 21:54:50,989 training [INFO ] Epoch 46 Batch 4740 Training err. 1.61645 Training err. RA 2.02291 Valid. err. 1.73287
2018-02-03 21:54:51,501 training [INFO ] Epoch 46 Batch 4760 Training err. 1.63629 Training err. RA 2.02128 Valid. err. 1.71253
2018-02-03 21:54:52,010 training [INFO ] Epoch 46 Batch 4780 Training err. 1.60773 Training err. RA 2.01955 Valid. err. 1.71516
2018-02-03 21:54:52,892 training [INFO ] Epoch 47 Batch 4800 Training err. 1.62582 Training err. RA 2.01791 Valid. err. 1.72479
2018-02-03 21:54:53,407 training [INFO ] Epoch 47 Batch 4820 Training err. 1.59999 Training err. RA 2.01618 Valid. err. 1.71917
2018-02-03 21:54:53,895 training [INFO ] Epoch 47 Batch 4840 Training err. 1.60599 Training err. RA 2.01448 Valid. err. 1.71459
2018-02-03 21:54:54,380 training [INFO ] Epoch 47 Batch 4860 Training err. 1.62320 Training err. RA 2.01287 Valid. err. 1.72659
2018-02-03 21:54:54,867 training [INFO ] Epoch 47 Batch 4880 Training err. 1.60902 Training err. RA 2.01122 Valid. err. 1.70809
2018-02-03 21:54:55,704 training [INFO ] Epoch 48 Batch 4900 Training err. 1.61883 Training err. RA 2.00962 Valid. err. 1.71783
2018-02-03 21:54:56,191 training [INFO ] Epoch 48 Batch 4920 Training err. 1.59574 Training err. RA 2.00793 Valid. err. 1.72213
2018-02-03 21:54:56,676 training [INFO ] Epoch 48 Batch 4940 Training err. 1.59977 Training err. RA 2.00628 Valid. err. 1.70954
2018-02-03 21:54:57,163 training [INFO ] Epoch 48 Batch 4960 Training err. 1.61696 Training err. RA 2.00471 Valid. err. 1.72372
2018-02-03 21:54:57,679 training [INFO ] Epoch 48 Batch 4980 Training err. 1.59958 Training err. RA 2.00308 Valid. err. 1.71518
2018-02-03 21:54:58,551 training [INFO ] Epoch 49 Batch 5000 Training err. 1.60072 Training err. RA 2.00147 Valid. err. 1.69115
2018-02-03 21:54:59,047 training [INFO ] Epoch 49 Batch 5020 Training err. 1.60092 Training err. RA 1.99988 Valid. err. 1.71453
2018-02-03 21:54:59,556 training [INFO ] Epoch 49 Batch 5040 Training err. 1.59932 Training err. RA 1.99829 Valid. err. 1.70489
2018-02-03 21:55:00,051 training [INFO ] Epoch 49 Batch 5060 Training err. 1.61066 Training err. RA 1.99676 Valid. err. 1.70107
2018-02-03 21:55:00,571 training [INFO ] Epoch 49 Batch 5080 Training err. 1.59148 Training err. RA 1.99516 Valid. err. 1.69384
2018-02-03 21:55:01,432 training [INFO ] Epoch 50 Batch 5100 Training err. 1.58113 Training err. RA 1.99354 Valid. err. 1.70222
2018-02-03 21:55:01,929 training [INFO ] Epoch 50 Batch 5120 Training err. 1.60433 Training err. RA 1.99202 Valid. err. 1.69771
2018-02-03 21:55:02,438 training [INFO ] Epoch 50 Batch 5140 Training err. 1.58445 Training err. RA 1.99043 Valid. err. 1.69485
2018-02-03 21:55:02,962 training [INFO ] Epoch 50 Batch 5160 Training err. 1.58749 Training err. RA 1.98887 Valid. err. 1.70586
2018-02-03 21:55:03,472 training [INFO ] Epoch 50 Batch 5180 Training err. 1.60011 Training err. RA 1.98737 Valid. err. 1.70056
2018-02-03 21:55:04,001 training [INFO ] Epoch 50 Batch 5200 Training err. 1.57935 Training err. RA 1.98580 Valid. err. 1.68494
2018-02-03 21:55:04,891 training [INFO ] Epoch 51 Batch 5220 Training err. 1.61126 Training err. RA 1.98436 Valid. err. 1.70986
2018-02-03 21:55:05,374 training [INFO ] Epoch 51 Batch 5240 Training err. 1.55502 Training err. RA 1.98273 Valid. err. 1.69901
2018-02-03 21:55:05,857 training [INFO ] Epoch 51 Batch 5260 Training err. 1.58338 Training err. RA 1.98121 Valid. err. 1.70089
2018-02-03 21:55:06,372 training [INFO ] Epoch 51 Batch 5280 Training err. 1.59752 Training err. RA 1.97975 Valid. err. 1.69038
2018-02-03 21:55:06,875 training [INFO ] Epoch 51 Batch 5300 Training err. 1.57499 Training err. RA 1.97823 Valid. err. 1.69022
2018-02-03 21:55:07,733 training [INFO ] Epoch 52 Batch 5320 Training err. 1.59820 Training err. RA 1.97680 Valid. err. 1.69438
2018-02-03 21:55:08,216 training [INFO ] Epoch 52 Batch 5340 Training err. 1.56697 Training err. RA 1.97526 Valid. err. 1.69301
2018-02-03 21:55:08,693 training [INFO ] Epoch 52 Batch 5360 Training err. 1.57398 Training err. RA 1.97377 Valid. err. 1.69153
2018-02-03 21:55:09,173 training [INFO ] Epoch 52 Batch 5380 Training err. 1.58940 Training err. RA 1.97234 Valid. err. 1.68446
2018-02-03 21:55:09,656 training [INFO ] Epoch 52 Batch 5400 Training err. 1.57215 Training err. RA 1.97085 Valid. err. 1.68766
2018-02-03 21:55:10,524 training [INFO ] Epoch 53 Batch 5420 Training err. 1.58495 Training err. RA 1.96943 Valid. err. 1.67210
2018-02-03 21:55:11,022 training [INFO ] Epoch 53 Batch 5440 Training err. 1.56558 Training err. RA 1.96795 Valid. err. 1.69248
2018-02-03 21:55:11,520 training [INFO ] Epoch 53 Batch 5460 Training err. 1.56923 Training err. RA 1.96648 Valid. err. 1.68669
2018-02-03 21:55:12,016 training [INFO ] Epoch 53 Batch 5480 Training err. 1.58816 Training err. RA 1.96510 Valid. err. 1.69688
2018-02-03 21:55:12,521 training [INFO ] Epoch 53 Batch 5500 Training err. 1.56844 Training err. RA 1.96366 Valid. err. 1.69136
2018-02-03 21:55:13,386 training [INFO ] Epoch 54 Batch 5520 Training err. 1.56425 Training err. RA 1.96221 Valid. err. 1.67295
2018-02-03 21:55:13,878 training [INFO ] Epoch 54 Batch 5540 Training err. 1.56958 Training err. RA 1.96080 Valid. err. 1.69409
2018-02-03 21:55:14,356 training [INFO ] Epoch 54 Batch 5560 Training err. 1.56977 Training err. RA 1.95939 Valid. err. 1.68721
2018-02-03 21:55:14,850 training [INFO ] Epoch 54 Batch 5580 Training err. 1.58315 Training err. RA 1.95804 Valid. err. 1.68045
2018-02-03 21:55:15,351 training [INFO ] Epoch 54 Batch 5600 Training err. 1.55978 Training err. RA 1.95662 Valid. err. 1.67796
2018-02-03 21:55:16,231 training [INFO ] Epoch 55 Batch 5620 Training err. 1.55231 Training err. RA 1.95518 Valid. err. 1.69128
2018-02-03 21:55:16,746 training [INFO ] Epoch 55 Batch 5640 Training err. 1.57636 Training err. RA 1.95384 Valid. err. 1.67193
2018-02-03 21:55:17,268 training [INFO ] Epoch 55 Batch 5660 Training err. 1.55490 Training err. RA 1.95243 Valid. err. 1.67309
2018-02-03 21:55:17,790 training [INFO ] Epoch 55 Batch 5680 Training err. 1.55761 Training err. RA 1.95104 Valid. err. 1.67918
2018-02-03 21:55:18,310 training [INFO ] Epoch 55 Batch 5700 Training err. 1.57124 Training err. RA 1.94971 Valid. err. 1.68057
2018-02-03 21:55:18,831 training [INFO ] Epoch 55 Batch 5720 Training err. 1.54826 Training err. RA 1.94830 Valid. err. 1.66601
2018-02-03 21:55:19,733 training [INFO ] Epoch 56 Batch 5740 Training err. 1.58247 Training err. RA 1.94703 Valid. err. 1.68537
2018-02-03 21:55:20,244 training [INFO ] Epoch 56 Batch 5760 Training err. 1.52594 Training err. RA 1.94556 Valid. err. 1.68451
2018-02-03 21:55:20,762 training [INFO ] Epoch 56 Batch 5780 Training err. 1.55611 Training err. RA 1.94422 Valid. err. 1.68379
2018-02-03 21:55:21,278 training [INFO ] Epoch 56 Batch 5800 Training err. 1.56781 Training err. RA 1.94292 Valid. err. 1.67457
2018-02-03 21:55:21,801 training [INFO ] Epoch 56 Batch 5820 Training err. 1.54548 Training err. RA 1.94155 Valid. err. 1.66889
2018-02-03 21:55:22,654 training [INFO ] Epoch 57 Batch 5840 Training err. 1.56258 Training err. RA 1.94026 Valid. err. 1.69059
2018-02-03 21:55:23,157 training [INFO ] Epoch 57 Batch 5860 Training err. 1.54364 Training err. RA 1.93890 Valid. err. 1.67448
2018-02-03 21:55:23,678 training [INFO ] Epoch 57 Batch 5880 Training err. 1.54570 Training err. RA 1.93756 Valid. err. 1.67009
2018-02-03 21:55:24,195 training [INFO ] Epoch 57 Batch 5900 Training err. 1.56403 Training err. RA 1.93630 Valid. err. 1.66569
2018-02-03 21:55:24,681 training [INFO ] Epoch 57 Batch 5920 Training err. 1.54354 Training err. RA 1.93497 Valid. err. 1.67205
2018-02-03 21:55:25,559 training [INFO ] Epoch 58 Batch 5940 Training err. 1.55776 Training err. RA 1.93370 Valid. err. 1.65300
2018-02-03 21:55:26,085 training [INFO ] Epoch 58 Batch 5960 Training err. 1.53880 Training err. RA 1.93238 Valid. err. 1.67182
2018-02-03 21:55:26,624 training [INFO ] Epoch 58 Batch 5980 Training err. 1.54065 Training err. RA 1.93107 Valid. err. 1.66537
2018-02-03 21:55:27,158 training [INFO ] Epoch 58 Batch 6000 Training err. 1.55987 Training err. RA 1.92983 Valid. err. 1.67726
2018-02-03 21:55:27,699 training [INFO ] Epoch 58 Batch 6020 Training err. 1.54077 Training err. RA 1.92854 Valid. err. 1.66903
2018-02-03 21:55:28,591 training [INFO ] Epoch 59 Batch 6040 Training err. 1.53821 Training err. RA 1.92724 Valid. err. 1.65573
2018-02-03 21:55:29,107 training [INFO ] Epoch 59 Batch 6060 Training err. 1.54195 Training err. RA 1.92597 Valid. err. 1.67514
2018-02-03 21:55:29,625 training [INFO ] Epoch 59 Batch 6080 Training err. 1.54195 Training err. RA 1.92471 Valid. err. 1.67194
2018-02-03 21:55:30,118 training [INFO ] Epoch 59 Batch 6100 Training err. 1.55494 Training err. RA 1.92350 Valid. err. 1.66308
2018-02-03 21:55:30,624 training [INFO ] Epoch 59 Batch 6120 Training err. 1.53278 Training err. RA 1.92222 Valid. err. 1.65860
2018-02-03 21:55:31,464 training [INFO ] Epoch 60 Batch 6140 Training err. 1.52507 Training err. RA 1.92093 Valid. err. 1.67518
2018-02-03 21:55:31,949 training [INFO ] Epoch 60 Batch 6160 Training err. 1.54854 Training err. RA 1.91972 Valid. err. 1.65908
2018-02-03 21:55:32,443 training [INFO ] Epoch 60 Batch 6180 Training err. 1.52800 Training err. RA 1.91845 Valid. err. 1.65543
2018-02-03 21:55:32,998 training [INFO ] Epoch 60 Batch 6200 Training err. 1.53232 Training err. RA 1.91720 Valid. err. 1.66234
2018-02-03 21:55:33,567 training [INFO ] Epoch 60 Batch 6220 Training err. 1.54488 Training err. RA 1.91601 Valid. err. 1.66483
2018-02-03 21:55:34,083 training [INFO ] Epoch 60 Batch 6240 Training err. 1.52322 Training err. RA 1.91475 Valid. err. 1.64973
2018-02-03 21:55:34,332 __main__ [INFO ] End of training
2018-02-03 21:55:34,575 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 10,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:55:34,575 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 21:55:35,210 training [INFO ] Epoch  1 Batch   20 Training err. 6.86979 Training err. RA 6.86979 Valid. err. 5.23495
2018-02-03 21:55:35,724 training [INFO ] Epoch  1 Batch   40 Training err. 5.43110 Training err. RA 6.15044 Valid. err. 6.48231
2018-02-03 21:55:36,231 training [INFO ] Epoch  1 Batch   60 Training err. 4.64479 Training err. RA 5.64856 Valid. err. 4.66602
2018-02-03 21:55:36,735 training [INFO ] Epoch  1 Batch   80 Training err. 4.37707 Training err. RA 5.33069 Valid. err. 4.82431
2018-02-03 21:55:37,227 training [INFO ] Epoch  1 Batch  100 Training err. 3.96628 Training err. RA 5.05781 Valid. err. 3.26173
2018-02-03 21:55:38,062 training [INFO ] Epoch  2 Batch  120 Training err. 3.94596 Training err. RA 4.87250 Valid. err. 3.14812
2018-02-03 21:55:38,584 training [INFO ] Epoch  2 Batch  140 Training err. 3.26824 Training err. RA 4.64332 Valid. err. 3.16011
2018-02-03 21:55:39,093 training [INFO ] Epoch  2 Batch  160 Training err. 3.16870 Training err. RA 4.45899 Valid. err. 3.36296
2018-02-03 21:55:39,608 training [INFO ] Epoch  2 Batch  180 Training err. 3.27175 Training err. RA 4.32708 Valid. err. 3.07677
2018-02-03 21:55:40,128 training [INFO ] Epoch  2 Batch  200 Training err. 3.12659 Training err. RA 4.20703 Valid. err. 3.13063
2018-02-03 21:55:41,010 training [INFO ] Epoch  3 Batch  220 Training err. 3.13350 Training err. RA 4.10943 Valid. err. 3.16886
2018-02-03 21:55:41,553 training [INFO ] Epoch  3 Batch  240 Training err. 3.06136 Training err. RA 4.02209 Valid. err. 3.41372
2018-02-03 21:55:42,056 training [INFO ] Epoch  3 Batch  260 Training err. 2.95915 Training err. RA 3.94033 Valid. err. 2.87520
2018-02-03 21:55:42,559 training [INFO ] Epoch  3 Batch  280 Training err. 3.09275 Training err. RA 3.87979 Valid. err. 3.23598
2018-02-03 21:55:43,061 training [INFO ] Epoch  3 Batch  300 Training err. 2.89978 Training err. RA 3.81445 Valid. err. 2.98416
2018-02-03 21:55:43,924 training [INFO ] Epoch  4 Batch  320 Training err. 3.03473 Training err. RA 3.76572 Valid. err. 2.85844
2018-02-03 21:55:44,428 training [INFO ] Epoch  4 Batch  340 Training err. 2.86996 Training err. RA 3.71303 Valid. err. 3.28802
2018-02-03 21:55:44,930 training [INFO ] Epoch  4 Batch  360 Training err. 2.85029 Training err. RA 3.66510 Valid. err. 2.81019
2018-02-03 21:55:45,415 training [INFO ] Epoch  4 Batch  380 Training err. 2.72989 Training err. RA 3.61588 Valid. err. 2.67957
2018-02-03 21:55:45,925 training [INFO ] Epoch  4 Batch  400 Training err. 2.75235 Training err. RA 3.57270 Valid. err. 2.77522
2018-02-03 21:55:46,776 training [INFO ] Epoch  5 Batch  420 Training err. 2.80343 Training err. RA 3.53607 Valid. err. 2.61294
2018-02-03 21:55:47,272 training [INFO ] Epoch  5 Batch  440 Training err. 2.65532 Training err. RA 3.49604 Valid. err. 2.81042
2018-02-03 21:55:47,783 training [INFO ] Epoch  5 Batch  460 Training err. 2.65150 Training err. RA 3.45932 Valid. err. 2.63603
2018-02-03 21:55:48,283 training [INFO ] Epoch  5 Batch  480 Training err. 2.57849 Training err. RA 3.42261 Valid. err. 2.56236
2018-02-03 21:55:48,781 training [INFO ] Epoch  5 Batch  500 Training err. 2.49186 Training err. RA 3.38538 Valid. err. 2.58647
2018-02-03 21:55:49,316 training [INFO ] Epoch  5 Batch  520 Training err. 2.52254 Training err. RA 3.35220 Valid. err. 2.42905
2018-02-03 21:55:50,201 training [INFO ] Epoch  6 Batch  540 Training err. 2.50313 Training err. RA 3.32075 Valid. err. 2.52653
2018-02-03 21:55:50,699 training [INFO ] Epoch  6 Batch  560 Training err. 2.49193 Training err. RA 3.29115 Valid. err. 2.45927
2018-02-03 21:55:51,197 training [INFO ] Epoch  6 Batch  580 Training err. 2.40049 Training err. RA 3.26044 Valid. err. 2.43431
2018-02-03 21:55:51,749 training [INFO ] Epoch  6 Batch  600 Training err. 2.41687 Training err. RA 3.23232 Valid. err. 2.41518
2018-02-03 21:55:52,270 training [INFO ] Epoch  6 Batch  620 Training err. 2.38103 Training err. RA 3.20486 Valid. err. 2.38608
2018-02-03 21:55:53,133 training [INFO ] Epoch  7 Batch  640 Training err. 2.37675 Training err. RA 3.17898 Valid. err. 2.33914
2018-02-03 21:55:53,642 training [INFO ] Epoch  7 Batch  660 Training err. 2.46227 Training err. RA 3.15726 Valid. err. 2.38484
2018-02-03 21:55:54,126 training [INFO ] Epoch  7 Batch  680 Training err. 2.34209 Training err. RA 3.13329 Valid. err. 2.36910
2018-02-03 21:55:54,606 training [INFO ] Epoch  7 Batch  700 Training err. 2.32949 Training err. RA 3.11032 Valid. err. 2.29554
2018-02-03 21:55:55,086 training [INFO ] Epoch  7 Batch  720 Training err. 2.30865 Training err. RA 3.08805 Valid. err. 2.31604
2018-02-03 21:55:55,914 training [INFO ] Epoch  8 Batch  740 Training err. 2.39902 Training err. RA 3.06943 Valid. err. 2.38152
2018-02-03 21:55:56,396 training [INFO ] Epoch  8 Batch  760 Training err. 2.28786 Training err. RA 3.04886 Valid. err. 2.35575
2018-02-03 21:55:56,878 training [INFO ] Epoch  8 Batch  780 Training err. 2.28584 Training err. RA 3.02930 Valid. err. 2.29370
2018-02-03 21:55:57,369 training [INFO ] Epoch  8 Batch  800 Training err. 2.25680 Training err. RA 3.00998 Valid. err. 2.25977
2018-02-03 21:55:57,868 training [INFO ] Epoch  8 Batch  820 Training err. 2.24553 Training err. RA 2.99134 Valid. err. 2.24536
2018-02-03 21:55:58,770 training [INFO ] Epoch  9 Batch  840 Training err. 2.30036 Training err. RA 2.97489 Valid. err. 2.29690
2018-02-03 21:55:59,267 training [INFO ] Epoch  9 Batch  860 Training err. 2.25658 Training err. RA 2.95818 Valid. err. 2.31887
2018-02-03 21:55:59,776 training [INFO ] Epoch  9 Batch  880 Training err. 2.23234 Training err. RA 2.94169 Valid. err. 2.24542
2018-02-03 21:56:00,301 training [INFO ] Epoch  9 Batch  900 Training err. 2.20187 Training err. RA 2.92525 Valid. err. 2.21595
2018-02-03 21:56:00,799 training [INFO ] Epoch  9 Batch  920 Training err. 2.20469 Training err. RA 2.90958 Valid. err. 2.20769
2018-02-03 21:56:01,690 training [INFO ] Epoch 10 Batch  940 Training err. 2.20890 Training err. RA 2.89467 Valid. err. 2.22115
2018-02-03 21:56:02,219 training [INFO ] Epoch 10 Batch  960 Training err. 2.22908 Training err. RA 2.88081 Valid. err. 2.19250
2018-02-03 21:56:02,716 training [INFO ] Epoch 10 Batch  980 Training err. 2.15514 Training err. RA 2.86600 Valid. err. 2.17658
2018-02-03 21:56:03,194 training [INFO ] Epoch 10 Batch 1000 Training err. 2.17312 Training err. RA 2.85214 Valid. err. 2.15931
2018-02-03 21:56:03,733 training [INFO ] Epoch 10 Batch 1020 Training err. 2.14149 Training err. RA 2.83821 Valid. err. 2.14653
2018-02-03 21:56:04,263 training [INFO ] Epoch 10 Batch 1040 Training err. 2.14838 Training err. RA 2.82494 Valid. err. 2.13978
2018-02-03 21:56:05,165 training [INFO ] Epoch 11 Batch 1060 Training err. 2.20667 Training err. RA 2.81327 Valid. err. 2.18033
2018-02-03 21:56:05,711 training [INFO ] Epoch 11 Batch 1080 Training err. 2.11393 Training err. RA 2.80032 Valid. err. 2.14497
2018-02-03 21:56:06,231 training [INFO ] Epoch 11 Batch 1100 Training err. 2.12881 Training err. RA 2.78811 Valid. err. 2.13202
2018-02-03 21:56:06,746 training [INFO ] Epoch 11 Batch 1120 Training err. 2.11308 Training err. RA 2.77606 Valid. err. 2.13064
2018-02-03 21:56:07,279 training [INFO ] Epoch 11 Batch 1140 Training err. 2.13269 Training err. RA 2.76477 Valid. err. 2.10098
2018-02-03 21:56:08,154 training [INFO ] Epoch 12 Batch 1160 Training err. 2.13329 Training err. RA 2.75388 Valid. err. 2.15583
2018-02-03 21:56:08,696 training [INFO ] Epoch 12 Batch 1180 Training err. 2.08884 Training err. RA 2.74261 Valid. err. 2.13837
2018-02-03 21:56:09,231 training [INFO ] Epoch 12 Batch 1200 Training err. 2.09305 Training err. RA 2.73179 Valid. err. 2.13516
2018-02-03 21:56:09,776 training [INFO ] Epoch 12 Batch 1220 Training err. 2.09008 Training err. RA 2.72127 Valid. err. 2.07713
2018-02-03 21:56:10,287 training [INFO ] Epoch 12 Batch 1240 Training err. 2.06495 Training err. RA 2.71068 Valid. err. 2.12489
2018-02-03 21:56:11,181 training [INFO ] Epoch 13 Batch 1260 Training err. 2.09506 Training err. RA 2.70091 Valid. err. 2.14538
2018-02-03 21:56:11,735 training [INFO ] Epoch 13 Batch 1280 Training err. 2.06336 Training err. RA 2.69095 Valid. err. 2.10286
2018-02-03 21:56:12,244 training [INFO ] Epoch 13 Batch 1300 Training err. 2.05236 Training err. RA 2.68112 Valid. err. 2.13962
2018-02-03 21:56:12,745 training [INFO ] Epoch 13 Batch 1320 Training err. 2.06843 Training err. RA 2.67184 Valid. err. 2.04466
2018-02-03 21:56:13,237 training [INFO ] Epoch 13 Batch 1340 Training err. 2.01635 Training err. RA 2.66206 Valid. err. 2.05236
2018-02-03 21:56:14,074 training [INFO ] Epoch 14 Batch 1360 Training err. 2.08433 Training err. RA 2.65356 Valid. err. 2.05856
2018-02-03 21:56:14,562 training [INFO ] Epoch 14 Batch 1380 Training err. 2.03872 Training err. RA 2.64465 Valid. err. 2.04863
2018-02-03 21:56:15,049 training [INFO ] Epoch 14 Batch 1400 Training err. 2.01269 Training err. RA 2.63562 Valid. err. 2.05183
2018-02-03 21:56:15,536 training [INFO ] Epoch 14 Batch 1420 Training err. 2.04022 Training err. RA 2.62724 Valid. err. 2.05792
2018-02-03 21:56:16,023 training [INFO ] Epoch 14 Batch 1440 Training err. 1.99753 Training err. RA 2.61849 Valid. err. 2.02731
2018-02-03 21:56:16,861 training [INFO ] Epoch 15 Batch 1460 Training err. 2.05128 Training err. RA 2.61072 Valid. err. 2.09465
2018-02-03 21:56:17,361 training [INFO ] Epoch 15 Batch 1480 Training err. 2.04318 Training err. RA 2.60305 Valid. err. 2.01110
2018-02-03 21:56:17,864 training [INFO ] Epoch 15 Batch 1500 Training err. 1.98011 Training err. RA 2.59474 Valid. err. 2.02052
2018-02-03 21:56:18,368 training [INFO ] Epoch 15 Batch 1520 Training err. 1.99276 Training err. RA 2.58682 Valid. err. 2.03065
2018-02-03 21:56:18,871 training [INFO ] Epoch 15 Batch 1540 Training err. 1.99648 Training err. RA 2.57916 Valid. err. 2.01990
2018-02-03 21:56:19,373 training [INFO ] Epoch 15 Batch 1560 Training err. 2.02279 Training err. RA 2.57202 Valid. err. 2.08818
2018-02-03 21:56:20,231 training [INFO ] Epoch 16 Batch 1580 Training err. 2.03921 Training err. RA 2.56528 Valid. err. 2.00229
2018-02-03 21:56:20,744 training [INFO ] Epoch 16 Batch 1600 Training err. 1.93807 Training err. RA 2.55744 Valid. err. 2.01235
2018-02-03 21:56:21,250 training [INFO ] Epoch 16 Batch 1620 Training err. 1.96150 Training err. RA 2.55008 Valid. err. 2.01046
2018-02-03 21:56:21,745 training [INFO ] Epoch 16 Batch 1640 Training err. 1.99423 Training err. RA 2.54330 Valid. err. 2.02282
2018-02-03 21:56:22,227 training [INFO ] Epoch 16 Batch 1660 Training err. 1.96318 Training err. RA 2.53631 Valid. err. 2.05334
2018-02-03 21:56:23,061 training [INFO ] Epoch 17 Batch 1680 Training err. 2.03306 Training err. RA 2.53032 Valid. err. 2.01601
2018-02-03 21:56:23,548 training [INFO ] Epoch 17 Batch 1700 Training err. 1.94265 Training err. RA 2.52341 Valid. err. 2.02715
2018-02-03 21:56:24,029 training [INFO ] Epoch 17 Batch 1720 Training err. 1.94108 Training err. RA 2.51664 Valid. err. 2.00887
2018-02-03 21:56:24,532 training [INFO ] Epoch 17 Batch 1740 Training err. 1.97041 Training err. RA 2.51036 Valid. err. 2.00576
2018-02-03 21:56:25,019 training [INFO ] Epoch 17 Batch 1760 Training err. 1.94419 Training err. RA 2.50393 Valid. err. 2.01128
2018-02-03 21:56:25,880 training [INFO ] Epoch 18 Batch 1780 Training err. 2.02915 Training err. RA 2.49859 Valid. err. 2.01748
2018-02-03 21:56:26,393 training [INFO ] Epoch 18 Batch 1800 Training err. 1.91988 Training err. RA 2.49216 Valid. err. 2.00127
2018-02-03 21:56:26,888 training [INFO ] Epoch 18 Batch 1820 Training err. 1.93064 Training err. RA 2.48599 Valid. err. 1.99763
2018-02-03 21:56:27,385 training [INFO ] Epoch 18 Batch 1840 Training err. 1.94860 Training err. RA 2.48015 Valid. err. 1.97170
2018-02-03 21:56:27,904 training [INFO ] Epoch 18 Batch 1860 Training err. 1.91592 Training err. RA 2.47408 Valid. err. 1.93656
2018-02-03 21:56:28,807 training [INFO ] Epoch 19 Batch 1880 Training err. 1.96231 Training err. RA 2.46864 Valid. err. 1.96190
2018-02-03 21:56:29,314 training [INFO ] Epoch 19 Batch 1900 Training err. 1.93761 Training err. RA 2.46305 Valid. err. 1.96949
2018-02-03 21:56:29,812 training [INFO ] Epoch 19 Batch 1920 Training err. 1.92222 Training err. RA 2.45741 Valid. err. 1.94415
2018-02-03 21:56:30,292 training [INFO ] Epoch 19 Batch 1940 Training err. 1.91927 Training err. RA 2.45187 Valid. err. 1.93121
2018-02-03 21:56:30,772 training [INFO ] Epoch 19 Batch 1960 Training err. 1.90341 Training err. RA 2.44627 Valid. err. 1.93146
2018-02-03 21:56:31,596 training [INFO ] Epoch 20 Batch 1980 Training err. 1.92827 Training err. RA 2.44104 Valid. err. 1.97093
2018-02-03 21:56:32,074 training [INFO ] Epoch 20 Batch 2000 Training err. 1.93445 Training err. RA 2.43597 Valid. err. 1.95266
2018-02-03 21:56:32,552 training [INFO ] Epoch 20 Batch 2020 Training err. 1.90535 Training err. RA 2.43072 Valid. err. 1.91746
2018-02-03 21:56:33,032 training [INFO ] Epoch 20 Batch 2040 Training err. 1.89025 Training err. RA 2.42542 Valid. err. 1.92421
2018-02-03 21:56:33,525 training [INFO ] Epoch 20 Batch 2060 Training err. 1.89663 Training err. RA 2.42029 Valid. err. 1.91120
2018-02-03 21:56:34,028 training [INFO ] Epoch 20 Batch 2080 Training err. 1.90689 Training err. RA 2.41535 Valid. err. 1.96386
2018-02-03 21:56:34,878 training [INFO ] Epoch 21 Batch 2100 Training err. 1.93570 Training err. RA 2.41078 Valid. err. 1.91609
2018-02-03 21:56:35,395 training [INFO ] Epoch 21 Batch 2120 Training err. 1.85398 Training err. RA 2.40553 Valid. err. 1.96879
2018-02-03 21:56:35,920 training [INFO ] Epoch 21 Batch 2140 Training err. 1.87408 Training err. RA 2.40056 Valid. err. 1.92323
2018-02-03 21:56:36,428 training [INFO ] Epoch 21 Batch 2160 Training err. 1.89922 Training err. RA 2.39592 Valid. err. 1.93301
2018-02-03 21:56:36,938 training [INFO ] Epoch 21 Batch 2180 Training err. 1.86306 Training err. RA 2.39103 Valid. err. 1.90488
2018-02-03 21:56:37,767 training [INFO ] Epoch 22 Batch 2200 Training err. 1.92111 Training err. RA 2.38676 Valid. err. 1.93065
2018-02-03 21:56:38,254 training [INFO ] Epoch 22 Batch 2220 Training err. 1.85273 Training err. RA 2.38195 Valid. err. 1.93682
2018-02-03 21:56:38,775 training [INFO ] Epoch 22 Batch 2240 Training err. 1.86682 Training err. RA 2.37735 Valid. err. 1.90524
2018-02-03 21:56:39,263 training [INFO ] Epoch 22 Batch 2260 Training err. 1.88718 Training err. RA 2.37301 Valid. err. 1.88398
2018-02-03 21:56:39,751 training [INFO ] Epoch 22 Batch 2280 Training err. 1.85376 Training err. RA 2.36846 Valid. err. 1.88319
2018-02-03 21:56:40,597 training [INFO ] Epoch 23 Batch 2300 Training err. 1.91139 Training err. RA 2.36448 Valid. err. 1.90249
2018-02-03 21:56:41,086 training [INFO ] Epoch 23 Batch 2320 Training err. 1.84026 Training err. RA 2.35996 Valid. err. 1.95451
2018-02-03 21:56:41,585 training [INFO ] Epoch 23 Batch 2340 Training err. 1.86197 Training err. RA 2.35571 Valid. err. 1.90706
2018-02-03 21:56:42,104 training [INFO ] Epoch 23 Batch 2360 Training err. 1.85757 Training err. RA 2.35148 Valid. err. 1.87517
2018-02-03 21:56:42,623 training [INFO ] Epoch 23 Batch 2380 Training err. 1.84003 Training err. RA 2.34719 Valid. err. 1.86524
2018-02-03 21:56:43,525 training [INFO ] Epoch 24 Batch 2400 Training err. 1.87640 Training err. RA 2.34326 Valid. err. 1.88426
2018-02-03 21:56:44,063 training [INFO ] Epoch 24 Batch 2420 Training err. 1.84653 Training err. RA 2.33916 Valid. err. 1.89556
2018-02-03 21:56:44,587 training [INFO ] Epoch 24 Batch 2440 Training err. 1.85329 Training err. RA 2.33518 Valid. err. 1.87869
2018-02-03 21:56:45,100 training [INFO ] Epoch 24 Batch 2460 Training err. 1.83534 Training err. RA 2.33111 Valid. err. 1.85759
2018-02-03 21:56:45,608 training [INFO ] Epoch 24 Batch 2480 Training err. 1.83429 Training err. RA 2.32710 Valid. err. 1.85185
2018-02-03 21:56:46,446 training [INFO ] Epoch 25 Batch 2500 Training err. 1.84634 Training err. RA 2.32326 Valid. err. 1.88367
2018-02-03 21:56:46,949 training [INFO ] Epoch 25 Batch 2520 Training err. 1.85003 Training err. RA 2.31950 Valid. err. 1.87139
2018-02-03 21:56:47,435 training [INFO ] Epoch 25 Batch 2540 Training err. 1.82777 Training err. RA 2.31563 Valid. err. 1.85753
2018-02-03 21:56:47,921 training [INFO ] Epoch 25 Batch 2560 Training err. 1.81083 Training err. RA 2.31169 Valid. err. 1.85188
2018-02-03 21:56:48,407 training [INFO ] Epoch 25 Batch 2580 Training err. 1.83230 Training err. RA 2.30797 Valid. err. 1.85277
2018-02-03 21:56:48,905 training [INFO ] Epoch 25 Batch 2600 Training err. 1.82962 Training err. RA 2.30429 Valid. err. 1.89202
2018-02-03 21:56:49,776 training [INFO ] Epoch 26 Batch 2620 Training err. 1.85080 Training err. RA 2.30083 Valid. err. 1.85077
2018-02-03 21:56:50,300 training [INFO ] Epoch 26 Batch 2640 Training err. 1.78303 Training err. RA 2.29691 Valid. err. 1.90119
2018-02-03 21:56:50,795 training [INFO ] Epoch 26 Batch 2660 Training err. 1.80357 Training err. RA 2.29320 Valid. err. 1.83825
2018-02-03 21:56:51,282 training [INFO ] Epoch 26 Batch 2680 Training err. 1.81940 Training err. RA 2.28966 Valid. err. 1.85778
2018-02-03 21:56:51,768 training [INFO ] Epoch 26 Batch 2700 Training err. 1.80554 Training err. RA 2.28608 Valid. err. 1.83440
2018-02-03 21:56:52,580 training [INFO ] Epoch 27 Batch 2720 Training err. 1.82539 Training err. RA 2.28269 Valid. err. 1.85772
2018-02-03 21:56:53,068 training [INFO ] Epoch 27 Batch 2740 Training err. 1.78511 Training err. RA 2.27906 Valid. err. 1.85434
2018-02-03 21:56:53,569 training [INFO ] Epoch 27 Batch 2760 Training err. 1.79817 Training err. RA 2.27557 Valid. err. 1.84499
2018-02-03 21:56:54,071 training [INFO ] Epoch 27 Batch 2780 Training err. 1.80581 Training err. RA 2.27219 Valid. err. 1.83113
2018-02-03 21:56:54,573 training [INFO ] Epoch 27 Batch 2800 Training err. 1.79466 Training err. RA 2.26878 Valid. err. 1.86297
2018-02-03 21:56:55,399 training [INFO ] Epoch 28 Batch 2820 Training err. 1.81818 Training err. RA 2.26559 Valid. err. 1.83040
2018-02-03 21:56:55,905 training [INFO ] Epoch 28 Batch 2840 Training err. 1.78050 Training err. RA 2.26217 Valid. err. 1.87183
2018-02-03 21:56:56,404 training [INFO ] Epoch 28 Batch 2860 Training err. 1.78392 Training err. RA 2.25882 Valid. err. 1.84331
2018-02-03 21:56:56,901 training [INFO ] Epoch 28 Batch 2880 Training err. 1.79626 Training err. RA 2.25561 Valid. err. 1.86381
2018-02-03 21:56:57,383 training [INFO ] Epoch 28 Batch 2900 Training err. 1.78311 Training err. RA 2.25235 Valid. err. 1.82710
2018-02-03 21:56:58,179 training [INFO ] Epoch 29 Batch 2920 Training err. 1.79139 Training err. RA 2.24920 Valid. err. 1.81341
2018-02-03 21:56:58,658 training [INFO ] Epoch 29 Batch 2940 Training err. 1.76639 Training err. RA 2.24591 Valid. err. 1.83380
2018-02-03 21:56:59,140 training [INFO ] Epoch 29 Batch 2960 Training err. 1.77213 Training err. RA 2.24271 Valid. err. 1.83637
2018-02-03 21:56:59,624 training [INFO ] Epoch 29 Batch 2980 Training err. 1.79786 Training err. RA 2.23973 Valid. err. 1.81300
2018-02-03 21:57:00,116 training [INFO ] Epoch 29 Batch 3000 Training err. 1.77019 Training err. RA 2.23660 Valid. err. 1.80591
2018-02-03 21:57:00,921 training [INFO ] Epoch 30 Batch 3020 Training err. 1.76628 Training err. RA 2.23348 Valid. err. 1.83505
2018-02-03 21:57:01,415 training [INFO ] Epoch 30 Batch 3040 Training err. 1.77391 Training err. RA 2.23046 Valid. err. 1.82597
2018-02-03 21:57:01,923 training [INFO ] Epoch 30 Batch 3060 Training err. 1.75299 Training err. RA 2.22734 Valid. err. 1.79919
2018-02-03 21:57:02,452 training [INFO ] Epoch 30 Batch 3080 Training err. 1.76352 Training err. RA 2.22432 Valid. err. 1.79215
2018-02-03 21:57:02,980 training [INFO ] Epoch 30 Batch 3100 Training err. 1.76390 Training err. RA 2.22135 Valid. err. 1.80735
2018-02-03 21:57:03,477 training [INFO ] Epoch 30 Batch 3120 Training err. 1.76749 Training err. RA 2.21844 Valid. err. 1.87827
2018-02-03 21:57:04,299 training [INFO ] Epoch 31 Batch 3140 Training err. 1.80043 Training err. RA 2.21578 Valid. err. 1.82059
2018-02-03 21:57:04,803 training [INFO ] Epoch 31 Batch 3160 Training err. 1.72024 Training err. RA 2.21265 Valid. err. 1.87432
2018-02-03 21:57:05,294 training [INFO ] Epoch 31 Batch 3180 Training err. 1.74420 Training err. RA 2.20970 Valid. err. 1.78657
2018-02-03 21:57:05,789 training [INFO ] Epoch 31 Batch 3200 Training err. 1.77046 Training err. RA 2.20695 Valid. err. 1.79368
2018-02-03 21:57:06,281 training [INFO ] Epoch 31 Batch 3220 Training err. 1.75196 Training err. RA 2.20413 Valid. err. 1.79451
2018-02-03 21:57:07,085 training [INFO ] Epoch 32 Batch 3240 Training err. 1.76619 Training err. RA 2.20143 Valid. err. 1.83004
2018-02-03 21:57:07,593 training [INFO ] Epoch 32 Batch 3260 Training err. 1.72221 Training err. RA 2.19849 Valid. err. 1.83093
2018-02-03 21:57:08,081 training [INFO ] Epoch 32 Batch 3280 Training err. 1.73491 Training err. RA 2.19566 Valid. err. 1.78939
2018-02-03 21:57:08,569 training [INFO ] Epoch 32 Batch 3300 Training err. 1.76092 Training err. RA 2.19302 Valid. err. 1.79288
2018-02-03 21:57:09,059 training [INFO ] Epoch 32 Batch 3320 Training err. 1.74377 Training err. RA 2.19032 Valid. err. 1.80100
2018-02-03 21:57:09,886 training [INFO ] Epoch 33 Batch 3340 Training err. 1.76800 Training err. RA 2.18779 Valid. err. 1.78245
2018-02-03 21:57:10,392 training [INFO ] Epoch 33 Batch 3360 Training err. 1.72167 Training err. RA 2.18501 Valid. err. 1.80034
2018-02-03 21:57:10,896 training [INFO ] Epoch 33 Batch 3380 Training err. 1.73830 Training err. RA 2.18237 Valid. err. 1.78511
2018-02-03 21:57:11,399 training [INFO ] Epoch 33 Batch 3400 Training err. 1.74345 Training err. RA 2.17979 Valid. err. 1.79495
2018-02-03 21:57:11,906 training [INFO ] Epoch 33 Batch 3420 Training err. 1.73015 Training err. RA 2.17716 Valid. err. 1.79678
2018-02-03 21:57:12,735 training [INFO ] Epoch 34 Batch 3440 Training err. 1.75110 Training err. RA 2.17468 Valid. err. 1.77877
2018-02-03 21:57:13,229 training [INFO ] Epoch 34 Batch 3460 Training err. 1.73010 Training err. RA 2.17211 Valid. err. 1.79514
2018-02-03 21:57:13,713 training [INFO ] Epoch 34 Batch 3480 Training err. 1.72480 Training err. RA 2.16954 Valid. err. 1.77602
2018-02-03 21:57:14,200 training [INFO ] Epoch 34 Batch 3500 Training err. 1.72315 Training err. RA 2.16699 Valid. err. 1.76808
2018-02-03 21:57:14,685 training [INFO ] Epoch 34 Batch 3520 Training err. 1.73105 Training err. RA 2.16451 Valid. err. 1.77335
2018-02-03 21:57:15,485 training [INFO ] Epoch 35 Batch 3540 Training err. 1.72678 Training err. RA 2.16204 Valid. err. 1.78755
2018-02-03 21:57:15,973 training [INFO ] Epoch 35 Batch 3560 Training err. 1.73230 Training err. RA 2.15963 Valid. err. 1.76531
2018-02-03 21:57:16,461 training [INFO ] Epoch 35 Batch 3580 Training err. 1.70657 Training err. RA 2.15710 Valid. err. 1.76815
2018-02-03 21:57:16,958 training [INFO ] Epoch 35 Batch 3600 Training err. 1.70067 Training err. RA 2.15456 Valid. err. 1.78773
2018-02-03 21:57:17,448 training [INFO ] Epoch 35 Batch 3620 Training err. 1.72725 Training err. RA 2.15220 Valid. err. 1.75525
2018-02-03 21:57:17,950 training [INFO ] Epoch 35 Batch 3640 Training err. 1.72512 Training err. RA 2.14985 Valid. err. 1.89305
2018-02-03 21:57:18,775 training [INFO ] Epoch 36 Batch 3660 Training err. 1.76107 Training err. RA 2.14773 Valid. err. 1.78376
2018-02-03 21:57:19,279 training [INFO ] Epoch 36 Batch 3680 Training err. 1.66709 Training err. RA 2.14512 Valid. err. 1.81285
2018-02-03 21:57:19,792 training [INFO ] Epoch 36 Batch 3700 Training err. 1.69698 Training err. RA 2.14269 Valid. err. 1.74940
2018-02-03 21:57:20,297 training [INFO ] Epoch 36 Batch 3720 Training err. 1.72721 Training err. RA 2.14046 Valid. err. 1.76408
2018-02-03 21:57:20,829 training [INFO ] Epoch 36 Batch 3740 Training err. 1.71117 Training err. RA 2.13816 Valid. err. 1.76490
2018-02-03 21:57:21,634 training [INFO ] Epoch 37 Batch 3760 Training err. 1.73088 Training err. RA 2.13600 Valid. err. 1.79907
2018-02-03 21:57:22,121 training [INFO ] Epoch 37 Batch 3780 Training err. 1.68689 Training err. RA 2.13362 Valid. err. 1.77963
2018-02-03 21:57:22,611 training [INFO ] Epoch 37 Batch 3800 Training err. 1.69769 Training err. RA 2.13133 Valid. err. 1.75771
2018-02-03 21:57:23,096 training [INFO ] Epoch 37 Batch 3820 Training err. 1.70888 Training err. RA 2.12912 Valid. err. 1.75182
2018-02-03 21:57:23,584 training [INFO ] Epoch 37 Batch 3840 Training err. 1.69983 Training err. RA 2.12688 Valid. err. 1.75366
2018-02-03 21:57:24,397 training [INFO ] Epoch 38 Batch 3860 Training err. 1.72679 Training err. RA 2.12481 Valid. err. 1.74651
2018-02-03 21:57:24,886 training [INFO ] Epoch 38 Batch 3880 Training err. 1.68340 Training err. RA 2.12253 Valid. err. 1.76377
2018-02-03 21:57:25,372 training [INFO ] Epoch 38 Batch 3900 Training err. 1.70428 Training err. RA 2.12039 Valid. err. 1.74246
2018-02-03 21:57:25,866 training [INFO ] Epoch 38 Batch 3920 Training err. 1.69291 Training err. RA 2.11821 Valid. err. 1.75380
2018-02-03 21:57:26,369 training [INFO ] Epoch 38 Batch 3940 Training err. 1.69335 Training err. RA 2.11605 Valid. err. 1.78039
2018-02-03 21:57:27,207 training [INFO ] Epoch 39 Batch 3960 Training err. 1.69767 Training err. RA 2.11394 Valid. err. 1.73776
2018-02-03 21:57:27,709 training [INFO ] Epoch 39 Batch 3980 Training err. 1.68528 Training err. RA 2.11178 Valid. err. 1.77301
2018-02-03 21:57:28,210 training [INFO ] Epoch 39 Batch 4000 Training err. 1.69342 Training err. RA 2.10969 Valid. err. 1.74243
2018-02-03 21:57:28,720 training [INFO ] Epoch 39 Batch 4020 Training err. 1.68897 Training err. RA 2.10760 Valid. err. 1.76975
2018-02-03 21:57:29,239 training [INFO ] Epoch 39 Batch 4040 Training err. 1.70430 Training err. RA 2.10560 Valid. err. 1.75369
2018-02-03 21:57:30,083 training [INFO ] Epoch 40 Batch 4060 Training err. 1.68854 Training err. RA 2.10355 Valid. err. 1.78512
2018-02-03 21:57:30,575 training [INFO ] Epoch 40 Batch 4080 Training err. 1.68978 Training err. RA 2.10152 Valid. err. 1.72934
2018-02-03 21:57:31,056 training [INFO ] Epoch 40 Batch 4100 Training err. 1.69205 Training err. RA 2.09952 Valid. err. 1.74364
2018-02-03 21:57:31,548 training [INFO ] Epoch 40 Batch 4120 Training err. 1.67155 Training err. RA 2.09744 Valid. err. 1.78143
2018-02-03 21:57:32,028 training [INFO ] Epoch 40 Batch 4140 Training err. 1.67880 Training err. RA 2.09542 Valid. err. 1.72756
2018-02-03 21:57:32,507 training [INFO ] Epoch 40 Batch 4160 Training err. 1.69105 Training err. RA 2.09348 Valid. err. 1.81578
2018-02-03 21:57:33,307 training [INFO ] Epoch 41 Batch 4180 Training err. 1.70297 Training err. RA 2.09161 Valid. err. 1.72127
2018-02-03 21:57:33,800 training [INFO ] Epoch 41 Batch 4200 Training err. 1.64091 Training err. RA 2.08946 Valid. err. 1.79104
2018-02-03 21:57:34,312 training [INFO ] Epoch 41 Batch 4220 Training err. 1.67873 Training err. RA 2.08751 Valid. err. 1.72552
2018-02-03 21:57:34,847 training [INFO ] Epoch 41 Batch 4240 Training err. 1.67285 Training err. RA 2.08556 Valid. err. 1.72956
2018-02-03 21:57:35,356 training [INFO ] Epoch 41 Batch 4260 Training err. 1.69069 Training err. RA 2.08371 Valid. err. 1.73717
2018-02-03 21:57:36,190 training [INFO ] Epoch 42 Batch 4280 Training err. 1.68027 Training err. RA 2.08182 Valid. err. 1.73909
2018-02-03 21:57:36,706 training [INFO ] Epoch 42 Batch 4300 Training err. 1.65057 Training err. RA 2.07981 Valid. err. 1.79241
2018-02-03 21:57:37,243 training [INFO ] Epoch 42 Batch 4320 Training err. 1.68081 Training err. RA 2.07797 Valid. err. 1.73820
2018-02-03 21:57:37,750 training [INFO ] Epoch 42 Batch 4340 Training err. 1.67315 Training err. RA 2.07610 Valid. err. 1.71979
2018-02-03 21:57:38,270 training [INFO ] Epoch 42 Batch 4360 Training err. 1.66880 Training err. RA 2.07423 Valid. err. 1.73377
2018-02-03 21:57:39,084 training [INFO ] Epoch 43 Batch 4380 Training err. 1.69710 Training err. RA 2.07251 Valid. err. 1.70607
2018-02-03 21:57:39,583 training [INFO ] Epoch 43 Batch 4400 Training err. 1.63648 Training err. RA 2.07053 Valid. err. 1.72040
2018-02-03 21:57:40,097 training [INFO ] Epoch 43 Batch 4420 Training err. 1.67701 Training err. RA 2.06875 Valid. err. 1.72372
2018-02-03 21:57:40,575 training [INFO ] Epoch 43 Batch 4440 Training err. 1.65966 Training err. RA 2.06691 Valid. err. 1.71582
2018-02-03 21:57:41,057 training [INFO ] Epoch 43 Batch 4460 Training err. 1.65422 Training err. RA 2.06505 Valid. err. 1.72814
2018-02-03 21:57:41,894 training [INFO ] Epoch 44 Batch 4480 Training err. 1.67086 Training err. RA 2.06330 Valid. err. 1.71795
2018-02-03 21:57:42,406 training [INFO ] Epoch 44 Batch 4500 Training err. 1.65205 Training err. RA 2.06147 Valid. err. 1.72708
2018-02-03 21:57:42,931 training [INFO ] Epoch 44 Batch 4520 Training err. 1.67458 Training err. RA 2.05976 Valid. err. 1.72799
2018-02-03 21:57:43,434 training [INFO ] Epoch 44 Batch 4540 Training err. 1.66683 Training err. RA 2.05802 Valid. err. 1.70594
2018-02-03 21:57:43,941 training [INFO ] Epoch 44 Batch 4560 Training err. 1.66530 Training err. RA 2.05630 Valid. err. 1.71934
2018-02-03 21:57:44,793 training [INFO ] Epoch 45 Batch 4580 Training err. 1.66261 Training err. RA 2.05458 Valid. err. 1.73295
2018-02-03 21:57:45,316 training [INFO ] Epoch 45 Batch 4600 Training err. 1.65822 Training err. RA 2.05286 Valid. err. 1.69714
2018-02-03 21:57:45,844 training [INFO ] Epoch 45 Batch 4620 Training err. 1.65656 Training err. RA 2.05114 Valid. err. 1.75950
2018-02-03 21:57:46,342 training [INFO ] Epoch 45 Batch 4640 Training err. 1.64970 Training err. RA 2.04941 Valid. err. 1.72192
2018-02-03 21:57:46,820 training [INFO ] Epoch 45 Batch 4660 Training err. 1.64143 Training err. RA 2.04766 Valid. err. 1.71140
2018-02-03 21:57:47,300 training [INFO ] Epoch 45 Batch 4680 Training err. 1.66344 Training err. RA 2.04602 Valid. err. 1.75943
2018-02-03 21:57:48,120 training [INFO ] Epoch 46 Batch 4700 Training err. 1.67348 Training err. RA 2.04444 Valid. err. 1.69816
2018-02-03 21:57:48,612 training [INFO ] Epoch 46 Batch 4720 Training err. 1.60655 Training err. RA 2.04258 Valid. err. 1.77375
2018-02-03 21:57:49,092 training [INFO ] Epoch 46 Batch 4740 Training err. 1.64130 Training err. RA 2.04089 Valid. err. 1.70601
2018-02-03 21:57:49,618 training [INFO ] Epoch 46 Batch 4760 Training err. 1.66956 Training err. RA 2.03933 Valid. err. 1.70367
2018-02-03 21:57:50,128 training [INFO ] Epoch 46 Batch 4780 Training err. 1.64628 Training err. RA 2.03768 Valid. err. 1.72582
2018-02-03 21:57:50,955 training [INFO ] Epoch 47 Batch 4800 Training err. 1.65203 Training err. RA 2.03608 Valid. err. 1.70760
2018-02-03 21:57:51,453 training [INFO ] Epoch 47 Batch 4820 Training err. 1.61347 Training err. RA 2.03432 Valid. err. 1.72844
2018-02-03 21:57:51,960 training [INFO ] Epoch 47 Batch 4840 Training err. 1.64525 Training err. RA 2.03271 Valid. err. 1.72494
2018-02-03 21:57:52,463 training [INFO ] Epoch 47 Batch 4860 Training err. 1.64483 Training err. RA 2.03112 Valid. err. 1.71032
2018-02-03 21:57:52,975 training [INFO ] Epoch 47 Batch 4880 Training err. 1.63803 Training err. RA 2.02951 Valid. err. 1.70690
2018-02-03 21:57:54,077 training [INFO ] Epoch 48 Batch 4900 Training err. 1.65837 Training err. RA 2.02799 Valid. err. 1.69288
2018-02-03 21:57:54,739 training [INFO ] Epoch 48 Batch 4920 Training err. 1.61299 Training err. RA 2.02630 Valid. err. 1.70314
2018-02-03 21:57:55,400 training [INFO ] Epoch 48 Batch 4940 Training err. 1.64434 Training err. RA 2.02476 Valid. err. 1.70708
2018-02-03 21:57:56,095 training [INFO ] Epoch 48 Batch 4960 Training err. 1.64264 Training err. RA 2.02322 Valid. err. 1.70471
2018-02-03 21:57:56,788 training [INFO ] Epoch 48 Batch 4980 Training err. 1.62899 Training err. RA 2.02163 Valid. err. 1.69141
2018-02-03 21:57:57,754 training [INFO ] Epoch 49 Batch 5000 Training err. 1.63701 Training err. RA 2.02010 Valid. err. 1.68934
2018-02-03 21:57:58,246 training [INFO ] Epoch 49 Batch 5020 Training err. 1.62400 Training err. RA 2.01852 Valid. err. 1.69994
2018-02-03 21:57:58,736 training [INFO ] Epoch 49 Batch 5040 Training err. 1.63825 Training err. RA 2.01701 Valid. err. 1.70731
2018-02-03 21:57:59,222 training [INFO ] Epoch 49 Batch 5060 Training err. 1.64121 Training err. RA 2.01552 Valid. err. 1.68049
2018-02-03 21:57:59,708 training [INFO ] Epoch 49 Batch 5080 Training err. 1.61805 Training err. RA 2.01396 Valid. err. 1.67874
2018-02-03 21:58:00,516 training [INFO ] Epoch 50 Batch 5100 Training err. 1.62712 Training err. RA 2.01244 Valid. err. 1.71471
2018-02-03 21:58:01,004 training [INFO ] Epoch 50 Batch 5120 Training err. 1.63564 Training err. RA 2.01097 Valid. err. 1.69206
2018-02-03 21:58:01,491 training [INFO ] Epoch 50 Batch 5140 Training err. 1.62630 Training err. RA 2.00947 Valid. err. 1.69796
2018-02-03 21:58:01,976 training [INFO ] Epoch 50 Batch 5160 Training err. 1.61258 Training err. RA 2.00793 Valid. err. 1.72990
2018-02-03 21:58:02,460 training [INFO ] Epoch 50 Batch 5180 Training err. 1.62762 Training err. RA 2.00647 Valid. err. 1.69586
2018-02-03 21:58:02,949 training [INFO ] Epoch 50 Batch 5200 Training err. 1.63050 Training err. RA 2.00502 Valid. err. 1.69724
2018-02-03 21:58:03,746 training [INFO ] Epoch 51 Batch 5220 Training err. 1.63864 Training err. RA 2.00362 Valid. err. 1.68998
2018-02-03 21:58:04,232 training [INFO ] Epoch 51 Batch 5240 Training err. 1.59075 Training err. RA 2.00204 Valid. err. 1.79459
2018-02-03 21:58:04,719 training [INFO ] Epoch 51 Batch 5260 Training err. 1.64182 Training err. RA 2.00067 Valid. err. 1.69429
2018-02-03 21:58:05,208 training [INFO ] Epoch 51 Batch 5280 Training err. 1.61930 Training err. RA 1.99923 Valid. err. 1.67090
2018-02-03 21:58:05,696 training [INFO ] Epoch 51 Batch 5300 Training err. 1.62121 Training err. RA 1.99780 Valid. err. 1.70185
2018-02-03 21:58:06,505 training [INFO ] Epoch 52 Batch 5320 Training err. 1.63069 Training err. RA 1.99642 Valid. err. 1.69889
2018-02-03 21:58:06,992 training [INFO ] Epoch 52 Batch 5340 Training err. 1.59175 Training err. RA 1.99490 Valid. err. 1.69054
2018-02-03 21:58:07,477 training [INFO ] Epoch 52 Batch 5360 Training err. 1.64128 Training err. RA 1.99358 Valid. err. 1.67728
2018-02-03 21:58:07,962 training [INFO ] Epoch 52 Batch 5380 Training err. 1.61451 Training err. RA 1.99218 Valid. err. 1.68331
2018-02-03 21:58:08,448 training [INFO ] Epoch 52 Batch 5400 Training err. 1.61284 Training err. RA 1.99077 Valid. err. 1.68315
2018-02-03 21:58:09,256 training [INFO ] Epoch 53 Batch 5420 Training err. 1.63535 Training err. RA 1.98946 Valid. err. 1.68464
2018-02-03 21:58:09,742 training [INFO ] Epoch 53 Batch 5440 Training err. 1.59182 Training err. RA 1.98800 Valid. err. 1.67554
2018-02-03 21:58:10,229 training [INFO ] Epoch 53 Batch 5460 Training err. 1.60832 Training err. RA 1.98661 Valid. err. 1.67712
2018-02-03 21:58:10,742 training [INFO ] Epoch 53 Batch 5480 Training err. 1.63473 Training err. RA 1.98532 Valid. err. 1.69717
2018-02-03 21:58:11,261 training [INFO ] Epoch 53 Batch 5500 Training err. 1.61216 Training err. RA 1.98397 Valid. err. 1.66452
2018-02-03 21:58:12,112 training [INFO ] Epoch 54 Batch 5520 Training err. 1.60832 Training err. RA 1.98260 Valid. err. 1.67511
2018-02-03 21:58:12,622 training [INFO ] Epoch 54 Batch 5540 Training err. 1.60216 Training err. RA 1.98123 Valid. err. 1.66894
2018-02-03 21:58:13,133 training [INFO ] Epoch 54 Batch 5560 Training err. 1.62079 Training err. RA 1.97993 Valid. err. 1.69728
2018-02-03 21:58:13,628 training [INFO ] Epoch 54 Batch 5580 Training err. 1.61930 Training err. RA 1.97864 Valid. err. 1.66235
2018-02-03 21:58:14,124 training [INFO ] Epoch 54 Batch 5600 Training err. 1.59330 Training err. RA 1.97727 Valid. err. 1.65242
2018-02-03 21:58:14,950 training [INFO ] Epoch 55 Batch 5620 Training err. 1.59498 Training err. RA 1.97590 Valid. err. 1.68084
2018-02-03 21:58:15,448 training [INFO ] Epoch 55 Batch 5640 Training err. 1.61446 Training err. RA 1.97462 Valid. err. 1.66801
2018-02-03 21:58:15,946 training [INFO ] Epoch 55 Batch 5660 Training err. 1.59111 Training err. RA 1.97327 Valid. err. 1.68669
2018-02-03 21:58:16,466 training [INFO ] Epoch 55 Batch 5680 Training err. 1.59613 Training err. RA 1.97194 Valid. err. 1.74873
2018-02-03 21:58:17,005 training [INFO ] Epoch 55 Batch 5700 Training err. 1.61724 Training err. RA 1.97070 Valid. err. 1.68091
2018-02-03 21:58:17,493 training [INFO ] Epoch 55 Batch 5720 Training err. 1.60219 Training err. RA 1.96941 Valid. err. 1.67491
2018-02-03 21:58:18,302 training [INFO ] Epoch 56 Batch 5740 Training err. 1.61954 Training err. RA 1.96819 Valid. err. 1.65883
2018-02-03 21:58:18,797 training [INFO ] Epoch 56 Batch 5760 Training err. 1.56793 Training err. RA 1.96680 Valid. err. 1.78253
2018-02-03 21:58:19,284 training [INFO ] Epoch 56 Batch 5780 Training err. 1.61568 Training err. RA 1.96558 Valid. err. 1.66818
2018-02-03 21:58:19,775 training [INFO ] Epoch 56 Batch 5800 Training err. 1.59323 Training err. RA 1.96430 Valid. err. 1.65130
2018-02-03 21:58:20,310 training [INFO ] Epoch 56 Batch 5820 Training err. 1.59629 Training err. RA 1.96303 Valid. err. 1.68210
2018-02-03 21:58:21,156 training [INFO ] Epoch 57 Batch 5840 Training err. 1.60688 Training err. RA 1.96181 Valid. err. 1.67523
2018-02-03 21:58:21,674 training [INFO ] Epoch 57 Batch 5860 Training err. 1.57634 Training err. RA 1.96050 Valid. err. 1.67223
2018-02-03 21:58:22,183 training [INFO ] Epoch 57 Batch 5880 Training err. 1.59625 Training err. RA 1.95926 Valid. err. 1.67261
2018-02-03 21:58:22,680 training [INFO ] Epoch 57 Batch 5900 Training err. 1.60458 Training err. RA 1.95806 Valid. err. 1.67211
2018-02-03 21:58:23,168 training [INFO ] Epoch 57 Batch 5920 Training err. 1.59713 Training err. RA 1.95684 Valid. err. 1.65052
2018-02-03 21:58:23,972 training [INFO ] Epoch 58 Batch 5940 Training err. 1.60473 Training err. RA 1.95565 Valid. err. 1.66176
2018-02-03 21:58:24,461 training [INFO ] Epoch 58 Batch 5960 Training err. 1.56930 Training err. RA 1.95436 Valid. err. 1.65741
2018-02-03 21:58:24,949 training [INFO ] Epoch 58 Batch 5980 Training err. 1.60692 Training err. RA 1.95319 Valid. err. 1.66156
2018-02-03 21:58:25,436 training [INFO ] Epoch 58 Batch 6000 Training err. 1.59685 Training err. RA 1.95201 Valid. err. 1.65749
2018-02-03 21:58:25,948 training [INFO ] Epoch 58 Batch 6020 Training err. 1.58586 Training err. RA 1.95079 Valid. err. 1.64208
2018-02-03 21:58:26,775 training [INFO ] Epoch 59 Batch 6040 Training err. 1.59090 Training err. RA 1.94960 Valid. err. 1.66172
2018-02-03 21:58:27,272 training [INFO ] Epoch 59 Batch 6060 Training err. 1.58998 Training err. RA 1.94841 Valid. err. 1.66281
2018-02-03 21:58:27,791 training [INFO ] Epoch 59 Batch 6080 Training err. 1.58587 Training err. RA 1.94722 Valid. err. 1.66952
2018-02-03 21:58:28,281 training [INFO ] Epoch 59 Batch 6100 Training err. 1.60166 Training err. RA 1.94609 Valid. err. 1.64855
2018-02-03 21:58:28,808 training [INFO ] Epoch 59 Batch 6120 Training err. 1.58593 Training err. RA 1.94491 Valid. err. 1.63890
2018-02-03 21:58:29,651 training [INFO ] Epoch 60 Batch 6140 Training err. 1.57416 Training err. RA 1.94370 Valid. err. 1.64171
2018-02-03 21:58:30,162 training [INFO ] Epoch 60 Batch 6160 Training err. 1.58828 Training err. RA 1.94255 Valid. err. 1.66701
2018-02-03 21:58:30,662 training [INFO ] Epoch 60 Batch 6180 Training err. 1.58565 Training err. RA 1.94139 Valid. err. 1.69328
2018-02-03 21:58:31,184 training [INFO ] Epoch 60 Batch 6200 Training err. 1.59012 Training err. RA 1.94026 Valid. err. 1.67139
2018-02-03 21:58:31,672 training [INFO ] Epoch 60 Batch 6220 Training err. 1.57816 Training err. RA 1.93910 Valid. err. 1.65331
2018-02-03 21:58:32,159 training [INFO ] Epoch 60 Batch 6240 Training err. 1.57966 Training err. RA 1.93794 Valid. err. 1.65994
2018-02-03 21:58:32,397 __main__ [INFO ] End of training
2018-02-03 21:58:32,629 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 10,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 21:58:33,175 training [INFO ] Epoch  1 Batch   20 Training err. 4.23200 Training err. RA 4.23200 Valid. err. 4.15878
2018-02-03 21:58:33,647 training [INFO ] Epoch  1 Batch   40 Training err. 4.05239 Training err. RA 4.14220 Valid. err. 3.99617
2018-02-03 21:58:34,125 training [INFO ] Epoch  1 Batch   60 Training err. 3.89805 Training err. RA 4.06082 Valid. err. 3.82542
2018-02-03 21:58:34,617 training [INFO ] Epoch  1 Batch   80 Training err. 3.72414 Training err. RA 3.97665 Valid. err. 3.65016
2018-02-03 21:58:35,094 training [INFO ] Epoch  1 Batch  100 Training err. 3.53621 Training err. RA 3.88856 Valid. err. 3.51038
2018-02-03 21:58:35,577 training [INFO ] Epoch  1 Batch  120 Training err. 3.43117 Training err. RA 3.81233 Valid. err. 3.39884
2018-02-03 21:58:36,081 training [INFO ] Epoch  1 Batch  140 Training err. 3.31355 Training err. RA 3.74108 Valid. err. 3.32102
2018-02-03 21:58:36,571 training [INFO ] Epoch  1 Batch  160 Training err. 3.23218 Training err. RA 3.67746 Valid. err. 3.27647
2018-02-03 21:58:37,050 training [INFO ] Epoch  1 Batch  180 Training err. 3.23970 Training err. RA 3.62882 Valid. err. 3.25215
2018-02-03 21:58:37,522 training [INFO ] Epoch  1 Batch  200 Training err. 3.22765 Training err. RA 3.58871 Valid. err. 3.23358
2018-02-03 21:58:38,427 training [INFO ] Epoch  2 Batch  220 Training err. 3.19297 Training err. RA 3.55273 Valid. err. 3.22777
2018-02-03 21:58:38,900 training [INFO ] Epoch  2 Batch  240 Training err. 3.10741 Training err. RA 3.51562 Valid. err. 3.24653
2018-02-03 21:58:39,415 training [INFO ] Epoch  2 Batch  260 Training err. 3.19026 Training err. RA 3.49059 Valid. err. 3.20885
2018-02-03 21:58:39,933 training [INFO ] Epoch  2 Batch  280 Training err. 3.14494 Training err. RA 3.46590 Valid. err. 3.20466
2018-02-03 21:58:40,464 training [INFO ] Epoch  2 Batch  300 Training err. 3.13858 Training err. RA 3.44408 Valid. err. 3.20391
2018-02-03 21:58:40,995 training [INFO ] Epoch  2 Batch  320 Training err. 3.17087 Training err. RA 3.42701 Valid. err. 3.19702
2018-02-03 21:58:41,483 training [INFO ] Epoch  2 Batch  340 Training err. 3.14691 Training err. RA 3.41053 Valid. err. 3.19677
2018-02-03 21:58:41,994 training [INFO ] Epoch  2 Batch  360 Training err. 3.13354 Training err. RA 3.39514 Valid. err. 3.19439
2018-02-03 21:58:42,498 training [INFO ] Epoch  2 Batch  380 Training err. 3.12594 Training err. RA 3.38097 Valid. err. 3.19079
2018-02-03 21:58:43,001 training [INFO ] Epoch  2 Batch  400 Training err. 3.16975 Training err. RA 3.37041 Valid. err. 3.18838
2018-02-03 21:58:43,834 training [INFO ] Epoch  3 Batch  420 Training err. 3.16463 Training err. RA 3.36061 Valid. err. 3.18807
2018-02-03 21:58:44,309 training [INFO ] Epoch  3 Batch  440 Training err. 3.12729 Training err. RA 3.35001 Valid. err. 3.19230
2018-02-03 21:58:44,790 training [INFO ] Epoch  3 Batch  460 Training err. 3.11427 Training err. RA 3.33976 Valid. err. 3.18546
2018-02-03 21:58:45,269 training [INFO ] Epoch  3 Batch  480 Training err. 3.12075 Training err. RA 3.33063 Valid. err. 3.18629
2018-02-03 21:58:45,741 training [INFO ] Epoch  3 Batch  500 Training err. 3.10783 Training err. RA 3.32172 Valid. err. 3.19204
2018-02-03 21:58:46,214 training [INFO ] Epoch  3 Batch  520 Training err. 3.16296 Training err. RA 3.31561 Valid. err. 3.18762
2018-02-03 21:58:46,688 training [INFO ] Epoch  3 Batch  540 Training err. 3.15269 Training err. RA 3.30958 Valid. err. 3.18593
2018-02-03 21:58:47,161 training [INFO ] Epoch  3 Batch  560 Training err. 3.11920 Training err. RA 3.30278 Valid. err. 3.18569
2018-02-03 21:58:47,635 training [INFO ] Epoch  3 Batch  580 Training err. 3.08246 Training err. RA 3.29518 Valid. err. 3.18839
2018-02-03 21:58:48,109 training [INFO ] Epoch  3 Batch  600 Training err. 3.16298 Training err. RA 3.29078 Valid. err. 3.18260
2018-02-03 21:58:48,582 training [INFO ] Epoch  3 Batch  620 Training err. 3.16331 Training err. RA 3.28666 Valid. err. 3.17938
2018-02-03 21:58:49,391 training [INFO ] Epoch  4 Batch  640 Training err. 3.13494 Training err. RA 3.28192 Valid. err. 3.18208
2018-02-03 21:58:49,873 training [INFO ] Epoch  4 Batch  660 Training err. 3.07745 Training err. RA 3.27573 Valid. err. 3.18272
2018-02-03 21:58:50,350 training [INFO ] Epoch  4 Batch  680 Training err. 3.13531 Training err. RA 3.27160 Valid. err. 3.18227
2018-02-03 21:58:50,826 training [INFO ] Epoch  4 Batch  700 Training err. 3.11988 Training err. RA 3.26726 Valid. err. 3.18108
2018-02-03 21:58:51,302 training [INFO ] Epoch  4 Batch  720 Training err. 3.11157 Training err. RA 3.26294 Valid. err. 3.18366
2018-02-03 21:58:51,777 training [INFO ] Epoch  4 Batch  740 Training err. 3.16561 Training err. RA 3.26031 Valid. err. 3.17940
2018-02-03 21:58:52,253 training [INFO ] Epoch  4 Batch  760 Training err. 3.11290 Training err. RA 3.25643 Valid. err. 3.18213
2018-02-03 21:58:52,729 training [INFO ] Epoch  4 Batch  780 Training err. 3.11241 Training err. RA 3.25273 Valid. err. 3.17999
2018-02-03 21:58:53,203 training [INFO ] Epoch  4 Batch  800 Training err. 3.12170 Training err. RA 3.24946 Valid. err. 3.17936
2018-02-03 21:58:53,674 training [INFO ] Epoch  4 Batch  820 Training err. 3.14690 Training err. RA 3.24696 Valid. err. 3.17763
2018-02-03 21:58:54,479 training [INFO ] Epoch  5 Batch  840 Training err. 3.15597 Training err. RA 3.24479 Valid. err. 3.17497
2018-02-03 21:58:54,951 training [INFO ] Epoch  5 Batch  860 Training err. 3.07857 Training err. RA 3.24093 Valid. err. 3.20201
2018-02-03 21:58:55,421 training [INFO ] Epoch  5 Batch  880 Training err. 3.13210 Training err. RA 3.23845 Valid. err. 3.17688
2018-02-03 21:58:55,895 training [INFO ] Epoch  5 Batch  900 Training err. 3.11349 Training err. RA 3.23568 Valid. err. 3.17669
2018-02-03 21:58:56,369 training [INFO ] Epoch  5 Batch  920 Training err. 3.09108 Training err. RA 3.23253 Valid. err. 3.18060
2018-02-03 21:58:56,842 training [INFO ] Epoch  5 Batch  940 Training err. 3.15299 Training err. RA 3.23084 Valid. err. 3.17940
2018-02-03 21:58:57,317 training [INFO ] Epoch  5 Batch  960 Training err. 3.12470 Training err. RA 3.22863 Valid. err. 3.17961
2018-02-03 21:58:57,800 training [INFO ] Epoch  5 Batch  980 Training err. 3.11708 Training err. RA 3.22635 Valid. err. 3.17535
2018-02-03 21:58:58,372 training [INFO ] Epoch  5 Batch 1000 Training err. 3.08074 Training err. RA 3.22344 Valid. err. 3.17476
2018-02-03 21:58:58,877 training [INFO ] Epoch  5 Batch 1020 Training err. 3.15843 Training err. RA 3.22216 Valid. err. 3.17281
2018-02-03 21:58:59,372 training [INFO ] Epoch  5 Batch 1040 Training err. 3.14399 Training err. RA 3.22066 Valid. err. 3.16945
2018-02-03 21:59:00,223 training [INFO ] Epoch  6 Batch 1060 Training err. 3.11024 Training err. RA 3.21858 Valid. err. 3.17207
2018-02-03 21:59:00,701 training [INFO ] Epoch  6 Batch 1080 Training err. 3.08984 Training err. RA 3.21619 Valid. err. 3.17190
2018-02-03 21:59:01,179 training [INFO ] Epoch  6 Batch 1100 Training err. 3.09951 Training err. RA 3.21407 Valid. err. 3.17321
2018-02-03 21:59:01,654 training [INFO ] Epoch  6 Batch 1120 Training err. 3.11656 Training err. RA 3.21233 Valid. err. 3.17268
2018-02-03 21:59:02,128 training [INFO ] Epoch  6 Batch 1140 Training err. 3.11328 Training err. RA 3.21059 Valid. err. 3.17127
2018-02-03 21:59:02,601 training [INFO ] Epoch  6 Batch 1160 Training err. 3.14747 Training err. RA 3.20951 Valid. err. 3.16950
2018-02-03 21:59:03,082 training [INFO ] Epoch  6 Batch 1180 Training err. 3.10414 Training err. RA 3.20772 Valid. err. 3.17030
2018-02-03 21:59:03,556 training [INFO ] Epoch  6 Batch 1200 Training err. 3.07738 Training err. RA 3.20555 Valid. err. 3.16979
2018-02-03 21:59:04,029 training [INFO ] Epoch  6 Batch 1220 Training err. 3.12907 Training err. RA 3.20429 Valid. err. 3.16845
2018-02-03 21:59:04,501 training [INFO ] Epoch  6 Batch 1240 Training err. 3.13966 Training err. RA 3.20325 Valid. err. 3.16434
2018-02-03 21:59:05,323 training [INFO ] Epoch  7 Batch 1260 Training err. 3.12889 Training err. RA 3.20207 Valid. err. 3.17589
2018-02-03 21:59:05,798 training [INFO ] Epoch  7 Batch 1280 Training err. 3.04978 Training err. RA 3.19969 Valid. err. 3.20097
2018-02-03 21:59:06,286 training [INFO ] Epoch  7 Batch 1300 Training err. 3.13182 Training err. RA 3.19865 Valid. err. 3.16529
2018-02-03 21:59:06,761 training [INFO ] Epoch  7 Batch 1320 Training err. 3.09939 Training err. RA 3.19714 Valid. err. 3.16351
2018-02-03 21:59:07,239 training [INFO ] Epoch  7 Batch 1340 Training err. 3.09391 Training err. RA 3.19560 Valid. err. 3.16751
2018-02-03 21:59:07,711 training [INFO ] Epoch  7 Batch 1360 Training err. 3.13306 Training err. RA 3.19468 Valid. err. 3.16091
2018-02-03 21:59:08,183 training [INFO ] Epoch  7 Batch 1380 Training err. 3.10711 Training err. RA 3.19341 Valid. err. 3.16264
2018-02-03 21:59:08,655 training [INFO ] Epoch  7 Batch 1400 Training err. 3.09300 Training err. RA 3.19198 Valid. err. 3.16153
2018-02-03 21:59:09,172 training [INFO ] Epoch  7 Batch 1420 Training err. 3.08678 Training err. RA 3.19050 Valid. err. 3.15848
2018-02-03 21:59:09,651 training [INFO ] Epoch  7 Batch 1440 Training err. 3.13195 Training err. RA 3.18968 Valid. err. 3.15570
2018-02-03 21:59:10,493 training [INFO ] Epoch  8 Batch 1460 Training err. 3.12795 Training err. RA 3.18884 Valid. err. 3.15559
2018-02-03 21:59:10,969 training [INFO ] Epoch  8 Batch 1480 Training err. 3.09231 Training err. RA 3.18753 Valid. err. 3.16203
2018-02-03 21:59:11,455 training [INFO ] Epoch  8 Batch 1500 Training err. 3.08417 Training err. RA 3.18616 Valid. err. 3.15287
2018-02-03 21:59:11,941 training [INFO ] Epoch  8 Batch 1520 Training err. 3.08470 Training err. RA 3.18482 Valid. err. 3.15297
2018-02-03 21:59:12,418 training [INFO ] Epoch  8 Batch 1540 Training err. 3.07385 Training err. RA 3.18338 Valid. err. 3.15823
2018-02-03 21:59:12,895 training [INFO ] Epoch  8 Batch 1560 Training err. 3.12725 Training err. RA 3.18266 Valid. err. 3.15291
2018-02-03 21:59:13,368 training [INFO ] Epoch  8 Batch 1580 Training err. 3.11572 Training err. RA 3.18181 Valid. err. 3.15014
2018-02-03 21:59:13,840 training [INFO ] Epoch  8 Batch 1600 Training err. 3.07941 Training err. RA 3.18053 Valid. err. 3.14868
2018-02-03 21:59:14,318 training [INFO ] Epoch  8 Batch 1620 Training err. 3.04286 Training err. RA 3.17883 Valid. err. 3.15018
2018-02-03 21:59:14,825 training [INFO ] Epoch  8 Batch 1640 Training err. 3.12030 Training err. RA 3.17812 Valid. err. 3.14306
2018-02-03 21:59:15,320 training [INFO ] Epoch  8 Batch 1660 Training err. 3.12078 Training err. RA 3.17743 Valid. err. 3.13841
2018-02-03 21:59:16,181 training [INFO ] Epoch  9 Batch 1680 Training err. 3.09426 Training err. RA 3.17644 Valid. err. 3.13948
2018-02-03 21:59:16,656 training [INFO ] Epoch  9 Batch 1700 Training err. 3.04444 Training err. RA 3.17489 Valid. err. 3.13876
2018-02-03 21:59:17,130 training [INFO ] Epoch  9 Batch 1720 Training err. 3.09002 Training err. RA 3.17390 Valid. err. 3.13746
2018-02-03 21:59:17,605 training [INFO ] Epoch  9 Batch 1740 Training err. 3.07622 Training err. RA 3.17278 Valid. err. 3.13450
2018-02-03 21:59:18,082 training [INFO ] Epoch  9 Batch 1760 Training err. 3.06567 Training err. RA 3.17156 Valid. err. 3.13472
2018-02-03 21:59:18,558 training [INFO ] Epoch  9 Batch 1780 Training err. 3.11800 Training err. RA 3.17096 Valid. err. 3.12962
2018-02-03 21:59:19,034 training [INFO ] Epoch  9 Batch 1800 Training err. 3.06134 Training err. RA 3.16974 Valid. err. 3.12937
2018-02-03 21:59:19,525 training [INFO ] Epoch  9 Batch 1820 Training err. 3.05657 Training err. RA 3.16850 Valid. err. 3.12490
2018-02-03 21:59:20,007 training [INFO ] Epoch  9 Batch 1840 Training err. 3.06644 Training err. RA 3.16739 Valid. err. 3.12196
2018-02-03 21:59:20,509 training [INFO ] Epoch  9 Batch 1860 Training err. 3.08752 Training err. RA 3.16653 Valid. err. 3.11717
2018-02-03 21:59:21,388 training [INFO ] Epoch 10 Batch 1880 Training err. 3.09504 Training err. RA 3.16577 Valid. err. 3.11164
2018-02-03 21:59:21,903 training [INFO ] Epoch 10 Batch 1900 Training err. 3.02526 Training err. RA 3.16429 Valid. err. 3.14542
2018-02-03 21:59:22,406 training [INFO ] Epoch 10 Batch 1920 Training err. 3.07604 Training err. RA 3.16337 Valid. err. 3.10927
2018-02-03 21:59:22,889 training [INFO ] Epoch 10 Batch 1940 Training err. 3.04731 Training err. RA 3.16217 Valid. err. 3.10570
2018-02-03 21:59:23,410 training [INFO ] Epoch 10 Batch 1960 Training err. 3.02286 Training err. RA 3.16075 Valid. err. 3.10666
2018-02-03 21:59:23,908 training [INFO ] Epoch 10 Batch 1980 Training err. 3.08505 Training err. RA 3.15999 Valid. err. 3.10211
2018-02-03 21:59:24,413 training [INFO ] Epoch 10 Batch 2000 Training err. 3.04909 Training err. RA 3.15888 Valid. err. 3.09932
2018-02-03 21:59:24,896 training [INFO ] Epoch 10 Batch 2020 Training err. 3.03202 Training err. RA 3.15762 Valid. err. 3.09106
2018-02-03 21:59:25,385 training [INFO ] Epoch 10 Batch 2040 Training err. 2.99587 Training err. RA 3.15603 Valid. err. 3.08397
2018-02-03 21:59:25,887 training [INFO ] Epoch 10 Batch 2060 Training err. 3.06469 Training err. RA 3.15515 Valid. err. 3.07710
2018-02-03 21:59:26,381 training [INFO ] Epoch 10 Batch 2080 Training err. 3.04662 Training err. RA 3.15410 Valid. err. 3.06821
2018-02-03 21:59:27,253 training [INFO ] Epoch 11 Batch 2100 Training err. 3.01504 Training err. RA 3.15278 Valid. err. 3.06612
2018-02-03 21:59:27,731 training [INFO ] Epoch 11 Batch 2120 Training err. 3.01829 Training err. RA 3.15151 Valid. err. 3.06547
2018-02-03 21:59:28,236 training [INFO ] Epoch 11 Batch 2140 Training err. 2.99547 Training err. RA 3.15005 Valid. err. 3.05974
2018-02-03 21:59:28,746 training [INFO ] Epoch 11 Batch 2160 Training err. 3.00444 Training err. RA 3.14870 Valid. err. 3.05391
2018-02-03 21:59:29,219 training [INFO ] Epoch 11 Batch 2180 Training err. 3.00197 Training err. RA 3.14736 Valid. err. 3.04712
2018-02-03 21:59:29,707 training [INFO ] Epoch 11 Batch 2200 Training err. 3.03290 Training err. RA 3.14632 Valid. err. 3.03987
2018-02-03 21:59:30,196 training [INFO ] Epoch 11 Batch 2220 Training err. 2.97473 Training err. RA 3.14477 Valid. err. 3.03454
2018-02-03 21:59:30,692 training [INFO ] Epoch 11 Batch 2240 Training err. 2.94028 Training err. RA 3.14295 Valid. err. 3.02814
2018-02-03 21:59:31,171 training [INFO ] Epoch 11 Batch 2260 Training err. 2.99564 Training err. RA 3.14164 Valid. err. 3.02038
2018-02-03 21:59:31,661 training [INFO ] Epoch 11 Batch 2280 Training err. 2.99365 Training err. RA 3.14034 Valid. err. 3.01013
2018-02-03 21:59:32,482 training [INFO ] Epoch 12 Batch 2300 Training err. 2.98395 Training err. RA 3.13898 Valid. err. 3.07945
2018-02-03 21:59:32,961 training [INFO ] Epoch 12 Batch 2320 Training err. 2.92287 Training err. RA 3.13712 Valid. err. 3.04341
2018-02-03 21:59:33,441 training [INFO ] Epoch 12 Batch 2340 Training err. 2.97694 Training err. RA 3.13575 Valid. err. 2.99709
2018-02-03 21:59:33,914 training [INFO ] Epoch 12 Batch 2360 Training err. 2.94331 Training err. RA 3.13412 Valid. err. 2.98905
2018-02-03 21:59:34,387 training [INFO ] Epoch 12 Batch 2380 Training err. 2.91784 Training err. RA 3.13230 Valid. err. 2.99885
2018-02-03 21:59:34,865 training [INFO ] Epoch 12 Batch 2400 Training err. 2.96849 Training err. RA 3.13094 Valid. err. 2.97574
2018-02-03 21:59:35,378 training [INFO ] Epoch 12 Batch 2420 Training err. 2.92917 Training err. RA 3.12927 Valid. err. 2.97101
2018-02-03 21:59:35,860 training [INFO ] Epoch 12 Batch 2440 Training err. 2.90300 Training err. RA 3.12742 Valid. err. 2.96401
2018-02-03 21:59:36,351 training [INFO ] Epoch 12 Batch 2460 Training err. 2.90235 Training err. RA 3.12559 Valid. err. 2.95420
2018-02-03 21:59:36,827 training [INFO ] Epoch 12 Batch 2480 Training err. 2.92722 Training err. RA 3.12399 Valid. err. 2.94540
2018-02-03 21:59:37,646 training [INFO ] Epoch 13 Batch 2500 Training err. 2.92279 Training err. RA 3.12238 Valid. err. 2.93986
2018-02-03 21:59:38,122 training [INFO ] Epoch 13 Batch 2520 Training err. 2.88215 Training err. RA 3.12047 Valid. err. 2.96782
2018-02-03 21:59:38,599 training [INFO ] Epoch 13 Batch 2540 Training err. 2.90654 Training err. RA 3.11879 Valid. err. 2.92928
2018-02-03 21:59:39,075 training [INFO ] Epoch 13 Batch 2560 Training err. 2.86583 Training err. RA 3.11681 Valid. err. 2.92044
2018-02-03 21:59:39,552 training [INFO ] Epoch 13 Batch 2580 Training err. 2.85096 Training err. RA 3.11475 Valid. err. 2.92040
2018-02-03 21:59:40,030 training [INFO ] Epoch 13 Batch 2600 Training err. 2.89581 Training err. RA 3.11307 Valid. err. 2.91917
2018-02-03 21:59:40,517 training [INFO ] Epoch 13 Batch 2620 Training err. 2.88957 Training err. RA 3.11136 Valid. err. 2.90075
2018-02-03 21:59:41,024 training [INFO ] Epoch 13 Batch 2640 Training err. 2.83592 Training err. RA 3.10927 Valid. err. 2.89394
2018-02-03 21:59:41,592 training [INFO ] Epoch 13 Batch 2660 Training err. 2.80029 Training err. RA 3.10695 Valid. err. 2.97010
2018-02-03 21:59:42,162 training [INFO ] Epoch 13 Batch 2680 Training err. 2.86782 Training err. RA 3.10516 Valid. err. 2.87965
2018-02-03 21:59:42,725 training [INFO ] Epoch 13 Batch 2700 Training err. 2.86680 Training err. RA 3.10340 Valid. err. 2.86858
2018-02-03 21:59:43,774 training [INFO ] Epoch 14 Batch 2720 Training err. 2.82718 Training err. RA 3.10137 Valid. err. 2.87504
2018-02-03 21:59:44,351 training [INFO ] Epoch 14 Batch 2740 Training err. 2.80601 Training err. RA 3.09921 Valid. err. 2.88295
2018-02-03 21:59:44,938 training [INFO ] Epoch 14 Batch 2760 Training err. 2.83257 Training err. RA 3.09728 Valid. err. 2.85913
2018-02-03 21:59:45,479 training [INFO ] Epoch 14 Batch 2780 Training err. 2.79831 Training err. RA 3.09513 Valid. err. 2.85011
2018-02-03 21:59:45,990 training [INFO ] Epoch 14 Batch 2800 Training err. 2.76412 Training err. RA 3.09276 Valid. err. 2.84139
2018-02-03 21:59:46,484 training [INFO ] Epoch 14 Batch 2820 Training err. 2.84660 Training err. RA 3.09102 Valid. err. 2.83975
2018-02-03 21:59:46,956 training [INFO ] Epoch 14 Batch 2840 Training err. 2.78213 Training err. RA 3.08884 Valid. err. 2.85301
2018-02-03 21:59:47,447 training [INFO ] Epoch 14 Batch 2860 Training err. 2.77184 Training err. RA 3.08663 Valid. err. 2.82127
2018-02-03 21:59:47,932 training [INFO ] Epoch 14 Batch 2880 Training err. 2.77645 Training err. RA 3.08447 Valid. err. 2.81725
2018-02-03 21:59:48,437 training [INFO ] Epoch 14 Batch 2900 Training err. 2.79022 Training err. RA 3.08244 Valid. err. 2.81322
2018-02-03 21:59:49,285 training [INFO ] Epoch 15 Batch 2920 Training err. 2.78960 Training err. RA 3.08044 Valid. err. 2.80424
2018-02-03 21:59:49,764 training [INFO ] Epoch 15 Batch 2940 Training err. 2.70517 Training err. RA 3.07788 Valid. err. 2.86364
2018-02-03 21:59:50,237 training [INFO ] Epoch 15 Batch 2960 Training err. 2.79145 Training err. RA 3.07595 Valid. err. 2.79910
2018-02-03 21:59:50,711 training [INFO ] Epoch 15 Batch 2980 Training err. 2.74276 Training err. RA 3.07371 Valid. err. 2.79073
2018-02-03 21:59:51,184 training [INFO ] Epoch 15 Batch 3000 Training err. 2.70074 Training err. RA 3.07123 Valid. err. 2.80449
2018-02-03 21:59:51,658 training [INFO ] Epoch 15 Batch 3020 Training err. 2.76237 Training err. RA 3.06918 Valid. err. 2.81430
2018-02-03 21:59:52,130 training [INFO ] Epoch 15 Batch 3040 Training err. 2.75842 Training err. RA 3.06714 Valid. err. 2.77574
2018-02-03 21:59:52,601 training [INFO ] Epoch 15 Batch 3060 Training err. 2.73643 Training err. RA 3.06498 Valid. err. 2.78539
2018-02-03 21:59:53,073 training [INFO ] Epoch 15 Batch 3080 Training err. 2.67835 Training err. RA 3.06247 Valid. err. 2.78033
2018-02-03 21:59:53,546 training [INFO ] Epoch 15 Batch 3100 Training err. 2.75202 Training err. RA 3.06046 Valid. err. 2.75982
2018-02-03 21:59:54,019 training [INFO ] Epoch 15 Batch 3120 Training err. 2.74629 Training err. RA 3.05845 Valid. err. 2.75251
2018-02-03 21:59:54,844 training [INFO ] Epoch 16 Batch 3140 Training err. 2.68280 Training err. RA 3.05606 Valid. err. 2.75786
2018-02-03 21:59:55,318 training [INFO ] Epoch 16 Batch 3160 Training err. 2.69407 Training err. RA 3.05376 Valid. err. 2.78130
2018-02-03 21:59:55,814 training [INFO ] Epoch 16 Batch 3180 Training err. 2.69358 Training err. RA 3.05150 Valid. err. 2.74625
2018-02-03 21:59:56,299 training [INFO ] Epoch 16 Batch 3200 Training err. 2.69960 Training err. RA 3.04930 Valid. err. 2.74142
2018-02-03 21:59:56,805 training [INFO ] Epoch 16 Batch 3220 Training err. 2.67752 Training err. RA 3.04699 Valid. err. 2.73541
2018-02-03 21:59:57,307 training [INFO ] Epoch 16 Batch 3240 Training err. 2.73962 Training err. RA 3.04509 Valid. err. 2.74059
2018-02-03 21:59:57,802 training [INFO ] Epoch 16 Batch 3260 Training err. 2.68390 Training err. RA 3.04288 Valid. err. 2.73791
2018-02-03 21:59:58,292 training [INFO ] Epoch 16 Batch 3280 Training err. 2.65138 Training err. RA 3.04049 Valid. err. 2.73907
2018-02-03 21:59:58,788 training [INFO ] Epoch 16 Batch 3300 Training err. 2.69047 Training err. RA 3.03837 Valid. err. 2.72214
2018-02-03 21:59:59,299 training [INFO ] Epoch 16 Batch 3320 Training err. 2.69463 Training err. RA 3.03630 Valid. err. 2.70262
2018-02-03 22:00:00,182 training [INFO ] Epoch 17 Batch 3340 Training err. 2.66939 Training err. RA 3.03410 Valid. err. 2.71608
2018-02-03 22:00:00,672 training [INFO ] Epoch 17 Batch 3360 Training err. 2.71230 Training err. RA 3.03219 Valid. err. 2.79947
2018-02-03 22:00:01,189 training [INFO ] Epoch 17 Batch 3380 Training err. 2.74677 Training err. RA 3.03050 Valid. err. 2.75007
2018-02-03 22:00:01,687 training [INFO ] Epoch 17 Batch 3400 Training err. 2.71554 Training err. RA 3.02864 Valid. err. 2.73192
2018-02-03 22:00:02,193 training [INFO ] Epoch 17 Batch 3420 Training err. 2.66020 Training err. RA 3.02649 Valid. err. 2.72201
2018-02-03 22:00:02,684 training [INFO ] Epoch 17 Batch 3440 Training err. 2.69634 Training err. RA 3.02457 Valid. err. 2.69359
2018-02-03 22:00:03,188 training [INFO ] Epoch 17 Batch 3460 Training err. 2.67422 Training err. RA 3.02254 Valid. err. 2.69465
2018-02-03 22:00:03,665 training [INFO ] Epoch 17 Batch 3480 Training err. 2.63728 Training err. RA 3.02033 Valid. err. 2.69166
2018-02-03 22:00:04,163 training [INFO ] Epoch 17 Batch 3500 Training err. 2.63532 Training err. RA 3.01813 Valid. err. 2.68369
2018-02-03 22:00:04,714 training [INFO ] Epoch 17 Batch 3520 Training err. 2.65261 Training err. RA 3.01605 Valid. err. 2.67618
2018-02-03 22:00:05,574 training [INFO ] Epoch 18 Batch 3540 Training err. 2.65357 Training err. RA 3.01401 Valid. err. 2.66198
2018-02-03 22:00:06,230 training [INFO ] Epoch 18 Batch 3560 Training err. 2.60661 Training err. RA 3.01172 Valid. err. 2.66222
2018-02-03 22:00:06,719 training [INFO ] Epoch 18 Batch 3580 Training err. 2.60999 Training err. RA 3.00947 Valid. err. 2.70795
2018-02-03 22:00:07,204 training [INFO ] Epoch 18 Batch 3600 Training err. 2.62207 Training err. RA 3.00732 Valid. err. 2.66527
2018-02-03 22:00:07,694 training [INFO ] Epoch 18 Batch 3620 Training err. 2.60004 Training err. RA 3.00507 Valid. err. 2.68768
2018-02-03 22:00:08,172 training [INFO ] Epoch 18 Batch 3640 Training err. 2.64195 Training err. RA 3.00308 Valid. err. 2.67310
2018-02-03 22:00:08,651 training [INFO ] Epoch 18 Batch 3660 Training err. 2.66356 Training err. RA 3.00122 Valid. err. 2.65298
2018-02-03 22:00:09,142 training [INFO ] Epoch 18 Batch 3680 Training err. 2.59983 Training err. RA 2.99904 Valid. err. 2.64721
2018-02-03 22:00:09,627 training [INFO ] Epoch 18 Batch 3700 Training err. 2.56210 Training err. RA 2.99668 Valid. err. 2.64226
2018-02-03 22:00:10,137 training [INFO ] Epoch 18 Batch 3720 Training err. 2.62014 Training err. RA 2.99465 Valid. err. 2.63019
2018-02-03 22:00:10,615 training [INFO ] Epoch 18 Batch 3740 Training err. 2.62476 Training err. RA 2.99267 Valid. err. 2.62966
2018-02-03 22:00:11,441 training [INFO ] Epoch 19 Batch 3760 Training err. 2.59429 Training err. RA 2.99056 Valid. err. 2.62560
2018-02-03 22:00:11,951 training [INFO ] Epoch 19 Batch 3780 Training err. 2.51663 Training err. RA 2.98805 Valid. err. 2.62542
2018-02-03 22:00:12,441 training [INFO ] Epoch 19 Batch 3800 Training err. 2.62886 Training err. RA 2.98616 Valid. err. 2.64184
2018-02-03 22:00:12,943 training [INFO ] Epoch 19 Batch 3820 Training err. 2.58974 Training err. RA 2.98408 Valid. err. 2.62809
2018-02-03 22:00:13,418 training [INFO ] Epoch 19 Batch 3840 Training err. 2.54983 Training err. RA 2.98182 Valid. err. 2.62403
2018-02-03 22:00:13,899 training [INFO ] Epoch 19 Batch 3860 Training err. 2.63767 Training err. RA 2.98004 Valid. err. 2.62275
2018-02-03 22:00:14,383 training [INFO ] Epoch 19 Batch 3880 Training err. 2.58441 Training err. RA 2.97800 Valid. err. 2.61646
2018-02-03 22:00:14,857 training [INFO ] Epoch 19 Batch 3900 Training err. 2.55986 Training err. RA 2.97585 Valid. err. 2.59979
2018-02-03 22:00:15,331 training [INFO ] Epoch 19 Batch 3920 Training err. 2.56944 Training err. RA 2.97378 Valid. err. 2.59967
2018-02-03 22:00:15,822 training [INFO ] Epoch 19 Batch 3940 Training err. 2.56378 Training err. RA 2.97170 Valid. err. 2.59043
2018-02-03 22:00:16,654 training [INFO ] Epoch 20 Batch 3960 Training err. 2.58600 Training err. RA 2.96975 Valid. err. 2.59034
2018-02-03 22:00:17,135 training [INFO ] Epoch 20 Batch 3980 Training err. 2.49331 Training err. RA 2.96736 Valid. err. 2.58913
2018-02-03 22:00:17,662 training [INFO ] Epoch 20 Batch 4000 Training err. 2.58756 Training err. RA 2.96546 Valid. err. 2.59009
2018-02-03 22:00:18,251 training [INFO ] Epoch 20 Batch 4020 Training err. 2.55375 Training err. RA 2.96341 Valid. err. 2.58039
2018-02-03 22:00:18,805 training [INFO ] Epoch 20 Batch 4040 Training err. 2.51781 Training err. RA 2.96120 Valid. err. 2.59630
2018-02-03 22:00:19,316 training [INFO ] Epoch 20 Batch 4060 Training err. 2.56152 Training err. RA 2.95923 Valid. err. 2.61758
2018-02-03 22:00:19,951 training [INFO ] Epoch 20 Batch 4080 Training err. 2.58797 Training err. RA 2.95741 Valid. err. 2.57803
2018-02-03 22:00:20,582 training [INFO ] Epoch 20 Batch 4100 Training err. 2.54575 Training err. RA 2.95541 Valid. err. 2.58564
2018-02-03 22:00:21,192 training [INFO ] Epoch 20 Batch 4120 Training err. 2.49118 Training err. RA 2.95315 Valid. err. 2.57873
2018-02-03 22:00:22,027 training [INFO ] Epoch 20 Batch 4140 Training err. 2.55451 Training err. RA 2.95123 Valid. err. 2.55608
2018-02-03 22:00:22,603 training [INFO ] Epoch 20 Batch 4160 Training err. 2.54935 Training err. RA 2.94929 Valid. err. 2.57303
2018-02-03 22:00:23,551 training [INFO ] Epoch 21 Batch 4180 Training err. 2.51022 Training err. RA 2.94719 Valid. err. 2.55468
2018-02-03 22:00:24,104 training [INFO ] Epoch 21 Batch 4200 Training err. 2.47797 Training err. RA 2.94496 Valid. err. 2.55861
2018-02-03 22:00:24,669 training [INFO ] Epoch 21 Batch 4220 Training err. 2.52692 Training err. RA 2.94298 Valid. err. 2.55091
2018-02-03 22:00:25,220 training [INFO ] Epoch 21 Batch 4240 Training err. 2.52747 Training err. RA 2.94102 Valid. err. 2.54340
2018-02-03 22:00:25,769 training [INFO ] Epoch 21 Batch 4260 Training err. 2.50344 Training err. RA 2.93896 Valid. err. 2.54353
2018-02-03 22:00:26,323 training [INFO ] Epoch 21 Batch 4280 Training err. 2.56977 Training err. RA 2.93724 Valid. err. 2.54852
2018-02-03 22:00:26,876 training [INFO ] Epoch 21 Batch 4300 Training err. 2.51296 Training err. RA 2.93527 Valid. err. 2.54786
2018-02-03 22:00:27,428 training [INFO ] Epoch 21 Batch 4320 Training err. 2.48001 Training err. RA 2.93316 Valid. err. 2.54752
2018-02-03 22:00:27,986 training [INFO ] Epoch 21 Batch 4340 Training err. 2.51170 Training err. RA 2.93122 Valid. err. 2.52910
2018-02-03 22:00:28,542 training [INFO ] Epoch 21 Batch 4360 Training err. 2.50193 Training err. RA 2.92925 Valid. err. 2.53608
2018-02-03 22:00:29,492 training [INFO ] Epoch 22 Batch 4380 Training err. 2.50566 Training err. RA 2.92731 Valid. err. 2.53545
2018-02-03 22:00:30,054 training [INFO ] Epoch 22 Batch 4400 Training err. 2.40252 Training err. RA 2.92493 Valid. err. 2.52867
2018-02-03 22:00:30,620 training [INFO ] Epoch 22 Batch 4420 Training err. 2.54222 Training err. RA 2.92319 Valid. err. 2.51205
2018-02-03 22:00:31,179 training [INFO ] Epoch 22 Batch 4440 Training err. 2.49257 Training err. RA 2.92126 Valid. err. 2.51110
2018-02-03 22:00:31,730 training [INFO ] Epoch 22 Batch 4460 Training err. 2.46242 Training err. RA 2.91920 Valid. err. 2.51599
2018-02-03 22:00:32,279 training [INFO ] Epoch 22 Batch 4480 Training err. 2.50527 Training err. RA 2.91735 Valid. err. 2.52438
2018-02-03 22:00:32,833 training [INFO ] Epoch 22 Batch 4500 Training err. 2.52976 Training err. RA 2.91563 Valid. err. 2.51917
2018-02-03 22:00:33,394 training [INFO ] Epoch 22 Batch 4520 Training err. 2.46894 Training err. RA 2.91365 Valid. err. 2.50078
2018-02-03 22:00:33,949 training [INFO ] Epoch 22 Batch 4540 Training err. 2.46420 Training err. RA 2.91167 Valid. err. 2.51677
2018-02-03 22:00:34,498 training [INFO ] Epoch 22 Batch 4560 Training err. 2.46971 Training err. RA 2.90973 Valid. err. 2.49759
2018-02-03 22:00:35,450 training [INFO ] Epoch 23 Batch 4580 Training err. 2.48272 Training err. RA 2.90787 Valid. err. 2.48706
2018-02-03 22:00:36,000 training [INFO ] Epoch 23 Batch 4600 Training err. 2.43743 Training err. RA 2.90582 Valid. err. 2.48922
2018-02-03 22:00:36,553 training [INFO ] Epoch 23 Batch 4620 Training err. 2.44235 Training err. RA 2.90382 Valid. err. 2.51352
2018-02-03 22:00:37,105 training [INFO ] Epoch 23 Batch 4640 Training err. 2.46700 Training err. RA 2.90193 Valid. err. 2.49591
2018-02-03 22:00:37,661 training [INFO ] Epoch 23 Batch 4660 Training err. 2.43299 Training err. RA 2.89992 Valid. err. 2.55949
2018-02-03 22:00:38,220 training [INFO ] Epoch 23 Batch 4680 Training err. 2.47542 Training err. RA 2.89811 Valid. err. 2.49571
2018-02-03 22:00:38,775 training [INFO ] Epoch 23 Batch 4700 Training err. 2.52156 Training err. RA 2.89650 Valid. err. 2.49026
2018-02-03 22:00:39,325 training [INFO ] Epoch 23 Batch 4720 Training err. 2.43761 Training err. RA 2.89456 Valid. err. 2.47858
2018-02-03 22:00:39,879 training [INFO ] Epoch 23 Batch 4740 Training err. 2.41273 Training err. RA 2.89253 Valid. err. 2.47663
2018-02-03 22:00:40,427 training [INFO ] Epoch 23 Batch 4760 Training err. 2.45213 Training err. RA 2.89068 Valid. err. 2.45995
2018-02-03 22:00:40,980 training [INFO ] Epoch 23 Batch 4780 Training err. 2.45801 Training err. RA 2.88887 Valid. err. 2.48836
2018-02-03 22:00:41,913 training [INFO ] Epoch 24 Batch 4800 Training err. 2.43593 Training err. RA 2.88698 Valid. err. 2.46753
2018-02-03 22:00:42,469 training [INFO ] Epoch 24 Batch 4820 Training err. 2.35947 Training err. RA 2.88479 Valid. err. 2.46032
2018-02-03 22:00:43,033 training [INFO ] Epoch 24 Batch 4840 Training err. 2.47318 Training err. RA 2.88309 Valid. err. 2.47211
2018-02-03 22:00:43,586 training [INFO ] Epoch 24 Batch 4860 Training err. 2.43490 Training err. RA 2.88124 Valid. err. 2.45767
2018-02-03 22:00:44,137 training [INFO ] Epoch 24 Batch 4880 Training err. 2.40235 Training err. RA 2.87928 Valid. err. 2.46458
2018-02-03 22:00:44,689 training [INFO ] Epoch 24 Batch 4900 Training err. 2.48856 Training err. RA 2.87769 Valid. err. 2.47381
2018-02-03 22:00:45,239 training [INFO ] Epoch 24 Batch 4920 Training err. 2.44243 Training err. RA 2.87592 Valid. err. 2.45793
2018-02-03 22:00:45,802 training [INFO ] Epoch 24 Batch 4940 Training err. 2.41091 Training err. RA 2.87403 Valid. err. 2.44484
2018-02-03 22:00:46,393 training [INFO ] Epoch 24 Batch 4960 Training err. 2.41893 Training err. RA 2.87220 Valid. err. 2.43914
2018-02-03 22:00:46,944 training [INFO ] Epoch 24 Batch 4980 Training err. 2.40376 Training err. RA 2.87032 Valid. err. 2.43743
2018-02-03 22:00:47,874 training [INFO ] Epoch 25 Batch 5000 Training err. 2.43899 Training err. RA 2.86859 Valid. err. 2.43379
2018-02-03 22:00:48,433 training [INFO ] Epoch 25 Batch 5020 Training err. 2.34377 Training err. RA 2.86650 Valid. err. 2.43888
2018-02-03 22:00:48,987 training [INFO ] Epoch 25 Batch 5040 Training err. 2.43712 Training err. RA 2.86480 Valid. err. 2.43642
2018-02-03 22:00:49,541 training [INFO ] Epoch 25 Batch 5060 Training err. 2.41425 Training err. RA 2.86302 Valid. err. 2.43242
2018-02-03 22:00:50,089 training [INFO ] Epoch 25 Batch 5080 Training err. 2.37407 Training err. RA 2.86109 Valid. err. 2.45145
2018-02-03 22:00:50,641 training [INFO ] Epoch 25 Batch 5100 Training err. 2.40797 Training err. RA 2.85932 Valid. err. 2.47314
2018-02-03 22:00:51,204 training [INFO ] Epoch 25 Batch 5120 Training err. 2.46396 Training err. RA 2.85777 Valid. err. 2.43318
2018-02-03 22:00:51,759 training [INFO ] Epoch 25 Batch 5140 Training err. 2.40376 Training err. RA 2.85600 Valid. err. 2.45471
2018-02-03 22:00:52,309 training [INFO ] Epoch 25 Batch 5160 Training err. 2.35568 Training err. RA 2.85407 Valid. err. 2.41737
2018-02-03 22:00:52,862 training [INFO ] Epoch 25 Batch 5180 Training err. 2.40294 Training err. RA 2.85232 Valid. err. 2.41021
2018-02-03 22:00:53,423 training [INFO ] Epoch 25 Batch 5200 Training err. 2.40657 Training err. RA 2.85061 Valid. err. 2.42044
2018-02-03 22:00:54,379 training [INFO ] Epoch 26 Batch 5220 Training err. 2.37300 Training err. RA 2.84878 Valid. err. 2.42464
2018-02-03 22:00:54,939 training [INFO ] Epoch 26 Batch 5240 Training err. 2.33132 Training err. RA 2.84680 Valid. err. 2.41391
2018-02-03 22:00:55,490 training [INFO ] Epoch 26 Batch 5260 Training err. 2.39713 Training err. RA 2.84509 Valid. err. 2.40812
2018-02-03 22:00:56,040 training [INFO ] Epoch 26 Batch 5280 Training err. 2.39352 Training err. RA 2.84338 Valid. err. 2.40398
2018-02-03 22:00:56,604 training [INFO ] Epoch 26 Batch 5300 Training err. 2.36921 Training err. RA 2.84159 Valid. err. 2.40705
2018-02-03 22:00:57,159 training [INFO ] Epoch 26 Batch 5320 Training err. 2.44017 Training err. RA 2.84009 Valid. err. 2.40463
2018-02-03 22:00:57,709 training [INFO ] Epoch 26 Batch 5340 Training err. 2.38190 Training err. RA 2.83837 Valid. err. 2.41369
2018-02-03 22:00:58,258 training [INFO ] Epoch 26 Batch 5360 Training err. 2.35053 Training err. RA 2.83655 Valid. err. 2.42861
2018-02-03 22:00:58,812 training [INFO ] Epoch 26 Batch 5380 Training err. 2.37162 Training err. RA 2.83482 Valid. err. 2.39704
2018-02-03 22:00:59,366 training [INFO ] Epoch 26 Batch 5400 Training err. 2.36773 Training err. RA 2.83309 Valid. err. 2.40986
2018-02-03 22:01:00,288 training [INFO ] Epoch 27 Batch 5420 Training err. 2.37775 Training err. RA 2.83141 Valid. err. 2.39470
2018-02-03 22:01:00,841 training [INFO ] Epoch 27 Batch 5440 Training err. 2.27420 Training err. RA 2.82936 Valid. err. 2.39495
2018-02-03 22:01:01,400 training [INFO ] Epoch 27 Batch 5460 Training err. 2.40656 Training err. RA 2.82781 Valid. err. 2.38426
2018-02-03 22:01:01,959 training [INFO ] Epoch 27 Batch 5480 Training err. 2.36844 Training err. RA 2.82614 Valid. err. 2.38140
2018-02-03 22:01:02,510 training [INFO ] Epoch 27 Batch 5500 Training err. 2.33427 Training err. RA 2.82435 Valid. err. 2.39593
2018-02-03 22:01:03,062 training [INFO ] Epoch 27 Batch 5520 Training err. 2.37779 Training err. RA 2.82273 Valid. err. 2.40010
2018-02-03 22:01:03,626 training [INFO ] Epoch 27 Batch 5540 Training err. 2.40986 Training err. RA 2.82124 Valid. err. 2.39145
2018-02-03 22:01:04,184 training [INFO ] Epoch 27 Batch 5560 Training err. 2.34429 Training err. RA 2.81952 Valid. err. 2.37435
2018-02-03 22:01:04,739 training [INFO ] Epoch 27 Batch 5580 Training err. 2.33679 Training err. RA 2.81779 Valid. err. 2.39674
2018-02-03 22:01:05,305 training [INFO ] Epoch 27 Batch 5600 Training err. 2.34386 Training err. RA 2.81610 Valid. err. 2.37439
2018-02-03 22:01:06,284 training [INFO ] Epoch 28 Batch 5620 Training err. 2.35819 Training err. RA 2.81447 Valid. err. 2.36609
2018-02-03 22:01:06,902 training [INFO ] Epoch 28 Batch 5640 Training err. 2.31315 Training err. RA 2.81269 Valid. err. 2.37231
2018-02-03 22:01:07,554 training [INFO ] Epoch 28 Batch 5660 Training err. 2.31011 Training err. RA 2.81092 Valid. err. 2.40329
2018-02-03 22:01:08,235 training [INFO ] Epoch 28 Batch 5680 Training err. 2.35535 Training err. RA 2.80931 Valid. err. 2.36936
2018-02-03 22:01:08,883 training [INFO ] Epoch 28 Batch 5700 Training err. 2.31496 Training err. RA 2.80758 Valid. err. 2.42191
2018-02-03 22:01:09,501 training [INFO ] Epoch 28 Batch 5720 Training err. 2.35496 Training err. RA 2.80600 Valid. err. 2.36741
2018-02-03 22:01:10,093 training [INFO ] Epoch 28 Batch 5740 Training err. 2.40817 Training err. RA 2.80461 Valid. err. 2.36641
2018-02-03 22:01:10,686 training [INFO ] Epoch 28 Batch 5760 Training err. 2.31618 Training err. RA 2.80291 Valid. err. 2.36208
2018-02-03 22:01:11,263 training [INFO ] Epoch 28 Batch 5780 Training err. 2.29944 Training err. RA 2.80117 Valid. err. 2.36531
2018-02-03 22:01:11,896 training [INFO ] Epoch 28 Batch 5800 Training err. 2.32802 Training err. RA 2.79954 Valid. err. 2.34494
2018-02-03 22:01:12,592 training [INFO ] Epoch 28 Batch 5820 Training err. 2.33689 Training err. RA 2.79795 Valid. err. 2.37600
2018-02-03 22:01:13,625 training [INFO ] Epoch 29 Batch 5840 Training err. 2.31974 Training err. RA 2.79631 Valid. err. 2.35970
2018-02-03 22:01:14,278 training [INFO ] Epoch 29 Batch 5860 Training err. 2.24783 Training err. RA 2.79444 Valid. err. 2.35025
2018-02-03 22:01:14,921 training [INFO ] Epoch 29 Batch 5880 Training err. 2.35076 Training err. RA 2.79293 Valid. err. 2.36107
2018-02-03 22:01:15,591 training [INFO ] Epoch 29 Batch 5900 Training err. 2.32347 Training err. RA 2.79134 Valid. err. 2.34651
2018-02-03 22:01:16,247 training [INFO ] Epoch 29 Batch 5920 Training err. 2.29691 Training err. RA 2.78967 Valid. err. 2.36311
2018-02-03 22:01:16,906 training [INFO ] Epoch 29 Batch 5940 Training err. 2.37454 Training err. RA 2.78827 Valid. err. 2.36520
2018-02-03 22:01:17,539 training [INFO ] Epoch 29 Batch 5960 Training err. 2.33046 Training err. RA 2.78674 Valid. err. 2.34341
2018-02-03 22:01:18,134 training [INFO ] Epoch 29 Batch 5980 Training err. 2.29601 Training err. RA 2.78510 Valid. err. 2.33449
2018-02-03 22:01:18,719 training [INFO ] Epoch 29 Batch 6000 Training err. 2.30653 Training err. RA 2.78350 Valid. err. 2.32774
2018-02-03 22:01:19,302 training [INFO ] Epoch 29 Batch 6020 Training err. 2.29211 Training err. RA 2.78187 Valid. err. 2.33065
2018-02-03 22:01:20,351 training [INFO ] Epoch 30 Batch 6040 Training err. 2.32469 Training err. RA 2.78035 Valid. err. 2.32517
2018-02-03 22:01:20,949 training [INFO ] Epoch 30 Batch 6060 Training err. 2.23553 Training err. RA 2.77856 Valid. err. 2.32752
2018-02-03 22:01:21,532 training [INFO ] Epoch 30 Batch 6080 Training err. 2.31786 Training err. RA 2.77704 Valid. err. 2.33951
2018-02-03 22:01:22,104 training [INFO ] Epoch 30 Batch 6100 Training err. 2.31164 Training err. RA 2.77551 Valid. err. 2.32651
2018-02-03 22:01:22,700 training [INFO ] Epoch 30 Batch 6120 Training err. 2.27194 Training err. RA 2.77387 Valid. err. 2.34075
2018-02-03 22:01:23,280 training [INFO ] Epoch 30 Batch 6140 Training err. 2.29979 Training err. RA 2.77232 Valid. err. 2.36659
2018-02-03 22:01:23,855 training [INFO ] Epoch 30 Batch 6160 Training err. 2.36021 Training err. RA 2.77099 Valid. err. 2.32357
2018-02-03 22:01:24,427 training [INFO ] Epoch 30 Batch 6180 Training err. 2.29133 Training err. RA 2.76943 Valid. err. 2.35810
2018-02-03 22:01:24,994 training [INFO ] Epoch 30 Batch 6200 Training err. 2.25319 Training err. RA 2.76777 Valid. err. 2.31087
2018-02-03 22:01:25,575 training [INFO ] Epoch 30 Batch 6220 Training err. 2.29487 Training err. RA 2.76625 Valid. err. 2.30571
2018-02-03 22:01:26,154 training [INFO ] Epoch 30 Batch 6240 Training err. 2.29425 Training err. RA 2.76474 Valid. err. 2.31726
2018-02-03 22:01:27,143 training [INFO ] Epoch 31 Batch 6260 Training err. 2.26998 Training err. RA 2.76315 Valid. err. 2.32542
2018-02-03 22:01:27,732 training [INFO ] Epoch 31 Batch 6280 Training err. 2.22623 Training err. RA 2.76144 Valid. err. 2.31157
2018-02-03 22:01:28,328 training [INFO ] Epoch 31 Batch 6300 Training err. 2.29206 Training err. RA 2.75995 Valid. err. 2.30775
2018-02-03 22:01:28,898 training [INFO ] Epoch 31 Batch 6320 Training err. 2.29403 Training err. RA 2.75848 Valid. err. 2.30430
2018-02-03 22:01:29,474 training [INFO ] Epoch 31 Batch 6340 Training err. 2.27358 Training err. RA 2.75695 Valid. err. 2.31431
2018-02-03 22:01:30,050 training [INFO ] Epoch 31 Batch 6360 Training err. 2.33544 Training err. RA 2.75562 Valid. err. 2.30010
2018-02-03 22:01:30,621 training [INFO ] Epoch 31 Batch 6380 Training err. 2.27924 Training err. RA 2.75413 Valid. err. 2.30661
2018-02-03 22:01:31,200 training [INFO ] Epoch 31 Batch 6400 Training err. 2.24709 Training err. RA 2.75255 Valid. err. 2.34005
2018-02-03 22:01:31,771 training [INFO ] Epoch 31 Batch 6420 Training err. 2.26941 Training err. RA 2.75104 Valid. err. 2.30081
2018-02-03 22:01:32,335 training [INFO ] Epoch 31 Batch 6440 Training err. 2.26669 Training err. RA 2.74954 Valid. err. 2.30364
2018-02-03 22:01:33,296 training [INFO ] Epoch 32 Batch 6460 Training err. 2.27332 Training err. RA 2.74806 Valid. err. 2.29609
2018-02-03 22:01:33,863 training [INFO ] Epoch 32 Batch 6480 Training err. 2.17982 Training err. RA 2.74631 Valid. err. 2.29479
2018-02-03 22:01:34,437 training [INFO ] Epoch 32 Batch 6500 Training err. 2.29741 Training err. RA 2.74493 Valid. err. 2.28992
2018-02-03 22:01:35,015 training [INFO ] Epoch 32 Batch 6520 Training err. 2.27569 Training err. RA 2.74349 Valid. err. 2.29132
2018-02-03 22:01:35,597 training [INFO ] Epoch 32 Batch 6540 Training err. 2.24183 Training err. RA 2.74195 Valid. err. 2.30451
2018-02-03 22:01:36,162 training [INFO ] Epoch 32 Batch 6560 Training err. 2.27928 Training err. RA 2.74054 Valid. err. 2.30946
2018-02-03 22:01:36,731 training [INFO ] Epoch 32 Batch 6580 Training err. 2.31507 Training err. RA 2.73925 Valid. err. 2.29212
2018-02-03 22:01:37,310 training [INFO ] Epoch 32 Batch 6600 Training err. 2.24063 Training err. RA 2.73774 Valid. err. 2.28544
2018-02-03 22:01:37,884 training [INFO ] Epoch 32 Batch 6620 Training err. 2.24076 Training err. RA 2.73624 Valid. err. 2.31308
2018-02-03 22:01:38,446 training [INFO ] Epoch 32 Batch 6640 Training err. 2.24959 Training err. RA 2.73477 Valid. err. 2.28059
2018-02-03 22:01:39,429 training [INFO ] Epoch 33 Batch 6660 Training err. 2.25545 Training err. RA 2.73333 Valid. err. 2.27529
2018-02-03 22:01:40,039 training [INFO ] Epoch 33 Batch 6680 Training err. 2.21765 Training err. RA 2.73179 Valid. err. 2.27960
2018-02-03 22:01:40,685 training [INFO ] Epoch 33 Batch 6700 Training err. 2.21491 Training err. RA 2.73025 Valid. err. 2.29958
2018-02-03 22:01:41,274 training [INFO ] Epoch 33 Batch 6720 Training err. 2.26185 Training err. RA 2.72885 Valid. err. 2.27599
2018-02-03 22:01:41,864 training [INFO ] Epoch 33 Batch 6740 Training err. 2.22707 Training err. RA 2.72736 Valid. err. 2.33310
2018-02-03 22:01:42,434 training [INFO ] Epoch 33 Batch 6760 Training err. 2.26461 Training err. RA 2.72599 Valid. err. 2.27727
2018-02-03 22:01:43,010 training [INFO ] Epoch 33 Batch 6780 Training err. 2.31414 Training err. RA 2.72478 Valid. err. 2.27461
2018-02-03 22:01:43,587 training [INFO ] Epoch 33 Batch 6800 Training err. 2.21918 Training err. RA 2.72329 Valid. err. 2.27090
2018-02-03 22:01:44,186 training [INFO ] Epoch 33 Batch 6820 Training err. 2.20675 Training err. RA 2.72178 Valid. err. 2.27686
2018-02-03 22:01:44,819 training [INFO ] Epoch 33 Batch 6840 Training err. 2.23592 Training err. RA 2.72036 Valid. err. 2.25925
2018-02-03 22:01:45,445 training [INFO ] Epoch 33 Batch 6860 Training err. 2.23926 Training err. RA 2.71895 Valid. err. 2.27708
2018-02-03 22:01:46,763 training [INFO ] Epoch 34 Batch 6880 Training err. 2.22660 Training err. RA 2.71752 Valid. err. 2.27941
2018-02-03 22:01:47,381 training [INFO ] Epoch 34 Batch 6900 Training err. 2.16153 Training err. RA 2.71591 Valid. err. 2.26380
2018-02-03 22:01:47,954 training [INFO ] Epoch 34 Batch 6920 Training err. 2.25563 Training err. RA 2.71458 Valid. err. 2.26954
2018-02-03 22:01:48,551 training [INFO ] Epoch 34 Batch 6940 Training err. 2.23768 Training err. RA 2.71321 Valid. err. 2.26166
2018-02-03 22:01:49,120 training [INFO ] Epoch 34 Batch 6960 Training err. 2.21469 Training err. RA 2.71177 Valid. err. 2.30600
2018-02-03 22:01:49,699 training [INFO ] Epoch 34 Batch 6980 Training err. 2.28136 Training err. RA 2.71054 Valid. err. 2.27603
2018-02-03 22:01:50,270 training [INFO ] Epoch 34 Batch 7000 Training err. 2.24419 Training err. RA 2.70921 Valid. err. 2.25657
2018-02-03 22:01:50,828 training [INFO ] Epoch 34 Batch 7020 Training err. 2.20039 Training err. RA 2.70776 Valid. err. 2.24908
2018-02-03 22:01:51,392 training [INFO ] Epoch 34 Batch 7040 Training err. 2.21871 Training err. RA 2.70637 Valid. err. 2.24321
2018-02-03 22:01:51,955 training [INFO ] Epoch 34 Batch 7060 Training err. 2.20472 Training err. RA 2.70495 Valid. err. 2.24674
2018-02-03 22:01:52,964 training [INFO ] Epoch 35 Batch 7080 Training err. 2.22986 Training err. RA 2.70361 Valid. err. 2.24260
2018-02-03 22:01:53,517 training [INFO ] Epoch 35 Batch 7100 Training err. 2.15159 Training err. RA 2.70205 Valid. err. 2.24372
2018-02-03 22:01:54,084 training [INFO ] Epoch 35 Batch 7120 Training err. 2.22703 Training err. RA 2.70072 Valid. err. 2.26049
2018-02-03 22:01:54,651 training [INFO ] Epoch 35 Batch 7140 Training err. 2.22867 Training err. RA 2.69939 Valid. err. 2.25129
2018-02-03 22:01:55,209 training [INFO ] Epoch 35 Batch 7160 Training err. 2.19005 Training err. RA 2.69797 Valid. err. 2.25474
2018-02-03 22:01:55,773 training [INFO ] Epoch 35 Batch 7180 Training err. 2.21538 Training err. RA 2.69663 Valid. err. 2.27452
2018-02-03 22:01:56,347 training [INFO ] Epoch 35 Batch 7200 Training err. 2.27653 Training err. RA 2.69546 Valid. err. 2.24218
2018-02-03 22:01:56,924 training [INFO ] Epoch 35 Batch 7220 Training err. 2.19908 Training err. RA 2.69409 Valid. err. 2.26342
2018-02-03 22:01:57,487 training [INFO ] Epoch 35 Batch 7240 Training err. 2.16992 Training err. RA 2.69264 Valid. err. 2.22815
2018-02-03 22:01:58,051 training [INFO ] Epoch 35 Batch 7260 Training err. 2.21057 Training err. RA 2.69131 Valid. err. 2.22676
2018-02-03 22:01:58,620 training [INFO ] Epoch 35 Batch 7280 Training err. 2.20268 Training err. RA 2.68997 Valid. err. 2.23479
2018-02-03 22:01:59,576 training [INFO ] Epoch 36 Batch 7300 Training err. 2.18783 Training err. RA 2.68859 Valid. err. 2.24707
2018-02-03 22:02:00,134 training [INFO ] Epoch 36 Batch 7320 Training err. 2.14419 Training err. RA 2.68710 Valid. err. 2.23725
2018-02-03 22:02:00,697 training [INFO ] Epoch 36 Batch 7340 Training err. 2.20846 Training err. RA 2.68580 Valid. err. 2.22810
2018-02-03 22:02:01,266 training [INFO ] Epoch 36 Batch 7360 Training err. 2.21602 Training err. RA 2.68452 Valid. err. 2.22997
2018-02-03 22:02:01,833 training [INFO ] Epoch 36 Batch 7380 Training err. 2.19399 Training err. RA 2.68319 Valid. err. 2.23485
2018-02-03 22:02:02,395 training [INFO ] Epoch 36 Batch 7400 Training err. 2.24981 Training err. RA 2.68202 Valid. err. 2.22484
2018-02-03 22:02:02,959 training [INFO ] Epoch 36 Batch 7420 Training err. 2.19922 Training err. RA 2.68072 Valid. err. 2.22369
2018-02-03 22:02:03,511 training [INFO ] Epoch 36 Batch 7440 Training err. 2.16205 Training err. RA 2.67933 Valid. err. 2.26655
2018-02-03 22:02:04,076 training [INFO ] Epoch 36 Batch 7460 Training err. 2.18739 Training err. RA 2.67801 Valid. err. 2.22349
2018-02-03 22:02:04,641 training [INFO ] Epoch 36 Batch 7480 Training err. 2.18347 Training err. RA 2.67669 Valid. err. 2.22323
2018-02-03 22:02:05,660 training [INFO ] Epoch 37 Batch 7500 Training err. 2.18913 Training err. RA 2.67539 Valid. err. 2.22035
2018-02-03 22:02:06,227 training [INFO ] Epoch 37 Batch 7520 Training err. 2.10513 Training err. RA 2.67387 Valid. err. 2.21980
2018-02-03 22:02:06,799 training [INFO ] Epoch 37 Batch 7540 Training err. 2.21211 Training err. RA 2.67264 Valid. err. 2.21631
2018-02-03 22:02:07,375 training [INFO ] Epoch 37 Batch 7560 Training err. 2.20077 Training err. RA 2.67140 Valid. err. 2.21961
2018-02-03 22:02:07,944 training [INFO ] Epoch 37 Batch 7580 Training err. 2.16425 Training err. RA 2.67006 Valid. err. 2.23461
2018-02-03 22:02:08,503 training [INFO ] Epoch 37 Batch 7600 Training err. 2.19932 Training err. RA 2.66882 Valid. err. 2.23080
2018-02-03 22:02:09,073 training [INFO ] Epoch 37 Batch 7620 Training err. 2.24073 Training err. RA 2.66770 Valid. err. 2.21828
2018-02-03 22:02:09,643 training [INFO ] Epoch 37 Batch 7640 Training err. 2.15662 Training err. RA 2.66636 Valid. err. 2.21467
2018-02-03 22:02:10,217 training [INFO ] Epoch 37 Batch 7660 Training err. 2.16254 Training err. RA 2.66504 Valid. err. 2.23773
2018-02-03 22:02:10,773 training [INFO ] Epoch 37 Batch 7680 Training err. 2.17183 Training err. RA 2.66376 Valid. err. 2.20572
2018-02-03 22:02:11,773 training [INFO ] Epoch 38 Batch 7700 Training err. 2.17192 Training err. RA 2.66248 Valid. err. 2.20339
2018-02-03 22:02:12,344 training [INFO ] Epoch 38 Batch 7720 Training err. 2.14083 Training err. RA 2.66113 Valid. err. 2.20468
2018-02-03 22:02:12,910 training [INFO ] Epoch 38 Batch 7740 Training err. 2.13977 Training err. RA 2.65978 Valid. err. 2.20546
2018-02-03 22:02:13,483 training [INFO ] Epoch 38 Batch 7760 Training err. 2.18549 Training err. RA 2.65856 Valid. err. 2.20428
2018-02-03 22:02:14,035 training [INFO ] Epoch 38 Batch 7780 Training err. 2.15507 Training err. RA 2.65727 Valid. err. 2.24204
2018-02-03 22:02:14,599 training [INFO ] Epoch 38 Batch 7800 Training err. 2.18803 Training err. RA 2.65606 Valid. err. 2.20566
2018-02-03 22:02:15,171 training [INFO ] Epoch 38 Batch 7820 Training err. 2.23863 Training err. RA 2.65499 Valid. err. 2.20600
2018-02-03 22:02:15,736 training [INFO ] Epoch 38 Batch 7840 Training err. 2.14495 Training err. RA 2.65369 Valid. err. 2.20407
2018-02-03 22:02:16,302 training [INFO ] Epoch 38 Batch 7860 Training err. 2.12981 Training err. RA 2.65236 Valid. err. 2.20309
2018-02-03 22:02:16,868 training [INFO ] Epoch 38 Batch 7880 Training err. 2.15931 Training err. RA 2.65111 Valid. err. 2.18981
2018-02-03 22:02:17,438 training [INFO ] Epoch 38 Batch 7900 Training err. 2.16010 Training err. RA 2.64987 Valid. err. 2.20590
2018-02-03 22:02:18,405 training [INFO ] Epoch 39 Batch 7920 Training err. 2.15059 Training err. RA 2.64860 Valid. err. 2.20516
2018-02-03 22:02:18,967 training [INFO ] Epoch 39 Batch 7940 Training err. 2.09132 Training err. RA 2.64720 Valid. err. 2.19804
2018-02-03 22:02:19,533 training [INFO ] Epoch 39 Batch 7960 Training err. 2.17855 Training err. RA 2.64602 Valid. err. 2.19754
2018-02-03 22:02:20,097 training [INFO ] Epoch 39 Batch 7980 Training err. 2.16645 Training err. RA 2.64482 Valid. err. 2.19545
2018-02-03 22:02:20,678 training [INFO ] Epoch 39 Batch 8000 Training err. 2.14629 Training err. RA 2.64358 Valid. err. 2.24484
2018-02-03 22:02:21,239 training [INFO ] Epoch 39 Batch 8020 Training err. 2.20445 Training err. RA 2.64248 Valid. err. 2.20876
2018-02-03 22:02:21,809 training [INFO ] Epoch 39 Batch 8040 Training err. 2.17661 Training err. RA 2.64132 Valid. err. 2.18914
2018-02-03 22:02:22,376 training [INFO ] Epoch 39 Batch 8060 Training err. 2.12521 Training err. RA 2.64004 Valid. err. 2.18041
2018-02-03 22:02:22,948 training [INFO ] Epoch 39 Batch 8080 Training err. 2.14406 Training err. RA 2.63881 Valid. err. 2.17481
2018-02-03 22:02:23,504 training [INFO ] Epoch 39 Batch 8100 Training err. 2.13231 Training err. RA 2.63756 Valid. err. 2.17612
2018-02-03 22:02:24,493 training [INFO ] Epoch 40 Batch 8120 Training err. 2.15352 Training err. RA 2.63637 Valid. err. 2.17785
2018-02-03 22:02:25,050 training [INFO ] Epoch 40 Batch 8140 Training err. 2.08174 Training err. RA 2.63501 Valid. err. 2.17596
2018-02-03 22:02:25,609 training [INFO ] Epoch 40 Batch 8160 Training err. 2.15268 Training err. RA 2.63383 Valid. err. 2.19224
2018-02-03 22:02:26,182 training [INFO ] Epoch 40 Batch 8180 Training err. 2.16170 Training err. RA 2.63267 Valid. err. 2.18181
2018-02-03 22:02:26,749 training [INFO ] Epoch 40 Batch 8200 Training err. 2.12057 Training err. RA 2.63142 Valid. err. 2.18374
2018-02-03 22:02:27,323 training [INFO ] Epoch 40 Batch 8220 Training err. 2.14359 Training err. RA 2.63023 Valid. err. 2.20579
2018-02-03 22:02:27,877 training [INFO ] Epoch 40 Batch 8240 Training err. 2.21074 Training err. RA 2.62922 Valid. err. 2.17593
2018-02-03 22:02:28,438 training [INFO ] Epoch 40 Batch 8260 Training err. 2.13045 Training err. RA 2.62801 Valid. err. 2.19060
2018-02-03 22:02:29,000 training [INFO ] Epoch 40 Batch 8280 Training err. 2.09808 Training err. RA 2.62673 Valid. err. 2.16181
2018-02-03 22:02:29,564 training [INFO ] Epoch 40 Batch 8300 Training err. 2.13978 Training err. RA 2.62556 Valid. err. 2.16352
2018-02-03 22:02:30,140 training [INFO ] Epoch 40 Batch 8320 Training err. 2.12648 Training err. RA 2.62436 Valid. err. 2.16984
2018-02-03 22:02:31,124 training [INFO ] Epoch 41 Batch 8340 Training err. 2.12133 Training err. RA 2.62315 Valid. err. 2.17718
2018-02-03 22:02:31,694 training [INFO ] Epoch 41 Batch 8360 Training err. 2.07662 Training err. RA 2.62184 Valid. err. 2.17229
2018-02-03 22:02:32,263 training [INFO ] Epoch 41 Batch 8380 Training err. 2.13879 Training err. RA 2.62069 Valid. err. 2.16292
2018-02-03 22:02:32,831 training [INFO ] Epoch 41 Batch 8400 Training err. 2.14925 Training err. RA 2.61957 Valid. err. 2.16801
2018-02-03 22:02:33,391 training [INFO ] Epoch 41 Batch 8420 Training err. 2.12690 Training err. RA 2.61840 Valid. err. 2.17516
2018-02-03 22:02:33,956 training [INFO ] Epoch 41 Batch 8440 Training err. 2.18207 Training err. RA 2.61736 Valid. err. 2.16709
2018-02-03 22:02:34,513 training [INFO ] Epoch 41 Batch 8460 Training err. 2.13469 Training err. RA 2.61622 Valid. err. 2.16067
2018-02-03 22:02:35,120 training [INFO ] Epoch 41 Batch 8480 Training err. 2.09479 Training err. RA 2.61499 Valid. err. 2.19409
2018-02-03 22:02:35,721 training [INFO ] Epoch 41 Batch 8500 Training err. 2.11811 Training err. RA 2.61382 Valid. err. 2.16115
2018-02-03 22:02:36,345 training [INFO ] Epoch 41 Batch 8520 Training err. 2.11309 Training err. RA 2.61265 Valid. err. 2.15453
2018-02-03 22:02:37,360 training [INFO ] Epoch 42 Batch 8540 Training err. 2.12297 Training err. RA 2.61150 Valid. err. 2.15572
2018-02-03 22:02:37,937 training [INFO ] Epoch 42 Batch 8560 Training err. 2.04117 Training err. RA 2.61017 Valid. err. 2.15958
2018-02-03 22:02:38,511 training [INFO ] Epoch 42 Batch 8580 Training err. 2.14140 Training err. RA 2.60908 Valid. err. 2.15176
2018-02-03 22:02:39,098 training [INFO ] Epoch 42 Batch 8600 Training err. 2.13712 Training err. RA 2.60798 Valid. err. 2.15427
2018-02-03 22:02:39,710 training [INFO ] Epoch 42 Batch 8620 Training err. 2.10024 Training err. RA 2.60680 Valid. err. 2.16877
2018-02-03 22:02:40,280 training [INFO ] Epoch 42 Batch 8640 Training err. 2.13241 Training err. RA 2.60570 Valid. err. 2.16230
2018-02-03 22:02:40,855 training [INFO ] Epoch 42 Batch 8660 Training err. 2.17992 Training err. RA 2.60472 Valid. err. 2.15630
2018-02-03 22:02:41,432 training [INFO ] Epoch 42 Batch 8680 Training err. 2.09160 Training err. RA 2.60354 Valid. err. 2.14710
2018-02-03 22:02:42,012 training [INFO ] Epoch 42 Batch 8700 Training err. 2.09631 Training err. RA 2.60237 Valid. err. 2.17316
2018-02-03 22:02:42,589 training [INFO ] Epoch 42 Batch 8720 Training err. 2.10534 Training err. RA 2.60123 Valid. err. 2.14452
2018-02-03 22:02:43,617 training [INFO ] Epoch 43 Batch 8740 Training err. 2.10598 Training err. RA 2.60010 Valid. err. 2.14807
2018-02-03 22:02:44,242 training [INFO ] Epoch 43 Batch 8760 Training err. 2.07631 Training err. RA 2.59890 Valid. err. 2.14187
2018-02-03 22:02:44,827 training [INFO ] Epoch 43 Batch 8780 Training err. 2.07864 Training err. RA 2.59772 Valid. err. 2.13827
2018-02-03 22:02:45,415 training [INFO ] Epoch 43 Batch 8800 Training err. 2.12001 Training err. RA 2.59663 Valid. err. 2.14772
2018-02-03 22:02:45,991 training [INFO ] Epoch 43 Batch 8820 Training err. 2.09418 Training err. RA 2.59549 Valid. err. 2.16919
2018-02-03 22:02:46,573 training [INFO ] Epoch 43 Batch 8840 Training err. 2.12211 Training err. RA 2.59442 Valid. err. 2.14603
2018-02-03 22:02:47,202 training [INFO ] Epoch 43 Batch 8860 Training err. 2.17871 Training err. RA 2.59348 Valid. err. 2.14937
2018-02-03 22:02:47,787 training [INFO ] Epoch 43 Batch 8880 Training err. 2.08371 Training err. RA 2.59233 Valid. err. 2.14193
2018-02-03 22:02:48,349 training [INFO ] Epoch 43 Batch 8900 Training err. 2.06715 Training err. RA 2.59115 Valid. err. 2.13845
2018-02-03 22:02:48,925 training [INFO ] Epoch 43 Batch 8920 Training err. 2.09594 Training err. RA 2.59004 Valid. err. 2.13021
2018-02-03 22:02:49,515 training [INFO ] Epoch 43 Batch 8940 Training err. 2.09280 Training err. RA 2.58893 Valid. err. 2.14363
2018-02-03 22:02:50,751 training [INFO ] Epoch 44 Batch 8960 Training err. 2.09066 Training err. RA 2.58782 Valid. err. 2.13570
2018-02-03 22:02:51,411 training [INFO ] Epoch 44 Batch 8980 Training err. 2.03248 Training err. RA 2.58658 Valid. err. 2.14704
2018-02-03 22:02:52,066 training [INFO ] Epoch 44 Batch 9000 Training err. 2.11525 Training err. RA 2.58553 Valid. err. 2.13107
2018-02-03 22:02:52,724 training [INFO ] Epoch 44 Batch 9020 Training err. 2.10554 Training err. RA 2.58447 Valid. err. 2.13674
2018-02-03 22:02:53,368 training [INFO ] Epoch 44 Batch 9040 Training err. 2.08713 Training err. RA 2.58337 Valid. err. 2.17824
2018-02-03 22:02:54,009 training [INFO ] Epoch 44 Batch 9060 Training err. 2.14226 Training err. RA 2.58240 Valid. err. 2.15472
2018-02-03 22:02:54,592 training [INFO ] Epoch 44 Batch 9080 Training err. 2.12016 Training err. RA 2.58138 Valid. err. 2.13179
2018-02-03 22:02:55,181 training [INFO ] Epoch 44 Batch 9100 Training err. 2.06482 Training err. RA 2.58024 Valid. err. 2.12352
2018-02-03 22:02:55,767 training [INFO ] Epoch 44 Batch 9120 Training err. 2.08114 Training err. RA 2.57915 Valid. err. 2.11718
2018-02-03 22:02:56,351 training [INFO ] Epoch 44 Batch 9140 Training err. 2.07194 Training err. RA 2.57804 Valid. err. 2.11945
2018-02-03 22:02:57,390 training [INFO ] Epoch 45 Batch 9160 Training err. 2.09316 Training err. RA 2.57698 Valid. err. 2.12442
2018-02-03 22:02:57,966 training [INFO ] Epoch 45 Batch 9180 Training err. 2.02214 Training err. RA 2.57577 Valid. err. 2.12133
2018-02-03 22:02:58,547 training [INFO ] Epoch 45 Batch 9200 Training err. 2.09524 Training err. RA 2.57473 Valid. err. 2.12537
2018-02-03 22:02:59,125 training [INFO ] Epoch 45 Batch 9220 Training err. 2.10253 Training err. RA 2.57370 Valid. err. 2.12796
2018-02-03 22:02:59,689 training [INFO ] Epoch 45 Batch 9240 Training err. 2.06485 Training err. RA 2.57260 Valid. err. 2.12641
2018-02-03 22:03:00,291 training [INFO ] Epoch 45 Batch 9260 Training err. 2.08111 Training err. RA 2.57154 Valid. err. 2.14746
2018-02-03 22:03:00,860 training [INFO ] Epoch 45 Batch 9280 Training err. 2.15527 Training err. RA 2.57064 Valid. err. 2.11943
2018-02-03 22:03:01,459 training [INFO ] Epoch 45 Batch 9300 Training err. 2.07415 Training err. RA 2.56957 Valid. err. 2.13345
2018-02-03 22:03:02,041 training [INFO ] Epoch 45 Batch 9320 Training err. 2.03870 Training err. RA 2.56843 Valid. err. 2.10705
2018-02-03 22:03:02,617 training [INFO ] Epoch 45 Batch 9340 Training err. 2.08055 Training err. RA 2.56739 Valid. err. 2.10597
2018-02-03 22:03:03,194 training [INFO ] Epoch 45 Batch 9360 Training err. 2.06294 Training err. RA 2.56631 Valid. err. 2.11548
2018-02-03 22:03:04,202 training [INFO ] Epoch 46 Batch 9380 Training err. 2.06864 Training err. RA 2.56525 Valid. err. 2.11802
2018-02-03 22:03:04,766 training [INFO ] Epoch 46 Batch 9400 Training err. 2.02107 Training err. RA 2.56409 Valid. err. 2.11689
2018-02-03 22:03:05,355 training [INFO ] Epoch 46 Batch 9420 Training err. 2.08240 Training err. RA 2.56307 Valid. err. 2.10505
2018-02-03 22:03:05,934 training [INFO ] Epoch 46 Batch 9440 Training err. 2.09535 Training err. RA 2.56208 Valid. err. 2.11633
2018-02-03 22:03:06,505 training [INFO ] Epoch 46 Batch 9460 Training err. 2.06627 Training err. RA 2.56103 Valid. err. 2.11732
2018-02-03 22:03:07,070 training [INFO ] Epoch 46 Batch 9480 Training err. 2.12705 Training err. RA 2.56012 Valid. err. 2.12476
2018-02-03 22:03:07,665 training [INFO ] Epoch 46 Batch 9500 Training err. 2.08050 Training err. RA 2.55911 Valid. err. 2.10820
2018-02-03 22:03:08,233 training [INFO ] Epoch 46 Batch 9520 Training err. 2.03892 Training err. RA 2.55801 Valid. err. 2.13396
2018-02-03 22:03:08,797 training [INFO ] Epoch 46 Batch 9540 Training err. 2.06052 Training err. RA 2.55697 Valid. err. 2.10926
2018-02-03 22:03:09,375 training [INFO ] Epoch 46 Batch 9560 Training err. 2.05502 Training err. RA 2.55592 Valid. err. 2.09753
2018-02-03 22:03:10,646 training [INFO ] Epoch 47 Batch 9580 Training err. 2.06911 Training err. RA 2.55490 Valid. err. 2.10095
2018-02-03 22:03:11,325 training [INFO ] Epoch 47 Batch 9600 Training err. 1.98822 Training err. RA 2.55372 Valid. err. 2.11240
2018-02-03 22:03:12,020 training [INFO ] Epoch 47 Batch 9620 Training err. 2.08768 Training err. RA 2.55275 Valid. err. 2.09994
2018-02-03 22:03:12,653 training [INFO ] Epoch 47 Batch 9640 Training err. 2.08371 Training err. RA 2.55178 Valid. err. 2.10677
2018-02-03 22:03:13,304 training [INFO ] Epoch 47 Batch 9660 Training err. 2.04559 Training err. RA 2.55073 Valid. err. 2.10473
2018-02-03 22:03:13,917 training [INFO ] Epoch 47 Batch 9680 Training err. 2.07510 Training err. RA 2.54975 Valid. err. 2.10722
2018-02-03 22:03:14,502 training [INFO ] Epoch 47 Batch 9700 Training err. 2.12790 Training err. RA 2.54888 Valid. err. 2.10361
2018-02-03 22:03:15,169 training [INFO ] Epoch 47 Batch 9720 Training err. 2.03860 Training err. RA 2.54783 Valid. err. 2.09293
2018-02-03 22:03:15,789 training [INFO ] Epoch 47 Batch 9740 Training err. 2.04081 Training err. RA 2.54679 Valid. err. 2.11412
2018-02-03 22:03:16,403 training [INFO ] Epoch 47 Batch 9760 Training err. 2.04989 Training err. RA 2.54577 Valid. err. 2.09145
2018-02-03 22:03:17,430 training [INFO ] Epoch 48 Batch 9780 Training err. 2.05022 Training err. RA 2.54476 Valid. err. 2.10671
2018-02-03 22:03:17,993 training [INFO ] Epoch 48 Batch 9800 Training err. 2.02319 Training err. RA 2.54369 Valid. err. 2.08844
2018-02-03 22:03:18,559 training [INFO ] Epoch 48 Batch 9820 Training err. 2.02909 Training err. RA 2.54264 Valid. err. 2.08839
2018-02-03 22:03:19,130 training [INFO ] Epoch 48 Batch 9840 Training err. 2.06829 Training err. RA 2.54168 Valid. err. 2.09858
2018-02-03 22:03:19,704 training [INFO ] Epoch 48 Batch 9860 Training err. 2.04569 Training err. RA 2.54067 Valid. err. 2.11172
2018-02-03 22:03:20,352 training [INFO ] Epoch 48 Batch 9880 Training err. 2.06304 Training err. RA 2.53971 Valid. err. 2.09529
2018-02-03 22:03:20,989 training [INFO ] Epoch 48 Batch 9900 Training err. 2.12937 Training err. RA 2.53888 Valid. err. 2.10174
2018-02-03 22:03:21,553 training [INFO ] Epoch 48 Batch 9920 Training err. 2.03129 Training err. RA 2.53786 Valid. err. 2.09110
2018-02-03 22:03:22,130 training [INFO ] Epoch 48 Batch 9940 Training err. 2.01543 Training err. RA 2.53680 Valid. err. 2.08732
2018-02-03 22:03:22,702 training [INFO ] Epoch 48 Batch 9960 Training err. 2.04301 Training err. RA 2.53581 Valid. err. 2.08094
2018-02-03 22:03:23,304 training [INFO ] Epoch 48 Batch 9980 Training err. 2.03723 Training err. RA 2.53481 Valid. err. 2.09000
2018-02-03 22:03:24,294 training [INFO ] Epoch 49 Batch10000 Training err. 2.03681 Training err. RA 2.53382 Valid. err. 2.08079
2018-02-03 22:03:24,885 training [INFO ] Epoch 49 Batch10020 Training err. 1.98535 Training err. RA 2.53272 Valid. err. 2.10009
2018-02-03 22:03:25,465 training [INFO ] Epoch 49 Batch10040 Training err. 2.06549 Training err. RA 2.53179 Valid. err. 2.08110
2018-02-03 22:03:26,031 training [INFO ] Epoch 49 Batch10060 Training err. 2.05639 Training err. RA 2.53085 Valid. err. 2.08784
2018-02-03 22:03:26,604 training [INFO ] Epoch 49 Batch10080 Training err. 2.03499 Training err. RA 2.52986 Valid. err. 2.10604
2018-02-03 22:03:27,169 training [INFO ] Epoch 49 Batch10100 Training err. 2.08942 Training err. RA 2.52899 Valid. err. 2.10791
2018-02-03 22:03:27,734 training [INFO ] Epoch 49 Batch10120 Training err. 2.07272 Training err. RA 2.52809 Valid. err. 2.08472
2018-02-03 22:03:28,298 training [INFO ] Epoch 49 Batch10140 Training err. 2.01493 Training err. RA 2.52708 Valid. err. 2.07547
2018-02-03 22:03:28,875 training [INFO ] Epoch 49 Batch10160 Training err. 2.02843 Training err. RA 2.52610 Valid. err. 2.07001
2018-02-03 22:03:29,450 training [INFO ] Epoch 49 Batch10180 Training err. 2.02179 Training err. RA 2.52510 Valid. err. 2.07496
2018-02-03 22:03:30,682 training [INFO ] Epoch 50 Batch10200 Training err. 2.03595 Training err. RA 2.52415 Valid. err. 2.07204
2018-02-03 22:03:31,332 training [INFO ] Epoch 50 Batch10220 Training err. 1.97084 Training err. RA 2.52306 Valid. err. 2.07525
2018-02-03 22:03:31,965 training [INFO ] Epoch 50 Batch10240 Training err. 2.04995 Training err. RA 2.52214 Valid. err. 2.07491
2018-02-03 22:03:32,606 training [INFO ] Epoch 50 Batch10260 Training err. 2.05575 Training err. RA 2.52123 Valid. err. 2.08655
2018-02-03 22:03:33,237 training [INFO ] Epoch 50 Batch10280 Training err. 2.01638 Training err. RA 2.52025 Valid. err. 2.07853
2018-02-03 22:03:33,830 training [INFO ] Epoch 50 Batch10300 Training err. 2.02739 Training err. RA 2.51929 Valid. err. 2.10226
2018-02-03 22:03:34,417 training [INFO ] Epoch 50 Batch10320 Training err. 2.11040 Training err. RA 2.51850 Valid. err. 2.07296
2018-02-03 22:03:34,993 training [INFO ] Epoch 50 Batch10340 Training err. 2.02644 Training err. RA 2.51755 Valid. err. 2.08520
2018-02-03 22:03:35,576 training [INFO ] Epoch 50 Batch10360 Training err. 1.98976 Training err. RA 2.51653 Valid. err. 2.06148
2018-02-03 22:03:36,154 training [INFO ] Epoch 50 Batch10380 Training err. 2.03009 Training err. RA 2.51559 Valid. err. 2.06032
2018-02-03 22:03:36,736 training [INFO ] Epoch 50 Batch10400 Training err. 2.01026 Training err. RA 2.51462 Valid. err. 2.06847
2018-02-03 22:03:37,760 training [INFO ] Epoch 51 Batch10420 Training err. 2.01276 Training err. RA 2.51366 Valid. err. 2.06782
2018-02-03 22:03:38,324 training [INFO ] Epoch 51 Batch10440 Training err. 1.97692 Training err. RA 2.51263 Valid. err. 2.07132
2018-02-03 22:03:38,900 training [INFO ] Epoch 51 Batch10460 Training err. 2.03652 Training err. RA 2.51172 Valid. err. 2.05963
2018-02-03 22:03:39,464 training [INFO ] Epoch 51 Batch10480 Training err. 2.04835 Training err. RA 2.51083 Valid. err. 2.06956
2018-02-03 22:03:40,032 training [INFO ] Epoch 51 Batch10500 Training err. 2.01482 Training err. RA 2.50989 Valid. err. 2.06545
2018-02-03 22:03:40,598 training [INFO ] Epoch 51 Batch10520 Training err. 2.08231 Training err. RA 2.50907 Valid. err. 2.13857
2018-02-03 22:03:41,169 training [INFO ] Epoch 51 Batch10540 Training err. 2.03707 Training err. RA 2.50818 Valid. err. 2.06549
2018-02-03 22:03:41,732 training [INFO ] Epoch 51 Batch10560 Training err. 1.99203 Training err. RA 2.50720 Valid. err. 2.08330
2018-02-03 22:03:42,309 training [INFO ] Epoch 51 Batch10580 Training err. 2.01109 Training err. RA 2.50626 Valid. err. 2.06450
2018-02-03 22:03:42,879 training [INFO ] Epoch 51 Batch10600 Training err. 2.00751 Training err. RA 2.50532 Valid. err. 2.05178
2018-02-03 22:03:43,877 training [INFO ] Epoch 52 Batch10620 Training err. 2.00986 Training err. RA 2.50439 Valid. err. 2.05304
2018-02-03 22:03:44,448 training [INFO ] Epoch 52 Batch10640 Training err. 1.94574 Training err. RA 2.50334 Valid. err. 2.07391
2018-02-03 22:03:45,015 training [INFO ] Epoch 52 Batch10660 Training err. 2.04173 Training err. RA 2.50247 Valid. err. 2.05678
2018-02-03 22:03:45,633 training [INFO ] Epoch 52 Batch10680 Training err. 2.04005 Training err. RA 2.50161 Valid. err. 2.06329
2018-02-03 22:03:46,550 training [INFO ] Epoch 52 Batch10700 Training err. 1.99802 Training err. RA 2.50067 Valid. err. 2.05561
2018-02-03 22:03:47,160 training [INFO ] Epoch 52 Batch10720 Training err. 2.02786 Training err. RA 2.49978 Valid. err. 2.06278
2018-02-03 22:03:47,794 training [INFO ] Epoch 52 Batch10740 Training err. 2.08799 Training err. RA 2.49902 Valid. err. 2.06339
2018-02-03 22:03:48,282 training [INFO ] Epoch 52 Batch10760 Training err. 1.99461 Training err. RA 2.49808 Valid. err. 2.05122
2018-02-03 22:03:48,777 training [INFO ] Epoch 52 Batch10780 Training err. 1.99382 Training err. RA 2.49714 Valid. err. 2.06086
2018-02-03 22:03:49,264 training [INFO ] Epoch 52 Batch10800 Training err. 2.00238 Training err. RA 2.49623 Valid. err. 2.04644
2018-02-03 22:03:50,150 training [INFO ] Epoch 53 Batch10820 Training err. 1.99343 Training err. RA 2.49530 Valid. err. 2.04915
2018-02-03 22:03:50,688 training [INFO ] Epoch 53 Batch10840 Training err. 1.97530 Training err. RA 2.49434 Valid. err. 2.04379
2018-02-03 22:03:51,270 training [INFO ] Epoch 53 Batch10860 Training err. 1.98810 Training err. RA 2.49341 Valid. err. 2.04557
2018-02-03 22:03:51,875 training [INFO ] Epoch 53 Batch10880 Training err. 2.02522 Training err. RA 2.49255 Valid. err. 2.05925
2018-02-03 22:03:52,626 training [INFO ] Epoch 53 Batch10900 Training err. 2.00221 Training err. RA 2.49165 Valid. err. 2.06504
2018-02-03 22:03:53,336 training [INFO ] Epoch 53 Batch10920 Training err. 2.01580 Training err. RA 2.49077 Valid. err. 2.05507
2018-02-03 22:03:53,936 training [INFO ] Epoch 53 Batch10940 Training err. 2.09181 Training err. RA 2.49005 Valid. err. 2.07109
2018-02-03 22:03:54,711 training [INFO ] Epoch 53 Batch10960 Training err. 1.98718 Training err. RA 2.48913 Valid. err. 2.05116
2018-02-03 22:03:55,448 training [INFO ] Epoch 53 Batch10980 Training err. 1.97228 Training err. RA 2.48819 Valid. err. 2.04629
2018-02-03 22:03:55,943 training [INFO ] Epoch 53 Batch11000 Training err. 1.99668 Training err. RA 2.48729 Valid. err. 2.04038
2018-02-03 22:03:56,569 training [INFO ] Epoch 53 Batch11020 Training err. 1.99130 Training err. RA 2.48639 Valid. err. 2.04700
2018-02-03 22:03:57,778 training [INFO ] Epoch 54 Batch11040 Training err. 1.98143 Training err. RA 2.48548 Valid. err. 2.03997
2018-02-03 22:03:58,349 training [INFO ] Epoch 54 Batch11060 Training err. 1.94538 Training err. RA 2.48450 Valid. err. 2.05403
2018-02-03 22:03:58,942 training [INFO ] Epoch 54 Batch11080 Training err. 2.02170 Training err. RA 2.48367 Valid. err. 2.04175
2018-02-03 22:03:59,432 training [INFO ] Epoch 54 Batch11100 Training err. 2.01572 Training err. RA 2.48282 Valid. err. 2.04711
2018-02-03 22:03:59,963 training [INFO ] Epoch 54 Batch11120 Training err. 1.98963 Training err. RA 2.48194 Valid. err. 2.05186
2018-02-03 22:04:00,446 training [INFO ] Epoch 54 Batch11140 Training err. 2.04777 Training err. RA 2.48116 Valid. err. 2.06545
2018-02-03 22:04:00,930 training [INFO ] Epoch 54 Batch11160 Training err. 2.03433 Training err. RA 2.48036 Valid. err. 2.04599
2018-02-03 22:04:01,412 training [INFO ] Epoch 54 Batch11180 Training err. 1.97296 Training err. RA 2.47945 Valid. err. 2.03552
2018-02-03 22:04:01,894 training [INFO ] Epoch 54 Batch11200 Training err. 1.98297 Training err. RA 2.47856 Valid. err. 2.03098
2018-02-03 22:04:02,375 training [INFO ] Epoch 54 Batch11220 Training err. 1.97908 Training err. RA 2.47767 Valid. err. 2.04150
2018-02-03 22:04:03,240 training [INFO ] Epoch 55 Batch11240 Training err. 1.98246 Training err. RA 2.47679 Valid. err. 2.03062
2018-02-03 22:04:03,722 training [INFO ] Epoch 55 Batch11260 Training err. 1.92923 Training err. RA 2.47582 Valid. err. 2.03831
2018-02-03 22:04:04,205 training [INFO ] Epoch 55 Batch11280 Training err. 2.00897 Training err. RA 2.47499 Valid. err. 2.03174
2018-02-03 22:04:04,687 training [INFO ] Epoch 55 Batch11300 Training err. 2.01673 Training err. RA 2.47418 Valid. err. 2.04867
2018-02-03 22:04:05,164 training [INFO ] Epoch 55 Batch11320 Training err. 1.97401 Training err. RA 2.47329 Valid. err. 2.04037
2018-02-03 22:04:05,642 training [INFO ] Epoch 55 Batch11340 Training err. 1.98471 Training err. RA 2.47243 Valid. err. 2.06706
2018-02-03 22:04:06,124 training [INFO ] Epoch 55 Batch11360 Training err. 2.06958 Training err. RA 2.47172 Valid. err. 2.03316
2018-02-03 22:04:06,599 training [INFO ] Epoch 55 Batch11380 Training err. 1.98532 Training err. RA 2.47087 Valid. err. 2.04404
2018-02-03 22:04:07,077 training [INFO ] Epoch 55 Batch11400 Training err. 1.94849 Training err. RA 2.46995 Valid. err. 2.02312
2018-02-03 22:04:07,556 training [INFO ] Epoch 55 Batch11420 Training err. 1.98560 Training err. RA 2.46910 Valid. err. 2.02439
2018-02-03 22:04:08,036 training [INFO ] Epoch 55 Batch11440 Training err. 1.96723 Training err. RA 2.46823 Valid. err. 2.03107
2018-02-03 22:04:08,892 training [INFO ] Epoch 56 Batch11460 Training err. 1.96715 Training err. RA 2.46735 Valid. err. 2.02776
2018-02-03 22:04:09,371 training [INFO ] Epoch 56 Batch11480 Training err. 1.93622 Training err. RA 2.46643 Valid. err. 2.03353
2018-02-03 22:04:09,851 training [INFO ] Epoch 56 Batch11500 Training err. 1.99671 Training err. RA 2.46561 Valid. err. 2.02234
2018-02-03 22:04:10,333 training [INFO ] Epoch 56 Batch11520 Training err. 2.00923 Training err. RA 2.46482 Valid. err. 2.03127
2018-02-03 22:04:10,814 training [INFO ] Epoch 56 Batch11540 Training err. 1.97199 Training err. RA 2.46396 Valid. err. 2.02910
2018-02-03 22:04:11,299 training [INFO ] Epoch 56 Batch11560 Training err. 2.04250 Training err. RA 2.46323 Valid. err. 2.06018
2018-02-03 22:04:11,779 training [INFO ] Epoch 56 Batch11580 Training err. 1.99501 Training err. RA 2.46243 Valid. err. 2.02915
2018-02-03 22:04:12,260 training [INFO ] Epoch 56 Batch11600 Training err. 1.95183 Training err. RA 2.46155 Valid. err. 2.03938
2018-02-03 22:04:12,738 training [INFO ] Epoch 56 Batch11620 Training err. 1.96839 Training err. RA 2.46070 Valid. err. 2.02566
2018-02-03 22:04:13,218 training [INFO ] Epoch 56 Batch11640 Training err. 1.96828 Training err. RA 2.45985 Valid. err. 2.01514
2018-02-03 22:04:14,071 training [INFO ] Epoch 57 Batch11660 Training err. 1.96535 Training err. RA 2.45900 Valid. err. 2.01689
2018-02-03 22:04:14,544 training [INFO ] Epoch 57 Batch11680 Training err. 1.90704 Training err. RA 2.45806 Valid. err. 2.03308
2018-02-03 22:04:15,023 training [INFO ] Epoch 57 Batch11700 Training err. 2.00035 Training err. RA 2.45727 Valid. err. 2.02058
2018-02-03 22:04:15,501 training [INFO ] Epoch 57 Batch11720 Training err. 2.00385 Training err. RA 2.45650 Valid. err. 2.02498
2018-02-03 22:04:15,986 training [INFO ] Epoch 57 Batch11740 Training err. 1.95769 Training err. RA 2.45565 Valid. err. 2.01676
2018-02-03 22:04:16,462 training [INFO ] Epoch 57 Batch11760 Training err. 1.98916 Training err. RA 2.45486 Valid. err. 2.02670
2018-02-03 22:04:16,944 training [INFO ] Epoch 57 Batch11780 Training err. 2.04294 Training err. RA 2.45416 Valid. err. 2.02384
2018-02-03 22:04:17,420 training [INFO ] Epoch 57 Batch11800 Training err. 1.95628 Training err. RA 2.45331 Valid. err. 2.01625
2018-02-03 22:04:17,911 training [INFO ] Epoch 57 Batch11820 Training err. 1.95299 Training err. RA 2.45247 Valid. err. 2.01895
2018-02-03 22:04:18,393 training [INFO ] Epoch 57 Batch11840 Training err. 1.96287 Training err. RA 2.45164 Valid. err. 2.01054
2018-02-03 22:04:19,264 training [INFO ] Epoch 58 Batch11860 Training err. 1.95138 Training err. RA 2.45080 Valid. err. 2.01225
2018-02-03 22:04:19,747 training [INFO ] Epoch 58 Batch11880 Training err. 1.93691 Training err. RA 2.44993 Valid. err. 2.01002
2018-02-03 22:04:20,229 training [INFO ] Epoch 58 Batch11900 Training err. 1.94962 Training err. RA 2.44909 Valid. err. 2.00910
2018-02-03 22:04:20,719 training [INFO ] Epoch 58 Batch11920 Training err. 1.98787 Training err. RA 2.44832 Valid. err. 2.02829
2018-02-03 22:04:21,203 training [INFO ] Epoch 58 Batch11940 Training err. 1.96630 Training err. RA 2.44751 Valid. err. 2.02575
2018-02-03 22:04:21,676 training [INFO ] Epoch 58 Batch11960 Training err. 1.97654 Training err. RA 2.44672 Valid. err. 2.01963
2018-02-03 22:04:22,151 training [INFO ] Epoch 58 Batch11980 Training err. 2.04745 Training err. RA 2.44606 Valid. err. 2.02762
2018-02-03 22:04:22,631 training [INFO ] Epoch 58 Batch12000 Training err. 1.94751 Training err. RA 2.44522 Valid. err. 2.01250
2018-02-03 22:04:23,110 training [INFO ] Epoch 58 Batch12020 Training err. 1.93509 Training err. RA 2.44438 Valid. err. 2.01161
2018-02-03 22:04:23,589 training [INFO ] Epoch 58 Batch12040 Training err. 1.95733 Training err. RA 2.44357 Valid. err. 2.00475
2018-02-03 22:04:24,070 training [INFO ] Epoch 58 Batch12060 Training err. 1.95313 Training err. RA 2.44275 Valid. err. 2.01348
2018-02-03 22:04:24,923 training [INFO ] Epoch 59 Batch12080 Training err. 1.94268 Training err. RA 2.44193 Valid. err. 2.00762
2018-02-03 22:04:25,400 training [INFO ] Epoch 59 Batch12100 Training err. 1.90811 Training err. RA 2.44104 Valid. err. 2.01386
2018-02-03 22:04:25,876 training [INFO ] Epoch 59 Batch12120 Training err. 1.98266 Training err. RA 2.44029 Valid. err. 2.00991
2018-02-03 22:04:26,358 training [INFO ] Epoch 59 Batch12140 Training err. 1.98167 Training err. RA 2.43953 Valid. err. 2.01272
2018-02-03 22:04:26,835 training [INFO ] Epoch 59 Batch12160 Training err. 1.95162 Training err. RA 2.43873 Valid. err. 2.01098
2018-02-03 22:04:27,311 training [INFO ] Epoch 59 Batch12180 Training err. 2.01242 Training err. RA 2.43803 Valid. err. 2.03980
2018-02-03 22:04:27,790 training [INFO ] Epoch 59 Batch12200 Training err. 1.99014 Training err. RA 2.43729 Valid. err. 2.01190
2018-02-03 22:04:28,268 training [INFO ] Epoch 59 Batch12220 Training err. 1.93629 Training err. RA 2.43647 Valid. err. 1.99960
2018-02-03 22:04:28,747 training [INFO ] Epoch 59 Batch12240 Training err. 1.94321 Training err. RA 2.43567 Valid. err. 1.99719
2018-02-03 22:04:29,226 training [INFO ] Epoch 59 Batch12260 Training err. 1.94397 Training err. RA 2.43487 Valid. err. 2.01295
2018-02-03 22:04:30,070 training [INFO ] Epoch 60 Batch12280 Training err. 1.94445 Training err. RA 2.43407 Valid. err. 2.00120
2018-02-03 22:04:30,543 training [INFO ] Epoch 60 Batch12300 Training err. 1.89334 Training err. RA 2.43319 Valid. err. 2.00571
2018-02-03 22:04:31,025 training [INFO ] Epoch 60 Batch12320 Training err. 1.97119 Training err. RA 2.43244 Valid. err. 1.99611
2018-02-03 22:04:31,500 training [INFO ] Epoch 60 Batch12340 Training err. 1.98280 Training err. RA 2.43171 Valid. err. 2.01266
2018-02-03 22:04:31,979 training [INFO ] Epoch 60 Batch12360 Training err. 1.93880 Training err. RA 2.43091 Valid. err. 2.00948
2018-02-03 22:04:32,463 training [INFO ] Epoch 60 Batch12380 Training err. 1.94788 Training err. RA 2.43013 Valid. err. 2.03584
2018-02-03 22:04:32,940 training [INFO ] Epoch 60 Batch12400 Training err. 2.02941 Training err. RA 2.42949 Valid. err. 1.99942
2018-02-03 22:04:33,419 training [INFO ] Epoch 60 Batch12420 Training err. 1.94932 Training err. RA 2.42871 Valid. err. 2.00931
2018-02-03 22:04:33,901 training [INFO ] Epoch 60 Batch12440 Training err. 1.91333 Training err. RA 2.42788 Valid. err. 1.99060
2018-02-03 22:04:34,385 training [INFO ] Epoch 60 Batch12460 Training err. 1.94762 Training err. RA 2.42711 Valid. err. 1.99324
2018-02-03 22:04:34,865 training [INFO ] Epoch 60 Batch12480 Training err. 1.93147 Training err. RA 2.42632 Valid. err. 2.00184
2018-02-03 22:04:35,134 __main__ [INFO ] End of training
2018-02-03 22:04:35,382 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 22:04:35,993 training [INFO ] Epoch  1 Batch   20 Training err. 3.55549 Training err. RA 3.55549 Valid. err. 3.22915
2018-02-03 22:04:36,476 training [INFO ] Epoch  1 Batch   40 Training err. 3.17873 Training err. RA 3.36711 Valid. err. 3.20575
2018-02-03 22:04:36,959 training [INFO ] Epoch  1 Batch   60 Training err. 3.16397 Training err. RA 3.29940 Valid. err. 3.19950
2018-02-03 22:04:37,440 training [INFO ] Epoch  1 Batch   80 Training err. 3.14643 Training err. RA 3.26115 Valid. err. 3.20237
2018-02-03 22:04:37,920 training [INFO ] Epoch  1 Batch  100 Training err. 3.13418 Training err. RA 3.23576 Valid. err. 3.18252
2018-02-03 22:04:38,401 training [INFO ] Epoch  1 Batch  120 Training err. 3.16008 Training err. RA 3.22315 Valid. err. 3.18262
2018-02-03 22:04:38,891 training [INFO ] Epoch  1 Batch  140 Training err. 3.11213 Training err. RA 3.20729 Valid. err. 3.17885
2018-02-03 22:04:39,371 training [INFO ] Epoch  1 Batch  160 Training err. 3.07529 Training err. RA 3.19079 Valid. err. 3.17769
2018-02-03 22:04:39,851 training [INFO ] Epoch  1 Batch  180 Training err. 3.13794 Training err. RA 3.18492 Valid. err. 3.15168
2018-02-03 22:04:40,332 training [INFO ] Epoch  1 Batch  200 Training err. 3.11130 Training err. RA 3.17755 Valid. err. 3.12295
2018-02-03 22:04:41,177 training [INFO ] Epoch  2 Batch  220 Training err. 3.08393 Training err. RA 3.16904 Valid. err. 3.26741
2018-02-03 22:04:41,655 training [INFO ] Epoch  2 Batch  240 Training err. 3.01195 Training err. RA 3.15595 Valid. err. 3.17567
2018-02-03 22:04:42,136 training [INFO ] Epoch  2 Batch  260 Training err. 3.03822 Training err. RA 3.14690 Valid. err. 3.04608
2018-02-03 22:04:42,615 training [INFO ] Epoch  2 Batch  280 Training err. 2.97789 Training err. RA 3.13482 Valid. err. 2.98763
2018-02-03 22:04:43,098 training [INFO ] Epoch  2 Batch  300 Training err. 2.91681 Training err. RA 3.12029 Valid. err. 2.96540
2018-02-03 22:04:43,579 training [INFO ] Epoch  2 Batch  320 Training err. 2.92523 Training err. RA 3.10810 Valid. err. 2.90704
2018-02-03 22:04:44,061 training [INFO ] Epoch  2 Batch  340 Training err. 2.85528 Training err. RA 3.09323 Valid. err. 2.87423
2018-02-03 22:04:44,542 training [INFO ] Epoch  2 Batch  360 Training err. 2.82031 Training err. RA 3.07807 Valid. err. 2.85004
2018-02-03 22:04:45,023 training [INFO ] Epoch  2 Batch  380 Training err. 2.77454 Training err. RA 3.06209 Valid. err. 2.78502
2018-02-03 22:04:45,505 training [INFO ] Epoch  2 Batch  400 Training err. 2.77249 Training err. RA 3.04761 Valid. err. 2.77907
2018-02-03 22:04:46,379 training [INFO ] Epoch  3 Batch  420 Training err. 2.74017 Training err. RA 3.03297 Valid. err. 2.72899
2018-02-03 22:04:46,863 training [INFO ] Epoch  3 Batch  440 Training err. 2.72277 Training err. RA 3.01887 Valid. err. 2.71090
2018-02-03 22:04:47,349 training [INFO ] Epoch  3 Batch  460 Training err. 2.67992 Training err. RA 3.00413 Valid. err. 2.69395
2018-02-03 22:04:47,833 training [INFO ] Epoch  3 Batch  480 Training err. 2.63504 Training err. RA 2.98875 Valid. err. 2.67709
2018-02-03 22:04:48,317 training [INFO ] Epoch  3 Batch  500 Training err. 2.60208 Training err. RA 2.97329 Valid. err. 2.67569
2018-02-03 22:04:48,798 training [INFO ] Epoch  3 Batch  520 Training err. 2.60814 Training err. RA 2.95924 Valid. err. 2.65442
2018-02-03 22:04:49,279 training [INFO ] Epoch  3 Batch  540 Training err. 2.61952 Training err. RA 2.94666 Valid. err. 2.58740
2018-02-03 22:04:49,758 training [INFO ] Epoch  3 Batch  560 Training err. 2.53108 Training err. RA 2.93182 Valid. err. 2.55610
2018-02-03 22:04:50,238 training [INFO ] Epoch  3 Batch  580 Training err. 2.48878 Training err. RA 2.91654 Valid. err. 2.53297
2018-02-03 22:04:50,713 training [INFO ] Epoch  3 Batch  600 Training err. 2.51054 Training err. RA 2.90301 Valid. err. 2.53911
2018-02-03 22:04:51,195 training [INFO ] Epoch  3 Batch  620 Training err. 2.50706 Training err. RA 2.89024 Valid. err. 2.49053
2018-02-03 22:04:52,047 training [INFO ] Epoch  4 Batch  640 Training err. 2.44787 Training err. RA 2.87641 Valid. err. 2.48601
2018-02-03 22:04:52,522 training [INFO ] Epoch  4 Batch  660 Training err. 2.37382 Training err. RA 2.86118 Valid. err. 2.44763
2018-02-03 22:04:53,002 training [INFO ] Epoch  4 Batch  680 Training err. 2.45510 Training err. RA 2.84924 Valid. err. 2.45532
2018-02-03 22:04:53,487 training [INFO ] Epoch  4 Batch  700 Training err. 2.40701 Training err. RA 2.83660 Valid. err. 2.46240
2018-02-03 22:04:53,967 training [INFO ] Epoch  4 Batch  720 Training err. 2.37303 Training err. RA 2.82373 Valid. err. 2.42048
2018-02-03 22:04:54,451 training [INFO ] Epoch  4 Batch  740 Training err. 2.44140 Training err. RA 2.81339 Valid. err. 2.40839
2018-02-03 22:04:54,935 training [INFO ] Epoch  4 Batch  760 Training err. 2.37832 Training err. RA 2.80194 Valid. err. 2.40775
2018-02-03 22:04:55,419 training [INFO ] Epoch  4 Batch  780 Training err. 2.33897 Training err. RA 2.79007 Valid. err. 2.37455
2018-02-03 22:04:55,903 training [INFO ] Epoch  4 Batch  800 Training err. 2.33709 Training err. RA 2.77875 Valid. err. 2.34505
2018-02-03 22:04:56,391 training [INFO ] Epoch  4 Batch  820 Training err. 2.30225 Training err. RA 2.76713 Valid. err. 2.34373
2018-02-03 22:04:57,259 training [INFO ] Epoch  5 Batch  840 Training err. 2.32795 Training err. RA 2.75667 Valid. err. 2.32770
2018-02-03 22:04:57,738 training [INFO ] Epoch  5 Batch  860 Training err. 2.22976 Training err. RA 2.74442 Valid. err. 2.31354
2018-02-03 22:04:58,212 training [INFO ] Epoch  5 Batch  880 Training err. 2.29072 Training err. RA 2.73410 Valid. err. 2.31149
2018-02-03 22:04:58,688 training [INFO ] Epoch  5 Batch  900 Training err. 2.27549 Training err. RA 2.72391 Valid. err. 2.31830
2018-02-03 22:04:59,168 training [INFO ] Epoch  5 Batch  920 Training err. 2.26257 Training err. RA 2.71388 Valid. err. 2.30718
2018-02-03 22:04:59,650 training [INFO ] Epoch  5 Batch  940 Training err. 2.25251 Training err. RA 2.70407 Valid. err. 2.31915
2018-02-03 22:05:00,136 training [INFO ] Epoch  5 Batch  960 Training err. 2.29947 Training err. RA 2.69564 Valid. err. 2.26676
2018-02-03 22:05:00,618 training [INFO ] Epoch  5 Batch  980 Training err. 2.23004 Training err. RA 2.68614 Valid. err. 2.31028
2018-02-03 22:05:01,103 training [INFO ] Epoch  5 Batch 1000 Training err. 2.19421 Training err. RA 2.67630 Valid. err. 2.23231
2018-02-03 22:05:01,582 training [INFO ] Epoch  5 Batch 1020 Training err. 2.20697 Training err. RA 2.66709 Valid. err. 2.24094
2018-02-03 22:05:02,063 training [INFO ] Epoch  5 Batch 1040 Training err. 2.19366 Training err. RA 2.65799 Valid. err. 2.23863
2018-02-03 22:05:02,910 training [INFO ] Epoch  6 Batch 1060 Training err. 2.17470 Training err. RA 2.64887 Valid. err. 2.22370
2018-02-03 22:05:03,390 training [INFO ] Epoch  6 Batch 1080 Training err. 2.11356 Training err. RA 2.63896 Valid. err. 2.22965
2018-02-03 22:05:03,870 training [INFO ] Epoch  6 Batch 1100 Training err. 2.18718 Training err. RA 2.63074 Valid. err. 2.19845
2018-02-03 22:05:04,351 training [INFO ] Epoch  6 Batch 1120 Training err. 2.17242 Training err. RA 2.62256 Valid. err. 2.22293
2018-02-03 22:05:04,829 training [INFO ] Epoch  6 Batch 1140 Training err. 2.14566 Training err. RA 2.61419 Valid. err. 2.17509
2018-02-03 22:05:05,311 training [INFO ] Epoch  6 Batch 1160 Training err. 2.20705 Training err. RA 2.60717 Valid. err. 2.18115
2018-02-03 22:05:05,790 training [INFO ] Epoch  6 Batch 1180 Training err. 2.13246 Training err. RA 2.59913 Valid. err. 2.20340
2018-02-03 22:05:06,277 training [INFO ] Epoch  6 Batch 1200 Training err. 2.11874 Training err. RA 2.59112 Valid. err. 2.21851
2018-02-03 22:05:06,756 training [INFO ] Epoch  6 Batch 1220 Training err. 2.11482 Training err. RA 2.58331 Valid. err. 2.15356
2018-02-03 22:05:07,238 training [INFO ] Epoch  6 Batch 1240 Training err. 2.10106 Training err. RA 2.57553 Valid. err. 2.26386
2018-02-03 22:05:08,104 training [INFO ] Epoch  7 Batch 1260 Training err. 2.11080 Training err. RA 2.56816 Valid. err. 2.13479
2018-02-03 22:05:08,582 training [INFO ] Epoch  7 Batch 1280 Training err. 2.00722 Training err. RA 2.55939 Valid. err. 2.12028
2018-02-03 22:05:09,066 training [INFO ] Epoch  7 Batch 1300 Training err. 2.10485 Training err. RA 2.55240 Valid. err. 2.12321
2018-02-03 22:05:09,548 training [INFO ] Epoch  7 Batch 1320 Training err. 2.10495 Training err. RA 2.54562 Valid. err. 2.14948
2018-02-03 22:05:10,028 training [INFO ] Epoch  7 Batch 1340 Training err. 2.05851 Training err. RA 2.53835 Valid. err. 2.10716
2018-02-03 22:05:10,510 training [INFO ] Epoch  7 Batch 1360 Training err. 2.08953 Training err. RA 2.53175 Valid. err. 2.11277
2018-02-03 22:05:10,989 training [INFO ] Epoch  7 Batch 1380 Training err. 2.11749 Training err. RA 2.52575 Valid. err. 2.12220
2018-02-03 22:05:11,471 training [INFO ] Epoch  7 Batch 1400 Training err. 2.03153 Training err. RA 2.51869 Valid. err. 2.11083
2018-02-03 22:05:11,951 training [INFO ] Epoch  7 Batch 1420 Training err. 2.05449 Training err. RA 2.51215 Valid. err. 2.09933
2018-02-03 22:05:12,428 training [INFO ] Epoch  7 Batch 1440 Training err. 2.02991 Training err. RA 2.50545 Valid. err. 2.07156
2018-02-03 22:05:13,277 training [INFO ] Epoch  8 Batch 1460 Training err. 2.02029 Training err. RA 2.49880 Valid. err. 2.07049
2018-02-03 22:05:13,754 training [INFO ] Epoch  8 Batch 1480 Training err. 1.99886 Training err. RA 2.49205 Valid. err. 2.05903
2018-02-03 22:05:14,231 training [INFO ] Epoch  8 Batch 1500 Training err. 1.98407 Training err. RA 2.48528 Valid. err. 2.04476
2018-02-03 22:05:14,706 training [INFO ] Epoch  8 Batch 1520 Training err. 2.03320 Training err. RA 2.47933 Valid. err. 2.04182
2018-02-03 22:05:15,186 training [INFO ] Epoch  8 Batch 1540 Training err. 2.00624 Training err. RA 2.47318 Valid. err. 2.10114
2018-02-03 22:05:15,666 training [INFO ] Epoch  8 Batch 1560 Training err. 2.01085 Training err. RA 2.46726 Valid. err. 2.04649
2018-02-03 22:05:16,155 training [INFO ] Epoch  8 Batch 1580 Training err. 2.07490 Training err. RA 2.46229 Valid. err. 2.03965
2018-02-03 22:05:16,633 training [INFO ] Epoch  8 Batch 1600 Training err. 1.96720 Training err. RA 2.45610 Valid. err. 2.05105
2018-02-03 22:05:17,113 training [INFO ] Epoch  8 Batch 1620 Training err. 1.97280 Training err. RA 2.45013 Valid. err. 2.03891
2018-02-03 22:05:17,594 training [INFO ] Epoch  8 Batch 1640 Training err. 1.96678 Training err. RA 2.44424 Valid. err. 2.02000
2018-02-03 22:05:18,076 training [INFO ] Epoch  8 Batch 1660 Training err. 1.97397 Training err. RA 2.43857 Valid. err. 2.02572
2018-02-03 22:05:18,929 training [INFO ] Epoch  9 Batch 1680 Training err. 1.95710 Training err. RA 2.43284 Valid. err. 2.01867
2018-02-03 22:05:19,408 training [INFO ] Epoch  9 Batch 1700 Training err. 1.89057 Training err. RA 2.42646 Valid. err. 2.03490
2018-02-03 22:05:19,886 training [INFO ] Epoch  9 Batch 1720 Training err. 1.97882 Training err. RA 2.42126 Valid. err. 2.00404
2018-02-03 22:05:20,370 training [INFO ] Epoch  9 Batch 1740 Training err. 1.96639 Training err. RA 2.41603 Valid. err. 2.01594
2018-02-03 22:05:20,850 training [INFO ] Epoch  9 Batch 1760 Training err. 1.93664 Training err. RA 2.41058 Valid. err. 2.02201
2018-02-03 22:05:21,334 training [INFO ] Epoch  9 Batch 1780 Training err. 1.99800 Training err. RA 2.40594 Valid. err. 2.02050
2018-02-03 22:05:21,811 training [INFO ] Epoch  9 Batch 1800 Training err. 1.96175 Training err. RA 2.40101 Valid. err. 1.98837
2018-02-03 22:05:22,292 training [INFO ] Epoch  9 Batch 1820 Training err. 1.90444 Training err. RA 2.39555 Valid. err. 2.00585
2018-02-03 22:05:22,772 training [INFO ] Epoch  9 Batch 1840 Training err. 1.93115 Training err. RA 2.39050 Valid. err. 1.97352
2018-02-03 22:05:23,244 training [INFO ] Epoch  9 Batch 1860 Training err. 1.92446 Training err. RA 2.38549 Valid. err. 1.97032
2018-02-03 22:05:24,104 training [INFO ] Epoch 10 Batch 1880 Training err. 1.91178 Training err. RA 2.38045 Valid. err. 1.95244
2018-02-03 22:05:24,584 training [INFO ] Epoch 10 Batch 1900 Training err. 1.85124 Training err. RA 2.37488 Valid. err. 1.96045
2018-02-03 22:05:25,072 training [INFO ] Epoch 10 Batch 1920 Training err. 1.91438 Training err. RA 2.37009 Valid. err. 1.97183
2018-02-03 22:05:25,556 training [INFO ] Epoch 10 Batch 1940 Training err. 1.92577 Training err. RA 2.36551 Valid. err. 1.95239
2018-02-03 22:05:26,041 training [INFO ] Epoch 10 Batch 1960 Training err. 1.88554 Training err. RA 2.36061 Valid. err. 1.96337
2018-02-03 22:05:26,524 training [INFO ] Epoch 10 Batch 1980 Training err. 1.88529 Training err. RA 2.35581 Valid. err. 1.98574
2018-02-03 22:05:27,002 training [INFO ] Epoch 10 Batch 2000 Training err. 1.95879 Training err. RA 2.35184 Valid. err. 1.93708
2018-02-03 22:05:27,482 training [INFO ] Epoch 10 Batch 2020 Training err. 1.87856 Training err. RA 2.34715 Valid. err. 1.94316
2018-02-03 22:05:27,961 training [INFO ] Epoch 10 Batch 2040 Training err. 1.85675 Training err. RA 2.34234 Valid. err. 1.92521
2018-02-03 22:05:28,441 training [INFO ] Epoch 10 Batch 2060 Training err. 1.87658 Training err. RA 2.33782 Valid. err. 1.92970
2018-02-03 22:05:28,921 training [INFO ] Epoch 10 Batch 2080 Training err. 1.84739 Training err. RA 2.33311 Valid. err. 1.92198
2018-02-03 22:05:29,769 training [INFO ] Epoch 11 Batch 2100 Training err. 1.86609 Training err. RA 2.32866 Valid. err. 1.90433
2018-02-03 22:05:30,244 training [INFO ] Epoch 11 Batch 2120 Training err. 1.79853 Training err. RA 2.32366 Valid. err. 1.93282
2018-02-03 22:05:30,721 training [INFO ] Epoch 11 Batch 2140 Training err. 1.87644 Training err. RA 2.31948 Valid. err. 1.92448
2018-02-03 22:05:31,208 training [INFO ] Epoch 11 Batch 2160 Training err. 1.88121 Training err. RA 2.31542 Valid. err. 1.92150
2018-02-03 22:05:31,686 training [INFO ] Epoch 11 Batch 2180 Training err. 1.83328 Training err. RA 2.31100 Valid. err. 1.90490
2018-02-03 22:05:32,168 training [INFO ] Epoch 11 Batch 2200 Training err. 1.90741 Training err. RA 2.30733 Valid. err. 1.89620
2018-02-03 22:05:32,648 training [INFO ] Epoch 11 Batch 2220 Training err. 1.84748 Training err. RA 2.30318 Valid. err. 1.90554
2018-02-03 22:05:33,129 training [INFO ] Epoch 11 Batch 2240 Training err. 1.81859 Training err. RA 2.29886 Valid. err. 1.95240
2018-02-03 22:05:33,613 training [INFO ] Epoch 11 Batch 2260 Training err. 1.82641 Training err. RA 2.29468 Valid. err. 1.88794
2018-02-03 22:05:34,098 training [INFO ] Epoch 11 Batch 2280 Training err. 1.82204 Training err. RA 2.29053 Valid. err. 1.91221
2018-02-03 22:05:34,963 training [INFO ] Epoch 12 Batch 2300 Training err. 1.82188 Training err. RA 2.28645 Valid. err. 1.88305
2018-02-03 22:05:35,448 training [INFO ] Epoch 12 Batch 2320 Training err. 1.74778 Training err. RA 2.28181 Valid. err. 1.89050
2018-02-03 22:05:35,932 training [INFO ] Epoch 12 Batch 2340 Training err. 1.83582 Training err. RA 2.27800 Valid. err. 1.88296
2018-02-03 22:05:36,422 training [INFO ] Epoch 12 Batch 2360 Training err. 1.84547 Training err. RA 2.27433 Valid. err. 1.89894
2018-02-03 22:05:36,908 training [INFO ] Epoch 12 Batch 2380 Training err. 1.79382 Training err. RA 2.27030 Valid. err. 1.88341
2018-02-03 22:05:37,389 training [INFO ] Epoch 12 Batch 2400 Training err. 1.82426 Training err. RA 2.26658 Valid. err. 1.88329
2018-02-03 22:05:37,869 training [INFO ] Epoch 12 Batch 2420 Training err. 1.86109 Training err. RA 2.26323 Valid. err. 1.88432
2018-02-03 22:05:38,349 training [INFO ] Epoch 12 Batch 2440 Training err. 1.78232 Training err. RA 2.25929 Valid. err. 1.86885
2018-02-03 22:05:38,875 training [INFO ] Epoch 12 Batch 2460 Training err. 1.79221 Training err. RA 2.25549 Valid. err. 1.88475
2018-02-03 22:05:39,353 training [INFO ] Epoch 12 Batch 2480 Training err. 1.78703 Training err. RA 2.25171 Valid. err. 1.84571
2018-02-03 22:05:40,238 training [INFO ] Epoch 13 Batch 2500 Training err. 1.76057 Training err. RA 2.24778 Valid. err. 1.85337
2018-02-03 22:05:40,713 training [INFO ] Epoch 13 Batch 2520 Training err. 1.74974 Training err. RA 2.24383 Valid. err. 1.85582
2018-02-03 22:05:41,201 training [INFO ] Epoch 13 Batch 2540 Training err. 1.75821 Training err. RA 2.24001 Valid. err. 1.85236
2018-02-03 22:05:41,680 training [INFO ] Epoch 13 Batch 2560 Training err. 1.80175 Training err. RA 2.23658 Valid. err. 1.84891
2018-02-03 22:05:42,166 training [INFO ] Epoch 13 Batch 2580 Training err. 1.78328 Training err. RA 2.23307 Valid. err. 1.87332
2018-02-03 22:05:42,654 training [INFO ] Epoch 13 Batch 2600 Training err. 1.77343 Training err. RA 2.22953 Valid. err. 1.85507
2018-02-03 22:05:43,137 training [INFO ] Epoch 13 Batch 2620 Training err. 1.84034 Training err. RA 2.22656 Valid. err. 1.86102
2018-02-03 22:05:43,701 training [INFO ] Epoch 13 Batch 2640 Training err. 1.74489 Training err. RA 2.22291 Valid. err. 1.85531
2018-02-03 22:05:44,213 training [INFO ] Epoch 13 Batch 2660 Training err. 1.74962 Training err. RA 2.21935 Valid. err. 1.86846
2018-02-03 22:05:44,694 training [INFO ] Epoch 13 Batch 2680 Training err. 1.74834 Training err. RA 2.21584 Valid. err. 1.82034
2018-02-03 22:05:45,188 training [INFO ] Epoch 13 Batch 2700 Training err. 1.75114 Training err. RA 2.21240 Valid. err. 1.84217
2018-02-03 22:05:46,074 training [INFO ] Epoch 14 Batch 2720 Training err. 1.72339 Training err. RA 2.20880 Valid. err. 1.82343
2018-02-03 22:05:46,558 training [INFO ] Epoch 14 Batch 2740 Training err. 1.69146 Training err. RA 2.20502 Valid. err. 1.83718
2018-02-03 22:05:47,123 training [INFO ] Epoch 14 Batch 2760 Training err. 1.76411 Training err. RA 2.20183 Valid. err. 1.83258
2018-02-03 22:05:47,609 training [INFO ] Epoch 14 Batch 2780 Training err. 1.77025 Training err. RA 2.19872 Valid. err. 1.84290
2018-02-03 22:05:48,088 training [INFO ] Epoch 14 Batch 2800 Training err. 1.72849 Training err. RA 2.19537 Valid. err. 1.82793
2018-02-03 22:05:48,564 training [INFO ] Epoch 14 Batch 2820 Training err. 1.78967 Training err. RA 2.19249 Valid. err. 1.81299
2018-02-03 22:05:49,043 training [INFO ] Epoch 14 Batch 2840 Training err. 1.75804 Training err. RA 2.18943 Valid. err. 1.81556
2018-02-03 22:05:49,523 training [INFO ] Epoch 14 Batch 2860 Training err. 1.71028 Training err. RA 2.18608 Valid. err. 1.82039
2018-02-03 22:05:50,004 training [INFO ] Epoch 14 Batch 2880 Training err. 1.72463 Training err. RA 2.18287 Valid. err. 1.80041
2018-02-03 22:05:50,483 training [INFO ] Epoch 14 Batch 2900 Training err. 1.71969 Training err. RA 2.17968 Valid. err. 1.81009
2018-02-03 22:05:51,331 training [INFO ] Epoch 15 Batch 2920 Training err. 1.70150 Training err. RA 2.17640 Valid. err. 1.80414
2018-02-03 22:05:51,808 training [INFO ] Epoch 15 Batch 2940 Training err. 1.66176 Training err. RA 2.17290 Valid. err. 1.81753
2018-02-03 22:05:52,287 training [INFO ] Epoch 15 Batch 2960 Training err. 1.72923 Training err. RA 2.16990 Valid. err. 1.80053
2018-02-03 22:05:52,770 training [INFO ] Epoch 15 Batch 2980 Training err. 1.74719 Training err. RA 2.16707 Valid. err. 1.79729
2018-02-03 22:05:53,253 training [INFO ] Epoch 15 Batch 3000 Training err. 1.69925 Training err. RA 2.16395 Valid. err. 1.81263
2018-02-03 22:05:53,736 training [INFO ] Epoch 15 Batch 3020 Training err. 1.70054 Training err. RA 2.16088 Valid. err. 1.81752
2018-02-03 22:05:54,222 training [INFO ] Epoch 15 Batch 3040 Training err. 1.76673 Training err. RA 2.15829 Valid. err. 1.78512
2018-02-03 22:05:54,705 training [INFO ] Epoch 15 Batch 3060 Training err. 1.70085 Training err. RA 2.15530 Valid. err. 1.79119
2018-02-03 22:05:55,187 training [INFO ] Epoch 15 Batch 3080 Training err. 1.67948 Training err. RA 2.15221 Valid. err. 1.77829
2018-02-03 22:05:55,673 training [INFO ] Epoch 15 Batch 3100 Training err. 1.69283 Training err. RA 2.14924 Valid. err. 1.77562
2018-02-03 22:05:56,156 training [INFO ] Epoch 15 Batch 3120 Training err. 1.67418 Training err. RA 2.14620 Valid. err. 1.77842
2018-02-03 22:05:56,997 training [INFO ] Epoch 16 Batch 3140 Training err. 1.66829 Training err. RA 2.14315 Valid. err. 1.75284
2018-02-03 22:05:57,472 training [INFO ] Epoch 16 Batch 3160 Training err. 1.63535 Training err. RA 2.13994 Valid. err. 1.77064
2018-02-03 22:05:57,953 training [INFO ] Epoch 16 Batch 3180 Training err. 1.70333 Training err. RA 2.13719 Valid. err. 1.79615
2018-02-03 22:05:58,433 training [INFO ] Epoch 16 Batch 3200 Training err. 1.72098 Training err. RA 2.13459 Valid. err. 1.77793
2018-02-03 22:05:58,912 training [INFO ] Epoch 16 Batch 3220 Training err. 1.66245 Training err. RA 2.13166 Valid. err. 1.77771
2018-02-03 22:05:59,391 training [INFO ] Epoch 16 Batch 3240 Training err. 1.73247 Training err. RA 2.12920 Valid. err. 1.76418
2018-02-03 22:05:59,872 training [INFO ] Epoch 16 Batch 3260 Training err. 1.68628 Training err. RA 2.12648 Valid. err. 1.76044
2018-02-03 22:06:00,359 training [INFO ] Epoch 16 Batch 3280 Training err. 1.66056 Training err. RA 2.12364 Valid. err. 1.78714
2018-02-03 22:06:00,842 training [INFO ] Epoch 16 Batch 3300 Training err. 1.65874 Training err. RA 2.12082 Valid. err. 1.75051
2018-02-03 22:06:01,327 training [INFO ] Epoch 16 Batch 3320 Training err. 1.66799 Training err. RA 2.11809 Valid. err. 1.74475
2018-02-03 22:06:02,184 training [INFO ] Epoch 17 Batch 3340 Training err. 1.64473 Training err. RA 2.11526 Valid. err. 1.74432
2018-02-03 22:06:02,668 training [INFO ] Epoch 17 Batch 3360 Training err. 1.59611 Training err. RA 2.11217 Valid. err. 1.75687
2018-02-03 22:06:03,151 training [INFO ] Epoch 17 Batch 3380 Training err. 1.68153 Training err. RA 2.10962 Valid. err. 1.75858
2018-02-03 22:06:03,631 training [INFO ] Epoch 17 Batch 3400 Training err. 1.68998 Training err. RA 2.10715 Valid. err. 1.77118
2018-02-03 22:06:04,111 training [INFO ] Epoch 17 Batch 3420 Training err. 1.64187 Training err. RA 2.10443 Valid. err. 1.74969
2018-02-03 22:06:04,584 training [INFO ] Epoch 17 Batch 3440 Training err. 1.66793 Training err. RA 2.10189 Valid. err. 1.75911
2018-02-03 22:06:05,057 training [INFO ] Epoch 17 Batch 3460 Training err. 1.70369 Training err. RA 2.09959 Valid. err. 1.74721
2018-02-03 22:06:05,535 training [INFO ] Epoch 17 Batch 3480 Training err. 1.63645 Training err. RA 2.09693 Valid. err. 1.74648
2018-02-03 22:06:06,019 training [INFO ] Epoch 17 Batch 3500 Training err. 1.64312 Training err. RA 2.09434 Valid. err. 1.74564
2018-02-03 22:06:06,496 training [INFO ] Epoch 17 Batch 3520 Training err. 1.63775 Training err. RA 2.09174 Valid. err. 1.71321
2018-02-03 22:06:07,344 training [INFO ] Epoch 18 Batch 3540 Training err. 1.61296 Training err. RA 2.08904 Valid. err. 1.74337
2018-02-03 22:06:07,822 training [INFO ] Epoch 18 Batch 3560 Training err. 1.60110 Training err. RA 2.08630 Valid. err. 1.73554
2018-02-03 22:06:08,303 training [INFO ] Epoch 18 Batch 3580 Training err. 1.62070 Training err. RA 2.08369 Valid. err. 1.72574
2018-02-03 22:06:08,786 training [INFO ] Epoch 18 Batch 3600 Training err. 1.65737 Training err. RA 2.08133 Valid. err. 1.73506
2018-02-03 22:06:09,272 training [INFO ] Epoch 18 Batch 3620 Training err. 1.64640 Training err. RA 2.07892 Valid. err. 1.74197
2018-02-03 22:06:09,757 training [INFO ] Epoch 18 Batch 3640 Training err. 1.62440 Training err. RA 2.07643 Valid. err. 1.73043
2018-02-03 22:06:10,240 training [INFO ] Epoch 18 Batch 3660 Training err. 1.69682 Training err. RA 2.07435 Valid. err. 1.74845
2018-02-03 22:06:10,719 training [INFO ] Epoch 18 Batch 3680 Training err. 1.60292 Training err. RA 2.07179 Valid. err. 1.74145
2018-02-03 22:06:11,205 training [INFO ] Epoch 18 Batch 3700 Training err. 1.61249 Training err. RA 2.06931 Valid. err. 1.76260
2018-02-03 22:06:11,687 training [INFO ] Epoch 18 Batch 3720 Training err. 1.60437 Training err. RA 2.06681 Valid. err. 1.71028
2018-02-03 22:06:12,172 training [INFO ] Epoch 18 Batch 3740 Training err. 1.62367 Training err. RA 2.06444 Valid. err. 1.72335
2018-02-03 22:06:13,017 training [INFO ] Epoch 19 Batch 3760 Training err. 1.58160 Training err. RA 2.06187 Valid. err. 1.71323
2018-02-03 22:06:13,492 training [INFO ] Epoch 19 Batch 3780 Training err. 1.56258 Training err. RA 2.05923 Valid. err. 1.71534
2018-02-03 22:06:13,973 training [INFO ] Epoch 19 Batch 3800 Training err. 1.62929 Training err. RA 2.05696 Valid. err. 1.72111
2018-02-03 22:06:14,454 training [INFO ] Epoch 19 Batch 3820 Training err. 1.64021 Training err. RA 2.05478 Valid. err. 1.73844
2018-02-03 22:06:14,933 training [INFO ] Epoch 19 Batch 3840 Training err. 1.59390 Training err. RA 2.05238 Valid. err. 1.72431
2018-02-03 22:06:15,412 training [INFO ] Epoch 19 Batch 3860 Training err. 1.65707 Training err. RA 2.05033 Valid. err. 1.71414
2018-02-03 22:06:15,896 training [INFO ] Epoch 19 Batch 3880 Training err. 1.62576 Training err. RA 2.04815 Valid. err. 1.70883
2018-02-03 22:06:16,376 training [INFO ] Epoch 19 Batch 3900 Training err. 1.58119 Training err. RA 2.04575 Valid. err. 1.70845
2018-02-03 22:06:16,856 training [INFO ] Epoch 19 Batch 3920 Training err. 1.59734 Training err. RA 2.04346 Valid. err. 1.69333
2018-02-03 22:06:17,332 training [INFO ] Epoch 19 Batch 3940 Training err. 1.59792 Training err. RA 2.04120 Valid. err. 1.70296
2018-02-03 22:06:18,183 training [INFO ] Epoch 20 Batch 3960 Training err. 1.57101 Training err. RA 2.03883 Valid. err. 1.70377
2018-02-03 22:06:18,660 training [INFO ] Epoch 20 Batch 3980 Training err. 1.54138 Training err. RA 2.03633 Valid. err. 1.70788
2018-02-03 22:06:19,141 training [INFO ] Epoch 20 Batch 4000 Training err. 1.60344 Training err. RA 2.03416 Valid. err. 1.69953
2018-02-03 22:06:19,621 training [INFO ] Epoch 20 Batch 4020 Training err. 1.62631 Training err. RA 2.03213 Valid. err. 1.69511
2018-02-03 22:06:20,100 training [INFO ] Epoch 20 Batch 4040 Training err. 1.57424 Training err. RA 2.02987 Valid. err. 1.71065
2018-02-03 22:06:20,582 training [INFO ] Epoch 20 Batch 4060 Training err. 1.57654 Training err. RA 2.02763 Valid. err. 1.71450
2018-02-03 22:06:21,066 training [INFO ] Epoch 20 Batch 4080 Training err. 1.64340 Training err. RA 2.02575 Valid. err. 1.69913
2018-02-03 22:06:21,546 training [INFO ] Epoch 20 Batch 4100 Training err. 1.57613 Training err. RA 2.02356 Valid. err. 1.69376
2018-02-03 22:06:22,023 training [INFO ] Epoch 20 Batch 4120 Training err. 1.55607 Training err. RA 2.02129 Valid. err. 1.69137
2018-02-03 22:06:22,501 training [INFO ] Epoch 20 Batch 4140 Training err. 1.57001 Training err. RA 2.01911 Valid. err. 1.67479
2018-02-03 22:06:22,981 training [INFO ] Epoch 20 Batch 4160 Training err. 1.55567 Training err. RA 2.01688 Valid. err. 1.68675
2018-02-03 22:06:23,827 training [INFO ] Epoch 21 Batch 4180 Training err. 1.55280 Training err. RA 2.01466 Valid. err. 1.66258
2018-02-03 22:06:24,303 training [INFO ] Epoch 21 Batch 4200 Training err. 1.52008 Training err. RA 2.01230 Valid. err. 1.69385
2018-02-03 22:06:24,786 training [INFO ] Epoch 21 Batch 4220 Training err. 1.58722 Training err. RA 2.01029 Valid. err. 1.71944
2018-02-03 22:06:25,270 training [INFO ] Epoch 21 Batch 4240 Training err. 1.60688 Training err. RA 2.00839 Valid. err. 1.69263
2018-02-03 22:06:25,753 training [INFO ] Epoch 21 Batch 4260 Training err. 1.54157 Training err. RA 2.00619 Valid. err. 1.68779
2018-02-03 22:06:26,241 training [INFO ] Epoch 21 Batch 4280 Training err. 1.61841 Training err. RA 2.00438 Valid. err. 1.69142
2018-02-03 22:06:26,725 training [INFO ] Epoch 21 Batch 4300 Training err. 1.57193 Training err. RA 2.00237 Valid. err. 1.68315
2018-02-03 22:06:27,214 training [INFO ] Epoch 21 Batch 4320 Training err. 1.54153 Training err. RA 2.00024 Valid. err. 1.69106
2018-02-03 22:06:27,697 training [INFO ] Epoch 21 Batch 4340 Training err. 1.54200 Training err. RA 1.99813 Valid. err. 1.65990
2018-02-03 22:06:28,173 training [INFO ] Epoch 21 Batch 4360 Training err. 1.56036 Training err. RA 1.99612 Valid. err. 1.65312
2018-02-03 22:06:29,019 training [INFO ] Epoch 22 Batch 4380 Training err. 1.53081 Training err. RA 1.99399 Valid. err. 1.66015
2018-02-03 22:06:29,499 training [INFO ] Epoch 22 Batch 4400 Training err. 1.49288 Training err. RA 1.99172 Valid. err. 1.68252
2018-02-03 22:06:29,977 training [INFO ] Epoch 22 Batch 4420 Training err. 1.56909 Training err. RA 1.98980 Valid. err. 1.67910
2018-02-03 22:06:30,454 training [INFO ] Epoch 22 Batch 4440 Training err. 1.58145 Training err. RA 1.98796 Valid. err. 1.69466
2018-02-03 22:06:30,934 training [INFO ] Epoch 22 Batch 4460 Training err. 1.53312 Training err. RA 1.98592 Valid. err. 1.67697
2018-02-03 22:06:31,409 training [INFO ] Epoch 22 Batch 4480 Training err. 1.55705 Training err. RA 1.98401 Valid. err. 1.67126
2018-02-03 22:06:31,888 training [INFO ] Epoch 22 Batch 4500 Training err. 1.59555 Training err. RA 1.98228 Valid. err. 1.66361
2018-02-03 22:06:32,367 training [INFO ] Epoch 22 Batch 4520 Training err. 1.52474 Training err. RA 1.98026 Valid. err. 1.66873
2018-02-03 22:06:32,847 training [INFO ] Epoch 22 Batch 4540 Training err. 1.53050 Training err. RA 1.97828 Valid. err. 1.67455
2018-02-03 22:06:33,324 training [INFO ] Epoch 22 Batch 4560 Training err. 1.52984 Training err. RA 1.97631 Valid. err. 1.64224
2018-02-03 22:06:34,175 training [INFO ] Epoch 23 Batch 4580 Training err. 1.51175 Training err. RA 1.97428 Valid. err. 1.67305
2018-02-03 22:06:34,653 training [INFO ] Epoch 23 Batch 4600 Training err. 1.49796 Training err. RA 1.97221 Valid. err. 1.66449
2018-02-03 22:06:35,134 training [INFO ] Epoch 23 Batch 4620 Training err. 1.51456 Training err. RA 1.97023 Valid. err. 1.65811
2018-02-03 22:06:35,611 training [INFO ] Epoch 23 Batch 4640 Training err. 1.55491 Training err. RA 1.96844 Valid. err. 1.66057
2018-02-03 22:06:36,095 training [INFO ] Epoch 23 Batch 4660 Training err. 1.54672 Training err. RA 1.96663 Valid. err. 1.68549
2018-02-03 22:06:36,574 training [INFO ] Epoch 23 Batch 4680 Training err. 1.51912 Training err. RA 1.96472 Valid. err. 1.66456
2018-02-03 22:06:37,052 training [INFO ] Epoch 23 Batch 4700 Training err. 1.59489 Training err. RA 1.96314 Valid. err. 1.68018
2018-02-03 22:06:37,532 training [INFO ] Epoch 23 Batch 4720 Training err. 1.50016 Training err. RA 1.96118 Valid. err. 1.67179
2018-02-03 22:06:38,012 training [INFO ] Epoch 23 Batch 4740 Training err. 1.50590 Training err. RA 1.95926 Valid. err. 1.67202
2018-02-03 22:06:38,492 training [INFO ] Epoch 23 Batch 4760 Training err. 1.49836 Training err. RA 1.95732 Valid. err. 1.65907
2018-02-03 22:06:38,978 training [INFO ] Epoch 23 Batch 4780 Training err. 1.52745 Training err. RA 1.95552 Valid. err. 1.64335
2018-02-03 22:06:39,825 training [INFO ] Epoch 24 Batch 4800 Training err. 1.47996 Training err. RA 1.95354 Valid. err. 1.66620
2018-02-03 22:06:40,303 training [INFO ] Epoch 24 Batch 4820 Training err. 1.46767 Training err. RA 1.95153 Valid. err. 1.64984
2018-02-03 22:06:40,788 training [INFO ] Epoch 24 Batch 4840 Training err. 1.52771 Training err. RA 1.94978 Valid. err. 1.66228
2018-02-03 22:06:41,275 training [INFO ] Epoch 24 Batch 4860 Training err. 1.54518 Training err. RA 1.94811 Valid. err. 1.67847
2018-02-03 22:06:41,760 training [INFO ] Epoch 24 Batch 4880 Training err. 1.49575 Training err. RA 1.94626 Valid. err. 1.68018
2018-02-03 22:06:42,244 training [INFO ] Epoch 24 Batch 4900 Training err. 1.55860 Training err. RA 1.94467 Valid. err. 1.65505
2018-02-03 22:06:42,733 training [INFO ] Epoch 24 Batch 4920 Training err. 1.52952 Training err. RA 1.94299 Valid. err. 1.65837
2018-02-03 22:06:43,218 training [INFO ] Epoch 24 Batch 4940 Training err. 1.48086 Training err. RA 1.94112 Valid. err. 1.65514
2018-02-03 22:06:43,700 training [INFO ] Epoch 24 Batch 4960 Training err. 1.48917 Training err. RA 1.93929 Valid. err. 1.64334
2018-02-03 22:06:44,178 training [INFO ] Epoch 24 Batch 4980 Training err. 1.50192 Training err. RA 1.93754 Valid. err. 1.65019
2018-02-03 22:06:45,008 training [INFO ] Epoch 25 Batch 5000 Training err. 1.47514 Training err. RA 1.93569 Valid. err. 1.64065
2018-02-03 22:06:45,484 training [INFO ] Epoch 25 Batch 5020 Training err. 1.44807 Training err. RA 1.93374 Valid. err. 1.65968
2018-02-03 22:06:45,961 training [INFO ] Epoch 25 Batch 5040 Training err. 1.50516 Training err. RA 1.93204 Valid. err. 1.64536
2018-02-03 22:06:46,436 training [INFO ] Epoch 25 Batch 5060 Training err. 1.53576 Training err. RA 1.93048 Valid. err. 1.64918
2018-02-03 22:06:46,916 training [INFO ] Epoch 25 Batch 5080 Training err. 1.48335 Training err. RA 1.92872 Valid. err. 1.65644
2018-02-03 22:06:47,395 training [INFO ] Epoch 25 Batch 5100 Training err. 1.48323 Training err. RA 1.92697 Valid. err. 1.67538
2018-02-03 22:06:47,874 training [INFO ] Epoch 25 Batch 5120 Training err. 1.54879 Training err. RA 1.92549 Valid. err. 1.64361
2018-02-03 22:06:48,357 training [INFO ] Epoch 25 Batch 5140 Training err. 1.48053 Training err. RA 1.92376 Valid. err. 1.64266
2018-02-03 22:06:48,842 training [INFO ] Epoch 25 Batch 5160 Training err. 1.45921 Training err. RA 1.92196 Valid. err. 1.64311
2018-02-03 22:06:49,326 training [INFO ] Epoch 25 Batch 5180 Training err. 1.47628 Training err. RA 1.92024 Valid. err. 1.62473
2018-02-03 22:06:49,811 training [INFO ] Epoch 25 Batch 5200 Training err. 1.46673 Training err. RA 1.91850 Valid. err. 1.63658
2018-02-03 22:06:50,677 training [INFO ] Epoch 26 Batch 5220 Training err. 1.46109 Training err. RA 1.91674 Valid. err. 1.62348
2018-02-03 22:06:51,167 training [INFO ] Epoch 26 Batch 5240 Training err. 1.43029 Training err. RA 1.91489 Valid. err. 1.65401
2018-02-03 22:06:51,649 training [INFO ] Epoch 26 Batch 5260 Training err. 1.49817 Training err. RA 1.91330 Valid. err. 1.67941
2018-02-03 22:06:52,129 training [INFO ] Epoch 26 Batch 5280 Training err. 1.51954 Training err. RA 1.91181 Valid. err. 1.65009
2018-02-03 22:06:52,612 training [INFO ] Epoch 26 Batch 5300 Training err. 1.45160 Training err. RA 1.91007 Valid. err. 1.64840
2018-02-03 22:06:53,129 training [INFO ] Epoch 26 Batch 5320 Training err. 1.53007 Training err. RA 1.90865 Valid. err. 1.65049
2018-02-03 22:06:53,696 training [INFO ] Epoch 26 Batch 5340 Training err. 1.48459 Training err. RA 1.90706 Valid. err. 1.63858
2018-02-03 22:06:54,237 training [INFO ] Epoch 26 Batch 5360 Training err. 1.44998 Training err. RA 1.90535 Valid. err. 1.64465
2018-02-03 22:06:54,720 training [INFO ] Epoch 26 Batch 5380 Training err. 1.44965 Training err. RA 1.90366 Valid. err. 1.62604
2018-02-03 22:06:55,203 training [INFO ] Epoch 26 Batch 5400 Training err. 1.47604 Training err. RA 1.90207 Valid. err. 1.60848
2018-02-03 22:06:56,073 training [INFO ] Epoch 27 Batch 5420 Training err. 1.43897 Training err. RA 1.90037 Valid. err. 1.62053
2018-02-03 22:06:56,717 training [INFO ] Epoch 27 Batch 5440 Training err. 1.41293 Training err. RA 1.89857 Valid. err. 1.65131
2018-02-03 22:06:57,294 training [INFO ] Epoch 27 Batch 5460 Training err. 1.48037 Training err. RA 1.89704 Valid. err. 1.63974
2018-02-03 22:06:57,885 training [INFO ] Epoch 27 Batch 5480 Training err. 1.49839 Training err. RA 1.89559 Valid. err. 1.65358
2018-02-03 22:06:58,378 training [INFO ] Epoch 27 Batch 5500 Training err. 1.44798 Training err. RA 1.89396 Valid. err. 1.64592
2018-02-03 22:06:58,889 training [INFO ] Epoch 27 Batch 5520 Training err. 1.47301 Training err. RA 1.89243 Valid. err. 1.62047
2018-02-03 22:06:59,415 training [INFO ] Epoch 27 Batch 5540 Training err. 1.51441 Training err. RA 1.89107 Valid. err. 1.63123
2018-02-03 22:06:59,923 training [INFO ] Epoch 27 Batch 5560 Training err. 1.43603 Training err. RA 1.88943 Valid. err. 1.65148
2018-02-03 22:07:00,504 training [INFO ] Epoch 27 Batch 5580 Training err. 1.44776 Training err. RA 1.88785 Valid. err. 1.64047
2018-02-03 22:07:01,095 training [INFO ] Epoch 27 Batch 5600 Training err. 1.44445 Training err. RA 1.88627 Valid. err. 1.61687
2018-02-03 22:07:02,337 training [INFO ] Epoch 28 Batch 5620 Training err. 1.43066 Training err. RA 1.88464 Valid. err. 1.64778
2018-02-03 22:07:02,998 training [INFO ] Epoch 28 Batch 5640 Training err. 1.42003 Training err. RA 1.88300 Valid. err. 1.64002
2018-02-03 22:07:03,597 training [INFO ] Epoch 28 Batch 5660 Training err. 1.42656 Training err. RA 1.88138 Valid. err. 1.63414
2018-02-03 22:07:04,196 training [INFO ] Epoch 28 Batch 5680 Training err. 1.47721 Training err. RA 1.87996 Valid. err. 1.63216
2018-02-03 22:07:04,689 training [INFO ] Epoch 28 Batch 5700 Training err. 1.46866 Training err. RA 1.87852 Valid. err. 1.66120
2018-02-03 22:07:05,215 training [INFO ] Epoch 28 Batch 5720 Training err. 1.43765 Training err. RA 1.87698 Valid. err. 1.63113
2018-02-03 22:07:05,839 training [INFO ] Epoch 28 Batch 5740 Training err. 1.51213 Training err. RA 1.87570 Valid. err. 1.64210
2018-02-03 22:07:06,427 training [INFO ] Epoch 28 Batch 5760 Training err. 1.42134 Training err. RA 1.87413 Valid. err. 1.63774
2018-02-03 22:07:07,010 training [INFO ] Epoch 28 Batch 5780 Training err. 1.42771 Training err. RA 1.87258 Valid. err. 1.66476
2018-02-03 22:07:07,529 training [INFO ] Epoch 28 Batch 5800 Training err. 1.41837 Training err. RA 1.87102 Valid. err. 1.63475
2018-02-03 22:07:08,095 training [INFO ] Epoch 28 Batch 5820 Training err. 1.45174 Training err. RA 1.86958 Valid. err. 1.60773
2018-02-03 22:07:09,126 training [INFO ] Epoch 29 Batch 5840 Training err. 1.40039 Training err. RA 1.86797 Valid. err. 1.64321
2018-02-03 22:07:09,677 training [INFO ] Epoch 29 Batch 5860 Training err. 1.39069 Training err. RA 1.86634 Valid. err. 1.63453
2018-02-03 22:07:10,249 training [INFO ] Epoch 29 Batch 5880 Training err. 1.44948 Training err. RA 1.86492 Valid. err. 1.63333
2018-02-03 22:07:10,835 training [INFO ] Epoch 29 Batch 5900 Training err. 1.46802 Training err. RA 1.86358 Valid. err. 1.65156
2018-02-03 22:07:11,428 training [INFO ] Epoch 29 Batch 5920 Training err. 1.41730 Training err. RA 1.86207 Valid. err. 1.66750
2018-02-03 22:07:11,950 training [INFO ] Epoch 29 Batch 5940 Training err. 1.48170 Training err. RA 1.86079 Valid. err. 1.62499
2018-02-03 22:07:12,436 training [INFO ] Epoch 29 Batch 5960 Training err. 1.45992 Training err. RA 1.85944 Valid. err. 1.63202
2018-02-03 22:07:12,915 training [INFO ] Epoch 29 Batch 5980 Training err. 1.40638 Training err. RA 1.85793 Valid. err. 1.64333
2018-02-03 22:07:13,397 training [INFO ] Epoch 29 Batch 6000 Training err. 1.41616 Training err. RA 1.85645 Valid. err. 1.61455
2018-02-03 22:07:13,880 training [INFO ] Epoch 29 Batch 6020 Training err. 1.42626 Training err. RA 1.85503 Valid. err. 1.63662
2018-02-03 22:07:14,729 training [INFO ] Epoch 30 Batch 6040 Training err. 1.39673 Training err. RA 1.85351 Valid. err. 1.62437
2018-02-03 22:07:15,239 training [INFO ] Epoch 30 Batch 6060 Training err. 1.37994 Training err. RA 1.85195 Valid. err. 1.63585
2018-02-03 22:07:15,721 training [INFO ] Epoch 30 Batch 6080 Training err. 1.42964 Training err. RA 1.85056 Valid. err. 1.62826
2018-02-03 22:07:16,207 training [INFO ] Epoch 30 Batch 6100 Training err. 1.46303 Training err. RA 1.84929 Valid. err. 1.62645
2018-02-03 22:07:16,691 training [INFO ] Epoch 30 Batch 6120 Training err. 1.40952 Training err. RA 1.84785 Valid. err. 1.63091
2018-02-03 22:07:17,179 training [INFO ] Epoch 30 Batch 6140 Training err. 1.41664 Training err. RA 1.84644 Valid. err. 1.63811
2018-02-03 22:07:17,667 training [INFO ] Epoch 30 Batch 6160 Training err. 1.47188 Training err. RA 1.84523 Valid. err. 1.62225
2018-02-03 22:07:18,160 training [INFO ] Epoch 30 Batch 6180 Training err. 1.40684 Training err. RA 1.84381 Valid. err. 1.61669
2018-02-03 22:07:18,650 training [INFO ] Epoch 30 Batch 6200 Training err. 1.39474 Training err. RA 1.84236 Valid. err. 1.62326
2018-02-03 22:07:19,138 training [INFO ] Epoch 30 Batch 6220 Training err. 1.40206 Training err. RA 1.84094 Valid. err. 1.60886
2018-02-03 22:07:19,626 training [INFO ] Epoch 30 Batch 6240 Training err. 1.39614 Training err. RA 1.83952 Valid. err. 1.61570
2018-02-03 22:07:20,479 training [INFO ] Epoch 31 Batch 6260 Training err. 1.39026 Training err. RA 1.83808 Valid. err. 1.62049
2018-02-03 22:07:20,963 training [INFO ] Epoch 31 Batch 6280 Training err. 1.36308 Training err. RA 1.83657 Valid. err. 1.63229
2018-02-03 22:07:21,447 training [INFO ] Epoch 31 Batch 6300 Training err. 1.42775 Training err. RA 1.83527 Valid. err. 1.65790
2018-02-03 22:07:21,934 training [INFO ] Epoch 31 Batch 6320 Training err. 1.44758 Training err. RA 1.83405 Valid. err. 1.63420
2018-02-03 22:07:22,418 training [INFO ] Epoch 31 Batch 6340 Training err. 1.37849 Training err. RA 1.83261 Valid. err. 1.63274
2018-02-03 22:07:22,901 training [INFO ] Epoch 31 Batch 6360 Training err. 1.46044 Training err. RA 1.83144 Valid. err. 1.62754
2018-02-03 22:07:23,387 training [INFO ] Epoch 31 Batch 6380 Training err. 1.41475 Training err. RA 1.83013 Valid. err. 1.62194
2018-02-03 22:07:23,870 training [INFO ] Epoch 31 Batch 6400 Training err. 1.38048 Training err. RA 1.82873 Valid. err. 1.63250
2018-02-03 22:07:24,360 training [INFO ] Epoch 31 Batch 6420 Training err. 1.38221 Training err. RA 1.82734 Valid. err. 1.61181
2018-02-03 22:07:24,851 training [INFO ] Epoch 31 Batch 6440 Training err. 1.40824 Training err. RA 1.82603 Valid. err. 1.59889
2018-02-03 22:07:25,719 training [INFO ] Epoch 32 Batch 6460 Training err. 1.36884 Training err. RA 1.82462 Valid. err. 1.60432
2018-02-03 22:07:26,207 training [INFO ] Epoch 32 Batch 6480 Training err. 1.34914 Training err. RA 1.82315 Valid. err. 1.63133
2018-02-03 22:07:26,694 training [INFO ] Epoch 32 Batch 6500 Training err. 1.41148 Training err. RA 1.82188 Valid. err. 1.63386
2018-02-03 22:07:27,182 training [INFO ] Epoch 32 Batch 6520 Training err. 1.42976 Training err. RA 1.82068 Valid. err. 1.63996
2018-02-03 22:07:27,668 training [INFO ] Epoch 32 Batch 6540 Training err. 1.37714 Training err. RA 1.81933 Valid. err. 1.64221
2018-02-03 22:07:28,153 training [INFO ] Epoch 32 Batch 6560 Training err. 1.41504 Training err. RA 1.81809 Valid. err. 1.60504
2018-02-03 22:07:28,634 training [INFO ] Epoch 32 Batch 6580 Training err. 1.44420 Training err. RA 1.81696 Valid. err. 1.62182
2018-02-03 22:07:29,118 training [INFO ] Epoch 32 Batch 6600 Training err. 1.36653 Training err. RA 1.81559 Valid. err. 1.63732
2018-02-03 22:07:29,599 training [INFO ] Epoch 32 Batch 6620 Training err. 1.38240 Training err. RA 1.81428 Valid. err. 1.62466
2018-02-03 22:07:30,079 training [INFO ] Epoch 32 Batch 6640 Training err. 1.37714 Training err. RA 1.81297 Valid. err. 1.60544
2018-02-03 22:07:30,926 training [INFO ] Epoch 33 Batch 6660 Training err. 1.37042 Training err. RA 1.81164 Valid. err. 1.62257
2018-02-03 22:07:31,408 training [INFO ] Epoch 33 Batch 6680 Training err. 1.35667 Training err. RA 1.81028 Valid. err. 1.63268
2018-02-03 22:07:31,890 training [INFO ] Epoch 33 Batch 6700 Training err. 1.36104 Training err. RA 1.80893 Valid. err. 1.63432
2018-02-03 22:07:32,373 training [INFO ] Epoch 33 Batch 6720 Training err. 1.41215 Training err. RA 1.80775 Valid. err. 1.62869
2018-02-03 22:07:32,857 training [INFO ] Epoch 33 Batch 6740 Training err. 1.40655 Training err. RA 1.80656 Valid. err. 1.64641
2018-02-03 22:07:33,343 training [INFO ] Epoch 33 Batch 6760 Training err. 1.37347 Training err. RA 1.80528 Valid. err. 1.61393
2018-02-03 22:07:33,830 training [INFO ] Epoch 33 Batch 6780 Training err. 1.44259 Training err. RA 1.80421 Valid. err. 1.63013
2018-02-03 22:07:34,316 training [INFO ] Epoch 33 Batch 6800 Training err. 1.35779 Training err. RA 1.80290 Valid. err. 1.62871
2018-02-03 22:07:34,802 training [INFO ] Epoch 33 Batch 6820 Training err. 1.36051 Training err. RA 1.80160 Valid. err. 1.65580
2018-02-03 22:07:35,288 training [INFO ] Epoch 33 Batch 6840 Training err. 1.35303 Training err. RA 1.80029 Valid. err. 1.63382
2018-02-03 22:07:35,772 training [INFO ] Epoch 33 Batch 6860 Training err. 1.38621 Training err. RA 1.79908 Valid. err. 1.60860
2018-02-03 22:07:36,627 training [INFO ] Epoch 34 Batch 6880 Training err. 1.33831 Training err. RA 1.79774 Valid. err. 1.63783
2018-02-03 22:07:37,111 training [INFO ] Epoch 34 Batch 6900 Training err. 1.33128 Training err. RA 1.79639 Valid. err. 1.63330
2018-02-03 22:07:37,592 training [INFO ] Epoch 34 Batch 6920 Training err. 1.38927 Training err. RA 1.79521 Valid. err. 1.64010
2018-02-03 22:07:38,073 training [INFO ] Epoch 34 Batch 6940 Training err. 1.40407 Training err. RA 1.79409 Valid. err. 1.64190
2018-02-03 22:07:38,556 training [INFO ] Epoch 34 Batch 6960 Training err. 1.35160 Training err. RA 1.79282 Valid. err. 1.66563
2018-02-03 22:07:39,043 training [INFO ] Epoch 34 Batch 6980 Training err. 1.41984 Training err. RA 1.79175 Valid. err. 1.62716
2018-02-03 22:07:39,525 training [INFO ] Epoch 34 Batch 7000 Training err. 1.38706 Training err. RA 1.79059 Valid. err. 1.64356
2018-02-03 22:07:40,008 training [INFO ] Epoch 34 Batch 7020 Training err. 1.34197 Training err. RA 1.78931 Valid. err. 1.66456
2018-02-03 22:07:40,492 training [INFO ] Epoch 34 Batch 7040 Training err. 1.35821 Training err. RA 1.78809 Valid. err. 1.62229
2018-02-03 22:07:40,980 training [INFO ] Epoch 34 Batch 7060 Training err. 1.36567 Training err. RA 1.78689 Valid. err. 1.64499
2018-02-03 22:07:41,834 training [INFO ] Epoch 35 Batch 7080 Training err. 1.33856 Training err. RA 1.78562 Valid. err. 1.61050
2018-02-03 22:07:42,322 training [INFO ] Epoch 35 Batch 7100 Training err. 1.32468 Training err. RA 1.78433 Valid. err. 1.62383
2018-02-03 22:07:42,810 training [INFO ] Epoch 35 Batch 7120 Training err. 1.37012 Training err. RA 1.78316 Valid. err. 1.63716
2018-02-03 22:07:43,295 training [INFO ] Epoch 35 Batch 7140 Training err. 1.40018 Training err. RA 1.78209 Valid. err. 1.63212
2018-02-03 22:07:43,781 training [INFO ] Epoch 35 Batch 7160 Training err. 1.34959 Training err. RA 1.78088 Valid. err. 1.63128
2018-02-03 22:07:44,263 training [INFO ] Epoch 35 Batch 7180 Training err. 1.35052 Training err. RA 1.77968 Valid. err. 1.64184
2018-02-03 22:07:44,746 training [INFO ] Epoch 35 Batch 7200 Training err. 1.40569 Training err. RA 1.77864 Valid. err. 1.63078
2018-02-03 22:07:45,227 training [INFO ] Epoch 35 Batch 7220 Training err. 1.34211 Training err. RA 1.77743 Valid. err. 1.62507
2018-02-03 22:07:45,709 training [INFO ] Epoch 35 Batch 7240 Training err. 1.33145 Training err. RA 1.77620 Valid. err. 1.61858
2018-02-03 22:07:46,193 training [INFO ] Epoch 35 Batch 7260 Training err. 1.34595 Training err. RA 1.77502 Valid. err. 1.62265
2018-02-03 22:07:46,675 training [INFO ] Epoch 35 Batch 7280 Training err. 1.34094 Training err. RA 1.77383 Valid. err. 1.65748
2018-02-03 22:07:47,508 training [INFO ] Epoch 36 Batch 7300 Training err. 1.34794 Training err. RA 1.77266 Valid. err. 1.63022
2018-02-03 22:07:47,998 training [INFO ] Epoch 36 Batch 7320 Training err. 1.31090 Training err. RA 1.77140 Valid. err. 1.64640
2018-02-03 22:07:48,482 training [INFO ] Epoch 36 Batch 7340 Training err. 1.37017 Training err. RA 1.77030 Valid. err. 1.66046
2018-02-03 22:07:48,964 training [INFO ] Epoch 36 Batch 7360 Training err. 1.39051 Training err. RA 1.76927 Valid. err. 1.63272
2018-02-03 22:07:49,447 training [INFO ] Epoch 36 Batch 7380 Training err. 1.31843 Training err. RA 1.76805 Valid. err. 1.63026
2018-02-03 22:07:49,929 training [INFO ] Epoch 36 Batch 7400 Training err. 1.39690 Training err. RA 1.76705 Valid. err. 1.63651
2018-02-03 22:07:50,411 training [INFO ] Epoch 36 Batch 7420 Training err. 1.35426 Training err. RA 1.76593 Valid. err. 1.64910
2018-02-03 22:07:50,895 training [INFO ] Epoch 36 Batch 7440 Training err. 1.32111 Training err. RA 1.76474 Valid. err. 1.64279
2018-02-03 22:07:51,381 training [INFO ] Epoch 36 Batch 7460 Training err. 1.32536 Training err. RA 1.76356 Valid. err. 1.62159
2018-02-03 22:07:51,865 training [INFO ] Epoch 36 Batch 7480 Training err. 1.35362 Training err. RA 1.76246 Valid. err. 1.61143
2018-02-03 22:07:52,728 training [INFO ] Epoch 37 Batch 7500 Training err. 1.31809 Training err. RA 1.76128 Valid. err. 1.61327
2018-02-03 22:07:53,218 training [INFO ] Epoch 37 Batch 7520 Training err. 1.30037 Training err. RA 1.76005 Valid. err. 1.63319
2018-02-03 22:07:53,705 training [INFO ] Epoch 37 Batch 7540 Training err. 1.36144 Training err. RA 1.75900 Valid. err. 1.64443
2018-02-03 22:07:54,199 training [INFO ] Epoch 37 Batch 7560 Training err. 1.37559 Training err. RA 1.75798 Valid. err. 1.64443
2018-02-03 22:07:54,687 training [INFO ] Epoch 37 Batch 7580 Training err. 1.31950 Training err. RA 1.75682 Valid. err. 1.65923
2018-02-03 22:07:55,175 training [INFO ] Epoch 37 Batch 7600 Training err. 1.34986 Training err. RA 1.75575 Valid. err. 1.60462
2018-02-03 22:07:55,664 training [INFO ] Epoch 37 Batch 7620 Training err. 1.38415 Training err. RA 1.75478 Valid. err. 1.61809
2018-02-03 22:07:56,148 training [INFO ] Epoch 37 Batch 7640 Training err. 1.30500 Training err. RA 1.75360 Valid. err. 1.63596
2018-02-03 22:07:56,631 training [INFO ] Epoch 37 Batch 7660 Training err. 1.33017 Training err. RA 1.75250 Valid. err. 1.62908
2018-02-03 22:07:57,110 training [INFO ] Epoch 37 Batch 7680 Training err. 1.32093 Training err. RA 1.75137 Valid. err. 1.61060
2018-02-03 22:07:57,958 training [INFO ] Epoch 38 Batch 7700 Training err. 1.31227 Training err. RA 1.75023 Valid. err. 1.63141
2018-02-03 22:07:58,442 training [INFO ] Epoch 38 Batch 7720 Training err. 1.30824 Training err. RA 1.74909 Valid. err. 1.64201
2018-02-03 22:07:58,924 training [INFO ] Epoch 38 Batch 7740 Training err. 1.30912 Training err. RA 1.74795 Valid. err. 1.67133
2018-02-03 22:07:59,408 training [INFO ] Epoch 38 Batch 7760 Training err. 1.36071 Training err. RA 1.74695 Valid. err. 1.63760
2018-02-03 22:07:59,892 training [INFO ] Epoch 38 Batch 7780 Training err. 1.34983 Training err. RA 1.74593 Valid. err. 1.64693
2018-02-03 22:08:00,382 training [INFO ] Epoch 38 Batch 7800 Training err. 1.31924 Training err. RA 1.74484 Valid. err. 1.61233
2018-02-03 22:08:00,869 training [INFO ] Epoch 38 Batch 7820 Training err. 1.38404 Training err. RA 1.74391 Valid. err. 1.64108
2018-02-03 22:08:01,357 training [INFO ] Epoch 38 Batch 7840 Training err. 1.30102 Training err. RA 1.74278 Valid. err. 1.63940
2018-02-03 22:08:01,845 training [INFO ] Epoch 38 Batch 7860 Training err. 1.30990 Training err. RA 1.74168 Valid. err. 1.68390
2018-02-03 22:08:02,334 training [INFO ] Epoch 38 Batch 7880 Training err. 1.29944 Training err. RA 1.74056 Valid. err. 1.63601
2018-02-03 22:08:02,820 training [INFO ] Epoch 38 Batch 7900 Training err. 1.33543 Training err. RA 1.73953 Valid. err. 1.61592
2018-02-03 22:08:03,673 training [INFO ] Epoch 39 Batch 7920 Training err. 1.28831 Training err. RA 1.73839 Valid. err. 1.64434
2018-02-03 22:08:04,159 training [INFO ] Epoch 39 Batch 7940 Training err. 1.28193 Training err. RA 1.73724 Valid. err. 1.66067
2018-02-03 22:08:04,643 training [INFO ] Epoch 39 Batch 7960 Training err. 1.34092 Training err. RA 1.73625 Valid. err. 1.64630
2018-02-03 22:08:05,123 training [INFO ] Epoch 39 Batch 7980 Training err. 1.35541 Training err. RA 1.73529 Valid. err. 1.64913
2018-02-03 22:08:05,603 training [INFO ] Epoch 39 Batch 8000 Training err. 1.29398 Training err. RA 1.73419 Valid. err. 1.68400
2018-02-03 22:08:06,091 training [INFO ] Epoch 39 Batch 8020 Training err. 1.36454 Training err. RA 1.73327 Valid. err. 1.64053
2018-02-03 22:08:06,574 training [INFO ] Epoch 39 Batch 8040 Training err. 1.33793 Training err. RA 1.73229 Valid. err. 1.65982
2018-02-03 22:08:07,056 training [INFO ] Epoch 39 Batch 8060 Training err. 1.29107 Training err. RA 1.73119 Valid. err. 1.66821
2018-02-03 22:08:07,538 training [INFO ] Epoch 39 Batch 8080 Training err. 1.30623 Training err. RA 1.73014 Valid. err. 1.62410
2018-02-03 22:08:08,019 training [INFO ] Epoch 39 Batch 8100 Training err. 1.31217 Training err. RA 1.72911 Valid. err. 1.63137
2018-02-03 22:08:08,842 training [INFO ] Epoch 40 Batch 8120 Training err. 1.29789 Training err. RA 1.72804 Valid. err. 1.60995
2018-02-03 22:08:09,322 training [INFO ] Epoch 40 Batch 8140 Training err. 1.28131 Training err. RA 1.72695 Valid. err. 1.64363
2018-02-03 22:08:09,803 training [INFO ] Epoch 40 Batch 8160 Training err. 1.32552 Training err. RA 1.72596 Valid. err. 1.62728
2018-02-03 22:08:10,285 training [INFO ] Epoch 40 Batch 8180 Training err. 1.34740 Training err. RA 1.72504 Valid. err. 1.64011
2018-02-03 22:08:10,768 training [INFO ] Epoch 40 Batch 8200 Training err. 1.29185 Training err. RA 1.72398 Valid. err. 1.64418
2018-02-03 22:08:11,251 training [INFO ] Epoch 40 Batch 8220 Training err. 1.30720 Training err. RA 1.72297 Valid. err. 1.64307
2018-02-03 22:08:11,735 training [INFO ] Epoch 40 Batch 8240 Training err. 1.35388 Training err. RA 1.72207 Valid. err. 1.63198
2018-02-03 22:08:12,221 training [INFO ] Epoch 40 Batch 8260 Training err. 1.29799 Training err. RA 1.72104 Valid. err. 1.63184
2018-02-03 22:08:12,709 training [INFO ] Epoch 40 Batch 8280 Training err. 1.28303 Training err. RA 1.71999 Valid. err. 1.63408
2018-02-03 22:08:13,195 training [INFO ] Epoch 40 Batch 8300 Training err. 1.29133 Training err. RA 1.71895 Valid. err. 1.62858
2018-02-03 22:08:13,682 training [INFO ] Epoch 40 Batch 8320 Training err. 1.28943 Training err. RA 1.71792 Valid. err. 1.65631
2018-02-03 22:08:14,529 training [INFO ] Epoch 41 Batch 8340 Training err. 1.30245 Training err. RA 1.71692 Valid. err. 1.63518
2018-02-03 22:08:15,016 training [INFO ] Epoch 41 Batch 8360 Training err. 1.26149 Training err. RA 1.71584 Valid. err. 1.67814
2018-02-03 22:08:15,503 training [INFO ] Epoch 41 Batch 8380 Training err. 1.33005 Training err. RA 1.71491 Valid. err. 1.66994
2018-02-03 22:08:15,988 training [INFO ] Epoch 41 Batch 8400 Training err. 1.33706 Training err. RA 1.71401 Valid. err. 1.63534
2018-02-03 22:08:16,470 training [INFO ] Epoch 41 Batch 8420 Training err. 1.27217 Training err. RA 1.71297 Valid. err. 1.63331
2018-02-03 22:08:16,952 training [INFO ] Epoch 41 Batch 8440 Training err. 1.34542 Training err. RA 1.71209 Valid. err. 1.64613
2018-02-03 22:08:17,433 training [INFO ] Epoch 41 Batch 8460 Training err. 1.31019 Training err. RA 1.71114 Valid. err. 1.66028
2018-02-03 22:08:17,920 training [INFO ] Epoch 41 Batch 8480 Training err. 1.27869 Training err. RA 1.71012 Valid. err. 1.66718
2018-02-03 22:08:18,401 training [INFO ] Epoch 41 Batch 8500 Training err. 1.27675 Training err. RA 1.70910 Valid. err. 1.63189
2018-02-03 22:08:18,882 training [INFO ] Epoch 41 Batch 8520 Training err. 1.31380 Training err. RA 1.70818 Valid. err. 1.63413
2018-02-03 22:08:19,706 training [INFO ] Epoch 42 Batch 8540 Training err. 1.26844 Training err. RA 1.70715 Valid. err. 1.62328
2018-02-03 22:08:20,192 training [INFO ] Epoch 42 Batch 8560 Training err. 1.25533 Training err. RA 1.70609 Valid. err. 1.64243
2018-02-03 22:08:20,682 training [INFO ] Epoch 42 Batch 8580 Training err. 1.31502 Training err. RA 1.70518 Valid. err. 1.64598
2018-02-03 22:08:21,167 training [INFO ] Epoch 42 Batch 8600 Training err. 1.33188 Training err. RA 1.70431 Valid. err. 1.64787
2018-02-03 22:08:21,654 training [INFO ] Epoch 42 Batch 8620 Training err. 1.28484 Training err. RA 1.70334 Valid. err. 1.65797
2018-02-03 22:08:22,139 training [INFO ] Epoch 42 Batch 8640 Training err. 1.30384 Training err. RA 1.70241 Valid. err. 1.62007
2018-02-03 22:08:22,622 training [INFO ] Epoch 42 Batch 8660 Training err. 1.34091 Training err. RA 1.70158 Valid. err. 1.63135
2018-02-03 22:08:23,108 training [INFO ] Epoch 42 Batch 8680 Training err. 1.28302 Training err. RA 1.70061 Valid. err. 1.65262
2018-02-03 22:08:23,595 training [INFO ] Epoch 42 Batch 8700 Training err. 1.28255 Training err. RA 1.69965 Valid. err. 1.65105
2018-02-03 22:08:24,079 training [INFO ] Epoch 42 Batch 8720 Training err. 1.27593 Training err. RA 1.69868 Valid. err. 1.63381
2018-02-03 22:08:24,917 training [INFO ] Epoch 43 Batch 8740 Training err. 1.26954 Training err. RA 1.69770 Valid. err. 1.63641
2018-02-03 22:08:25,398 training [INFO ] Epoch 43 Batch 8760 Training err. 1.26601 Training err. RA 1.69671 Valid. err. 1.65456
2018-02-03 22:08:25,880 training [INFO ] Epoch 43 Batch 8780 Training err. 1.27207 Training err. RA 1.69575 Valid. err. 1.66172
2018-02-03 22:08:26,363 training [INFO ] Epoch 43 Batch 8800 Training err. 1.31638 Training err. RA 1.69488 Valid. err. 1.63323
2018-02-03 22:08:26,845 training [INFO ] Epoch 43 Batch 8820 Training err. 1.30581 Training err. RA 1.69400 Valid. err. 1.64669
2018-02-03 22:08:27,326 training [INFO ] Epoch 43 Batch 8840 Training err. 1.26483 Training err. RA 1.69303 Valid. err. 1.62100
2018-02-03 22:08:27,808 training [INFO ] Epoch 43 Batch 8860 Training err. 1.34146 Training err. RA 1.69224 Valid. err. 1.64814
2018-02-03 22:08:28,294 training [INFO ] Epoch 43 Batch 8880 Training err. 1.26118 Training err. RA 1.69127 Valid. err. 1.64938
2018-02-03 22:08:28,781 training [INFO ] Epoch 43 Batch 8900 Training err. 1.27064 Training err. RA 1.69032 Valid. err. 1.68617
2018-02-03 22:08:29,267 training [INFO ] Epoch 43 Batch 8920 Training err. 1.25171 Training err. RA 1.68934 Valid. err. 1.63856
2018-02-03 22:08:29,755 training [INFO ] Epoch 43 Batch 8940 Training err. 1.29945 Training err. RA 1.68847 Valid. err. 1.62942
2018-02-03 22:08:30,594 training [INFO ] Epoch 44 Batch 8960 Training err. 1.24894 Training err. RA 1.68748 Valid. err. 1.64938
2018-02-03 22:08:31,083 training [INFO ] Epoch 44 Batch 8980 Training err. 1.23945 Training err. RA 1.68649 Valid. err. 1.64767
2018-02-03 22:08:31,572 training [INFO ] Epoch 44 Batch 9000 Training err. 1.30364 Training err. RA 1.68564 Valid. err. 1.66486
2018-02-03 22:08:32,055 training [INFO ] Epoch 44 Batch 9020 Training err. 1.31297 Training err. RA 1.68481 Valid. err. 1.65199
2018-02-03 22:08:32,537 training [INFO ] Epoch 44 Batch 9040 Training err. 1.25636 Training err. RA 1.68386 Valid. err. 1.66323
2018-02-03 22:08:33,019 training [INFO ] Epoch 44 Batch 9060 Training err. 1.32244 Training err. RA 1.68306 Valid. err. 1.62389
2018-02-03 22:08:33,502 training [INFO ] Epoch 44 Batch 9080 Training err. 1.29557 Training err. RA 1.68221 Valid. err. 1.66222
2018-02-03 22:08:33,984 training [INFO ] Epoch 44 Batch 9100 Training err. 1.25661 Training err. RA 1.68127 Valid. err. 1.67987
2018-02-03 22:08:34,467 training [INFO ] Epoch 44 Batch 9120 Training err. 1.26246 Training err. RA 1.68036 Valid. err. 1.62328
2018-02-03 22:08:34,952 training [INFO ] Epoch 44 Batch 9140 Training err. 1.26819 Training err. RA 1.67945 Valid. err. 1.65510
2018-02-03 22:08:35,785 training [INFO ] Epoch 45 Batch 9160 Training err. 1.24615 Training err. RA 1.67851 Valid. err. 1.63293
2018-02-03 22:08:36,279 training [INFO ] Epoch 45 Batch 9180 Training err. 1.24277 Training err. RA 1.67756 Valid. err. 1.64895
2018-02-03 22:08:36,767 training [INFO ] Epoch 45 Batch 9200 Training err. 1.28179 Training err. RA 1.67670 Valid. err. 1.64484
2018-02-03 22:08:37,253 training [INFO ] Epoch 45 Batch 9220 Training err. 1.30803 Training err. RA 1.67590 Valid. err. 1.63921
2018-02-03 22:08:37,740 training [INFO ] Epoch 45 Batch 9240 Training err. 1.25415 Training err. RA 1.67499 Valid. err. 1.66334
2018-02-03 22:08:38,230 training [INFO ] Epoch 45 Batch 9260 Training err. 1.26213 Training err. RA 1.67409 Valid. err. 1.63684
2018-02-03 22:08:38,722 training [INFO ] Epoch 45 Batch 9280 Training err. 1.31770 Training err. RA 1.67333 Valid. err. 1.64195
2018-02-03 22:08:39,211 training [INFO ] Epoch 45 Batch 9300 Training err. 1.24730 Training err. RA 1.67241 Valid. err. 1.64904
2018-02-03 22:08:39,698 training [INFO ] Epoch 45 Batch 9320 Training err. 1.24243 Training err. RA 1.67149 Valid. err. 1.64329
2018-02-03 22:08:40,183 training [INFO ] Epoch 45 Batch 9340 Training err. 1.24900 Training err. RA 1.67058 Valid. err. 1.67737
2018-02-03 22:08:40,664 training [INFO ] Epoch 45 Batch 9360 Training err. 1.25422 Training err. RA 1.66969 Valid. err. 1.68645
2018-02-03 22:08:41,478 training [INFO ] Epoch 46 Batch 9380 Training err. 1.25657 Training err. RA 1.66881 Valid. err. 1.65034
2018-02-03 22:08:41,960 training [INFO ] Epoch 46 Batch 9400 Training err. 1.22450 Training err. RA 1.66787 Valid. err. 1.68866
2018-02-03 22:08:42,445 training [INFO ] Epoch 46 Batch 9420 Training err. 1.28529 Training err. RA 1.66705 Valid. err. 1.65917
2018-02-03 22:08:42,928 training [INFO ] Epoch 46 Batch 9440 Training err. 1.29985 Training err. RA 1.66628 Valid. err. 1.64062
2018-02-03 22:08:43,409 training [INFO ] Epoch 46 Batch 9460 Training err. 1.23013 Training err. RA 1.66535 Valid. err. 1.64205
2018-02-03 22:08:43,891 training [INFO ] Epoch 46 Batch 9480 Training err. 1.30700 Training err. RA 1.66460 Valid. err. 1.65566
2018-02-03 22:08:44,377 training [INFO ] Epoch 46 Batch 9500 Training err. 1.27169 Training err. RA 1.66377 Valid. err. 1.66749
2018-02-03 22:08:44,861 training [INFO ] Epoch 46 Batch 9520 Training err. 1.23224 Training err. RA 1.66286 Valid. err. 1.66941
2018-02-03 22:08:45,348 training [INFO ] Epoch 46 Batch 9540 Training err. 1.23676 Training err. RA 1.66197 Valid. err. 1.63879
2018-02-03 22:08:45,834 training [INFO ] Epoch 46 Batch 9560 Training err. 1.27304 Training err. RA 1.66116 Valid. err. 1.63468
2018-02-03 22:08:46,688 training [INFO ] Epoch 47 Batch 9580 Training err. 1.23563 Training err. RA 1.66027 Valid. err. 1.64240
2018-02-03 22:08:47,173 training [INFO ] Epoch 47 Batch 9600 Training err. 1.22926 Training err. RA 1.65937 Valid. err. 1.67332
2018-02-03 22:08:47,654 training [INFO ] Epoch 47 Batch 9620 Training err. 1.27864 Training err. RA 1.65858 Valid. err. 1.65028
2018-02-03 22:08:48,143 training [INFO ] Epoch 47 Batch 9640 Training err. 1.29277 Training err. RA 1.65782 Valid. err. 1.65132
2018-02-03 22:08:48,623 training [INFO ] Epoch 47 Batch 9660 Training err. 1.23359 Training err. RA 1.65694 Valid. err. 1.68880
2018-02-03 22:08:49,104 training [INFO ] Epoch 47 Batch 9680 Training err. 1.26358 Training err. RA 1.65613 Valid. err. 1.63776
2018-02-03 22:08:49,587 training [INFO ] Epoch 47 Batch 9700 Training err. 1.31013 Training err. RA 1.65542 Valid. err. 1.60977
2018-02-03 22:08:50,070 training [INFO ] Epoch 47 Batch 9720 Training err. 1.22783 Training err. RA 1.65454 Valid. err. 1.65550
2018-02-03 22:08:50,553 training [INFO ] Epoch 47 Batch 9740 Training err. 1.24567 Training err. RA 1.65370 Valid. err. 1.65102
2018-02-03 22:08:51,036 training [INFO ] Epoch 47 Batch 9760 Training err. 1.24339 Training err. RA 1.65286 Valid. err. 1.64354
2018-02-03 22:08:51,866 training [INFO ] Epoch 48 Batch 9780 Training err. 1.23898 Training err. RA 1.65201 Valid. err. 1.65705
2018-02-03 22:08:52,348 training [INFO ] Epoch 48 Batch 9800 Training err. 1.23368 Training err. RA 1.65116 Valid. err. 1.66583
2018-02-03 22:08:52,831 training [INFO ] Epoch 48 Batch 9820 Training err. 1.23619 Training err. RA 1.65031 Valid. err. 1.67825
2018-02-03 22:08:53,313 training [INFO ] Epoch 48 Batch 9840 Training err. 1.27761 Training err. RA 1.64955 Valid. err. 1.65344
2018-02-03 22:08:53,795 training [INFO ] Epoch 48 Batch 9860 Training err. 1.26641 Training err. RA 1.64878 Valid. err. 1.65023
2018-02-03 22:08:54,286 training [INFO ] Epoch 48 Batch 9880 Training err. 1.23459 Training err. RA 1.64794 Valid. err. 1.62828
2018-02-03 22:08:54,767 training [INFO ] Epoch 48 Batch 9900 Training err. 1.30381 Training err. RA 1.64724 Valid. err. 1.65188
2018-02-03 22:08:55,250 training [INFO ] Epoch 48 Batch 9920 Training err. 1.21978 Training err. RA 1.64638 Valid. err. 1.66827
2018-02-03 22:08:55,733 training [INFO ] Epoch 48 Batch 9940 Training err. 1.22962 Training err. RA 1.64554 Valid. err. 1.71659
2018-02-03 22:08:56,216 training [INFO ] Epoch 48 Batch 9960 Training err. 1.21820 Training err. RA 1.64468 Valid. err. 1.65433
2018-02-03 22:08:56,699 training [INFO ] Epoch 48 Batch 9980 Training err. 1.26146 Training err. RA 1.64392 Valid. err. 1.62437
2018-02-03 22:08:57,518 training [INFO ] Epoch 49 Batch10000 Training err. 1.21378 Training err. RA 1.64306 Valid. err. 1.65295
2018-02-03 22:08:57,999 training [INFO ] Epoch 49 Batch10020 Training err. 1.21261 Training err. RA 1.64220 Valid. err. 1.66233
2018-02-03 22:08:58,481 training [INFO ] Epoch 49 Batch10040 Training err. 1.26785 Training err. RA 1.64145 Valid. err. 1.68534
2018-02-03 22:08:58,959 training [INFO ] Epoch 49 Batch10060 Training err. 1.27706 Training err. RA 1.64073 Valid. err. 1.65684
2018-02-03 22:08:59,442 training [INFO ] Epoch 49 Batch10080 Training err. 1.21044 Training err. RA 1.63987 Valid. err. 1.67223
2018-02-03 22:08:59,923 training [INFO ] Epoch 49 Batch10100 Training err. 1.29221 Training err. RA 1.63918 Valid. err. 1.62858
2018-02-03 22:09:00,415 training [INFO ] Epoch 49 Batch10120 Training err. 1.26241 Training err. RA 1.63844 Valid. err. 1.66293
2018-02-03 22:09:00,903 training [INFO ] Epoch 49 Batch10140 Training err. 1.21264 Training err. RA 1.63760 Valid. err. 1.70398
2018-02-03 22:09:01,391 training [INFO ] Epoch 49 Batch10160 Training err. 1.23559 Training err. RA 1.63681 Valid. err. 1.63374
2018-02-03 22:09:01,876 training [INFO ] Epoch 49 Batch10180 Training err. 1.23711 Training err. RA 1.63602 Valid. err. 1.64462
2018-02-03 22:09:02,723 training [INFO ] Epoch 50 Batch10200 Training err. 1.21505 Training err. RA 1.63520 Valid. err. 1.63351
2018-02-03 22:09:03,211 training [INFO ] Epoch 50 Batch10220 Training err. 1.20798 Training err. RA 1.63436 Valid. err. 1.67205
2018-02-03 22:09:03,697 training [INFO ] Epoch 50 Batch10240 Training err. 1.25180 Training err. RA 1.63361 Valid. err. 1.64959
2018-02-03 22:09:04,181 training [INFO ] Epoch 50 Batch10260 Training err. 1.27250 Training err. RA 1.63291 Valid. err. 1.65492
2018-02-03 22:09:04,663 training [INFO ] Epoch 50 Batch10280 Training err. 1.21816 Training err. RA 1.63210 Valid. err. 1.67357
2018-02-03 22:09:05,146 training [INFO ] Epoch 50 Batch10300 Training err. 1.22705 Training err. RA 1.63132 Valid. err. 1.65479
2018-02-03 22:09:05,630 training [INFO ] Epoch 50 Batch10320 Training err. 1.27891 Training err. RA 1.63063 Valid. err. 1.66510
2018-02-03 22:09:06,117 training [INFO ] Epoch 50 Batch10340 Training err. 1.22174 Training err. RA 1.62984 Valid. err. 1.65660
2018-02-03 22:09:06,601 training [INFO ] Epoch 50 Batch10360 Training err. 1.20868 Training err. RA 1.62903 Valid. err. 1.65252
2018-02-03 22:09:07,083 training [INFO ] Epoch 50 Batch10380 Training err. 1.21750 Training err. RA 1.62824 Valid. err. 1.68558
2018-02-03 22:09:07,567 training [INFO ] Epoch 50 Batch10400 Training err. 1.22813 Training err. RA 1.62747 Valid. err. 1.67155
2018-02-03 22:09:08,391 training [INFO ] Epoch 51 Batch10420 Training err. 1.22469 Training err. RA 1.62670 Valid. err. 1.65170
2018-02-03 22:09:08,879 training [INFO ] Epoch 51 Batch10440 Training err. 1.19352 Training err. RA 1.62587 Valid. err. 1.66396
2018-02-03 22:09:09,364 training [INFO ] Epoch 51 Batch10460 Training err. 1.25479 Training err. RA 1.62516 Valid. err. 1.67575
2018-02-03 22:09:09,852 training [INFO ] Epoch 51 Batch10480 Training err. 1.26560 Training err. RA 1.62447 Valid. err. 1.65012
2018-02-03 22:09:10,338 training [INFO ] Epoch 51 Batch10500 Training err. 1.20207 Training err. RA 1.62367 Valid. err. 1.65563
2018-02-03 22:09:10,826 training [INFO ] Epoch 51 Batch10520 Training err. 1.26976 Training err. RA 1.62299 Valid. err. 1.64610
2018-02-03 22:09:11,312 training [INFO ] Epoch 51 Batch10540 Training err. 1.24771 Training err. RA 1.62228 Valid. err. 1.66272
2018-02-03 22:09:11,802 training [INFO ] Epoch 51 Batch10560 Training err. 1.19366 Training err. RA 1.62147 Valid. err. 1.68755
2018-02-03 22:09:12,286 training [INFO ] Epoch 51 Batch10580 Training err. 1.19959 Training err. RA 1.62067 Valid. err. 1.64798
2018-02-03 22:09:12,771 training [INFO ] Epoch 51 Batch10600 Training err. 1.23721 Training err. RA 1.61995 Valid. err. 1.64175
2018-02-03 22:09:13,603 training [INFO ] Epoch 52 Batch10620 Training err. 1.19970 Training err. RA 1.61916 Valid. err. 1.64345
2018-02-03 22:09:14,084 training [INFO ] Epoch 52 Batch10640 Training err. 1.18819 Training err. RA 1.61835 Valid. err. 1.68445
2018-02-03 22:09:14,567 training [INFO ] Epoch 52 Batch10660 Training err. 1.23967 Training err. RA 1.61764 Valid. err. 1.67435
2018-02-03 22:09:15,051 training [INFO ] Epoch 52 Batch10680 Training err. 1.26138 Training err. RA 1.61697 Valid. err. 1.63898
2018-02-03 22:09:15,536 training [INFO ] Epoch 52 Batch10700 Training err. 1.20044 Training err. RA 1.61619 Valid. err. 1.68080
2018-02-03 22:09:16,018 training [INFO ] Epoch 52 Batch10720 Training err. 1.22884 Training err. RA 1.61547 Valid. err. 1.63799
2018-02-03 22:09:16,503 training [INFO ] Epoch 52 Batch10740 Training err. 1.27340 Training err. RA 1.61483 Valid. err. 1.62283
2018-02-03 22:09:16,989 training [INFO ] Epoch 52 Batch10760 Training err. 1.18929 Training err. RA 1.61404 Valid. err. 1.65866
2018-02-03 22:09:17,476 training [INFO ] Epoch 52 Batch10780 Training err. 1.21420 Training err. RA 1.61330 Valid. err. 1.65032
2018-02-03 22:09:17,969 training [INFO ] Epoch 52 Batch10800 Training err. 1.21243 Training err. RA 1.61255 Valid. err. 1.62540
2018-02-03 22:09:18,804 training [INFO ] Epoch 53 Batch10820 Training err. 1.21052 Training err. RA 1.61181 Valid. err. 1.63665
2018-02-03 22:09:19,291 training [INFO ] Epoch 53 Batch10840 Training err. 1.20322 Training err. RA 1.61106 Valid. err. 1.65793
2018-02-03 22:09:19,776 training [INFO ] Epoch 53 Batch10860 Training err. 1.20394 Training err. RA 1.61031 Valid. err. 1.67852
2018-02-03 22:09:20,259 training [INFO ] Epoch 53 Batch10880 Training err. 1.24453 Training err. RA 1.60964 Valid. err. 1.67388
2018-02-03 22:09:20,744 training [INFO ] Epoch 53 Batch10900 Training err. 1.23513 Training err. RA 1.60895 Valid. err. 1.67022
2018-02-03 22:09:21,225 training [INFO ] Epoch 53 Batch10920 Training err. 1.20426 Training err. RA 1.60821 Valid. err. 1.63132
2018-02-03 22:09:21,709 training [INFO ] Epoch 53 Batch10940 Training err. 1.26979 Training err. RA 1.60759 Valid. err. 1.65028
2018-02-03 22:09:22,191 training [INFO ] Epoch 53 Batch10960 Training err. 1.19913 Training err. RA 1.60684 Valid. err. 1.67032
2018-02-03 22:09:22,675 training [INFO ] Epoch 53 Batch10980 Training err. 1.19351 Training err. RA 1.60609 Valid. err. 1.72271
2018-02-03 22:09:23,155 training [INFO ] Epoch 53 Batch11000 Training err. 1.18723 Training err. RA 1.60533 Valid. err. 1.65883
2018-02-03 22:09:23,637 training [INFO ] Epoch 53 Batch11020 Training err. 1.23359 Training err. RA 1.60465 Valid. err. 1.63938
2018-02-03 22:09:24,476 training [INFO ] Epoch 54 Batch11040 Training err. 1.18076 Training err. RA 1.60389 Valid. err. 1.66374
2018-02-03 22:09:24,962 training [INFO ] Epoch 54 Batch11060 Training err. 1.18030 Training err. RA 1.60312 Valid. err. 1.68738
2018-02-03 22:09:25,448 training [INFO ] Epoch 54 Batch11080 Training err. 1.22668 Training err. RA 1.60244 Valid. err. 1.68230
2018-02-03 22:09:25,936 training [INFO ] Epoch 54 Batch11100 Training err. 1.25149 Training err. RA 1.60181 Valid. err. 1.69258
2018-02-03 22:09:26,423 training [INFO ] Epoch 54 Batch11120 Training err. 1.18214 Training err. RA 1.60105 Valid. err. 1.70256
2018-02-03 22:09:26,909 training [INFO ] Epoch 54 Batch11140 Training err. 1.26059 Training err. RA 1.60044 Valid. err. 1.65039
2018-02-03 22:09:27,396 training [INFO ] Epoch 54 Batch11160 Training err. 1.22536 Training err. RA 1.59977 Valid. err. 1.65146
2018-02-03 22:09:27,882 training [INFO ] Epoch 54 Batch11180 Training err. 1.18166 Training err. RA 1.59902 Valid. err. 1.70526
2018-02-03 22:09:28,365 training [INFO ] Epoch 54 Batch11200 Training err. 1.21343 Training err. RA 1.59833 Valid. err. 1.65350
2018-02-03 22:09:28,845 training [INFO ] Epoch 54 Batch11220 Training err. 1.20780 Training err. RA 1.59764 Valid. err. 1.66234
2018-02-03 22:09:29,671 training [INFO ] Epoch 55 Batch11240 Training err. 1.18261 Training err. RA 1.59690 Valid. err. 1.65953
2018-02-03 22:09:30,153 training [INFO ] Epoch 55 Batch11260 Training err. 1.18131 Training err. RA 1.59616 Valid. err. 1.69458
2018-02-03 22:09:30,636 training [INFO ] Epoch 55 Batch11280 Training err. 1.21181 Training err. RA 1.59548 Valid. err. 1.65914
2018-02-03 22:09:31,119 training [INFO ] Epoch 55 Batch11300 Training err. 1.24530 Training err. RA 1.59486 Valid. err. 1.65908
2018-02-03 22:09:31,602 training [INFO ] Epoch 55 Batch11320 Training err. 1.18750 Training err. RA 1.59414 Valid. err. 1.69428
2018-02-03 22:09:32,084 training [INFO ] Epoch 55 Batch11340 Training err. 1.20232 Training err. RA 1.59345 Valid. err. 1.65571
2018-02-03 22:09:32,566 training [INFO ] Epoch 55 Batch11360 Training err. 1.25299 Training err. RA 1.59285 Valid. err. 1.67498
2018-02-03 22:09:33,047 training [INFO ] Epoch 55 Batch11380 Training err. 1.18768 Training err. RA 1.59214 Valid. err. 1.66153
2018-02-03 22:09:33,530 training [INFO ] Epoch 55 Batch11400 Training err. 1.18248 Training err. RA 1.59142 Valid. err. 1.65540
2018-02-03 22:09:34,014 training [INFO ] Epoch 55 Batch11420 Training err. 1.18506 Training err. RA 1.59071 Valid. err. 1.68907
2018-02-03 22:09:34,497 training [INFO ] Epoch 55 Batch11440 Training err. 1.20067 Training err. RA 1.59003 Valid. err. 1.69153
2018-02-03 22:09:35,331 training [INFO ] Epoch 56 Batch11460 Training err. 1.20406 Training err. RA 1.58935 Valid. err. 1.66789
2018-02-03 22:09:35,815 training [INFO ] Epoch 56 Batch11480 Training err. 1.16445 Training err. RA 1.58861 Valid. err. 1.70069
2018-02-03 22:09:36,307 training [INFO ] Epoch 56 Batch11500 Training err. 1.22405 Training err. RA 1.58798 Valid. err. 1.70655
2018-02-03 22:09:36,794 training [INFO ] Epoch 56 Batch11520 Training err. 1.23884 Training err. RA 1.58737 Valid. err. 1.68903
2018-02-03 22:09:37,283 training [INFO ] Epoch 56 Batch11540 Training err. 1.16682 Training err. RA 1.58664 Valid. err. 1.67622
2018-02-03 22:09:37,770 training [INFO ] Epoch 56 Batch11560 Training err. 1.24393 Training err. RA 1.58605 Valid. err. 1.66276
2018-02-03 22:09:38,258 training [INFO ] Epoch 56 Batch11580 Training err. 1.20322 Training err. RA 1.58539 Valid. err. 1.69110
2018-02-03 22:09:38,753 training [INFO ] Epoch 56 Batch11600 Training err. 1.16713 Training err. RA 1.58467 Valid. err. 1.68939
2018-02-03 22:09:39,240 training [INFO ] Epoch 56 Batch11620 Training err. 1.17382 Training err. RA 1.58396 Valid. err. 1.65238
2018-02-03 22:09:39,727 training [INFO ] Epoch 56 Batch11640 Training err. 1.20794 Training err. RA 1.58331 Valid. err. 1.69056
2018-02-03 22:09:40,555 training [INFO ] Epoch 57 Batch11660 Training err. 1.17777 Training err. RA 1.58262 Valid. err. 1.66148
2018-02-03 22:09:41,039 training [INFO ] Epoch 57 Batch11680 Training err. 1.16928 Training err. RA 1.58191 Valid. err. 1.70221
2018-02-03 22:09:41,523 training [INFO ] Epoch 57 Batch11700 Training err. 1.20942 Training err. RA 1.58127 Valid. err. 1.67720
2018-02-03 22:09:42,008 training [INFO ] Epoch 57 Batch11720 Training err. 1.23310 Training err. RA 1.58068 Valid. err. 1.66623
2018-02-03 22:09:42,490 training [INFO ] Epoch 57 Batch11740 Training err. 1.16876 Training err. RA 1.57998 Valid. err. 1.71683
2018-02-03 22:09:42,973 training [INFO ] Epoch 57 Batch11760 Training err. 1.20682 Training err. RA 1.57934 Valid. err. 1.64936
2018-02-03 22:09:43,455 training [INFO ] Epoch 57 Batch11780 Training err. 1.24588 Training err. RA 1.57878 Valid. err. 1.63984
2018-02-03 22:09:43,936 training [INFO ] Epoch 57 Batch11800 Training err. 1.16782 Training err. RA 1.57808 Valid. err. 1.67540
2018-02-03 22:09:44,422 training [INFO ] Epoch 57 Batch11820 Training err. 1.18703 Training err. RA 1.57742 Valid. err. 1.68200
2018-02-03 22:09:44,909 training [INFO ] Epoch 57 Batch11840 Training err. 1.18407 Training err. RA 1.57675 Valid. err. 1.66623
2018-02-03 22:09:45,758 training [INFO ] Epoch 58 Batch11860 Training err. 1.18042 Training err. RA 1.57609 Valid. err. 1.65546
2018-02-03 22:09:46,245 training [INFO ] Epoch 58 Batch11880 Training err. 1.18513 Training err. RA 1.57543 Valid. err. 1.65830
2018-02-03 22:09:46,733 training [INFO ] Epoch 58 Batch11900 Training err. 1.16953 Training err. RA 1.57475 Valid. err. 1.67707
2018-02-03 22:09:47,221 training [INFO ] Epoch 58 Batch11920 Training err. 1.21516 Training err. RA 1.57414 Valid. err. 1.69144
2018-02-03 22:09:47,707 training [INFO ] Epoch 58 Batch11940 Training err. 1.20415 Training err. RA 1.57352 Valid. err. 1.68033
2018-02-03 22:09:48,191 training [INFO ] Epoch 58 Batch11960 Training err. 1.17508 Training err. RA 1.57286 Valid. err. 1.65252
2018-02-03 22:09:48,674 training [INFO ] Epoch 58 Batch11980 Training err. 1.24645 Training err. RA 1.57231 Valid. err. 1.65937
2018-02-03 22:09:49,153 training [INFO ] Epoch 58 Batch12000 Training err. 1.16894 Training err. RA 1.57164 Valid. err. 1.69324
2018-02-03 22:09:49,636 training [INFO ] Epoch 58 Batch12020 Training err. 1.16896 Training err. RA 1.57097 Valid. err. 1.71295
2018-02-03 22:09:50,120 training [INFO ] Epoch 58 Batch12040 Training err. 1.16284 Training err. RA 1.57029 Valid. err. 1.67617
2018-02-03 22:09:50,604 training [INFO ] Epoch 58 Batch12060 Training err. 1.20459 Training err. RA 1.56968 Valid. err. 1.64288
2018-02-03 22:09:51,432 training [INFO ] Epoch 59 Batch12080 Training err. 1.14915 Training err. RA 1.56899 Valid. err. 1.66787
2018-02-03 22:09:51,945 training [INFO ] Epoch 59 Batch12100 Training err. 1.15874 Training err. RA 1.56831 Valid. err. 1.69206
2018-02-03 22:09:52,453 training [INFO ] Epoch 59 Batch12120 Training err. 1.21483 Training err. RA 1.56773 Valid. err. 1.69371
2018-02-03 22:09:52,977 training [INFO ] Epoch 59 Batch12140 Training err. 1.21813 Training err. RA 1.56715 Valid. err. 1.68316
2018-02-03 22:09:53,492 training [INFO ] Epoch 59 Batch12160 Training err. 1.15903 Training err. RA 1.56648 Valid. err. 1.69091
2018-02-03 22:09:54,059 training [INFO ] Epoch 59 Batch12180 Training err. 1.22658 Training err. RA 1.56592 Valid. err. 1.66109
2018-02-03 22:09:54,701 training [INFO ] Epoch 59 Batch12200 Training err. 1.20688 Training err. RA 1.56533 Valid. err. 1.66099
2018-02-03 22:09:55,185 training [INFO ] Epoch 59 Batch12220 Training err. 1.14606 Training err. RA 1.56465 Valid. err. 1.71605
2018-02-03 22:09:55,746 training [INFO ] Epoch 59 Batch12240 Training err. 1.16961 Training err. RA 1.56400 Valid. err. 1.64163
2018-02-03 22:09:56,317 training [INFO ] Epoch 59 Batch12260 Training err. 1.18470 Training err. RA 1.56338 Valid. err. 1.65386
2018-02-03 22:09:57,258 training [INFO ] Epoch 60 Batch12280 Training err. 1.16204 Training err. RA 1.56273 Valid. err. 1.67748
2018-02-03 22:09:57,824 training [INFO ] Epoch 60 Batch12300 Training err. 1.15480 Training err. RA 1.56207 Valid. err. 1.69019
2018-02-03 22:09:58,416 training [INFO ] Epoch 60 Batch12320 Training err. 1.19683 Training err. RA 1.56147 Valid. err. 1.66058
2018-02-03 22:09:58,985 training [INFO ] Epoch 60 Batch12340 Training err. 1.22056 Training err. RA 1.56092 Valid. err. 1.66538
2018-02-03 22:09:59,600 training [INFO ] Epoch 60 Batch12360 Training err. 1.16565 Training err. RA 1.56028 Valid. err. 1.70783
2018-02-03 22:10:00,220 training [INFO ] Epoch 60 Batch12380 Training err. 1.16939 Training err. RA 1.55965 Valid. err. 1.66948
2018-02-03 22:10:00,846 training [INFO ] Epoch 60 Batch12400 Training err. 1.22084 Training err. RA 1.55910 Valid. err. 1.68207
2018-02-03 22:10:01,457 training [INFO ] Epoch 60 Batch12420 Training err. 1.15546 Training err. RA 1.55845 Valid. err. 1.66116
2018-02-03 22:10:02,041 training [INFO ] Epoch 60 Batch12440 Training err. 1.14567 Training err. RA 1.55779 Valid. err. 1.69546
2018-02-03 22:10:02,546 training [INFO ] Epoch 60 Batch12460 Training err. 1.16271 Training err. RA 1.55715 Valid. err. 1.70359
2018-02-03 22:10:03,116 training [INFO ] Epoch 60 Batch12480 Training err. 1.16604 Training err. RA 1.55653 Valid. err. 1.69451
2018-02-03 22:10:03,449 __main__ [INFO ] End of training
2018-02-03 22:10:03,735 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 10,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 22:10:04,531 training [INFO ] Epoch  1 Batch   20 Training err. 3.44670 Training err. RA 3.44670 Valid. err. 3.17347
2018-02-03 22:10:05,238 training [INFO ] Epoch  1 Batch   40 Training err. 4.33270 Training err. RA 3.88970 Valid. err. 3.20542
2018-02-03 22:10:05,891 training [INFO ] Epoch  1 Batch   60 Training err. 3.13873 Training err. RA 3.63938 Valid. err. 3.21887
2018-02-03 22:10:06,565 training [INFO ] Epoch  1 Batch   80 Training err. 3.05080 Training err. RA 3.49223 Valid. err. 3.28901
2018-02-03 22:10:07,279 training [INFO ] Epoch  1 Batch  100 Training err. 2.97610 Training err. RA 3.38901 Valid. err. 2.89005
2018-02-03 22:10:08,023 training [INFO ] Epoch  1 Batch  120 Training err. 2.89106 Training err. RA 3.30602 Valid. err. 2.81242
2018-02-03 22:10:08,554 training [INFO ] Epoch  1 Batch  140 Training err. 2.75913 Training err. RA 3.22789 Valid. err. 2.73562
2018-02-03 22:10:09,058 training [INFO ] Epoch  1 Batch  160 Training err. 2.61063 Training err. RA 3.15073 Valid. err. 2.66680
2018-02-03 22:10:09,552 training [INFO ] Epoch  1 Batch  180 Training err. 3.63557 Training err. RA 3.20460 Valid. err. 3.02924
2018-02-03 22:10:10,069 training [INFO ] Epoch  1 Batch  200 Training err. 3.48257 Training err. RA 3.23240 Valid. err. 3.62385
2018-02-03 22:10:11,008 training [INFO ] Epoch  2 Batch  220 Training err. 3.32049 Training err. RA 3.24041 Valid. err. 3.92467
2018-02-03 22:10:11,557 training [INFO ] Epoch  2 Batch  240 Training err. 3.70376 Training err. RA 3.27902 Valid. err. 3.44652
2018-02-03 22:10:12,138 training [INFO ] Epoch  2 Batch  260 Training err. 3.11603 Training err. RA 3.26648 Valid. err. 3.26420
2018-02-03 22:10:12,741 training [INFO ] Epoch  2 Batch  280 Training err. 3.10905 Training err. RA 3.25524 Valid. err. 3.78639
2018-02-03 22:10:13,227 training [INFO ] Epoch  2 Batch  300 Training err. 3.12771 Training err. RA 3.24673 Valid. err. 2.69398
2018-02-03 22:10:13,719 training [INFO ] Epoch  2 Batch  320 Training err. 2.71169 Training err. RA 3.21329 Valid. err. 2.59750
2018-02-03 22:10:14,211 training [INFO ] Epoch  2 Batch  340 Training err. 2.56865 Training err. RA 3.17537 Valid. err. 2.56814
2018-02-03 22:10:14,716 training [INFO ] Epoch  2 Batch  360 Training err. 2.49974 Training err. RA 3.13784 Valid. err. 2.51188
2018-02-03 22:10:15,232 training [INFO ] Epoch  2 Batch  380 Training err. 2.61757 Training err. RA 3.11046 Valid. err. 2.61028
2018-02-03 22:10:15,847 training [INFO ] Epoch  2 Batch  400 Training err. 2.52014 Training err. RA 3.08094 Valid. err. 2.54124
2018-02-03 22:10:16,866 training [INFO ] Epoch  3 Batch  420 Training err. 2.46304 Training err. RA 3.05152 Valid. err. 2.61110
2018-02-03 22:10:17,457 training [INFO ] Epoch  3 Batch  440 Training err. 2.40371 Training err. RA 3.02207 Valid. err. 2.40243
2018-02-03 22:10:18,139 training [INFO ] Epoch  3 Batch  460 Training err. 2.39459 Training err. RA 2.99479 Valid. err. 2.48126
2018-02-03 22:10:18,816 training [INFO ] Epoch  3 Batch  480 Training err. 2.39948 Training err. RA 2.96998 Valid. err. 2.34205
2018-02-03 22:10:19,488 training [INFO ] Epoch  3 Batch  500 Training err. 2.31019 Training err. RA 2.94359 Valid. err. 2.33781
2018-02-03 22:10:20,059 training [INFO ] Epoch  3 Batch  520 Training err. 2.31610 Training err. RA 2.91946 Valid. err. 2.31494
2018-02-03 22:10:20,566 training [INFO ] Epoch  3 Batch  540 Training err. 2.34757 Training err. RA 2.89828 Valid. err. 2.31374
2018-02-03 22:10:21,066 training [INFO ] Epoch  3 Batch  560 Training err. 2.20786 Training err. RA 2.87362 Valid. err. 2.22139
2018-02-03 22:10:21,587 training [INFO ] Epoch  3 Batch  580 Training err. 2.16346 Training err. RA 2.84913 Valid. err. 2.41424
2018-02-03 22:10:22,089 training [INFO ] Epoch  3 Batch  600 Training err. 2.24501 Training err. RA 2.82899 Valid. err. 2.19254
2018-02-03 22:10:22,619 training [INFO ] Epoch  3 Batch  620 Training err. 2.15366 Training err. RA 2.80721 Valid. err. 2.23735
2018-02-03 22:10:23,577 training [INFO ] Epoch  4 Batch  640 Training err. 2.17735 Training err. RA 2.78753 Valid. err. 2.23730
2018-02-03 22:10:24,093 training [INFO ] Epoch  4 Batch  660 Training err. 2.07179 Training err. RA 2.76584 Valid. err. 2.21661
2018-02-03 22:10:24,714 training [INFO ] Epoch  4 Batch  680 Training err. 2.12570 Training err. RA 2.74701 Valid. err. 2.12271
2018-02-03 22:10:25,324 training [INFO ] Epoch  4 Batch  700 Training err. 2.13020 Training err. RA 2.72939 Valid. err. 2.16676
2018-02-03 22:10:25,958 training [INFO ] Epoch  4 Batch  720 Training err. 2.08448 Training err. RA 2.71147 Valid. err. 2.16550
2018-02-03 22:10:26,601 training [INFO ] Epoch  4 Batch  740 Training err. 2.14776 Training err. RA 2.69624 Valid. err. 2.12243
2018-02-03 22:10:27,225 training [INFO ] Epoch  4 Batch  760 Training err. 2.07953 Training err. RA 2.68001 Valid. err. 2.09945
2018-02-03 22:10:27,703 training [INFO ] Epoch  4 Batch  780 Training err. 2.01618 Training err. RA 2.66299 Valid. err. 2.06701
2018-02-03 22:10:28,260 training [INFO ] Epoch  4 Batch  800 Training err. 2.03586 Training err. RA 2.64731 Valid. err. 2.04869
2018-02-03 22:10:28,815 training [INFO ] Epoch  4 Batch  820 Training err. 2.01508 Training err. RA 2.63189 Valid. err. 2.07215
2018-02-03 22:10:29,788 training [INFO ] Epoch  5 Batch  840 Training err. 2.01218 Training err. RA 2.61713 Valid. err. 2.02696
2018-02-03 22:10:30,315 training [INFO ] Epoch  5 Batch  860 Training err. 1.95211 Training err. RA 2.60167 Valid. err. 2.06126
2018-02-03 22:10:30,881 training [INFO ] Epoch  5 Batch  880 Training err. 1.99031 Training err. RA 2.58777 Valid. err. 2.00991
2018-02-03 22:10:31,428 training [INFO ] Epoch  5 Batch  900 Training err. 2.00721 Training err. RA 2.57487 Valid. err. 2.00957
2018-02-03 22:10:31,995 training [INFO ] Epoch  5 Batch  920 Training err. 1.97022 Training err. RA 2.56173 Valid. err. 2.00617
2018-02-03 22:10:32,473 training [INFO ] Epoch  5 Batch  940 Training err. 1.96148 Training err. RA 2.54896 Valid. err. 2.02215
2018-02-03 22:10:33,010 training [INFO ] Epoch  5 Batch  960 Training err. 2.02982 Training err. RA 2.53814 Valid. err. 1.99238
2018-02-03 22:10:33,598 training [INFO ] Epoch  5 Batch  980 Training err. 1.93722 Training err. RA 2.52588 Valid. err. 1.97323
2018-02-03 22:10:34,092 training [INFO ] Epoch  5 Batch 1000 Training err. 1.90476 Training err. RA 2.51345 Valid. err. 1.95607
2018-02-03 22:10:34,653 training [INFO ] Epoch  5 Batch 1020 Training err. 1.93309 Training err. RA 2.50207 Valid. err. 1.97187
2018-02-03 22:10:35,238 training [INFO ] Epoch  5 Batch 1040 Training err. 1.89805 Training err. RA 2.49046 Valid. err. 1.99260
2018-02-03 22:10:36,160 training [INFO ] Epoch  6 Batch 1060 Training err. 1.96691 Training err. RA 2.48058 Valid. err. 1.95965
2018-02-03 22:10:36,639 training [INFO ] Epoch  6 Batch 1080 Training err. 1.84852 Training err. RA 2.46888 Valid. err. 1.96679
2018-02-03 22:10:37,225 training [INFO ] Epoch  6 Batch 1100 Training err. 1.91694 Training err. RA 2.45884 Valid. err. 1.95109
2018-02-03 22:10:37,703 training [INFO ] Epoch  6 Batch 1120 Training err. 1.93278 Training err. RA 2.44945 Valid. err. 1.93648
2018-02-03 22:10:38,183 training [INFO ] Epoch  6 Batch 1140 Training err. 1.88730 Training err. RA 2.43958 Valid. err. 1.91686
2018-02-03 22:10:38,699 training [INFO ] Epoch  6 Batch 1160 Training err. 1.93550 Training err. RA 2.43089 Valid. err. 1.90589
2018-02-03 22:10:39,294 training [INFO ] Epoch  6 Batch 1180 Training err. 1.87932 Training err. RA 2.42154 Valid. err. 1.92578
2018-02-03 22:10:39,934 training [INFO ] Epoch  6 Batch 1200 Training err. 1.83634 Training err. RA 2.41179 Valid. err. 2.04386
2018-02-03 22:10:40,560 training [INFO ] Epoch  6 Batch 1220 Training err. 1.85725 Training err. RA 2.40270 Valid. err. 1.89172
2018-02-03 22:10:41,219 training [INFO ] Epoch  6 Batch 1240 Training err. 1.83471 Training err. RA 2.39354 Valid. err. 1.88855
2018-02-03 22:10:42,239 training [INFO ] Epoch  7 Batch 1260 Training err. 1.87865 Training err. RA 2.38537 Valid. err. 1.91299
2018-02-03 22:10:42,781 training [INFO ] Epoch  7 Batch 1280 Training err. 1.76483 Training err. RA 2.37567 Valid. err. 1.87564
2018-02-03 22:10:43,269 training [INFO ] Epoch  7 Batch 1300 Training err. 1.84459 Training err. RA 2.36750 Valid. err. 1.86306
2018-02-03 22:10:43,765 training [INFO ] Epoch  7 Batch 1320 Training err. 1.88020 Training err. RA 2.36012 Valid. err. 1.86837
2018-02-03 22:10:44,255 training [INFO ] Epoch  7 Batch 1340 Training err. 1.82026 Training err. RA 2.35206 Valid. err. 1.87689
2018-02-03 22:10:44,742 training [INFO ] Epoch  7 Batch 1360 Training err. 1.83775 Training err. RA 2.34450 Valid. err. 1.85162
2018-02-03 22:10:45,227 training [INFO ] Epoch  7 Batch 1380 Training err. 1.85686 Training err. RA 2.33743 Valid. err. 1.84208
2018-02-03 22:10:45,708 training [INFO ] Epoch  7 Batch 1400 Training err. 1.78260 Training err. RA 2.32950 Valid. err. 1.83346
2018-02-03 22:10:46,388 training [INFO ] Epoch  7 Batch 1420 Training err. 1.80800 Training err. RA 2.32216 Valid. err. 1.86498
2018-02-03 22:10:46,995 training [INFO ] Epoch  7 Batch 1440 Training err. 1.77878 Training err. RA 2.31461 Valid. err. 1.82144
2018-02-03 22:10:48,201 training [INFO ] Epoch  8 Batch 1460 Training err. 1.81118 Training err. RA 2.30771 Valid. err. 1.88613
2018-02-03 22:10:48,966 training [INFO ] Epoch  8 Batch 1480 Training err. 1.78248 Training err. RA 2.30062 Valid. err. 1.81438
2018-02-03 22:10:49,594 training [INFO ] Epoch  8 Batch 1500 Training err. 1.74714 Training err. RA 2.29324 Valid. err. 1.82190
2018-02-03 22:10:50,326 training [INFO ] Epoch  8 Batch 1520 Training err. 1.80688 Training err. RA 2.28684 Valid. err. 1.80963
2018-02-03 22:10:51,008 training [INFO ] Epoch  8 Batch 1540 Training err. 1.78750 Training err. RA 2.28035 Valid. err. 1.84922
2018-02-03 22:10:51,577 training [INFO ] Epoch  8 Batch 1560 Training err. 1.78445 Training err. RA 2.27399 Valid. err. 1.81613
2018-02-03 22:10:52,184 training [INFO ] Epoch  8 Batch 1580 Training err. 1.82167 Training err. RA 2.26827 Valid. err. 1.81342
2018-02-03 22:10:52,688 training [INFO ] Epoch  8 Batch 1600 Training err. 1.72806 Training err. RA 2.26152 Valid. err. 1.80805
2018-02-03 22:10:53,193 training [INFO ] Epoch  8 Batch 1620 Training err. 1.73453 Training err. RA 2.25501 Valid. err. 1.79064
2018-02-03 22:10:53,695 training [INFO ] Epoch  8 Batch 1640 Training err. 1.73487 Training err. RA 2.24867 Valid. err. 1.82386
2018-02-03 22:10:54,197 training [INFO ] Epoch  8 Batch 1660 Training err. 1.74508 Training err. RA 2.24260 Valid. err. 1.77720
2018-02-03 22:10:55,180 training [INFO ] Epoch  9 Batch 1680 Training err. 1.75605 Training err. RA 2.23681 Valid. err. 1.78444
2018-02-03 22:10:55,720 training [INFO ] Epoch  9 Batch 1700 Training err. 1.67763 Training err. RA 2.23023 Valid. err. 1.77360
2018-02-03 22:10:56,266 training [INFO ] Epoch  9 Batch 1720 Training err. 1.73654 Training err. RA 2.22449 Valid. err. 1.78601
2018-02-03 22:10:56,900 training [INFO ] Epoch  9 Batch 1740 Training err. 1.77146 Training err. RA 2.21928 Valid. err. 1.78130
2018-02-03 22:10:57,523 training [INFO ] Epoch  9 Batch 1760 Training err. 1.73107 Training err. RA 2.21373 Valid. err. 1.84175
2018-02-03 22:10:58,097 training [INFO ] Epoch  9 Batch 1780 Training err. 1.77123 Training err. RA 2.20876 Valid. err. 1.75331
2018-02-03 22:10:58,709 training [INFO ] Epoch  9 Batch 1800 Training err. 1.72608 Training err. RA 2.20340 Valid. err. 1.77708
2018-02-03 22:10:59,369 training [INFO ] Epoch  9 Batch 1820 Training err. 1.68879 Training err. RA 2.19774 Valid. err. 1.77968
2018-02-03 22:10:59,976 training [INFO ] Epoch  9 Batch 1840 Training err. 1.70985 Training err. RA 2.19244 Valid. err. 1.73839
2018-02-03 22:11:00,492 training [INFO ] Epoch  9 Batch 1860 Training err. 1.70004 Training err. RA 2.18715 Valid. err. 1.77605
2018-02-03 22:11:01,533 training [INFO ] Epoch 10 Batch 1880 Training err. 1.68845 Training err. RA 2.18184 Valid. err. 1.78283
2018-02-03 22:11:02,062 training [INFO ] Epoch 10 Batch 1900 Training err. 1.65649 Training err. RA 2.17631 Valid. err. 1.75593
2018-02-03 22:11:02,665 training [INFO ] Epoch 10 Batch 1920 Training err. 1.69777 Training err. RA 2.17133 Valid. err. 1.74415
2018-02-03 22:11:03,165 training [INFO ] Epoch 10 Batch 1940 Training err. 1.72851 Training err. RA 2.16676 Valid. err. 1.77186
2018-02-03 22:11:03,798 training [INFO ] Epoch 10 Batch 1960 Training err. 1.68648 Training err. RA 2.16186 Valid. err. 1.79120
2018-02-03 22:11:04,389 training [INFO ] Epoch 10 Batch 1980 Training err. 1.69570 Training err. RA 2.15715 Valid. err. 1.76327
2018-02-03 22:11:05,093 training [INFO ] Epoch 10 Batch 2000 Training err. 1.72746 Training err. RA 2.15285 Valid. err. 1.72301
2018-02-03 22:11:05,770 training [INFO ] Epoch 10 Batch 2020 Training err. 1.66186 Training err. RA 2.14799 Valid. err. 1.73278
2018-02-03 22:11:06,437 training [INFO ] Epoch 10 Batch 2040 Training err. 1.65561 Training err. RA 2.14317 Valid. err. 1.71857
2018-02-03 22:11:07,097 training [INFO ] Epoch 10 Batch 2060 Training err. 1.67258 Training err. RA 2.13860 Valid. err. 1.71400
2018-02-03 22:11:07,766 training [INFO ] Epoch 10 Batch 2080 Training err. 1.65656 Training err. RA 2.13396 Valid. err. 1.74597
2018-02-03 22:11:08,895 training [INFO ] Epoch 11 Batch 2100 Training err. 1.66163 Training err. RA 2.12946 Valid. err. 1.71949
2018-02-03 22:11:09,542 training [INFO ] Epoch 11 Batch 2120 Training err. 1.60470 Training err. RA 2.12451 Valid. err. 1.73901
2018-02-03 22:11:10,253 training [INFO ] Epoch 11 Batch 2140 Training err. 1.67923 Training err. RA 2.12035 Valid. err. 1.71655
2018-02-03 22:11:10,980 training [INFO ] Epoch 11 Batch 2160 Training err. 1.70513 Training err. RA 2.11651 Valid. err. 1.71019
2018-02-03 22:11:11,717 training [INFO ] Epoch 11 Batch 2180 Training err. 1.65565 Training err. RA 2.11228 Valid. err. 1.69737
2018-02-03 22:11:12,461 training [INFO ] Epoch 11 Batch 2200 Training err. 1.69070 Training err. RA 2.10845 Valid. err. 1.69956
2018-02-03 22:11:13,201 training [INFO ] Epoch 11 Batch 2220 Training err. 1.65407 Training err. RA 2.10435 Valid. err. 1.69903
2018-02-03 22:11:13,943 training [INFO ] Epoch 11 Batch 2240 Training err. 1.61952 Training err. RA 2.10002 Valid. err. 1.71895
2018-02-03 22:11:14,631 training [INFO ] Epoch 11 Batch 2260 Training err. 1.63384 Training err. RA 2.09590 Valid. err. 1.70739
2018-02-03 22:11:15,349 training [INFO ] Epoch 11 Batch 2280 Training err. 1.64891 Training err. RA 2.09198 Valid. err. 1.68671
2018-02-03 22:11:16,503 training [INFO ] Epoch 12 Batch 2300 Training err. 1.62503 Training err. RA 2.08792 Valid. err. 1.68002
2018-02-03 22:11:17,187 training [INFO ] Epoch 12 Batch 2320 Training err. 1.57846 Training err. RA 2.08352 Valid. err. 1.69768
2018-02-03 22:11:17,893 training [INFO ] Epoch 12 Batch 2340 Training err. 1.65072 Training err. RA 2.07983 Valid. err. 1.69003
2018-02-03 22:11:18,569 training [INFO ] Epoch 12 Batch 2360 Training err. 1.67486 Training err. RA 2.07639 Valid. err. 1.69930
2018-02-03 22:11:19,257 training [INFO ] Epoch 12 Batch 2380 Training err. 1.62934 Training err. RA 2.07264 Valid. err. 1.71423
2018-02-03 22:11:19,914 training [INFO ] Epoch 12 Batch 2400 Training err. 1.63705 Training err. RA 2.06901 Valid. err. 1.68941
2018-02-03 22:11:20,587 training [INFO ] Epoch 12 Batch 2420 Training err. 1.66621 Training err. RA 2.06568 Valid. err. 1.68124
2018-02-03 22:11:21,276 training [INFO ] Epoch 12 Batch 2440 Training err. 1.59619 Training err. RA 2.06183 Valid. err. 1.68075
2018-02-03 22:11:21,940 training [INFO ] Epoch 12 Batch 2460 Training err. 1.61537 Training err. RA 2.05820 Valid. err. 1.71075
2018-02-03 22:11:22,612 training [INFO ] Epoch 12 Batch 2480 Training err. 1.60470 Training err. RA 2.05454 Valid. err. 1.68264
2018-02-03 22:11:23,711 training [INFO ] Epoch 13 Batch 2500 Training err. 1.60279 Training err. RA 2.05093 Valid. err. 1.65516
2018-02-03 22:11:24,375 training [INFO ] Epoch 13 Batch 2520 Training err. 1.58590 Training err. RA 2.04724 Valid. err. 1.66458
2018-02-03 22:11:25,045 training [INFO ] Epoch 13 Batch 2540 Training err. 1.58578 Training err. RA 2.04360 Valid. err. 1.66338
2018-02-03 22:11:25,712 training [INFO ] Epoch 13 Batch 2560 Training err. 1.63445 Training err. RA 2.04041 Valid. err. 1.68590
2018-02-03 22:11:26,352 training [INFO ] Epoch 13 Batch 2580 Training err. 1.62652 Training err. RA 2.03720 Valid. err. 1.69873
2018-02-03 22:11:27,002 training [INFO ] Epoch 13 Batch 2600 Training err. 1.61560 Training err. RA 2.03396 Valid. err. 1.67651
2018-02-03 22:11:27,710 training [INFO ] Epoch 13 Batch 2620 Training err. 1.65827 Training err. RA 2.03109 Valid. err. 1.68799
2018-02-03 22:11:28,371 training [INFO ] Epoch 13 Batch 2640 Training err. 1.57694 Training err. RA 2.02765 Valid. err. 1.67381
2018-02-03 22:11:29,034 training [INFO ] Epoch 13 Batch 2660 Training err. 1.57817 Training err. RA 2.02427 Valid. err. 1.65841
2018-02-03 22:11:29,706 training [INFO ] Epoch 13 Batch 2680 Training err. 1.56726 Training err. RA 2.02086 Valid. err. 1.67397
2018-02-03 22:11:30,439 training [INFO ] Epoch 13 Batch 2700 Training err. 1.60327 Training err. RA 2.01776 Valid. err. 1.64677
2018-02-03 22:11:31,742 training [INFO ] Epoch 14 Batch 2720 Training err. 1.57205 Training err. RA 2.01449 Valid. err. 1.66090
2018-02-03 22:11:32,317 training [INFO ] Epoch 14 Batch 2740 Training err. 1.53457 Training err. RA 2.01098 Valid. err. 1.65815
2018-02-03 22:11:32,952 training [INFO ] Epoch 14 Batch 2760 Training err. 1.60157 Training err. RA 2.00802 Valid. err. 1.66783
2018-02-03 22:11:33,618 training [INFO ] Epoch 14 Batch 2780 Training err. 1.62767 Training err. RA 2.00528 Valid. err. 1.66224
2018-02-03 22:11:34,241 training [INFO ] Epoch 14 Batch 2800 Training err. 1.58488 Training err. RA 2.00228 Valid. err. 1.68701
2018-02-03 22:11:34,754 training [INFO ] Epoch 14 Batch 2820 Training err. 1.62443 Training err. RA 1.99960 Valid. err. 1.65898
2018-02-03 22:11:35,298 training [INFO ] Epoch 14 Batch 2840 Training err. 1.59484 Training err. RA 1.99675 Valid. err. 1.66445
2018-02-03 22:11:35,847 training [INFO ] Epoch 14 Batch 2860 Training err. 1.54683 Training err. RA 1.99360 Valid. err. 1.66093
2018-02-03 22:11:36,372 training [INFO ] Epoch 14 Batch 2880 Training err. 1.56670 Training err. RA 1.99064 Valid. err. 1.64937
2018-02-03 22:11:36,868 training [INFO ] Epoch 14 Batch 2900 Training err. 1.56992 Training err. RA 1.98774 Valid. err. 1.65378
2018-02-03 22:11:37,843 training [INFO ] Epoch 15 Batch 2920 Training err. 1.54968 Training err. RA 1.98474 Valid. err. 1.63255
2018-02-03 22:11:38,366 training [INFO ] Epoch 15 Batch 2940 Training err. 1.52983 Training err. RA 1.98164 Valid. err. 1.65343
2018-02-03 22:11:38,872 training [INFO ] Epoch 15 Batch 2960 Training err. 1.57192 Training err. RA 1.97887 Valid. err. 1.64506
2018-02-03 22:11:39,412 training [INFO ] Epoch 15 Batch 2980 Training err. 1.60835 Training err. RA 1.97639 Valid. err. 1.65052
2018-02-03 22:11:39,931 training [INFO ] Epoch 15 Batch 3000 Training err. 1.56261 Training err. RA 1.97363 Valid. err. 1.66954
2018-02-03 22:11:40,464 training [INFO ] Epoch 15 Batch 3020 Training err. 1.56655 Training err. RA 1.97093 Valid. err. 1.66570
2018-02-03 22:11:40,991 training [INFO ] Epoch 15 Batch 3040 Training err. 1.60941 Training err. RA 1.96855 Valid. err. 1.63114
2018-02-03 22:11:41,501 training [INFO ] Epoch 15 Batch 3060 Training err. 1.54089 Training err. RA 1.96576 Valid. err. 1.64521
2018-02-03 22:11:41,993 training [INFO ] Epoch 15 Batch 3080 Training err. 1.53433 Training err. RA 1.96296 Valid. err. 1.63295
2018-02-03 22:11:42,585 training [INFO ] Epoch 15 Batch 3100 Training err. 1.53755 Training err. RA 1.96021 Valid. err. 1.62554
2018-02-03 22:11:43,126 training [INFO ] Epoch 15 Batch 3120 Training err. 1.54777 Training err. RA 1.95757 Valid. err. 1.64512
2018-02-03 22:11:43,999 training [INFO ] Epoch 16 Batch 3140 Training err. 1.54199 Training err. RA 1.95492 Valid. err. 1.61292
2018-02-03 22:11:44,495 training [INFO ] Epoch 16 Batch 3160 Training err. 1.49298 Training err. RA 1.95200 Valid. err. 1.67084
2018-02-03 22:11:45,015 training [INFO ] Epoch 16 Batch 3180 Training err. 1.57370 Training err. RA 1.94962 Valid. err. 1.65177
2018-02-03 22:11:45,522 training [INFO ] Epoch 16 Batch 3200 Training err. 1.59577 Training err. RA 1.94741 Valid. err. 1.63694
2018-02-03 22:11:46,033 training [INFO ] Epoch 16 Batch 3220 Training err. 1.53116 Training err. RA 1.94482 Valid. err. 1.63888
2018-02-03 22:11:46,530 training [INFO ] Epoch 16 Batch 3240 Training err. 1.58929 Training err. RA 1.94263 Valid. err. 1.62942
2018-02-03 22:11:47,009 training [INFO ] Epoch 16 Batch 3260 Training err. 1.55224 Training err. RA 1.94023 Valid. err. 1.63149
2018-02-03 22:11:47,541 training [INFO ] Epoch 16 Batch 3280 Training err. 1.50933 Training err. RA 1.93760 Valid. err. 1.64181
2018-02-03 22:11:48,069 training [INFO ] Epoch 16 Batch 3300 Training err. 1.52174 Training err. RA 1.93508 Valid. err. 1.62164
2018-02-03 22:11:48,592 training [INFO ] Epoch 16 Batch 3320 Training err. 1.53933 Training err. RA 1.93270 Valid. err. 1.60913
2018-02-03 22:11:49,449 training [INFO ] Epoch 17 Batch 3340 Training err. 1.52388 Training err. RA 1.93025 Valid. err. 1.60775
2018-02-03 22:11:49,955 training [INFO ] Epoch 17 Batch 3360 Training err. 1.48339 Training err. RA 1.92759 Valid. err. 1.63415
2018-02-03 22:11:50,488 training [INFO ] Epoch 17 Batch 3380 Training err. 1.55375 Training err. RA 1.92538 Valid. err. 1.62972
2018-02-03 22:11:51,019 training [INFO ] Epoch 17 Batch 3400 Training err. 1.57666 Training err. RA 1.92333 Valid. err. 1.64795
2018-02-03 22:11:51,530 training [INFO ] Epoch 17 Batch 3420 Training err. 1.52178 Training err. RA 1.92098 Valid. err. 1.64457
2018-02-03 22:11:52,015 training [INFO ] Epoch 17 Batch 3440 Training err. 1.53652 Training err. RA 1.91874 Valid. err. 1.61939
2018-02-03 22:11:52,509 training [INFO ] Epoch 17 Batch 3460 Training err. 1.57259 Training err. RA 1.91674 Valid. err. 1.62574
2018-02-03 22:11:53,036 training [INFO ] Epoch 17 Batch 3480 Training err. 1.49551 Training err. RA 1.91432 Valid. err. 1.63249
2018-02-03 22:11:53,563 training [INFO ] Epoch 17 Batch 3500 Training err. 1.51922 Training err. RA 1.91207 Valid. err. 1.63042
2018-02-03 22:11:54,220 training [INFO ] Epoch 17 Batch 3520 Training err. 1.49993 Training err. RA 1.90972 Valid. err. 1.61601
2018-02-03 22:11:55,487 training [INFO ] Epoch 18 Batch 3540 Training err. 1.50887 Training err. RA 1.90746 Valid. err. 1.60839
2018-02-03 22:11:56,150 training [INFO ] Epoch 18 Batch 3560 Training err. 1.49436 Training err. RA 1.90514 Valid. err. 1.61340
2018-02-03 22:11:56,816 training [INFO ] Epoch 18 Batch 3580 Training err. 1.49728 Training err. RA 1.90286 Valid. err. 1.60498
2018-02-03 22:11:57,419 training [INFO ] Epoch 18 Batch 3600 Training err. 1.54862 Training err. RA 1.90089 Valid. err. 1.62695
2018-02-03 22:11:58,022 training [INFO ] Epoch 18 Batch 3620 Training err. 1.53709 Training err. RA 1.89888 Valid. err. 1.64437
2018-02-03 22:11:58,528 training [INFO ] Epoch 18 Batch 3640 Training err. 1.51117 Training err. RA 1.89675 Valid. err. 1.61812
2018-02-03 22:11:59,029 training [INFO ] Epoch 18 Batch 3660 Training err. 1.57323 Training err. RA 1.89498 Valid. err. 1.64454
2018-02-03 22:11:59,528 training [INFO ] Epoch 18 Batch 3680 Training err. 1.48376 Training err. RA 1.89275 Valid. err. 1.63001
2018-02-03 22:12:00,028 training [INFO ] Epoch 18 Batch 3700 Training err. 1.49200 Training err. RA 1.89058 Valid. err. 1.63255
2018-02-03 22:12:00,530 training [INFO ] Epoch 18 Batch 3720 Training err. 1.47130 Training err. RA 1.88833 Valid. err. 1.60979
2018-02-03 22:12:01,027 training [INFO ] Epoch 18 Batch 3740 Training err. 1.52012 Training err. RA 1.88636 Valid. err. 1.59752
2018-02-03 22:12:01,958 training [INFO ] Epoch 19 Batch 3760 Training err. 1.48200 Training err. RA 1.88421 Valid. err. 1.60892
2018-02-03 22:12:02,437 training [INFO ] Epoch 19 Batch 3780 Training err. 1.45746 Training err. RA 1.88195 Valid. err. 1.61480
2018-02-03 22:12:02,921 training [INFO ] Epoch 19 Batch 3800 Training err. 1.52520 Training err. RA 1.88007 Valid. err. 1.60934
2018-02-03 22:12:03,404 training [INFO ] Epoch 19 Batch 3820 Training err. 1.54334 Training err. RA 1.87831 Valid. err. 1.61586
2018-02-03 22:12:03,910 training [INFO ] Epoch 19 Batch 3840 Training err. 1.49127 Training err. RA 1.87629 Valid. err. 1.65004
2018-02-03 22:12:04,473 training [INFO ] Epoch 19 Batch 3860 Training err. 1.54308 Training err. RA 1.87457 Valid. err. 1.66698
2018-02-03 22:12:04,967 training [INFO ] Epoch 19 Batch 3880 Training err. 1.51361 Training err. RA 1.87271 Valid. err. 1.62435
2018-02-03 22:12:05,495 training [INFO ] Epoch 19 Batch 3900 Training err. 1.46503 Training err. RA 1.87062 Valid. err. 1.63047
2018-02-03 22:12:06,017 training [INFO ] Epoch 19 Batch 3920 Training err. 1.48324 Training err. RA 1.86864 Valid. err. 1.61106
2018-02-03 22:12:06,534 training [INFO ] Epoch 19 Batch 3940 Training err. 1.48877 Training err. RA 1.86671 Valid. err. 1.62591
2018-02-03 22:12:07,447 training [INFO ] Epoch 20 Batch 3960 Training err. 1.47376 Training err. RA 1.86473 Valid. err. 1.57957
2018-02-03 22:12:08,080 training [INFO ] Epoch 20 Batch 3980 Training err. 1.45734 Training err. RA 1.86268 Valid. err. 1.60634
2018-02-03 22:12:08,665 training [INFO ] Epoch 20 Batch 4000 Training err. 1.49715 Training err. RA 1.86085 Valid. err. 1.59739
2018-02-03 22:12:09,297 training [INFO ] Epoch 20 Batch 4020 Training err. 1.52986 Training err. RA 1.85921 Valid. err. 1.60282
2018-02-03 22:12:09,861 training [INFO ] Epoch 20 Batch 4040 Training err. 1.48502 Training err. RA 1.85735 Valid. err. 1.62661
2018-02-03 22:12:10,347 training [INFO ] Epoch 20 Batch 4060 Training err. 1.48162 Training err. RA 1.85550 Valid. err. 1.62371
2018-02-03 22:12:10,832 training [INFO ] Epoch 20 Batch 4080 Training err. 1.53623 Training err. RA 1.85394 Valid. err. 1.59601
2018-02-03 22:12:11,318 training [INFO ] Epoch 20 Batch 4100 Training err. 1.46367 Training err. RA 1.85203 Valid. err. 1.62682
2018-02-03 22:12:11,831 training [INFO ] Epoch 20 Batch 4120 Training err. 1.45695 Training err. RA 1.85012 Valid. err. 1.59772
2018-02-03 22:12:12,314 training [INFO ] Epoch 20 Batch 4140 Training err. 1.45926 Training err. RA 1.84823 Valid. err. 1.59528
2018-02-03 22:12:12,799 training [INFO ] Epoch 20 Batch 4160 Training err. 1.47940 Training err. RA 1.84645 Valid. err. 1.60484
2018-02-03 22:12:13,660 training [INFO ] Epoch 21 Batch 4180 Training err. 1.46769 Training err. RA 1.84464 Valid. err. 1.57819
2018-02-03 22:12:14,219 training [INFO ] Epoch 21 Batch 4200 Training err. 1.42407 Training err. RA 1.84264 Valid. err. 1.62776
2018-02-03 22:12:14,795 training [INFO ] Epoch 21 Batch 4220 Training err. 1.50711 Training err. RA 1.84105 Valid. err. 1.62221
2018-02-03 22:12:15,367 training [INFO ] Epoch 21 Batch 4240 Training err. 1.52243 Training err. RA 1.83955 Valid. err. 1.61175
2018-02-03 22:12:15,929 training [INFO ] Epoch 21 Batch 4260 Training err. 1.44942 Training err. RA 1.83771 Valid. err. 1.60668
2018-02-03 22:12:16,497 training [INFO ] Epoch 21 Batch 4280 Training err. 1.52699 Training err. RA 1.83626 Valid. err. 1.59529
2018-02-03 22:12:17,070 training [INFO ] Epoch 21 Batch 4300 Training err. 1.48192 Training err. RA 1.83461 Valid. err. 1.59787
2018-02-03 22:12:17,640 training [INFO ] Epoch 21 Batch 4320 Training err. 1.44164 Training err. RA 1.83279 Valid. err. 1.62779
2018-02-03 22:12:18,201 training [INFO ] Epoch 21 Batch 4340 Training err. 1.44383 Training err. RA 1.83100 Valid. err. 1.58404
2018-02-03 22:12:18,700 training [INFO ] Epoch 21 Batch 4360 Training err. 1.46984 Training err. RA 1.82935 Valid. err. 1.57791
2018-02-03 22:12:19,632 training [INFO ] Epoch 22 Batch 4380 Training err. 1.45348 Training err. RA 1.82763 Valid. err. 1.57296
2018-02-03 22:12:20,157 training [INFO ] Epoch 22 Batch 4400 Training err. 1.42012 Training err. RA 1.82578 Valid. err. 1.60222
2018-02-03 22:12:20,667 training [INFO ] Epoch 22 Batch 4420 Training err. 1.48997 Training err. RA 1.82426 Valid. err. 1.58631
2018-02-03 22:12:21,205 training [INFO ] Epoch 22 Batch 4440 Training err. 1.50555 Training err. RA 1.82282 Valid. err. 1.61389
2018-02-03 22:12:21,763 training [INFO ] Epoch 22 Batch 4460 Training err. 1.45253 Training err. RA 1.82116 Valid. err. 1.60792
2018-02-03 22:12:22,293 training [INFO ] Epoch 22 Batch 4480 Training err. 1.47027 Training err. RA 1.81959 Valid. err. 1.59169
2018-02-03 22:12:22,794 training [INFO ] Epoch 22 Batch 4500 Training err. 1.51386 Training err. RA 1.81824 Valid. err. 1.59362
2018-02-03 22:12:23,278 training [INFO ] Epoch 22 Batch 4520 Training err. 1.43395 Training err. RA 1.81654 Valid. err. 1.60272
2018-02-03 22:12:23,763 training [INFO ] Epoch 22 Batch 4540 Training err. 1.44738 Training err. RA 1.81491 Valid. err. 1.63575
2018-02-03 22:12:24,289 training [INFO ] Epoch 22 Batch 4560 Training err. 1.43742 Training err. RA 1.81325 Valid. err. 1.60096
2018-02-03 22:12:25,219 training [INFO ] Epoch 23 Batch 4580 Training err. 1.44808 Training err. RA 1.81166 Valid. err. 1.57549
2018-02-03 22:12:25,703 training [INFO ] Epoch 23 Batch 4600 Training err. 1.43001 Training err. RA 1.81000 Valid. err. 1.59784
2018-02-03 22:12:26,194 training [INFO ] Epoch 23 Batch 4620 Training err. 1.43516 Training err. RA 1.80838 Valid. err. 1.58024
2018-02-03 22:12:26,719 training [INFO ] Epoch 23 Batch 4640 Training err. 1.48429 Training err. RA 1.80698 Valid. err. 1.62678
2018-02-03 22:12:27,243 training [INFO ] Epoch 23 Batch 4660 Training err. 1.47556 Training err. RA 1.80556 Valid. err. 1.62565
2018-02-03 22:12:27,743 training [INFO ] Epoch 23 Batch 4680 Training err. 1.44425 Training err. RA 1.80401 Valid. err. 1.58484
2018-02-03 22:12:28,226 training [INFO ] Epoch 23 Batch 4700 Training err. 1.52139 Training err. RA 1.80281 Valid. err. 1.61949
2018-02-03 22:12:28,707 training [INFO ] Epoch 23 Batch 4720 Training err. 1.42587 Training err. RA 1.80121 Valid. err. 1.59878
2018-02-03 22:12:29,195 training [INFO ] Epoch 23 Batch 4740 Training err. 1.42377 Training err. RA 1.79962 Valid. err. 1.61616
2018-02-03 22:12:29,717 training [INFO ] Epoch 23 Batch 4760 Training err. 1.40877 Training err. RA 1.79798 Valid. err. 1.59600
2018-02-03 22:12:30,231 training [INFO ] Epoch 23 Batch 4780 Training err. 1.46258 Training err. RA 1.79658 Valid. err. 1.57352
2018-02-03 22:12:31,121 training [INFO ] Epoch 24 Batch 4800 Training err. 1.42182 Training err. RA 1.79501 Valid. err. 1.58631
2018-02-03 22:12:31,617 training [INFO ] Epoch 24 Batch 4820 Training err. 1.40523 Training err. RA 1.79340 Valid. err. 1.60052
2018-02-03 22:12:32,140 training [INFO ] Epoch 24 Batch 4840 Training err. 1.46519 Training err. RA 1.79204 Valid. err. 1.59770
2018-02-03 22:12:32,662 training [INFO ] Epoch 24 Batch 4860 Training err. 1.48483 Training err. RA 1.79078 Valid. err. 1.56636
2018-02-03 22:12:33,244 training [INFO ] Epoch 24 Batch 4880 Training err. 1.42911 Training err. RA 1.78929 Valid. err. 1.63584
2018-02-03 22:12:33,890 training [INFO ] Epoch 24 Batch 4900 Training err. 1.48506 Training err. RA 1.78805 Valid. err. 1.61894
2018-02-03 22:12:34,571 training [INFO ] Epoch 24 Batch 4920 Training err. 1.45978 Training err. RA 1.78672 Valid. err. 1.59594
2018-02-03 22:12:35,274 training [INFO ] Epoch 24 Batch 4940 Training err. 1.40939 Training err. RA 1.78519 Valid. err. 1.61409
2018-02-03 22:12:35,941 training [INFO ] Epoch 24 Batch 4960 Training err. 1.42382 Training err. RA 1.78373 Valid. err. 1.59118
2018-02-03 22:12:36,623 training [INFO ] Epoch 24 Batch 4980 Training err. 1.42634 Training err. RA 1.78230 Valid. err. 1.59481
2018-02-03 22:12:37,747 training [INFO ] Epoch 25 Batch 5000 Training err. 1.41386 Training err. RA 1.78082 Valid. err. 1.56453
2018-02-03 22:12:38,406 training [INFO ] Epoch 25 Batch 5020 Training err. 1.40605 Training err. RA 1.77933 Valid. err. 1.58644
2018-02-03 22:12:39,062 training [INFO ] Epoch 25 Batch 5040 Training err. 1.44469 Training err. RA 1.77800 Valid. err. 1.57911
2018-02-03 22:12:39,735 training [INFO ] Epoch 25 Batch 5060 Training err. 1.47505 Training err. RA 1.77681 Valid. err. 1.57207
2018-02-03 22:12:40,412 training [INFO ] Epoch 25 Batch 5080 Training err. 1.42606 Training err. RA 1.77542 Valid. err. 1.60631
2018-02-03 22:12:41,074 training [INFO ] Epoch 25 Batch 5100 Training err. 1.42463 Training err. RA 1.77405 Valid. err. 1.59820
2018-02-03 22:12:41,783 training [INFO ] Epoch 25 Batch 5120 Training err. 1.48973 Training err. RA 1.77294 Valid. err. 1.56370
2018-02-03 22:12:42,455 training [INFO ] Epoch 25 Batch 5140 Training err. 1.41196 Training err. RA 1.77153 Valid. err. 1.59765
2018-02-03 22:12:43,054 training [INFO ] Epoch 25 Batch 5160 Training err. 1.39444 Training err. RA 1.77007 Valid. err. 1.59047
2018-02-03 22:12:43,682 training [INFO ] Epoch 25 Batch 5180 Training err. 1.40259 Training err. RA 1.76865 Valid. err. 1.57356
2018-02-03 22:12:44,296 training [INFO ] Epoch 25 Batch 5200 Training err. 1.42369 Training err. RA 1.76733 Valid. err. 1.56572
2018-02-03 22:12:45,445 training [INFO ] Epoch 26 Batch 5220 Training err. 1.41359 Training err. RA 1.76597 Valid. err. 1.56461
2018-02-03 22:12:46,189 training [INFO ] Epoch 26 Batch 5240 Training err. 1.37988 Training err. RA 1.76450 Valid. err. 1.59016
2018-02-03 22:12:46,907 training [INFO ] Epoch 26 Batch 5260 Training err. 1.45460 Training err. RA 1.76332 Valid. err. 1.59761
2018-02-03 22:12:47,630 training [INFO ] Epoch 26 Batch 5280 Training err. 1.46998 Training err. RA 1.76221 Valid. err. 1.57939
2018-02-03 22:12:48,351 training [INFO ] Epoch 26 Batch 5300 Training err. 1.39757 Training err. RA 1.76083 Valid. err. 1.60277
2018-02-03 22:12:49,074 training [INFO ] Epoch 26 Batch 5320 Training err. 1.47178 Training err. RA 1.75975 Valid. err. 1.57848
2018-02-03 22:12:49,818 training [INFO ] Epoch 26 Batch 5340 Training err. 1.43095 Training err. RA 1.75851 Valid. err. 1.58204
2018-02-03 22:12:50,439 training [INFO ] Epoch 26 Batch 5360 Training err. 1.38883 Training err. RA 1.75713 Valid. err. 1.59640
2018-02-03 22:12:51,105 training [INFO ] Epoch 26 Batch 5380 Training err. 1.39615 Training err. RA 1.75579 Valid. err. 1.56642
2018-02-03 22:12:51,595 training [INFO ] Epoch 26 Batch 5400 Training err. 1.42333 Training err. RA 1.75456 Valid. err. 1.55433
2018-02-03 22:12:52,619 training [INFO ] Epoch 27 Batch 5420 Training err. 1.39626 Training err. RA 1.75324 Valid. err. 1.55407
2018-02-03 22:12:53,160 training [INFO ] Epoch 27 Batch 5440 Training err. 1.37711 Training err. RA 1.75186 Valid. err. 1.58700
2018-02-03 22:12:53,792 training [INFO ] Epoch 27 Batch 5460 Training err. 1.43696 Training err. RA 1.75070 Valid. err. 1.57086
2018-02-03 22:12:54,370 training [INFO ] Epoch 27 Batch 5480 Training err. 1.45359 Training err. RA 1.74962 Valid. err. 1.59825
2018-02-03 22:12:54,987 training [INFO ] Epoch 27 Batch 5500 Training err. 1.39764 Training err. RA 1.74834 Valid. err. 1.58100
2018-02-03 22:12:55,526 training [INFO ] Epoch 27 Batch 5520 Training err. 1.42203 Training err. RA 1.74716 Valid. err. 1.56314
2018-02-03 22:12:56,069 training [INFO ] Epoch 27 Batch 5540 Training err. 1.46672 Training err. RA 1.74614 Valid. err. 1.56315
2018-02-03 22:12:56,557 training [INFO ] Epoch 27 Batch 5560 Training err. 1.38142 Training err. RA 1.74483 Valid. err. 1.58459
2018-02-03 22:12:57,065 training [INFO ] Epoch 27 Batch 5580 Training err. 1.39373 Training err. RA 1.74357 Valid. err. 1.60751
2018-02-03 22:12:57,611 training [INFO ] Epoch 27 Batch 5600 Training err. 1.38713 Training err. RA 1.74230 Valid. err. 1.57011
2018-02-03 22:12:58,553 training [INFO ] Epoch 28 Batch 5620 Training err. 1.40008 Training err. RA 1.74108 Valid. err. 1.56955
2018-02-03 22:12:59,139 training [INFO ] Epoch 28 Batch 5640 Training err. 1.38234 Training err. RA 1.73981 Valid. err. 1.57335
2018-02-03 22:12:59,805 training [INFO ] Epoch 28 Batch 5660 Training err. 1.39597 Training err. RA 1.73860 Valid. err. 1.57320
2018-02-03 22:13:00,447 training [INFO ] Epoch 28 Batch 5680 Training err. 1.43914 Training err. RA 1.73754 Valid. err. 1.58858
2018-02-03 22:13:00,944 training [INFO ] Epoch 28 Batch 5700 Training err. 1.42742 Training err. RA 1.73645 Valid. err. 1.61606
2018-02-03 22:13:01,438 training [INFO ] Epoch 28 Batch 5720 Training err. 1.39602 Training err. RA 1.73526 Valid. err. 1.57111
2018-02-03 22:13:01,927 training [INFO ] Epoch 28 Batch 5740 Training err. 1.46697 Training err. RA 1.73433 Valid. err. 1.59075
2018-02-03 22:13:02,413 training [INFO ] Epoch 28 Batch 5760 Training err. 1.37575 Training err. RA 1.73308 Valid. err. 1.59133
2018-02-03 22:13:02,905 training [INFO ] Epoch 28 Batch 5780 Training err. 1.37425 Training err. RA 1.73184 Valid. err. 1.59292
2018-02-03 22:13:03,395 training [INFO ] Epoch 28 Batch 5800 Training err. 1.35791 Training err. RA 1.73055 Valid. err. 1.57113
2018-02-03 22:13:03,880 training [INFO ] Epoch 28 Batch 5820 Training err. 1.41300 Training err. RA 1.72946 Valid. err. 1.55907
2018-02-03 22:13:04,831 training [INFO ] Epoch 29 Batch 5840 Training err. 1.37182 Training err. RA 1.72824 Valid. err. 1.56682
2018-02-03 22:13:05,318 training [INFO ] Epoch 29 Batch 5860 Training err. 1.37166 Training err. RA 1.72702 Valid. err. 1.59536
2018-02-03 22:13:05,803 training [INFO ] Epoch 29 Batch 5880 Training err. 1.42565 Training err. RA 1.72599 Valid. err. 1.57854
2018-02-03 22:13:06,292 training [INFO ] Epoch 29 Batch 5900 Training err. 1.43664 Training err. RA 1.72501 Valid. err. 1.56810
2018-02-03 22:13:06,781 training [INFO ] Epoch 29 Batch 5920 Training err. 1.38496 Training err. RA 1.72386 Valid. err. 1.60116
2018-02-03 22:13:07,268 training [INFO ] Epoch 29 Batch 5940 Training err. 1.43300 Training err. RA 1.72288 Valid. err. 1.58878
2018-02-03 22:13:07,753 training [INFO ] Epoch 29 Batch 5960 Training err. 1.41386 Training err. RA 1.72185 Valid. err. 1.57407
2018-02-03 22:13:08,235 training [INFO ] Epoch 29 Batch 5980 Training err. 1.35487 Training err. RA 1.72062 Valid. err. 1.59350
2018-02-03 22:13:08,726 training [INFO ] Epoch 29 Batch 6000 Training err. 1.38051 Training err. RA 1.71949 Valid. err. 1.57865
2018-02-03 22:13:09,210 training [INFO ] Epoch 29 Batch 6020 Training err. 1.38629 Training err. RA 1.71838 Valid. err. 1.59073
2018-02-03 22:13:10,076 training [INFO ] Epoch 30 Batch 6040 Training err. 1.36560 Training err. RA 1.71721 Valid. err. 1.54926
2018-02-03 22:13:10,608 training [INFO ] Epoch 30 Batch 6060 Training err. 1.36718 Training err. RA 1.71606 Valid. err. 1.58215
2018-02-03 22:13:11,173 training [INFO ] Epoch 30 Batch 6080 Training err. 1.40464 Training err. RA 1.71503 Valid. err. 1.56481
2018-02-03 22:13:11,719 training [INFO ] Epoch 30 Batch 6100 Training err. 1.43198 Training err. RA 1.71410 Valid. err. 1.55670
2018-02-03 22:13:12,246 training [INFO ] Epoch 30 Batch 6120 Training err. 1.38573 Training err. RA 1.71303 Valid. err. 1.59592
2018-02-03 22:13:12,734 training [INFO ] Epoch 30 Batch 6140 Training err. 1.38054 Training err. RA 1.71195 Valid. err. 1.57768
2018-02-03 22:13:13,224 training [INFO ] Epoch 30 Batch 6160 Training err. 1.43856 Training err. RA 1.71106 Valid. err. 1.55958
2018-02-03 22:13:13,720 training [INFO ] Epoch 30 Batch 6180 Training err. 1.36384 Training err. RA 1.70994 Valid. err. 1.59861
2018-02-03 22:13:14,208 training [INFO ] Epoch 30 Batch 6200 Training err. 1.35437 Training err. RA 1.70879 Valid. err. 1.58074
2018-02-03 22:13:14,697 training [INFO ] Epoch 30 Batch 6220 Training err. 1.36170 Training err. RA 1.70767 Valid. err. 1.57588
2018-02-03 22:13:15,180 training [INFO ] Epoch 30 Batch 6240 Training err. 1.38342 Training err. RA 1.70663 Valid. err. 1.57788
2018-02-03 22:13:16,048 training [INFO ] Epoch 31 Batch 6260 Training err. 1.37870 Training err. RA 1.70559 Valid. err. 1.55041
2018-02-03 22:13:16,528 training [INFO ] Epoch 31 Batch 6280 Training err. 1.34725 Training err. RA 1.70445 Valid. err. 1.59591
2018-02-03 22:13:17,023 training [INFO ] Epoch 31 Batch 6300 Training err. 1.41865 Training err. RA 1.70354 Valid. err. 1.59138
2018-02-03 22:13:17,511 training [INFO ] Epoch 31 Batch 6320 Training err. 1.42301 Training err. RA 1.70265 Valid. err. 1.56287
2018-02-03 22:13:18,020 training [INFO ] Epoch 31 Batch 6340 Training err. 1.36558 Training err. RA 1.70159 Valid. err. 1.58034
2018-02-03 22:13:18,521 training [INFO ] Epoch 31 Batch 6360 Training err. 1.42501 Training err. RA 1.70072 Valid. err. 1.56676
2018-02-03 22:13:19,019 training [INFO ] Epoch 31 Batch 6380 Training err. 1.38976 Training err. RA 1.69974 Valid. err. 1.57285
2018-02-03 22:13:19,507 training [INFO ] Epoch 31 Batch 6400 Training err. 1.34557 Training err. RA 1.69864 Valid. err. 1.60894
2018-02-03 22:13:19,989 training [INFO ] Epoch 31 Batch 6420 Training err. 1.34642 Training err. RA 1.69754 Valid. err. 1.55829
2018-02-03 22:13:20,475 training [INFO ] Epoch 31 Batch 6440 Training err. 1.38459 Training err. RA 1.69657 Valid. err. 1.55403
2018-02-03 22:13:21,343 training [INFO ] Epoch 32 Batch 6460 Training err. 1.36980 Training err. RA 1.69555 Valid. err. 1.55070
2018-02-03 22:13:21,827 training [INFO ] Epoch 32 Batch 6480 Training err. 1.34603 Training err. RA 1.69448 Valid. err. 1.57965
2018-02-03 22:13:22,311 training [INFO ] Epoch 32 Batch 6500 Training err. 1.40241 Training err. RA 1.69358 Valid. err. 1.55503
2018-02-03 22:13:22,799 training [INFO ] Epoch 32 Batch 6520 Training err. 1.41816 Training err. RA 1.69273 Valid. err. 1.56716
2018-02-03 22:13:23,283 training [INFO ] Epoch 32 Batch 6540 Training err. 1.36409 Training err. RA 1.69173 Valid. err. 1.57191
2018-02-03 22:13:23,783 training [INFO ] Epoch 32 Batch 6560 Training err. 1.38460 Training err. RA 1.69079 Valid. err. 1.55637
2018-02-03 22:13:24,293 training [INFO ] Epoch 32 Batch 6580 Training err. 1.42677 Training err. RA 1.68999 Valid. err. 1.56377
2018-02-03 22:13:24,784 training [INFO ] Epoch 32 Batch 6600 Training err. 1.33799 Training err. RA 1.68892 Valid. err. 1.58484
2018-02-03 22:13:25,271 training [INFO ] Epoch 32 Batch 6620 Training err. 1.35552 Training err. RA 1.68791 Valid. err. 1.58694
2018-02-03 22:13:25,756 training [INFO ] Epoch 32 Batch 6640 Training err. 1.34559 Training err. RA 1.68688 Valid. err. 1.58709
2018-02-03 22:13:26,608 training [INFO ] Epoch 33 Batch 6660 Training err. 1.36968 Training err. RA 1.68593 Valid. err. 1.55340
2018-02-03 22:13:27,089 training [INFO ] Epoch 33 Batch 6680 Training err. 1.35511 Training err. RA 1.68494 Valid. err. 1.55131
2018-02-03 22:13:27,572 training [INFO ] Epoch 33 Batch 6700 Training err. 1.35867 Training err. RA 1.68397 Valid. err. 1.55573
2018-02-03 22:13:28,056 training [INFO ] Epoch 33 Batch 6720 Training err. 1.40283 Training err. RA 1.68313 Valid. err. 1.56903
2018-02-03 22:13:28,539 training [INFO ] Epoch 33 Batch 6740 Training err. 1.38771 Training err. RA 1.68225 Valid. err. 1.61778
2018-02-03 22:13:29,064 training [INFO ] Epoch 33 Batch 6760 Training err. 1.35750 Training err. RA 1.68129 Valid. err. 1.55915
2018-02-03 22:13:29,548 training [INFO ] Epoch 33 Batch 6780 Training err. 1.42405 Training err. RA 1.68053 Valid. err. 1.59999
2018-02-03 22:13:30,027 training [INFO ] Epoch 33 Batch 6800 Training err. 1.34122 Training err. RA 1.67954 Valid. err. 1.59431
2018-02-03 22:13:30,542 training [INFO ] Epoch 33 Batch 6820 Training err. 1.34285 Training err. RA 1.67855 Valid. err. 1.60077
2018-02-03 22:13:31,071 training [INFO ] Epoch 33 Batch 6840 Training err. 1.31667 Training err. RA 1.67749 Valid. err. 1.56704
2018-02-03 22:13:31,631 training [INFO ] Epoch 33 Batch 6860 Training err. 1.37969 Training err. RA 1.67662 Valid. err. 1.56766
2018-02-03 22:13:32,668 training [INFO ] Epoch 34 Batch 6880 Training err. 1.35223 Training err. RA 1.67568 Valid. err. 1.56087
2018-02-03 22:13:33,164 training [INFO ] Epoch 34 Batch 6900 Training err. 1.32842 Training err. RA 1.67467 Valid. err. 1.56713
2018-02-03 22:13:33,651 training [INFO ] Epoch 34 Batch 6920 Training err. 1.38388 Training err. RA 1.67383 Valid. err. 1.56037
2018-02-03 22:13:34,207 training [INFO ] Epoch 34 Batch 6940 Training err. 1.39648 Training err. RA 1.67303 Valid. err. 1.56255
2018-02-03 22:13:34,745 training [INFO ] Epoch 34 Batch 6960 Training err. 1.34825 Training err. RA 1.67210 Valid. err. 1.60168
2018-02-03 22:13:35,228 training [INFO ] Epoch 34 Batch 6980 Training err. 1.39679 Training err. RA 1.67131 Valid. err. 1.56587
2018-02-03 22:13:35,784 training [INFO ] Epoch 34 Batch 7000 Training err. 1.38178 Training err. RA 1.67048 Valid. err. 1.57255
2018-02-03 22:13:36,264 training [INFO ] Epoch 34 Batch 7020 Training err. 1.32380 Training err. RA 1.66950 Valid. err. 1.58502
2018-02-03 22:13:36,745 training [INFO ] Epoch 34 Batch 7040 Training err. 1.34049 Training err. RA 1.66856 Valid. err. 1.57947
2018-02-03 22:13:37,234 training [INFO ] Epoch 34 Batch 7060 Training err. 1.34796 Training err. RA 1.66765 Valid. err. 1.58616
2018-02-03 22:13:38,088 training [INFO ] Epoch 35 Batch 7080 Training err. 1.33137 Training err. RA 1.66670 Valid. err. 1.55941
2018-02-03 22:13:38,634 training [INFO ] Epoch 35 Batch 7100 Training err. 1.33467 Training err. RA 1.66577 Valid. err. 1.56791
2018-02-03 22:13:39,146 training [INFO ] Epoch 35 Batch 7120 Training err. 1.36129 Training err. RA 1.66491 Valid. err. 1.55238
2018-02-03 22:13:39,645 training [INFO ] Epoch 35 Batch 7140 Training err. 1.40701 Training err. RA 1.66419 Valid. err. 1.54423
2018-02-03 22:13:40,136 training [INFO ] Epoch 35 Batch 7160 Training err. 1.34887 Training err. RA 1.66331 Valid. err. 1.58363
2018-02-03 22:13:40,645 training [INFO ] Epoch 35 Batch 7180 Training err. 1.34470 Training err. RA 1.66242 Valid. err. 1.57289
2018-02-03 22:13:41,158 training [INFO ] Epoch 35 Batch 7200 Training err. 1.42201 Training err. RA 1.66175 Valid. err. 1.55218
2018-02-03 22:13:41,666 training [INFO ] Epoch 35 Batch 7220 Training err. 1.33111 Training err. RA 1.66084 Valid. err. 1.58388
2018-02-03 22:13:42,159 training [INFO ] Epoch 35 Batch 7240 Training err. 1.32085 Training err. RA 1.65990 Valid. err. 1.58522
2018-02-03 22:13:42,643 training [INFO ] Epoch 35 Batch 7260 Training err. 1.32141 Training err. RA 1.65897 Valid. err. 1.55237
2018-02-03 22:13:43,126 training [INFO ] Epoch 35 Batch 7280 Training err. 1.34107 Training err. RA 1.65809 Valid. err. 1.57624
2018-02-03 22:13:44,029 training [INFO ] Epoch 36 Batch 7300 Training err. 1.35484 Training err. RA 1.65726 Valid. err. 1.54611
2018-02-03 22:13:44,509 training [INFO ] Epoch 36 Batch 7320 Training err. 1.29929 Training err. RA 1.65628 Valid. err. 1.58259
2018-02-03 22:13:44,988 training [INFO ] Epoch 36 Batch 7340 Training err. 1.37919 Training err. RA 1.65553 Valid. err. 1.58387
2018-02-03 22:13:45,482 training [INFO ] Epoch 36 Batch 7360 Training err. 1.39119 Training err. RA 1.65481 Valid. err. 1.55795
2018-02-03 22:13:45,993 training [INFO ] Epoch 36 Batch 7380 Training err. 1.31802 Training err. RA 1.65390 Valid. err. 1.56190
2018-02-03 22:13:46,502 training [INFO ] Epoch 36 Batch 7400 Training err. 1.39398 Training err. RA 1.65320 Valid. err. 1.55878
2018-02-03 22:13:46,985 training [INFO ] Epoch 36 Batch 7420 Training err. 1.36141 Training err. RA 1.65241 Valid. err. 1.56512
2018-02-03 22:13:47,470 training [INFO ] Epoch 36 Batch 7440 Training err. 1.31825 Training err. RA 1.65151 Valid. err. 1.57923
2018-02-03 22:13:47,960 training [INFO ] Epoch 36 Batch 7460 Training err. 1.31226 Training err. RA 1.65060 Valid. err. 1.54832
2018-02-03 22:13:48,454 training [INFO ] Epoch 36 Batch 7480 Training err. 1.37100 Training err. RA 1.64985 Valid. err. 1.55168
2018-02-03 22:13:49,359 training [INFO ] Epoch 37 Batch 7500 Training err. 1.32910 Training err. RA 1.64900 Valid. err. 1.54434
2018-02-03 22:13:49,852 training [INFO ] Epoch 37 Batch 7520 Training err. 1.31025 Training err. RA 1.64810 Valid. err. 1.57032
2018-02-03 22:13:50,363 training [INFO ] Epoch 37 Batch 7540 Training err. 1.36649 Training err. RA 1.64735 Valid. err. 1.55708
2018-02-03 22:13:50,936 training [INFO ] Epoch 37 Batch 7560 Training err. 1.38120 Training err. RA 1.64665 Valid. err. 1.56823
2018-02-03 22:13:51,511 training [INFO ] Epoch 37 Batch 7580 Training err. 1.31965 Training err. RA 1.64578 Valid. err. 1.57573
2018-02-03 22:13:52,071 training [INFO ] Epoch 37 Batch 7600 Training err. 1.34548 Training err. RA 1.64499 Valid. err. 1.54986
2018-02-03 22:13:52,643 training [INFO ] Epoch 37 Batch 7620 Training err. 1.39814 Training err. RA 1.64435 Valid. err. 1.55701
2018-02-03 22:13:53,255 training [INFO ] Epoch 37 Batch 7640 Training err. 1.30345 Training err. RA 1.64345 Valid. err. 1.58027
2018-02-03 22:13:53,827 training [INFO ] Epoch 37 Batch 7660 Training err. 1.33183 Training err. RA 1.64264 Valid. err. 1.57920
2018-02-03 22:13:54,351 training [INFO ] Epoch 37 Batch 7680 Training err. 1.32197 Training err. RA 1.64180 Valid. err. 1.56046
2018-02-03 22:13:55,310 training [INFO ] Epoch 38 Batch 7700 Training err. 1.32734 Training err. RA 1.64099 Valid. err. 1.53750
2018-02-03 22:13:55,821 training [INFO ] Epoch 38 Batch 7720 Training err. 1.31334 Training err. RA 1.64014 Valid. err. 1.55985
2018-02-03 22:13:56,389 training [INFO ] Epoch 38 Batch 7740 Training err. 1.31883 Training err. RA 1.63931 Valid. err. 1.55136
2018-02-03 22:13:56,988 training [INFO ] Epoch 38 Batch 7760 Training err. 1.37394 Training err. RA 1.63862 Valid. err. 1.56389
2018-02-03 22:13:57,571 training [INFO ] Epoch 38 Batch 7780 Training err. 1.36249 Training err. RA 1.63791 Valid. err. 1.58958
2018-02-03 22:13:58,065 training [INFO ] Epoch 38 Batch 7800 Training err. 1.31973 Training err. RA 1.63710 Valid. err. 1.54819
2018-02-03 22:13:58,553 training [INFO ] Epoch 38 Batch 7820 Training err. 1.38996 Training err. RA 1.63647 Valid. err. 1.58022
2018-02-03 22:13:59,146 training [INFO ] Epoch 38 Batch 7840 Training err. 1.30425 Training err. RA 1.63562 Valid. err. 1.57517
2018-02-03 22:13:59,683 training [INFO ] Epoch 38 Batch 7860 Training err. 1.31354 Training err. RA 1.63480 Valid. err. 1.58098
2018-02-03 22:14:00,200 training [INFO ] Epoch 38 Batch 7880 Training err. 1.28178 Training err. RA 1.63390 Valid. err. 1.56525
2018-02-03 22:14:00,751 training [INFO ] Epoch 38 Batch 7900 Training err. 1.34662 Training err. RA 1.63318 Valid. err. 1.56756
2018-02-03 22:14:01,708 training [INFO ] Epoch 39 Batch 7920 Training err. 1.30944 Training err. RA 1.63236 Valid. err. 1.54474
2018-02-03 22:14:02,250 training [INFO ] Epoch 39 Batch 7940 Training err. 1.28765 Training err. RA 1.63149 Valid. err. 1.56328
2018-02-03 22:14:02,802 training [INFO ] Epoch 39 Batch 7960 Training err. 1.34667 Training err. RA 1.63077 Valid. err. 1.55171
2018-02-03 22:14:03,304 training [INFO ] Epoch 39 Batch 7980 Training err. 1.36530 Training err. RA 1.63011 Valid. err. 1.54399
2018-02-03 22:14:03,804 training [INFO ] Epoch 39 Batch 8000 Training err. 1.31072 Training err. RA 1.62931 Valid. err. 1.59332
2018-02-03 22:14:04,355 training [INFO ] Epoch 39 Batch 8020 Training err. 1.35601 Training err. RA 1.62863 Valid. err. 1.55250
2018-02-03 22:14:04,908 training [INFO ] Epoch 39 Batch 8040 Training err. 1.34697 Training err. RA 1.62793 Valid. err. 1.56197
2018-02-03 22:14:05,445 training [INFO ] Epoch 39 Batch 8060 Training err. 1.28708 Training err. RA 1.62708 Valid. err. 1.57841
2018-02-03 22:14:05,995 training [INFO ] Epoch 39 Batch 8080 Training err. 1.30603 Training err. RA 1.62629 Valid. err. 1.54617
2018-02-03 22:14:06,536 training [INFO ] Epoch 39 Batch 8100 Training err. 1.31097 Training err. RA 1.62551 Valid. err. 1.57215
2018-02-03 22:14:07,433 training [INFO ] Epoch 40 Batch 8120 Training err. 1.30071 Training err. RA 1.62471 Valid. err. 1.53898
2018-02-03 22:14:07,982 training [INFO ] Epoch 40 Batch 8140 Training err. 1.30004 Training err. RA 1.62391 Valid. err. 1.55130
2018-02-03 22:14:08,541 training [INFO ] Epoch 40 Batch 8160 Training err. 1.32646 Training err. RA 1.62318 Valid. err. 1.54953
2018-02-03 22:14:09,096 training [INFO ] Epoch 40 Batch 8180 Training err. 1.36956 Training err. RA 1.62256 Valid. err. 1.53742
2018-02-03 22:14:09,655 training [INFO ] Epoch 40 Batch 8200 Training err. 1.31732 Training err. RA 1.62182 Valid. err. 1.57561
2018-02-03 22:14:10,238 training [INFO ] Epoch 40 Batch 8220 Training err. 1.31557 Training err. RA 1.62107 Valid. err. 1.56256
2018-02-03 22:14:10,839 training [INFO ] Epoch 40 Batch 8240 Training err. 1.37937 Training err. RA 1.62049 Valid. err. 1.53817
2018-02-03 22:14:11,471 training [INFO ] Epoch 40 Batch 8260 Training err. 1.29697 Training err. RA 1.61970 Valid. err. 1.57213
2018-02-03 22:14:12,107 training [INFO ] Epoch 40 Batch 8280 Training err. 1.28773 Training err. RA 1.61890 Valid. err. 1.56872
2018-02-03 22:14:12,730 training [INFO ] Epoch 40 Batch 8300 Training err. 1.29255 Training err. RA 1.61811 Valid. err. 1.54425
2018-02-03 22:14:13,384 training [INFO ] Epoch 40 Batch 8320 Training err. 1.31851 Training err. RA 1.61739 Valid. err. 1.55395
2018-02-03 22:14:14,414 training [INFO ] Epoch 41 Batch 8340 Training err. 1.32187 Training err. RA 1.61669 Valid. err. 1.54705
2018-02-03 22:14:14,951 training [INFO ] Epoch 41 Batch 8360 Training err. 1.27062 Training err. RA 1.61586 Valid. err. 1.56553
2018-02-03 22:14:15,519 training [INFO ] Epoch 41 Batch 8380 Training err. 1.34219 Training err. RA 1.61520 Valid. err. 1.56151
2018-02-03 22:14:16,081 training [INFO ] Epoch 41 Batch 8400 Training err. 1.35841 Training err. RA 1.61459 Valid. err. 1.54470
2018-02-03 22:14:16,650 training [INFO ] Epoch 41 Batch 8420 Training err. 1.28298 Training err. RA 1.61381 Valid. err. 1.56238
2018-02-03 22:14:17,227 training [INFO ] Epoch 41 Batch 8440 Training err. 1.35122 Training err. RA 1.61318 Valid. err. 1.56125
2018-02-03 22:14:17,783 training [INFO ] Epoch 41 Batch 8460 Training err. 1.32771 Training err. RA 1.61251 Valid. err. 1.55109
2018-02-03 22:14:18,357 training [INFO ] Epoch 41 Batch 8480 Training err. 1.28586 Training err. RA 1.61174 Valid. err. 1.57578
2018-02-03 22:14:18,912 training [INFO ] Epoch 41 Batch 8500 Training err. 1.28941 Training err. RA 1.61098 Valid. err. 1.53200
2018-02-03 22:14:19,464 training [INFO ] Epoch 41 Batch 8520 Training err. 1.31967 Training err. RA 1.61030 Valid. err. 1.52098
2018-02-03 22:14:20,440 training [INFO ] Epoch 42 Batch 8540 Training err. 1.30228 Training err. RA 1.60957 Valid. err. 1.52210
2018-02-03 22:14:20,988 training [INFO ] Epoch 42 Batch 8560 Training err. 1.28352 Training err. RA 1.60881 Valid. err. 1.54007
2018-02-03 22:14:21,546 training [INFO ] Epoch 42 Batch 8580 Training err. 1.32879 Training err. RA 1.60816 Valid. err. 1.54116
2018-02-03 22:14:22,043 training [INFO ] Epoch 42 Batch 8600 Training err. 1.34988 Training err. RA 1.60756 Valid. err. 1.54325
2018-02-03 22:14:22,604 training [INFO ] Epoch 42 Batch 8620 Training err. 1.28814 Training err. RA 1.60682 Valid. err. 1.55719
2018-02-03 22:14:23,172 training [INFO ] Epoch 42 Batch 8640 Training err. 1.30813 Training err. RA 1.60613 Valid. err. 1.57826
2018-02-03 22:14:23,738 training [INFO ] Epoch 42 Batch 8660 Training err. 1.37051 Training err. RA 1.60558 Valid. err. 1.54661
2018-02-03 22:14:24,305 training [INFO ] Epoch 42 Batch 8680 Training err. 1.27183 Training err. RA 1.60481 Valid. err. 1.56246
2018-02-03 22:14:24,877 training [INFO ] Epoch 42 Batch 8700 Training err. 1.28865 Training err. RA 1.60409 Valid. err. 1.54888
2018-02-03 22:14:25,395 training [INFO ] Epoch 42 Batch 8720 Training err. 1.29283 Training err. RA 1.60337 Valid. err. 1.55407
2018-02-03 22:14:26,330 training [INFO ] Epoch 43 Batch 8740 Training err. 1.31604 Training err. RA 1.60272 Valid. err. 1.54083
2018-02-03 22:14:26,884 training [INFO ] Epoch 43 Batch 8760 Training err. 1.29808 Training err. RA 1.60202 Valid. err. 1.53894
2018-02-03 22:14:27,444 training [INFO ] Epoch 43 Batch 8780 Training err. 1.28853 Training err. RA 1.60131 Valid. err. 1.54622
2018-02-03 22:14:27,995 training [INFO ] Epoch 43 Batch 8800 Training err. 1.33832 Training err. RA 1.60071 Valid. err. 1.53557
2018-02-03 22:14:28,545 training [INFO ] Epoch 43 Batch 8820 Training err. 1.32183 Training err. RA 1.60008 Valid. err. 1.56427
2018-02-03 22:14:29,046 training [INFO ] Epoch 43 Batch 8840 Training err. 1.29291 Training err. RA 1.59938 Valid. err. 1.53996
2018-02-03 22:14:29,581 training [INFO ] Epoch 43 Batch 8860 Training err. 1.36307 Training err. RA 1.59885 Valid. err. 1.56956
2018-02-03 22:14:30,282 training [INFO ] Epoch 43 Batch 8880 Training err. 1.27422 Training err. RA 1.59812 Valid. err. 1.55631
2018-02-03 22:14:30,847 training [INFO ] Epoch 43 Batch 8900 Training err. 1.27957 Training err. RA 1.59740 Valid. err. 1.59305
2018-02-03 22:14:31,344 training [INFO ] Epoch 43 Batch 8920 Training err. 1.26115 Training err. RA 1.59665 Valid. err. 1.57166
2018-02-03 22:14:31,879 training [INFO ] Epoch 43 Batch 8940 Training err. 1.32096 Training err. RA 1.59603 Valid. err. 1.53494
2018-02-03 22:14:32,904 training [INFO ] Epoch 44 Batch 8960 Training err. 1.28506 Training err. RA 1.59534 Valid. err. 1.53485
2018-02-03 22:14:33,511 training [INFO ] Epoch 44 Batch 8980 Training err. 1.27037 Training err. RA 1.59461 Valid. err. 1.54640
2018-02-03 22:14:34,000 training [INFO ] Epoch 44 Batch 9000 Training err. 1.32505 Training err. RA 1.59401 Valid. err. 1.52887
2018-02-03 22:14:34,493 training [INFO ] Epoch 44 Batch 9020 Training err. 1.33996 Training err. RA 1.59345 Valid. err. 1.52067
2018-02-03 22:14:35,020 training [INFO ] Epoch 44 Batch 9040 Training err. 1.28254 Training err. RA 1.59276 Valid. err. 1.56980
2018-02-03 22:14:35,566 training [INFO ] Epoch 44 Batch 9060 Training err. 1.32891 Training err. RA 1.59218 Valid. err. 1.52472
2018-02-03 22:14:36,051 training [INFO ] Epoch 44 Batch 9080 Training err. 1.32298 Training err. RA 1.59159 Valid. err. 1.55499
2018-02-03 22:14:36,540 training [INFO ] Epoch 44 Batch 9100 Training err. 1.26283 Training err. RA 1.59086 Valid. err. 1.57535
2018-02-03 22:14:37,025 training [INFO ] Epoch 44 Batch 9120 Training err. 1.28790 Training err. RA 1.59020 Valid. err. 1.57613
2018-02-03 22:14:37,516 training [INFO ] Epoch 44 Batch 9140 Training err. 1.29411 Training err. RA 1.58955 Valid. err. 1.55690
2018-02-03 22:14:38,532 training [INFO ] Epoch 45 Batch 9160 Training err. 1.27493 Training err. RA 1.58886 Valid. err. 1.52968
2018-02-03 22:14:39,057 training [INFO ] Epoch 45 Batch 9180 Training err. 1.27039 Training err. RA 1.58817 Valid. err. 1.52697
2018-02-03 22:14:39,648 training [INFO ] Epoch 45 Batch 9200 Training err. 1.29526 Training err. RA 1.58753 Valid. err. 1.52690
2018-02-03 22:14:40,217 training [INFO ] Epoch 45 Batch 9220 Training err. 1.33785 Training err. RA 1.58699 Valid. err. 1.52485
2018-02-03 22:14:40,792 training [INFO ] Epoch 45 Batch 9240 Training err. 1.28040 Training err. RA 1.58633 Valid. err. 1.55064
2018-02-03 22:14:41,348 training [INFO ] Epoch 45 Batch 9260 Training err. 1.27888 Training err. RA 1.58566 Valid. err. 1.54790
2018-02-03 22:14:41,857 training [INFO ] Epoch 45 Batch 9280 Training err. 1.35616 Training err. RA 1.58517 Valid. err. 1.53046
2018-02-03 22:14:42,379 training [INFO ] Epoch 45 Batch 9300 Training err. 1.26736 Training err. RA 1.58449 Valid. err. 1.56149
2018-02-03 22:14:42,945 training [INFO ] Epoch 45 Batch 9320 Training err. 1.26199 Training err. RA 1.58379 Valid. err. 1.55221
2018-02-03 22:14:43,565 training [INFO ] Epoch 45 Batch 9340 Training err. 1.26041 Training err. RA 1.58310 Valid. err. 1.53516
2018-02-03 22:14:44,118 training [INFO ] Epoch 45 Batch 9360 Training err. 1.28365 Training err. RA 1.58246 Valid. err. 1.54053
2018-02-03 22:14:45,004 training [INFO ] Epoch 46 Batch 9380 Training err. 1.29060 Training err. RA 1.58184 Valid. err. 1.52995
2018-02-03 22:14:45,508 training [INFO ] Epoch 46 Batch 9400 Training err. 1.24249 Training err. RA 1.58112 Valid. err. 1.55118
2018-02-03 22:14:46,073 training [INFO ] Epoch 46 Batch 9420 Training err. 1.31319 Training err. RA 1.58055 Valid. err. 1.56597
2018-02-03 22:14:46,616 training [INFO ] Epoch 46 Batch 9440 Training err. 1.33213 Training err. RA 1.58002 Valid. err. 1.55352
2018-02-03 22:14:47,116 training [INFO ] Epoch 46 Batch 9460 Training err. 1.25798 Training err. RA 1.57934 Valid. err. 1.54851
2018-02-03 22:14:47,617 training [INFO ] Epoch 46 Batch 9480 Training err. 1.31643 Training err. RA 1.57879 Valid. err. 1.53567
2018-02-03 22:14:48,116 training [INFO ] Epoch 46 Batch 9500 Training err. 1.29361 Training err. RA 1.57819 Valid. err. 1.54666
2018-02-03 22:14:48,617 training [INFO ] Epoch 46 Batch 9520 Training err. 1.30231 Training err. RA 1.57761 Valid. err. 1.58471
2018-02-03 22:14:49,116 training [INFO ] Epoch 46 Batch 9540 Training err. 1.27324 Training err. RA 1.57697 Valid. err. 1.53621
2018-02-03 22:14:49,623 training [INFO ] Epoch 46 Batch 9560 Training err. 1.29496 Training err. RA 1.57638 Valid. err. 1.51356
2018-02-03 22:14:50,505 training [INFO ] Epoch 47 Batch 9580 Training err. 1.26876 Training err. RA 1.57574 Valid. err. 1.53284
2018-02-03 22:14:50,989 training [INFO ] Epoch 47 Batch 9600 Training err. 1.26246 Training err. RA 1.57508 Valid. err. 1.53271
2018-02-03 22:14:51,471 training [INFO ] Epoch 47 Batch 9620 Training err. 1.30399 Training err. RA 1.57452 Valid. err. 1.53223
2018-02-03 22:14:51,959 training [INFO ] Epoch 47 Batch 9640 Training err. 1.32640 Training err. RA 1.57401 Valid. err. 1.53669
2018-02-03 22:14:52,446 training [INFO ] Epoch 47 Batch 9660 Training err. 1.27589 Training err. RA 1.57339 Valid. err. 1.55116
2018-02-03 22:14:52,934 training [INFO ] Epoch 47 Batch 9680 Training err. 1.27941 Training err. RA 1.57278 Valid. err. 1.52922
2018-02-03 22:14:53,421 training [INFO ] Epoch 47 Batch 9700 Training err. 1.33446 Training err. RA 1.57229 Valid. err. 1.53635
2018-02-03 22:14:53,910 training [INFO ] Epoch 47 Batch 9720 Training err. 1.24955 Training err. RA 1.57163 Valid. err. 1.55812
2018-02-03 22:14:54,392 training [INFO ] Epoch 47 Batch 9740 Training err. 1.26713 Training err. RA 1.57100 Valid. err. 1.53056
2018-02-03 22:14:54,889 training [INFO ] Epoch 47 Batch 9760 Training err. 1.26895 Training err. RA 1.57038 Valid. err. 1.52053
2018-02-03 22:14:55,745 training [INFO ] Epoch 48 Batch 9780 Training err. 1.27165 Training err. RA 1.56977 Valid. err. 1.51528
2018-02-03 22:14:56,226 training [INFO ] Epoch 48 Batch 9800 Training err. 1.26153 Training err. RA 1.56914 Valid. err. 1.52684
2018-02-03 22:14:56,713 training [INFO ] Epoch 48 Batch 9820 Training err. 1.25179 Training err. RA 1.56850 Valid. err. 1.53124
2018-02-03 22:14:57,196 training [INFO ] Epoch 48 Batch 9840 Training err. 1.31585 Training err. RA 1.56798 Valid. err. 1.54730
2018-02-03 22:14:57,680 training [INFO ] Epoch 48 Batch 9860 Training err. 1.30161 Training err. RA 1.56744 Valid. err. 1.58320
2018-02-03 22:14:58,159 training [INFO ] Epoch 48 Batch 9880 Training err. 1.26260 Training err. RA 1.56682 Valid. err. 1.54798
2018-02-03 22:14:58,645 training [INFO ] Epoch 48 Batch 9900 Training err. 1.32728 Training err. RA 1.56634 Valid. err. 1.56832
2018-02-03 22:14:59,130 training [INFO ] Epoch 48 Batch 9920 Training err. 1.25007 Training err. RA 1.56570 Valid. err. 1.54852
2018-02-03 22:14:59,620 training [INFO ] Epoch 48 Batch 9940 Training err. 1.25487 Training err. RA 1.56508 Valid. err. 1.60602
2018-02-03 22:15:00,116 training [INFO ] Epoch 48 Batch 9960 Training err. 1.23648 Training err. RA 1.56442 Valid. err. 1.54590
2018-02-03 22:15:00,602 training [INFO ] Epoch 48 Batch 9980 Training err. 1.30318 Training err. RA 1.56389 Valid. err. 1.52050
2018-02-03 22:15:01,478 training [INFO ] Epoch 49 Batch10000 Training err. 1.25194 Training err. RA 1.56327 Valid. err. 1.53219
2018-02-03 22:15:01,969 training [INFO ] Epoch 49 Batch10020 Training err. 1.23298 Training err. RA 1.56261 Valid. err. 1.53178
2018-02-03 22:15:02,542 training [INFO ] Epoch 49 Batch10040 Training err. 1.28833 Training err. RA 1.56206 Valid. err. 1.54001
2018-02-03 22:15:03,119 training [INFO ] Epoch 49 Batch10060 Training err. 1.31058 Training err. RA 1.56156 Valid. err. 1.54407
2018-02-03 22:15:03,688 training [INFO ] Epoch 49 Batch10080 Training err. 1.25528 Training err. RA 1.56096 Valid. err. 1.57721
2018-02-03 22:15:04,261 training [INFO ] Epoch 49 Batch10100 Training err. 1.29092 Training err. RA 1.56042 Valid. err. 1.53704
2018-02-03 22:15:04,844 training [INFO ] Epoch 49 Batch10120 Training err. 1.29282 Training err. RA 1.55989 Valid. err. 1.55074
2018-02-03 22:15:05,465 training [INFO ] Epoch 49 Batch10140 Training err. 1.23395 Training err. RA 1.55925 Valid. err. 1.55311
2018-02-03 22:15:06,039 training [INFO ] Epoch 49 Batch10160 Training err. 1.26111 Training err. RA 1.55866 Valid. err. 1.53647
2018-02-03 22:15:06,549 training [INFO ] Epoch 49 Batch10180 Training err. 1.26263 Training err. RA 1.55808 Valid. err. 1.55128
2018-02-03 22:15:07,506 training [INFO ] Epoch 50 Batch10200 Training err. 1.26034 Training err. RA 1.55750 Valid. err. 1.53052
2018-02-03 22:15:08,007 training [INFO ] Epoch 50 Batch10220 Training err. 1.24967 Training err. RA 1.55690 Valid. err. 1.53581
2018-02-03 22:15:08,502 training [INFO ] Epoch 50 Batch10240 Training err. 1.27101 Training err. RA 1.55634 Valid. err. 1.53148
2018-02-03 22:15:08,996 training [INFO ] Epoch 50 Batch10260 Training err. 1.31693 Training err. RA 1.55587 Valid. err. 1.53649
2018-02-03 22:15:09,565 training [INFO ] Epoch 50 Batch10280 Training err. 1.26766 Training err. RA 1.55531 Valid. err. 1.56176
2018-02-03 22:15:10,058 training [INFO ] Epoch 50 Batch10300 Training err. 1.24890 Training err. RA 1.55472 Valid. err. 1.54240
2018-02-03 22:15:10,543 training [INFO ] Epoch 50 Batch10320 Training err. 1.31253 Training err. RA 1.55425 Valid. err. 1.52658
2018-02-03 22:15:11,032 training [INFO ] Epoch 50 Batch10340 Training err. 1.24694 Training err. RA 1.55365 Valid. err. 1.54844
2018-02-03 22:15:11,515 training [INFO ] Epoch 50 Batch10360 Training err. 1.23594 Training err. RA 1.55304 Valid. err. 1.54976
2018-02-03 22:15:12,041 training [INFO ] Epoch 50 Batch10380 Training err. 1.25777 Training err. RA 1.55247 Valid. err. 1.52747
2018-02-03 22:15:12,529 training [INFO ] Epoch 50 Batch10400 Training err. 1.26778 Training err. RA 1.55192 Valid. err. 1.55568
2018-02-03 22:15:13,392 training [INFO ] Epoch 51 Batch10420 Training err. 1.26412 Training err. RA 1.55137 Valid. err. 1.51393
2018-02-03 22:15:13,880 training [INFO ] Epoch 51 Batch10440 Training err. 1.21924 Training err. RA 1.55073 Valid. err. 1.53153
2018-02-03 22:15:14,364 training [INFO ] Epoch 51 Batch10460 Training err. 1.28598 Training err. RA 1.55023 Valid. err. 1.55751
2018-02-03 22:15:14,898 training [INFO ] Epoch 51 Batch10480 Training err. 1.30142 Training err. RA 1.54975 Valid. err. 1.53851
2018-02-03 22:15:15,380 training [INFO ] Epoch 51 Batch10500 Training err. 1.22943 Training err. RA 1.54914 Valid. err. 1.55662
2018-02-03 22:15:15,863 training [INFO ] Epoch 51 Batch10520 Training err. 1.28142 Training err. RA 1.54863 Valid. err. 1.53700
2018-02-03 22:15:16,342 training [INFO ] Epoch 51 Batch10540 Training err. 1.27352 Training err. RA 1.54811 Valid. err. 1.55055
2018-02-03 22:15:16,823 training [INFO ] Epoch 51 Batch10560 Training err. 1.22759 Training err. RA 1.54750 Valid. err. 1.59000
2018-02-03 22:15:17,330 training [INFO ] Epoch 51 Batch10580 Training err. 1.24239 Training err. RA 1.54693 Valid. err. 1.53800
2018-02-03 22:15:17,820 training [INFO ] Epoch 51 Batch10600 Training err. 1.26130 Training err. RA 1.54639 Valid. err. 1.52833
2018-02-03 22:15:18,682 training [INFO ] Epoch 52 Batch10620 Training err. 1.26049 Training err. RA 1.54585 Valid. err. 1.53137
2018-02-03 22:15:19,165 training [INFO ] Epoch 52 Batch10640 Training err. 1.23236 Training err. RA 1.54526 Valid. err. 1.54844
2018-02-03 22:15:19,653 training [INFO ] Epoch 52 Batch10660 Training err. 1.28318 Training err. RA 1.54477 Valid. err. 1.52635
2018-02-03 22:15:20,145 training [INFO ] Epoch 52 Batch10680 Training err. 1.30090 Training err. RA 1.54431 Valid. err. 1.53655
2018-02-03 22:15:20,668 training [INFO ] Epoch 52 Batch10700 Training err. 1.23625 Training err. RA 1.54374 Valid. err. 1.55190
2018-02-03 22:15:21,156 training [INFO ] Epoch 52 Batch10720 Training err. 1.24639 Training err. RA 1.54318 Valid. err. 1.53139
2018-02-03 22:15:21,642 training [INFO ] Epoch 52 Batch10740 Training err. 1.30516 Training err. RA 1.54274 Valid. err. 1.53504
2018-02-03 22:15:22,127 training [INFO ] Epoch 52 Batch10760 Training err. 1.21542 Training err. RA 1.54213 Valid. err. 1.53105
2018-02-03 22:15:22,609 training [INFO ] Epoch 52 Batch10780 Training err. 1.24675 Training err. RA 1.54158 Valid. err. 1.63077
2018-02-03 22:15:23,134 training [INFO ] Epoch 52 Batch10800 Training err. 1.25061 Training err. RA 1.54104 Valid. err. 1.52360
2018-02-03 22:15:23,993 training [INFO ] Epoch 53 Batch10820 Training err. 1.24122 Training err. RA 1.54049 Valid. err. 1.52486
2018-02-03 22:15:24,475 training [INFO ] Epoch 53 Batch10840 Training err. 1.23525 Training err. RA 1.53993 Valid. err. 1.51761
2018-02-03 22:15:24,960 training [INFO ] Epoch 53 Batch10860 Training err. 1.25016 Training err. RA 1.53939 Valid. err. 1.53275
2018-02-03 22:15:25,440 training [INFO ] Epoch 53 Batch10880 Training err. 1.28682 Training err. RA 1.53893 Valid. err. 1.53389
2018-02-03 22:15:25,964 training [INFO ] Epoch 53 Batch10900 Training err. 1.27841 Training err. RA 1.53845 Valid. err. 1.54741
2018-02-03 22:15:26,441 training [INFO ] Epoch 53 Batch10920 Training err. 1.23868 Training err. RA 1.53790 Valid. err. 1.53646
2018-02-03 22:15:26,926 training [INFO ] Epoch 53 Batch10940 Training err. 1.29860 Training err. RA 1.53746 Valid. err. 1.54906
2018-02-03 22:15:27,410 training [INFO ] Epoch 53 Batch10960 Training err. 1.22876 Training err. RA 1.53690 Valid. err. 1.53284
2018-02-03 22:15:27,899 training [INFO ] Epoch 53 Batch10980 Training err. 1.23135 Training err. RA 1.53634 Valid. err. 1.59978
2018-02-03 22:15:28,382 training [INFO ] Epoch 53 Batch11000 Training err. 1.21537 Training err. RA 1.53576 Valid. err. 1.53831
2018-02-03 22:15:28,910 training [INFO ] Epoch 53 Batch11020 Training err. 1.26340 Training err. RA 1.53527 Valid. err. 1.52666
2018-02-03 22:15:29,776 training [INFO ] Epoch 54 Batch11040 Training err. 1.24441 Training err. RA 1.53474 Valid. err. 1.53634
2018-02-03 22:15:30,298 training [INFO ] Epoch 54 Batch11060 Training err. 1.21055 Training err. RA 1.53415 Valid. err. 1.53517
2018-02-03 22:15:30,877 training [INFO ] Epoch 54 Batch11080 Training err. 1.26178 Training err. RA 1.53366 Valid. err. 1.53705
2018-02-03 22:15:31,487 training [INFO ] Epoch 54 Batch11100 Training err. 1.28490 Training err. RA 1.53321 Valid. err. 1.53465
2018-02-03 22:15:32,057 training [INFO ] Epoch 54 Batch11120 Training err. 1.22193 Training err. RA 1.53265 Valid. err. 1.60115
2018-02-03 22:15:32,643 training [INFO ] Epoch 54 Batch11140 Training err. 1.28427 Training err. RA 1.53221 Valid. err. 1.54293
2018-02-03 22:15:33,233 training [INFO ] Epoch 54 Batch11160 Training err. 1.27758 Training err. RA 1.53175 Valid. err. 1.55687
2018-02-03 22:15:33,802 training [INFO ] Epoch 54 Batch11180 Training err. 1.21535 Training err. RA 1.53118 Valid. err. 1.54624
2018-02-03 22:15:34,360 training [INFO ] Epoch 54 Batch11200 Training err. 1.23529 Training err. RA 1.53066 Valid. err. 1.53704
2018-02-03 22:15:34,867 training [INFO ] Epoch 54 Batch11220 Training err. 1.22634 Training err. RA 1.53011 Valid. err. 1.55407
2018-02-03 22:15:35,698 training [INFO ] Epoch 55 Batch11240 Training err. 1.23139 Training err. RA 1.52958 Valid. err. 1.49831
2018-02-03 22:15:36,177 training [INFO ] Epoch 55 Batch11260 Training err. 1.22579 Training err. RA 1.52904 Valid. err. 1.53383
2018-02-03 22:15:36,659 training [INFO ] Epoch 55 Batch11280 Training err. 1.24152 Training err. RA 1.52853 Valid. err. 1.52812
2018-02-03 22:15:37,142 training [INFO ] Epoch 55 Batch11300 Training err. 1.29724 Training err. RA 1.52812 Valid. err. 1.53513
2018-02-03 22:15:37,671 training [INFO ] Epoch 55 Batch11320 Training err. 1.25319 Training err. RA 1.52764 Valid. err. 1.55650
2018-02-03 22:15:38,152 training [INFO ] Epoch 55 Batch11340 Training err. 1.25017 Training err. RA 1.52715 Valid. err. 1.55470
2018-02-03 22:15:38,642 training [INFO ] Epoch 55 Batch11360 Training err. 1.29827 Training err. RA 1.52674 Valid. err. 1.53743
2018-02-03 22:15:39,130 training [INFO ] Epoch 55 Batch11380 Training err. 1.21825 Training err. RA 1.52620 Valid. err. 1.53249
2018-02-03 22:15:39,625 training [INFO ] Epoch 55 Batch11400 Training err. 1.22017 Training err. RA 1.52567 Valid. err. 1.55869
2018-02-03 22:15:40,109 training [INFO ] Epoch 55 Batch11420 Training err. 1.22691 Training err. RA 1.52514 Valid. err. 1.52986
2018-02-03 22:15:40,636 training [INFO ] Epoch 55 Batch11440 Training err. 1.24932 Training err. RA 1.52466 Valid. err. 1.53374
2018-02-03 22:15:41,523 training [INFO ] Epoch 56 Batch11460 Training err. 1.24936 Training err. RA 1.52418 Valid. err. 1.50928
2018-02-03 22:15:42,022 training [INFO ] Epoch 56 Batch11480 Training err. 1.19223 Training err. RA 1.52360 Valid. err. 1.54728
2018-02-03 22:15:42,588 training [INFO ] Epoch 56 Batch11500 Training err. 1.26975 Training err. RA 1.52316 Valid. err. 1.54868
2018-02-03 22:15:43,174 training [INFO ] Epoch 56 Batch11520 Training err. 1.28101 Training err. RA 1.52274 Valid. err. 1.53220
2018-02-03 22:15:43,744 training [INFO ] Epoch 56 Batch11540 Training err. 1.21021 Training err. RA 1.52220 Valid. err. 1.53216
2018-02-03 22:15:44,314 training [INFO ] Epoch 56 Batch11560 Training err. 1.26588 Training err. RA 1.52175 Valid. err. 1.53621
2018-02-03 22:15:44,934 training [INFO ] Epoch 56 Batch11580 Training err. 1.25515 Training err. RA 1.52129 Valid. err. 1.52283
2018-02-03 22:15:45,514 training [INFO ] Epoch 56 Batch11600 Training err. 1.20726 Training err. RA 1.52075 Valid. err. 1.57105
2018-02-03 22:15:46,092 training [INFO ] Epoch 56 Batch11620 Training err. 1.23183 Training err. RA 1.52026 Valid. err. 1.51917
2018-02-03 22:15:46,617 training [INFO ] Epoch 56 Batch11640 Training err. 1.24558 Training err. RA 1.51978 Valid. err. 1.52350
2018-02-03 22:15:47,498 training [INFO ] Epoch 57 Batch11660 Training err. 1.22245 Training err. RA 1.51927 Valid. err. 1.51691
2018-02-03 22:15:47,986 training [INFO ] Epoch 57 Batch11680 Training err. 1.20583 Training err. RA 1.51874 Valid. err. 1.52186
2018-02-03 22:15:48,466 training [INFO ] Epoch 57 Batch11700 Training err. 1.24368 Training err. RA 1.51827 Valid. err. 1.50821
2018-02-03 22:15:48,988 training [INFO ] Epoch 57 Batch11720 Training err. 1.26606 Training err. RA 1.51784 Valid. err. 1.54271
2018-02-03 22:15:49,470 training [INFO ] Epoch 57 Batch11740 Training err. 1.22901 Training err. RA 1.51734 Valid. err. 1.53813
2018-02-03 22:15:49,960 training [INFO ] Epoch 57 Batch11760 Training err. 1.23392 Training err. RA 1.51686 Valid. err. 1.51498
2018-02-03 22:15:50,442 training [INFO ] Epoch 57 Batch11780 Training err. 1.29639 Training err. RA 1.51649 Valid. err. 1.54949
2018-02-03 22:15:50,923 training [INFO ] Epoch 57 Batch11800 Training err. 1.20142 Training err. RA 1.51595 Valid. err. 1.54577
2018-02-03 22:15:51,452 training [INFO ] Epoch 57 Batch11820 Training err. 1.23448 Training err. RA 1.51548 Valid. err. 1.56797
2018-02-03 22:15:51,937 training [INFO ] Epoch 57 Batch11840 Training err. 1.22507 Training err. RA 1.51499 Valid. err. 1.51565
2018-02-03 22:15:52,805 training [INFO ] Epoch 58 Batch11860 Training err. 1.22888 Training err. RA 1.51450 Valid. err. 1.53964
2018-02-03 22:15:53,282 training [INFO ] Epoch 58 Batch11880 Training err. 1.21580 Training err. RA 1.51400 Valid. err. 1.53559
2018-02-03 22:15:53,767 training [INFO ] Epoch 58 Batch11900 Training err. 1.20998 Training err. RA 1.51349 Valid. err. 1.54892
2018-02-03 22:15:54,289 training [INFO ] Epoch 58 Batch11920 Training err. 1.26607 Training err. RA 1.51308 Valid. err. 1.54236
2018-02-03 22:15:54,781 training [INFO ] Epoch 58 Batch11940 Training err. 1.25070 Training err. RA 1.51264 Valid. err. 1.55840
2018-02-03 22:15:55,264 training [INFO ] Epoch 58 Batch11960 Training err. 1.21237 Training err. RA 1.51213 Valid. err. 1.51883
2018-02-03 22:15:55,750 training [INFO ] Epoch 58 Batch11980 Training err. 1.27782 Training err. RA 1.51174 Valid. err. 1.54456
2018-02-03 22:15:56,238 training [INFO ] Epoch 58 Batch12000 Training err. 1.21392 Training err. RA 1.51125 Valid. err. 1.54711
2018-02-03 22:15:56,728 training [INFO ] Epoch 58 Batch12020 Training err. 1.22919 Training err. RA 1.51078 Valid. err. 1.62441
2018-02-03 22:15:57,244 training [INFO ] Epoch 58 Batch12040 Training err. 1.20825 Training err. RA 1.51027 Valid. err. 1.53036
2018-02-03 22:15:57,740 training [INFO ] Epoch 58 Batch12060 Training err. 1.24019 Training err. RA 1.50983 Valid. err. 1.50981
2018-02-03 22:15:58,792 training [INFO ] Epoch 59 Batch12080 Training err. 1.20828 Training err. RA 1.50933 Valid. err. 1.52164
2018-02-03 22:15:59,366 training [INFO ] Epoch 59 Batch12100 Training err. 1.18472 Training err. RA 1.50879 Valid. err. 1.52710
2018-02-03 22:15:59,970 training [INFO ] Epoch 59 Batch12120 Training err. 1.23987 Training err. RA 1.50835 Valid. err. 1.52338
2018-02-03 22:16:00,549 training [INFO ] Epoch 59 Batch12140 Training err. 1.26565 Training err. RA 1.50795 Valid. err. 1.53750
2018-02-03 22:16:01,133 training [INFO ] Epoch 59 Batch12160 Training err. 1.20686 Training err. RA 1.50745 Valid. err. 1.57425
2018-02-03 22:16:01,740 training [INFO ] Epoch 59 Batch12180 Training err. 1.25927 Training err. RA 1.50704 Valid. err. 1.54161
2018-02-03 22:16:02,288 training [INFO ] Epoch 59 Batch12200 Training err. 1.26001 Training err. RA 1.50664 Valid. err. 1.54847
2018-02-03 22:16:02,807 training [INFO ] Epoch 59 Batch12220 Training err. 1.20032 Training err. RA 1.50614 Valid. err. 1.53469
2018-02-03 22:16:03,326 training [INFO ] Epoch 59 Batch12240 Training err. 1.21627 Training err. RA 1.50566 Valid. err. 1.52296
2018-02-03 22:16:03,811 training [INFO ] Epoch 59 Batch12260 Training err. 1.20912 Training err. RA 1.50518 Valid. err. 1.55025
2018-02-03 22:16:04,639 training [INFO ] Epoch 60 Batch12280 Training err. 1.21677 Training err. RA 1.50471 Valid. err. 1.53296
2018-02-03 22:16:05,122 training [INFO ] Epoch 60 Batch12300 Training err. 1.20882 Training err. RA 1.50423 Valid. err. 1.56464
2018-02-03 22:16:05,606 training [INFO ] Epoch 60 Batch12320 Training err. 1.22446 Training err. RA 1.50378 Valid. err. 1.52571
2018-02-03 22:16:06,136 training [INFO ] Epoch 60 Batch12340 Training err. 1.26845 Training err. RA 1.50339 Valid. err. 1.51513
2018-02-03 22:16:06,612 training [INFO ] Epoch 60 Batch12360 Training err. 1.21804 Training err. RA 1.50293 Valid. err. 1.55831
2018-02-03 22:16:07,102 training [INFO ] Epoch 60 Batch12380 Training err. 1.20823 Training err. RA 1.50246 Valid. err. 1.55136
2018-02-03 22:16:07,591 training [INFO ] Epoch 60 Batch12400 Training err. 1.26682 Training err. RA 1.50208 Valid. err. 1.53810
2018-02-03 22:16:08,079 training [INFO ] Epoch 60 Batch12420 Training err. 1.20687 Training err. RA 1.50160 Valid. err. 1.52081
2018-02-03 22:16:08,580 training [INFO ] Epoch 60 Batch12440 Training err. 1.19065 Training err. RA 1.50110 Valid. err. 1.54338
2018-02-03 22:16:09,131 training [INFO ] Epoch 60 Batch12460 Training err. 1.20019 Training err. RA 1.50062 Valid. err. 1.52766
2018-02-03 22:16:09,615 training [INFO ] Epoch 60 Batch12480 Training err. 1.21963 Training err. RA 1.50017 Valid. err. 1.53125
2018-02-03 22:16:09,886 __main__ [INFO ] End of training
2018-02-03 22:16:10,163 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 10,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 22:16:10,778 training [INFO ] Epoch  1 Batch   20 Training err. 4.22586 Training err. RA 4.22586 Valid. err. 4.14682
2018-02-03 22:16:11,277 training [INFO ] Epoch  1 Batch   40 Training err. 4.03778 Training err. RA 4.13182 Valid. err. 3.95536
2018-02-03 22:16:11,826 training [INFO ] Epoch  1 Batch   60 Training err. 3.81806 Training err. RA 4.02723 Valid. err. 3.70906
2018-02-03 22:16:12,322 training [INFO ] Epoch  1 Batch   80 Training err. 3.59906 Training err. RA 3.92019 Valid. err. 3.50614
2018-02-03 22:16:12,830 training [INFO ] Epoch  1 Batch  100 Training err. 3.41544 Training err. RA 3.81924 Valid. err. 3.36655
2018-02-03 22:16:13,646 training [INFO ] Epoch  2 Batch  120 Training err. 3.29822 Training err. RA 3.73240 Valid. err. 3.29072
2018-02-03 22:16:14,203 training [INFO ] Epoch  2 Batch  140 Training err. 3.20338 Training err. RA 3.65683 Valid. err. 3.25479
2018-02-03 22:16:14,742 training [INFO ] Epoch  2 Batch  160 Training err. 3.19334 Training err. RA 3.59889 Valid. err. 3.23046
2018-02-03 22:16:15,250 training [INFO ] Epoch  2 Batch  180 Training err. 3.18727 Training err. RA 3.55315 Valid. err. 3.21615
2018-02-03 22:16:15,758 training [INFO ] Epoch  2 Batch  200 Training err. 3.17677 Training err. RA 3.51552 Valid. err. 3.20683
2018-02-03 22:16:16,603 training [INFO ] Epoch  3 Batch  220 Training err. 3.18607 Training err. RA 3.48557 Valid. err. 3.20199
2018-02-03 22:16:17,172 training [INFO ] Epoch  3 Batch  240 Training err. 3.11936 Training err. RA 3.45505 Valid. err. 3.20864
2018-02-03 22:16:17,713 training [INFO ] Epoch  3 Batch  260 Training err. 3.15884 Training err. RA 3.43226 Valid. err. 3.19326
2018-02-03 22:16:18,229 training [INFO ] Epoch  3 Batch  280 Training err. 3.14087 Training err. RA 3.41145 Valid. err. 3.19023
2018-02-03 22:16:18,732 training [INFO ] Epoch  3 Batch  300 Training err. 3.15007 Training err. RA 3.39402 Valid. err. 3.18963
2018-02-03 22:16:19,569 training [INFO ] Epoch  4 Batch  320 Training err. 3.17091 Training err. RA 3.38008 Valid. err. 3.18533
2018-02-03 22:16:20,155 training [INFO ] Epoch  4 Batch  340 Training err. 3.11947 Training err. RA 3.36475 Valid. err. 3.19373
2018-02-03 22:16:20,655 training [INFO ] Epoch  4 Batch  360 Training err. 3.14089 Training err. RA 3.35231 Valid. err. 3.18450
2018-02-03 22:16:21,158 training [INFO ] Epoch  4 Batch  380 Training err. 3.12577 Training err. RA 3.34039 Valid. err. 3.18349
2018-02-03 22:16:21,659 training [INFO ] Epoch  4 Batch  400 Training err. 3.13783 Training err. RA 3.33026 Valid. err. 3.18372
2018-02-03 22:16:22,554 training [INFO ] Epoch  5 Batch  420 Training err. 3.16492 Training err. RA 3.32239 Valid. err. 3.18409
2018-02-03 22:16:23,152 training [INFO ] Epoch  5 Batch  440 Training err. 3.13327 Training err. RA 3.31379 Valid. err. 3.18767
2018-02-03 22:16:23,656 training [INFO ] Epoch  5 Batch  460 Training err. 3.12491 Training err. RA 3.30558 Valid. err. 3.18061
2018-02-03 22:16:24,173 training [INFO ] Epoch  5 Batch  480 Training err. 3.10762 Training err. RA 3.29733 Valid. err. 3.18102
2018-02-03 22:16:24,693 training [INFO ] Epoch  5 Batch  500 Training err. 3.14178 Training err. RA 3.29111 Valid. err. 3.18206
2018-02-03 22:16:25,210 training [INFO ] Epoch  5 Batch  520 Training err. 3.16144 Training err. RA 3.28612 Valid. err. 3.17858
2018-02-03 22:16:26,107 training [INFO ] Epoch  6 Batch  540 Training err. 3.13812 Training err. RA 3.28064 Valid. err. 3.18040
2018-02-03 22:16:26,610 training [INFO ] Epoch  6 Batch  560 Training err. 3.11247 Training err. RA 3.27463 Valid. err. 3.18027
2018-02-03 22:16:27,113 training [INFO ] Epoch  6 Batch  580 Training err. 3.09851 Training err. RA 3.26856 Valid. err. 3.18186
2018-02-03 22:16:27,617 training [INFO ] Epoch  6 Batch  600 Training err. 3.14734 Training err. RA 3.26452 Valid. err. 3.17844
2018-02-03 22:16:28,156 training [INFO ] Epoch  6 Batch  620 Training err. 3.14605 Training err. RA 3.26070 Valid. err. 3.17694
2018-02-03 22:16:29,021 training [INFO ] Epoch  7 Batch  640 Training err. 3.14889 Training err. RA 3.25720 Valid. err. 3.17781
2018-02-03 22:16:29,520 training [INFO ] Epoch  7 Batch  660 Training err. 3.10063 Training err. RA 3.25246 Valid. err. 3.17849
2018-02-03 22:16:30,023 training [INFO ] Epoch  7 Batch  680 Training err. 3.11463 Training err. RA 3.24841 Valid. err. 3.17822
2018-02-03 22:16:30,522 training [INFO ] Epoch  7 Batch  700 Training err. 3.13269 Training err. RA 3.24510 Valid. err. 3.17655
2018-02-03 22:16:31,056 training [INFO ] Epoch  7 Batch  720 Training err. 3.13497 Training err. RA 3.24204 Valid. err. 3.17546
2018-02-03 22:16:31,946 training [INFO ] Epoch  8 Batch  740 Training err. 3.15525 Training err. RA 3.23970 Valid. err. 3.17752
2018-02-03 22:16:32,461 training [INFO ] Epoch  8 Batch  760 Training err. 3.09046 Training err. RA 3.23577 Valid. err. 3.18769
2018-02-03 22:16:32,973 training [INFO ] Epoch  8 Batch  780 Training err. 3.13075 Training err. RA 3.23308 Valid. err. 3.17527
2018-02-03 22:16:33,483 training [INFO ] Epoch  8 Batch  800 Training err. 3.11844 Training err. RA 3.23021 Valid. err. 3.17441
2018-02-03 22:16:34,054 training [INFO ] Epoch  8 Batch  820 Training err. 3.13029 Training err. RA 3.22777 Valid. err. 3.17557
2018-02-03 22:16:34,891 training [INFO ] Epoch  9 Batch  840 Training err. 3.15313 Training err. RA 3.22599 Valid. err. 3.17192
2018-02-03 22:16:35,389 training [INFO ] Epoch  9 Batch  860 Training err. 3.10320 Training err. RA 3.22314 Valid. err. 3.18151
2018-02-03 22:16:35,890 training [INFO ] Epoch  9 Batch  880 Training err. 3.12376 Training err. RA 3.22088 Valid. err. 3.17261
2018-02-03 22:16:36,414 training [INFO ] Epoch  9 Batch  900 Training err. 3.10955 Training err. RA 3.21841 Valid. err. 3.17214
2018-02-03 22:16:36,978 training [INFO ] Epoch  9 Batch  920 Training err. 3.12313 Training err. RA 3.21634 Valid. err. 3.17242
2018-02-03 22:16:37,797 training [INFO ] Epoch 10 Batch  940 Training err. 3.15064 Training err. RA 3.21494 Valid. err. 3.17286
2018-02-03 22:16:38,294 training [INFO ] Epoch 10 Batch  960 Training err. 3.11910 Training err. RA 3.21294 Valid. err. 3.17721
2018-02-03 22:16:38,803 training [INFO ] Epoch 10 Batch  980 Training err. 3.11109 Training err. RA 3.21086 Valid. err. 3.16939
2018-02-03 22:16:39,319 training [INFO ] Epoch 10 Batch 1000 Training err. 3.09339 Training err. RA 3.20851 Valid. err. 3.16973
2018-02-03 22:16:39,904 training [INFO ] Epoch 10 Batch 1020 Training err. 3.12773 Training err. RA 3.20693 Valid. err. 3.17062
2018-02-03 22:16:40,413 training [INFO ] Epoch 10 Batch 1040 Training err. 3.14715 Training err. RA 3.20578 Valid. err. 3.16691
2018-02-03 22:16:41,236 training [INFO ] Epoch 11 Batch 1060 Training err. 3.12458 Training err. RA 3.20425 Valid. err. 3.16856
2018-02-03 22:16:41,742 training [INFO ] Epoch 11 Batch 1080 Training err. 3.09931 Training err. RA 3.20230 Valid. err. 3.16822
2018-02-03 22:16:42,246 training [INFO ] Epoch 11 Batch 1100 Training err. 3.08407 Training err. RA 3.20015 Valid. err. 3.16941
2018-02-03 22:16:42,818 training [INFO ] Epoch 11 Batch 1120 Training err. 3.13265 Training err. RA 3.19895 Valid. err. 3.16575
2018-02-03 22:16:43,339 training [INFO ] Epoch 11 Batch 1140 Training err. 3.13158 Training err. RA 3.19777 Valid. err. 3.16388
2018-02-03 22:16:44,174 training [INFO ] Epoch 12 Batch 1160 Training err. 3.13450 Training err. RA 3.19668 Valid. err. 3.16439
2018-02-03 22:16:44,676 training [INFO ] Epoch 12 Batch 1180 Training err. 3.08692 Training err. RA 3.19482 Valid. err. 3.16468
2018-02-03 22:16:45,202 training [INFO ] Epoch 12 Batch 1200 Training err. 3.09871 Training err. RA 3.19321 Valid. err. 3.16412
2018-02-03 22:16:45,786 training [INFO ] Epoch 12 Batch 1220 Training err. 3.11752 Training err. RA 3.19197 Valid. err. 3.16188
2018-02-03 22:16:46,314 training [INFO ] Epoch 12 Batch 1240 Training err. 3.11895 Training err. RA 3.19080 Valid. err. 3.16023
2018-02-03 22:16:47,155 training [INFO ] Epoch 13 Batch 1260 Training err. 3.13929 Training err. RA 3.18998 Valid. err. 3.16244
2018-02-03 22:16:47,666 training [INFO ] Epoch 13 Batch 1280 Training err. 3.07549 Training err. RA 3.18819 Valid. err. 3.17175
2018-02-03 22:16:48,218 training [INFO ] Epoch 13 Batch 1300 Training err. 3.11271 Training err. RA 3.18703 Valid. err. 3.15860
2018-02-03 22:16:48,803 training [INFO ] Epoch 13 Batch 1320 Training err. 3.10133 Training err. RA 3.18573 Valid. err. 3.15700
2018-02-03 22:16:49,335 training [INFO ] Epoch 13 Batch 1340 Training err. 3.11157 Training err. RA 3.18462 Valid. err. 3.15764
2018-02-03 22:16:50,193 training [INFO ] Epoch 14 Batch 1360 Training err. 3.13465 Training err. RA 3.18389 Valid. err. 3.15319
2018-02-03 22:16:50,688 training [INFO ] Epoch 14 Batch 1380 Training err. 3.08506 Training err. RA 3.18246 Valid. err. 3.16235
2018-02-03 22:16:51,217 training [INFO ] Epoch 14 Batch 1400 Training err. 3.10444 Training err. RA 3.18134 Valid. err. 3.15249
2018-02-03 22:16:51,800 training [INFO ] Epoch 14 Batch 1420 Training err. 3.08874 Training err. RA 3.18004 Valid. err. 3.15120
2018-02-03 22:16:52,328 training [INFO ] Epoch 14 Batch 1440 Training err. 3.10130 Training err. RA 3.17894 Valid. err. 3.15032
2018-02-03 22:16:53,161 training [INFO ] Epoch 15 Batch 1460 Training err. 3.12901 Training err. RA 3.17826 Valid. err. 3.14986
2018-02-03 22:16:53,657 training [INFO ] Epoch 15 Batch 1480 Training err. 3.09573 Training err. RA 3.17714 Valid. err. 3.15512
2018-02-03 22:16:54,201 training [INFO ] Epoch 15 Batch 1500 Training err. 3.08930 Training err. RA 3.17597 Valid. err. 3.14441
2018-02-03 22:16:54,784 training [INFO ] Epoch 15 Batch 1520 Training err. 3.06789 Training err. RA 3.17455 Valid. err. 3.14345
2018-02-03 22:16:55,321 training [INFO ] Epoch 15 Batch 1540 Training err. 3.10100 Training err. RA 3.17360 Valid. err. 3.14296
2018-02-03 22:16:55,837 training [INFO ] Epoch 15 Batch 1560 Training err. 3.11946 Training err. RA 3.17290 Valid. err. 3.13768
2018-02-03 22:16:56,681 training [INFO ] Epoch 16 Batch 1580 Training err. 3.09584 Training err. RA 3.17193 Valid. err. 3.13795
2018-02-03 22:16:57,218 training [INFO ] Epoch 16 Batch 1600 Training err. 3.07301 Training err. RA 3.17069 Valid. err. 3.13631
2018-02-03 22:16:57,802 training [INFO ] Epoch 16 Batch 1620 Training err. 3.05178 Training err. RA 3.16922 Valid. err. 3.13516
2018-02-03 22:16:58,444 training [INFO ] Epoch 16 Batch 1640 Training err. 3.09787 Training err. RA 3.16835 Valid. err. 3.13000
2018-02-03 22:16:59,108 training [INFO ] Epoch 16 Batch 1660 Training err. 3.09646 Training err. RA 3.16748 Valid. err. 3.12584
2018-02-03 22:17:00,288 training [INFO ] Epoch 17 Batch 1680 Training err. 3.09837 Training err. RA 3.16666 Valid. err. 3.12443
2018-02-03 22:17:00,959 training [INFO ] Epoch 17 Batch 1700 Training err. 3.05252 Training err. RA 3.16532 Valid. err. 3.12270
2018-02-03 22:17:01,655 training [INFO ] Epoch 17 Batch 1720 Training err. 3.05557 Training err. RA 3.16404 Valid. err. 3.12034
2018-02-03 22:17:02,301 training [INFO ] Epoch 17 Batch 1740 Training err. 3.07443 Training err. RA 3.16301 Valid. err. 3.11455
2018-02-03 22:17:02,837 training [INFO ] Epoch 17 Batch 1760 Training err. 3.07248 Training err. RA 3.16198 Valid. err. 3.11005
2018-02-03 22:17:03,753 training [INFO ] Epoch 18 Batch 1780 Training err. 3.09199 Training err. RA 3.16120 Valid. err. 3.11570
2018-02-03 22:17:04,352 training [INFO ] Epoch 18 Batch 1800 Training err. 3.03018 Training err. RA 3.15974 Valid. err. 3.11575
2018-02-03 22:17:04,940 training [INFO ] Epoch 18 Batch 1820 Training err. 3.05581 Training err. RA 3.15860 Valid. err. 3.09932
2018-02-03 22:17:05,481 training [INFO ] Epoch 18 Batch 1840 Training err. 3.04470 Training err. RA 3.15736 Valid. err. 3.09400
2018-02-03 22:17:06,022 training [INFO ] Epoch 18 Batch 1860 Training err. 3.04826 Training err. RA 3.15619 Valid. err. 3.09206
2018-02-03 22:17:06,917 training [INFO ] Epoch 19 Batch 1880 Training err. 3.07203 Training err. RA 3.15529 Valid. err. 3.08260
2018-02-03 22:17:07,465 training [INFO ] Epoch 19 Batch 1900 Training err. 3.02093 Training err. RA 3.15388 Valid. err. 3.09183
2018-02-03 22:17:07,973 training [INFO ] Epoch 19 Batch 1920 Training err. 3.03589 Training err. RA 3.15265 Valid. err. 3.07435
2018-02-03 22:17:08,482 training [INFO ] Epoch 19 Batch 1940 Training err. 3.01221 Training err. RA 3.15120 Valid. err. 3.06811
2018-02-03 22:17:09,020 training [INFO ] Epoch 19 Batch 1960 Training err. 3.01981 Training err. RA 3.14986 Valid. err. 3.06233
2018-02-03 22:17:09,984 training [INFO ] Epoch 20 Batch 1980 Training err. 3.04797 Training err. RA 3.14883 Valid. err. 3.05871
2018-02-03 22:17:10,527 training [INFO ] Epoch 20 Batch 2000 Training err. 3.00625 Training err. RA 3.14741 Valid. err. 3.06614
2018-02-03 22:17:11,065 training [INFO ] Epoch 20 Batch 2020 Training err. 3.00592 Training err. RA 3.14601 Valid. err. 3.04452
2018-02-03 22:17:11,601 training [INFO ] Epoch 20 Batch 2040 Training err. 2.97025 Training err. RA 3.14428 Valid. err. 3.03767
2018-02-03 22:17:12,145 training [INFO ] Epoch 20 Batch 2060 Training err. 2.99783 Training err. RA 3.14286 Valid. err. 3.03066
2018-02-03 22:17:12,752 training [INFO ] Epoch 20 Batch 2080 Training err. 3.01325 Training err. RA 3.14161 Valid. err. 3.02270
2018-02-03 22:17:13,679 training [INFO ] Epoch 21 Batch 2100 Training err. 2.98579 Training err. RA 3.14013 Valid. err. 3.01726
2018-02-03 22:17:14,215 training [INFO ] Epoch 21 Batch 2120 Training err. 2.97086 Training err. RA 3.13853 Valid. err. 3.01170
2018-02-03 22:17:14,722 training [INFO ] Epoch 21 Batch 2140 Training err. 2.93158 Training err. RA 3.13660 Valid. err. 3.02587
2018-02-03 22:17:15,241 training [INFO ] Epoch 21 Batch 2160 Training err. 2.97115 Training err. RA 3.13507 Valid. err. 2.99657
2018-02-03 22:17:15,835 training [INFO ] Epoch 21 Batch 2180 Training err. 2.96939 Training err. RA 3.13355 Valid. err. 2.98589
2018-02-03 22:17:16,739 training [INFO ] Epoch 22 Batch 2200 Training err. 2.97053 Training err. RA 3.13207 Valid. err. 2.98352
2018-02-03 22:17:17,244 training [INFO ] Epoch 22 Batch 2220 Training err. 2.92620 Training err. RA 3.13021 Valid. err. 2.97700
2018-02-03 22:17:17,752 training [INFO ] Epoch 22 Batch 2240 Training err. 2.91335 Training err. RA 3.12827 Valid. err. 2.96923
2018-02-03 22:17:18,276 training [INFO ] Epoch 22 Batch 2260 Training err. 2.93896 Training err. RA 3.12660 Valid. err. 2.96021
2018-02-03 22:17:18,884 training [INFO ] Epoch 22 Batch 2280 Training err. 2.92512 Training err. RA 3.12483 Valid. err. 2.95361
2018-02-03 22:17:19,810 training [INFO ] Epoch 23 Batch 2300 Training err. 2.94713 Training err. RA 3.12329 Valid. err. 2.97647
2018-02-03 22:17:20,353 training [INFO ] Epoch 23 Batch 2320 Training err. 2.88723 Training err. RA 3.12125 Valid. err. 2.95226
2018-02-03 22:17:20,904 training [INFO ] Epoch 23 Batch 2340 Training err. 2.90112 Training err. RA 3.11937 Valid. err. 2.93597
2018-02-03 22:17:21,503 training [INFO ] Epoch 23 Batch 2360 Training err. 2.90074 Training err. RA 3.11752 Valid. err. 2.92919
2018-02-03 22:17:22,065 training [INFO ] Epoch 23 Batch 2380 Training err. 2.88512 Training err. RA 3.11556 Valid. err. 2.92373
2018-02-03 22:17:22,925 training [INFO ] Epoch 24 Batch 2400 Training err. 2.91497 Training err. RA 3.11389 Valid. err. 2.91289
2018-02-03 22:17:23,433 training [INFO ] Epoch 24 Batch 2420 Training err. 2.86627 Training err. RA 3.11185 Valid. err. 2.94500
2018-02-03 22:17:23,955 training [INFO ] Epoch 24 Batch 2440 Training err. 2.87856 Training err. RA 3.10993 Valid. err. 2.91594
2018-02-03 22:17:24,535 training [INFO ] Epoch 24 Batch 2460 Training err. 2.86183 Training err. RA 3.10792 Valid. err. 2.89514
2018-02-03 22:17:25,121 training [INFO ] Epoch 24 Batch 2480 Training err. 2.85240 Training err. RA 3.10586 Valid. err. 2.89007
2018-02-03 22:17:25,981 training [INFO ] Epoch 25 Batch 2500 Training err. 2.88388 Training err. RA 3.10408 Valid. err. 2.89872
2018-02-03 22:17:26,505 training [INFO ] Epoch 25 Batch 2520 Training err. 2.84834 Training err. RA 3.10205 Valid. err. 2.89442
2018-02-03 22:17:27,069 training [INFO ] Epoch 25 Batch 2540 Training err. 2.84702 Training err. RA 3.10004 Valid. err. 2.87881
2018-02-03 22:17:27,668 training [INFO ] Epoch 25 Batch 2560 Training err. 2.81880 Training err. RA 3.09785 Valid. err. 2.87605
2018-02-03 22:17:28,263 training [INFO ] Epoch 25 Batch 2580 Training err. 2.83174 Training err. RA 3.09578 Valid. err. 2.86020
2018-02-03 22:17:28,801 training [INFO ] Epoch 25 Batch 2600 Training err. 2.85357 Training err. RA 3.09392 Valid. err. 2.86244
2018-02-03 22:17:29,738 training [INFO ] Epoch 26 Batch 2620 Training err. 2.83317 Training err. RA 3.09193 Valid. err. 2.84922
2018-02-03 22:17:30,336 training [INFO ] Epoch 26 Batch 2640 Training err. 2.80721 Training err. RA 3.08977 Valid. err. 2.84709
2018-02-03 22:17:30,918 training [INFO ] Epoch 26 Batch 2660 Training err. 2.78259 Training err. RA 3.08746 Valid. err. 2.92115
2018-02-03 22:17:31,424 training [INFO ] Epoch 26 Batch 2680 Training err. 2.81773 Training err. RA 3.08545 Valid. err. 2.83364
2018-02-03 22:17:31,934 training [INFO ] Epoch 26 Batch 2700 Training err. 2.81286 Training err. RA 3.08343 Valid. err. 2.84137
2018-02-03 22:17:32,819 training [INFO ] Epoch 27 Batch 2720 Training err. 2.82226 Training err. RA 3.08151 Valid. err. 2.84044
2018-02-03 22:17:33,401 training [INFO ] Epoch 27 Batch 2740 Training err. 2.76636 Training err. RA 3.07921 Valid. err. 2.81893
2018-02-03 22:17:33,978 training [INFO ] Epoch 27 Batch 2760 Training err. 2.77379 Training err. RA 3.07700 Valid. err. 2.81377
2018-02-03 22:17:34,490 training [INFO ] Epoch 27 Batch 2780 Training err. 2.79080 Training err. RA 3.07494 Valid. err. 2.81584
2018-02-03 22:17:35,034 training [INFO ] Epoch 27 Batch 2800 Training err. 2.76697 Training err. RA 3.07274 Valid. err. 2.80879
2018-02-03 22:17:35,990 training [INFO ] Epoch 28 Batch 2820 Training err. 2.80641 Training err. RA 3.07085 Valid. err. 2.85438
2018-02-03 22:17:36,602 training [INFO ] Epoch 28 Batch 2840 Training err. 2.73356 Training err. RA 3.06847 Valid. err. 2.82453
2018-02-03 22:17:37,140 training [INFO ] Epoch 28 Batch 2860 Training err. 2.77123 Training err. RA 3.06640 Valid. err. 2.77962
2018-02-03 22:17:37,679 training [INFO ] Epoch 28 Batch 2880 Training err. 2.74979 Training err. RA 3.06420 Valid. err. 2.77966
2018-02-03 22:17:38,218 training [INFO ] Epoch 28 Batch 2900 Training err. 2.73449 Training err. RA 3.06192 Valid. err. 2.77094
2018-02-03 22:17:39,183 training [INFO ] Epoch 29 Batch 2920 Training err. 2.77644 Training err. RA 3.05997 Valid. err. 2.77770
2018-02-03 22:17:39,749 training [INFO ] Epoch 29 Batch 2940 Training err. 2.72405 Training err. RA 3.05768 Valid. err. 2.79633
2018-02-03 22:17:40,257 training [INFO ] Epoch 29 Batch 2960 Training err. 2.74503 Training err. RA 3.05557 Valid. err. 2.75958
2018-02-03 22:17:40,773 training [INFO ] Epoch 29 Batch 2980 Training err. 2.71214 Training err. RA 3.05326 Valid. err. 2.75350
2018-02-03 22:17:41,290 training [INFO ] Epoch 29 Batch 3000 Training err. 2.70536 Training err. RA 3.05095 Valid. err. 2.74357
2018-02-03 22:17:42,268 training [INFO ] Epoch 30 Batch 3020 Training err. 2.73688 Training err. RA 3.04887 Valid. err. 2.77973
2018-02-03 22:17:42,832 training [INFO ] Epoch 30 Batch 3040 Training err. 2.72531 Training err. RA 3.04674 Valid. err. 2.74637
2018-02-03 22:17:43,378 training [INFO ] Epoch 30 Batch 3060 Training err. 2.70109 Training err. RA 3.04448 Valid. err. 2.76120
2018-02-03 22:17:43,923 training [INFO ] Epoch 30 Batch 3080 Training err. 2.67124 Training err. RA 3.04205 Valid. err. 2.74826
2018-02-03 22:17:44,499 training [INFO ] Epoch 30 Batch 3100 Training err. 2.69286 Training err. RA 3.03980 Valid. err. 2.72750
2018-02-03 22:17:45,102 training [INFO ] Epoch 30 Batch 3120 Training err. 2.70932 Training err. RA 3.03768 Valid. err. 2.75388
2018-02-03 22:17:46,057 training [INFO ] Epoch 31 Batch 3140 Training err. 2.71480 Training err. RA 3.03563 Valid. err. 2.72381
2018-02-03 22:17:46,563 training [INFO ] Epoch 31 Batch 3160 Training err. 2.66402 Training err. RA 3.03327 Valid. err. 2.72111
2018-02-03 22:17:47,074 training [INFO ] Epoch 31 Batch 3180 Training err. 2.64955 Training err. RA 3.03086 Valid. err. 2.70703
2018-02-03 22:17:47,616 training [INFO ] Epoch 31 Batch 3200 Training err. 2.68241 Training err. RA 3.02868 Valid. err. 2.70286
2018-02-03 22:17:48,217 training [INFO ] Epoch 31 Batch 3220 Training err. 2.67488 Training err. RA 3.02649 Valid. err. 2.69566
2018-02-03 22:17:49,200 training [INFO ] Epoch 32 Batch 3240 Training err. 2.69470 Training err. RA 3.02444 Valid. err. 2.69361
2018-02-03 22:17:49,727 training [INFO ] Epoch 32 Batch 3260 Training err. 2.62742 Training err. RA 3.02200 Valid. err. 2.70448
2018-02-03 22:17:50,224 training [INFO ] Epoch 32 Batch 3280 Training err. 2.66227 Training err. RA 3.01981 Valid. err. 2.68645
2018-02-03 22:17:50,734 training [INFO ] Epoch 32 Batch 3300 Training err. 2.65699 Training err. RA 3.01761 Valid. err. 2.70842
2018-02-03 22:17:51,315 training [INFO ] Epoch 32 Batch 3320 Training err. 2.64155 Training err. RA 3.01534 Valid. err. 2.66851
2018-02-03 22:17:52,282 training [INFO ] Epoch 33 Batch 3340 Training err. 2.68167 Training err. RA 3.01335 Valid. err. 2.67146
2018-02-03 22:17:52,789 training [INFO ] Epoch 33 Batch 3360 Training err. 2.61292 Training err. RA 3.01096 Valid. err. 2.67497
2018-02-03 22:17:53,289 training [INFO ] Epoch 33 Batch 3380 Training err. 2.65633 Training err. RA 3.00886 Valid. err. 2.66102
2018-02-03 22:17:53,804 training [INFO ] Epoch 33 Batch 3400 Training err. 2.62165 Training err. RA 3.00659 Valid. err. 2.65835
2018-02-03 22:17:54,399 training [INFO ] Epoch 33 Batch 3420 Training err. 2.62566 Training err. RA 3.00436 Valid. err. 2.65569
2018-02-03 22:17:55,367 training [INFO ] Epoch 34 Batch 3440 Training err. 2.66064 Training err. RA 3.00236 Valid. err. 2.66040
2018-02-03 22:17:55,869 training [INFO ] Epoch 34 Batch 3460 Training err. 2.60383 Training err. RA 3.00006 Valid. err. 2.65439
2018-02-03 22:17:56,380 training [INFO ] Epoch 34 Batch 3480 Training err. 2.63663 Training err. RA 2.99797 Valid. err. 2.64577
2018-02-03 22:17:56,887 training [INFO ] Epoch 34 Batch 3500 Training err. 2.60066 Training err. RA 2.99570 Valid. err. 2.64872
2018-02-03 22:17:57,456 training [INFO ] Epoch 34 Batch 3520 Training err. 2.61008 Training err. RA 2.99351 Valid. err. 2.64472
2018-02-03 22:17:58,481 training [INFO ] Epoch 35 Batch 3540 Training err. 2.63161 Training err. RA 2.99146 Valid. err. 2.65922
2018-02-03 22:17:59,156 training [INFO ] Epoch 35 Batch 3560 Training err. 2.60959 Training err. RA 2.98932 Valid. err. 2.64276
2018-02-03 22:17:59,886 training [INFO ] Epoch 35 Batch 3580 Training err. 2.60437 Training err. RA 2.98717 Valid. err. 2.64347
2018-02-03 22:18:00,573 training [INFO ] Epoch 35 Batch 3600 Training err. 2.56964 Training err. RA 2.98485 Valid. err. 2.63182
2018-02-03 22:18:01,270 training [INFO ] Epoch 35 Batch 3620 Training err. 2.60013 Training err. RA 2.98272 Valid. err. 2.63868
2018-02-03 22:18:02,001 training [INFO ] Epoch 35 Batch 3640 Training err. 2.61999 Training err. RA 2.98073 Valid. err. 2.66163
2018-02-03 22:18:02,974 training [INFO ] Epoch 36 Batch 3660 Training err. 2.60501 Training err. RA 2.97867 Valid. err. 2.61764
2018-02-03 22:18:03,584 training [INFO ] Epoch 36 Batch 3680 Training err. 2.56745 Training err. RA 2.97644 Valid. err. 2.61803
2018-02-03 22:18:04,182 training [INFO ] Epoch 36 Batch 3700 Training err. 2.56006 Training err. RA 2.97419 Valid. err. 2.60705
2018-02-03 22:18:04,744 training [INFO ] Epoch 36 Batch 3720 Training err. 2.59487 Training err. RA 2.97215 Valid. err. 2.60245
2018-02-03 22:18:05,278 training [INFO ] Epoch 36 Batch 3740 Training err. 2.58501 Training err. RA 2.97008 Valid. err. 2.60559
2018-02-03 22:18:06,301 training [INFO ] Epoch 37 Batch 3760 Training err. 2.60001 Training err. RA 2.96811 Valid. err. 2.61084
2018-02-03 22:18:06,883 training [INFO ] Epoch 37 Batch 3780 Training err. 2.54219 Training err. RA 2.96586 Valid. err. 2.59904
2018-02-03 22:18:07,421 training [INFO ] Epoch 37 Batch 3800 Training err. 2.57113 Training err. RA 2.96378 Valid. err. 2.59446
2018-02-03 22:18:07,933 training [INFO ] Epoch 37 Batch 3820 Training err. 2.56781 Training err. RA 2.96171 Valid. err. 2.60356
2018-02-03 22:18:08,444 training [INFO ] Epoch 37 Batch 3840 Training err. 2.55677 Training err. RA 2.95960 Valid. err. 2.58536
2018-02-03 22:18:09,382 training [INFO ] Epoch 38 Batch 3860 Training err. 2.59468 Training err. RA 2.95771 Valid. err. 2.58098
2018-02-03 22:18:09,974 training [INFO ] Epoch 38 Batch 3880 Training err. 2.52160 Training err. RA 2.95546 Valid. err. 2.59199
2018-02-03 22:18:10,551 training [INFO ] Epoch 38 Batch 3900 Training err. 2.57277 Training err. RA 2.95350 Valid. err. 2.57618
2018-02-03 22:18:11,081 training [INFO ] Epoch 38 Batch 3920 Training err. 2.54163 Training err. RA 2.95140 Valid. err. 2.57916
2018-02-03 22:18:11,583 training [INFO ] Epoch 38 Batch 3940 Training err. 2.54257 Training err. RA 2.94932 Valid. err. 2.57129
2018-02-03 22:18:12,480 training [INFO ] Epoch 39 Batch 3960 Training err. 2.57408 Training err. RA 2.94743 Valid. err. 2.56996
2018-02-03 22:18:13,049 training [INFO ] Epoch 39 Batch 3980 Training err. 2.52808 Training err. RA 2.94532 Valid. err. 2.57570
2018-02-03 22:18:13,629 training [INFO ] Epoch 39 Batch 4000 Training err. 2.55205 Training err. RA 2.94335 Valid. err. 2.57088
2018-02-03 22:18:14,199 training [INFO ] Epoch 39 Batch 4020 Training err. 2.52412 Training err. RA 2.94127 Valid. err. 2.56869
2018-02-03 22:18:14,747 training [INFO ] Epoch 39 Batch 4040 Training err. 2.52747 Training err. RA 2.93922 Valid. err. 2.56961
2018-02-03 22:18:15,619 training [INFO ] Epoch 40 Batch 4060 Training err. 2.55173 Training err. RA 2.93731 Valid. err. 2.56696
2018-02-03 22:18:16,126 training [INFO ] Epoch 40 Batch 4080 Training err. 2.53588 Training err. RA 2.93534 Valid. err. 2.55635
2018-02-03 22:18:16,716 training [INFO ] Epoch 40 Batch 4100 Training err. 2.51905 Training err. RA 2.93331 Valid. err. 2.56490
2018-02-03 22:18:17,298 training [INFO ] Epoch 40 Batch 4120 Training err. 2.49841 Training err. RA 2.93120 Valid. err. 2.54486
2018-02-03 22:18:17,868 training [INFO ] Epoch 40 Batch 4140 Training err. 2.52218 Training err. RA 2.92922 Valid. err. 2.56562
2018-02-03 22:18:18,409 training [INFO ] Epoch 40 Batch 4160 Training err. 2.54461 Training err. RA 2.92737 Valid. err. 2.57191
2018-02-03 22:18:19,631 training [INFO ] Epoch 41 Batch 4180 Training err. 2.53405 Training err. RA 2.92549 Valid. err. 2.55265
2018-02-03 22:18:20,323 training [INFO ] Epoch 41 Batch 4200 Training err. 2.48332 Training err. RA 2.92339 Valid. err. 2.53802
2018-02-03 22:18:21,053 training [INFO ] Epoch 41 Batch 4220 Training err. 2.49181 Training err. RA 2.92134 Valid. err. 2.52985
2018-02-03 22:18:21,727 training [INFO ] Epoch 41 Batch 4240 Training err. 2.51816 Training err. RA 2.91944 Valid. err. 2.52878
2018-02-03 22:18:22,384 training [INFO ] Epoch 41 Batch 4260 Training err. 2.51427 Training err. RA 2.91754 Valid. err. 2.53625
2018-02-03 22:18:23,414 training [INFO ] Epoch 42 Batch 4280 Training err. 2.52878 Training err. RA 2.91572 Valid. err. 2.54898
2018-02-03 22:18:24,000 training [INFO ] Epoch 42 Batch 4300 Training err. 2.46526 Training err. RA 2.91363 Valid. err. 2.52411
2018-02-03 22:18:24,539 training [INFO ] Epoch 42 Batch 4320 Training err. 2.50356 Training err. RA 2.91173 Valid. err. 2.52651
2018-02-03 22:18:25,079 training [INFO ] Epoch 42 Batch 4340 Training err. 2.49605 Training err. RA 2.90981 Valid. err. 2.52761
2018-02-03 22:18:25,666 training [INFO ] Epoch 42 Batch 4360 Training err. 2.48692 Training err. RA 2.90787 Valid. err. 2.51475
2018-02-03 22:18:26,665 training [INFO ] Epoch 43 Batch 4380 Training err. 2.52482 Training err. RA 2.90612 Valid. err. 2.52083
2018-02-03 22:18:27,207 training [INFO ] Epoch 43 Batch 4400 Training err. 2.44998 Training err. RA 2.90405 Valid. err. 2.51007
2018-02-03 22:18:27,720 training [INFO ] Epoch 43 Batch 4420 Training err. 2.50546 Training err. RA 2.90225 Valid. err. 2.51111
2018-02-03 22:18:28,235 training [INFO ] Epoch 43 Batch 4440 Training err. 2.47422 Training err. RA 2.90032 Valid. err. 2.51017
2018-02-03 22:18:28,813 training [INFO ] Epoch 43 Batch 4460 Training err. 2.47508 Training err. RA 2.89841 Valid. err. 2.50352
2018-02-03 22:18:29,799 training [INFO ] Epoch 44 Batch 4480 Training err. 2.50421 Training err. RA 2.89665 Valid. err. 2.49862
2018-02-03 22:18:30,356 training [INFO ] Epoch 44 Batch 4500 Training err. 2.46266 Training err. RA 2.89472 Valid. err. 2.50043
2018-02-03 22:18:30,855 training [INFO ] Epoch 44 Batch 4520 Training err. 2.48388 Training err. RA 2.89290 Valid. err. 2.51179
2018-02-03 22:18:31,358 training [INFO ] Epoch 44 Batch 4540 Training err. 2.46155 Training err. RA 2.89100 Valid. err. 2.49909
2018-02-03 22:18:31,898 training [INFO ] Epoch 44 Batch 4560 Training err. 2.46206 Training err. RA 2.88912 Valid. err. 2.50808
2018-02-03 22:18:32,880 training [INFO ] Epoch 45 Batch 4580 Training err. 2.48375 Training err. RA 2.88735 Valid. err. 2.49832
2018-02-03 22:18:33,448 training [INFO ] Epoch 45 Batch 4600 Training err. 2.47355 Training err. RA 2.88555 Valid. err. 2.48966
2018-02-03 22:18:33,966 training [INFO ] Epoch 45 Batch 4620 Training err. 2.45243 Training err. RA 2.88368 Valid. err. 2.50311
2018-02-03 22:18:34,478 training [INFO ] Epoch 45 Batch 4640 Training err. 2.44011 Training err. RA 2.88177 Valid. err. 2.47816
2018-02-03 22:18:35,005 training [INFO ] Epoch 45 Batch 4660 Training err. 2.45778 Training err. RA 2.87995 Valid. err. 2.49495
2018-02-03 22:18:35,615 training [INFO ] Epoch 45 Batch 4680 Training err. 2.47872 Training err. RA 2.87823 Valid. err. 2.50313
2018-02-03 22:18:36,614 training [INFO ] Epoch 46 Batch 4700 Training err. 2.47343 Training err. RA 2.87651 Valid. err. 2.49059
2018-02-03 22:18:37,169 training [INFO ] Epoch 46 Batch 4720 Training err. 2.41924 Training err. RA 2.87457 Valid. err. 2.47313
2018-02-03 22:18:37,680 training [INFO ] Epoch 46 Batch 4740 Training err. 2.43470 Training err. RA 2.87272 Valid. err. 2.46759
2018-02-03 22:18:38,200 training [INFO ] Epoch 46 Batch 4760 Training err. 2.45688 Training err. RA 2.87097 Valid. err. 2.46640
2018-02-03 22:18:38,904 training [INFO ] Epoch 46 Batch 4780 Training err. 2.44915 Training err. RA 2.86920 Valid. err. 2.47117
2018-02-03 22:18:40,129 training [INFO ] Epoch 47 Batch 4800 Training err. 2.46708 Training err. RA 2.86753 Valid. err. 2.48752
2018-02-03 22:18:40,861 training [INFO ] Epoch 47 Batch 4820 Training err. 2.40605 Training err. RA 2.86561 Valid. err. 2.46967
2018-02-03 22:18:41,563 training [INFO ] Epoch 47 Batch 4840 Training err. 2.44628 Training err. RA 2.86388 Valid. err. 2.46509
2018-02-03 22:18:42,265 training [INFO ] Epoch 47 Batch 4860 Training err. 2.43601 Training err. RA 2.86212 Valid. err. 2.46900
2018-02-03 22:18:42,864 training [INFO ] Epoch 47 Batch 4880 Training err. 2.42554 Training err. RA 2.86033 Valid. err. 2.45154
2018-02-03 22:18:43,899 training [INFO ] Epoch 48 Batch 4900 Training err. 2.46392 Training err. RA 2.85871 Valid. err. 2.44937
2018-02-03 22:18:44,448 training [INFO ] Epoch 48 Batch 4920 Training err. 2.39095 Training err. RA 2.85681 Valid. err. 2.44923
2018-02-03 22:18:44,990 training [INFO ] Epoch 48 Batch 4940 Training err. 2.44887 Training err. RA 2.85516 Valid. err. 2.44960
2018-02-03 22:18:45,599 training [INFO ] Epoch 48 Batch 4960 Training err. 2.41715 Training err. RA 2.85339 Valid. err. 2.44910
2018-02-03 22:18:46,198 training [INFO ] Epoch 48 Batch 4980 Training err. 2.41599 Training err. RA 2.85164 Valid. err. 2.44306
2018-02-03 22:18:47,197 training [INFO ] Epoch 49 Batch 5000 Training err. 2.44342 Training err. RA 2.85000 Valid. err. 2.43903
2018-02-03 22:18:47,724 training [INFO ] Epoch 49 Batch 5020 Training err. 2.40556 Training err. RA 2.84823 Valid. err. 2.44409
2018-02-03 22:18:48,233 training [INFO ] Epoch 49 Batch 5040 Training err. 2.42821 Training err. RA 2.84657 Valid. err. 2.45542
2018-02-03 22:18:48,796 training [INFO ] Epoch 49 Batch 5060 Training err. 2.40560 Training err. RA 2.84482 Valid. err. 2.44735
2018-02-03 22:18:49,383 training [INFO ] Epoch 49 Batch 5080 Training err. 2.40529 Training err. RA 2.84309 Valid. err. 2.45204
2018-02-03 22:18:50,389 training [INFO ] Epoch 50 Batch 5100 Training err. 2.42312 Training err. RA 2.84145 Valid. err. 2.44999
2018-02-03 22:18:50,968 training [INFO ] Epoch 50 Batch 5120 Training err. 2.41803 Training err. RA 2.83979 Valid. err. 2.43565
2018-02-03 22:18:51,520 training [INFO ] Epoch 50 Batch 5140 Training err. 2.39681 Training err. RA 2.83807 Valid. err. 2.44963
2018-02-03 22:18:52,103 training [INFO ] Epoch 50 Batch 5160 Training err. 2.38599 Training err. RA 2.83632 Valid. err. 2.42221
2018-02-03 22:18:52,718 training [INFO ] Epoch 50 Batch 5180 Training err. 2.40156 Training err. RA 2.83464 Valid. err. 2.43849
2018-02-03 22:18:53,331 training [INFO ] Epoch 50 Batch 5200 Training err. 2.42038 Training err. RA 2.83304 Valid. err. 2.44241
2018-02-03 22:18:54,300 training [INFO ] Epoch 51 Batch 5220 Training err. 2.41783 Training err. RA 2.83145 Valid. err. 2.44224
2018-02-03 22:18:54,817 training [INFO ] Epoch 51 Batch 5240 Training err. 2.36485 Training err. RA 2.82967 Valid. err. 2.42028
2018-02-03 22:18:55,398 training [INFO ] Epoch 51 Batch 5260 Training err. 2.38171 Training err. RA 2.82797 Valid. err. 2.41426
2018-02-03 22:18:55,981 training [INFO ] Epoch 51 Batch 5280 Training err. 2.40264 Training err. RA 2.82636 Valid. err. 2.41353
2018-02-03 22:18:56,565 training [INFO ] Epoch 51 Batch 5300 Training err. 2.39460 Training err. RA 2.82473 Valid. err. 2.41442
2018-02-03 22:18:57,490 training [INFO ] Epoch 52 Batch 5320 Training err. 2.41163 Training err. RA 2.82318 Valid. err. 2.42975
2018-02-03 22:18:57,992 training [INFO ] Epoch 52 Batch 5340 Training err. 2.35302 Training err. RA 2.82141 Valid. err. 2.41655
2018-02-03 22:18:58,585 training [INFO ] Epoch 52 Batch 5360 Training err. 2.39301 Training err. RA 2.81982 Valid. err. 2.41300
2018-02-03 22:18:59,186 training [INFO ] Epoch 52 Batch 5380 Training err. 2.38330 Training err. RA 2.81819 Valid. err. 2.41805
2018-02-03 22:18:59,797 training [INFO ] Epoch 52 Batch 5400 Training err. 2.37387 Training err. RA 2.81655 Valid. err. 2.39711
2018-02-03 22:19:00,767 training [INFO ] Epoch 53 Batch 5420 Training err. 2.40879 Training err. RA 2.81504 Valid. err. 2.40411
2018-02-03 22:19:01,331 training [INFO ] Epoch 53 Batch 5440 Training err. 2.34097 Training err. RA 2.81330 Valid. err. 2.39687
2018-02-03 22:19:01,964 training [INFO ] Epoch 53 Batch 5460 Training err. 2.39434 Training err. RA 2.81177 Valid. err. 2.39718
2018-02-03 22:19:02,565 training [INFO ] Epoch 53 Batch 5480 Training err. 2.36553 Training err. RA 2.81014 Valid. err. 2.39563
2018-02-03 22:19:03,146 training [INFO ] Epoch 53 Batch 5500 Training err. 2.36547 Training err. RA 2.80852 Valid. err. 2.39075
2018-02-03 22:19:04,060 training [INFO ] Epoch 54 Batch 5520 Training err. 2.38835 Training err. RA 2.80700 Valid. err. 2.38869
2018-02-03 22:19:04,597 training [INFO ] Epoch 54 Batch 5540 Training err. 2.35644 Training err. RA 2.80537 Valid. err. 2.39147
2018-02-03 22:19:05,180 training [INFO ] Epoch 54 Batch 5560 Training err. 2.37548 Training err. RA 2.80382 Valid. err. 2.40443
2018-02-03 22:19:05,763 training [INFO ] Epoch 54 Batch 5580 Training err. 2.35449 Training err. RA 2.80221 Valid. err. 2.39200
2018-02-03 22:19:06,350 training [INFO ] Epoch 54 Batch 5600 Training err. 2.35641 Training err. RA 2.80062 Valid. err. 2.40687
2018-02-03 22:19:07,325 training [INFO ] Epoch 55 Batch 5620 Training err. 2.36943 Training err. RA 2.79909 Valid. err. 2.40089
2018-02-03 22:19:07,869 training [INFO ] Epoch 55 Batch 5640 Training err. 2.36950 Training err. RA 2.79756 Valid. err. 2.38478
2018-02-03 22:19:08,481 training [INFO ] Epoch 55 Batch 5660 Training err. 2.34402 Training err. RA 2.79596 Valid. err. 2.40229
2018-02-03 22:19:09,099 training [INFO ] Epoch 55 Batch 5680 Training err. 2.33815 Training err. RA 2.79435 Valid. err. 2.37612
2018-02-03 22:19:09,697 training [INFO ] Epoch 55 Batch 5700 Training err. 2.35231 Training err. RA 2.79280 Valid. err. 2.39425
2018-02-03 22:19:10,238 training [INFO ] Epoch 55 Batch 5720 Training err. 2.36844 Training err. RA 2.79131 Valid. err. 2.39239
2018-02-03 22:19:11,155 training [INFO ] Epoch 56 Batch 5740 Training err. 2.37194 Training err. RA 2.78985 Valid. err. 2.39271
2018-02-03 22:19:11,747 training [INFO ] Epoch 56 Batch 5760 Training err. 2.31337 Training err. RA 2.78820 Valid. err. 2.37016
2018-02-03 22:19:12,330 training [INFO ] Epoch 56 Batch 5780 Training err. 2.33254 Training err. RA 2.78662 Valid. err. 2.36834
2018-02-03 22:19:12,913 training [INFO ] Epoch 56 Batch 5800 Training err. 2.35410 Training err. RA 2.78513 Valid. err. 2.36502
2018-02-03 22:19:13,448 training [INFO ] Epoch 56 Batch 5820 Training err. 2.34573 Training err. RA 2.78362 Valid. err. 2.36468
2018-02-03 22:19:14,363 training [INFO ] Epoch 57 Batch 5840 Training err. 2.36368 Training err. RA 2.78218 Valid. err. 2.38221
2018-02-03 22:19:14,964 training [INFO ] Epoch 57 Batch 5860 Training err. 2.30537 Training err. RA 2.78056 Valid. err. 2.36629
2018-02-03 22:19:15,584 training [INFO ] Epoch 57 Batch 5880 Training err. 2.34223 Training err. RA 2.77906 Valid. err. 2.36647
2018-02-03 22:19:16,177 training [INFO ] Epoch 57 Batch 5900 Training err. 2.33619 Training err. RA 2.77756 Valid. err. 2.37153
2018-02-03 22:19:16,716 training [INFO ] Epoch 57 Batch 5920 Training err. 2.32713 Training err. RA 2.77604 Valid. err. 2.35010
2018-02-03 22:19:17,701 training [INFO ] Epoch 58 Batch 5940 Training err. 2.36081 Training err. RA 2.77464 Valid. err. 2.36018
2018-02-03 22:19:18,313 training [INFO ] Epoch 58 Batch 5960 Training err. 2.29537 Training err. RA 2.77303 Valid. err. 2.35062
2018-02-03 22:19:18,895 training [INFO ] Epoch 58 Batch 5980 Training err. 2.34312 Training err. RA 2.77160 Valid. err. 2.35086
2018-02-03 22:19:19,445 training [INFO ] Epoch 58 Batch 6000 Training err. 2.32121 Training err. RA 2.77010 Valid. err. 2.34888
2018-02-03 22:19:19,960 training [INFO ] Epoch 58 Batch 6020 Training err. 2.31893 Training err. RA 2.76860 Valid. err. 2.34522
2018-02-03 22:19:20,899 training [INFO ] Epoch 59 Batch 6040 Training err. 2.33864 Training err. RA 2.76717 Valid. err. 2.34531
2018-02-03 22:19:21,479 training [INFO ] Epoch 59 Batch 6060 Training err. 2.31279 Training err. RA 2.76567 Valid. err. 2.34572
2018-02-03 22:19:22,066 training [INFO ] Epoch 59 Batch 6080 Training err. 2.32488 Training err. RA 2.76422 Valid. err. 2.36518
2018-02-03 22:19:22,646 training [INFO ] Epoch 59 Batch 6100 Training err. 2.31110 Training err. RA 2.76274 Valid. err. 2.34406
2018-02-03 22:19:23,176 training [INFO ] Epoch 59 Batch 6120 Training err. 2.31131 Training err. RA 2.76126 Valid. err. 2.36722
2018-02-03 22:19:24,054 training [INFO ] Epoch 60 Batch 6140 Training err. 2.31972 Training err. RA 2.75982 Valid. err. 2.36475
2018-02-03 22:19:24,629 training [INFO ] Epoch 60 Batch 6160 Training err. 2.32690 Training err. RA 2.75842 Valid. err. 2.33933
2018-02-03 22:19:25,212 training [INFO ] Epoch 60 Batch 6180 Training err. 2.29500 Training err. RA 2.75692 Valid. err. 2.35001
2018-02-03 22:19:25,795 training [INFO ] Epoch 60 Batch 6200 Training err. 2.29456 Training err. RA 2.75543 Valid. err. 2.33775
2018-02-03 22:19:26,350 training [INFO ] Epoch 60 Batch 6220 Training err. 2.30599 Training err. RA 2.75398 Valid. err. 2.35826
2018-02-03 22:19:26,853 training [INFO ] Epoch 60 Batch 6240 Training err. 2.32110 Training err. RA 2.75260 Valid. err. 2.35098
2018-02-03 22:19:27,130 __main__ [INFO ] End of training
2018-02-03 22:19:27,420 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 22:19:28,150 training [INFO ] Epoch  1 Batch   20 Training err. 3.63647 Training err. RA 3.63647 Valid. err. 3.25046
2018-02-03 22:19:28,746 training [INFO ] Epoch  1 Batch   40 Training err. 3.17616 Training err. RA 3.40631 Valid. err. 3.19396
2018-02-03 22:19:29,332 training [INFO ] Epoch  1 Batch   60 Training err. 3.14429 Training err. RA 3.31897 Valid. err. 3.38954
2018-02-03 22:19:29,871 training [INFO ] Epoch  1 Batch   80 Training err. 3.16566 Training err. RA 3.28064 Valid. err. 3.18160
2018-02-03 22:19:30,384 training [INFO ] Epoch  1 Batch  100 Training err. 3.14525 Training err. RA 3.25356 Valid. err. 3.17036
2018-02-03 22:19:31,329 training [INFO ] Epoch  2 Batch  120 Training err. 3.14835 Training err. RA 3.23603 Valid. err. 3.17714
2018-02-03 22:19:31,906 training [INFO ] Epoch  2 Batch  140 Training err. 3.09946 Training err. RA 3.21652 Valid. err. 3.16291
2018-02-03 22:19:32,488 training [INFO ] Epoch  2 Batch  160 Training err. 3.09205 Training err. RA 3.20096 Valid. err. 3.16423
2018-02-03 22:19:33,067 training [INFO ] Epoch  2 Batch  180 Training err. 3.12471 Training err. RA 3.19249 Valid. err. 3.14002
2018-02-03 22:19:33,592 training [INFO ] Epoch  2 Batch  200 Training err. 3.09125 Training err. RA 3.18236 Valid. err. 3.12262
2018-02-03 22:19:34,512 training [INFO ] Epoch  3 Batch  220 Training err. 3.09681 Training err. RA 3.17459 Valid. err. 3.15947
2018-02-03 22:19:35,098 training [INFO ] Epoch  3 Batch  240 Training err. 3.03069 Training err. RA 3.16259 Valid. err. 3.11464
2018-02-03 22:19:35,680 training [INFO ] Epoch  3 Batch  260 Training err. 3.02917 Training err. RA 3.15233 Valid. err. 3.03350
2018-02-03 22:19:36,279 training [INFO ] Epoch  3 Batch  280 Training err. 2.99192 Training err. RA 3.14087 Valid. err. 2.98803
2018-02-03 22:19:36,830 training [INFO ] Epoch  3 Batch  300 Training err. 2.93729 Training err. RA 3.12730 Valid. err. 2.93684
2018-02-03 22:19:37,755 training [INFO ] Epoch  4 Batch  320 Training err. 2.92831 Training err. RA 3.11486 Valid. err. 2.90021
2018-02-03 22:19:38,349 training [INFO ] Epoch  4 Batch  340 Training err. 2.86050 Training err. RA 3.09990 Valid. err. 2.94683
2018-02-03 22:19:39,052 training [INFO ] Epoch  4 Batch  360 Training err. 2.83715 Training err. RA 3.08530 Valid. err. 2.83676
2018-02-03 22:19:39,762 training [INFO ] Epoch  4 Batch  380 Training err. 2.77187 Training err. RA 3.06881 Valid. err. 2.84979
2018-02-03 22:19:40,479 training [INFO ] Epoch  4 Batch  400 Training err. 2.75556 Training err. RA 3.05314 Valid. err. 2.75569
2018-02-03 22:19:41,711 training [INFO ] Epoch  5 Batch  420 Training err. 2.74987 Training err. RA 3.03870 Valid. err. 2.73636
2018-02-03 22:19:42,402 training [INFO ] Epoch  5 Batch  440 Training err. 2.69931 Training err. RA 3.02328 Valid. err. 2.69074
2018-02-03 22:19:43,012 training [INFO ] Epoch  5 Batch  460 Training err. 2.66794 Training err. RA 3.00783 Valid. err. 2.66503
2018-02-03 22:19:43,636 training [INFO ] Epoch  5 Batch  480 Training err. 2.59792 Training err. RA 2.99075 Valid. err. 2.62452
2018-02-03 22:19:44,246 training [INFO ] Epoch  5 Batch  500 Training err. 2.61485 Training err. RA 2.97571 Valid. err. 2.61120
2018-02-03 22:19:44,795 training [INFO ] Epoch  5 Batch  520 Training err. 2.60081 Training err. RA 2.96129 Valid. err. 2.57505
2018-02-03 22:19:45,777 training [INFO ] Epoch  6 Batch  540 Training err. 2.58198 Training err. RA 2.94724 Valid. err. 2.61407
2018-02-03 22:19:46,378 training [INFO ] Epoch  6 Batch  560 Training err. 2.51081 Training err. RA 2.93166 Valid. err. 2.58006
2018-02-03 22:19:46,961 training [INFO ] Epoch  6 Batch  580 Training err. 2.49656 Training err. RA 2.91665 Valid. err. 2.52271
2018-02-03 22:19:47,514 training [INFO ] Epoch  6 Batch  600 Training err. 2.49289 Training err. RA 2.90253 Valid. err. 2.55698
2018-02-03 22:19:48,022 training [INFO ] Epoch  6 Batch  620 Training err. 2.48540 Training err. RA 2.88907 Valid. err. 2.46101
2018-02-03 22:19:48,964 training [INFO ] Epoch  7 Batch  640 Training err. 2.47130 Training err. RA 2.87602 Valid. err. 2.53880
2018-02-03 22:19:49,546 training [INFO ] Epoch  7 Batch  660 Training err. 2.40478 Training err. RA 2.86174 Valid. err. 2.44269
2018-02-03 22:19:50,131 training [INFO ] Epoch  7 Batch  680 Training err. 2.42217 Training err. RA 2.84881 Valid. err. 2.49138
2018-02-03 22:19:50,729 training [INFO ] Epoch  7 Batch  700 Training err. 2.39453 Training err. RA 2.83583 Valid. err. 2.41518
2018-02-03 22:19:51,287 training [INFO ] Epoch  7 Batch  720 Training err. 2.36459 Training err. RA 2.82274 Valid. err. 2.42104
2018-02-03 22:19:52,251 training [INFO ] Epoch  8 Batch  740 Training err. 2.40004 Training err. RA 2.81131 Valid. err. 2.37805
2018-02-03 22:19:52,860 training [INFO ] Epoch  8 Batch  760 Training err. 2.31411 Training err. RA 2.79823 Valid. err. 2.38484
2018-02-03 22:19:53,462 training [INFO ] Epoch  8 Batch  780 Training err. 2.34010 Training err. RA 2.78648 Valid. err. 2.32941
2018-02-03 22:19:54,058 training [INFO ] Epoch  8 Batch  800 Training err. 2.31694 Training err. RA 2.77475 Valid. err. 2.31636
2018-02-03 22:19:54,581 training [INFO ] Epoch  8 Batch  820 Training err. 2.27982 Training err. RA 2.76267 Valid. err. 2.30434
2018-02-03 22:19:55,545 training [INFO ] Epoch  9 Batch  840 Training err. 2.30566 Training err. RA 2.75179 Valid. err. 2.29880
2018-02-03 22:19:56,132 training [INFO ] Epoch  9 Batch  860 Training err. 2.27290 Training err. RA 2.74066 Valid. err. 2.29213
2018-02-03 22:19:56,714 training [INFO ] Epoch  9 Batch  880 Training err. 2.24983 Training err. RA 2.72950 Valid. err. 2.31633
2018-02-03 22:19:57,297 training [INFO ] Epoch  9 Batch  900 Training err. 2.25347 Training err. RA 2.71892 Valid. err. 2.27600
2018-02-03 22:19:57,824 training [INFO ] Epoch  9 Batch  920 Training err. 2.21916 Training err. RA 2.70806 Valid. err. 2.26104
2018-02-03 22:19:58,797 training [INFO ] Epoch 10 Batch  940 Training err. 2.22111 Training err. RA 2.69770 Valid. err. 2.28984
2018-02-03 22:19:59,395 training [INFO ] Epoch 10 Batch  960 Training err. 2.23965 Training err. RA 2.68815 Valid. err. 2.24007
2018-02-03 22:19:59,985 training [INFO ] Epoch 10 Batch  980 Training err. 2.17486 Training err. RA 2.67768 Valid. err. 2.22204
2018-02-03 22:20:00,569 training [INFO ] Epoch 10 Batch 1000 Training err. 2.17831 Training err. RA 2.66769 Valid. err. 2.22409
2018-02-03 22:20:01,113 training [INFO ] Epoch 10 Batch 1020 Training err. 2.16968 Training err. RA 2.65793 Valid. err. 2.21267
2018-02-03 22:20:01,712 training [INFO ] Epoch 10 Batch 1040 Training err. 2.17099 Training err. RA 2.64856 Valid. err. 2.20171
2018-02-03 22:20:02,694 training [INFO ] Epoch 11 Batch 1060 Training err. 2.19382 Training err. RA 2.63998 Valid. err. 2.19169
2018-02-03 22:20:03,277 training [INFO ] Epoch 11 Batch 1080 Training err. 2.10478 Training err. RA 2.63007 Valid. err. 2.17234
2018-02-03 22:20:03,843 training [INFO ] Epoch 11 Batch 1100 Training err. 2.11961 Training err. RA 2.62079 Valid. err. 2.16648
2018-02-03 22:20:04,349 training [INFO ] Epoch 11 Batch 1120 Training err. 2.13834 Training err. RA 2.61217 Valid. err. 2.14938
2018-02-03 22:20:04,928 training [INFO ] Epoch 11 Batch 1140 Training err. 2.11366 Training err. RA 2.60343 Valid. err. 2.15086
2018-02-03 22:20:05,913 training [INFO ] Epoch 12 Batch 1160 Training err. 2.14389 Training err. RA 2.59551 Valid. err. 2.13849
2018-02-03 22:20:06,498 training [INFO ] Epoch 12 Batch 1180 Training err. 2.06277 Training err. RA 2.58648 Valid. err. 2.12885
2018-02-03 22:20:07,113 training [INFO ] Epoch 12 Batch 1200 Training err. 2.08415 Training err. RA 2.57810 Valid. err. 2.13222
2018-02-03 22:20:07,677 training [INFO ] Epoch 12 Batch 1220 Training err. 2.08492 Training err. RA 2.57002 Valid. err. 2.12181
2018-02-03 22:20:08,279 training [INFO ] Epoch 12 Batch 1240 Training err. 2.06676 Training err. RA 2.56190 Valid. err. 2.16660
2018-02-03 22:20:09,278 training [INFO ] Epoch 13 Batch 1260 Training err. 2.09030 Training err. RA 2.55442 Valid. err. 2.09262
2018-02-03 22:20:09,882 training [INFO ] Epoch 13 Batch 1280 Training err. 2.03129 Training err. RA 2.54624 Valid. err. 2.09785
2018-02-03 22:20:10,472 training [INFO ] Epoch 13 Batch 1300 Training err. 2.03500 Training err. RA 2.53838 Valid. err. 2.09580
2018-02-03 22:20:10,984 training [INFO ] Epoch 13 Batch 1320 Training err. 2.04763 Training err. RA 2.53094 Valid. err. 2.08685
2018-02-03 22:20:11,547 training [INFO ] Epoch 13 Batch 1340 Training err. 2.01675 Training err. RA 2.52327 Valid. err. 2.08123
2018-02-03 22:20:12,529 training [INFO ] Epoch 14 Batch 1360 Training err. 2.03998 Training err. RA 2.51616 Valid. err. 2.05159
2018-02-03 22:20:13,118 training [INFO ] Epoch 14 Batch 1380 Training err. 2.00996 Training err. RA 2.50882 Valid. err. 2.07367
2018-02-03 22:20:13,703 training [INFO ] Epoch 14 Batch 1400 Training err. 2.00485 Training err. RA 2.50162 Valid. err. 2.05667
2018-02-03 22:20:14,294 training [INFO ] Epoch 14 Batch 1420 Training err. 2.00563 Training err. RA 2.49464 Valid. err. 2.02743
2018-02-03 22:20:14,848 training [INFO ] Epoch 14 Batch 1440 Training err. 2.00022 Training err. RA 2.48777 Valid. err. 2.03768
2018-02-03 22:20:15,835 training [INFO ] Epoch 15 Batch 1460 Training err. 1.99850 Training err. RA 2.48107 Valid. err. 2.22790
2018-02-03 22:20:16,443 training [INFO ] Epoch 15 Batch 1480 Training err. 2.03537 Training err. RA 2.47505 Valid. err. 2.05460
2018-02-03 22:20:17,044 training [INFO ] Epoch 15 Batch 1500 Training err. 1.96009 Training err. RA 2.46818 Valid. err. 2.02739
2018-02-03 22:20:17,665 training [INFO ] Epoch 15 Batch 1520 Training err. 1.96874 Training err. RA 2.46161 Valid. err. 2.01294
2018-02-03 22:20:18,256 training [INFO ] Epoch 15 Batch 1540 Training err. 1.96967 Training err. RA 2.45522 Valid. err. 2.01384
2018-02-03 22:20:18,768 training [INFO ] Epoch 15 Batch 1560 Training err. 1.95656 Training err. RA 2.44883 Valid. err. 2.02952
2018-02-03 22:20:19,744 training [INFO ] Epoch 16 Batch 1580 Training err. 1.98152 Training err. RA 2.44291 Valid. err. 1.99756
2018-02-03 22:20:20,325 training [INFO ] Epoch 16 Batch 1600 Training err. 1.91015 Training err. RA 2.43625 Valid. err. 2.02406
2018-02-03 22:20:20,911 training [INFO ] Epoch 16 Batch 1620 Training err. 1.92983 Training err. RA 2.43000 Valid. err. 1.99469
2018-02-03 22:20:21,494 training [INFO ] Epoch 16 Batch 1640 Training err. 1.94874 Training err. RA 2.42413 Valid. err. 1.98935
2018-02-03 22:20:22,047 training [INFO ] Epoch 16 Batch 1660 Training err. 1.91940 Training err. RA 2.41805 Valid. err. 1.97247
2018-02-03 22:20:22,993 training [INFO ] Epoch 17 Batch 1680 Training err. 1.94145 Training err. RA 2.41238 Valid. err. 1.98994
2018-02-03 22:20:23,561 training [INFO ] Epoch 17 Batch 1700 Training err. 1.89491 Training err. RA 2.40629 Valid. err. 1.98903
2018-02-03 22:20:24,146 training [INFO ] Epoch 17 Batch 1720 Training err. 1.89886 Training err. RA 2.40039 Valid. err. 2.00223
2018-02-03 22:20:24,727 training [INFO ] Epoch 17 Batch 1740 Training err. 1.91164 Training err. RA 2.39477 Valid. err. 1.97082
2018-02-03 22:20:25,285 training [INFO ] Epoch 17 Batch 1760 Training err. 1.89415 Training err. RA 2.38908 Valid. err. 2.00137
2018-02-03 22:20:26,176 training [INFO ] Epoch 18 Batch 1780 Training err. 1.91670 Training err. RA 2.38377 Valid. err. 1.92535
2018-02-03 22:20:26,760 training [INFO ] Epoch 18 Batch 1800 Training err. 1.86435 Training err. RA 2.37800 Valid. err. 1.95180
2018-02-03 22:20:27,344 training [INFO ] Epoch 18 Batch 1820 Training err. 1.87665 Training err. RA 2.37249 Valid. err. 1.94121
2018-02-03 22:20:27,927 training [INFO ] Epoch 18 Batch 1840 Training err. 1.88059 Training err. RA 2.36715 Valid. err. 1.94779
2018-02-03 22:20:28,510 training [INFO ] Epoch 18 Batch 1860 Training err. 1.86574 Training err. RA 2.36175 Valid. err. 1.94803
2018-02-03 22:20:29,460 training [INFO ] Epoch 19 Batch 1880 Training err. 1.87049 Training err. RA 2.35653 Valid. err. 1.93115
2018-02-03 22:20:30,044 training [INFO ] Epoch 19 Batch 1900 Training err. 1.87176 Training err. RA 2.35143 Valid. err. 1.92600
2018-02-03 22:20:30,706 training [INFO ] Epoch 19 Batch 1920 Training err. 1.85486 Training err. RA 2.34625 Valid. err. 1.91948
2018-02-03 22:20:31,426 training [INFO ] Epoch 19 Batch 1940 Training err. 1.85559 Training err. RA 2.34119 Valid. err. 1.93016
2018-02-03 22:20:32,131 training [INFO ] Epoch 19 Batch 1960 Training err. 1.84208 Training err. RA 2.33610 Valid. err. 1.91944
2018-02-03 22:20:33,352 training [INFO ] Epoch 20 Batch 1980 Training err. 1.84110 Training err. RA 2.33110 Valid. err. 1.93038
2018-02-03 22:20:34,066 training [INFO ] Epoch 20 Batch 2000 Training err. 1.84944 Training err. RA 2.32628 Valid. err. 1.90442
2018-02-03 22:20:34,719 training [INFO ] Epoch 20 Batch 2020 Training err. 1.81575 Training err. RA 2.32123 Valid. err. 1.89301
2018-02-03 22:20:35,331 training [INFO ] Epoch 20 Batch 2040 Training err. 1.82372 Training err. RA 2.31635 Valid. err. 1.88826
2018-02-03 22:20:35,943 training [INFO ] Epoch 20 Batch 2060 Training err. 1.82507 Training err. RA 2.31158 Valid. err. 1.88898
2018-02-03 22:20:36,545 training [INFO ] Epoch 20 Batch 2080 Training err. 1.81910 Training err. RA 2.30685 Valid. err. 1.89289
2018-02-03 22:20:37,528 training [INFO ] Epoch 21 Batch 2100 Training err. 1.84021 Training err. RA 2.30240 Valid. err. 1.87179
2018-02-03 22:20:38,132 training [INFO ] Epoch 21 Batch 2120 Training err. 1.77252 Training err. RA 2.29740 Valid. err. 1.88023
2018-02-03 22:20:38,743 training [INFO ] Epoch 21 Batch 2140 Training err. 1.80513 Training err. RA 2.29280 Valid. err. 1.86974
2018-02-03 22:20:39,343 training [INFO ] Epoch 21 Batch 2160 Training err. 1.81243 Training err. RA 2.28836 Valid. err. 1.87724
2018-02-03 22:20:39,931 training [INFO ] Epoch 21 Batch 2180 Training err. 1.79061 Training err. RA 2.28379 Valid. err. 1.85594
2018-02-03 22:20:40,860 training [INFO ] Epoch 22 Batch 2200 Training err. 1.80743 Training err. RA 2.27946 Valid. err. 1.86199
2018-02-03 22:20:41,443 training [INFO ] Epoch 22 Batch 2220 Training err. 1.76103 Training err. RA 2.27479 Valid. err. 1.87112
2018-02-03 22:20:42,026 training [INFO ] Epoch 22 Batch 2240 Training err. 1.78285 Training err. RA 2.27040 Valid. err. 1.87053
2018-02-03 22:20:42,619 training [INFO ] Epoch 22 Batch 2260 Training err. 1.79371 Training err. RA 2.26618 Valid. err. 1.85980
2018-02-03 22:20:43,229 training [INFO ] Epoch 22 Batch 2280 Training err. 1.76948 Training err. RA 2.26182 Valid. err. 1.85754
2018-02-03 22:20:44,211 training [INFO ] Epoch 23 Batch 2300 Training err. 1.79209 Training err. RA 2.25774 Valid. err. 1.83131
2018-02-03 22:20:44,805 training [INFO ] Epoch 23 Batch 2320 Training err. 1.74120 Training err. RA 2.25328 Valid. err. 1.85156
2018-02-03 22:20:45,410 training [INFO ] Epoch 23 Batch 2340 Training err. 1.76233 Training err. RA 2.24909 Valid. err. 1.83106
2018-02-03 22:20:46,011 training [INFO ] Epoch 23 Batch 2360 Training err. 1.76663 Training err. RA 2.24500 Valid. err. 1.85924
2018-02-03 22:20:46,597 training [INFO ] Epoch 23 Batch 2380 Training err. 1.74795 Training err. RA 2.24082 Valid. err. 1.84207
2018-02-03 22:20:47,524 training [INFO ] Epoch 24 Batch 2400 Training err. 1.75200 Training err. RA 2.23675 Valid. err. 1.80929
2018-02-03 22:20:48,132 training [INFO ] Epoch 24 Batch 2420 Training err. 1.74312 Training err. RA 2.23267 Valid. err. 1.82652
2018-02-03 22:20:48,715 training [INFO ] Epoch 24 Batch 2440 Training err. 1.74365 Training err. RA 2.22866 Valid. err. 1.82453
2018-02-03 22:20:49,297 training [INFO ] Epoch 24 Batch 2460 Training err. 1.74423 Training err. RA 2.22472 Valid. err. 1.81588
2018-02-03 22:20:49,892 training [INFO ] Epoch 24 Batch 2480 Training err. 1.72918 Training err. RA 2.22072 Valid. err. 1.81330
2018-02-03 22:20:50,893 training [INFO ] Epoch 25 Batch 2500 Training err. 1.72918 Training err. RA 2.21679 Valid. err. 1.85414
2018-02-03 22:20:51,493 training [INFO ] Epoch 25 Batch 2520 Training err. 1.73698 Training err. RA 2.21298 Valid. err. 1.81509
2018-02-03 22:20:52,092 training [INFO ] Epoch 25 Batch 2540 Training err. 1.71350 Training err. RA 2.20905 Valid. err. 1.79846
2018-02-03 22:20:52,712 training [INFO ] Epoch 25 Batch 2560 Training err. 1.71996 Training err. RA 2.20523 Valid. err. 1.82026
2018-02-03 22:20:53,310 training [INFO ] Epoch 25 Batch 2580 Training err. 1.72089 Training err. RA 2.20148 Valid. err. 1.79330
2018-02-03 22:20:53,885 training [INFO ] Epoch 25 Batch 2600 Training err. 1.71205 Training err. RA 2.19771 Valid. err. 1.79395
2018-02-03 22:20:55,100 training [INFO ] Epoch 26 Batch 2620 Training err. 1.73320 Training err. RA 2.19417 Valid. err. 1.78268
2018-02-03 22:20:55,858 training [INFO ] Epoch 26 Batch 2640 Training err. 1.66805 Training err. RA 2.19018 Valid. err. 1.79494
2018-02-03 22:20:56,636 training [INFO ] Epoch 26 Batch 2660 Training err. 1.70107 Training err. RA 2.18650 Valid. err. 1.81111
2018-02-03 22:20:57,415 training [INFO ] Epoch 26 Batch 2680 Training err. 1.71174 Training err. RA 2.18296 Valid. err. 1.78276
2018-02-03 22:20:58,194 training [INFO ] Epoch 26 Batch 2700 Training err. 1.69004 Training err. RA 2.17931 Valid. err. 1.77705
2018-02-03 22:20:59,427 training [INFO ] Epoch 27 Batch 2720 Training err. 1.70548 Training err. RA 2.17582 Valid. err. 1.78696
2018-02-03 22:21:00,166 training [INFO ] Epoch 27 Batch 2740 Training err. 1.66709 Training err. RA 2.17211 Valid. err. 1.77633
2018-02-03 22:21:00,882 training [INFO ] Epoch 27 Batch 2760 Training err. 1.68996 Training err. RA 2.16862 Valid. err. 1.78158
2018-02-03 22:21:01,601 training [INFO ] Epoch 27 Batch 2780 Training err. 1.69227 Training err. RA 2.16519 Valid. err. 1.78306
2018-02-03 22:21:02,324 training [INFO ] Epoch 27 Batch 2800 Training err. 1.67479 Training err. RA 2.16169 Valid. err. 1.77915
2018-02-03 22:21:03,305 training [INFO ] Epoch 28 Batch 2820 Training err. 1.69993 Training err. RA 2.15841 Valid. err. 1.75269
2018-02-03 22:21:03,896 training [INFO ] Epoch 28 Batch 2840 Training err. 1.64746 Training err. RA 2.15481 Valid. err. 1.78805
2018-02-03 22:21:04,509 training [INFO ] Epoch 28 Batch 2860 Training err. 1.67601 Training err. RA 2.15147 Valid. err. 1.77114
2018-02-03 22:21:05,109 training [INFO ] Epoch 28 Batch 2880 Training err. 1.67973 Training err. RA 2.14819 Valid. err. 1.78501
2018-02-03 22:21:05,728 training [INFO ] Epoch 28 Batch 2900 Training err. 1.66030 Training err. RA 2.14482 Valid. err. 1.76732
2018-02-03 22:21:06,709 training [INFO ] Epoch 29 Batch 2920 Training err. 1.66345 Training err. RA 2.14153 Valid. err. 1.73897
2018-02-03 22:21:07,292 training [INFO ] Epoch 29 Batch 2940 Training err. 1.65062 Training err. RA 2.13819 Valid. err. 1.75879
2018-02-03 22:21:07,875 training [INFO ] Epoch 29 Batch 2960 Training err. 1.65650 Training err. RA 2.13493 Valid. err. 1.76257
2018-02-03 22:21:08,459 training [INFO ] Epoch 29 Batch 2980 Training err. 1.66757 Training err. RA 2.13180 Valid. err. 1.74099
2018-02-03 22:21:09,006 training [INFO ] Epoch 29 Batch 3000 Training err. 1.64005 Training err. RA 2.12852 Valid. err. 1.75536
2018-02-03 22:21:09,959 training [INFO ] Epoch 30 Batch 3020 Training err. 1.64474 Training err. RA 2.12531 Valid. err. 1.76026
2018-02-03 22:21:10,543 training [INFO ] Epoch 30 Batch 3040 Training err. 1.65135 Training err. RA 2.12220 Valid. err. 1.74583
2018-02-03 22:21:11,124 training [INFO ] Epoch 30 Batch 3060 Training err. 1.62637 Training err. RA 2.11896 Valid. err. 1.73442
2018-02-03 22:21:11,708 training [INFO ] Epoch 30 Batch 3080 Training err. 1.64055 Training err. RA 2.11585 Valid. err. 1.76103
2018-02-03 22:21:12,277 training [INFO ] Epoch 30 Batch 3100 Training err. 1.63667 Training err. RA 2.11276 Valid. err. 1.74147
2018-02-03 22:21:12,802 training [INFO ] Epoch 30 Batch 3120 Training err. 1.63230 Training err. RA 2.10968 Valid. err. 1.73319
2018-02-03 22:21:13,741 training [INFO ] Epoch 31 Batch 3140 Training err. 1.65185 Training err. RA 2.10676 Valid. err. 1.72488
2018-02-03 22:21:14,323 training [INFO ] Epoch 31 Batch 3160 Training err. 1.59367 Training err. RA 2.10351 Valid. err. 1.74506
2018-02-03 22:21:14,900 training [INFO ] Epoch 31 Batch 3180 Training err. 1.62423 Training err. RA 2.10050 Valid. err. 1.76249
2018-02-03 22:21:15,479 training [INFO ] Epoch 31 Batch 3200 Training err. 1.63242 Training err. RA 2.09757 Valid. err. 1.73099
2018-02-03 22:21:16,032 training [INFO ] Epoch 31 Batch 3220 Training err. 1.61938 Training err. RA 2.09460 Valid. err. 1.73066
2018-02-03 22:21:16,984 training [INFO ] Epoch 32 Batch 3240 Training err. 1.62881 Training err. RA 2.09173 Valid. err. 1.73404
2018-02-03 22:21:17,483 training [INFO ] Epoch 32 Batch 3260 Training err. 1.59115 Training err. RA 2.08866 Valid. err. 1.72312
2018-02-03 22:21:18,022 training [INFO ] Epoch 32 Batch 3280 Training err. 1.61482 Training err. RA 2.08577 Valid. err. 1.72092
2018-02-03 22:21:18,643 training [INFO ] Epoch 32 Batch 3300 Training err. 1.61883 Training err. RA 2.08294 Valid. err. 1.72048
2018-02-03 22:21:19,331 training [INFO ] Epoch 32 Batch 3320 Training err. 1.60493 Training err. RA 2.08006 Valid. err. 1.72697
2018-02-03 22:21:20,551 training [INFO ] Epoch 33 Batch 3340 Training err. 1.62381 Training err. RA 2.07733 Valid. err. 1.71474
2018-02-03 22:21:21,236 training [INFO ] Epoch 33 Batch 3360 Training err. 1.58000 Training err. RA 2.07437 Valid. err. 1.73876
2018-02-03 22:21:21,935 training [INFO ] Epoch 33 Batch 3380 Training err. 1.59691 Training err. RA 2.07154 Valid. err. 1.70932
2018-02-03 22:21:22,580 training [INFO ] Epoch 33 Batch 3400 Training err. 1.60991 Training err. RA 2.06883 Valid. err. 1.71789
2018-02-03 22:21:23,294 training [INFO ] Epoch 33 Batch 3420 Training err. 1.58864 Training err. RA 2.06602 Valid. err. 1.71190
2018-02-03 22:21:24,458 training [INFO ] Epoch 34 Batch 3440 Training err. 1.59326 Training err. RA 2.06327 Valid. err. 1.69207
2018-02-03 22:21:25,123 training [INFO ] Epoch 34 Batch 3460 Training err. 1.58498 Training err. RA 2.06050 Valid. err. 1.71399
2018-02-03 22:21:25,851 training [INFO ] Epoch 34 Batch 3480 Training err. 1.58777 Training err. RA 2.05779 Valid. err. 1.72041
2018-02-03 22:21:26,487 training [INFO ] Epoch 34 Batch 3500 Training err. 1.59821 Training err. RA 2.05516 Valid. err. 1.68681
2018-02-03 22:21:27,045 training [INFO ] Epoch 34 Batch 3520 Training err. 1.57263 Training err. RA 2.05242 Valid. err. 1.70241
2018-02-03 22:21:28,020 training [INFO ] Epoch 35 Batch 3540 Training err. 1.57237 Training err. RA 2.04971 Valid. err. 1.71227
2018-02-03 22:21:28,602 training [INFO ] Epoch 35 Batch 3560 Training err. 1.58318 Training err. RA 2.04709 Valid. err. 1.71090
2018-02-03 22:21:29,157 training [INFO ] Epoch 35 Batch 3580 Training err. 1.56431 Training err. RA 2.04439 Valid. err. 1.69690
2018-02-03 22:21:29,753 training [INFO ] Epoch 35 Batch 3600 Training err. 1.57426 Training err. RA 2.04178 Valid. err. 1.71160
2018-02-03 22:21:30,345 training [INFO ] Epoch 35 Batch 3620 Training err. 1.56922 Training err. RA 2.03917 Valid. err. 1.70407
2018-02-03 22:21:30,983 training [INFO ] Epoch 35 Batch 3640 Training err. 1.57011 Training err. RA 2.03659 Valid. err. 1.69096
2018-02-03 22:21:32,032 training [INFO ] Epoch 36 Batch 3660 Training err. 1.58643 Training err. RA 2.03413 Valid. err. 1.69013
2018-02-03 22:21:32,604 training [INFO ] Epoch 36 Batch 3680 Training err. 1.52686 Training err. RA 2.03137 Valid. err. 1.68699
2018-02-03 22:21:33,168 training [INFO ] Epoch 36 Batch 3700 Training err. 1.55778 Training err. RA 2.02881 Valid. err. 1.72322
2018-02-03 22:21:33,785 training [INFO ] Epoch 36 Batch 3720 Training err. 1.57051 Training err. RA 2.02635 Valid. err. 1.68389
2018-02-03 22:21:34,395 training [INFO ] Epoch 36 Batch 3740 Training err. 1.55346 Training err. RA 2.02382 Valid. err. 1.68286
2018-02-03 22:21:35,399 training [INFO ] Epoch 37 Batch 3760 Training err. 1.56381 Training err. RA 2.02137 Valid. err. 1.69010
2018-02-03 22:21:36,006 training [INFO ] Epoch 37 Batch 3780 Training err. 1.53445 Training err. RA 2.01880 Valid. err. 1.68367
2018-02-03 22:21:36,549 training [INFO ] Epoch 37 Batch 3800 Training err. 1.54942 Training err. RA 2.01633 Valid. err. 1.68235
2018-02-03 22:21:37,149 training [INFO ] Epoch 37 Batch 3820 Training err. 1.55590 Training err. RA 2.01392 Valid. err. 1.68732
2018-02-03 22:21:37,752 training [INFO ] Epoch 37 Batch 3840 Training err. 1.54343 Training err. RA 2.01147 Valid. err. 1.68469
2018-02-03 22:21:38,779 training [INFO ] Epoch 38 Batch 3860 Training err. 1.55661 Training err. RA 2.00911 Valid. err. 1.67281
2018-02-03 22:21:39,377 training [INFO ] Epoch 38 Batch 3880 Training err. 1.51807 Training err. RA 2.00658 Valid. err. 1.70435
2018-02-03 22:21:39,966 training [INFO ] Epoch 38 Batch 3900 Training err. 1.53639 Training err. RA 2.00417 Valid. err. 1.67811
2018-02-03 22:21:40,588 training [INFO ] Epoch 38 Batch 3920 Training err. 1.55145 Training err. RA 2.00186 Valid. err. 1.68408
2018-02-03 22:21:41,202 training [INFO ] Epoch 38 Batch 3940 Training err. 1.53190 Training err. RA 1.99947 Valid. err. 1.67377
2018-02-03 22:21:42,235 training [INFO ] Epoch 39 Batch 3960 Training err. 1.53237 Training err. RA 1.99711 Valid. err. 1.66003
2018-02-03 22:21:42,768 training [INFO ] Epoch 39 Batch 3980 Training err. 1.52700 Training err. RA 1.99475 Valid. err. 1.68489
2018-02-03 22:21:43,366 training [INFO ] Epoch 39 Batch 4000 Training err. 1.52729 Training err. RA 1.99241 Valid. err. 1.67933
2018-02-03 22:21:43,984 training [INFO ] Epoch 39 Batch 4020 Training err. 1.53988 Training err. RA 1.99016 Valid. err. 1.65139
2018-02-03 22:21:44,600 training [INFO ] Epoch 39 Batch 4040 Training err. 1.51844 Training err. RA 1.98783 Valid. err. 1.66375
2018-02-03 22:21:45,612 training [INFO ] Epoch 40 Batch 4060 Training err. 1.51520 Training err. RA 1.98550 Valid. err. 1.68035
2018-02-03 22:21:46,149 training [INFO ] Epoch 40 Batch 4080 Training err. 1.52751 Training err. RA 1.98325 Valid. err. 1.66901
2018-02-03 22:21:46,760 training [INFO ] Epoch 40 Batch 4100 Training err. 1.50468 Training err. RA 1.98092 Valid. err. 1.67341
2018-02-03 22:21:47,363 training [INFO ] Epoch 40 Batch 4120 Training err. 1.52059 Training err. RA 1.97868 Valid. err. 1.67322
2018-02-03 22:21:47,994 training [INFO ] Epoch 40 Batch 4140 Training err. 1.51576 Training err. RA 1.97645 Valid. err. 1.67036
2018-02-03 22:21:48,613 training [INFO ] Epoch 40 Batch 4160 Training err. 1.51114 Training err. RA 1.97421 Valid. err. 1.65864
2018-02-03 22:21:49,600 training [INFO ] Epoch 41 Batch 4180 Training err. 1.53152 Training err. RA 1.97209 Valid. err. 1.67065
2018-02-03 22:21:50,214 training [INFO ] Epoch 41 Batch 4200 Training err. 1.47552 Training err. RA 1.96973 Valid. err. 1.66331
2018-02-03 22:21:50,830 training [INFO ] Epoch 41 Batch 4220 Training err. 1.50937 Training err. RA 1.96755 Valid. err. 1.70286
2018-02-03 22:21:51,451 training [INFO ] Epoch 41 Batch 4240 Training err. 1.51769 Training err. RA 1.96542 Valid. err. 1.64989
2018-02-03 22:21:52,065 training [INFO ] Epoch 41 Batch 4260 Training err. 1.49923 Training err. RA 1.96323 Valid. err. 1.64442
2018-02-03 22:21:52,979 training [INFO ] Epoch 42 Batch 4280 Training err. 1.50993 Training err. RA 1.96112 Valid. err. 1.65954
2018-02-03 22:21:53,565 training [INFO ] Epoch 42 Batch 4300 Training err. 1.48200 Training err. RA 1.95889 Valid. err. 1.66265
2018-02-03 22:21:54,164 training [INFO ] Epoch 42 Batch 4320 Training err. 1.49978 Training err. RA 1.95676 Valid. err. 1.65471
2018-02-03 22:21:54,762 training [INFO ] Epoch 42 Batch 4340 Training err. 1.50323 Training err. RA 1.95467 Valid. err. 1.66886
2018-02-03 22:21:55,346 training [INFO ] Epoch 42 Batch 4360 Training err. 1.49083 Training err. RA 1.95254 Valid. err. 1.65143
2018-02-03 22:21:56,346 training [INFO ] Epoch 43 Batch 4380 Training err. 1.50467 Training err. RA 1.95050 Valid. err. 1.63948
2018-02-03 22:21:56,865 training [INFO ] Epoch 43 Batch 4400 Training err. 1.47168 Training err. RA 1.94832 Valid. err. 1.66521
2018-02-03 22:21:57,469 training [INFO ] Epoch 43 Batch 4420 Training err. 1.48910 Training err. RA 1.94625 Valid. err. 1.65109
2018-02-03 22:21:58,064 training [INFO ] Epoch 43 Batch 4440 Training err. 1.49941 Training err. RA 1.94423 Valid. err. 1.66182
2018-02-03 22:21:58,663 training [INFO ] Epoch 43 Batch 4460 Training err. 1.48286 Training err. RA 1.94216 Valid. err. 1.65601
2018-02-03 22:21:59,663 training [INFO ] Epoch 44 Batch 4480 Training err. 1.47765 Training err. RA 1.94009 Valid. err. 1.63537
2018-02-03 22:22:00,280 training [INFO ] Epoch 44 Batch 4500 Training err. 1.48125 Training err. RA 1.93805 Valid. err. 1.67066
2018-02-03 22:22:00,879 training [INFO ] Epoch 44 Batch 4520 Training err. 1.48062 Training err. RA 1.93603 Valid. err. 1.65686
2018-02-03 22:22:01,481 training [INFO ] Epoch 44 Batch 4540 Training err. 1.49049 Training err. RA 1.93406 Valid. err. 1.63444
2018-02-03 22:22:02,040 training [INFO ] Epoch 44 Batch 4560 Training err. 1.46640 Training err. RA 1.93201 Valid. err. 1.63541
2018-02-03 22:22:03,166 training [INFO ] Epoch 45 Batch 4580 Training err. 1.46384 Training err. RA 1.92997 Valid. err. 1.66095
2018-02-03 22:22:03,923 training [INFO ] Epoch 45 Batch 4600 Training err. 1.47894 Training err. RA 1.92801 Valid. err. 1.65844
2018-02-03 22:22:04,630 training [INFO ] Epoch 45 Batch 4620 Training err. 1.45923 Training err. RA 1.92598 Valid. err. 1.64439
2018-02-03 22:22:05,377 training [INFO ] Epoch 45 Batch 4640 Training err. 1.47320 Training err. RA 1.92403 Valid. err. 1.64664
2018-02-03 22:22:06,136 training [INFO ] Epoch 45 Batch 4660 Training err. 1.46913 Training err. RA 1.92207 Valid. err. 1.63222
2018-02-03 22:22:06,783 training [INFO ] Epoch 45 Batch 4680 Training err. 1.46068 Training err. RA 1.92010 Valid. err. 1.64079
2018-02-03 22:22:07,887 training [INFO ] Epoch 46 Batch 4700 Training err. 1.48451 Training err. RA 1.91825 Valid. err. 1.64168
2018-02-03 22:22:08,500 training [INFO ] Epoch 46 Batch 4720 Training err. 1.42631 Training err. RA 1.91616 Valid. err. 1.63983
2018-02-03 22:22:09,077 training [INFO ] Epoch 46 Batch 4740 Training err. 1.46562 Training err. RA 1.91426 Valid. err. 1.66393
2018-02-03 22:22:09,697 training [INFO ] Epoch 46 Batch 4760 Training err. 1.46699 Training err. RA 1.91238 Valid. err. 1.62490
2018-02-03 22:22:10,316 training [INFO ] Epoch 46 Batch 4780 Training err. 1.45304 Training err. RA 1.91046 Valid. err. 1.62721
2018-02-03 22:22:11,314 training [INFO ] Epoch 47 Batch 4800 Training err. 1.46033 Training err. RA 1.90859 Valid. err. 1.64178
2018-02-03 22:22:11,914 training [INFO ] Epoch 47 Batch 4820 Training err. 1.43385 Training err. RA 1.90662 Valid. err. 1.65377
2018-02-03 22:22:12,535 training [INFO ] Epoch 47 Batch 4840 Training err. 1.45472 Training err. RA 1.90475 Valid. err. 1.64252
2018-02-03 22:22:13,143 training [INFO ] Epoch 47 Batch 4860 Training err. 1.45885 Training err. RA 1.90291 Valid. err. 1.63381
2018-02-03 22:22:13,747 training [INFO ] Epoch 47 Batch 4880 Training err. 1.44508 Training err. RA 1.90104 Valid. err. 1.64947
2018-02-03 22:22:14,750 training [INFO ] Epoch 48 Batch 4900 Training err. 1.45637 Training err. RA 1.89922 Valid. err. 1.62925
2018-02-03 22:22:15,339 training [INFO ] Epoch 48 Batch 4920 Training err. 1.42981 Training err. RA 1.89731 Valid. err. 1.64955
2018-02-03 22:22:15,928 training [INFO ] Epoch 48 Batch 4940 Training err. 1.43824 Training err. RA 1.89546 Valid. err. 1.64621
2018-02-03 22:22:16,547 training [INFO ] Epoch 48 Batch 4960 Training err. 1.45311 Training err. RA 1.89367 Valid. err. 1.65553
2018-02-03 22:22:17,164 training [INFO ] Epoch 48 Batch 4980 Training err. 1.43377 Training err. RA 1.89183 Valid. err. 1.64284
2018-02-03 22:22:18,200 training [INFO ] Epoch 49 Batch 5000 Training err. 1.43535 Training err. RA 1.89000 Valid. err. 1.62289
2018-02-03 22:22:18,765 training [INFO ] Epoch 49 Batch 5020 Training err. 1.44328 Training err. RA 1.88822 Valid. err. 1.65393
2018-02-03 22:22:19,344 training [INFO ] Epoch 49 Batch 5040 Training err. 1.43670 Training err. RA 1.88643 Valid. err. 1.63705
2018-02-03 22:22:19,945 training [INFO ] Epoch 49 Batch 5060 Training err. 1.45499 Training err. RA 1.88472 Valid. err. 1.61286
2018-02-03 22:22:20,549 training [INFO ] Epoch 49 Batch 5080 Training err. 1.41749 Training err. RA 1.88288 Valid. err. 1.61686
2018-02-03 22:22:21,549 training [INFO ] Epoch 50 Batch 5100 Training err. 1.41879 Training err. RA 1.88106 Valid. err. 1.63431
2018-02-03 22:22:22,146 training [INFO ] Epoch 50 Batch 5120 Training err. 1.44330 Training err. RA 1.87935 Valid. err. 1.63801
2018-02-03 22:22:22,750 training [INFO ] Epoch 50 Batch 5140 Training err. 1.41128 Training err. RA 1.87753 Valid. err. 1.63312
2018-02-03 22:22:23,363 training [INFO ] Epoch 50 Batch 5160 Training err. 1.43136 Training err. RA 1.87580 Valid. err. 1.66576
2018-02-03 22:22:23,995 training [INFO ] Epoch 50 Batch 5180 Training err. 1.42244 Training err. RA 1.87405 Valid. err. 1.62921
2018-02-03 22:22:24,612 training [INFO ] Epoch 50 Batch 5200 Training err. 1.41858 Training err. RA 1.87230 Valid. err. 1.63334
2018-02-03 22:22:25,629 training [INFO ] Epoch 51 Batch 5220 Training err. 1.45194 Training err. RA 1.87069 Valid. err. 1.63101
2018-02-03 22:22:26,245 training [INFO ] Epoch 51 Batch 5240 Training err. 1.38372 Training err. RA 1.86883 Valid. err. 1.63288
2018-02-03 22:22:26,842 training [INFO ] Epoch 51 Batch 5260 Training err. 1.41648 Training err. RA 1.86711 Valid. err. 1.64675
2018-02-03 22:22:27,403 training [INFO ] Epoch 51 Batch 5280 Training err. 1.42750 Training err. RA 1.86545 Valid. err. 1.61238
2018-02-03 22:22:27,913 training [INFO ] Epoch 51 Batch 5300 Training err. 1.41021 Training err. RA 1.86373 Valid. err. 1.61885
2018-02-03 22:22:28,924 training [INFO ] Epoch 52 Batch 5320 Training err. 1.42110 Training err. RA 1.86206 Valid. err. 1.63503
2018-02-03 22:22:29,449 training [INFO ] Epoch 52 Batch 5340 Training err. 1.39432 Training err. RA 1.86031 Valid. err. 1.64265
2018-02-03 22:22:29,962 training [INFO ] Epoch 52 Batch 5360 Training err. 1.41836 Training err. RA 1.85866 Valid. err. 1.63615
2018-02-03 22:22:30,484 training [INFO ] Epoch 52 Batch 5380 Training err. 1.41682 Training err. RA 1.85702 Valid. err. 1.63092
2018-02-03 22:22:31,037 training [INFO ] Epoch 52 Batch 5400 Training err. 1.39908 Training err. RA 1.85532 Valid. err. 1.63259
2018-02-03 22:22:32,012 training [INFO ] Epoch 53 Batch 5420 Training err. 1.42268 Training err. RA 1.85373 Valid. err. 1.61838
2018-02-03 22:22:32,563 training [INFO ] Epoch 53 Batch 5440 Training err. 1.38969 Training err. RA 1.85202 Valid. err. 1.63103
2018-02-03 22:22:33,133 training [INFO ] Epoch 53 Batch 5460 Training err. 1.40090 Training err. RA 1.85037 Valid. err. 1.62779
2018-02-03 22:22:33,674 training [INFO ] Epoch 53 Batch 5480 Training err. 1.42077 Training err. RA 1.84880 Valid. err. 1.62706
2018-02-03 22:22:34,212 training [INFO ] Epoch 53 Batch 5500 Training err. 1.39010 Training err. RA 1.84713 Valid. err. 1.62776
2018-02-03 22:22:35,116 training [INFO ] Epoch 54 Batch 5520 Training err. 1.39552 Training err. RA 1.84550 Valid. err. 1.61459
2018-02-03 22:22:35,634 training [INFO ] Epoch 54 Batch 5540 Training err. 1.40175 Training err. RA 1.84390 Valid. err. 1.64952
2018-02-03 22:22:36,152 training [INFO ] Epoch 54 Batch 5560 Training err. 1.39073 Training err. RA 1.84227 Valid. err. 1.63437
2018-02-03 22:22:36,679 training [INFO ] Epoch 54 Batch 5580 Training err. 1.41247 Training err. RA 1.84072 Valid. err. 1.61509
2018-02-03 22:22:37,185 training [INFO ] Epoch 54 Batch 5600 Training err. 1.38229 Training err. RA 1.83909 Valid. err. 1.61074
2018-02-03 22:22:38,063 training [INFO ] Epoch 55 Batch 5620 Training err. 1.38270 Training err. RA 1.83746 Valid. err. 1.64155
2018-02-03 22:22:38,582 training [INFO ] Epoch 55 Batch 5640 Training err. 1.40224 Training err. RA 1.83592 Valid. err. 1.63225
2018-02-03 22:22:39,088 training [INFO ] Epoch 55 Batch 5660 Training err. 1.38088 Training err. RA 1.83431 Valid. err. 1.63134
2018-02-03 22:22:39,600 training [INFO ] Epoch 55 Batch 5680 Training err. 1.39826 Training err. RA 1.83278 Valid. err. 1.64588
2018-02-03 22:22:40,111 training [INFO ] Epoch 55 Batch 5700 Training err. 1.38980 Training err. RA 1.83122 Valid. err. 1.62845
2018-02-03 22:22:40,617 training [INFO ] Epoch 55 Batch 5720 Training err. 1.38104 Training err. RA 1.82965 Valid. err. 1.61653
2018-02-03 22:22:41,460 training [INFO ] Epoch 56 Batch 5740 Training err. 1.40561 Training err. RA 1.82817 Valid. err. 1.62825
2018-02-03 22:22:41,959 training [INFO ] Epoch 56 Batch 5760 Training err. 1.34498 Training err. RA 1.82649 Valid. err. 1.64130
2018-02-03 22:22:42,476 training [INFO ] Epoch 56 Batch 5780 Training err. 1.38239 Training err. RA 1.82496 Valid. err. 1.63943
2018-02-03 22:22:42,987 training [INFO ] Epoch 56 Batch 5800 Training err. 1.38851 Training err. RA 1.82345 Valid. err. 1.61797
2018-02-03 22:22:43,504 training [INFO ] Epoch 56 Batch 5820 Training err. 1.37236 Training err. RA 1.82190 Valid. err. 1.62972
2018-02-03 22:22:44,365 training [INFO ] Epoch 57 Batch 5840 Training err. 1.38668 Training err. RA 1.82041 Valid. err. 1.63868
2018-02-03 22:22:44,871 training [INFO ] Epoch 57 Batch 5860 Training err. 1.35687 Training err. RA 1.81883 Valid. err. 1.63222
2018-02-03 22:22:45,384 training [INFO ] Epoch 57 Batch 5880 Training err. 1.38141 Training err. RA 1.81734 Valid. err. 1.63832
2018-02-03 22:22:45,895 training [INFO ] Epoch 57 Batch 5900 Training err. 1.37940 Training err. RA 1.81586 Valid. err. 1.62367
2018-02-03 22:22:46,408 training [INFO ] Epoch 57 Batch 5920 Training err. 1.37042 Training err. RA 1.81435 Valid. err. 1.62309
2018-02-03 22:22:47,557 training [INFO ] Epoch 58 Batch 5940 Training err. 1.38063 Training err. RA 1.81289 Valid. err. 1.61332
2018-02-03 22:22:48,228 training [INFO ] Epoch 58 Batch 5960 Training err. 1.35641 Training err. RA 1.81136 Valid. err. 1.62526
2018-02-03 22:22:48,896 training [INFO ] Epoch 58 Batch 5980 Training err. 1.36323 Training err. RA 1.80986 Valid. err. 1.63187
2018-02-03 22:22:49,602 training [INFO ] Epoch 58 Batch 6000 Training err. 1.37971 Training err. RA 1.80843 Valid. err. 1.63562
2018-02-03 22:22:50,301 training [INFO ] Epoch 58 Batch 6020 Training err. 1.35850 Training err. RA 1.80693 Valid. err. 1.63997
2018-02-03 22:22:51,300 training [INFO ] Epoch 59 Batch 6040 Training err. 1.36280 Training err. RA 1.80546 Valid. err. 1.62627
2018-02-03 22:22:51,905 training [INFO ] Epoch 59 Batch 6060 Training err. 1.36650 Training err. RA 1.80401 Valid. err. 1.63322
2018-02-03 22:22:52,444 training [INFO ] Epoch 59 Batch 6080 Training err. 1.35713 Training err. RA 1.80254 Valid. err. 1.63026
2018-02-03 22:22:52,978 training [INFO ] Epoch 59 Batch 6100 Training err. 1.37634 Training err. RA 1.80115 Valid. err. 1.61153
2018-02-03 22:22:53,523 training [INFO ] Epoch 59 Batch 6120 Training err. 1.34511 Training err. RA 1.79965 Valid. err. 1.61247
2018-02-03 22:22:54,443 training [INFO ] Epoch 60 Batch 6140 Training err. 1.35213 Training err. RA 1.79820 Valid. err. 1.64395
2018-02-03 22:22:54,949 training [INFO ] Epoch 60 Batch 6160 Training err. 1.36714 Training err. RA 1.79680 Valid. err. 1.63418
2018-02-03 22:22:55,464 training [INFO ] Epoch 60 Batch 6180 Training err. 1.34310 Training err. RA 1.79533 Valid. err. 1.63547
2018-02-03 22:22:55,973 training [INFO ] Epoch 60 Batch 6200 Training err. 1.35716 Training err. RA 1.79392 Valid. err. 1.63904
2018-02-03 22:22:56,480 training [INFO ] Epoch 60 Batch 6220 Training err. 1.35644 Training err. RA 1.79251 Valid. err. 1.61317
2018-02-03 22:22:56,984 training [INFO ] Epoch 60 Batch 6240 Training err. 1.34983 Training err. RA 1.79109 Valid. err. 1.62094
2018-02-03 22:22:57,230 __main__ [INFO ] End of training
2018-02-03 22:22:57,551 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 10,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 22:22:58,226 training [INFO ] Epoch  1 Batch   20 Training err. 25.77136 Training err. RA 25.77136 Valid. err. 117.28146
2018-02-03 22:22:58,774 training [INFO ] Epoch  1 Batch   40 Training err. 136.58561 Training err. RA 81.17848 Valid. err. 142.52658
2018-02-03 22:22:59,342 training [INFO ] Epoch  1 Batch   60 Training err. 145.15436 Training err. RA 102.50377 Valid. err. 152.82837
2018-02-03 22:22:59,906 training [INFO ] Epoch  1 Batch   80 Training err. 142.29381 Training err. RA 112.45128 Valid. err. 116.79444
2018-02-03 22:23:00,477 training [INFO ] Epoch  1 Batch  100 Training err. 137.59993 Training err. RA 117.48101 Valid. err. 140.94928
2018-02-03 22:23:01,447 training [INFO ] Epoch  2 Batch  120 Training err. 150.00782 Training err. RA 122.90215 Valid. err. 134.22075
2018-02-03 22:23:02,020 training [INFO ] Epoch  2 Batch  140 Training err. 148.54266 Training err. RA 126.56508 Valid. err. 120.02328
2018-02-03 22:23:02,589 training [INFO ] Epoch  2 Batch  160 Training err. 137.70540 Training err. RA 127.95762 Valid. err. 130.08618
2018-02-03 22:23:03,132 training [INFO ] Epoch  2 Batch  180 Training err. 149.23230 Training err. RA 130.32147 Valid. err. 123.98112
2018-02-03 22:23:03,679 training [INFO ] Epoch  2 Batch  200 Training err. 130.19496 Training err. RA 130.30882 Valid. err. 107.04776
2018-02-03 22:23:04,586 training [INFO ] Epoch  3 Batch  220 Training err. 137.98028 Training err. RA 131.00623 Valid. err. 105.93559
2018-02-03 22:23:05,127 training [INFO ] Epoch  3 Batch  240 Training err. 131.77273 Training err. RA 131.07010 Valid. err. 147.93177
2018-02-03 22:23:05,663 training [INFO ] Epoch  3 Batch  260 Training err. 153.01923 Training err. RA 132.75850 Valid. err. 118.08980
2018-02-03 22:23:06,201 training [INFO ] Epoch  3 Batch  280 Training err. 138.30522 Training err. RA 133.15469 Valid. err. 139.65862
2018-02-03 22:23:06,723 training [INFO ] Epoch  3 Batch  300 Training err. 120.19375 Training err. RA 132.29063 Valid. err. 104.51943
2018-02-03 22:23:07,683 training [INFO ] Epoch  4 Batch  320 Training err. 129.15329 Training err. RA 132.09454 Valid. err. 129.35128
2018-02-03 22:23:08,279 training [INFO ] Epoch  4 Batch  340 Training err. 137.36065 Training err. RA 132.40431 Valid. err. 161.79022
2018-02-03 22:23:08,977 training [INFO ] Epoch  4 Batch  360 Training err. 122.25705 Training err. RA 131.84058 Valid. err. 142.94066
2018-02-03 22:23:09,632 training [INFO ] Epoch  4 Batch  380 Training err. 120.27978 Training err. RA 131.23211 Valid. err. 143.82636
2018-02-03 22:23:10,330 training [INFO ] Epoch  4 Batch  400 Training err. 126.24693 Training err. RA 130.98286 Valid. err. 147.54256
2018-02-03 22:23:11,489 training [INFO ] Epoch  5 Batch  420 Training err. 119.65876 Training err. RA 130.44361 Valid. err. 135.26410
2018-02-03 22:23:12,109 training [INFO ] Epoch  5 Batch  440 Training err. 136.78115 Training err. RA 130.73168 Valid. err. 117.90888
2018-02-03 22:23:12,716 training [INFO ] Epoch  5 Batch  460 Training err. 120.78368 Training err. RA 130.29916 Valid. err. 130.52161
2018-02-03 22:23:13,302 training [INFO ] Epoch  5 Batch  480 Training err. 120.36160 Training err. RA 129.88510 Valid. err. 127.69028
2018-02-03 22:23:13,865 training [INFO ] Epoch  5 Batch  500 Training err. 109.96956 Training err. RA 129.08847 Valid. err. 162.84103
2018-02-03 22:23:14,479 training [INFO ] Epoch  5 Batch  520 Training err. 132.41039 Training err. RA 129.21624 Valid. err. 143.88409
2018-02-03 22:23:15,977 training [INFO ] Epoch  6 Batch  540 Training err. 128.87715 Training err. RA 129.20368 Valid. err. 121.99688
2018-02-03 22:23:16,880 training [INFO ] Epoch  6 Batch  560 Training err. 128.26658 Training err. RA 129.17021 Valid. err. 88.04081
2018-02-03 22:23:17,674 training [INFO ] Epoch  6 Batch  580 Training err. 122.88507 Training err. RA 128.95348 Valid. err. 160.04639
2018-02-03 22:23:18,459 training [INFO ] Epoch  6 Batch  600 Training err. 114.69055 Training err. RA 128.47805 Valid. err. 101.19996
2018-02-03 22:23:19,088 training [INFO ] Epoch  6 Batch  620 Training err. 108.01981 Training err. RA 127.81811 Valid. err. 119.88147
2018-02-03 22:23:20,048 training [INFO ] Epoch  7 Batch  640 Training err. 121.77095 Training err. RA 127.62914 Valid. err. 157.85652
2018-02-03 22:23:20,607 training [INFO ] Epoch  7 Batch  660 Training err. 124.45823 Training err. RA 127.53305 Valid. err. 111.14529
2018-02-03 22:23:21,164 training [INFO ] Epoch  7 Batch  680 Training err. 111.31899 Training err. RA 127.05616 Valid. err. 116.97590
2018-02-03 22:23:21,745 training [INFO ] Epoch  7 Batch  700 Training err. 110.37775 Training err. RA 126.57964 Valid. err. 113.83906
2018-02-03 22:23:22,317 training [INFO ] Epoch  7 Batch  720 Training err. 119.64353 Training err. RA 126.38697 Valid. err. 87.46390
2018-02-03 22:23:23,240 training [INFO ] Epoch  8 Batch  740 Training err. 109.96492 Training err. RA 125.94313 Valid. err. 105.67822
2018-02-03 22:23:23,805 training [INFO ] Epoch  8 Batch  760 Training err. 118.56053 Training err. RA 125.74885 Valid. err. 79.59614
2018-02-03 22:23:24,357 training [INFO ] Epoch  8 Batch  780 Training err. 105.35554 Training err. RA 125.22595 Valid. err. 102.89409
2018-02-03 22:23:24,942 training [INFO ] Epoch  8 Batch  800 Training err. 127.84191 Training err. RA 125.29134 Valid. err. 93.93873
2018-02-03 22:23:25,510 training [INFO ] Epoch  8 Batch  820 Training err. 129.06287 Training err. RA 125.38333 Valid. err. 149.77603
2018-02-03 22:23:26,411 training [INFO ] Epoch  9 Batch  840 Training err. 119.52097 Training err. RA 125.24375 Valid. err. 137.16166
2018-02-03 22:23:26,934 training [INFO ] Epoch  9 Batch  860 Training err. 109.03907 Training err. RA 124.86690 Valid. err. 100.79958
2018-02-03 22:23:27,471 training [INFO ] Epoch  9 Batch  880 Training err. 111.31003 Training err. RA 124.55879 Valid. err. 143.69713
2018-02-03 22:23:28,073 training [INFO ] Epoch  9 Batch  900 Training err. 124.52004 Training err. RA 124.55793 Valid. err. 104.15171
2018-02-03 22:23:28,637 training [INFO ] Epoch  9 Batch  920 Training err. 114.20786 Training err. RA 124.33293 Valid. err. 114.43076
2018-02-03 22:23:29,576 training [INFO ] Epoch 10 Batch  940 Training err. 119.49427 Training err. RA 124.22998 Valid. err. 128.91864
2018-02-03 22:23:30,100 training [INFO ] Epoch 10 Batch  960 Training err. 112.35832 Training err. RA 123.98265 Valid. err. 83.45582
2018-02-03 22:23:30,677 training [INFO ] Epoch 10 Batch  980 Training err. 110.36237 Training err. RA 123.70469 Valid. err. 114.07984
2018-02-03 22:23:31,243 training [INFO ] Epoch 10 Batch 1000 Training err. 117.58813 Training err. RA 123.58235 Valid. err. 136.23110
2018-02-03 22:23:31,775 training [INFO ] Epoch 10 Batch 1020 Training err. 114.64616 Training err. RA 123.40713 Valid. err. 147.89853
2018-02-03 22:23:32,312 training [INFO ] Epoch 10 Batch 1040 Training err. 119.03912 Training err. RA 123.32313 Valid. err. 105.10742
2018-02-03 22:23:33,217 training [INFO ] Epoch 11 Batch 1060 Training err. 130.30930 Training err. RA 123.45495 Valid. err. 109.53943
2018-02-03 22:23:33,822 training [INFO ] Epoch 11 Batch 1080 Training err. 109.87146 Training err. RA 123.20340 Valid. err. 111.23311
2018-02-03 22:23:34,350 training [INFO ] Epoch 11 Batch 1100 Training err. 121.08208 Training err. RA 123.16483 Valid. err. 146.55369
2018-02-03 22:23:34,977 training [INFO ] Epoch 11 Batch 1120 Training err. 102.95145 Training err. RA 122.80388 Valid. err. 91.78932
2018-02-03 22:23:35,681 training [INFO ] Epoch 11 Batch 1140 Training err. 116.55931 Training err. RA 122.69433 Valid. err. 93.99540
2018-02-03 22:23:36,918 training [INFO ] Epoch 12 Batch 1160 Training err. 114.23689 Training err. RA 122.54851 Valid. err. 95.98599
2018-02-03 22:23:37,641 training [INFO ] Epoch 12 Batch 1180 Training err. 104.19021 Training err. RA 122.23735 Valid. err. 123.31405
2018-02-03 22:23:38,323 training [INFO ] Epoch 12 Batch 1200 Training err. 96.79657 Training err. RA 121.81334 Valid. err. 121.98705
2018-02-03 22:23:38,912 training [INFO ] Epoch 12 Batch 1220 Training err. 126.17973 Training err. RA 121.88492 Valid. err. 132.25894
2018-02-03 22:23:39,523 training [INFO ] Epoch 12 Batch 1240 Training err. 116.70943 Training err. RA 121.80144 Valid. err. 114.19815
2018-02-03 22:23:40,691 training [INFO ] Epoch 13 Batch 1260 Training err. 99.48719 Training err. RA 121.44725 Valid. err. 97.27025
2018-02-03 22:23:41,252 training [INFO ] Epoch 13 Batch 1280 Training err. 109.60315 Training err. RA 121.26218 Valid. err. 120.08284
2018-02-03 22:23:41,824 training [INFO ] Epoch 13 Batch 1300 Training err. 103.46272 Training err. RA 120.98835 Valid. err. 112.24740
2018-02-03 22:23:42,401 training [INFO ] Epoch 13 Batch 1320 Training err. 113.27678 Training err. RA 120.87150 Valid. err. 134.98950
2018-02-03 22:23:42,994 training [INFO ] Epoch 13 Batch 1340 Training err. 114.11718 Training err. RA 120.77069 Valid. err. 95.56559
2018-02-03 22:23:43,972 training [INFO ] Epoch 14 Batch 1360 Training err. 111.09248 Training err. RA 120.62837 Valid. err. 135.82254
2018-02-03 22:23:44,610 training [INFO ] Epoch 14 Batch 1380 Training err. 100.59388 Training err. RA 120.33801 Valid. err. 113.90699
2018-02-03 22:23:45,195 training [INFO ] Epoch 14 Batch 1400 Training err. 100.96246 Training err. RA 120.06122 Valid. err. 116.50216
2018-02-03 22:23:45,768 training [INFO ] Epoch 14 Batch 1420 Training err. 99.17534 Training err. RA 119.76705 Valid. err. 83.12807
2018-02-03 22:23:46,358 training [INFO ] Epoch 14 Batch 1440 Training err. 103.51120 Training err. RA 119.54128 Valid. err. 130.29252
2018-02-03 22:23:47,388 training [INFO ] Epoch 15 Batch 1460 Training err. 110.25517 Training err. RA 119.41407 Valid. err. 140.33368
2018-02-03 22:23:48,140 training [INFO ] Epoch 15 Batch 1480 Training err. 108.62908 Training err. RA 119.26833 Valid. err. 104.55134
2018-02-03 22:23:48,752 training [INFO ] Epoch 15 Batch 1500 Training err. 106.68103 Training err. RA 119.10049 Valid. err. 104.55630
2018-02-03 22:23:49,371 training [INFO ] Epoch 15 Batch 1520 Training err. 114.54189 Training err. RA 119.04051 Valid. err. 120.31269
2018-02-03 22:23:50,004 training [INFO ] Epoch 15 Batch 1540 Training err. 115.39853 Training err. RA 118.99321 Valid. err. 108.60014
2018-02-03 22:23:50,635 training [INFO ] Epoch 15 Batch 1560 Training err. 105.18716 Training err. RA 118.81621 Valid. err. 105.80679
2018-02-03 22:23:51,671 training [INFO ] Epoch 16 Batch 1580 Training err. 100.47582 Training err. RA 118.58406 Valid. err. 98.33026
2018-02-03 22:23:52,316 training [INFO ] Epoch 16 Batch 1600 Training err. 101.42350 Training err. RA 118.36955 Valid. err. 77.45070
2018-02-03 22:23:52,911 training [INFO ] Epoch 16 Batch 1620 Training err. 97.29935 Training err. RA 118.10942 Valid. err. 130.61472
2018-02-03 22:23:53,467 training [INFO ] Epoch 16 Batch 1640 Training err. 100.93882 Training err. RA 117.90003 Valid. err. 105.80737
2018-02-03 22:23:54,014 training [INFO ] Epoch 16 Batch 1660 Training err. 105.29362 Training err. RA 117.74814 Valid. err. 107.23687
2018-02-03 22:23:55,098 training [INFO ] Epoch 17 Batch 1680 Training err. 99.99544 Training err. RA 117.53680 Valid. err. 89.87338
2018-02-03 22:23:55,636 training [INFO ] Epoch 17 Batch 1700 Training err. 98.90839 Training err. RA 117.31764 Valid. err. 109.41042
2018-02-03 22:23:56,163 training [INFO ] Epoch 17 Batch 1720 Training err. 114.98959 Training err. RA 117.29057 Valid. err. 126.20209
2018-02-03 22:23:56,683 training [INFO ] Epoch 17 Batch 1740 Training err. 111.59181 Training err. RA 117.22507 Valid. err. 82.68454
2018-02-03 22:23:57,326 training [INFO ] Epoch 17 Batch 1760 Training err. 103.78296 Training err. RA 117.07232 Valid. err. 61.02968
2018-02-03 22:23:58,385 training [INFO ] Epoch 18 Batch 1780 Training err. 103.01986 Training err. RA 116.91443 Valid. err. 110.52521
2018-02-03 22:23:59,016 training [INFO ] Epoch 18 Batch 1800 Training err. 112.13399 Training err. RA 116.86131 Valid. err. 102.46583
2018-02-03 22:23:59,632 training [INFO ] Epoch 18 Batch 1820 Training err. 87.39032 Training err. RA 116.53745 Valid. err. 108.45870
2018-02-03 22:24:00,189 training [INFO ] Epoch 18 Batch 1840 Training err. 114.67453 Training err. RA 116.51720 Valid. err. 91.51694
2018-02-03 22:24:00,795 training [INFO ] Epoch 18 Batch 1860 Training err. 116.28569 Training err. RA 116.51471 Valid. err. 133.97749
2018-02-03 22:24:01,859 training [INFO ] Epoch 19 Batch 1880 Training err. 109.63721 Training err. RA 116.44155 Valid. err. 73.73893
2018-02-03 22:24:02,383 training [INFO ] Epoch 19 Batch 1900 Training err. 103.70196 Training err. RA 116.30745 Valid. err. 83.49118
2018-02-03 22:24:03,042 training [INFO ] Epoch 19 Batch 1920 Training err. 111.19804 Training err. RA 116.25422 Valid. err. 93.93085
2018-02-03 22:24:03,867 training [INFO ] Epoch 19 Batch 1940 Training err. 114.35479 Training err. RA 116.23464 Valid. err. 101.61460
2018-02-03 22:24:04,643 training [INFO ] Epoch 19 Batch 1960 Training err. 99.66154 Training err. RA 116.06553 Valid. err. 98.08915
2018-02-03 22:24:05,793 training [INFO ] Epoch 20 Batch 1980 Training err. 111.59641 Training err. RA 116.02039 Valid. err. 143.06170
2018-02-03 22:24:06,575 training [INFO ] Epoch 20 Batch 2000 Training err. 109.04781 Training err. RA 115.95066 Valid. err. 131.80798
2018-02-03 22:24:07,147 training [INFO ] Epoch 20 Batch 2020 Training err. 105.22926 Training err. RA 115.84451 Valid. err. 131.16357
2018-02-03 22:24:07,709 training [INFO ] Epoch 20 Batch 2040 Training err. 119.97776 Training err. RA 115.88503 Valid. err. 122.10992
2018-02-03 22:24:08,373 training [INFO ] Epoch 20 Batch 2060 Training err. 124.94979 Training err. RA 115.97304 Valid. err. 117.26084
2018-02-03 22:24:08,950 training [INFO ] Epoch 20 Batch 2080 Training err. 103.29262 Training err. RA 115.85111 Valid. err. 100.20163
2018-02-03 22:24:09,907 training [INFO ] Epoch 21 Batch 2100 Training err. 107.26062 Training err. RA 115.76930 Valid. err. 118.00760
2018-02-03 22:24:10,453 training [INFO ] Epoch 21 Batch 2120 Training err. 106.36274 Training err. RA 115.68056 Valid. err. 114.34085
2018-02-03 22:24:11,084 training [INFO ] Epoch 21 Batch 2140 Training err. 114.85239 Training err. RA 115.67282 Valid. err. 143.49303
2018-02-03 22:24:11,731 training [INFO ] Epoch 21 Batch 2160 Training err. 96.28550 Training err. RA 115.49330 Valid. err. 82.78773
2018-02-03 22:24:12,420 training [INFO ] Epoch 21 Batch 2180 Training err. 87.71644 Training err. RA 115.23847 Valid. err. 69.99683
2018-02-03 22:24:13,296 training [INFO ] Epoch 22 Batch 2200 Training err. 81.75816 Training err. RA 114.93410 Valid. err. 96.97739
2018-02-03 22:24:13,822 training [INFO ] Epoch 22 Batch 2220 Training err. 106.16172 Training err. RA 114.85507 Valid. err. 154.55929
2018-02-03 22:24:14,356 training [INFO ] Epoch 22 Batch 2240 Training err. 104.55193 Training err. RA 114.76308 Valid. err. 112.99882
2018-02-03 22:24:14,905 training [INFO ] Epoch 22 Batch 2260 Training err. 107.10913 Training err. RA 114.69535 Valid. err. 95.57666
2018-02-03 22:24:15,486 training [INFO ] Epoch 22 Batch 2280 Training err. 105.92743 Training err. RA 114.61844 Valid. err. 83.50192
2018-02-03 22:24:16,460 training [INFO ] Epoch 23 Batch 2300 Training err. 79.01328 Training err. RA 114.30883 Valid. err. 102.42256
2018-02-03 22:24:17,043 training [INFO ] Epoch 23 Batch 2320 Training err. 105.40901 Training err. RA 114.23210 Valid. err. 101.68209
2018-02-03 22:24:17,602 training [INFO ] Epoch 23 Batch 2340 Training err. 109.58711 Training err. RA 114.19240 Valid. err. 61.08588
2018-02-03 22:24:18,164 training [INFO ] Epoch 23 Batch 2360 Training err. 96.60126 Training err. RA 114.04332 Valid. err. 97.48905
2018-02-03 22:24:18,709 training [INFO ] Epoch 23 Batch 2380 Training err. 105.33920 Training err. RA 113.97018 Valid. err. 135.48768
2018-02-03 22:24:19,596 training [INFO ] Epoch 24 Batch 2400 Training err. 93.87694 Training err. RA 113.80274 Valid. err. 81.57083
2018-02-03 22:24:20,173 training [INFO ] Epoch 24 Batch 2420 Training err. 96.76120 Training err. RA 113.66190 Valid. err. 81.07223
2018-02-03 22:24:20,738 training [INFO ] Epoch 24 Batch 2440 Training err. 96.04766 Training err. RA 113.51752 Valid. err. 86.33395
2018-02-03 22:24:21,322 training [INFO ] Epoch 24 Batch 2460 Training err. 105.78858 Training err. RA 113.45468 Valid. err. 138.63747
2018-02-03 22:24:21,935 training [INFO ] Epoch 24 Batch 2480 Training err. 116.41166 Training err. RA 113.47853 Valid. err. 99.66670
2018-02-03 22:24:23,014 training [INFO ] Epoch 25 Batch 2500 Training err. 97.19450 Training err. RA 113.34826 Valid. err. 110.06503
2018-02-03 22:24:23,674 training [INFO ] Epoch 25 Batch 2520 Training err. 105.31674 Training err. RA 113.28451 Valid. err. 113.23864
2018-02-03 22:24:24,340 training [INFO ] Epoch 25 Batch 2540 Training err. 103.10858 Training err. RA 113.20439 Valid. err. 102.02876
2018-02-03 22:24:25,044 training [INFO ] Epoch 25 Batch 2560 Training err. 123.73641 Training err. RA 113.28667 Valid. err. 106.22847
2018-02-03 22:24:25,731 training [INFO ] Epoch 25 Batch 2580 Training err. 105.34403 Training err. RA 113.22510 Valid. err. 83.94420
2018-02-03 22:24:26,375 training [INFO ] Epoch 25 Batch 2600 Training err. 94.42850 Training err. RA 113.08051 Valid. err. 63.45335
2018-02-03 22:24:27,423 training [INFO ] Epoch 26 Batch 2620 Training err. 105.72870 Training err. RA 113.02439 Valid. err. 103.52860
2018-02-03 22:24:28,065 training [INFO ] Epoch 26 Batch 2640 Training err. 107.58470 Training err. RA 112.98318 Valid. err. 93.70949
2018-02-03 22:24:28,685 training [INFO ] Epoch 26 Batch 2660 Training err. 105.10128 Training err. RA 112.92392 Valid. err. 107.25517
2018-02-03 22:24:29,404 training [INFO ] Epoch 26 Batch 2680 Training err. 114.17768 Training err. RA 112.93327 Valid. err. 101.04537
2018-02-03 22:24:30,078 training [INFO ] Epoch 26 Batch 2700 Training err. 112.13674 Training err. RA 112.92737 Valid. err. 83.65439
2018-02-03 22:24:31,184 training [INFO ] Epoch 27 Batch 2720 Training err. 86.15923 Training err. RA 112.73055 Valid. err. 114.58734
2018-02-03 22:24:31,833 training [INFO ] Epoch 27 Batch 2740 Training err. 100.40388 Training err. RA 112.64057 Valid. err. 107.10731
2018-02-03 22:24:32,510 training [INFO ] Epoch 27 Batch 2760 Training err. 93.75217 Training err. RA 112.50370 Valid. err. 133.21394
2018-02-03 22:24:33,177 training [INFO ] Epoch 27 Batch 2780 Training err. 95.01696 Training err. RA 112.37790 Valid. err. 79.44745
2018-02-03 22:24:33,849 training [INFO ] Epoch 27 Batch 2800 Training err. 103.03799 Training err. RA 112.31118 Valid. err. 88.25098
2018-02-03 22:24:34,903 training [INFO ] Epoch 28 Batch 2820 Training err. 112.85930 Training err. RA 112.31507 Valid. err. 100.67188
2018-02-03 22:24:35,574 training [INFO ] Epoch 28 Batch 2840 Training err. 96.23530 Training err. RA 112.20183 Valid. err. 80.46879
2018-02-03 22:24:36,215 training [INFO ] Epoch 28 Batch 2860 Training err. 97.66723 Training err. RA 112.10019 Valid. err. 89.24131
2018-02-03 22:24:36,822 training [INFO ] Epoch 28 Batch 2880 Training err. 108.17960 Training err. RA 112.07297 Valid. err. 91.19785
2018-02-03 22:24:37,453 training [INFO ] Epoch 28 Batch 2900 Training err. 98.45904 Training err. RA 111.97908 Valid. err. 95.16780
2018-02-03 22:24:38,476 training [INFO ] Epoch 29 Batch 2920 Training err. 106.62478 Training err. RA 111.94240 Valid. err. 92.32521
2018-02-03 22:24:39,084 training [INFO ] Epoch 29 Batch 2940 Training err. 88.73290 Training err. RA 111.78452 Valid. err. 125.95956
2018-02-03 22:24:39,783 training [INFO ] Epoch 29 Batch 2960 Training err. 102.18410 Training err. RA 111.71965 Valid. err. 80.69872
2018-02-03 22:24:40,370 training [INFO ] Epoch 29 Batch 2980 Training err. 107.25693 Training err. RA 111.68970 Valid. err. 106.53190
2018-02-03 22:24:40,946 training [INFO ] Epoch 29 Batch 3000 Training err. 111.74603 Training err. RA 111.69007 Valid. err. 58.93557
2018-02-03 22:24:42,066 training [INFO ] Epoch 30 Batch 3020 Training err. 90.68417 Training err. RA 111.55096 Valid. err. 81.93897
2018-02-03 22:24:42,622 training [INFO ] Epoch 30 Batch 3040 Training err. 109.36161 Training err. RA 111.53656 Valid. err. 81.70636
2018-02-03 22:24:43,156 training [INFO ] Epoch 30 Batch 3060 Training err. 105.49950 Training err. RA 111.49710 Valid. err. 121.06619
2018-02-03 22:24:43,690 training [INFO ] Epoch 30 Batch 3080 Training err. 106.50122 Training err. RA 111.46466 Valid. err. 126.69033
2018-02-03 22:24:44,225 training [INFO ] Epoch 30 Batch 3100 Training err. 114.30827 Training err. RA 111.48300 Valid. err. 91.83294
2018-02-03 22:24:44,761 training [INFO ] Epoch 30 Batch 3120 Training err. 91.20075 Training err. RA 111.35299 Valid. err. 64.21045
2018-02-03 22:24:45,661 training [INFO ] Epoch 31 Batch 3140 Training err. 89.43198 Training err. RA 111.21337 Valid. err. 76.94802
2018-02-03 22:24:46,194 training [INFO ] Epoch 31 Batch 3160 Training err. 83.10472 Training err. RA 111.03546 Valid. err. 69.62960
2018-02-03 22:24:46,724 training [INFO ] Epoch 31 Batch 3180 Training err. 92.10356 Training err. RA 110.91639 Valid. err. 109.13067
2018-02-03 22:24:47,252 training [INFO ] Epoch 31 Batch 3200 Training err. 99.11966 Training err. RA 110.84266 Valid. err. 75.00549
2018-02-03 22:24:47,773 training [INFO ] Epoch 31 Batch 3220 Training err. 93.99363 Training err. RA 110.73801 Valid. err. 88.78780
2018-02-03 22:24:48,649 training [INFO ] Epoch 32 Batch 3240 Training err. 105.66967 Training err. RA 110.70673 Valid. err. 89.39777
2018-02-03 22:24:49,176 training [INFO ] Epoch 32 Batch 3260 Training err. 91.94945 Training err. RA 110.59165 Valid. err. 96.57783
2018-02-03 22:24:49,696 training [INFO ] Epoch 32 Batch 3280 Training err. 106.39827 Training err. RA 110.56608 Valid. err. 87.49711
2018-02-03 22:24:50,222 training [INFO ] Epoch 32 Batch 3300 Training err. 114.68905 Training err. RA 110.59107 Valid. err. 97.06075
2018-02-03 22:24:50,746 training [INFO ] Epoch 32 Batch 3320 Training err. 95.07461 Training err. RA 110.49760 Valid. err. 94.29750
2018-02-03 22:24:51,657 training [INFO ] Epoch 33 Batch 3340 Training err. 100.87951 Training err. RA 110.44000 Valid. err. 86.45593
2018-02-03 22:24:52,197 training [INFO ] Epoch 33 Batch 3360 Training err. 93.53744 Training err. RA 110.33939 Valid. err. 123.16848
2018-02-03 22:24:52,732 training [INFO ] Epoch 33 Batch 3380 Training err. 105.18828 Training err. RA 110.30891 Valid. err. 68.51404
2018-02-03 22:24:53,264 training [INFO ] Epoch 33 Batch 3400 Training err. 89.65285 Training err. RA 110.18741 Valid. err. 137.91517
2018-02-03 22:24:53,788 training [INFO ] Epoch 33 Batch 3420 Training err. 109.54557 Training err. RA 110.18365 Valid. err. 95.70704
2018-02-03 22:24:54,686 training [INFO ] Epoch 34 Batch 3440 Training err. 98.20737 Training err. RA 110.11402 Valid. err. 109.43773
2018-02-03 22:24:55,207 training [INFO ] Epoch 34 Batch 3460 Training err. 100.56248 Training err. RA 110.05881 Valid. err. 124.84172
2018-02-03 22:24:55,731 training [INFO ] Epoch 34 Batch 3480 Training err. 89.67264 Training err. RA 109.94165 Valid. err. 66.71143
2018-02-03 22:24:56,251 training [INFO ] Epoch 34 Batch 3500 Training err. 98.98370 Training err. RA 109.87903 Valid. err. 106.51763
2018-02-03 22:24:56,773 training [INFO ] Epoch 34 Batch 3520 Training err. 118.39433 Training err. RA 109.92742 Valid. err. 88.08483
2018-02-03 22:24:57,659 training [INFO ] Epoch 35 Batch 3540 Training err. 113.05438 Training err. RA 109.94508 Valid. err. 122.70633
2018-02-03 22:24:58,180 training [INFO ] Epoch 35 Batch 3560 Training err. 103.66969 Training err. RA 109.90983 Valid. err. 95.73556
2018-02-03 22:24:58,734 training [INFO ] Epoch 35 Batch 3580 Training err. 91.75869 Training err. RA 109.80842 Valid. err. 82.58970
2018-02-03 22:24:59,284 training [INFO ] Epoch 35 Batch 3600 Training err. 82.94767 Training err. RA 109.65920 Valid. err. 60.73639
2018-02-03 22:24:59,909 training [INFO ] Epoch 35 Batch 3620 Training err. 84.44489 Training err. RA 109.51989 Valid. err. 74.27290
2018-02-03 22:25:00,465 training [INFO ] Epoch 35 Batch 3640 Training err. 97.39366 Training err. RA 109.45326 Valid. err. 92.77361
2018-02-03 22:25:01,430 training [INFO ] Epoch 36 Batch 3660 Training err. 97.18755 Training err. RA 109.38624 Valid. err. 88.64240
2018-02-03 22:25:01,989 training [INFO ] Epoch 36 Batch 3680 Training err. 101.01814 Training err. RA 109.34076 Valid. err. 79.54861
2018-02-03 22:25:02,549 training [INFO ] Epoch 36 Batch 3700 Training err. 86.68679 Training err. RA 109.21831 Valid. err. 115.74457
2018-02-03 22:25:03,252 training [INFO ] Epoch 36 Batch 3720 Training err. 89.62389 Training err. RA 109.11296 Valid. err. 104.24976
2018-02-03 22:25:03,936 training [INFO ] Epoch 36 Batch 3740 Training err. 100.85964 Training err. RA 109.06882 Valid. err. 98.63365
2018-02-03 22:25:05,156 training [INFO ] Epoch 37 Batch 3760 Training err. 98.71802 Training err. RA 109.01377 Valid. err. 136.43628
2018-02-03 22:25:05,905 training [INFO ] Epoch 37 Batch 3780 Training err. 107.49540 Training err. RA 109.00573 Valid. err. 77.51864
2018-02-03 22:25:06,677 training [INFO ] Epoch 37 Batch 3800 Training err. 108.00376 Training err. RA 109.00046 Valid. err. 98.84510
2018-02-03 22:25:07,328 training [INFO ] Epoch 37 Batch 3820 Training err. 102.01747 Training err. RA 108.96390 Valid. err. 85.93729
2018-02-03 22:25:07,892 training [INFO ] Epoch 37 Batch 3840 Training err. 97.59461 Training err. RA 108.90468 Valid. err. 116.21177
2018-02-03 22:25:08,859 training [INFO ] Epoch 38 Batch 3860 Training err. 85.74737 Training err. RA 108.78470 Valid. err. 105.65063
2018-02-03 22:25:09,426 training [INFO ] Epoch 38 Batch 3880 Training err. 96.85202 Training err. RA 108.72319 Valid. err. 126.08723
2018-02-03 22:25:09,986 training [INFO ] Epoch 38 Batch 3900 Training err. 101.85352 Training err. RA 108.68796 Valid. err. 74.87096
2018-02-03 22:25:10,545 training [INFO ] Epoch 38 Batch 3920 Training err. 85.24360 Training err. RA 108.56835 Valid. err. 61.51060
2018-02-03 22:25:11,090 training [INFO ] Epoch 38 Batch 3940 Training err. 100.08979 Training err. RA 108.52531 Valid. err. 98.60029
2018-02-03 22:25:12,019 training [INFO ] Epoch 39 Batch 3960 Training err. 108.50640 Training err. RA 108.52521 Valid. err. 98.85751
2018-02-03 22:25:12,548 training [INFO ] Epoch 39 Batch 3980 Training err. 93.61669 Training err. RA 108.45030 Valid. err. 88.74047
2018-02-03 22:25:13,093 training [INFO ] Epoch 39 Batch 4000 Training err. 86.70830 Training err. RA 108.34159 Valid. err. 71.53095
2018-02-03 22:25:13,625 training [INFO ] Epoch 39 Batch 4020 Training err. 93.07156 Training err. RA 108.26561 Valid. err. 89.12496
2018-02-03 22:25:14,166 training [INFO ] Epoch 39 Batch 4040 Training err. 92.80119 Training err. RA 108.18906 Valid. err. 126.21039
2018-02-03 22:25:15,108 training [INFO ] Epoch 40 Batch 4060 Training err. 89.27927 Training err. RA 108.09591 Valid. err. 98.96660
2018-02-03 22:25:15,750 training [INFO ] Epoch 40 Batch 4080 Training err. 104.18062 Training err. RA 108.07671 Valid. err. 79.00637
2018-02-03 22:25:16,298 training [INFO ] Epoch 40 Batch 4100 Training err. 85.90206 Training err. RA 107.96855 Valid. err. 112.73873
2018-02-03 22:25:16,866 training [INFO ] Epoch 40 Batch 4120 Training err. 95.61992 Training err. RA 107.90860 Valid. err. 108.14888
2018-02-03 22:25:17,410 training [INFO ] Epoch 40 Batch 4140 Training err. 103.02267 Training err. RA 107.88500 Valid. err. 92.27301
2018-02-03 22:25:17,936 training [INFO ] Epoch 40 Batch 4160 Training err. 87.73652 Training err. RA 107.78813 Valid. err. 73.47100
2018-02-03 22:25:18,823 training [INFO ] Epoch 41 Batch 4180 Training err. 85.14995 Training err. RA 107.67981 Valid. err. 96.08373
2018-02-03 22:25:19,353 training [INFO ] Epoch 41 Batch 4200 Training err. 84.47750 Training err. RA 107.56933 Valid. err. 74.99027
2018-02-03 22:25:19,888 training [INFO ] Epoch 41 Batch 4220 Training err. 94.35098 Training err. RA 107.50668 Valid. err. 94.97846
2018-02-03 22:25:20,548 training [INFO ] Epoch 41 Batch 4240 Training err. 79.22993 Training err. RA 107.37330 Valid. err. 90.84542
2018-02-03 22:25:21,071 training [INFO ] Epoch 41 Batch 4260 Training err. 103.06443 Training err. RA 107.35307 Valid. err. 89.48099
2018-02-03 22:25:21,975 training [INFO ] Epoch 42 Batch 4280 Training err. 89.47981 Training err. RA 107.26955 Valid. err. 103.22365
2018-02-03 22:25:22,501 training [INFO ] Epoch 42 Batch 4300 Training err. 102.82402 Training err. RA 107.24887 Valid. err. 77.34321
2018-02-03 22:25:23,033 training [INFO ] Epoch 42 Batch 4320 Training err. 90.53989 Training err. RA 107.17152 Valid. err. 102.30669
2018-02-03 22:25:23,649 training [INFO ] Epoch 42 Batch 4340 Training err. 85.31701 Training err. RA 107.07080 Valid. err. 79.62988
2018-02-03 22:25:24,350 training [INFO ] Epoch 42 Batch 4360 Training err. 84.33988 Training err. RA 106.96653 Valid. err. 111.37375
2018-02-03 22:25:25,465 training [INFO ] Epoch 43 Batch 4380 Training err. 87.01478 Training err. RA 106.87543 Valid. err. 57.28607
2018-02-03 22:25:26,091 training [INFO ] Epoch 43 Batch 4400 Training err. 81.21611 Training err. RA 106.75880 Valid. err. 101.53993
2018-02-03 22:25:26,758 training [INFO ] Epoch 43 Batch 4420 Training err. 102.50369 Training err. RA 106.73954 Valid. err. 106.78591
2018-02-03 22:25:27,394 training [INFO ] Epoch 43 Batch 4440 Training err. 95.94247 Training err. RA 106.69091 Valid. err. 86.81748
2018-02-03 22:25:28,014 training [INFO ] Epoch 43 Batch 4460 Training err. 98.21700 Training err. RA 106.65291 Valid. err. 90.26848
2018-02-03 22:25:28,907 training [INFO ] Epoch 44 Batch 4480 Training err. 92.30788 Training err. RA 106.58887 Valid. err. 105.78585
2018-02-03 22:25:29,437 training [INFO ] Epoch 44 Batch 4500 Training err. 97.95781 Training err. RA 106.55051 Valid. err. 75.51053
2018-02-03 22:25:29,965 training [INFO ] Epoch 44 Batch 4520 Training err. 89.06517 Training err. RA 106.47314 Valid. err. 114.33797
2018-02-03 22:25:30,495 training [INFO ] Epoch 44 Batch 4540 Training err. 110.88059 Training err. RA 106.49255 Valid. err. 86.85606
2018-02-03 22:25:31,183 training [INFO ] Epoch 44 Batch 4560 Training err. 104.39045 Training err. RA 106.48333 Valid. err. 148.69918
2018-02-03 22:25:32,372 training [INFO ] Epoch 45 Batch 4580 Training err. 100.87716 Training err. RA 106.45885 Valid. err. 77.59912
2018-02-03 22:25:33,051 training [INFO ] Epoch 45 Batch 4600 Training err. 96.93838 Training err. RA 106.41746 Valid. err. 129.41734
2018-02-03 22:25:33,740 training [INFO ] Epoch 45 Batch 4620 Training err. 99.19250 Training err. RA 106.38618 Valid. err. 110.57054
2018-02-03 22:25:34,426 training [INFO ] Epoch 45 Batch 4640 Training err. 97.78445 Training err. RA 106.34911 Valid. err. 98.43252
2018-02-03 22:25:35,005 training [INFO ] Epoch 45 Batch 4660 Training err. 102.38074 Training err. RA 106.33207 Valid. err. 105.06741
2018-02-03 22:25:35,577 training [INFO ] Epoch 45 Batch 4680 Training err. 76.51288 Training err. RA 106.20464 Valid. err. 53.95611
2018-02-03 22:25:36,552 training [INFO ] Epoch 46 Batch 4700 Training err. 89.18428 Training err. RA 106.13222 Valid. err. 94.60812
2018-02-03 22:25:37,121 training [INFO ] Epoch 46 Batch 4720 Training err. 97.66043 Training err. RA 106.09632 Valid. err. 94.55075
2018-02-03 22:25:37,696 training [INFO ] Epoch 46 Batch 4740 Training err. 101.33659 Training err. RA 106.07623 Valid. err. 127.55528
2018-02-03 22:25:38,275 training [INFO ] Epoch 46 Batch 4760 Training err. 90.83738 Training err. RA 106.01221 Valid. err. 105.15510
2018-02-03 22:25:38,832 training [INFO ] Epoch 46 Batch 4780 Training err. 92.59851 Training err. RA 105.95608 Valid. err. 101.08242
2018-02-03 22:25:39,731 training [INFO ] Epoch 47 Batch 4800 Training err. 77.46779 Training err. RA 105.83738 Valid. err. 61.22118
2018-02-03 22:25:40,256 training [INFO ] Epoch 47 Batch 4820 Training err. 93.16487 Training err. RA 105.78480 Valid. err. 73.65980
2018-02-03 22:25:40,790 training [INFO ] Epoch 47 Batch 4840 Training err. 87.71163 Training err. RA 105.71011 Valid. err. 86.77997
2018-02-03 22:25:41,427 training [INFO ] Epoch 47 Batch 4860 Training err. 101.06179 Training err. RA 105.69099 Valid. err. 123.32852
2018-02-03 22:25:42,101 training [INFO ] Epoch 47 Batch 4880 Training err. 87.84031 Training err. RA 105.61783 Valid. err. 98.83066
2018-02-03 22:25:42,995 training [INFO ] Epoch 48 Batch 4900 Training err. 74.69055 Training err. RA 105.49159 Valid. err. 59.19249
2018-02-03 22:25:43,571 training [INFO ] Epoch 48 Batch 4920 Training err. 91.97994 Training err. RA 105.43667 Valid. err. 133.36749
2018-02-03 22:25:44,124 training [INFO ] Epoch 48 Batch 4940 Training err. 105.13715 Training err. RA 105.43546 Valid. err. 105.11388
2018-02-03 22:25:44,652 training [INFO ] Epoch 48 Batch 4960 Training err. 109.88496 Training err. RA 105.45340 Valid. err. 133.79153
2018-02-03 22:25:45,173 training [INFO ] Epoch 48 Batch 4980 Training err. 104.20915 Training err. RA 105.44840 Valid. err. 121.51438
2018-02-03 22:25:46,072 training [INFO ] Epoch 49 Batch 5000 Training err. 93.36303 Training err. RA 105.40006 Valid. err. 102.52277
2018-02-03 22:25:46,592 training [INFO ] Epoch 49 Batch 5020 Training err. 94.75414 Training err. RA 105.35764 Valid. err. 101.11516
2018-02-03 22:25:47,120 training [INFO ] Epoch 49 Batch 5040 Training err. 91.68723 Training err. RA 105.30340 Valid. err. 72.87813
2018-02-03 22:25:47,661 training [INFO ] Epoch 49 Batch 5060 Training err. 90.62034 Training err. RA 105.24536 Valid. err. 71.65211
2018-02-03 22:25:48,207 training [INFO ] Epoch 49 Batch 5080 Training err. 83.98671 Training err. RA 105.16167 Valid. err. 115.51315
2018-02-03 22:25:49,102 training [INFO ] Epoch 50 Batch 5100 Training err. 97.20499 Training err. RA 105.13046 Valid. err. 93.28912
2018-02-03 22:25:49,636 training [INFO ] Epoch 50 Batch 5120 Training err. 93.58332 Training err. RA 105.08536 Valid. err. 119.35553
2018-02-03 22:25:50,164 training [INFO ] Epoch 50 Batch 5140 Training err. 89.63567 Training err. RA 105.02524 Valid. err. 110.73159
2018-02-03 22:25:50,710 training [INFO ] Epoch 50 Batch 5160 Training err. 81.27502 Training err. RA 104.93319 Valid. err. 93.86410
2018-02-03 22:25:51,231 training [INFO ] Epoch 50 Batch 5180 Training err. 82.12618 Training err. RA 104.84513 Valid. err. 96.87548
2018-02-03 22:25:51,754 training [INFO ] Epoch 50 Batch 5200 Training err. 102.82455 Training err. RA 104.83736 Valid. err. 123.11978
2018-02-03 22:25:52,639 training [INFO ] Epoch 51 Batch 5220 Training err. 106.14563 Training err. RA 104.84237 Valid. err. 127.99803
2018-02-03 22:25:53,154 training [INFO ] Epoch 51 Batch 5240 Training err. 97.98715 Training err. RA 104.81620 Valid. err. 67.13042
2018-02-03 22:25:53,677 training [INFO ] Epoch 51 Batch 5260 Training err. 78.31857 Training err. RA 104.71545 Valid. err. 78.42230
2018-02-03 22:25:54,245 training [INFO ] Epoch 51 Batch 5280 Training err. 84.97871 Training err. RA 104.64069 Valid. err. 68.82859
2018-02-03 22:25:54,822 training [INFO ] Epoch 51 Batch 5300 Training err. 99.86171 Training err. RA 104.62266 Valid. err. 116.51026
2018-02-03 22:25:55,710 training [INFO ] Epoch 52 Batch 5320 Training err. 88.98533 Training err. RA 104.56387 Valid. err. 77.58139
2018-02-03 22:25:56,237 training [INFO ] Epoch 52 Batch 5340 Training err. 98.38342 Training err. RA 104.54072 Valid. err. 65.35972
2018-02-03 22:25:56,761 training [INFO ] Epoch 52 Batch 5360 Training err. 95.13010 Training err. RA 104.50561 Valid. err. 125.11749
2018-02-03 22:25:57,293 training [INFO ] Epoch 52 Batch 5380 Training err. 102.32582 Training err. RA 104.49751 Valid. err. 88.00623
2018-02-03 22:25:57,821 training [INFO ] Epoch 52 Batch 5400 Training err. 95.79129 Training err. RA 104.46526 Valid. err. 74.08109
2018-02-03 22:25:58,734 training [INFO ] Epoch 53 Batch 5420 Training err. 86.23750 Training err. RA 104.39800 Valid. err. 78.52823
2018-02-03 22:25:59,261 training [INFO ] Epoch 53 Batch 5440 Training err. 97.16605 Training err. RA 104.37141 Valid. err. 108.95501
2018-02-03 22:25:59,788 training [INFO ] Epoch 53 Batch 5460 Training err. 94.49964 Training err. RA 104.33525 Valid. err. 105.52643
2018-02-03 22:26:00,316 training [INFO ] Epoch 53 Batch 5480 Training err. 88.90450 Training err. RA 104.27894 Valid. err. 104.16153
2018-02-03 22:26:00,840 training [INFO ] Epoch 53 Batch 5500 Training err. 90.01352 Training err. RA 104.22706 Valid. err. 75.10664
2018-02-03 22:26:01,718 training [INFO ] Epoch 54 Batch 5520 Training err. 88.81945 Training err. RA 104.17124 Valid. err. 95.11756
2018-02-03 22:26:02,312 training [INFO ] Epoch 54 Batch 5540 Training err. 101.56200 Training err. RA 104.16182 Valid. err. 112.16286
2018-02-03 22:26:02,845 training [INFO ] Epoch 54 Batch 5560 Training err. 94.55588 Training err. RA 104.12726 Valid. err. 113.09964
2018-02-03 22:26:03,392 training [INFO ] Epoch 54 Batch 5580 Training err. 102.37004 Training err. RA 104.12096 Valid. err. 76.82498
2018-02-03 22:26:03,930 training [INFO ] Epoch 54 Batch 5600 Training err. 86.47104 Training err. RA 104.05793 Valid. err. 91.77172
2018-02-03 22:26:04,854 training [INFO ] Epoch 55 Batch 5620 Training err. 84.13310 Training err. RA 103.98702 Valid. err. 120.06024
2018-02-03 22:26:05,409 training [INFO ] Epoch 55 Batch 5640 Training err. 89.07832 Training err. RA 103.93415 Valid. err. 132.45155
2018-02-03 22:26:06,095 training [INFO ] Epoch 55 Batch 5660 Training err. 91.24363 Training err. RA 103.88931 Valid. err. 99.76031
2018-02-03 22:26:06,674 training [INFO ] Epoch 55 Batch 5680 Training err. 83.24804 Training err. RA 103.81663 Valid. err. 95.52625
2018-02-03 22:26:07,381 training [INFO ] Epoch 55 Batch 5700 Training err. 98.15805 Training err. RA 103.79678 Valid. err. 94.69671
2018-02-03 22:26:08,074 training [INFO ] Epoch 55 Batch 5720 Training err. 98.47125 Training err. RA 103.77816 Valid. err. 90.37521
2018-02-03 22:26:09,261 training [INFO ] Epoch 56 Batch 5740 Training err. 85.04628 Training err. RA 103.71289 Valid. err. 82.25181
2018-02-03 22:26:09,974 training [INFO ] Epoch 56 Batch 5760 Training err. 79.14240 Training err. RA 103.62757 Valid. err. 76.68703
2018-02-03 22:26:10,672 training [INFO ] Epoch 56 Batch 5780 Training err. 86.62904 Training err. RA 103.56876 Valid. err. 102.30665
2018-02-03 22:26:11,256 training [INFO ] Epoch 56 Batch 5800 Training err. 99.47732 Training err. RA 103.55465 Valid. err. 113.58859
2018-02-03 22:26:11,833 training [INFO ] Epoch 56 Batch 5820 Training err. 85.91491 Training err. RA 103.49403 Valid. err. 78.86115
2018-02-03 22:26:12,803 training [INFO ] Epoch 57 Batch 5840 Training err. 86.32189 Training err. RA 103.43522 Valid. err. 61.08940
2018-02-03 22:26:13,471 training [INFO ] Epoch 57 Batch 5860 Training err. 91.87121 Training err. RA 103.39575 Valid. err. 98.06110
2018-02-03 22:26:14,076 training [INFO ] Epoch 57 Batch 5880 Training err. 90.20579 Training err. RA 103.35089 Valid. err. 98.52431
2018-02-03 22:26:14,640 training [INFO ] Epoch 57 Batch 5900 Training err. 95.07414 Training err. RA 103.32283 Valid. err. 85.62005
2018-02-03 22:26:15,171 training [INFO ] Epoch 57 Batch 5920 Training err. 90.49585 Training err. RA 103.27950 Valid. err. 81.05380
2018-02-03 22:26:16,124 training [INFO ] Epoch 58 Batch 5940 Training err. 74.55580 Training err. RA 103.18279 Valid. err. 91.52626
2018-02-03 22:26:16,775 training [INFO ] Epoch 58 Batch 5960 Training err. 86.67979 Training err. RA 103.12741 Valid. err. 118.15347
2018-02-03 22:26:17,398 training [INFO ] Epoch 58 Batch 5980 Training err. 104.32631 Training err. RA 103.13142 Valid. err. 90.42514
2018-02-03 22:26:18,011 training [INFO ] Epoch 58 Batch 6000 Training err. 89.28592 Training err. RA 103.08526 Valid. err. 63.78460
2018-02-03 22:26:18,636 training [INFO ] Epoch 58 Batch 6020 Training err. 78.92090 Training err. RA 103.00498 Valid. err. 112.03369
2018-02-03 22:26:19,710 training [INFO ] Epoch 59 Batch 6040 Training err. 95.24834 Training err. RA 102.97930 Valid. err. 92.83176
2018-02-03 22:26:20,328 training [INFO ] Epoch 59 Batch 6060 Training err. 105.01918 Training err. RA 102.98603 Valid. err. 83.70550
2018-02-03 22:26:20,968 training [INFO ] Epoch 59 Batch 6080 Training err. 86.60210 Training err. RA 102.93214 Valid. err. 105.80760
2018-02-03 22:26:21,566 training [INFO ] Epoch 59 Batch 6100 Training err. 79.92210 Training err. RA 102.85669 Valid. err. 85.46596
2018-02-03 22:26:22,136 training [INFO ] Epoch 59 Batch 6120 Training err. 91.56237 Training err. RA 102.81979 Valid. err. 72.51364
2018-02-03 22:26:23,061 training [INFO ] Epoch 60 Batch 6140 Training err. 91.99389 Training err. RA 102.78452 Valid. err. 88.10355
2018-02-03 22:26:23,625 training [INFO ] Epoch 60 Batch 6160 Training err. 101.49560 Training err. RA 102.78034 Valid. err. 96.70164
2018-02-03 22:26:24,168 training [INFO ] Epoch 60 Batch 6180 Training err. 111.05290 Training err. RA 102.80711 Valid. err. 84.94884
2018-02-03 22:26:24,707 training [INFO ] Epoch 60 Batch 6200 Training err. 96.91046 Training err. RA 102.78809 Valid. err. 93.40363
2018-02-03 22:26:25,245 training [INFO ] Epoch 60 Batch 6220 Training err. 94.56473 Training err. RA 102.76165 Valid. err. 91.85655
2018-02-03 22:26:25,879 training [INFO ] Epoch 60 Batch 6240 Training err. 93.95298 Training err. RA 102.73341 Valid. err. 70.29940
2018-02-03 22:26:26,138 __main__ [INFO ] End of training
2018-02-03 23:28:38,080 __main__ [INFO ] 
==============================
Starting experiment alice_test
==============================
2018-02-03 23:28:38,099 __main__ [INFO ] Removing old results directory ./experiments/alice_test/out
2018-02-03 23:28:38,211 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 23:28:38,211 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 23:28:50,514 training [INFO ] Epoch  1 Batch   20 Training err. 4.23960 Training err. RA 4.23960 Valid. err. 4.15943
2018-02-03 23:28:51,046 training [INFO ] Epoch  1 Batch   40 Training err. 4.04963 Training err. RA 4.14461 Valid. err. 3.98278
2018-02-03 23:28:51,518 training [INFO ] Epoch  1 Batch   60 Training err. 3.87484 Training err. RA 4.05469 Valid. err. 3.78741
2018-02-03 23:28:51,991 training [INFO ] Epoch  1 Batch   80 Training err. 3.67923 Training err. RA 3.96083 Valid. err. 3.60467
2018-02-03 23:28:52,468 training [INFO ] Epoch  1 Batch  100 Training err. 3.49417 Training err. RA 3.86749 Valid. err. 3.47321
2018-02-03 23:28:52,938 training [INFO ] Epoch  1 Batch  120 Training err. 3.40005 Training err. RA 3.78959 Valid. err. 3.37461
2018-02-03 23:28:53,413 training [INFO ] Epoch  1 Batch  140 Training err. 3.29695 Training err. RA 3.71921 Valid. err. 3.31157
2018-02-03 23:28:53,887 training [INFO ] Epoch  1 Batch  160 Training err. 3.22365 Training err. RA 3.65727 Valid. err. 3.27398
2018-02-03 23:28:54,358 training [INFO ] Epoch  1 Batch  180 Training err. 3.23683 Training err. RA 3.61055 Valid. err. 3.25210
2018-02-03 23:28:54,832 training [INFO ] Epoch  1 Batch  200 Training err. 3.22766 Training err. RA 3.57226 Valid. err. 3.23499
2018-02-03 23:28:55,900 training [INFO ] Epoch  2 Batch  220 Training err. 3.19346 Training err. RA 3.53783 Valid. err. 3.22939
2018-02-03 23:28:56,372 training [INFO ] Epoch  2 Batch  240 Training err. 3.10840 Training err. RA 3.50204 Valid. err. 3.24754
2018-02-03 23:28:56,920 training [INFO ] Epoch  2 Batch  260 Training err. 3.19116 Training err. RA 3.47813 Valid. err. 3.21113
2018-02-03 23:28:57,392 training [INFO ] Epoch  2 Batch  280 Training err. 3.14546 Training err. RA 3.45436 Valid. err. 3.20716
2018-02-03 23:28:57,866 training [INFO ] Epoch  2 Batch  300 Training err. 3.14052 Training err. RA 3.43344 Valid. err. 3.20608
2018-02-03 23:28:58,338 training [INFO ] Epoch  2 Batch  320 Training err. 3.17132 Training err. RA 3.41706 Valid. err. 3.19960
2018-02-03 23:28:58,813 training [INFO ] Epoch  2 Batch  340 Training err. 3.14793 Training err. RA 3.40123 Valid. err. 3.19897
2018-02-03 23:28:59,286 training [INFO ] Epoch  2 Batch  360 Training err. 3.13517 Training err. RA 3.38645 Valid. err. 3.19653
2018-02-03 23:28:59,762 training [INFO ] Epoch  2 Batch  380 Training err. 3.12735 Training err. RA 3.37281 Valid. err. 3.19303
2018-02-03 23:29:00,251 training [INFO ] Epoch  2 Batch  400 Training err. 3.17125 Training err. RA 3.36273 Valid. err. 3.19070
2018-02-03 23:29:01,136 training [INFO ] Epoch  3 Batch  420 Training err. 3.16600 Training err. RA 3.35336 Valid. err. 3.19013
2018-02-03 23:29:01,612 training [INFO ] Epoch  3 Batch  440 Training err. 3.12848 Training err. RA 3.34314 Valid. err. 3.19331
2018-02-03 23:29:02,088 training [INFO ] Epoch  3 Batch  460 Training err. 3.11440 Training err. RA 3.33320 Valid. err. 3.18743
2018-02-03 23:29:02,563 training [INFO ] Epoch  3 Batch  480 Training err. 3.12144 Training err. RA 3.32437 Valid. err. 3.18810
2018-02-03 23:29:03,042 training [INFO ] Epoch  3 Batch  500 Training err. 3.10889 Training err. RA 3.31575 Valid. err. 3.19309
2018-02-03 23:29:03,520 training [INFO ] Epoch  3 Batch  520 Training err. 3.16359 Training err. RA 3.30990 Valid. err. 3.18941
2018-02-03 23:29:03,995 training [INFO ] Epoch  3 Batch  540 Training err. 3.15294 Training err. RA 3.30409 Valid. err. 3.18750
2018-02-03 23:29:04,474 training [INFO ] Epoch  3 Batch  560 Training err. 3.12056 Training err. RA 3.29753 Valid. err. 3.18724
2018-02-03 23:29:04,949 training [INFO ] Epoch  3 Batch  580 Training err. 3.08349 Training err. RA 3.29015 Valid. err. 3.18948
2018-02-03 23:29:05,423 training [INFO ] Epoch  3 Batch  600 Training err. 3.16400 Training err. RA 3.28595 Valid. err. 3.18426
2018-02-03 23:29:05,905 training [INFO ] Epoch  3 Batch  620 Training err. 3.16444 Training err. RA 3.28203 Valid. err. 3.18107
2018-02-03 23:29:06,800 training [INFO ] Epoch  4 Batch  640 Training err. 3.13565 Training err. RA 3.27745 Valid. err. 3.18352
2018-02-03 23:29:07,276 training [INFO ] Epoch  4 Batch  660 Training err. 3.07801 Training err. RA 3.27141 Valid. err. 3.18470
2018-02-03 23:29:07,750 training [INFO ] Epoch  4 Batch  680 Training err. 3.13558 Training err. RA 3.26741 Valid. err. 3.18360
2018-02-03 23:29:08,226 training [INFO ] Epoch  4 Batch  700 Training err. 3.12051 Training err. RA 3.26322 Valid. err. 3.18239
2018-02-03 23:29:08,703 training [INFO ] Epoch  4 Batch  720 Training err. 3.11211 Training err. RA 3.25902 Valid. err. 3.18523
2018-02-03 23:29:09,180 training [INFO ] Epoch  4 Batch  740 Training err. 3.16567 Training err. RA 3.25650 Valid. err. 3.18089
2018-02-03 23:29:09,665 training [INFO ] Epoch  4 Batch  760 Training err. 3.11368 Training err. RA 3.25274 Valid. err. 3.18330
2018-02-03 23:29:10,142 training [INFO ] Epoch  4 Batch  780 Training err. 3.11343 Training err. RA 3.24917 Valid. err. 3.18122
2018-02-03 23:29:10,618 training [INFO ] Epoch  4 Batch  800 Training err. 3.12217 Training err. RA 3.24599 Valid. err. 3.18056
2018-02-03 23:29:11,090 training [INFO ] Epoch  4 Batch  820 Training err. 3.14790 Training err. RA 3.24360 Valid. err. 3.17902
2018-02-03 23:29:11,960 training [INFO ] Epoch  5 Batch  840 Training err. 3.15689 Training err. RA 3.24153 Valid. err. 3.17646
2018-02-03 23:29:12,430 training [INFO ] Epoch  5 Batch  860 Training err. 3.07911 Training err. RA 3.23776 Valid. err. 3.20139
2018-02-03 23:29:12,905 training [INFO ] Epoch  5 Batch  880 Training err. 3.13244 Training err. RA 3.23536 Valid. err. 3.17807
2018-02-03 23:29:13,378 training [INFO ] Epoch  5 Batch  900 Training err. 3.11355 Training err. RA 3.23266 Valid. err. 3.17787
2018-02-03 23:29:13,854 training [INFO ] Epoch  5 Batch  920 Training err. 3.09171 Training err. RA 3.22959 Valid. err. 3.18144
2018-02-03 23:29:14,327 training [INFO ] Epoch  5 Batch  940 Training err. 3.15304 Training err. RA 3.22796 Valid. err. 3.18064
2018-02-03 23:29:14,802 training [INFO ] Epoch  5 Batch  960 Training err. 3.12502 Training err. RA 3.22582 Valid. err. 3.18027
2018-02-03 23:29:15,281 training [INFO ] Epoch  5 Batch  980 Training err. 3.11769 Training err. RA 3.22361 Valid. err. 3.17644
2018-02-03 23:29:15,756 training [INFO ] Epoch  5 Batch 1000 Training err. 3.08118 Training err. RA 3.22076 Valid. err. 3.17575
2018-02-03 23:29:16,233 training [INFO ] Epoch  5 Batch 1020 Training err. 3.15899 Training err. RA 3.21955 Valid. err. 3.17394
2018-02-03 23:29:16,711 training [INFO ] Epoch  5 Batch 1040 Training err. 3.14474 Training err. RA 3.21811 Valid. err. 3.17050
2018-02-03 23:29:17,581 training [INFO ] Epoch  6 Batch 1060 Training err. 3.11068 Training err. RA 3.21609 Valid. err. 3.17273
2018-02-03 23:29:18,060 training [INFO ] Epoch  6 Batch 1080 Training err. 3.09011 Training err. RA 3.21375 Valid. err. 3.17266
2018-02-03 23:29:18,539 training [INFO ] Epoch  6 Batch 1100 Training err. 3.09905 Training err. RA 3.21167 Valid. err. 3.17377
2018-02-03 23:29:19,014 training [INFO ] Epoch  6 Batch 1120 Training err. 3.11653 Training err. RA 3.20997 Valid. err. 3.17298
2018-02-03 23:29:19,488 training [INFO ] Epoch  6 Batch 1140 Training err. 3.11335 Training err. RA 3.20827 Valid. err. 3.17185
2018-02-03 23:29:19,969 training [INFO ] Epoch  6 Batch 1160 Training err. 3.14701 Training err. RA 3.20722 Valid. err. 3.16994
2018-02-03 23:29:20,441 training [INFO ] Epoch  6 Batch 1180 Training err. 3.10419 Training err. RA 3.20547 Valid. err. 3.17045
2018-02-03 23:29:20,914 training [INFO ] Epoch  6 Batch 1200 Training err. 3.07718 Training err. RA 3.20333 Valid. err. 3.16973
2018-02-03 23:29:21,387 training [INFO ] Epoch  6 Batch 1220 Training err. 3.12852 Training err. RA 3.20211 Valid. err. 3.16837
2018-02-03 23:29:21,859 training [INFO ] Epoch  6 Batch 1240 Training err. 3.13936 Training err. RA 3.20110 Valid. err. 3.16421
2018-02-03 23:29:22,721 training [INFO ] Epoch  7 Batch 1260 Training err. 3.12876 Training err. RA 3.19995 Valid. err. 3.17516
2018-02-03 23:29:23,193 training [INFO ] Epoch  7 Batch 1280 Training err. 3.04951 Training err. RA 3.19760 Valid. err. 3.20120
2018-02-03 23:29:23,669 training [INFO ] Epoch  7 Batch 1300 Training err. 3.13053 Training err. RA 3.19656 Valid. err. 3.16448
2018-02-03 23:29:24,145 training [INFO ] Epoch  7 Batch 1320 Training err. 3.09768 Training err. RA 3.19507 Valid. err. 3.16256
2018-02-03 23:29:24,620 training [INFO ] Epoch  7 Batch 1340 Training err. 3.09255 Training err. RA 3.19354 Valid. err. 3.16607
2018-02-03 23:29:25,094 training [INFO ] Epoch  7 Batch 1360 Training err. 3.13151 Training err. RA 3.19262 Valid. err. 3.15957
2018-02-03 23:29:25,568 training [INFO ] Epoch  7 Batch 1380 Training err. 3.10491 Training err. RA 3.19135 Valid. err. 3.16050
2018-02-03 23:29:26,044 training [INFO ] Epoch  7 Batch 1400 Training err. 3.09072 Training err. RA 3.18992 Valid. err. 3.15924
2018-02-03 23:29:26,519 training [INFO ] Epoch  7 Batch 1420 Training err. 3.08410 Training err. RA 3.18843 Valid. err. 3.15573
2018-02-03 23:29:26,996 training [INFO ] Epoch  7 Batch 1440 Training err. 3.12879 Training err. RA 3.18760 Valid. err. 3.15246
2018-02-03 23:29:27,830 training [INFO ] Epoch  8 Batch 1460 Training err. 3.12482 Training err. RA 3.18674 Valid. err. 3.15163
2018-02-03 23:29:28,306 training [INFO ] Epoch  8 Batch 1480 Training err. 3.08848 Training err. RA 3.18541 Valid. err. 3.15961
2018-02-03 23:29:28,778 training [INFO ] Epoch  8 Batch 1500 Training err. 3.08225 Training err. RA 3.18403 Valid. err. 3.14829
2018-02-03 23:29:29,253 training [INFO ] Epoch  8 Batch 1520 Training err. 3.07910 Training err. RA 3.18265 Valid. err. 3.14763
2018-02-03 23:29:29,731 training [INFO ] Epoch  8 Batch 1540 Training err. 3.06869 Training err. RA 3.18117 Valid. err. 3.15169
2018-02-03 23:29:30,207 training [INFO ] Epoch  8 Batch 1560 Training err. 3.12203 Training err. RA 3.18041 Valid. err. 3.14674
2018-02-03 23:29:30,687 training [INFO ] Epoch  8 Batch 1580 Training err. 3.10865 Training err. RA 3.17951 Valid. err. 3.14247
2018-02-03 23:29:31,301 training [INFO ] Epoch  8 Batch 1600 Training err. 3.07165 Training err. RA 3.17816 Valid. err. 3.13987
2018-02-03 23:29:31,778 training [INFO ] Epoch  8 Batch 1620 Training err. 3.03455 Training err. RA 3.17639 Valid. err. 3.13972
2018-02-03 23:29:32,253 training [INFO ] Epoch  8 Batch 1640 Training err. 3.11016 Training err. RA 3.17558 Valid. err. 3.13202
2018-02-03 23:29:32,732 training [INFO ] Epoch  8 Batch 1660 Training err. 3.10923 Training err. RA 3.17478 Valid. err. 3.12598
2018-02-03 23:29:33,679 training [INFO ] Epoch  9 Batch 1680 Training err. 3.08440 Training err. RA 3.17370 Valid. err. 3.12605
2018-02-03 23:29:34,156 training [INFO ] Epoch  9 Batch 1700 Training err. 3.03918 Training err. RA 3.17212 Valid. err. 3.12510
2018-02-03 23:29:34,633 training [INFO ] Epoch  9 Batch 1720 Training err. 3.07540 Training err. RA 3.17099 Valid. err. 3.12237
2018-02-03 23:29:35,107 training [INFO ] Epoch  9 Batch 1740 Training err. 3.06230 Training err. RA 3.16975 Valid. err. 3.11801
2018-02-03 23:29:35,578 training [INFO ] Epoch  9 Batch 1760 Training err. 3.05180 Training err. RA 3.16841 Valid. err. 3.11692
2018-02-03 23:29:36,066 training [INFO ] Epoch  9 Batch 1780 Training err. 3.10192 Training err. RA 3.16766 Valid. err. 3.11063
2018-02-03 23:29:36,540 training [INFO ] Epoch  9 Batch 1800 Training err. 3.04225 Training err. RA 3.16626 Valid. err. 3.10795
2018-02-03 23:29:37,014 training [INFO ] Epoch  9 Batch 1820 Training err. 3.03555 Training err. RA 3.16483 Valid. err. 3.10163
2018-02-03 23:29:37,492 training [INFO ] Epoch  9 Batch 1840 Training err. 3.04562 Training err. RA 3.16353 Valid. err. 3.09678
2018-02-03 23:29:37,969 training [INFO ] Epoch  9 Batch 1860 Training err. 3.06350 Training err. RA 3.16246 Valid. err. 3.09047
2018-02-03 23:29:38,805 training [INFO ] Epoch 10 Batch 1880 Training err. 3.07091 Training err. RA 3.16148 Valid. err. 3.08341
2018-02-03 23:29:39,281 training [INFO ] Epoch 10 Batch 1900 Training err. 3.00784 Training err. RA 3.15987 Valid. err. 3.12411
2018-02-03 23:29:39,758 training [INFO ] Epoch 10 Batch 1920 Training err. 3.05464 Training err. RA 3.15877 Valid. err. 3.07950
2018-02-03 23:29:40,234 training [INFO ] Epoch 10 Batch 1940 Training err. 3.01807 Training err. RA 3.15732 Valid. err. 3.07388
2018-02-03 23:29:40,709 training [INFO ] Epoch 10 Batch 1960 Training err. 2.99625 Training err. RA 3.15568 Valid. err. 3.07354
2018-02-03 23:29:41,186 training [INFO ] Epoch 10 Batch 1980 Training err. 3.05846 Training err. RA 3.15469 Valid. err. 3.06890
2018-02-03 23:29:41,666 training [INFO ] Epoch 10 Batch 2000 Training err. 3.01686 Training err. RA 3.15332 Valid. err. 3.06228
2018-02-03 23:29:42,151 training [INFO ] Epoch 10 Batch 2020 Training err. 2.99659 Training err. RA 3.15176 Valid. err. 3.05497
2018-02-03 23:29:42,623 training [INFO ] Epoch 10 Batch 2040 Training err. 2.96360 Training err. RA 3.14992 Valid. err. 3.04516
2018-02-03 23:29:43,100 training [INFO ] Epoch 10 Batch 2060 Training err. 3.02632 Training err. RA 3.14872 Valid. err. 3.03678
2018-02-03 23:29:43,575 training [INFO ] Epoch 10 Batch 2080 Training err. 3.00752 Training err. RA 3.14736 Valid. err. 3.02611
2018-02-03 23:29:44,515 training [INFO ] Epoch 11 Batch 2100 Training err. 2.98118 Training err. RA 3.14578 Valid. err. 3.02431
2018-02-03 23:29:44,990 training [INFO ] Epoch 11 Batch 2120 Training err. 2.99458 Training err. RA 3.14435 Valid. err. 3.02362
2018-02-03 23:29:45,467 training [INFO ] Epoch 11 Batch 2140 Training err. 2.95578 Training err. RA 3.14259 Valid. err. 3.01668
2018-02-03 23:29:45,941 training [INFO ] Epoch 11 Batch 2160 Training err. 2.96534 Training err. RA 3.14095 Valid. err. 3.01009
2018-02-03 23:29:46,415 training [INFO ] Epoch 11 Batch 2180 Training err. 2.96638 Training err. RA 3.13935 Valid. err. 3.00358
2018-02-03 23:29:46,887 training [INFO ] Epoch 11 Batch 2200 Training err. 2.99397 Training err. RA 3.13803 Valid. err. 2.99612
2018-02-03 23:29:47,362 training [INFO ] Epoch 11 Batch 2220 Training err. 2.93440 Training err. RA 3.13619 Valid. err. 2.99048
2018-02-03 23:29:47,836 training [INFO ] Epoch 11 Batch 2240 Training err. 2.90001 Training err. RA 3.13408 Valid. err. 2.98354
2018-02-03 23:29:48,310 training [INFO ] Epoch 11 Batch 2260 Training err. 2.95473 Training err. RA 3.13249 Valid. err. 2.97629
2018-02-03 23:29:48,786 training [INFO ] Epoch 11 Batch 2280 Training err. 2.95341 Training err. RA 3.13092 Valid. err. 2.96855
2018-02-03 23:29:49,621 training [INFO ] Epoch 12 Batch 2300 Training err. 2.94667 Training err. RA 3.12932 Valid. err. 3.03558
2018-02-03 23:29:50,101 training [INFO ] Epoch 12 Batch 2320 Training err. 2.88867 Training err. RA 3.12725 Valid. err. 3.00234
2018-02-03 23:29:50,577 training [INFO ] Epoch 12 Batch 2340 Training err. 2.93469 Training err. RA 3.12560 Valid. err. 2.95528
2018-02-03 23:29:51,054 training [INFO ] Epoch 12 Batch 2360 Training err. 2.90387 Training err. RA 3.12372 Valid. err. 2.94652
2018-02-03 23:29:51,531 training [INFO ] Epoch 12 Batch 2380 Training err. 2.87830 Training err. RA 3.12166 Valid. err. 2.95625
2018-02-03 23:29:52,007 training [INFO ] Epoch 12 Batch 2400 Training err. 2.92913 Training err. RA 3.12006 Valid. err. 2.93217
2018-02-03 23:29:52,486 training [INFO ] Epoch 12 Batch 2420 Training err. 2.88864 Training err. RA 3.11814 Valid. err. 2.92852
2018-02-03 23:29:52,957 training [INFO ] Epoch 12 Batch 2440 Training err. 2.86270 Training err. RA 3.11605 Valid. err. 2.92276
2018-02-03 23:29:53,430 training [INFO ] Epoch 12 Batch 2460 Training err. 2.85932 Training err. RA 3.11396 Valid. err. 2.91115
2018-02-03 23:29:53,902 training [INFO ] Epoch 12 Batch 2480 Training err. 2.88611 Training err. RA 3.11212 Valid. err. 2.90476
2018-02-03 23:29:54,765 training [INFO ] Epoch 13 Batch 2500 Training err. 2.88490 Training err. RA 3.11031 Valid. err. 2.89588
2018-02-03 23:29:55,241 training [INFO ] Epoch 13 Batch 2520 Training err. 2.84300 Training err. RA 3.10819 Valid. err. 2.93499
2018-02-03 23:29:55,717 training [INFO ] Epoch 13 Batch 2540 Training err. 2.87175 Training err. RA 3.10632 Valid. err. 2.89108
2018-02-03 23:29:56,196 training [INFO ] Epoch 13 Batch 2560 Training err. 2.82684 Training err. RA 3.10414 Valid. err. 2.88115
2018-02-03 23:29:56,670 training [INFO ] Epoch 13 Batch 2580 Training err. 2.80625 Training err. RA 3.10183 Valid. err. 2.87852
2018-02-03 23:29:57,143 training [INFO ] Epoch 13 Batch 2600 Training err. 2.85463 Training err. RA 3.09993 Valid. err. 2.87893
2018-02-03 23:29:57,614 training [INFO ] Epoch 13 Batch 2620 Training err. 2.85179 Training err. RA 3.09804 Valid. err. 2.86168
2018-02-03 23:29:58,090 training [INFO ] Epoch 13 Batch 2640 Training err. 2.79737 Training err. RA 3.09576 Valid. err. 2.85814
2018-02-03 23:29:58,567 training [INFO ] Epoch 13 Batch 2660 Training err. 2.75999 Training err. RA 3.09323 Valid. err. 2.86911
2018-02-03 23:29:59,040 training [INFO ] Epoch 13 Batch 2680 Training err. 2.82474 Training err. RA 3.09123 Valid. err. 2.84171
2018-02-03 23:29:59,521 training [INFO ] Epoch 13 Batch 2700 Training err. 2.83483 Training err. RA 3.08933 Valid. err. 2.83184
2018-02-03 23:30:00,364 training [INFO ] Epoch 14 Batch 2720 Training err. 2.78914 Training err. RA 3.08712 Valid. err. 2.83159
2018-02-03 23:30:00,842 training [INFO ] Epoch 14 Batch 2740 Training err. 2.82390 Training err. RA 3.08520 Valid. err. 2.83738
2018-02-03 23:30:01,317 training [INFO ] Epoch 14 Batch 2760 Training err. 2.80266 Training err. RA 3.08315 Valid. err. 2.83091
2018-02-03 23:30:01,793 training [INFO ] Epoch 14 Batch 2780 Training err. 2.78853 Training err. RA 3.08103 Valid. err. 2.82739
2018-02-03 23:30:02,268 training [INFO ] Epoch 14 Batch 2800 Training err. 2.76629 Training err. RA 3.07879 Valid. err. 2.82305
2018-02-03 23:30:02,743 training [INFO ] Epoch 14 Batch 2820 Training err. 2.82952 Training err. RA 3.07702 Valid. err. 2.81855
2018-02-03 23:30:03,224 training [INFO ] Epoch 14 Batch 2840 Training err. 2.75995 Training err. RA 3.07479 Valid. err. 2.81512
2018-02-03 23:30:03,698 training [INFO ] Epoch 14 Batch 2860 Training err. 2.74364 Training err. RA 3.07247 Valid. err. 2.80541
2018-02-03 23:30:04,177 training [INFO ] Epoch 14 Batch 2880 Training err. 2.76610 Training err. RA 3.07034 Valid. err. 2.80123
2018-02-03 23:30:04,651 training [INFO ] Epoch 14 Batch 2900 Training err. 2.77232 Training err. RA 3.06829 Valid. err. 2.79300
2018-02-03 23:30:05,498 training [INFO ] Epoch 15 Batch 2920 Training err. 2.78297 Training err. RA 3.06633 Valid. err. 2.78764
2018-02-03 23:30:05,975 training [INFO ] Epoch 15 Batch 2940 Training err. 2.71697 Training err. RA 3.06396 Valid. err. 2.88266
2018-02-03 23:30:06,449 training [INFO ] Epoch 15 Batch 2960 Training err. 2.80413 Training err. RA 3.06220 Valid. err. 2.78506
2018-02-03 23:30:06,926 training [INFO ] Epoch 15 Batch 2980 Training err. 2.73075 Training err. RA 3.05998 Valid. err. 2.78142
2018-02-03 23:30:07,400 training [INFO ] Epoch 15 Batch 3000 Training err. 2.69811 Training err. RA 3.05756 Valid. err. 2.78139
2018-02-03 23:30:07,882 training [INFO ] Epoch 15 Batch 3020 Training err. 2.74747 Training err. RA 3.05551 Valid. err. 2.78144
2018-02-03 23:30:08,358 training [INFO ] Epoch 15 Batch 3040 Training err. 2.73595 Training err. RA 3.05341 Valid. err. 2.75879
2018-02-03 23:30:08,834 training [INFO ] Epoch 15 Batch 3060 Training err. 2.71253 Training err. RA 3.05118 Valid. err. 2.75738
2018-02-03 23:30:09,306 training [INFO ] Epoch 15 Batch 3080 Training err. 2.66591 Training err. RA 3.04868 Valid. err. 2.76291
2018-02-03 23:30:09,784 training [INFO ] Epoch 15 Batch 3100 Training err. 2.73681 Training err. RA 3.04667 Valid. err. 2.74448
2018-02-03 23:30:10,262 training [INFO ] Epoch 15 Batch 3120 Training err. 2.73462 Training err. RA 3.04467 Valid. err. 2.74098
2018-02-03 23:30:11,091 training [INFO ] Epoch 16 Batch 3140 Training err. 2.67838 Training err. RA 3.04233 Valid. err. 2.73917
2018-02-03 23:30:11,570 training [INFO ] Epoch 16 Batch 3160 Training err. 2.67719 Training err. RA 3.04002 Valid. err. 2.73806
2018-02-03 23:30:12,048 training [INFO ] Epoch 16 Batch 3180 Training err. 2.67661 Training err. RA 3.03774 Valid. err. 2.72947
2018-02-03 23:30:12,524 training [INFO ] Epoch 16 Batch 3200 Training err. 2.68184 Training err. RA 3.03551 Valid. err. 2.72388
2018-02-03 23:30:12,999 training [INFO ] Epoch 16 Batch 3220 Training err. 2.66792 Training err. RA 3.03323 Valid. err. 2.72211
2018-02-03 23:30:13,472 training [INFO ] Epoch 16 Batch 3240 Training err. 2.72602 Training err. RA 3.03133 Valid. err. 2.72904
2018-02-03 23:30:13,949 training [INFO ] Epoch 16 Batch 3260 Training err. 2.67245 Training err. RA 3.02913 Valid. err. 2.72901
2018-02-03 23:30:14,421 training [INFO ] Epoch 16 Batch 3280 Training err. 2.63774 Training err. RA 3.02674 Valid. err. 2.72038
2018-02-03 23:30:14,898 training [INFO ] Epoch 16 Batch 3300 Training err. 2.68230 Training err. RA 3.02466 Valid. err. 2.70449
2018-02-03 23:30:15,373 training [INFO ] Epoch 16 Batch 3320 Training err. 2.69180 Training err. RA 3.02265 Valid. err. 2.70362
2018-02-03 23:30:16,245 training [INFO ] Epoch 17 Batch 3340 Training err. 2.67517 Training err. RA 3.02057 Valid. err. 2.73804
2018-02-03 23:30:16,723 training [INFO ] Epoch 17 Batch 3360 Training err. 2.58240 Training err. RA 3.01796 Valid. err. 2.71108
2018-02-03 23:30:17,199 training [INFO ] Epoch 17 Batch 3380 Training err. 2.69732 Training err. RA 3.01606 Valid. err. 2.68886
2018-02-03 23:30:17,674 training [INFO ] Epoch 17 Batch 3400 Training err. 2.63747 Training err. RA 3.01384 Valid. err. 2.68498
2018-02-03 23:30:18,144 training [INFO ] Epoch 17 Batch 3420 Training err. 2.62004 Training err. RA 3.01153 Valid. err. 2.69248
2018-02-03 23:30:18,624 training [INFO ] Epoch 17 Batch 3440 Training err. 2.67032 Training err. RA 3.00955 Valid. err. 2.68302
2018-02-03 23:30:19,098 training [INFO ] Epoch 17 Batch 3460 Training err. 2.66978 Training err. RA 3.00759 Valid. err. 2.68955
2018-02-03 23:30:19,577 training [INFO ] Epoch 17 Batch 3480 Training err. 2.62789 Training err. RA 3.00540 Valid. err. 2.67189
2018-02-03 23:30:20,052 training [INFO ] Epoch 17 Batch 3500 Training err. 2.62128 Training err. RA 3.00321 Valid. err. 2.67616
2018-02-03 23:30:20,528 training [INFO ] Epoch 17 Batch 3520 Training err. 2.64740 Training err. RA 3.00119 Valid. err. 2.67080
2018-02-03 23:30:21,363 training [INFO ] Epoch 18 Batch 3540 Training err. 2.65726 Training err. RA 2.99925 Valid. err. 2.67424
2018-02-03 23:30:21,838 training [INFO ] Epoch 18 Batch 3560 Training err. 2.61080 Training err. RA 2.99706 Valid. err. 2.66219
2018-02-03 23:30:22,314 training [INFO ] Epoch 18 Batch 3580 Training err. 2.61016 Training err. RA 2.99490 Valid. err. 2.65430
2018-02-03 23:30:22,788 training [INFO ] Epoch 18 Batch 3600 Training err. 2.60979 Training err. RA 2.99276 Valid. err. 2.65851
2018-02-03 23:30:23,267 training [INFO ] Epoch 18 Batch 3620 Training err. 2.58021 Training err. RA 2.99048 Valid. err. 2.66784
2018-02-03 23:30:23,740 training [INFO ] Epoch 18 Batch 3640 Training err. 2.63459 Training err. RA 2.98853 Valid. err. 2.66894
2018-02-03 23:30:24,217 training [INFO ] Epoch 18 Batch 3660 Training err. 2.66471 Training err. RA 2.98676 Valid. err. 2.65483
2018-02-03 23:30:24,694 training [INFO ] Epoch 18 Batch 3680 Training err. 2.59678 Training err. RA 2.98464 Valid. err. 2.64356
2018-02-03 23:30:25,167 training [INFO ] Epoch 18 Batch 3700 Training err. 2.55883 Training err. RA 2.98234 Valid. err. 2.65033
2018-02-03 23:30:25,644 training [INFO ] Epoch 18 Batch 3720 Training err. 2.61976 Training err. RA 2.98039 Valid. err. 2.63508
2018-02-03 23:30:26,118 training [INFO ] Epoch 18 Batch 3740 Training err. 2.63451 Training err. RA 2.97854 Valid. err. 2.63975
2018-02-03 23:30:26,964 training [INFO ] Epoch 19 Batch 3760 Training err. 2.60574 Training err. RA 2.97655 Valid. err. 2.64145
2018-02-03 23:30:27,438 training [INFO ] Epoch 19 Batch 3780 Training err. 2.53156 Training err. RA 2.97420 Valid. err. 2.64866
2018-02-03 23:30:27,911 training [INFO ] Epoch 19 Batch 3800 Training err. 2.61584 Training err. RA 2.97231 Valid. err. 2.64313
2018-02-03 23:30:28,385 training [INFO ] Epoch 19 Batch 3820 Training err. 2.58190 Training err. RA 2.97027 Valid. err. 2.62533
2018-02-03 23:30:28,859 training [INFO ] Epoch 19 Batch 3840 Training err. 2.55456 Training err. RA 2.96810 Valid. err. 2.62632
2018-02-03 23:30:29,336 training [INFO ] Epoch 19 Batch 3860 Training err. 2.64137 Training err. RA 2.96641 Valid. err. 2.62930
2018-02-03 23:30:29,811 training [INFO ] Epoch 19 Batch 3880 Training err. 2.58790 Training err. RA 2.96446 Valid. err. 2.62172
2018-02-03 23:30:30,296 training [INFO ] Epoch 19 Batch 3900 Training err. 2.56327 Training err. RA 2.96240 Valid. err. 2.61142
2018-02-03 23:30:30,775 training [INFO ] Epoch 19 Batch 3920 Training err. 2.57638 Training err. RA 2.96043 Valid. err. 2.60884
2018-02-03 23:30:31,252 training [INFO ] Epoch 19 Batch 3940 Training err. 2.57722 Training err. RA 2.95849 Valid. err. 2.60346
2018-02-03 23:30:32,092 training [INFO ] Epoch 20 Batch 3960 Training err. 2.60285 Training err. RA 2.95669 Valid. err. 2.60858
2018-02-03 23:30:32,565 training [INFO ] Epoch 20 Batch 3980 Training err. 2.51419 Training err. RA 2.95447 Valid. err. 2.60383
2018-02-03 23:30:33,045 training [INFO ] Epoch 20 Batch 4000 Training err. 2.58968 Training err. RA 2.95264 Valid. err. 2.59699
2018-02-03 23:30:33,515 training [INFO ] Epoch 20 Batch 4020 Training err. 2.56077 Training err. RA 2.95070 Valid. err. 2.59295
2018-02-03 23:30:33,993 training [INFO ] Epoch 20 Batch 4040 Training err. 2.52248 Training err. RA 2.94858 Valid. err. 2.60832
2018-02-03 23:30:34,466 training [INFO ] Epoch 20 Batch 4060 Training err. 2.57719 Training err. RA 2.94675 Valid. err. 2.64725
2018-02-03 23:30:34,938 training [INFO ] Epoch 20 Batch 4080 Training err. 2.59618 Training err. RA 2.94503 Valid. err. 2.59752
2018-02-03 23:30:35,412 training [INFO ] Epoch 20 Batch 4100 Training err. 2.55745 Training err. RA 2.94314 Valid. err. 2.59329
2018-02-03 23:30:35,886 training [INFO ] Epoch 20 Batch 4120 Training err. 2.50550 Training err. RA 2.94101 Valid. err. 2.59962
2018-02-03 23:30:36,365 training [INFO ] Epoch 20 Batch 4140 Training err. 2.57165 Training err. RA 2.93923 Valid. err. 2.58103
2018-02-03 23:30:36,840 training [INFO ] Epoch 20 Batch 4160 Training err. 2.57009 Training err. RA 2.93745 Valid. err. 2.58761
2018-02-03 23:30:37,676 training [INFO ] Epoch 21 Batch 4180 Training err. 2.53683 Training err. RA 2.93554 Valid. err. 2.57703
2018-02-03 23:30:38,152 training [INFO ] Epoch 21 Batch 4200 Training err. 2.50003 Training err. RA 2.93346 Valid. err. 2.58772
2018-02-03 23:30:38,628 training [INFO ] Epoch 21 Batch 4220 Training err. 2.53697 Training err. RA 2.93158 Valid. err. 2.58345
2018-02-03 23:30:39,105 training [INFO ] Epoch 21 Batch 4240 Training err. 2.54186 Training err. RA 2.92975 Valid. err. 2.56638
2018-02-03 23:30:39,580 training [INFO ] Epoch 21 Batch 4260 Training err. 2.52334 Training err. RA 2.92784 Valid. err. 2.56779
2018-02-03 23:30:40,057 training [INFO ] Epoch 21 Batch 4280 Training err. 2.58477 Training err. RA 2.92623 Valid. err. 2.57974
2018-02-03 23:30:40,535 training [INFO ] Epoch 21 Batch 4300 Training err. 2.53282 Training err. RA 2.92440 Valid. err. 2.57352
2018-02-03 23:30:41,010 training [INFO ] Epoch 21 Batch 4320 Training err. 2.49710 Training err. RA 2.92243 Valid. err. 2.57932
2018-02-03 23:30:41,482 training [INFO ] Epoch 21 Batch 4340 Training err. 2.53489 Training err. RA 2.92064 Valid. err. 2.55387
2018-02-03 23:30:41,959 training [INFO ] Epoch 21 Batch 4360 Training err. 2.53176 Training err. RA 2.91886 Valid. err. 2.55488
2018-02-03 23:30:42,792 training [INFO ] Epoch 22 Batch 4380 Training err. 2.53304 Training err. RA 2.91709 Valid. err. 2.60166
2018-02-03 23:30:43,267 training [INFO ] Epoch 22 Batch 4400 Training err. 2.44067 Training err. RA 2.91493 Valid. err. 2.55711
2018-02-03 23:30:43,745 training [INFO ] Epoch 22 Batch 4420 Training err. 2.55442 Training err. RA 2.91330 Valid. err. 2.54290
2018-02-03 23:30:44,220 training [INFO ] Epoch 22 Batch 4440 Training err. 2.51321 Training err. RA 2.91150 Valid. err. 2.54705
2018-02-03 23:30:44,691 training [INFO ] Epoch 22 Batch 4460 Training err. 2.48918 Training err. RA 2.90960 Valid. err. 2.55617
2018-02-03 23:30:45,163 training [INFO ] Epoch 22 Batch 4480 Training err. 2.53296 Training err. RA 2.90792 Valid. err. 2.54336
2018-02-03 23:30:45,702 training [INFO ] Epoch 22 Batch 4500 Training err. 2.55050 Training err. RA 2.90633 Valid. err. 2.55026
2018-02-03 23:30:46,173 training [INFO ] Epoch 22 Batch 4520 Training err. 2.49207 Training err. RA 2.90450 Valid. err. 2.53493
2018-02-03 23:30:46,647 training [INFO ] Epoch 22 Batch 4540 Training err. 2.48949 Training err. RA 2.90267 Valid. err. 2.55404
2018-02-03 23:30:47,126 training [INFO ] Epoch 22 Batch 4560 Training err. 2.50547 Training err. RA 2.90093 Valid. err. 2.54458
2018-02-03 23:30:47,966 training [INFO ] Epoch 23 Batch 4580 Training err. 2.51198 Training err. RA 2.89923 Valid. err. 2.53969
2018-02-03 23:30:48,443 training [INFO ] Epoch 23 Batch 4600 Training err. 2.48138 Training err. RA 2.89741 Valid. err. 2.52594
2018-02-03 23:30:48,919 training [INFO ] Epoch 23 Batch 4620 Training err. 2.47294 Training err. RA 2.89558 Valid. err. 2.52079
2018-02-03 23:30:49,398 training [INFO ] Epoch 23 Batch 4640 Training err. 2.49275 Training err. RA 2.89384 Valid. err. 2.53253
2018-02-03 23:30:49,875 training [INFO ] Epoch 23 Batch 4660 Training err. 2.46200 Training err. RA 2.89199 Valid. err. 2.53516
2018-02-03 23:30:50,348 training [INFO ] Epoch 23 Batch 4680 Training err. 2.50614 Training err. RA 2.89034 Valid. err. 2.53310
2018-02-03 23:30:50,827 training [INFO ] Epoch 23 Batch 4700 Training err. 2.54677 Training err. RA 2.88888 Valid. err. 2.53604
2018-02-03 23:30:51,302 training [INFO ] Epoch 23 Batch 4720 Training err. 2.47040 Training err. RA 2.88710 Valid. err. 2.51482
2018-02-03 23:30:51,779 training [INFO ] Epoch 23 Batch 4740 Training err. 2.44182 Training err. RA 2.88522 Valid. err. 2.51861
2018-02-03 23:30:52,256 training [INFO ] Epoch 23 Batch 4760 Training err. 2.48915 Training err. RA 2.88356 Valid. err. 2.50475
2018-02-03 23:30:52,735 training [INFO ] Epoch 23 Batch 4780 Training err. 2.49559 Training err. RA 2.88194 Valid. err. 2.50786
2018-02-03 23:30:53,597 training [INFO ] Epoch 24 Batch 4800 Training err. 2.47845 Training err. RA 2.88025 Valid. err. 2.53127
2018-02-03 23:30:54,079 training [INFO ] Epoch 24 Batch 4820 Training err. 2.40823 Training err. RA 2.87830 Valid. err. 2.51454
2018-02-03 23:30:54,550 training [INFO ] Epoch 24 Batch 4840 Training err. 2.49323 Training err. RA 2.87670 Valid. err. 2.52184
2018-02-03 23:30:55,024 training [INFO ] Epoch 24 Batch 4860 Training err. 2.47092 Training err. RA 2.87503 Valid. err. 2.50175
2018-02-03 23:30:55,503 training [INFO ] Epoch 24 Batch 4880 Training err. 2.43846 Training err. RA 2.87325 Valid. err. 2.50627
2018-02-03 23:30:55,977 training [INFO ] Epoch 24 Batch 4900 Training err. 2.51927 Training err. RA 2.87180 Valid. err. 2.51639
2018-02-03 23:30:56,452 training [INFO ] Epoch 24 Batch 4920 Training err. 2.48118 Training err. RA 2.87021 Valid. err. 2.49777
2018-02-03 23:30:56,926 training [INFO ] Epoch 24 Batch 4940 Training err. 2.44473 Training err. RA 2.86849 Valid. err. 2.49103
2018-02-03 23:30:57,404 training [INFO ] Epoch 24 Batch 4960 Training err. 2.45884 Training err. RA 2.86684 Valid. err. 2.48540
2018-02-03 23:30:57,881 training [INFO ] Epoch 24 Batch 4980 Training err. 2.44863 Training err. RA 2.86516 Valid. err. 2.48240
2018-02-03 23:30:58,724 training [INFO ] Epoch 25 Batch 5000 Training err. 2.47543 Training err. RA 2.86360 Valid. err. 2.48578
2018-02-03 23:30:59,196 training [INFO ] Epoch 25 Batch 5020 Training err. 2.39988 Training err. RA 2.86175 Valid. err. 2.48975
2018-02-03 23:30:59,671 training [INFO ] Epoch 25 Batch 5040 Training err. 2.47003 Training err. RA 2.86020 Valid. err. 2.47998
2018-02-03 23:31:00,165 training [INFO ] Epoch 25 Batch 5060 Training err. 2.45249 Training err. RA 2.85859 Valid. err. 2.47590
2018-02-03 23:31:00,643 training [INFO ] Epoch 25 Batch 5080 Training err. 2.41245 Training err. RA 2.85683 Valid. err. 2.49477
2018-02-03 23:31:01,120 training [INFO ] Epoch 25 Batch 5100 Training err. 2.45508 Training err. RA 2.85525 Valid. err. 2.51388
2018-02-03 23:31:01,593 training [INFO ] Epoch 25 Batch 5120 Training err. 2.49880 Training err. RA 2.85386 Valid. err. 2.48182
2018-02-03 23:31:02,068 training [INFO ] Epoch 25 Batch 5140 Training err. 2.44457 Training err. RA 2.85227 Valid. err. 2.48134
2018-02-03 23:31:02,544 training [INFO ] Epoch 25 Batch 5160 Training err. 2.39655 Training err. RA 2.85050 Valid. err. 2.47229
2018-02-03 23:31:03,019 training [INFO ] Epoch 25 Batch 5180 Training err. 2.45296 Training err. RA 2.84897 Valid. err. 2.46598
2018-02-03 23:31:03,493 training [INFO ] Epoch 25 Batch 5200 Training err. 2.44760 Training err. RA 2.84742 Valid. err. 2.46861
2018-02-03 23:31:04,327 training [INFO ] Epoch 26 Batch 5220 Training err. 2.42627 Training err. RA 2.84581 Valid. err. 2.46582
2018-02-03 23:31:04,805 training [INFO ] Epoch 26 Batch 5240 Training err. 2.38829 Training err. RA 2.84406 Valid. err. 2.47079
2018-02-03 23:31:05,281 training [INFO ] Epoch 26 Batch 5260 Training err. 2.42961 Training err. RA 2.84249 Valid. err. 2.47097
2018-02-03 23:31:05,754 training [INFO ] Epoch 26 Batch 5280 Training err. 2.43658 Training err. RA 2.84095 Valid. err. 2.46016
2018-02-03 23:31:06,230 training [INFO ] Epoch 26 Batch 5300 Training err. 2.41499 Training err. RA 2.83934 Valid. err. 2.45994
2018-02-03 23:31:06,698 training [INFO ] Epoch 26 Batch 5320 Training err. 2.48218 Training err. RA 2.83800 Valid. err. 2.47103
2018-02-03 23:31:07,171 training [INFO ] Epoch 26 Batch 5340 Training err. 2.42984 Training err. RA 2.83647 Valid. err. 2.46365
2018-02-03 23:31:07,647 training [INFO ] Epoch 26 Batch 5360 Training err. 2.39378 Training err. RA 2.83482 Valid. err. 2.48058
2018-02-03 23:31:08,119 training [INFO ] Epoch 26 Batch 5380 Training err. 2.42556 Training err. RA 2.83330 Valid. err. 2.44820
2018-02-03 23:31:08,595 training [INFO ] Epoch 26 Batch 5400 Training err. 2.42007 Training err. RA 2.83177 Valid. err. 2.45096
2018-02-03 23:31:09,486 training [INFO ] Epoch 27 Batch 5420 Training err. 2.42292 Training err. RA 2.83026 Valid. err. 2.46709
2018-02-03 23:31:09,959 training [INFO ] Epoch 27 Batch 5440 Training err. 2.33905 Training err. RA 2.82845 Valid. err. 2.45209
2018-02-03 23:31:10,434 training [INFO ] Epoch 27 Batch 5460 Training err. 2.44894 Training err. RA 2.82706 Valid. err. 2.43985
2018-02-03 23:31:10,913 training [INFO ] Epoch 27 Batch 5480 Training err. 2.41139 Training err. RA 2.82555 Valid. err. 2.44180
2018-02-03 23:31:11,387 training [INFO ] Epoch 27 Batch 5500 Training err. 2.38527 Training err. RA 2.82395 Valid. err. 2.45593
2018-02-03 23:31:11,865 training [INFO ] Epoch 27 Batch 5520 Training err. 2.42918 Training err. RA 2.82252 Valid. err. 2.45045
2018-02-03 23:31:12,340 training [INFO ] Epoch 27 Batch 5540 Training err. 2.46088 Training err. RA 2.82121 Valid. err. 2.44623
2018-02-03 23:31:12,814 training [INFO ] Epoch 27 Batch 5560 Training err. 2.39158 Training err. RA 2.81966 Valid. err. 2.43582
2018-02-03 23:31:13,297 training [INFO ] Epoch 27 Batch 5580 Training err. 2.39051 Training err. RA 2.81813 Valid. err. 2.46286
2018-02-03 23:31:13,770 training [INFO ] Epoch 27 Batch 5600 Training err. 2.40306 Training err. RA 2.81664 Valid. err. 2.44453
2018-02-03 23:31:14,613 training [INFO ] Epoch 28 Batch 5620 Training err. 2.40954 Training err. RA 2.81520 Valid. err. 2.42676
2018-02-03 23:31:15,082 training [INFO ] Epoch 28 Batch 5640 Training err. 2.37588 Training err. RA 2.81364 Valid. err. 2.43032
2018-02-03 23:31:15,558 training [INFO ] Epoch 28 Batch 5660 Training err. 2.37523 Training err. RA 2.81209 Valid. err. 2.42297
2018-02-03 23:31:16,031 training [INFO ] Epoch 28 Batch 5680 Training err. 2.39767 Training err. RA 2.81063 Valid. err. 2.43229
2018-02-03 23:31:16,504 training [INFO ] Epoch 28 Batch 5700 Training err. 2.36718 Training err. RA 2.80907 Valid. err. 2.43241
2018-02-03 23:31:16,980 training [INFO ] Epoch 28 Batch 5720 Training err. 2.40782 Training err. RA 2.80767 Valid. err. 2.43047
2018-02-03 23:31:17,457 training [INFO ] Epoch 28 Batch 5740 Training err. 2.46152 Training err. RA 2.80646 Valid. err. 2.43610
2018-02-03 23:31:17,933 training [INFO ] Epoch 28 Batch 5760 Training err. 2.37397 Training err. RA 2.80496 Valid. err. 2.42140
2018-02-03 23:31:18,406 training [INFO ] Epoch 28 Batch 5780 Training err. 2.35282 Training err. RA 2.80340 Valid. err. 2.41813
2018-02-03 23:31:18,882 training [INFO ] Epoch 28 Batch 5800 Training err. 2.39062 Training err. RA 2.80197 Valid. err. 2.40969
2018-02-03 23:31:19,366 training [INFO ] Epoch 28 Batch 5820 Training err. 2.40056 Training err. RA 2.80059 Valid. err. 2.42042
2018-02-03 23:31:20,220 training [INFO ] Epoch 29 Batch 5840 Training err. 2.37740 Training err. RA 2.79915 Valid. err. 2.44116
2018-02-03 23:31:20,701 training [INFO ] Epoch 29 Batch 5860 Training err. 2.31716 Training err. RA 2.79750 Valid. err. 2.42196
2018-02-03 23:31:21,185 training [INFO ] Epoch 29 Batch 5880 Training err. 2.40004 Training err. RA 2.79615 Valid. err. 2.42504
2018-02-03 23:31:21,664 training [INFO ] Epoch 29 Batch 5900 Training err. 2.38172 Training err. RA 2.79474 Valid. err. 2.40557
2018-02-03 23:31:22,142 training [INFO ] Epoch 29 Batch 5920 Training err. 2.34764 Training err. RA 2.79323 Valid. err. 2.42325
2018-02-03 23:31:22,625 training [INFO ] Epoch 29 Batch 5940 Training err. 2.43345 Training err. RA 2.79202 Valid. err. 2.43145
2018-02-03 23:31:23,110 training [INFO ] Epoch 29 Batch 5960 Training err. 2.39635 Training err. RA 2.79069 Valid. err. 2.40991
2018-02-03 23:31:23,598 training [INFO ] Epoch 29 Batch 5980 Training err. 2.35535 Training err. RA 2.78924 Valid. err. 2.40676
2018-02-03 23:31:24,082 training [INFO ] Epoch 29 Batch 6000 Training err. 2.37125 Training err. RA 2.78784 Valid. err. 2.39911
2018-02-03 23:31:24,555 training [INFO ] Epoch 29 Batch 6020 Training err. 2.36073 Training err. RA 2.78643 Valid. err. 2.39660
2018-02-03 23:31:25,402 training [INFO ] Epoch 30 Batch 6040 Training err. 2.38540 Training err. RA 2.78510 Valid. err. 2.39405
2018-02-03 23:31:25,875 training [INFO ] Epoch 30 Batch 6060 Training err. 2.30776 Training err. RA 2.78352 Valid. err. 2.39886
2018-02-03 23:31:26,352 training [INFO ] Epoch 30 Batch 6080 Training err. 2.38028 Training err. RA 2.78220 Valid. err. 2.39408
2018-02-03 23:31:26,822 training [INFO ] Epoch 30 Batch 6100 Training err. 2.36924 Training err. RA 2.78084 Valid. err. 2.39526
2018-02-03 23:31:27,294 training [INFO ] Epoch 30 Batch 6120 Training err. 2.32777 Training err. RA 2.77936 Valid. err. 2.41151
2018-02-03 23:31:27,769 training [INFO ] Epoch 30 Batch 6140 Training err. 2.36646 Training err. RA 2.77802 Valid. err. 2.42963
2018-02-03 23:31:28,244 training [INFO ] Epoch 30 Batch 6160 Training err. 2.42495 Training err. RA 2.77687 Valid. err. 2.39250
2018-02-03 23:31:28,714 training [INFO ] Epoch 30 Batch 6180 Training err. 2.35918 Training err. RA 2.77552 Valid. err. 2.40116
2018-02-03 23:31:29,186 training [INFO ] Epoch 30 Batch 6200 Training err. 2.31709 Training err. RA 2.77404 Valid. err. 2.38636
2018-02-03 23:31:29,663 training [INFO ] Epoch 30 Batch 6220 Training err. 2.36635 Training err. RA 2.77273 Valid. err. 2.38457
2018-02-03 23:31:30,143 training [INFO ] Epoch 30 Batch 6240 Training err. 2.36531 Training err. RA 2.77142 Valid. err. 2.38407
2018-02-03 23:31:30,992 training [INFO ] Epoch 31 Batch 6260 Training err. 2.33925 Training err. RA 2.77004 Valid. err. 2.38350
2018-02-03 23:31:31,468 training [INFO ] Epoch 31 Batch 6280 Training err. 2.30117 Training err. RA 2.76855 Valid. err. 2.38748
2018-02-03 23:31:31,946 training [INFO ] Epoch 31 Batch 6300 Training err. 2.34959 Training err. RA 2.76722 Valid. err. 2.38741
2018-02-03 23:31:32,422 training [INFO ] Epoch 31 Batch 6320 Training err. 2.35766 Training err. RA 2.76592 Valid. err. 2.37962
2018-02-03 23:31:32,899 training [INFO ] Epoch 31 Batch 6340 Training err. 2.33332 Training err. RA 2.76456 Valid. err. 2.38139
2018-02-03 23:31:33,378 training [INFO ] Epoch 31 Batch 6360 Training err. 2.40772 Training err. RA 2.76344 Valid. err. 2.39188
2018-02-03 23:31:33,853 training [INFO ] Epoch 31 Batch 6380 Training err. 2.35065 Training err. RA 2.76214 Valid. err. 2.38305
2018-02-03 23:31:34,330 training [INFO ] Epoch 31 Batch 6400 Training err. 2.31660 Training err. RA 2.76075 Valid. err. 2.40912
2018-02-03 23:31:34,805 training [INFO ] Epoch 31 Batch 6420 Training err. 2.34506 Training err. RA 2.75945 Valid. err. 2.37086
2018-02-03 23:31:35,277 training [INFO ] Epoch 31 Batch 6440 Training err. 2.34337 Training err. RA 2.75816 Valid. err. 2.37791
2018-02-03 23:31:36,122 training [INFO ] Epoch 32 Batch 6460 Training err. 2.34211 Training err. RA 2.75687 Valid. err. 2.38171
2018-02-03 23:31:36,592 training [INFO ] Epoch 32 Batch 6480 Training err. 2.25705 Training err. RA 2.75533 Valid. err. 2.36857
2018-02-03 23:31:37,068 training [INFO ] Epoch 32 Batch 6500 Training err. 2.36810 Training err. RA 2.75414 Valid. err. 2.36381
2018-02-03 23:31:37,541 training [INFO ] Epoch 32 Batch 6520 Training err. 2.33725 Training err. RA 2.75286 Valid. err. 2.36656
2018-02-03 23:31:38,019 training [INFO ] Epoch 32 Batch 6540 Training err. 2.30742 Training err. RA 2.75150 Valid. err. 2.37729
2018-02-03 23:31:38,494 training [INFO ] Epoch 32 Batch 6560 Training err. 2.35377 Training err. RA 2.75029 Valid. err. 2.37994
2018-02-03 23:31:38,967 training [INFO ] Epoch 32 Batch 6580 Training err. 2.38949 Training err. RA 2.74919 Valid. err. 2.36852
2018-02-03 23:31:39,441 training [INFO ] Epoch 32 Batch 6600 Training err. 2.31467 Training err. RA 2.74787 Valid. err. 2.36243
2018-02-03 23:31:39,915 training [INFO ] Epoch 32 Batch 6620 Training err. 2.31798 Training err. RA 2.74657 Valid. err. 2.38980
2018-02-03 23:31:40,391 training [INFO ] Epoch 32 Batch 6640 Training err. 2.32695 Training err. RA 2.74531 Valid. err. 2.37618
2018-02-03 23:31:41,239 training [INFO ] Epoch 33 Batch 6660 Training err. 2.33462 Training err. RA 2.74408 Valid. err. 2.35038
2018-02-03 23:31:41,747 training [INFO ] Epoch 33 Batch 6680 Training err. 2.29683 Training err. RA 2.74274 Valid. err. 2.35478
2018-02-03 23:31:42,220 training [INFO ] Epoch 33 Batch 6700 Training err. 2.29763 Training err. RA 2.74141 Valid. err. 2.35009
2018-02-03 23:31:42,701 training [INFO ] Epoch 33 Batch 6720 Training err. 2.32384 Training err. RA 2.74017 Valid. err. 2.35771
2018-02-03 23:31:43,182 training [INFO ] Epoch 33 Batch 6740 Training err. 2.29626 Training err. RA 2.73885 Valid. err. 2.36019
2018-02-03 23:31:43,657 training [INFO ] Epoch 33 Batch 6760 Training err. 2.33254 Training err. RA 2.73765 Valid. err. 2.36265
2018-02-03 23:31:44,131 training [INFO ] Epoch 33 Batch 6780 Training err. 2.39536 Training err. RA 2.73664 Valid. err. 2.35893
2018-02-03 23:31:44,611 training [INFO ] Epoch 33 Batch 6800 Training err. 2.29995 Training err. RA 2.73535 Valid. err. 2.35115
2018-02-03 23:31:45,125 training [INFO ] Epoch 33 Batch 6820 Training err. 2.28367 Training err. RA 2.73403 Valid. err. 2.34725
2018-02-03 23:31:45,652 training [INFO ] Epoch 33 Batch 6840 Training err. 2.31744 Training err. RA 2.73281 Valid. err. 2.33909
2018-02-03 23:31:46,149 training [INFO ] Epoch 33 Batch 6860 Training err. 2.32880 Training err. RA 2.73163 Valid. err. 2.35018
2018-02-03 23:31:47,015 training [INFO ] Epoch 34 Batch 6880 Training err. 2.30314 Training err. RA 2.73039 Valid. err. 2.36171
2018-02-03 23:31:47,499 training [INFO ] Epoch 34 Batch 6900 Training err. 2.24292 Training err. RA 2.72897 Valid. err. 2.34624
2018-02-03 23:31:47,982 training [INFO ] Epoch 34 Batch 6920 Training err. 2.32659 Training err. RA 2.72781 Valid. err. 2.35183
2018-02-03 23:31:48,460 training [INFO ] Epoch 34 Batch 6940 Training err. 2.31140 Training err. RA 2.72661 Valid. err. 2.33465
2018-02-03 23:31:48,934 training [INFO ] Epoch 34 Batch 6960 Training err. 2.27971 Training err. RA 2.72533 Valid. err. 2.34983
2018-02-03 23:31:49,415 training [INFO ] Epoch 34 Batch 6980 Training err. 2.36717 Training err. RA 2.72430 Valid. err. 2.35502
2018-02-03 23:31:49,891 training [INFO ] Epoch 34 Batch 7000 Training err. 2.32688 Training err. RA 2.72317 Valid. err. 2.33952
2018-02-03 23:31:50,365 training [INFO ] Epoch 34 Batch 7020 Training err. 2.28455 Training err. RA 2.72192 Valid. err. 2.34145
2018-02-03 23:31:50,837 training [INFO ] Epoch 34 Batch 7040 Training err. 2.30382 Training err. RA 2.72073 Valid. err. 2.33155
2018-02-03 23:31:51,316 training [INFO ] Epoch 34 Batch 7060 Training err. 2.29250 Training err. RA 2.71952 Valid. err. 2.33227
2018-02-03 23:31:52,310 training [INFO ] Epoch 35 Batch 7080 Training err. 2.31423 Training err. RA 2.71837 Valid. err. 2.32636
2018-02-03 23:31:52,790 training [INFO ] Epoch 35 Batch 7100 Training err. 2.23609 Training err. RA 2.71701 Valid. err. 2.32780
2018-02-03 23:31:53,263 training [INFO ] Epoch 35 Batch 7120 Training err. 2.30958 Training err. RA 2.71587 Valid. err. 2.32491
2018-02-03 23:31:53,735 training [INFO ] Epoch 35 Batch 7140 Training err. 2.29893 Training err. RA 2.71470 Valid. err. 2.33233
2018-02-03 23:31:54,222 training [INFO ] Epoch 35 Batch 7160 Training err. 2.26595 Training err. RA 2.71345 Valid. err. 2.35619
2018-02-03 23:31:54,697 training [INFO ] Epoch 35 Batch 7180 Training err. 2.29625 Training err. RA 2.71228 Valid. err. 2.37315
2018-02-03 23:31:55,176 training [INFO ] Epoch 35 Batch 7200 Training err. 2.36235 Training err. RA 2.71131 Valid. err. 2.32425
2018-02-03 23:31:55,649 training [INFO ] Epoch 35 Batch 7220 Training err. 2.29017 Training err. RA 2.71015 Valid. err. 2.33532
2018-02-03 23:31:56,124 training [INFO ] Epoch 35 Batch 7240 Training err. 2.25303 Training err. RA 2.70888 Valid. err. 2.32073
2018-02-03 23:31:56,594 training [INFO ] Epoch 35 Batch 7260 Training err. 2.29861 Training err. RA 2.70775 Valid. err. 2.31860
2018-02-03 23:31:57,073 training [INFO ] Epoch 35 Batch 7280 Training err. 2.29690 Training err. RA 2.70662 Valid. err. 2.31697
2018-02-03 23:31:57,928 training [INFO ] Epoch 36 Batch 7300 Training err. 2.27284 Training err. RA 2.70543 Valid. err. 2.31654
2018-02-03 23:31:58,408 training [INFO ] Epoch 36 Batch 7320 Training err. 2.23161 Training err. RA 2.70414 Valid. err. 2.31765
2018-02-03 23:31:58,890 training [INFO ] Epoch 36 Batch 7340 Training err. 2.28256 Training err. RA 2.70299 Valid. err. 2.31468
2018-02-03 23:31:59,364 training [INFO ] Epoch 36 Batch 7360 Training err. 2.29376 Training err. RA 2.70188 Valid. err. 2.32232
2018-02-03 23:31:59,844 training [INFO ] Epoch 36 Batch 7380 Training err. 2.27107 Training err. RA 2.70071 Valid. err. 2.31228
2018-02-03 23:32:00,330 training [INFO ] Epoch 36 Batch 7400 Training err. 2.34433 Training err. RA 2.69975 Valid. err. 2.32135
2018-02-03 23:32:00,808 training [INFO ] Epoch 36 Batch 7420 Training err. 2.28577 Training err. RA 2.69863 Valid. err. 2.31809
2018-02-03 23:32:01,285 training [INFO ] Epoch 36 Batch 7440 Training err. 2.25291 Training err. RA 2.69743 Valid. err. 2.34734
2018-02-03 23:32:01,757 training [INFO ] Epoch 36 Batch 7460 Training err. 2.28038 Training err. RA 2.69632 Valid. err. 2.30801
2018-02-03 23:32:02,236 training [INFO ] Epoch 36 Batch 7480 Training err. 2.27899 Training err. RA 2.69520 Valid. err. 2.31389
2018-02-03 23:32:03,127 training [INFO ] Epoch 37 Batch 7500 Training err. 2.27733 Training err. RA 2.69409 Valid. err. 2.31808
2018-02-03 23:32:03,599 training [INFO ] Epoch 37 Batch 7520 Training err. 2.19256 Training err. RA 2.69275 Valid. err. 2.30304
2018-02-03 23:32:04,077 training [INFO ] Epoch 37 Batch 7540 Training err. 2.30238 Training err. RA 2.69172 Valid. err. 2.30348
2018-02-03 23:32:04,552 training [INFO ] Epoch 37 Batch 7560 Training err. 2.27231 Training err. RA 2.69061 Valid. err. 2.30337
2018-02-03 23:32:05,023 training [INFO ] Epoch 37 Batch 7580 Training err. 2.25295 Training err. RA 2.68945 Valid. err. 2.31152
2018-02-03 23:32:05,499 training [INFO ] Epoch 37 Batch 7600 Training err. 2.29037 Training err. RA 2.68840 Valid. err. 2.31058
2018-02-03 23:32:05,978 training [INFO ] Epoch 37 Batch 7620 Training err. 2.32644 Training err. RA 2.68745 Valid. err. 2.30444
2018-02-03 23:32:06,450 training [INFO ] Epoch 37 Batch 7640 Training err. 2.25138 Training err. RA 2.68631 Valid. err. 2.30107
2018-02-03 23:32:06,927 training [INFO ] Epoch 37 Batch 7660 Training err. 2.25706 Training err. RA 2.68519 Valid. err. 2.33104
2018-02-03 23:32:07,426 training [INFO ] Epoch 37 Batch 7680 Training err. 2.26406 Training err. RA 2.68409 Valid. err. 2.31926
2018-02-03 23:32:08,334 training [INFO ] Epoch 38 Batch 7700 Training err. 2.27118 Training err. RA 2.68302 Valid. err. 2.29268
2018-02-03 23:32:08,818 training [INFO ] Epoch 38 Batch 7720 Training err. 2.23534 Training err. RA 2.68186 Valid. err. 2.29270
2018-02-03 23:32:09,300 training [INFO ] Epoch 38 Batch 7740 Training err. 2.23447 Training err. RA 2.68071 Valid. err. 2.28927
2018-02-03 23:32:09,777 training [INFO ] Epoch 38 Batch 7760 Training err. 2.26203 Training err. RA 2.67963 Valid. err. 2.29225
2018-02-03 23:32:10,256 training [INFO ] Epoch 38 Batch 7780 Training err. 2.24341 Training err. RA 2.67850 Valid. err. 2.30789
2018-02-03 23:32:10,733 training [INFO ] Epoch 38 Batch 7800 Training err. 2.27356 Training err. RA 2.67747 Valid. err. 2.30449
2018-02-03 23:32:11,216 training [INFO ] Epoch 38 Batch 7820 Training err. 2.33179 Training err. RA 2.67658 Valid. err. 2.29463
2018-02-03 23:32:11,693 training [INFO ] Epoch 38 Batch 7840 Training err. 2.24029 Training err. RA 2.67547 Valid. err. 2.29350
2018-02-03 23:32:12,186 training [INFO ] Epoch 38 Batch 7860 Training err. 2.22437 Training err. RA 2.67432 Valid. err. 2.28898
2018-02-03 23:32:12,662 training [INFO ] Epoch 38 Batch 7880 Training err. 2.25753 Training err. RA 2.67326 Valid. err. 2.28196
2018-02-03 23:32:13,145 training [INFO ] Epoch 38 Batch 7900 Training err. 2.26626 Training err. RA 2.67223 Valid. err. 2.29049
2018-02-03 23:32:14,063 training [INFO ] Epoch 39 Batch 7920 Training err. 2.24417 Training err. RA 2.67115 Valid. err. 2.29701
2018-02-03 23:32:14,537 training [INFO ] Epoch 39 Batch 7940 Training err. 2.18414 Training err. RA 2.66993 Valid. err. 2.28219
2018-02-03 23:32:15,015 training [INFO ] Epoch 39 Batch 7960 Training err. 2.26738 Training err. RA 2.66891 Valid. err. 2.29564
2018-02-03 23:32:15,488 training [INFO ] Epoch 39 Batch 7980 Training err. 2.25326 Training err. RA 2.66787 Valid. err. 2.28222
2018-02-03 23:32:15,971 training [INFO ] Epoch 39 Batch 8000 Training err. 2.23030 Training err. RA 2.66678 Valid. err. 2.29955
2018-02-03 23:32:16,444 training [INFO ] Epoch 39 Batch 8020 Training err. 2.30494 Training err. RA 2.66588 Valid. err. 2.28892
2018-02-03 23:32:16,919 training [INFO ] Epoch 39 Batch 8040 Training err. 2.26915 Training err. RA 2.66489 Valid. err. 2.28300
2018-02-03 23:32:17,392 training [INFO ] Epoch 39 Batch 8060 Training err. 2.22636 Training err. RA 2.66380 Valid. err. 2.28872
2018-02-03 23:32:17,868 training [INFO ] Epoch 39 Batch 8080 Training err. 2.24571 Training err. RA 2.66277 Valid. err. 2.27746
2018-02-03 23:32:18,347 training [INFO ] Epoch 39 Batch 8100 Training err. 2.23439 Training err. RA 2.66171 Valid. err. 2.27671
2018-02-03 23:32:19,206 training [INFO ] Epoch 40 Batch 8120 Training err. 2.25454 Training err. RA 2.66071 Valid. err. 2.27109
2018-02-03 23:32:19,683 training [INFO ] Epoch 40 Batch 8140 Training err. 2.18048 Training err. RA 2.65953 Valid. err. 2.27196
2018-02-03 23:32:20,157 training [INFO ] Epoch 40 Batch 8160 Training err. 2.25177 Training err. RA 2.65853 Valid. err. 2.27165
2018-02-03 23:32:20,636 training [INFO ] Epoch 40 Batch 8180 Training err. 2.24403 Training err. RA 2.65751 Valid. err. 2.27720
2018-02-03 23:32:21,117 training [INFO ] Epoch 40 Batch 8200 Training err. 2.21744 Training err. RA 2.65644 Valid. err. 2.28956
2018-02-03 23:32:21,599 training [INFO ] Epoch 40 Batch 8220 Training err. 2.23849 Training err. RA 2.65542 Valid. err. 2.30863
2018-02-03 23:32:22,082 training [INFO ] Epoch 40 Batch 8240 Training err. 2.30533 Training err. RA 2.65457 Valid. err. 2.26838
2018-02-03 23:32:22,555 training [INFO ] Epoch 40 Batch 8260 Training err. 2.23409 Training err. RA 2.65355 Valid. err. 2.27840
2018-02-03 23:32:23,029 training [INFO ] Epoch 40 Batch 8280 Training err. 2.19738 Training err. RA 2.65245 Valid. err. 2.26713
2018-02-03 23:32:23,504 training [INFO ] Epoch 40 Batch 8300 Training err. 2.24211 Training err. RA 2.65146 Valid. err. 2.26549
2018-02-03 23:32:23,992 training [INFO ] Epoch 40 Batch 8320 Training err. 2.23825 Training err. RA 2.65047 Valid. err. 2.26332
2018-02-03 23:32:24,831 training [INFO ] Epoch 41 Batch 8340 Training err. 2.22058 Training err. RA 2.64944 Valid. err. 2.26225
2018-02-03 23:32:25,312 training [INFO ] Epoch 41 Batch 8360 Training err. 2.17692 Training err. RA 2.64831 Valid. err. 2.26232
2018-02-03 23:32:25,780 training [INFO ] Epoch 41 Batch 8380 Training err. 2.23066 Training err. RA 2.64731 Valid. err. 2.26122
2018-02-03 23:32:26,254 training [INFO ] Epoch 41 Batch 8400 Training err. 2.24492 Training err. RA 2.64635 Valid. err. 2.27970
2018-02-03 23:32:26,730 training [INFO ] Epoch 41 Batch 8420 Training err. 2.21693 Training err. RA 2.64533 Valid. err. 2.25989
2018-02-03 23:32:27,212 training [INFO ] Epoch 41 Batch 8440 Training err. 2.28658 Training err. RA 2.64448 Valid. err. 2.26520
2018-02-03 23:32:27,693 training [INFO ] Epoch 41 Batch 8460 Training err. 2.23311 Training err. RA 2.64351 Valid. err. 2.26781
2018-02-03 23:32:28,175 training [INFO ] Epoch 41 Batch 8480 Training err. 2.19965 Training err. RA 2.64247 Valid. err. 2.29119
2018-02-03 23:32:28,652 training [INFO ] Epoch 41 Batch 8500 Training err. 2.22524 Training err. RA 2.64148 Valid. err. 2.25827
2018-02-03 23:32:29,131 training [INFO ] Epoch 41 Batch 8520 Training err. 2.22414 Training err. RA 2.64050 Valid. err. 2.26005
2018-02-03 23:32:30,004 training [INFO ] Epoch 42 Batch 8540 Training err. 2.22403 Training err. RA 2.63953 Valid. err. 2.26640
2018-02-03 23:32:30,479 training [INFO ] Epoch 42 Batch 8560 Training err. 2.14275 Training err. RA 2.63837 Valid. err. 2.25352
2018-02-03 23:32:30,952 training [INFO ] Epoch 42 Batch 8580 Training err. 2.24921 Training err. RA 2.63746 Valid. err. 2.25663
2018-02-03 23:32:31,432 training [INFO ] Epoch 42 Batch 8600 Training err. 2.22407 Training err. RA 2.63650 Valid. err. 2.25331
2018-02-03 23:32:31,907 training [INFO ] Epoch 42 Batch 8620 Training err. 2.20081 Training err. RA 2.63549 Valid. err. 2.26739
2018-02-03 23:32:32,387 training [INFO ] Epoch 42 Batch 8640 Training err. 2.23791 Training err. RA 2.63457 Valid. err. 2.25589
2018-02-03 23:32:32,864 training [INFO ] Epoch 42 Batch 8660 Training err. 2.27538 Training err. RA 2.63374 Valid. err. 2.25203
2018-02-03 23:32:33,347 training [INFO ] Epoch 42 Batch 8680 Training err. 2.20004 Training err. RA 2.63274 Valid. err. 2.25133
2018-02-03 23:32:33,821 training [INFO ] Epoch 42 Batch 8700 Training err. 2.20411 Training err. RA 2.63175 Valid. err. 2.27906
2018-02-03 23:32:34,304 training [INFO ] Epoch 42 Batch 8720 Training err. 2.21235 Training err. RA 2.63079 Valid. err. 2.26902
2018-02-03 23:32:35,170 training [INFO ] Epoch 43 Batch 8740 Training err. 2.21664 Training err. RA 2.62984 Valid. err. 2.24503
2018-02-03 23:32:35,651 training [INFO ] Epoch 43 Batch 8760 Training err. 2.18656 Training err. RA 2.62883 Valid. err. 2.24403
2018-02-03 23:32:36,130 training [INFO ] Epoch 43 Batch 8780 Training err. 2.18529 Training err. RA 2.62782 Valid. err. 2.24155
2018-02-03 23:32:36,605 training [INFO ] Epoch 43 Batch 8800 Training err. 2.21501 Training err. RA 2.62688 Valid. err. 2.24701
2018-02-03 23:32:37,087 training [INFO ] Epoch 43 Batch 8820 Training err. 2.19512 Training err. RA 2.62590 Valid. err. 2.25082
2018-02-03 23:32:37,560 training [INFO ] Epoch 43 Batch 8840 Training err. 2.22257 Training err. RA 2.62499 Valid. err. 2.25075
2018-02-03 23:32:38,040 training [INFO ] Epoch 43 Batch 8860 Training err. 2.27988 Training err. RA 2.62421 Valid. err. 2.24408
2018-02-03 23:32:38,515 training [INFO ] Epoch 43 Batch 8880 Training err. 2.19186 Training err. RA 2.62324 Valid. err. 2.24692
2018-02-03 23:32:38,994 training [INFO ] Epoch 43 Batch 8900 Training err. 2.17394 Training err. RA 2.62223 Valid. err. 2.24233
2018-02-03 23:32:39,467 training [INFO ] Epoch 43 Batch 8920 Training err. 2.20803 Training err. RA 2.62130 Valid. err. 2.23591
2018-02-03 23:32:39,942 training [INFO ] Epoch 43 Batch 8940 Training err. 2.21373 Training err. RA 2.62039 Valid. err. 2.23935
2018-02-03 23:32:40,803 training [INFO ] Epoch 44 Batch 8960 Training err. 2.19494 Training err. RA 2.61944 Valid. err. 2.24757
2018-02-03 23:32:41,277 training [INFO ] Epoch 44 Batch 8980 Training err. 2.13836 Training err. RA 2.61837 Valid. err. 2.23474
2018-02-03 23:32:41,756 training [INFO ] Epoch 44 Batch 9000 Training err. 2.22005 Training err. RA 2.61748 Valid. err. 2.25298
2018-02-03 23:32:42,234 training [INFO ] Epoch 44 Batch 9020 Training err. 2.20807 Training err. RA 2.61658 Valid. err. 2.23482
2018-02-03 23:32:42,714 training [INFO ] Epoch 44 Batch 9040 Training err. 2.18077 Training err. RA 2.61561 Valid. err. 2.26368
2018-02-03 23:32:43,193 training [INFO ] Epoch 44 Batch 9060 Training err. 2.25603 Training err. RA 2.61482 Valid. err. 2.23834
2018-02-03 23:32:43,669 training [INFO ] Epoch 44 Batch 9080 Training err. 2.22213 Training err. RA 2.61395 Valid. err. 2.23729
2018-02-03 23:32:44,146 training [INFO ] Epoch 44 Batch 9100 Training err. 2.17858 Training err. RA 2.61300 Valid. err. 2.24461
2018-02-03 23:32:44,626 training [INFO ] Epoch 44 Batch 9120 Training err. 2.19578 Training err. RA 2.61208 Valid. err. 2.23466
2018-02-03 23:32:45,111 training [INFO ] Epoch 44 Batch 9140 Training err. 2.18679 Training err. RA 2.61115 Valid. err. 2.22864
2018-02-03 23:32:45,981 training [INFO ] Epoch 45 Batch 9160 Training err. 2.20312 Training err. RA 2.61026 Valid. err. 2.22613
2018-02-03 23:32:46,461 training [INFO ] Epoch 45 Batch 9180 Training err. 2.13639 Training err. RA 2.60923 Valid. err. 2.22743
2018-02-03 23:32:46,935 training [INFO ] Epoch 45 Batch 9200 Training err. 2.20478 Training err. RA 2.60835 Valid. err. 2.23017
2018-02-03 23:32:47,414 training [INFO ] Epoch 45 Batch 9220 Training err. 2.20166 Training err. RA 2.60747 Valid. err. 2.23306
2018-02-03 23:32:47,889 training [INFO ] Epoch 45 Batch 9240 Training err. 2.16842 Training err. RA 2.60651 Valid. err. 2.23779
2018-02-03 23:32:48,373 training [INFO ] Epoch 45 Batch 9260 Training err. 2.19224 Training err. RA 2.60562 Valid. err. 2.26181
2018-02-03 23:32:48,850 training [INFO ] Epoch 45 Batch 9280 Training err. 2.26025 Training err. RA 2.60488 Valid. err. 2.22391
2018-02-03 23:32:49,331 training [INFO ] Epoch 45 Batch 9300 Training err. 2.18860 Training err. RA 2.60398 Valid. err. 2.23281
2018-02-03 23:32:49,806 training [INFO ] Epoch 45 Batch 9320 Training err. 2.14972 Training err. RA 2.60301 Valid. err. 2.22396
2018-02-03 23:32:50,281 training [INFO ] Epoch 45 Batch 9340 Training err. 2.19540 Training err. RA 2.60213 Valid. err. 2.22206
2018-02-03 23:32:50,761 training [INFO ] Epoch 45 Batch 9360 Training err. 2.18818 Training err. RA 2.60125 Valid. err. 2.21978
2018-02-03 23:32:51,610 training [INFO ] Epoch 46 Batch 9380 Training err. 2.17681 Training err. RA 2.60034 Valid. err. 2.21870
2018-02-03 23:32:52,092 training [INFO ] Epoch 46 Batch 9400 Training err. 2.13290 Training err. RA 2.59935 Valid. err. 2.21988
2018-02-03 23:32:52,568 training [INFO ] Epoch 46 Batch 9420 Training err. 2.18846 Training err. RA 2.59848 Valid. err. 2.21926
2018-02-03 23:32:53,044 training [INFO ] Epoch 46 Batch 9440 Training err. 2.20094 Training err. RA 2.59763 Valid. err. 2.23021
2018-02-03 23:32:53,520 training [INFO ] Epoch 46 Batch 9460 Training err. 2.17058 Training err. RA 2.59673 Valid. err. 2.21780
2018-02-03 23:32:53,997 training [INFO ] Epoch 46 Batch 9480 Training err. 2.24069 Training err. RA 2.59598 Valid. err. 2.22068
2018-02-03 23:32:54,471 training [INFO ] Epoch 46 Batch 9500 Training err. 2.19023 Training err. RA 2.59513 Valid. err. 2.22671
2018-02-03 23:32:54,945 training [INFO ] Epoch 46 Batch 9520 Training err. 2.15403 Training err. RA 2.59420 Valid. err. 2.24435
2018-02-03 23:32:55,427 training [INFO ] Epoch 46 Batch 9540 Training err. 2.17904 Training err. RA 2.59333 Valid. err. 2.21859
2018-02-03 23:32:55,900 training [INFO ] Epoch 46 Batch 9560 Training err. 2.17857 Training err. RA 2.59246 Valid. err. 2.21746
2018-02-03 23:32:56,776 training [INFO ] Epoch 47 Batch 9580 Training err. 2.17864 Training err. RA 2.59160 Valid. err. 2.22246
2018-02-03 23:32:57,260 training [INFO ] Epoch 47 Batch 9600 Training err. 2.10165 Training err. RA 2.59058 Valid. err. 2.21210
2018-02-03 23:32:57,732 training [INFO ] Epoch 47 Batch 9620 Training err. 2.20517 Training err. RA 2.58978 Valid. err. 2.21671
2018-02-03 23:32:58,207 training [INFO ] Epoch 47 Batch 9640 Training err. 2.18444 Training err. RA 2.58893 Valid. err. 2.21338
2018-02-03 23:32:58,682 training [INFO ] Epoch 47 Batch 9660 Training err. 2.15455 Training err. RA 2.58803 Valid. err. 2.23067
2018-02-03 23:32:59,161 training [INFO ] Epoch 47 Batch 9680 Training err. 2.19474 Training err. RA 2.58722 Valid. err. 2.21246
2018-02-03 23:32:59,638 training [INFO ] Epoch 47 Batch 9700 Training err. 2.23395 Training err. RA 2.58649 Valid. err. 2.21103
2018-02-03 23:33:00,128 training [INFO ] Epoch 47 Batch 9720 Training err. 2.15664 Training err. RA 2.58561 Valid. err. 2.21046
2018-02-03 23:33:00,604 training [INFO ] Epoch 47 Batch 9740 Training err. 2.15876 Training err. RA 2.58473 Valid. err. 2.23084
2018-02-03 23:33:01,089 training [INFO ] Epoch 47 Batch 9760 Training err. 2.16930 Training err. RA 2.58388 Valid. err. 2.22565
2018-02-03 23:33:01,974 training [INFO ] Epoch 48 Batch 9780 Training err. 2.16987 Training err. RA 2.58304 Valid. err. 2.20619
2018-02-03 23:33:02,452 training [INFO ] Epoch 48 Batch 9800 Training err. 2.14531 Training err. RA 2.58214 Valid. err. 2.20561
2018-02-03 23:33:02,930 training [INFO ] Epoch 48 Batch 9820 Training err. 2.14462 Training err. RA 2.58125 Valid. err. 2.20306
2018-02-03 23:33:03,412 training [INFO ] Epoch 48 Batch 9840 Training err. 2.17550 Training err. RA 2.58043 Valid. err. 2.20963
2018-02-03 23:33:03,893 training [INFO ] Epoch 48 Batch 9860 Training err. 2.15268 Training err. RA 2.57956 Valid. err. 2.20891
2018-02-03 23:33:04,377 training [INFO ] Epoch 48 Batch 9880 Training err. 2.18041 Training err. RA 2.57875 Valid. err. 2.20692
2018-02-03 23:33:04,859 training [INFO ] Epoch 48 Batch 9900 Training err. 2.23740 Training err. RA 2.57806 Valid. err. 2.20452
2018-02-03 23:33:05,337 training [INFO ] Epoch 48 Batch 9920 Training err. 2.15156 Training err. RA 2.57720 Valid. err. 2.20851
2018-02-03 23:33:05,816 training [INFO ] Epoch 48 Batch 9940 Training err. 2.13007 Training err. RA 2.57630 Valid. err. 2.20373
2018-02-03 23:33:06,302 training [INFO ] Epoch 48 Batch 9960 Training err. 2.16584 Training err. RA 2.57548 Valid. err. 2.19822
2018-02-03 23:33:06,777 training [INFO ] Epoch 48 Batch 9980 Training err. 2.17016 Training err. RA 2.57466 Valid. err. 2.19643
2018-02-03 23:33:07,637 training [INFO ] Epoch 49 Batch10000 Training err. 2.15235 Training err. RA 2.57382 Valid. err. 2.20773
2018-02-03 23:33:08,110 training [INFO ] Epoch 49 Batch10020 Training err. 2.09998 Training err. RA 2.57287 Valid. err. 2.19694
2018-02-03 23:33:08,582 training [INFO ] Epoch 49 Batch10040 Training err. 2.17983 Training err. RA 2.57209 Valid. err. 2.21504
2018-02-03 23:33:09,062 training [INFO ] Epoch 49 Batch10060 Training err. 2.16905 Training err. RA 2.57129 Valid. err. 2.19553
2018-02-03 23:33:09,547 training [INFO ] Epoch 49 Batch10080 Training err. 2.13980 Training err. RA 2.57043 Valid. err. 2.23008
2018-02-03 23:33:10,031 training [INFO ] Epoch 49 Batch10100 Training err. 2.21479 Training err. RA 2.56973 Valid. err. 2.19886
2018-02-03 23:33:10,512 training [INFO ] Epoch 49 Batch10120 Training err. 2.18365 Training err. RA 2.56897 Valid. err. 2.19925
2018-02-03 23:33:10,984 training [INFO ] Epoch 49 Batch10140 Training err. 2.13663 Training err. RA 2.56811 Valid. err. 2.20608
2018-02-03 23:33:11,459 training [INFO ] Epoch 49 Batch10160 Training err. 2.15292 Training err. RA 2.56730 Valid. err. 2.19959
2018-02-03 23:33:11,942 training [INFO ] Epoch 49 Batch10180 Training err. 2.14640 Training err. RA 2.56647 Valid. err. 2.18890
2018-02-03 23:33:12,800 training [INFO ] Epoch 50 Batch10200 Training err. 2.16151 Training err. RA 2.56568 Valid. err. 2.18919
2018-02-03 23:33:13,283 training [INFO ] Epoch 50 Batch10220 Training err. 2.09870 Training err. RA 2.56476 Valid. err. 2.19095
2018-02-03 23:33:13,759 training [INFO ] Epoch 50 Batch10240 Training err. 2.16484 Training err. RA 2.56398 Valid. err. 2.19622
2018-02-03 23:33:14,235 training [INFO ] Epoch 50 Batch10260 Training err. 2.16460 Training err. RA 2.56320 Valid. err. 2.19566
2018-02-03 23:33:14,704 training [INFO ] Epoch 50 Batch10280 Training err. 2.12754 Training err. RA 2.56235 Valid. err. 2.19867
2018-02-03 23:33:15,191 training [INFO ] Epoch 50 Batch10300 Training err. 2.15263 Training err. RA 2.56156 Valid. err. 2.22419
2018-02-03 23:33:15,670 training [INFO ] Epoch 50 Batch10320 Training err. 2.22241 Training err. RA 2.56090 Valid. err. 2.18757
2018-02-03 23:33:16,150 training [INFO ] Epoch 50 Batch10340 Training err. 2.14963 Training err. RA 2.56011 Valid. err. 2.19622
2018-02-03 23:33:16,634 training [INFO ] Epoch 50 Batch10360 Training err. 2.10837 Training err. RA 2.55923 Valid. err. 2.18788
2018-02-03 23:33:17,110 training [INFO ] Epoch 50 Batch10380 Training err. 2.15518 Training err. RA 2.55846 Valid. err. 2.18654
2018-02-03 23:33:17,590 training [INFO ] Epoch 50 Batch10400 Training err. 2.14560 Training err. RA 2.55766 Valid. err. 2.18328
2018-02-03 23:33:18,467 training [INFO ] Epoch 51 Batch10420 Training err. 2.15821 Training err. RA 2.55690 Valid. err. 2.18385
2018-02-03 23:33:18,956 training [INFO ] Epoch 51 Batch10440 Training err. 2.09512 Training err. RA 2.55601 Valid. err. 2.18560
2018-02-03 23:33:19,436 training [INFO ] Epoch 51 Batch10460 Training err. 2.15096 Training err. RA 2.55524 Valid. err. 2.18373
2018-02-03 23:33:19,916 training [INFO ] Epoch 51 Batch10480 Training err. 2.16264 Training err. RA 2.55449 Valid. err. 2.18932
2018-02-03 23:33:20,398 training [INFO ] Epoch 51 Batch10500 Training err. 2.13178 Training err. RA 2.55368 Valid. err. 2.18302
2018-02-03 23:33:20,877 training [INFO ] Epoch 51 Batch10520 Training err. 2.20174 Training err. RA 2.55301 Valid. err. 2.18547
2018-02-03 23:33:21,376 training [INFO ] Epoch 51 Batch10540 Training err. 2.15439 Training err. RA 2.55226 Valid. err. 2.19287
2018-02-03 23:33:21,914 training [INFO ] Epoch 51 Batch10560 Training err. 2.11323 Training err. RA 2.55142 Valid. err. 2.20427
2018-02-03 23:33:22,416 training [INFO ] Epoch 51 Batch10580 Training err. 2.13864 Training err. RA 2.55064 Valid. err. 2.18432
2018-02-03 23:33:22,895 training [INFO ] Epoch 51 Batch10600 Training err. 2.13962 Training err. RA 2.54987 Valid. err. 2.18299
2018-02-03 23:33:23,803 training [INFO ] Epoch 52 Batch10620 Training err. 2.13910 Training err. RA 2.54910 Valid. err. 2.18508
2018-02-03 23:33:24,285 training [INFO ] Epoch 52 Batch10640 Training err. 2.06593 Training err. RA 2.54819 Valid. err. 2.17696
2018-02-03 23:33:24,766 training [INFO ] Epoch 52 Batch10660 Training err. 2.16715 Training err. RA 2.54747 Valid. err. 2.18080
2018-02-03 23:33:25,247 training [INFO ] Epoch 52 Batch10680 Training err. 2.14950 Training err. RA 2.54673 Valid. err. 2.17957
2018-02-03 23:33:25,722 training [INFO ] Epoch 52 Batch10700 Training err. 2.11668 Training err. RA 2.54592 Valid. err. 2.19605
2018-02-03 23:33:26,200 training [INFO ] Epoch 52 Batch10720 Training err. 2.15642 Training err. RA 2.54520 Valid. err. 2.17761
2018-02-03 23:33:26,681 training [INFO ] Epoch 52 Batch10740 Training err. 2.19901 Training err. RA 2.54455 Valid. err. 2.17745
2018-02-03 23:33:27,160 training [INFO ] Epoch 52 Batch10760 Training err. 2.11870 Training err. RA 2.54376 Valid. err. 2.17591
2018-02-03 23:33:27,639 training [INFO ] Epoch 52 Batch10780 Training err. 2.11933 Training err. RA 2.54297 Valid. err. 2.18820
2018-02-03 23:33:28,121 training [INFO ] Epoch 52 Batch10800 Training err. 2.13172 Training err. RA 2.54221 Valid. err. 2.18723
2018-02-03 23:33:28,982 training [INFO ] Epoch 53 Batch10820 Training err. 2.12821 Training err. RA 2.54145 Valid. err. 2.17252
2018-02-03 23:33:29,455 training [INFO ] Epoch 53 Batch10840 Training err. 2.10921 Training err. RA 2.54065 Valid. err. 2.17372
2018-02-03 23:33:29,935 training [INFO ] Epoch 53 Batch10860 Training err. 2.10988 Training err. RA 2.53985 Valid. err. 2.17037
2018-02-03 23:33:30,413 training [INFO ] Epoch 53 Batch10880 Training err. 2.14015 Training err. RA 2.53912 Valid. err. 2.17703
2018-02-03 23:33:30,889 training [INFO ] Epoch 53 Batch10900 Training err. 2.11744 Training err. RA 2.53835 Valid. err. 2.17637
2018-02-03 23:33:31,370 training [INFO ] Epoch 53 Batch10920 Training err. 2.14344 Training err. RA 2.53762 Valid. err. 2.17075
2018-02-03 23:33:31,843 training [INFO ] Epoch 53 Batch10940 Training err. 2.20145 Training err. RA 2.53701 Valid. err. 2.17174
2018-02-03 23:33:32,320 training [INFO ] Epoch 53 Batch10960 Training err. 2.11663 Training err. RA 2.53624 Valid. err. 2.17597
2018-02-03 23:33:32,795 training [INFO ] Epoch 53 Batch10980 Training err. 2.09174 Training err. RA 2.53543 Valid. err. 2.17083
2018-02-03 23:33:33,272 training [INFO ] Epoch 53 Batch11000 Training err. 2.12841 Training err. RA 2.53469 Valid. err. 2.16624
2018-02-03 23:33:33,745 training [INFO ] Epoch 53 Batch11020 Training err. 2.13289 Training err. RA 2.53396 Valid. err. 2.16169
2018-02-03 23:33:34,605 training [INFO ] Epoch 54 Batch11040 Training err. 2.11309 Training err. RA 2.53320 Valid. err. 2.17430
2018-02-03 23:33:35,078 training [INFO ] Epoch 54 Batch11060 Training err. 2.06742 Training err. RA 2.53236 Valid. err. 2.16530
2018-02-03 23:33:35,552 training [INFO ] Epoch 54 Batch11080 Training err. 2.14411 Training err. RA 2.53166 Valid. err. 2.18184
2018-02-03 23:33:36,032 training [INFO ] Epoch 54 Batch11100 Training err. 2.13538 Training err. RA 2.53094 Valid. err. 2.16342
2018-02-03 23:33:36,509 training [INFO ] Epoch 54 Batch11120 Training err. 2.10514 Training err. RA 2.53018 Valid. err. 2.19355
2018-02-03 23:33:36,991 training [INFO ] Epoch 54 Batch11140 Training err. 2.17865 Training err. RA 2.52955 Valid. err. 2.16583
2018-02-03 23:33:37,464 training [INFO ] Epoch 54 Batch11160 Training err. 2.15091 Training err. RA 2.52887 Valid. err. 2.16622
2018-02-03 23:33:37,937 training [INFO ] Epoch 54 Batch11180 Training err. 2.09946 Training err. RA 2.52810 Valid. err. 2.17332
2018-02-03 23:33:38,413 training [INFO ] Epoch 54 Batch11200 Training err. 2.11592 Training err. RA 2.52736 Valid. err. 2.16999
2018-02-03 23:33:38,887 training [INFO ] Epoch 54 Batch11220 Training err. 2.11062 Training err. RA 2.52662 Valid. err. 2.15625
2018-02-03 23:33:39,761 training [INFO ] Epoch 55 Batch11240 Training err. 2.12054 Training err. RA 2.52590 Valid. err. 2.15823
2018-02-03 23:33:40,238 training [INFO ] Epoch 55 Batch11260 Training err. 2.06639 Training err. RA 2.52508 Valid. err. 2.16034
2018-02-03 23:33:40,716 training [INFO ] Epoch 55 Batch11280 Training err. 2.13058 Training err. RA 2.52438 Valid. err. 2.16661
2018-02-03 23:33:41,192 training [INFO ] Epoch 55 Batch11300 Training err. 2.13160 Training err. RA 2.52369 Valid. err. 2.16415
2018-02-03 23:33:41,671 training [INFO ] Epoch 55 Batch11320 Training err. 2.09426 Training err. RA 2.52293 Valid. err. 2.16897
2018-02-03 23:33:42,152 training [INFO ] Epoch 55 Batch11340 Training err. 2.11721 Training err. RA 2.52221 Valid. err. 2.18907
2018-02-03 23:33:42,628 training [INFO ] Epoch 55 Batch11360 Training err. 2.18944 Training err. RA 2.52163 Valid. err. 2.15653
2018-02-03 23:33:43,109 training [INFO ] Epoch 55 Batch11380 Training err. 2.11539 Training err. RA 2.52091 Valid. err. 2.16549
2018-02-03 23:33:43,581 training [INFO ] Epoch 55 Batch11400 Training err. 2.07301 Training err. RA 2.52013 Valid. err. 2.15680
2018-02-03 23:33:44,053 training [INFO ] Epoch 55 Batch11420 Training err. 2.11961 Training err. RA 2.51943 Valid. err. 2.15610
2018-02-03 23:33:44,524 training [INFO ] Epoch 55 Batch11440 Training err. 2.10883 Training err. RA 2.51871 Valid. err. 2.15172
2018-02-03 23:33:45,434 training [INFO ] Epoch 56 Batch11460 Training err. 2.10379 Training err. RA 2.51798 Valid. err. 2.15269
2018-02-03 23:33:45,905 training [INFO ] Epoch 56 Batch11480 Training err. 2.06398 Training err. RA 2.51719 Valid. err. 2.15434
2018-02-03 23:33:46,388 training [INFO ] Epoch 56 Batch11500 Training err. 2.11843 Training err. RA 2.51650 Valid. err. 2.15237
2018-02-03 23:33:46,864 training [INFO ] Epoch 56 Batch11520 Training err. 2.13120 Training err. RA 2.51583 Valid. err. 2.15839
2018-02-03 23:33:47,343 training [INFO ] Epoch 56 Batch11540 Training err. 2.09761 Training err. RA 2.51511 Valid. err. 2.15326
2018-02-03 23:33:47,821 training [INFO ] Epoch 56 Batch11560 Training err. 2.16811 Training err. RA 2.51451 Valid. err. 2.15532
2018-02-03 23:33:48,309 training [INFO ] Epoch 56 Batch11580 Training err. 2.12350 Training err. RA 2.51383 Valid. err. 2.16331
2018-02-03 23:33:48,786 training [INFO ] Epoch 56 Batch11600 Training err. 2.07815 Training err. RA 2.51308 Valid. err. 2.17181
2018-02-03 23:33:49,263 training [INFO ] Epoch 56 Batch11620 Training err. 2.10377 Training err. RA 2.51237 Valid. err. 2.15455
2018-02-03 23:33:49,739 training [INFO ] Epoch 56 Batch11640 Training err. 2.10568 Training err. RA 2.51168 Valid. err. 2.15387
2018-02-03 23:33:50,605 training [INFO ] Epoch 57 Batch11660 Training err. 2.10474 Training err. RA 2.51098 Valid. err. 2.15414
2018-02-03 23:33:51,083 training [INFO ] Epoch 57 Batch11680 Training err. 2.03557 Training err. RA 2.51016 Valid. err. 2.14630
2018-02-03 23:33:51,556 training [INFO ] Epoch 57 Batch11700 Training err. 2.13393 Training err. RA 2.50952 Valid. err. 2.14928
2018-02-03 23:33:52,035 training [INFO ] Epoch 57 Batch11720 Training err. 2.11866 Training err. RA 2.50885 Valid. err. 2.14941
2018-02-03 23:33:52,511 training [INFO ] Epoch 57 Batch11740 Training err. 2.08550 Training err. RA 2.50813 Valid. err. 2.16248
2018-02-03 23:33:52,986 training [INFO ] Epoch 57 Batch11760 Training err. 2.12186 Training err. RA 2.50748 Valid. err. 2.14828
2018-02-03 23:33:53,456 training [INFO ] Epoch 57 Batch11780 Training err. 2.16849 Training err. RA 2.50690 Valid. err. 2.14774
2018-02-03 23:33:53,937 training [INFO ] Epoch 57 Batch11800 Training err. 2.08559 Training err. RA 2.50619 Valid. err. 2.14597
2018-02-03 23:33:54,418 training [INFO ] Epoch 57 Batch11820 Training err. 2.08594 Training err. RA 2.50547 Valid. err. 2.15401
2018-02-03 23:33:54,895 training [INFO ] Epoch 57 Batch11840 Training err. 2.09832 Training err. RA 2.50479 Valid. err. 2.15526
2018-02-03 23:33:55,785 training [INFO ] Epoch 58 Batch11860 Training err. 2.09360 Training err. RA 2.50409 Valid. err. 2.14164
2018-02-03 23:33:56,258 training [INFO ] Epoch 58 Batch11880 Training err. 2.07763 Training err. RA 2.50338 Valid. err. 2.14567
2018-02-03 23:33:56,735 training [INFO ] Epoch 58 Batch11900 Training err. 2.07961 Training err. RA 2.50266 Valid. err. 2.14158
2018-02-03 23:33:57,215 training [INFO ] Epoch 58 Batch11920 Training err. 2.10846 Training err. RA 2.50200 Valid. err. 2.14814
2018-02-03 23:33:57,691 training [INFO ] Epoch 58 Batch11940 Training err. 2.08850 Training err. RA 2.50131 Valid. err. 2.14854
2018-02-03 23:33:58,175 training [INFO ] Epoch 58 Batch11960 Training err. 2.11048 Training err. RA 2.50066 Valid. err. 2.14060
2018-02-03 23:33:58,651 training [INFO ] Epoch 58 Batch11980 Training err. 2.16986 Training err. RA 2.50010 Valid. err. 2.14254
2018-02-03 23:33:59,127 training [INFO ] Epoch 58 Batch12000 Training err. 2.08563 Training err. RA 2.49941 Valid. err. 2.14712
2018-02-03 23:33:59,599 training [INFO ] Epoch 58 Batch12020 Training err. 2.05901 Training err. RA 2.49868 Valid. err. 2.14189
2018-02-03 23:34:00,075 training [INFO ] Epoch 58 Batch12040 Training err. 2.09552 Training err. RA 2.49801 Valid. err. 2.13768
2018-02-03 23:34:00,555 training [INFO ] Epoch 58 Batch12060 Training err. 2.10027 Training err. RA 2.49735 Valid. err. 2.13246
2018-02-03 23:34:01,409 training [INFO ] Epoch 59 Batch12080 Training err. 2.08049 Training err. RA 2.49666 Valid. err. 2.14389
2018-02-03 23:34:01,880 training [INFO ] Epoch 59 Batch12100 Training err. 2.03865 Training err. RA 2.49590 Valid. err. 2.13799
2018-02-03 23:34:02,354 training [INFO ] Epoch 59 Batch12120 Training err. 2.11244 Training err. RA 2.49527 Valid. err. 2.15058
2018-02-03 23:34:02,831 training [INFO ] Epoch 59 Batch12140 Training err. 2.10644 Training err. RA 2.49463 Valid. err. 2.13519
2018-02-03 23:34:03,311 training [INFO ] Epoch 59 Batch12160 Training err. 2.07556 Training err. RA 2.49394 Valid. err. 2.15965
2018-02-03 23:34:03,784 training [INFO ] Epoch 59 Batch12180 Training err. 2.14632 Training err. RA 2.49337 Valid. err. 2.13689
2018-02-03 23:34:04,260 training [INFO ] Epoch 59 Batch12200 Training err. 2.12179 Training err. RA 2.49276 Valid. err. 2.13690
2018-02-03 23:34:04,733 training [INFO ] Epoch 59 Batch12220 Training err. 2.06717 Training err. RA 2.49206 Valid. err. 2.14451
2018-02-03 23:34:05,211 training [INFO ] Epoch 59 Batch12240 Training err. 2.08432 Training err. RA 2.49140 Valid. err. 2.14313
2018-02-03 23:34:05,685 training [INFO ] Epoch 59 Batch12260 Training err. 2.07885 Training err. RA 2.49072 Valid. err. 2.12798
2018-02-03 23:34:06,549 training [INFO ] Epoch 60 Batch12280 Training err. 2.08765 Training err. RA 2.49007 Valid. err. 2.13066
2018-02-03 23:34:07,028 training [INFO ] Epoch 60 Batch12300 Training err. 2.03755 Training err. RA 2.48933 Valid. err. 2.13297
2018-02-03 23:34:07,504 training [INFO ] Epoch 60 Batch12320 Training err. 2.10076 Training err. RA 2.48870 Valid. err. 2.13978
2018-02-03 23:34:07,978 training [INFO ] Epoch 60 Batch12340 Training err. 2.10225 Training err. RA 2.48808 Valid. err. 2.13637
2018-02-03 23:34:08,451 training [INFO ] Epoch 60 Batch12360 Training err. 2.06637 Training err. RA 2.48739 Valid. err. 2.14255
2018-02-03 23:34:08,928 training [INFO ] Epoch 60 Batch12380 Training err. 2.08562 Training err. RA 2.48674 Valid. err. 2.15756
2018-02-03 23:34:09,407 training [INFO ] Epoch 60 Batch12400 Training err. 2.15986 Training err. RA 2.48622 Valid. err. 2.12904
2018-02-03 23:34:09,889 training [INFO ] Epoch 60 Batch12420 Training err. 2.08494 Training err. RA 2.48557 Valid. err. 2.13843
2018-02-03 23:34:10,369 training [INFO ] Epoch 60 Batch12440 Training err. 2.04281 Training err. RA 2.48486 Valid. err. 2.12942
2018-02-03 23:34:10,848 training [INFO ] Epoch 60 Batch12460 Training err. 2.08816 Training err. RA 2.48422 Valid. err. 2.12836
2018-02-03 23:34:11,322 training [INFO ] Epoch 60 Batch12480 Training err. 2.07690 Training err. RA 2.48357 Valid. err. 2.12363
2018-02-03 23:34:11,590 __main__ [INFO ] End of training
2018-02-03 23:34:18,272 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 23:34:18,272 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 23:34:19,022 training [INFO ] Epoch  1 Batch   20 Training err. 3.65322 Training err. RA 3.65322 Valid. err. 3.27628
2018-02-03 23:34:19,511 training [INFO ] Epoch  1 Batch   40 Training err. 3.16764 Training err. RA 3.41043 Valid. err. 3.20910
2018-02-03 23:34:20,002 training [INFO ] Epoch  1 Batch   60 Training err. 3.14395 Training err. RA 3.32160 Valid. err. 3.21643
2018-02-03 23:34:20,488 training [INFO ] Epoch  1 Batch   80 Training err. 3.14547 Training err. RA 3.27757 Valid. err. 3.19968
2018-02-03 23:34:20,985 training [INFO ] Epoch  1 Batch  100 Training err. 3.13214 Training err. RA 3.24849 Valid. err. 3.18242
2018-02-03 23:34:21,470 training [INFO ] Epoch  1 Batch  120 Training err. 3.15972 Training err. RA 3.23369 Valid. err. 3.18190
2018-02-03 23:34:21,963 training [INFO ] Epoch  1 Batch  140 Training err. 3.11113 Training err. RA 3.21618 Valid. err. 3.17737
2018-02-03 23:34:22,450 training [INFO ] Epoch  1 Batch  160 Training err. 3.07327 Training err. RA 3.19832 Valid. err. 3.17784
2018-02-03 23:34:22,930 training [INFO ] Epoch  1 Batch  180 Training err. 3.13668 Training err. RA 3.19147 Valid. err. 3.15026
2018-02-03 23:34:23,406 training [INFO ] Epoch  1 Batch  200 Training err. 3.10858 Training err. RA 3.18318 Valid. err. 3.12066
2018-02-03 23:34:24,274 training [INFO ] Epoch  2 Batch  220 Training err. 3.08051 Training err. RA 3.17385 Valid. err. 3.24873
2018-02-03 23:34:24,748 training [INFO ] Epoch  2 Batch  240 Training err. 3.01157 Training err. RA 3.16032 Valid. err. 3.18497
2018-02-03 23:34:25,234 training [INFO ] Epoch  2 Batch  260 Training err. 3.02153 Training err. RA 3.14965 Valid. err. 3.01883
2018-02-03 23:34:25,711 training [INFO ] Epoch  2 Batch  280 Training err. 2.96308 Training err. RA 3.13632 Valid. err. 2.96882
2018-02-03 23:34:26,187 training [INFO ] Epoch  2 Batch  300 Training err. 2.88361 Training err. RA 3.11947 Valid. err. 2.94984
2018-02-03 23:34:26,665 training [INFO ] Epoch  2 Batch  320 Training err. 2.91151 Training err. RA 3.10648 Valid. err. 2.88021
2018-02-03 23:34:27,146 training [INFO ] Epoch  2 Batch  340 Training err. 2.83766 Training err. RA 3.09066 Valid. err. 2.88853
2018-02-03 23:34:27,621 training [INFO ] Epoch  2 Batch  360 Training err. 2.78663 Training err. RA 3.07377 Valid. err. 2.88545
2018-02-03 23:34:28,100 training [INFO ] Epoch  2 Batch  380 Training err. 2.75827 Training err. RA 3.05717 Valid. err. 2.76307
2018-02-03 23:34:28,572 training [INFO ] Epoch  2 Batch  400 Training err. 2.73259 Training err. RA 3.04094 Valid. err. 2.75285
2018-02-03 23:34:29,425 training [INFO ] Epoch  3 Batch  420 Training err. 2.71836 Training err. RA 3.02558 Valid. err. 2.72696
2018-02-03 23:34:29,902 training [INFO ] Epoch  3 Batch  440 Training err. 2.67309 Training err. RA 3.00955 Valid. err. 2.71406
2018-02-03 23:34:30,386 training [INFO ] Epoch  3 Batch  460 Training err. 2.69291 Training err. RA 2.99579 Valid. err. 2.66489
2018-02-03 23:34:30,861 training [INFO ] Epoch  3 Batch  480 Training err. 2.60278 Training err. RA 2.97941 Valid. err. 2.62056
2018-02-03 23:34:31,345 training [INFO ] Epoch  3 Batch  500 Training err. 2.58572 Training err. RA 2.96366 Valid. err. 2.67709
2018-02-03 23:34:31,820 training [INFO ] Epoch  3 Batch  520 Training err. 2.58118 Training err. RA 2.94895 Valid. err. 2.61297
2018-02-03 23:34:32,291 training [INFO ] Epoch  3 Batch  540 Training err. 2.59817 Training err. RA 2.93596 Valid. err. 2.57167
2018-02-03 23:34:32,765 training [INFO ] Epoch  3 Batch  560 Training err. 2.50583 Training err. RA 2.92060 Valid. err. 2.53910
2018-02-03 23:34:33,245 training [INFO ] Epoch  3 Batch  580 Training err. 2.46404 Training err. RA 2.90486 Valid. err. 2.52215
2018-02-03 23:34:33,722 training [INFO ] Epoch  3 Batch  600 Training err. 2.49202 Training err. RA 2.89110 Valid. err. 2.49525
2018-02-03 23:34:34,197 training [INFO ] Epoch  3 Batch  620 Training err. 2.49212 Training err. RA 2.87823 Valid. err. 2.47727
2018-02-03 23:34:35,049 training [INFO ] Epoch  4 Batch  640 Training err. 2.43745 Training err. RA 2.86445 Valid. err. 2.46655
2018-02-03 23:34:35,528 training [INFO ] Epoch  4 Batch  660 Training err. 2.35405 Training err. RA 2.84898 Valid. err. 2.44568
2018-02-03 23:34:36,011 training [INFO ] Epoch  4 Batch  680 Training err. 2.44897 Training err. RA 2.83722 Valid. err. 2.44638
2018-02-03 23:34:36,487 training [INFO ] Epoch  4 Batch  700 Training err. 2.40657 Training err. RA 2.82492 Valid. err. 2.44347
2018-02-03 23:34:36,972 training [INFO ] Epoch  4 Batch  720 Training err. 2.36502 Training err. RA 2.81214 Valid. err. 2.41249
2018-02-03 23:34:37,452 training [INFO ] Epoch  4 Batch  740 Training err. 2.43651 Training err. RA 2.80199 Valid. err. 2.41857
2018-02-03 23:34:37,930 training [INFO ] Epoch  4 Batch  760 Training err. 2.37542 Training err. RA 2.79076 Valid. err. 2.38307
2018-02-03 23:34:38,410 training [INFO ] Epoch  4 Batch  780 Training err. 2.32910 Training err. RA 2.77892 Valid. err. 2.37424
2018-02-03 23:34:38,886 training [INFO ] Epoch  4 Batch  800 Training err. 2.33126 Training err. RA 2.76773 Valid. err. 2.34123
2018-02-03 23:34:39,366 training [INFO ] Epoch  4 Batch  820 Training err. 2.29745 Training err. RA 2.75626 Valid. err. 2.35513
2018-02-03 23:34:40,206 training [INFO ] Epoch  5 Batch  840 Training err. 2.32140 Training err. RA 2.74591 Valid. err. 2.33160
2018-02-03 23:34:40,682 training [INFO ] Epoch  5 Batch  860 Training err. 2.22596 Training err. RA 2.73382 Valid. err. 2.32278
2018-02-03 23:34:41,155 training [INFO ] Epoch  5 Batch  880 Training err. 2.29262 Training err. RA 2.72379 Valid. err. 2.31597
2018-02-03 23:34:41,629 training [INFO ] Epoch  5 Batch  900 Training err. 2.30090 Training err. RA 2.71439 Valid. err. 2.31114
2018-02-03 23:34:42,112 training [INFO ] Epoch  5 Batch  920 Training err. 2.22540 Training err. RA 2.70376 Valid. err. 2.32693
2018-02-03 23:34:42,588 training [INFO ] Epoch  5 Batch  940 Training err. 2.26098 Training err. RA 2.69434 Valid. err. 2.34131
2018-02-03 23:34:43,073 training [INFO ] Epoch  5 Batch  960 Training err. 2.31011 Training err. RA 2.68634 Valid. err. 2.25922
2018-02-03 23:34:43,549 training [INFO ] Epoch  5 Batch  980 Training err. 2.22809 Training err. RA 2.67698 Valid. err. 2.38329
2018-02-03 23:34:44,027 training [INFO ] Epoch  5 Batch 1000 Training err. 2.20798 Training err. RA 2.66760 Valid. err. 2.24146
2018-02-03 23:34:44,502 training [INFO ] Epoch  5 Batch 1020 Training err. 2.21054 Training err. RA 2.65864 Valid. err. 2.24074
2018-02-03 23:34:44,980 training [INFO ] Epoch  5 Batch 1040 Training err. 2.18678 Training err. RA 2.64957 Valid. err. 2.23833
2018-02-03 23:34:45,822 training [INFO ] Epoch  6 Batch 1060 Training err. 2.18627 Training err. RA 2.64083 Valid. err. 2.22324
2018-02-03 23:34:46,298 training [INFO ] Epoch  6 Batch 1080 Training err. 2.11847 Training err. RA 2.63115 Valid. err. 2.24861
2018-02-03 23:34:46,779 training [INFO ] Epoch  6 Batch 1100 Training err. 2.20632 Training err. RA 2.62343 Valid. err. 2.20532
2018-02-03 23:34:47,256 training [INFO ] Epoch  6 Batch 1120 Training err. 2.19060 Training err. RA 2.61570 Valid. err. 2.21188
2018-02-03 23:34:47,735 training [INFO ] Epoch  6 Batch 1140 Training err. 2.14871 Training err. RA 2.60751 Valid. err. 2.18807
2018-02-03 23:34:48,228 training [INFO ] Epoch  6 Batch 1160 Training err. 2.22672 Training err. RA 2.60094 Valid. err. 2.18390
2018-02-03 23:34:48,710 training [INFO ] Epoch  6 Batch 1180 Training err. 2.13756 Training err. RA 2.59309 Valid. err. 2.18648
2018-02-03 23:34:49,192 training [INFO ] Epoch  6 Batch 1200 Training err. 2.10517 Training err. RA 2.58496 Valid. err. 2.40745
2018-02-03 23:34:49,668 training [INFO ] Epoch  6 Batch 1220 Training err. 2.13931 Training err. RA 2.57765 Valid. err. 2.18847
2018-02-03 23:34:50,151 training [INFO ] Epoch  6 Batch 1240 Training err. 2.11206 Training err. RA 2.57014 Valid. err. 2.19983
2018-02-03 23:34:51,005 training [INFO ] Epoch  7 Batch 1260 Training err. 2.12091 Training err. RA 2.56301 Valid. err. 2.16370
2018-02-03 23:34:51,479 training [INFO ] Epoch  7 Batch 1280 Training err. 2.02200 Training err. RA 2.55456 Valid. err. 2.14955
2018-02-03 23:34:51,954 training [INFO ] Epoch  7 Batch 1300 Training err. 2.13761 Training err. RA 2.54814 Valid. err. 2.12518
2018-02-03 23:34:52,432 training [INFO ] Epoch  7 Batch 1320 Training err. 2.11738 Training err. RA 2.54162 Valid. err. 2.13384
2018-02-03 23:34:52,906 training [INFO ] Epoch  7 Batch 1340 Training err. 2.06835 Training err. RA 2.53455 Valid. err. 2.13033
2018-02-03 23:34:53,381 training [INFO ] Epoch  7 Batch 1360 Training err. 2.11365 Training err. RA 2.52836 Valid. err. 2.15202
2018-02-03 23:34:53,855 training [INFO ] Epoch  7 Batch 1380 Training err. 2.13393 Training err. RA 2.52265 Valid. err. 2.12365
2018-02-03 23:34:54,336 training [INFO ] Epoch  7 Batch 1400 Training err. 2.04244 Training err. RA 2.51579 Valid. err. 2.13175
2018-02-03 23:34:54,810 training [INFO ] Epoch  7 Batch 1420 Training err. 2.07203 Training err. RA 2.50954 Valid. err. 2.10448
2018-02-03 23:34:55,291 training [INFO ] Epoch  7 Batch 1440 Training err. 2.04482 Training err. RA 2.50308 Valid. err. 2.07731
2018-02-03 23:34:56,155 training [INFO ] Epoch  8 Batch 1460 Training err. 2.04333 Training err. RA 2.49678 Valid. err. 2.11347
2018-02-03 23:34:56,632 training [INFO ] Epoch  8 Batch 1480 Training err. 2.01488 Training err. RA 2.49027 Valid. err. 2.07814
2018-02-03 23:34:57,117 training [INFO ] Epoch  8 Batch 1500 Training err. 2.00810 Training err. RA 2.48384 Valid. err. 2.06844
2018-02-03 23:34:57,595 training [INFO ] Epoch  8 Batch 1520 Training err. 2.05401 Training err. RA 2.47819 Valid. err. 2.07073
2018-02-03 23:34:58,080 training [INFO ] Epoch  8 Batch 1540 Training err. 2.02520 Training err. RA 2.47230 Valid. err. 2.09883
2018-02-03 23:34:58,558 training [INFO ] Epoch  8 Batch 1560 Training err. 2.04816 Training err. RA 2.46687 Valid. err. 2.17362
2018-02-03 23:34:59,035 training [INFO ] Epoch  8 Batch 1580 Training err. 2.10656 Training err. RA 2.46230 Valid. err. 2.05718
2018-02-03 23:34:59,514 training [INFO ] Epoch  8 Batch 1600 Training err. 1.98246 Training err. RA 2.45631 Valid. err. 2.07477
2018-02-03 23:34:59,997 training [INFO ] Epoch  8 Batch 1620 Training err. 1.98779 Training err. RA 2.45052 Valid. err. 2.06894
2018-02-03 23:35:00,481 training [INFO ] Epoch  8 Batch 1640 Training err. 1.99299 Training err. RA 2.44494 Valid. err. 2.04103
2018-02-03 23:35:00,960 training [INFO ] Epoch  8 Batch 1660 Training err. 1.98773 Training err. RA 2.43943 Valid. err. 2.02887
2018-02-03 23:35:01,806 training [INFO ] Epoch  9 Batch 1680 Training err. 1.99532 Training err. RA 2.43415 Valid. err. 2.04130
2018-02-03 23:35:02,282 training [INFO ] Epoch  9 Batch 1700 Training err. 1.92332 Training err. RA 2.42814 Valid. err. 2.04387
2018-02-03 23:35:02,757 training [INFO ] Epoch  9 Batch 1720 Training err. 2.00076 Training err. RA 2.42317 Valid. err. 2.02832
2018-02-03 23:35:03,239 training [INFO ] Epoch  9 Batch 1740 Training err. 2.00128 Training err. RA 2.41832 Valid. err. 2.05228
2018-02-03 23:35:03,711 training [INFO ] Epoch  9 Batch 1760 Training err. 1.96069 Training err. RA 2.41312 Valid. err. 2.07162
2018-02-03 23:35:04,191 training [INFO ] Epoch  9 Batch 1780 Training err. 2.03703 Training err. RA 2.40889 Valid. err. 2.07928
2018-02-03 23:35:04,670 training [INFO ] Epoch  9 Batch 1800 Training err. 1.99012 Training err. RA 2.40424 Valid. err. 2.01046
2018-02-03 23:35:05,145 training [INFO ] Epoch  9 Batch 1820 Training err. 1.92994 Training err. RA 2.39903 Valid. err. 2.00685
2018-02-03 23:35:05,619 training [INFO ] Epoch  9 Batch 1840 Training err. 1.96038 Training err. RA 2.39426 Valid. err. 1.99502
2018-02-03 23:35:06,099 training [INFO ] Epoch  9 Batch 1860 Training err. 1.93850 Training err. RA 2.38936 Valid. err. 2.01409
2018-02-03 23:35:06,965 training [INFO ] Epoch 10 Batch 1880 Training err. 1.96113 Training err. RA 2.38480 Valid. err. 1.99250
2018-02-03 23:35:07,444 training [INFO ] Epoch 10 Batch 1900 Training err. 1.88523 Training err. RA 2.37954 Valid. err. 1.99352
2018-02-03 23:35:07,921 training [INFO ] Epoch 10 Batch 1920 Training err. 1.95257 Training err. RA 2.37510 Valid. err. 2.00865
2018-02-03 23:35:08,399 training [INFO ] Epoch 10 Batch 1940 Training err. 1.96274 Training err. RA 2.37085 Valid. err. 2.00060
2018-02-03 23:35:08,881 training [INFO ] Epoch 10 Batch 1960 Training err. 1.91578 Training err. RA 2.36620 Valid. err. 2.00007
2018-02-03 23:35:09,364 training [INFO ] Epoch 10 Batch 1980 Training err. 1.92721 Training err. RA 2.36177 Valid. err. 2.01323
2018-02-03 23:35:09,850 training [INFO ] Epoch 10 Batch 2000 Training err. 2.01289 Training err. RA 2.35828 Valid. err. 1.97205
2018-02-03 23:35:10,329 training [INFO ] Epoch 10 Batch 2020 Training err. 1.91036 Training err. RA 2.35384 Valid. err. 1.97535
2018-02-03 23:35:10,806 training [INFO ] Epoch 10 Batch 2040 Training err. 1.88434 Training err. RA 2.34924 Valid. err. 1.96889
2018-02-03 23:35:11,281 training [INFO ] Epoch 10 Batch 2060 Training err. 1.91951 Training err. RA 2.34507 Valid. err. 1.96343
2018-02-03 23:35:11,754 training [INFO ] Epoch 10 Batch 2080 Training err. 1.89159 Training err. RA 2.34071 Valid. err. 1.97471
2018-02-03 23:35:12,612 training [INFO ] Epoch 11 Batch 2100 Training err. 1.90794 Training err. RA 2.33659 Valid. err. 1.94574
2018-02-03 23:35:13,094 training [INFO ] Epoch 11 Batch 2120 Training err. 1.84721 Training err. RA 2.33197 Valid. err. 1.96764
2018-02-03 23:35:13,573 training [INFO ] Epoch 11 Batch 2140 Training err. 1.91536 Training err. RA 2.32808 Valid. err. 1.95772
2018-02-03 23:35:14,051 training [INFO ] Epoch 11 Batch 2160 Training err. 1.92473 Training err. RA 2.32434 Valid. err. 1.94893
2018-02-03 23:35:14,529 training [INFO ] Epoch 11 Batch 2180 Training err. 1.87467 Training err. RA 2.32022 Valid. err. 1.93307
2018-02-03 23:35:15,012 training [INFO ] Epoch 11 Batch 2200 Training err. 1.97331 Training err. RA 2.31706 Valid. err. 1.95999
2018-02-03 23:35:15,492 training [INFO ] Epoch 11 Batch 2220 Training err. 1.89413 Training err. RA 2.31325 Valid. err. 1.94730
2018-02-03 23:35:15,975 training [INFO ] Epoch 11 Batch 2240 Training err. 1.84740 Training err. RA 2.30909 Valid. err. 1.98006
2018-02-03 23:35:16,452 training [INFO ] Epoch 11 Batch 2260 Training err. 1.87561 Training err. RA 2.30526 Valid. err. 1.94090
2018-02-03 23:35:16,935 training [INFO ] Epoch 11 Batch 2280 Training err. 1.87399 Training err. RA 2.30147 Valid. err. 1.92238
2018-02-03 23:35:17,798 training [INFO ] Epoch 12 Batch 2300 Training err. 1.87505 Training err. RA 2.29777 Valid. err. 1.94262
2018-02-03 23:35:18,289 training [INFO ] Epoch 12 Batch 2320 Training err. 1.79828 Training err. RA 2.29346 Valid. err. 1.93879
2018-02-03 23:35:18,762 training [INFO ] Epoch 12 Batch 2340 Training err. 1.88651 Training err. RA 2.28998 Valid. err. 1.91421
2018-02-03 23:35:19,244 training [INFO ] Epoch 12 Batch 2360 Training err. 1.89562 Training err. RA 2.28664 Valid. err. 1.92862
2018-02-03 23:35:19,720 training [INFO ] Epoch 12 Batch 2380 Training err. 1.83414 Training err. RA 2.28284 Valid. err. 1.91716
2018-02-03 23:35:20,195 training [INFO ] Epoch 12 Batch 2400 Training err. 1.87725 Training err. RA 2.27946 Valid. err. 1.93663
2018-02-03 23:35:20,669 training [INFO ] Epoch 12 Batch 2420 Training err. 1.92674 Training err. RA 2.27654 Valid. err. 1.92050
2018-02-03 23:35:21,147 training [INFO ] Epoch 12 Batch 2440 Training err. 1.83035 Training err. RA 2.27289 Valid. err. 1.90388
2018-02-03 23:35:21,623 training [INFO ] Epoch 12 Batch 2460 Training err. 1.83631 Training err. RA 2.26934 Valid. err. 1.92537
2018-02-03 23:35:22,100 training [INFO ] Epoch 12 Batch 2480 Training err. 1.83891 Training err. RA 2.26586 Valid. err. 1.88376
2018-02-03 23:35:22,954 training [INFO ] Epoch 13 Batch 2500 Training err. 1.83177 Training err. RA 2.26239 Valid. err. 1.89208
2018-02-03 23:35:23,428 training [INFO ] Epoch 13 Batch 2520 Training err. 1.80837 Training err. RA 2.25879 Valid. err. 1.89167
2018-02-03 23:35:23,911 training [INFO ] Epoch 13 Batch 2540 Training err. 1.80920 Training err. RA 2.25525 Valid. err. 1.89246
2018-02-03 23:35:24,388 training [INFO ] Epoch 13 Batch 2560 Training err. 1.85999 Training err. RA 2.25216 Valid. err. 1.89226
2018-02-03 23:35:24,859 training [INFO ] Epoch 13 Batch 2580 Training err. 1.82789 Training err. RA 2.24887 Valid. err. 1.90930
2018-02-03 23:35:25,342 training [INFO ] Epoch 13 Batch 2600 Training err. 1.83214 Training err. RA 2.24567 Valid. err. 1.91914
2018-02-03 23:35:25,814 training [INFO ] Epoch 13 Batch 2620 Training err. 1.91167 Training err. RA 2.24312 Valid. err. 1.89053
2018-02-03 23:35:26,290 training [INFO ] Epoch 13 Batch 2640 Training err. 1.79997 Training err. RA 2.23976 Valid. err. 1.90545
2018-02-03 23:35:26,768 training [INFO ] Epoch 13 Batch 2660 Training err. 1.79052 Training err. RA 2.23638 Valid. err. 1.89414
2018-02-03 23:35:27,256 training [INFO ] Epoch 13 Batch 2680 Training err. 1.81092 Training err. RA 2.23321 Valid. err. 1.86689
2018-02-03 23:35:27,736 training [INFO ] Epoch 13 Batch 2700 Training err. 1.81496 Training err. RA 2.23011 Valid. err. 1.87504
2018-02-03 23:35:28,610 training [INFO ] Epoch 14 Batch 2720 Training err. 1.79761 Training err. RA 2.22693 Valid. err. 1.88503
2018-02-03 23:35:29,086 training [INFO ] Epoch 14 Batch 2740 Training err. 1.75093 Training err. RA 2.22345 Valid. err. 1.87515
2018-02-03 23:35:29,564 training [INFO ] Epoch 14 Batch 2760 Training err. 1.81873 Training err. RA 2.22052 Valid. err. 1.88180
2018-02-03 23:35:30,060 training [INFO ] Epoch 14 Batch 2780 Training err. 1.83855 Training err. RA 2.21777 Valid. err. 1.86952
2018-02-03 23:35:30,537 training [INFO ] Epoch 14 Batch 2800 Training err. 1.78031 Training err. RA 2.21465 Valid. err. 1.90025
2018-02-03 23:35:31,019 training [INFO ] Epoch 14 Batch 2820 Training err. 1.85811 Training err. RA 2.21212 Valid. err. 1.93146
2018-02-03 23:35:31,492 training [INFO ] Epoch 14 Batch 2840 Training err. 1.82687 Training err. RA 2.20941 Valid. err. 1.86604
2018-02-03 23:35:31,968 training [INFO ] Epoch 14 Batch 2860 Training err. 1.76505 Training err. RA 2.20630 Valid. err. 1.85771
2018-02-03 23:35:32,444 training [INFO ] Epoch 14 Batch 2880 Training err. 1.78808 Training err. RA 2.20339 Valid. err. 1.85633
2018-02-03 23:35:32,918 training [INFO ] Epoch 14 Batch 2900 Training err. 1.77773 Training err. RA 2.20046 Valid. err. 1.89080
2018-02-03 23:35:33,771 training [INFO ] Epoch 15 Batch 2920 Training err. 1.78105 Training err. RA 2.19759 Valid. err. 1.84492
2018-02-03 23:35:34,249 training [INFO ] Epoch 15 Batch 2940 Training err. 1.72976 Training err. RA 2.19440 Valid. err. 1.86021
2018-02-03 23:35:34,726 training [INFO ] Epoch 15 Batch 2960 Training err. 1.78876 Training err. RA 2.19166 Valid. err. 1.87043
2018-02-03 23:35:35,197 training [INFO ] Epoch 15 Batch 2980 Training err. 1.81678 Training err. RA 2.18915 Valid. err. 1.85938
2018-02-03 23:35:35,674 training [INFO ] Epoch 15 Batch 3000 Training err. 1.75919 Training err. RA 2.18628 Valid. err. 1.86823
2018-02-03 23:35:36,154 training [INFO ] Epoch 15 Batch 3020 Training err. 1.76837 Training err. RA 2.18351 Valid. err. 1.87738
2018-02-03 23:35:36,629 training [INFO ] Epoch 15 Batch 3040 Training err. 1.85075 Training err. RA 2.18132 Valid. err. 1.84034
2018-02-03 23:35:37,107 training [INFO ] Epoch 15 Batch 3060 Training err. 1.76281 Training err. RA 2.17859 Valid. err. 1.83947
2018-02-03 23:35:37,583 training [INFO ] Epoch 15 Batch 3080 Training err. 1.73840 Training err. RA 2.17573 Valid. err. 1.83769
2018-02-03 23:35:38,061 training [INFO ] Epoch 15 Batch 3100 Training err. 1.76227 Training err. RA 2.17306 Valid. err. 1.83973
2018-02-03 23:35:38,536 training [INFO ] Epoch 15 Batch 3120 Training err. 1.75443 Training err. RA 2.17038 Valid. err. 1.83092
2018-02-03 23:35:39,410 training [INFO ] Epoch 16 Batch 3140 Training err. 1.74356 Training err. RA 2.16766 Valid. err. 1.83014
2018-02-03 23:35:39,892 training [INFO ] Epoch 16 Batch 3160 Training err. 1.70349 Training err. RA 2.16472 Valid. err. 1.84749
2018-02-03 23:35:40,373 training [INFO ] Epoch 16 Batch 3180 Training err. 1.77405 Training err. RA 2.16227 Valid. err. 1.84195
2018-02-03 23:35:40,848 training [INFO ] Epoch 16 Batch 3200 Training err. 1.79188 Training err. RA 2.15995 Valid. err. 1.83349
2018-02-03 23:35:41,328 training [INFO ] Epoch 16 Batch 3220 Training err. 1.73257 Training err. RA 2.15730 Valid. err. 1.82428
2018-02-03 23:35:41,807 training [INFO ] Epoch 16 Batch 3240 Training err. 1.81453 Training err. RA 2.15518 Valid. err. 1.83560
2018-02-03 23:35:42,289 training [INFO ] Epoch 16 Batch 3260 Training err. 1.76393 Training err. RA 2.15278 Valid. err. 1.83587
2018-02-03 23:35:42,767 training [INFO ] Epoch 16 Batch 3280 Training err. 1.71513 Training err. RA 2.15011 Valid. err. 1.84111
2018-02-03 23:35:43,247 training [INFO ] Epoch 16 Batch 3300 Training err. 1.73845 Training err. RA 2.14762 Valid. err. 1.82483
2018-02-03 23:35:43,726 training [INFO ] Epoch 16 Batch 3320 Training err. 1.73824 Training err. RA 2.14515 Valid. err. 1.81991
2018-02-03 23:35:44,579 training [INFO ] Epoch 17 Batch 3340 Training err. 1.73342 Training err. RA 2.14269 Valid. err. 1.81500
2018-02-03 23:35:45,072 training [INFO ] Epoch 17 Batch 3360 Training err. 1.67512 Training err. RA 2.13990 Valid. err. 1.82126
2018-02-03 23:35:45,549 training [INFO ] Epoch 17 Batch 3380 Training err. 1.74849 Training err. RA 2.13759 Valid. err. 1.80723
2018-02-03 23:35:46,034 training [INFO ] Epoch 17 Batch 3400 Training err. 1.77702 Training err. RA 2.13547 Valid. err. 1.81841
2018-02-03 23:35:46,509 training [INFO ] Epoch 17 Batch 3420 Training err. 1.71294 Training err. RA 2.13299 Valid. err. 1.81326
2018-02-03 23:35:46,986 training [INFO ] Epoch 17 Batch 3440 Training err. 1.74254 Training err. RA 2.13072 Valid. err. 1.81946
2018-02-03 23:35:47,468 training [INFO ] Epoch 17 Batch 3460 Training err. 1.79288 Training err. RA 2.12877 Valid. err. 1.81534
2018-02-03 23:35:47,948 training [INFO ] Epoch 17 Batch 3480 Training err. 1.71179 Training err. RA 2.12637 Valid. err. 1.80854
2018-02-03 23:35:48,427 training [INFO ] Epoch 17 Batch 3500 Training err. 1.71324 Training err. RA 2.12401 Valid. err. 1.81089
2018-02-03 23:35:48,902 training [INFO ] Epoch 17 Batch 3520 Training err. 1.70917 Training err. RA 2.12166 Valid. err. 1.78875
2018-02-03 23:35:49,753 training [INFO ] Epoch 18 Batch 3540 Training err. 1.71107 Training err. RA 2.11934 Valid. err. 1.79032
2018-02-03 23:35:50,227 training [INFO ] Epoch 18 Batch 3560 Training err. 1.68535 Training err. RA 2.11690 Valid. err. 1.79292
2018-02-03 23:35:50,702 training [INFO ] Epoch 18 Batch 3580 Training err. 1.69100 Training err. RA 2.11452 Valid. err. 1.80816
2018-02-03 23:35:51,179 training [INFO ] Epoch 18 Batch 3600 Training err. 1.74308 Training err. RA 2.11246 Valid. err. 1.79977
2018-02-03 23:35:51,650 training [INFO ] Epoch 18 Batch 3620 Training err. 1.72399 Training err. RA 2.11031 Valid. err. 1.81461
2018-02-03 23:35:52,131 training [INFO ] Epoch 18 Batch 3640 Training err. 1.71177 Training err. RA 2.10812 Valid. err. 1.79598
2018-02-03 23:35:52,606 training [INFO ] Epoch 18 Batch 3660 Training err. 1.78568 Training err. RA 2.10636 Valid. err. 1.79599
2018-02-03 23:35:53,088 training [INFO ] Epoch 18 Batch 3680 Training err. 1.69317 Training err. RA 2.10411 Valid. err. 1.80968
2018-02-03 23:35:53,564 training [INFO ] Epoch 18 Batch 3700 Training err. 1.67807 Training err. RA 2.10181 Valid. err. 1.81295
2018-02-03 23:35:54,052 training [INFO ] Epoch 18 Batch 3720 Training err. 1.69130 Training err. RA 2.09960 Valid. err. 1.78046
2018-02-03 23:35:54,529 training [INFO ] Epoch 18 Batch 3740 Training err. 1.70332 Training err. RA 2.09748 Valid. err. 1.79431
2018-02-03 23:35:55,370 training [INFO ] Epoch 19 Batch 3760 Training err. 1.68146 Training err. RA 2.09527 Valid. err. 1.79618
2018-02-03 23:35:55,849 training [INFO ] Epoch 19 Batch 3780 Training err. 1.64650 Training err. RA 2.09290 Valid. err. 1.78440
2018-02-03 23:35:56,325 training [INFO ] Epoch 19 Batch 3800 Training err. 1.70774 Training err. RA 2.09087 Valid. err. 1.79956
2018-02-03 23:35:56,805 training [INFO ] Epoch 19 Batch 3820 Training err. 1.73913 Training err. RA 2.08903 Valid. err. 1.78362
2018-02-03 23:35:57,289 training [INFO ] Epoch 19 Batch 3840 Training err. 1.67999 Training err. RA 2.08690 Valid. err. 1.80296
2018-02-03 23:35:57,768 training [INFO ] Epoch 19 Batch 3860 Training err. 1.74206 Training err. RA 2.08511 Valid. err. 1.79477
2018-02-03 23:35:58,250 training [INFO ] Epoch 19 Batch 3880 Training err. 1.71833 Training err. RA 2.08322 Valid. err. 1.77848
2018-02-03 23:35:58,726 training [INFO ] Epoch 19 Batch 3900 Training err. 1.66463 Training err. RA 2.08107 Valid. err. 1.77577
2018-02-03 23:35:59,199 training [INFO ] Epoch 19 Batch 3920 Training err. 1.67993 Training err. RA 2.07903 Valid. err. 1.76584
2018-02-03 23:35:59,672 training [INFO ] Epoch 19 Batch 3940 Training err. 1.67469 Training err. RA 2.07697 Valid. err. 1.78748
2018-02-03 23:36:00,536 training [INFO ] Epoch 20 Batch 3960 Training err. 1.67277 Training err. RA 2.07493 Valid. err. 1.75904
2018-02-03 23:36:01,017 training [INFO ] Epoch 20 Batch 3980 Training err. 1.63228 Training err. RA 2.07271 Valid. err. 1.77735
2018-02-03 23:36:01,493 training [INFO ] Epoch 20 Batch 4000 Training err. 1.68567 Training err. RA 2.07077 Valid. err. 1.77637
2018-02-03 23:36:01,966 training [INFO ] Epoch 20 Batch 4020 Training err. 1.72287 Training err. RA 2.06904 Valid. err. 1.77847
2018-02-03 23:36:02,442 training [INFO ] Epoch 20 Batch 4040 Training err. 1.67013 Training err. RA 2.06707 Valid. err. 1.79167
2018-02-03 23:36:02,920 training [INFO ] Epoch 20 Batch 4060 Training err. 1.66654 Training err. RA 2.06509 Valid. err. 1.79024
2018-02-03 23:36:03,397 training [INFO ] Epoch 20 Batch 4080 Training err. 1.73892 Training err. RA 2.06350 Valid. err. 1.76585
2018-02-03 23:36:03,876 training [INFO ] Epoch 20 Batch 4100 Training err. 1.67037 Training err. RA 2.06158 Valid. err. 1.76163
2018-02-03 23:36:04,361 training [INFO ] Epoch 20 Batch 4120 Training err. 1.64200 Training err. RA 2.05954 Valid. err. 1.76348
2018-02-03 23:36:04,840 training [INFO ] Epoch 20 Batch 4140 Training err. 1.65891 Training err. RA 2.05761 Valid. err. 1.75211
2018-02-03 23:36:05,317 training [INFO ] Epoch 20 Batch 4160 Training err. 1.65873 Training err. RA 2.05569 Valid. err. 1.75040
2018-02-03 23:36:06,191 training [INFO ] Epoch 21 Batch 4180 Training err. 1.64975 Training err. RA 2.05375 Valid. err. 1.75611
2018-02-03 23:36:06,667 training [INFO ] Epoch 21 Batch 4200 Training err. 1.61158 Training err. RA 2.05164 Valid. err. 1.77527
2018-02-03 23:36:07,150 training [INFO ] Epoch 21 Batch 4220 Training err. 1.68318 Training err. RA 2.04989 Valid. err. 1.76504
2018-02-03 23:36:07,625 training [INFO ] Epoch 21 Batch 4240 Training err. 1.70752 Training err. RA 2.04828 Valid. err. 1.77153
2018-02-03 23:36:08,102 training [INFO ] Epoch 21 Batch 4260 Training err. 1.64163 Training err. RA 2.04637 Valid. err. 1.75447
2018-02-03 23:36:08,579 training [INFO ] Epoch 21 Batch 4280 Training err. 1.71206 Training err. RA 2.04481 Valid. err. 1.75703
2018-02-03 23:36:09,061 training [INFO ] Epoch 21 Batch 4300 Training err. 1.67651 Training err. RA 2.04309 Valid. err. 1.77381
2018-02-03 23:36:09,545 training [INFO ] Epoch 21 Batch 4320 Training err. 1.62917 Training err. RA 2.04118 Valid. err. 1.76507
2018-02-03 23:36:10,027 training [INFO ] Epoch 21 Batch 4340 Training err. 1.64021 Training err. RA 2.03933 Valid. err. 1.74865
2018-02-03 23:36:10,506 training [INFO ] Epoch 21 Batch 4360 Training err. 1.65557 Training err. RA 2.03757 Valid. err. 1.74722
2018-02-03 23:36:11,437 training [INFO ] Epoch 22 Batch 4380 Training err. 1.63568 Training err. RA 2.03574 Valid. err. 1.73858
2018-02-03 23:36:11,932 training [INFO ] Epoch 22 Batch 4400 Training err. 1.59522 Training err. RA 2.03373 Valid. err. 1.74985
2018-02-03 23:36:12,416 training [INFO ] Epoch 22 Batch 4420 Training err. 1.65953 Training err. RA 2.03204 Valid. err. 1.74646
2018-02-03 23:36:12,896 training [INFO ] Epoch 22 Batch 4440 Training err. 1.69701 Training err. RA 2.03053 Valid. err. 1.75054
2018-02-03 23:36:13,383 training [INFO ] Epoch 22 Batch 4460 Training err. 1.63262 Training err. RA 2.02875 Valid. err. 1.74096
2018-02-03 23:36:13,867 training [INFO ] Epoch 22 Batch 4480 Training err. 1.65371 Training err. RA 2.02707 Valid. err. 1.74389
2018-02-03 23:36:14,350 training [INFO ] Epoch 22 Batch 4500 Training err. 1.70089 Training err. RA 2.02562 Valid. err. 1.75029
2018-02-03 23:36:14,839 training [INFO ] Epoch 22 Batch 4520 Training err. 1.63121 Training err. RA 2.02388 Valid. err. 1.74473
2018-02-03 23:36:15,326 training [INFO ] Epoch 22 Batch 4540 Training err. 1.63007 Training err. RA 2.02214 Valid. err. 1.74548
2018-02-03 23:36:15,810 training [INFO ] Epoch 22 Batch 4560 Training err. 1.62264 Training err. RA 2.02039 Valid. err. 1.72523
2018-02-03 23:36:16,692 training [INFO ] Epoch 23 Batch 4580 Training err. 1.62539 Training err. RA 2.01866 Valid. err. 1.73150
2018-02-03 23:36:17,167 training [INFO ] Epoch 23 Batch 4600 Training err. 1.60532 Training err. RA 2.01687 Valid. err. 1.73266
2018-02-03 23:36:17,652 training [INFO ] Epoch 23 Batch 4620 Training err. 1.61270 Training err. RA 2.01512 Valid. err. 1.74924
2018-02-03 23:36:18,136 training [INFO ] Epoch 23 Batch 4640 Training err. 1.66508 Training err. RA 2.01361 Valid. err. 1.73949
2018-02-03 23:36:18,619 training [INFO ] Epoch 23 Batch 4660 Training err. 1.65060 Training err. RA 2.01205 Valid. err. 1.75562
2018-02-03 23:36:19,100 training [INFO ] Epoch 23 Batch 4680 Training err. 1.62834 Training err. RA 2.01041 Valid. err. 1.71980
2018-02-03 23:36:19,580 training [INFO ] Epoch 23 Batch 4700 Training err. 1.69930 Training err. RA 2.00909 Valid. err. 1.73405
2018-02-03 23:36:20,057 training [INFO ] Epoch 23 Batch 4720 Training err. 1.61807 Training err. RA 2.00743 Valid. err. 1.73868
2018-02-03 23:36:20,531 training [INFO ] Epoch 23 Batch 4740 Training err. 1.59938 Training err. RA 2.00571 Valid. err. 1.75583
2018-02-03 23:36:21,011 training [INFO ] Epoch 23 Batch 4760 Training err. 1.60586 Training err. RA 2.00403 Valid. err. 1.71109
2018-02-03 23:36:21,482 training [INFO ] Epoch 23 Batch 4780 Training err. 1.63267 Training err. RA 2.00248 Valid. err. 1.72538
2018-02-03 23:36:22,332 training [INFO ] Epoch 24 Batch 4800 Training err. 1.59393 Training err. RA 2.00077 Valid. err. 1.73700
2018-02-03 23:36:22,804 training [INFO ] Epoch 24 Batch 4820 Training err. 1.57717 Training err. RA 1.99902 Valid. err. 1.72082
2018-02-03 23:36:23,286 training [INFO ] Epoch 24 Batch 4840 Training err. 1.63261 Training err. RA 1.99750 Valid. err. 1.74574
2018-02-03 23:36:23,764 training [INFO ] Epoch 24 Batch 4860 Training err. 1.66755 Training err. RA 1.99614 Valid. err. 1.72315
2018-02-03 23:36:24,245 training [INFO ] Epoch 24 Batch 4880 Training err. 1.60734 Training err. RA 1.99455 Valid. err. 1.74358
2018-02-03 23:36:24,725 training [INFO ] Epoch 24 Batch 4900 Training err. 1.66014 Training err. RA 1.99318 Valid. err. 1.71836
2018-02-03 23:36:25,208 training [INFO ] Epoch 24 Batch 4920 Training err. 1.64499 Training err. RA 1.99177 Valid. err. 1.72233
2018-02-03 23:36:25,685 training [INFO ] Epoch 24 Batch 4940 Training err. 1.59036 Training err. RA 1.99014 Valid. err. 1.71975
2018-02-03 23:36:26,163 training [INFO ] Epoch 24 Batch 4960 Training err. 1.60298 Training err. RA 1.98858 Valid. err. 1.70645
2018-02-03 23:36:26,642 training [INFO ] Epoch 24 Batch 4980 Training err. 1.60701 Training err. RA 1.98705 Valid. err. 1.72206
2018-02-03 23:36:27,496 training [INFO ] Epoch 25 Batch 5000 Training err. 1.59016 Training err. RA 1.98546 Valid. err. 1.70822
2018-02-03 23:36:27,975 training [INFO ] Epoch 25 Batch 5020 Training err. 1.56310 Training err. RA 1.98378 Valid. err. 1.72522
2018-02-03 23:36:28,448 training [INFO ] Epoch 25 Batch 5040 Training err. 1.61533 Training err. RA 1.98232 Valid. err. 1.71007
2018-02-03 23:36:28,921 training [INFO ] Epoch 25 Batch 5060 Training err. 1.65482 Training err. RA 1.98102 Valid. err. 1.72110
2018-02-03 23:36:29,388 training [INFO ] Epoch 25 Batch 5080 Training err. 1.60168 Training err. RA 1.97953 Valid. err. 1.74031
2018-02-03 23:36:29,864 training [INFO ] Epoch 25 Batch 5100 Training err. 1.59400 Training err. RA 1.97802 Valid. err. 1.72862
2018-02-03 23:36:30,347 training [INFO ] Epoch 25 Batch 5120 Training err. 1.66357 Training err. RA 1.97679 Valid. err. 1.71290
2018-02-03 23:36:30,823 training [INFO ] Epoch 25 Batch 5140 Training err. 1.60016 Training err. RA 1.97532 Valid. err. 1.71092
2018-02-03 23:36:31,308 training [INFO ] Epoch 25 Batch 5160 Training err. 1.57319 Training err. RA 1.97377 Valid. err. 1.70620
2018-02-03 23:36:31,783 training [INFO ] Epoch 25 Batch 5180 Training err. 1.58856 Training err. RA 1.97228 Valid. err. 1.69844
2018-02-03 23:36:32,263 training [INFO ] Epoch 25 Batch 5200 Training err. 1.58756 Training err. RA 1.97080 Valid. err. 1.69310
2018-02-03 23:36:33,127 training [INFO ] Epoch 26 Batch 5220 Training err. 1.57780 Training err. RA 1.96929 Valid. err. 1.70710
2018-02-03 23:36:33,606 training [INFO ] Epoch 26 Batch 5240 Training err. 1.54720 Training err. RA 1.96768 Valid. err. 1.72107
2018-02-03 23:36:34,095 training [INFO ] Epoch 26 Batch 5260 Training err. 1.61606 Training err. RA 1.96635 Valid. err. 1.71526
2018-02-03 23:36:34,578 training [INFO ] Epoch 26 Batch 5280 Training err. 1.64465 Training err. RA 1.96513 Valid. err. 1.71824
2018-02-03 23:36:35,060 training [INFO ] Epoch 26 Batch 5300 Training err. 1.57192 Training err. RA 1.96364 Valid. err. 1.71001
2018-02-03 23:36:35,535 training [INFO ] Epoch 26 Batch 5320 Training err. 1.63793 Training err. RA 1.96242 Valid. err. 1.70296
2018-02-03 23:36:36,017 training [INFO ] Epoch 26 Batch 5340 Training err. 1.61178 Training err. RA 1.96111 Valid. err. 1.71543
2018-02-03 23:36:36,492 training [INFO ] Epoch 26 Batch 5360 Training err. 1.56368 Training err. RA 1.95962 Valid. err. 1.71769
2018-02-03 23:36:36,977 training [INFO ] Epoch 26 Batch 5380 Training err. 1.57038 Training err. RA 1.95818 Valid. err. 1.70054
2018-02-03 23:36:37,450 training [INFO ] Epoch 26 Batch 5400 Training err. 1.59745 Training err. RA 1.95684 Valid. err. 1.68621
2018-02-03 23:36:38,304 training [INFO ] Epoch 27 Batch 5420 Training err. 1.55918 Training err. RA 1.95537 Valid. err. 1.68744
2018-02-03 23:36:38,780 training [INFO ] Epoch 27 Batch 5440 Training err. 1.53369 Training err. RA 1.95382 Valid. err. 1.70861
2018-02-03 23:36:39,262 training [INFO ] Epoch 27 Batch 5460 Training err. 1.59559 Training err. RA 1.95251 Valid. err. 1.69802
2018-02-03 23:36:39,747 training [INFO ] Epoch 27 Batch 5480 Training err. 1.63528 Training err. RA 1.95135 Valid. err. 1.70065
2018-02-03 23:36:40,231 training [INFO ] Epoch 27 Batch 5500 Training err. 1.56944 Training err. RA 1.94996 Valid. err. 1.69330
2018-02-03 23:36:40,713 training [INFO ] Epoch 27 Batch 5520 Training err. 1.58642 Training err. RA 1.94865 Valid. err. 1.69884
2018-02-03 23:36:41,198 training [INFO ] Epoch 27 Batch 5540 Training err. 1.63348 Training err. RA 1.94751 Valid. err. 1.71195
2018-02-03 23:36:41,680 training [INFO ] Epoch 27 Batch 5560 Training err. 1.56523 Training err. RA 1.94613 Valid. err. 1.70319
2018-02-03 23:36:42,177 training [INFO ] Epoch 27 Batch 5580 Training err. 1.56829 Training err. RA 1.94478 Valid. err. 1.69641
2018-02-03 23:36:42,653 training [INFO ] Epoch 27 Batch 5600 Training err. 1.56316 Training err. RA 1.94342 Valid. err. 1.67845
2018-02-03 23:36:43,522 training [INFO ] Epoch 28 Batch 5620 Training err. 1.55756 Training err. RA 1.94204 Valid. err. 1.68759
2018-02-03 23:36:43,998 training [INFO ] Epoch 28 Batch 5640 Training err. 1.54177 Training err. RA 1.94062 Valid. err. 1.69021
2018-02-03 23:36:44,472 training [INFO ] Epoch 28 Batch 5660 Training err. 1.55333 Training err. RA 1.93925 Valid. err. 1.69479
2018-02-03 23:36:44,945 training [INFO ] Epoch 28 Batch 5680 Training err. 1.60569 Training err. RA 1.93808 Valid. err. 1.69442
2018-02-03 23:36:45,426 training [INFO ] Epoch 28 Batch 5700 Training err. 1.59183 Training err. RA 1.93687 Valid. err. 1.70864
2018-02-03 23:36:45,898 training [INFO ] Epoch 28 Batch 5720 Training err. 1.56333 Training err. RA 1.93556 Valid. err. 1.67440
2018-02-03 23:36:46,380 training [INFO ] Epoch 28 Batch 5740 Training err. 1.63525 Training err. RA 1.93451 Valid. err. 1.68998
2018-02-03 23:36:46,854 training [INFO ] Epoch 28 Batch 5760 Training err. 1.55642 Training err. RA 1.93320 Valid. err. 1.69103
2018-02-03 23:36:47,329 training [INFO ] Epoch 28 Batch 5780 Training err. 1.54104 Training err. RA 1.93184 Valid. err. 1.70718
2018-02-03 23:36:47,806 training [INFO ] Epoch 28 Batch 5800 Training err. 1.54262 Training err. RA 1.93050 Valid. err. 1.66830
2018-02-03 23:36:48,294 training [INFO ] Epoch 28 Batch 5820 Training err. 1.57747 Training err. RA 1.92929 Valid. err. 1.67973
2018-02-03 23:36:49,149 training [INFO ] Epoch 29 Batch 5840 Training err. 1.52900 Training err. RA 1.92792 Valid. err. 1.69108
2018-02-03 23:36:49,620 training [INFO ] Epoch 29 Batch 5860 Training err. 1.51987 Training err. RA 1.92652 Valid. err. 1.68422
2018-02-03 23:36:50,097 training [INFO ] Epoch 29 Batch 5880 Training err. 1.57479 Training err. RA 1.92533 Valid. err. 1.69659
2018-02-03 23:36:50,575 training [INFO ] Epoch 29 Batch 5900 Training err. 1.61196 Training err. RA 1.92427 Valid. err. 1.67889
2018-02-03 23:36:51,061 training [INFO ] Epoch 29 Batch 5920 Training err. 1.54672 Training err. RA 1.92299 Valid. err. 1.69845
2018-02-03 23:36:51,534 training [INFO ] Epoch 29 Batch 5940 Training err. 1.59631 Training err. RA 1.92189 Valid. err. 1.67097
2018-02-03 23:36:52,011 training [INFO ] Epoch 29 Batch 5960 Training err. 1.58904 Training err. RA 1.92077 Valid. err. 1.68161
2018-02-03 23:36:52,489 training [INFO ] Epoch 29 Batch 5980 Training err. 1.52984 Training err. RA 1.91947 Valid. err. 1.68116
2018-02-03 23:36:52,963 training [INFO ] Epoch 29 Batch 6000 Training err. 1.54354 Training err. RA 1.91821 Valid. err. 1.66649
2018-02-03 23:36:53,437 training [INFO ] Epoch 29 Batch 6020 Training err. 1.55624 Training err. RA 1.91701 Valid. err. 1.67221
2018-02-03 23:36:54,291 training [INFO ] Epoch 30 Batch 6040 Training err. 1.52773 Training err. RA 1.91572 Valid. err. 1.67554
2018-02-03 23:36:54,767 training [INFO ] Epoch 30 Batch 6060 Training err. 1.50757 Training err. RA 1.91437 Valid. err. 1.68891
2018-02-03 23:36:55,250 training [INFO ] Epoch 30 Batch 6080 Training err. 1.56158 Training err. RA 1.91321 Valid. err. 1.67137
2018-02-03 23:36:55,731 training [INFO ] Epoch 30 Batch 6100 Training err. 1.60068 Training err. RA 1.91219 Valid. err. 1.67836
2018-02-03 23:36:56,207 training [INFO ] Epoch 30 Batch 6120 Training err. 1.54653 Training err. RA 1.91099 Valid. err. 1.69563
2018-02-03 23:36:56,686 training [INFO ] Epoch 30 Batch 6140 Training err. 1.53507 Training err. RA 1.90977 Valid. err. 1.68066
2018-02-03 23:36:57,174 training [INFO ] Epoch 30 Batch 6160 Training err. 1.60662 Training err. RA 1.90879 Valid. err. 1.67257
2018-02-03 23:36:57,653 training [INFO ] Epoch 30 Batch 6180 Training err. 1.54148 Training err. RA 1.90760 Valid. err. 1.67304
2018-02-03 23:36:58,139 training [INFO ] Epoch 30 Batch 6200 Training err. 1.51763 Training err. RA 1.90634 Valid. err. 1.66913
2018-02-03 23:36:58,618 training [INFO ] Epoch 30 Batch 6220 Training err. 1.53338 Training err. RA 1.90514 Valid. err. 1.66058
2018-02-03 23:36:59,098 training [INFO ] Epoch 30 Batch 6240 Training err. 1.53366 Training err. RA 1.90395 Valid. err. 1.65744
2018-02-03 23:36:59,945 training [INFO ] Epoch 31 Batch 6260 Training err. 1.52461 Training err. RA 1.90274 Valid. err. 1.66524
2018-02-03 23:37:00,433 training [INFO ] Epoch 31 Batch 6280 Training err. 1.49275 Training err. RA 1.90143 Valid. err. 1.68260
2018-02-03 23:37:00,905 training [INFO ] Epoch 31 Batch 6300 Training err. 1.56343 Training err. RA 1.90036 Valid. err. 1.67913
2018-02-03 23:37:01,387 training [INFO ] Epoch 31 Batch 6320 Training err. 1.59443 Training err. RA 1.89939 Valid. err. 1.67381
2018-02-03 23:37:01,868 training [INFO ] Epoch 31 Batch 6340 Training err. 1.51608 Training err. RA 1.89818 Valid. err. 1.66999
2018-02-03 23:37:02,346 training [INFO ] Epoch 31 Batch 6360 Training err. 1.57955 Training err. RA 1.89718 Valid. err. 1.67045
2018-02-03 23:37:02,827 training [INFO ] Epoch 31 Batch 6380 Training err. 1.56121 Training err. RA 1.89613 Valid. err. 1.67598
2018-02-03 23:37:03,308 training [INFO ] Epoch 31 Batch 6400 Training err. 1.51007 Training err. RA 1.89492 Valid. err. 1.68815
2018-02-03 23:37:03,788 training [INFO ] Epoch 31 Batch 6420 Training err. 1.51515 Training err. RA 1.89374 Valid. err. 1.66785
2018-02-03 23:37:04,271 training [INFO ] Epoch 31 Batch 6440 Training err. 1.55151 Training err. RA 1.89267 Valid. err. 1.65162
2018-02-03 23:37:05,124 training [INFO ] Epoch 32 Batch 6460 Training err. 1.50622 Training err. RA 1.89148 Valid. err. 1.65392
2018-02-03 23:37:05,600 training [INFO ] Epoch 32 Batch 6480 Training err. 1.48376 Training err. RA 1.89022 Valid. err. 1.68889
2018-02-03 23:37:06,083 training [INFO ] Epoch 32 Batch 6500 Training err. 1.54607 Training err. RA 1.88916 Valid. err. 1.66453
2018-02-03 23:37:06,563 training [INFO ] Epoch 32 Batch 6520 Training err. 1.58511 Training err. RA 1.88823 Valid. err. 1.66635
2018-02-03 23:37:07,041 training [INFO ] Epoch 32 Batch 6540 Training err. 1.51824 Training err. RA 1.88710 Valid. err. 1.65882
2018-02-03 23:37:07,535 training [INFO ] Epoch 32 Batch 6560 Training err. 1.53247 Training err. RA 1.88601 Valid. err. 1.66190
2018-02-03 23:37:08,010 training [INFO ] Epoch 32 Batch 6580 Training err. 1.58347 Training err. RA 1.88509 Valid. err. 1.67152
2018-02-03 23:37:08,486 training [INFO ] Epoch 32 Batch 6600 Training err. 1.51247 Training err. RA 1.88397 Valid. err. 1.67801
2018-02-03 23:37:08,960 training [INFO ] Epoch 32 Batch 6620 Training err. 1.51673 Training err. RA 1.88286 Valid. err. 1.66043
2018-02-03 23:37:09,434 training [INFO ] Epoch 32 Batch 6640 Training err. 1.51415 Training err. RA 1.88175 Valid. err. 1.65381
2018-02-03 23:37:10,312 training [INFO ] Epoch 33 Batch 6660 Training err. 1.50678 Training err. RA 1.88062 Valid. err. 1.65984
2018-02-03 23:37:10,789 training [INFO ] Epoch 33 Batch 6680 Training err. 1.49295 Training err. RA 1.87946 Valid. err. 1.66010
2018-02-03 23:37:11,273 training [INFO ] Epoch 33 Batch 6700 Training err. 1.50375 Training err. RA 1.87834 Valid. err. 1.66157
2018-02-03 23:37:11,749 training [INFO ] Epoch 33 Batch 6720 Training err. 1.55812 Training err. RA 1.87738 Valid. err. 1.65951
2018-02-03 23:37:12,233 training [INFO ] Epoch 33 Batch 6740 Training err. 1.54341 Training err. RA 1.87639 Valid. err. 1.67802
2018-02-03 23:37:12,710 training [INFO ] Epoch 33 Batch 6760 Training err. 1.51214 Training err. RA 1.87532 Valid. err. 1.64630
2018-02-03 23:37:13,193 training [INFO ] Epoch 33 Batch 6780 Training err. 1.58420 Training err. RA 1.87446 Valid. err. 1.66081
2018-02-03 23:37:13,668 training [INFO ] Epoch 33 Batch 6800 Training err. 1.50677 Training err. RA 1.87338 Valid. err. 1.66391
2018-02-03 23:37:14,143 training [INFO ] Epoch 33 Batch 6820 Training err. 1.49358 Training err. RA 1.87226 Valid. err. 1.67133
2018-02-03 23:37:14,617 training [INFO ] Epoch 33 Batch 6840 Training err. 1.48986 Training err. RA 1.87114 Valid. err. 1.64467
2018-02-03 23:37:15,103 training [INFO ] Epoch 33 Batch 6860 Training err. 1.53247 Training err. RA 1.87016 Valid. err. 1.65152
2018-02-03 23:37:15,993 training [INFO ] Epoch 34 Batch 6880 Training err. 1.48212 Training err. RA 1.86903 Valid. err. 1.66669
2018-02-03 23:37:16,471 training [INFO ] Epoch 34 Batch 6900 Training err. 1.47232 Training err. RA 1.86788 Valid. err. 1.66154
2018-02-03 23:37:16,952 training [INFO ] Epoch 34 Batch 6920 Training err. 1.52995 Training err. RA 1.86690 Valid. err. 1.66593
2018-02-03 23:37:17,430 training [INFO ] Epoch 34 Batch 6940 Training err. 1.56541 Training err. RA 1.86603 Valid. err. 1.64935
2018-02-03 23:37:17,909 training [INFO ] Epoch 34 Batch 6960 Training err. 1.49853 Training err. RA 1.86498 Valid. err. 1.67060
2018-02-03 23:37:18,394 training [INFO ] Epoch 34 Batch 6980 Training err. 1.54631 Training err. RA 1.86406 Valid. err. 1.64282
2018-02-03 23:37:18,876 training [INFO ] Epoch 34 Batch 7000 Training err. 1.54330 Training err. RA 1.86315 Valid. err. 1.64770
2018-02-03 23:37:19,358 training [INFO ] Epoch 34 Batch 7020 Training err. 1.48163 Training err. RA 1.86206 Valid. err. 1.65496
2018-02-03 23:37:19,859 training [INFO ] Epoch 34 Batch 7040 Training err. 1.49384 Training err. RA 1.86101 Valid. err. 1.64314
2018-02-03 23:37:20,336 training [INFO ] Epoch 34 Batch 7060 Training err. 1.51281 Training err. RA 1.86003 Valid. err. 1.63986
2018-02-03 23:37:21,197 training [INFO ] Epoch 35 Batch 7080 Training err. 1.48032 Training err. RA 1.85895 Valid. err. 1.64801
2018-02-03 23:37:21,676 training [INFO ] Epoch 35 Batch 7100 Training err. 1.46404 Training err. RA 1.85784 Valid. err. 1.65838
2018-02-03 23:37:22,156 training [INFO ] Epoch 35 Batch 7120 Training err. 1.51618 Training err. RA 1.85688 Valid. err. 1.64975
2018-02-03 23:37:22,629 training [INFO ] Epoch 35 Batch 7140 Training err. 1.55491 Training err. RA 1.85604 Valid. err. 1.64851
2018-02-03 23:37:23,107 training [INFO ] Epoch 35 Batch 7160 Training err. 1.50119 Training err. RA 1.85505 Valid. err. 1.66901
2018-02-03 23:37:23,590 training [INFO ] Epoch 35 Batch 7180 Training err. 1.49013 Training err. RA 1.85403 Valid. err. 1.65301
2018-02-03 23:37:24,075 training [INFO ] Epoch 35 Batch 7200 Training err. 1.55978 Training err. RA 1.85321 Valid. err. 1.64456
2018-02-03 23:37:24,563 training [INFO ] Epoch 35 Batch 7220 Training err. 1.49393 Training err. RA 1.85222 Valid. err. 1.65549
2018-02-03 23:37:25,041 training [INFO ] Epoch 35 Batch 7240 Training err. 1.47199 Training err. RA 1.85117 Valid. err. 1.65535
2018-02-03 23:37:25,519 training [INFO ] Epoch 35 Batch 7260 Training err. 1.48652 Training err. RA 1.85016 Valid. err. 1.63351
2018-02-03 23:37:25,997 training [INFO ] Epoch 35 Batch 7280 Training err. 1.49158 Training err. RA 1.84918 Valid. err. 1.63713
2018-02-03 23:37:26,861 training [INFO ] Epoch 36 Batch 7300 Training err. 1.48417 Training err. RA 1.84818 Valid. err. 1.63846
2018-02-03 23:37:27,346 training [INFO ] Epoch 36 Batch 7320 Training err. 1.44666 Training err. RA 1.84708 Valid. err. 1.66016
2018-02-03 23:37:27,824 training [INFO ] Epoch 36 Batch 7340 Training err. 1.52008 Training err. RA 1.84619 Valid. err. 1.65284
2018-02-03 23:37:28,313 training [INFO ] Epoch 36 Batch 7360 Training err. 1.55102 Training err. RA 1.84539 Valid. err. 1.64911
2018-02-03 23:37:28,788 training [INFO ] Epoch 36 Batch 7380 Training err. 1.47150 Training err. RA 1.84437 Valid. err. 1.64885
2018-02-03 23:37:29,267 training [INFO ] Epoch 36 Batch 7400 Training err. 1.53366 Training err. RA 1.84353 Valid. err. 1.64965
2018-02-03 23:37:29,740 training [INFO ] Epoch 36 Batch 7420 Training err. 1.51850 Training err. RA 1.84266 Valid. err. 1.65047
2018-02-03 23:37:30,220 training [INFO ] Epoch 36 Batch 7440 Training err. 1.46710 Training err. RA 1.84165 Valid. err. 1.66020
2018-02-03 23:37:30,698 training [INFO ] Epoch 36 Batch 7460 Training err. 1.46419 Training err. RA 1.84064 Valid. err. 1.64402
2018-02-03 23:37:31,178 training [INFO ] Epoch 36 Batch 7480 Training err. 1.50763 Training err. RA 1.83975 Valid. err. 1.63155
2018-02-03 23:37:32,029 training [INFO ] Epoch 37 Batch 7500 Training err. 1.46394 Training err. RA 1.83874 Valid. err. 1.63308
2018-02-03 23:37:32,503 training [INFO ] Epoch 37 Batch 7520 Training err. 1.44207 Training err. RA 1.83769 Valid. err. 1.67779
2018-02-03 23:37:32,985 training [INFO ] Epoch 37 Batch 7540 Training err. 1.50521 Training err. RA 1.83681 Valid. err. 1.65270
2018-02-03 23:37:33,459 training [INFO ] Epoch 37 Batch 7560 Training err. 1.54347 Training err. RA 1.83603 Valid. err. 1.64673
2018-02-03 23:37:33,932 training [INFO ] Epoch 37 Batch 7580 Training err. 1.47394 Training err. RA 1.83507 Valid. err. 1.63551
2018-02-03 23:37:34,413 training [INFO ] Epoch 37 Batch 7600 Training err. 1.49093 Training err. RA 1.83417 Valid. err. 1.62906
2018-02-03 23:37:34,889 training [INFO ] Epoch 37 Batch 7620 Training err. 1.53993 Training err. RA 1.83340 Valid. err. 1.64985
2018-02-03 23:37:35,367 training [INFO ] Epoch 37 Batch 7640 Training err. 1.46901 Training err. RA 1.83244 Valid. err. 1.66048
2018-02-03 23:37:35,843 training [INFO ] Epoch 37 Batch 7660 Training err. 1.47425 Training err. RA 1.83151 Valid. err. 1.63875
2018-02-03 23:37:36,331 training [INFO ] Epoch 37 Batch 7680 Training err. 1.47219 Training err. RA 1.83057 Valid. err. 1.63874
2018-02-03 23:37:37,194 training [INFO ] Epoch 38 Batch 7700 Training err. 1.46627 Training err. RA 1.82963 Valid. err. 1.64443
2018-02-03 23:37:37,671 training [INFO ] Epoch 38 Batch 7720 Training err. 1.45464 Training err. RA 1.82865 Valid. err. 1.63914
2018-02-03 23:37:38,144 training [INFO ] Epoch 38 Batch 7740 Training err. 1.46177 Training err. RA 1.82771 Valid. err. 1.64343
2018-02-03 23:37:38,620 training [INFO ] Epoch 38 Batch 7760 Training err. 1.51780 Training err. RA 1.82691 Valid. err. 1.64623
2018-02-03 23:37:39,100 training [INFO ] Epoch 38 Batch 7780 Training err. 1.50106 Training err. RA 1.82607 Valid. err. 1.65939
2018-02-03 23:37:39,573 training [INFO ] Epoch 38 Batch 7800 Training err. 1.47078 Training err. RA 1.82516 Valid. err. 1.62477
2018-02-03 23:37:40,056 training [INFO ] Epoch 38 Batch 7820 Training err. 1.54244 Training err. RA 1.82444 Valid. err. 1.64277
2018-02-03 23:37:40,531 training [INFO ] Epoch 38 Batch 7840 Training err. 1.46469 Training err. RA 1.82352 Valid. err. 1.64487
2018-02-03 23:37:41,009 training [INFO ] Epoch 38 Batch 7860 Training err. 1.45415 Training err. RA 1.82258 Valid. err. 1.65989
2018-02-03 23:37:41,483 training [INFO ] Epoch 38 Batch 7880 Training err. 1.44782 Training err. RA 1.82163 Valid. err. 1.62753
2018-02-03 23:37:41,956 training [INFO ] Epoch 38 Batch 7900 Training err. 1.49291 Training err. RA 1.82080 Valid. err. 1.63733
2018-02-03 23:37:42,806 training [INFO ] Epoch 39 Batch 7920 Training err. 1.44325 Training err. RA 1.81984 Valid. err. 1.64880
2018-02-03 23:37:43,285 training [INFO ] Epoch 39 Batch 7940 Training err. 1.43398 Training err. RA 1.81887 Valid. err. 1.64726
2018-02-03 23:37:43,764 training [INFO ] Epoch 39 Batch 7960 Training err. 1.49191 Training err. RA 1.81805 Valid. err. 1.64706
2018-02-03 23:37:44,237 training [INFO ] Epoch 39 Batch 7980 Training err. 1.52427 Training err. RA 1.81731 Valid. err. 1.63259
2018-02-03 23:37:44,715 training [INFO ] Epoch 39 Batch 8000 Training err. 1.45681 Training err. RA 1.81641 Valid. err. 1.64149
2018-02-03 23:37:45,193 training [INFO ] Epoch 39 Batch 8020 Training err. 1.50745 Training err. RA 1.81564 Valid. err. 1.62716
2018-02-03 23:37:45,668 training [INFO ] Epoch 39 Batch 8040 Training err. 1.50499 Training err. RA 1.81487 Valid. err. 1.62567
2018-02-03 23:37:46,149 training [INFO ] Epoch 39 Batch 8060 Training err. 1.44120 Training err. RA 1.81394 Valid. err. 1.63804
2018-02-03 23:37:46,624 training [INFO ] Epoch 39 Batch 8080 Training err. 1.45528 Training err. RA 1.81305 Valid. err. 1.63117
2018-02-03 23:37:47,112 training [INFO ] Epoch 39 Batch 8100 Training err. 1.47490 Training err. RA 1.81222 Valid. err. 1.61994
2018-02-03 23:37:47,987 training [INFO ] Epoch 40 Batch 8120 Training err. 1.44035 Training err. RA 1.81130 Valid. err. 1.63369
2018-02-03 23:37:48,465 training [INFO ] Epoch 40 Batch 8140 Training err. 1.42824 Training err. RA 1.81036 Valid. err. 1.64300
2018-02-03 23:37:48,940 training [INFO ] Epoch 40 Batch 8160 Training err. 1.47890 Training err. RA 1.80955 Valid. err. 1.63526
2018-02-03 23:37:49,425 training [INFO ] Epoch 40 Batch 8180 Training err. 1.51632 Training err. RA 1.80883 Valid. err. 1.62900
2018-02-03 23:37:49,901 training [INFO ] Epoch 40 Batch 8200 Training err. 1.45951 Training err. RA 1.80798 Valid. err. 1.65043
2018-02-03 23:37:50,385 training [INFO ] Epoch 40 Batch 8220 Training err. 1.45330 Training err. RA 1.80712 Valid. err. 1.62967
2018-02-03 23:37:50,860 training [INFO ] Epoch 40 Batch 8240 Training err. 1.52083 Training err. RA 1.80642 Valid. err. 1.62731
2018-02-03 23:37:51,342 training [INFO ] Epoch 40 Batch 8260 Training err. 1.45496 Training err. RA 1.80557 Valid. err. 1.64078
2018-02-03 23:37:51,816 training [INFO ] Epoch 40 Batch 8280 Training err. 1.43615 Training err. RA 1.80468 Valid. err. 1.64418
2018-02-03 23:37:52,298 training [INFO ] Epoch 40 Batch 8300 Training err. 1.44808 Training err. RA 1.80382 Valid. err. 1.61569
2018-02-03 23:37:52,776 training [INFO ] Epoch 40 Batch 8320 Training err. 1.45748 Training err. RA 1.80299 Valid. err. 1.61748
2018-02-03 23:37:53,619 training [INFO ] Epoch 41 Batch 8340 Training err. 1.44696 Training err. RA 1.80213 Valid. err. 1.62003
2018-02-03 23:37:54,100 training [INFO ] Epoch 41 Batch 8360 Training err. 1.40916 Training err. RA 1.80119 Valid. err. 1.66330
2018-02-03 23:37:54,579 training [INFO ] Epoch 41 Batch 8380 Training err. 1.48536 Training err. RA 1.80044 Valid. err. 1.63702
2018-02-03 23:37:55,059 training [INFO ] Epoch 41 Batch 8400 Training err. 1.51192 Training err. RA 1.79975 Valid. err. 1.63239
2018-02-03 23:37:55,535 training [INFO ] Epoch 41 Batch 8420 Training err. 1.43256 Training err. RA 1.79888 Valid. err. 1.63461
2018-02-03 23:37:56,010 training [INFO ] Epoch 41 Batch 8440 Training err. 1.49566 Training err. RA 1.79816 Valid. err. 1.63584
2018-02-03 23:37:56,486 training [INFO ] Epoch 41 Batch 8460 Training err. 1.48386 Training err. RA 1.79742 Valid. err. 1.63805
2018-02-03 23:37:56,959 training [INFO ] Epoch 41 Batch 8480 Training err. 1.43134 Training err. RA 1.79655 Valid. err. 1.64327
2018-02-03 23:37:57,439 training [INFO ] Epoch 41 Batch 8500 Training err. 1.42823 Training err. RA 1.79569 Valid. err. 1.62439
2018-02-03 23:37:57,916 training [INFO ] Epoch 41 Batch 8520 Training err. 1.47220 Training err. RA 1.79493 Valid. err. 1.61889
2018-02-03 23:37:58,781 training [INFO ] Epoch 42 Batch 8540 Training err. 1.42686 Training err. RA 1.79407 Valid. err. 1.62192
2018-02-03 23:37:59,259 training [INFO ] Epoch 42 Batch 8560 Training err. 1.40912 Training err. RA 1.79317 Valid. err. 1.65770
2018-02-03 23:37:59,738 training [INFO ] Epoch 42 Batch 8580 Training err. 1.47068 Training err. RA 1.79242 Valid. err. 1.63475
2018-02-03 23:38:00,237 training [INFO ] Epoch 42 Batch 8600 Training err. 1.50570 Training err. RA 1.79175 Valid. err. 1.63040
2018-02-03 23:38:00,715 training [INFO ] Epoch 42 Batch 8620 Training err. 1.43454 Training err. RA 1.79092 Valid. err. 1.62380
2018-02-03 23:38:01,194 training [INFO ] Epoch 42 Batch 8640 Training err. 1.45474 Training err. RA 1.79014 Valid. err. 1.61020
2018-02-03 23:38:01,668 training [INFO ] Epoch 42 Batch 8660 Training err. 1.50384 Training err. RA 1.78948 Valid. err. 1.63370
2018-02-03 23:38:02,153 training [INFO ] Epoch 42 Batch 8680 Training err. 1.43332 Training err. RA 1.78866 Valid. err. 1.64699
2018-02-03 23:38:02,630 training [INFO ] Epoch 42 Batch 8700 Training err. 1.43968 Training err. RA 1.78786 Valid. err. 1.63195
2018-02-03 23:38:03,203 training [INFO ] Epoch 42 Batch 8720 Training err. 1.43876 Training err. RA 1.78706 Valid. err. 1.62280
2018-02-03 23:38:04,318 training [INFO ] Epoch 43 Batch 8740 Training err. 1.43277 Training err. RA 1.78625 Valid. err. 1.62621
2018-02-03 23:38:04,915 training [INFO ] Epoch 43 Batch 8760 Training err. 1.42160 Training err. RA 1.78541 Valid. err. 1.61958
2018-02-03 23:38:05,532 training [INFO ] Epoch 43 Batch 8780 Training err. 1.42557 Training err. RA 1.78459 Valid. err. 1.63503
2018-02-03 23:38:06,156 training [INFO ] Epoch 43 Batch 8800 Training err. 1.48510 Training err. RA 1.78391 Valid. err. 1.64191
2018-02-03 23:38:06,773 training [INFO ] Epoch 43 Batch 8820 Training err. 1.46340 Training err. RA 1.78319 Valid. err. 1.64483
2018-02-03 23:38:07,301 training [INFO ] Epoch 43 Batch 8840 Training err. 1.43532 Training err. RA 1.78240 Valid. err. 1.61388
2018-02-03 23:38:07,814 training [INFO ] Epoch 43 Batch 8860 Training err. 1.50591 Training err. RA 1.78178 Valid. err. 1.63158
2018-02-03 23:38:08,312 training [INFO ] Epoch 43 Batch 8880 Training err. 1.43138 Training err. RA 1.78099 Valid. err. 1.63309
2018-02-03 23:38:08,810 training [INFO ] Epoch 43 Batch 8900 Training err. 1.42126 Training err. RA 1.78018 Valid. err. 1.65902
2018-02-03 23:38:09,312 training [INFO ] Epoch 43 Batch 8920 Training err. 1.41384 Training err. RA 1.77936 Valid. err. 1.61475
2018-02-03 23:38:09,813 training [INFO ] Epoch 43 Batch 8940 Training err. 1.46159 Training err. RA 1.77865 Valid. err. 1.62461
2018-02-03 23:38:10,727 training [INFO ] Epoch 44 Batch 8960 Training err. 1.40851 Training err. RA 1.77782 Valid. err. 1.63808
2018-02-03 23:38:11,212 training [INFO ] Epoch 44 Batch 8980 Training err. 1.40070 Training err. RA 1.77698 Valid. err. 1.63919
2018-02-03 23:38:11,692 training [INFO ] Epoch 44 Batch 9000 Training err. 1.45984 Training err. RA 1.77627 Valid. err. 1.63353
2018-02-03 23:38:12,182 training [INFO ] Epoch 44 Batch 9020 Training err. 1.48857 Training err. RA 1.77564 Valid. err. 1.62162
2018-02-03 23:38:12,664 training [INFO ] Epoch 44 Batch 9040 Training err. 1.42041 Training err. RA 1.77485 Valid. err. 1.62677
2018-02-03 23:38:13,148 training [INFO ] Epoch 44 Batch 9060 Training err. 1.47180 Training err. RA 1.77418 Valid. err. 1.61850
2018-02-03 23:38:13,632 training [INFO ] Epoch 44 Batch 9080 Training err. 1.47231 Training err. RA 1.77352 Valid. err. 1.61706
2018-02-03 23:38:14,112 training [INFO ] Epoch 44 Batch 9100 Training err. 1.40750 Training err. RA 1.77271 Valid. err. 1.62578
2018-02-03 23:38:14,590 training [INFO ] Epoch 44 Batch 9120 Training err. 1.42334 Training err. RA 1.77195 Valid. err. 1.62177
2018-02-03 23:38:15,074 training [INFO ] Epoch 44 Batch 9140 Training err. 1.44299 Training err. RA 1.77123 Valid. err. 1.60714
2018-02-03 23:38:15,930 training [INFO ] Epoch 45 Batch 9160 Training err. 1.40757 Training err. RA 1.77043 Valid. err. 1.61634
2018-02-03 23:38:16,413 training [INFO ] Epoch 45 Batch 9180 Training err. 1.39680 Training err. RA 1.76962 Valid. err. 1.63367
2018-02-03 23:38:16,886 training [INFO ] Epoch 45 Batch 9200 Training err. 1.44602 Training err. RA 1.76891 Valid. err. 1.61577
2018-02-03 23:38:17,362 training [INFO ] Epoch 45 Batch 9220 Training err. 1.48386 Training err. RA 1.76830 Valid. err. 1.61594
2018-02-03 23:38:17,839 training [INFO ] Epoch 45 Batch 9240 Training err. 1.42366 Training err. RA 1.76755 Valid. err. 1.64035
2018-02-03 23:38:18,321 training [INFO ] Epoch 45 Batch 9260 Training err. 1.42126 Training err. RA 1.76680 Valid. err. 1.61311
2018-02-03 23:38:18,798 training [INFO ] Epoch 45 Batch 9280 Training err. 1.48657 Training err. RA 1.76620 Valid. err. 1.61573
2018-02-03 23:38:19,285 training [INFO ] Epoch 45 Batch 9300 Training err. 1.42222 Training err. RA 1.76546 Valid. err. 1.62843
2018-02-03 23:38:19,762 training [INFO ] Epoch 45 Batch 9320 Training err. 1.40470 Training err. RA 1.76468 Valid. err. 1.63122
2018-02-03 23:38:20,242 training [INFO ] Epoch 45 Batch 9340 Training err. 1.41654 Training err. RA 1.76394 Valid. err. 1.60821
2018-02-03 23:38:20,719 training [INFO ] Epoch 45 Batch 9360 Training err. 1.42785 Training err. RA 1.76322 Valid. err. 1.60345
2018-02-03 23:38:21,590 training [INFO ] Epoch 46 Batch 9380 Training err. 1.41261 Training err. RA 1.76247 Valid. err. 1.60771
2018-02-03 23:38:22,077 training [INFO ] Epoch 46 Batch 9400 Training err. 1.37694 Training err. RA 1.76165 Valid. err. 1.65010
2018-02-03 23:38:22,552 training [INFO ] Epoch 46 Batch 9420 Training err. 1.45520 Training err. RA 1.76100 Valid. err. 1.62583
2018-02-03 23:38:23,026 training [INFO ] Epoch 46 Batch 9440 Training err. 1.47884 Training err. RA 1.76040 Valid. err. 1.62339
2018-02-03 23:38:23,497 training [INFO ] Epoch 46 Batch 9460 Training err. 1.40030 Training err. RA 1.75964 Valid. err. 1.62441
2018-02-03 23:38:23,977 training [INFO ] Epoch 46 Batch 9480 Training err. 1.46261 Training err. RA 1.75902 Valid. err. 1.63279
2018-02-03 23:38:24,451 training [INFO ] Epoch 46 Batch 9500 Training err. 1.45391 Training err. RA 1.75837 Valid. err. 1.62918
2018-02-03 23:38:24,926 training [INFO ] Epoch 46 Batch 9520 Training err. 1.39977 Training err. RA 1.75762 Valid. err. 1.63019
2018-02-03 23:38:25,407 training [INFO ] Epoch 46 Batch 9540 Training err. 1.39733 Training err. RA 1.75687 Valid. err. 1.61218
2018-02-03 23:38:25,883 training [INFO ] Epoch 46 Batch 9560 Training err. 1.44079 Training err. RA 1.75620 Valid. err. 1.60778
2018-02-03 23:38:26,720 training [INFO ] Epoch 47 Batch 9580 Training err. 1.39981 Training err. RA 1.75546 Valid. err. 1.61445
2018-02-03 23:38:27,200 training [INFO ] Epoch 47 Batch 9600 Training err. 1.37994 Training err. RA 1.75468 Valid. err. 1.63889
2018-02-03 23:38:27,680 training [INFO ] Epoch 47 Batch 9620 Training err. 1.43952 Training err. RA 1.75402 Valid. err. 1.62032
2018-02-03 23:38:28,163 training [INFO ] Epoch 47 Batch 9640 Training err. 1.47277 Training err. RA 1.75344 Valid. err. 1.62090
2018-02-03 23:38:28,646 training [INFO ] Epoch 47 Batch 9660 Training err. 1.40248 Training err. RA 1.75271 Valid. err. 1.62013
2018-02-03 23:38:29,127 training [INFO ] Epoch 47 Batch 9680 Training err. 1.42253 Training err. RA 1.75203 Valid. err. 1.59856
2018-02-03 23:38:29,609 training [INFO ] Epoch 47 Batch 9700 Training err. 1.47304 Training err. RA 1.75146 Valid. err. 1.62458
2018-02-03 23:38:30,094 training [INFO ] Epoch 47 Batch 9720 Training err. 1.40130 Training err. RA 1.75073 Valid. err. 1.63360
2018-02-03 23:38:30,574 training [INFO ] Epoch 47 Batch 9740 Training err. 1.40743 Training err. RA 1.75003 Valid. err. 1.63321
2018-02-03 23:38:31,052 training [INFO ] Epoch 47 Batch 9760 Training err. 1.40918 Training err. RA 1.74933 Valid. err. 1.61228
2018-02-03 23:38:31,904 training [INFO ] Epoch 48 Batch 9780 Training err. 1.40366 Training err. RA 1.74862 Valid. err. 1.61208
2018-02-03 23:38:32,380 training [INFO ] Epoch 48 Batch 9800 Training err. 1.39164 Training err. RA 1.74790 Valid. err. 1.60933
2018-02-03 23:38:32,857 training [INFO ] Epoch 48 Batch 9820 Training err. 1.39470 Training err. RA 1.74718 Valid. err. 1.63181
2018-02-03 23:38:33,339 training [INFO ] Epoch 48 Batch 9840 Training err. 1.45711 Training err. RA 1.74659 Valid. err. 1.63274
2018-02-03 23:38:33,817 training [INFO ] Epoch 48 Batch 9860 Training err. 1.43226 Training err. RA 1.74595 Valid. err. 1.63083
2018-02-03 23:38:34,302 training [INFO ] Epoch 48 Batch 9880 Training err. 1.40487 Training err. RA 1.74526 Valid. err. 1.60752
2018-02-03 23:38:34,775 training [INFO ] Epoch 48 Batch 9900 Training err. 1.47385 Training err. RA 1.74471 Valid. err. 1.62714
2018-02-03 23:38:35,254 training [INFO ] Epoch 48 Batch 9920 Training err. 1.40129 Training err. RA 1.74402 Valid. err. 1.62361
2018-02-03 23:38:35,729 training [INFO ] Epoch 48 Batch 9940 Training err. 1.39028 Training err. RA 1.74331 Valid. err. 1.65423
2018-02-03 23:38:36,212 training [INFO ] Epoch 48 Batch 9960 Training err. 1.38380 Training err. RA 1.74258 Valid. err. 1.60346
2018-02-03 23:38:36,695 training [INFO ] Epoch 48 Batch 9980 Training err. 1.43458 Training err. RA 1.74197 Valid. err. 1.61626
2018-02-03 23:38:37,572 training [INFO ] Epoch 49 Batch10000 Training err. 1.38054 Training err. RA 1.74124 Valid. err. 1.62932
2018-02-03 23:38:38,051 training [INFO ] Epoch 49 Batch10020 Training err. 1.37066 Training err. RA 1.74050 Valid. err. 1.62953
2018-02-03 23:38:38,529 training [INFO ] Epoch 49 Batch10040 Training err. 1.43128 Training err. RA 1.73989 Valid. err. 1.62846
2018-02-03 23:38:39,067 training [INFO ] Epoch 49 Batch10060 Training err. 1.45899 Training err. RA 1.73933 Valid. err. 1.61156
2018-02-03 23:38:39,616 training [INFO ] Epoch 49 Batch10080 Training err. 1.39078 Training err. RA 1.73864 Valid. err. 1.62063
2018-02-03 23:38:40,103 training [INFO ] Epoch 49 Batch10100 Training err. 1.43975 Training err. RA 1.73805 Valid. err. 1.61469
2018-02-03 23:38:40,576 training [INFO ] Epoch 49 Batch10120 Training err. 1.44309 Training err. RA 1.73746 Valid. err. 1.61305
2018-02-03 23:38:41,052 training [INFO ] Epoch 49 Batch10140 Training err. 1.37774 Training err. RA 1.73675 Valid. err. 1.61677
2018-02-03 23:38:41,527 training [INFO ] Epoch 49 Batch10160 Training err. 1.39358 Training err. RA 1.73608 Valid. err. 1.61372
2018-02-03 23:38:42,008 training [INFO ] Epoch 49 Batch10180 Training err. 1.41467 Training err. RA 1.73545 Valid. err. 1.59963
2018-02-03 23:38:42,908 training [INFO ] Epoch 50 Batch10200 Training err. 1.38119 Training err. RA 1.73475 Valid. err. 1.60740
2018-02-03 23:38:43,392 training [INFO ] Epoch 50 Batch10220 Training err. 1.37135 Training err. RA 1.73404 Valid. err. 1.62397
2018-02-03 23:38:43,868 training [INFO ] Epoch 50 Batch10240 Training err. 1.41737 Training err. RA 1.73342 Valid. err. 1.60511
2018-02-03 23:38:44,350 training [INFO ] Epoch 50 Batch10260 Training err. 1.45486 Training err. RA 1.73288 Valid. err. 1.60882
2018-02-03 23:38:44,826 training [INFO ] Epoch 50 Batch10280 Training err. 1.39412 Training err. RA 1.73222 Valid. err. 1.63084
2018-02-03 23:38:45,312 training [INFO ] Epoch 50 Batch10300 Training err. 1.39183 Training err. RA 1.73156 Valid. err. 1.60661
2018-02-03 23:38:45,794 training [INFO ] Epoch 50 Batch10320 Training err. 1.45644 Training err. RA 1.73103 Valid. err. 1.61352
2018-02-03 23:38:46,277 training [INFO ] Epoch 50 Batch10340 Training err. 1.39150 Training err. RA 1.73037 Valid. err. 1.61519
2018-02-03 23:38:46,758 training [INFO ] Epoch 50 Batch10360 Training err. 1.37534 Training err. RA 1.72968 Valid. err. 1.63287
2018-02-03 23:38:47,232 training [INFO ] Epoch 50 Batch10380 Training err. 1.38901 Training err. RA 1.72903 Valid. err. 1.60853
2018-02-03 23:38:47,709 training [INFO ] Epoch 50 Batch10400 Training err. 1.40295 Training err. RA 1.72840 Valid. err. 1.59792
2018-02-03 23:38:48,570 training [INFO ] Epoch 51 Batch10420 Training err. 1.38881 Training err. RA 1.72775 Valid. err. 1.60033
2018-02-03 23:38:49,052 training [INFO ] Epoch 51 Batch10440 Training err. 1.35011 Training err. RA 1.72703 Valid. err. 1.64195
2018-02-03 23:38:49,527 training [INFO ] Epoch 51 Batch10460 Training err. 1.42858 Training err. RA 1.72646 Valid. err. 1.62210
2018-02-03 23:38:50,000 training [INFO ] Epoch 51 Batch10480 Training err. 1.45062 Training err. RA 1.72593 Valid. err. 1.61963
2018-02-03 23:38:50,477 training [INFO ] Epoch 51 Batch10500 Training err. 1.37266 Training err. RA 1.72526 Valid. err. 1.61291
2018-02-03 23:38:50,952 training [INFO ] Epoch 51 Batch10520 Training err. 1.43073 Training err. RA 1.72470 Valid. err. 1.62737
2018-02-03 23:38:51,435 training [INFO ] Epoch 51 Batch10540 Training err. 1.42691 Training err. RA 1.72413 Valid. err. 1.62189
2018-02-03 23:38:51,914 training [INFO ] Epoch 51 Batch10560 Training err. 1.37190 Training err. RA 1.72346 Valid. err. 1.62046
2018-02-03 23:38:52,399 training [INFO ] Epoch 51 Batch10580 Training err. 1.36725 Training err. RA 1.72279 Valid. err. 1.59919
2018-02-03 23:38:52,878 training [INFO ] Epoch 51 Batch10600 Training err. 1.41532 Training err. RA 1.72221 Valid. err. 1.60029
2018-02-03 23:38:53,745 training [INFO ] Epoch 52 Batch10620 Training err. 1.36977 Training err. RA 1.72155 Valid. err. 1.61071
2018-02-03 23:38:54,226 training [INFO ] Epoch 52 Batch10640 Training err. 1.35623 Training err. RA 1.72086 Valid. err. 1.63499
2018-02-03 23:38:54,707 training [INFO ] Epoch 52 Batch10660 Training err. 1.41241 Training err. RA 1.72028 Valid. err. 1.61890
2018-02-03 23:38:55,189 training [INFO ] Epoch 52 Batch10680 Training err. 1.44445 Training err. RA 1.71977 Valid. err. 1.61600
2018-02-03 23:38:55,665 training [INFO ] Epoch 52 Batch10700 Training err. 1.37404 Training err. RA 1.71912 Valid. err. 1.61569
2018-02-03 23:38:56,142 training [INFO ] Epoch 52 Batch10720 Training err. 1.39497 Training err. RA 1.71851 Valid. err. 1.60362
2018-02-03 23:38:56,617 training [INFO ] Epoch 52 Batch10740 Training err. 1.44758 Training err. RA 1.71801 Valid. err. 1.61655
2018-02-03 23:38:57,100 training [INFO ] Epoch 52 Batch10760 Training err. 1.37309 Training err. RA 1.71737 Valid. err. 1.61948
2018-02-03 23:38:57,576 training [INFO ] Epoch 52 Batch10780 Training err. 1.38164 Training err. RA 1.71675 Valid. err. 1.62993
2018-02-03 23:38:58,054 training [INFO ] Epoch 52 Batch10800 Training err. 1.38300 Training err. RA 1.71613 Valid. err. 1.61243
2018-02-03 23:38:58,906 training [INFO ] Epoch 53 Batch10820 Training err. 1.38067 Training err. RA 1.71551 Valid. err. 1.60826
2018-02-03 23:38:59,385 training [INFO ] Epoch 53 Batch10840 Training err. 1.36920 Training err. RA 1.71487 Valid. err. 1.59598
2018-02-03 23:38:59,868 training [INFO ] Epoch 53 Batch10860 Training err. 1.37015 Training err. RA 1.71423 Valid. err. 1.62209
2018-02-03 23:39:00,351 training [INFO ] Epoch 53 Batch10880 Training err. 1.42968 Training err. RA 1.71371 Valid. err. 1.63322
2018-02-03 23:39:00,835 training [INFO ] Epoch 53 Batch10900 Training err. 1.40589 Training err. RA 1.71315 Valid. err. 1.62464
2018-02-03 23:39:01,321 training [INFO ] Epoch 53 Batch10920 Training err. 1.37735 Training err. RA 1.71253 Valid. err. 1.60394
2018-02-03 23:39:01,804 training [INFO ] Epoch 53 Batch10940 Training err. 1.44597 Training err. RA 1.71204 Valid. err. 1.62388
2018-02-03 23:39:02,280 training [INFO ] Epoch 53 Batch10960 Training err. 1.37578 Training err. RA 1.71143 Valid. err. 1.62087
2018-02-03 23:39:02,754 training [INFO ] Epoch 53 Batch10980 Training err. 1.36470 Training err. RA 1.71080 Valid. err. 1.64570
2018-02-03 23:39:03,234 training [INFO ] Epoch 53 Batch11000 Training err. 1.35543 Training err. RA 1.71015 Valid. err. 1.60093
2018-02-03 23:39:03,710 training [INFO ] Epoch 53 Batch11020 Training err. 1.41506 Training err. RA 1.70962 Valid. err. 1.60234
2018-02-03 23:39:04,600 training [INFO ] Epoch 54 Batch11040 Training err. 1.35346 Training err. RA 1.70897 Valid. err. 1.62050
2018-02-03 23:39:05,078 training [INFO ] Epoch 54 Batch11060 Training err. 1.34937 Training err. RA 1.70832 Valid. err. 1.64231
2018-02-03 23:39:05,555 training [INFO ] Epoch 54 Batch11080 Training err. 1.41256 Training err. RA 1.70779 Valid. err. 1.62642
2018-02-03 23:39:06,032 training [INFO ] Epoch 54 Batch11100 Training err. 1.43246 Training err. RA 1.70729 Valid. err. 1.60339
2018-02-03 23:39:06,514 training [INFO ] Epoch 54 Batch11120 Training err. 1.36644 Training err. RA 1.70668 Valid. err. 1.61768
2018-02-03 23:39:06,994 training [INFO ] Epoch 54 Batch11140 Training err. 1.41170 Training err. RA 1.70615 Valid. err. 1.61702
2018-02-03 23:39:07,469 training [INFO ] Epoch 54 Batch11160 Training err. 1.41922 Training err. RA 1.70563 Valid. err. 1.60832
2018-02-03 23:39:07,950 training [INFO ] Epoch 54 Batch11180 Training err. 1.35282 Training err. RA 1.70500 Valid. err. 1.61440
2018-02-03 23:39:08,425 training [INFO ] Epoch 54 Batch11200 Training err. 1.36750 Training err. RA 1.70440 Valid. err. 1.61329
2018-02-03 23:39:08,906 training [INFO ] Epoch 54 Batch11220 Training err. 1.39080 Training err. RA 1.70384 Valid. err. 1.59566
2018-02-03 23:39:09,772 training [INFO ] Epoch 55 Batch11240 Training err. 1.35960 Training err. RA 1.70323 Valid. err. 1.59657
2018-02-03 23:39:10,255 training [INFO ] Epoch 55 Batch11260 Training err. 1.34828 Training err. RA 1.70260 Valid. err. 1.62828
2018-02-03 23:39:10,731 training [INFO ] Epoch 55 Batch11280 Training err. 1.39386 Training err. RA 1.70205 Valid. err. 1.59593
2018-02-03 23:39:11,213 training [INFO ] Epoch 55 Batch11300 Training err. 1.42832 Training err. RA 1.70157 Valid. err. 1.60879
2018-02-03 23:39:11,697 training [INFO ] Epoch 55 Batch11320 Training err. 1.36889 Training err. RA 1.70098 Valid. err. 1.62766
2018-02-03 23:39:12,193 training [INFO ] Epoch 55 Batch11340 Training err. 1.37032 Training err. RA 1.70040 Valid. err. 1.60833
2018-02-03 23:39:12,673 training [INFO ] Epoch 55 Batch11360 Training err. 1.43254 Training err. RA 1.69992 Valid. err. 1.61392
2018-02-03 23:39:13,159 training [INFO ] Epoch 55 Batch11380 Training err. 1.36812 Training err. RA 1.69934 Valid. err. 1.61682
2018-02-03 23:39:13,641 training [INFO ] Epoch 55 Batch11400 Training err. 1.35125 Training err. RA 1.69873 Valid. err. 1.62236
2018-02-03 23:39:14,120 training [INFO ] Epoch 55 Batch11420 Training err. 1.36143 Training err. RA 1.69814 Valid. err. 1.61731
2018-02-03 23:39:14,600 training [INFO ] Epoch 55 Batch11440 Training err. 1.37710 Training err. RA 1.69758 Valid. err. 1.60331
2018-02-03 23:39:15,460 training [INFO ] Epoch 56 Batch11460 Training err. 1.37102 Training err. RA 1.69701 Valid. err. 1.60107
2018-02-03 23:39:15,941 training [INFO ] Epoch 56 Batch11480 Training err. 1.32995 Training err. RA 1.69637 Valid. err. 1.64060
2018-02-03 23:39:16,427 training [INFO ] Epoch 56 Batch11500 Training err. 1.40329 Training err. RA 1.69586 Valid. err. 1.61949
2018-02-03 23:39:16,906 training [INFO ] Epoch 56 Batch11520 Training err. 1.42264 Training err. RA 1.69538 Valid. err. 1.61705
2018-02-03 23:39:17,381 training [INFO ] Epoch 56 Batch11540 Training err. 1.34884 Training err. RA 1.69478 Valid. err. 1.61182
2018-02-03 23:39:17,859 training [INFO ] Epoch 56 Batch11560 Training err. 1.40635 Training err. RA 1.69429 Valid. err. 1.62199
2018-02-03 23:39:18,340 training [INFO ] Epoch 56 Batch11580 Training err. 1.40441 Training err. RA 1.69378 Valid. err. 1.61884
2018-02-03 23:39:18,816 training [INFO ] Epoch 56 Batch11600 Training err. 1.34804 Training err. RA 1.69319 Valid. err. 1.61839
2018-02-03 23:39:19,306 training [INFO ] Epoch 56 Batch11620 Training err. 1.34300 Training err. RA 1.69259 Valid. err. 1.59892
2018-02-03 23:39:19,782 training [INFO ] Epoch 56 Batch11640 Training err. 1.39487 Training err. RA 1.69207 Valid. err. 1.59737
2018-02-03 23:39:20,652 training [INFO ] Epoch 57 Batch11660 Training err. 1.34309 Training err. RA 1.69148 Valid. err. 1.61101
2018-02-03 23:39:21,134 training [INFO ] Epoch 57 Batch11680 Training err. 1.33585 Training err. RA 1.69087 Valid. err. 1.63830
2018-02-03 23:39:21,616 training [INFO ] Epoch 57 Batch11700 Training err. 1.38830 Training err. RA 1.69035 Valid. err. 1.61217
2018-02-03 23:39:22,103 training [INFO ] Epoch 57 Batch11720 Training err. 1.41716 Training err. RA 1.68988 Valid. err. 1.61336
2018-02-03 23:39:22,586 training [INFO ] Epoch 57 Batch11740 Training err. 1.35046 Training err. RA 1.68930 Valid. err. 1.61836
2018-02-03 23:39:23,058 training [INFO ] Epoch 57 Batch11760 Training err. 1.37549 Training err. RA 1.68877 Valid. err. 1.60464
2018-02-03 23:39:23,528 training [INFO ] Epoch 57 Batch11780 Training err. 1.42461 Training err. RA 1.68832 Valid. err. 1.61178
2018-02-03 23:39:24,011 training [INFO ] Epoch 57 Batch11800 Training err. 1.35025 Training err. RA 1.68775 Valid. err. 1.61466
2018-02-03 23:39:24,486 training [INFO ] Epoch 57 Batch11820 Training err. 1.35818 Training err. RA 1.68719 Valid. err. 1.62550
2018-02-03 23:39:24,973 training [INFO ] Epoch 57 Batch11840 Training err. 1.35795 Training err. RA 1.68664 Valid. err. 1.61307
2018-02-03 23:39:25,806 training [INFO ] Epoch 58 Batch11860 Training err. 1.35656 Training err. RA 1.68608 Valid. err. 1.62391
2018-02-03 23:39:26,280 training [INFO ] Epoch 58 Batch11880 Training err. 1.34780 Training err. RA 1.68551 Valid. err. 1.59896
2018-02-03 23:39:26,756 training [INFO ] Epoch 58 Batch11900 Training err. 1.34781 Training err. RA 1.68494 Valid. err. 1.61921
2018-02-03 23:39:27,235 training [INFO ] Epoch 58 Batch11920 Training err. 1.40407 Training err. RA 1.68447 Valid. err. 1.63032
2018-02-03 23:39:27,716 training [INFO ] Epoch 58 Batch11940 Training err. 1.38322 Training err. RA 1.68397 Valid. err. 1.62624
2018-02-03 23:39:28,201 training [INFO ] Epoch 58 Batch11960 Training err. 1.35249 Training err. RA 1.68341 Valid. err. 1.60858
2018-02-03 23:39:28,682 training [INFO ] Epoch 58 Batch11980 Training err. 1.42309 Training err. RA 1.68298 Valid. err. 1.62673
2018-02-03 23:39:29,157 training [INFO ] Epoch 58 Batch12000 Training err. 1.35631 Training err. RA 1.68243 Valid. err. 1.61811
2018-02-03 23:39:29,639 training [INFO ] Epoch 58 Batch12020 Training err. 1.34321 Training err. RA 1.68187 Valid. err. 1.64297
2018-02-03 23:39:30,122 training [INFO ] Epoch 58 Batch12040 Training err. 1.32870 Training err. RA 1.68128 Valid. err. 1.60220
2018-02-03 23:39:30,603 training [INFO ] Epoch 58 Batch12060 Training err. 1.38840 Training err. RA 1.68080 Valid. err. 1.59956
2018-02-03 23:39:31,476 training [INFO ] Epoch 59 Batch12080 Training err. 1.33759 Training err. RA 1.68023 Valid. err. 1.61941
2018-02-03 23:39:31,958 training [INFO ] Epoch 59 Batch12100 Training err. 1.33136 Training err. RA 1.67965 Valid. err. 1.63924
2018-02-03 23:39:32,436 training [INFO ] Epoch 59 Batch12120 Training err. 1.39107 Training err. RA 1.67918 Valid. err. 1.62271
2018-02-03 23:39:32,912 training [INFO ] Epoch 59 Batch12140 Training err. 1.40886 Training err. RA 1.67873 Valid. err. 1.60760
2018-02-03 23:39:33,398 training [INFO ] Epoch 59 Batch12160 Training err. 1.34405 Training err. RA 1.67818 Valid. err. 1.62186
2018-02-03 23:39:33,874 training [INFO ] Epoch 59 Batch12180 Training err. 1.38959 Training err. RA 1.67771 Valid. err. 1.61264
2018-02-03 23:39:34,356 training [INFO ] Epoch 59 Batch12200 Training err. 1.39582 Training err. RA 1.67724 Valid. err. 1.60623
2018-02-03 23:39:34,833 training [INFO ] Epoch 59 Batch12220 Training err. 1.33116 Training err. RA 1.67668 Valid. err. 1.61493
2018-02-03 23:39:35,310 training [INFO ] Epoch 59 Batch12240 Training err. 1.34316 Training err. RA 1.67613 Valid. err. 1.61305
2018-02-03 23:39:35,782 training [INFO ] Epoch 59 Batch12260 Training err. 1.36456 Training err. RA 1.67562 Valid. err. 1.59256
2018-02-03 23:39:36,650 training [INFO ] Epoch 60 Batch12280 Training err. 1.33849 Training err. RA 1.67507 Valid. err. 1.59409
2018-02-03 23:39:37,134 training [INFO ] Epoch 60 Batch12300 Training err. 1.32952 Training err. RA 1.67451 Valid. err. 1.62528
2018-02-03 23:39:37,609 training [INFO ] Epoch 60 Batch12320 Training err. 1.37446 Training err. RA 1.67403 Valid. err. 1.59422
2018-02-03 23:39:38,086 training [INFO ] Epoch 60 Batch12340 Training err. 1.40868 Training err. RA 1.67360 Valid. err. 1.60890
2018-02-03 23:39:38,558 training [INFO ] Epoch 60 Batch12360 Training err. 1.34986 Training err. RA 1.67307 Valid. err. 1.62595
2018-02-03 23:39:39,044 training [INFO ] Epoch 60 Batch12380 Training err. 1.34887 Training err. RA 1.67255 Valid. err. 1.60679
2018-02-03 23:39:39,523 training [INFO ] Epoch 60 Batch12400 Training err. 1.40861 Training err. RA 1.67212 Valid. err. 1.61604
2018-02-03 23:39:40,009 training [INFO ] Epoch 60 Batch12420 Training err. 1.35010 Training err. RA 1.67160 Valid. err. 1.60697
2018-02-03 23:39:40,489 training [INFO ] Epoch 60 Batch12440 Training err. 1.32967 Training err. RA 1.67105 Valid. err. 1.61334
2018-02-03 23:39:40,970 training [INFO ] Epoch 60 Batch12460 Training err. 1.33935 Training err. RA 1.67052 Valid. err. 1.61048
2018-02-03 23:39:41,449 training [INFO ] Epoch 60 Batch12480 Training err. 1.35521 Training err. RA 1.67002 Valid. err. 1.60271
2018-02-03 23:39:41,727 __main__ [INFO ] End of training
2018-02-03 23:39:42,033 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 10,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 23:39:42,033 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 23:39:42,673 training [INFO ] Epoch  1 Batch   20 Training err. 4.50536 Training err. RA 4.50536 Valid. err. 8.04659
2018-02-03 23:39:43,154 training [INFO ] Epoch  1 Batch   40 Training err. 4.10560 Training err. RA 4.30548 Valid. err. 3.21016
2018-02-03 23:39:43,625 training [INFO ] Epoch  1 Batch   60 Training err. 3.13285 Training err. RA 3.91460 Valid. err. 3.20579
2018-02-03 23:39:44,101 training [INFO ] Epoch  1 Batch   80 Training err. 3.13868 Training err. RA 3.72062 Valid. err. 3.19088
2018-02-03 23:39:44,569 training [INFO ] Epoch  1 Batch  100 Training err. 3.10709 Training err. RA 3.59792 Valid. err. 3.17294
2018-02-03 23:39:45,047 training [INFO ] Epoch  1 Batch  120 Training err. 3.13171 Training err. RA 3.52021 Valid. err. 3.11960
2018-02-03 23:39:45,521 training [INFO ] Epoch  1 Batch  140 Training err. 2.97888 Training err. RA 3.44288 Valid. err. 3.08469
2018-02-03 23:39:45,998 training [INFO ] Epoch  1 Batch  160 Training err. 2.88042 Training err. RA 3.37257 Valid. err. 3.01061
2018-02-03 23:39:46,475 training [INFO ] Epoch  1 Batch  180 Training err. 2.92412 Training err. RA 3.32275 Valid. err. 2.95232
2018-02-03 23:39:46,948 training [INFO ] Epoch  1 Batch  200 Training err. 2.81129 Training err. RA 3.27160 Valid. err. 2.79013
2018-02-03 23:39:47,849 training [INFO ] Epoch  2 Batch  220 Training err. 2.79437 Training err. RA 3.22822 Valid. err. 2.82825
2018-02-03 23:39:48,328 training [INFO ] Epoch  2 Batch  240 Training err. 2.70165 Training err. RA 3.18434 Valid. err. 2.95434
2018-02-03 23:39:48,803 training [INFO ] Epoch  2 Batch  260 Training err. 2.73964 Training err. RA 3.15013 Valid. err. 2.73555
2018-02-03 23:39:49,284 training [INFO ] Epoch  2 Batch  280 Training err. 2.67031 Training err. RA 3.11586 Valid. err. 2.77918
2018-02-03 23:39:49,766 training [INFO ] Epoch  2 Batch  300 Training err. 2.62133 Training err. RA 3.08289 Valid. err. 2.65550
2018-02-03 23:39:50,243 training [INFO ] Epoch  2 Batch  320 Training err. 2.64085 Training err. RA 3.05526 Valid. err. 2.57893
2018-02-03 23:39:50,724 training [INFO ] Epoch  2 Batch  340 Training err. 2.60222 Training err. RA 3.02861 Valid. err. 2.57855
2018-02-03 23:39:51,204 training [INFO ] Epoch  2 Batch  360 Training err. 2.47647 Training err. RA 2.99794 Valid. err. 2.51613
2018-02-03 23:39:51,679 training [INFO ] Epoch  2 Batch  380 Training err. 2.52145 Training err. RA 2.97286 Valid. err. 2.49799
2018-02-03 23:39:52,161 training [INFO ] Epoch  2 Batch  400 Training err. 2.44343 Training err. RA 2.94639 Valid. err. 2.48033
2018-02-03 23:39:53,005 training [INFO ] Epoch  3 Batch  420 Training err. 2.40539 Training err. RA 2.92062 Valid. err. 2.51607
2018-02-03 23:39:53,481 training [INFO ] Epoch  3 Batch  440 Training err. 2.40254 Training err. RA 2.89708 Valid. err. 2.46163
2018-02-03 23:39:53,957 training [INFO ] Epoch  3 Batch  460 Training err. 2.37293 Training err. RA 2.87429 Valid. err. 2.52748
2018-02-03 23:39:54,435 training [INFO ] Epoch  3 Batch  480 Training err. 2.41464 Training err. RA 2.85513 Valid. err. 2.40565
2018-02-03 23:39:54,911 training [INFO ] Epoch  3 Batch  500 Training err. 2.36589 Training err. RA 2.83556 Valid. err. 2.38844
2018-02-03 23:39:55,392 training [INFO ] Epoch  3 Batch  520 Training err. 2.35941 Training err. RA 2.81725 Valid. err. 2.35798
2018-02-03 23:39:55,871 training [INFO ] Epoch  3 Batch  540 Training err. 2.40468 Training err. RA 2.80197 Valid. err. 2.37197
2018-02-03 23:39:56,348 training [INFO ] Epoch  3 Batch  560 Training err. 2.28984 Training err. RA 2.78368 Valid. err. 2.34845
2018-02-03 23:39:56,826 training [INFO ] Epoch  3 Batch  580 Training err. 2.24059 Training err. RA 2.76495 Valid. err. 2.39523
2018-02-03 23:39:57,306 training [INFO ] Epoch  3 Batch  600 Training err. 2.28950 Training err. RA 2.74910 Valid. err. 2.27368
2018-02-03 23:39:57,782 training [INFO ] Epoch  3 Batch  620 Training err. 2.26627 Training err. RA 2.73353 Valid. err. 2.37877
2018-02-03 23:39:58,656 training [INFO ] Epoch  4 Batch  640 Training err. 2.24651 Training err. RA 2.71831 Valid. err. 2.29922
2018-02-03 23:39:59,133 training [INFO ] Epoch  4 Batch  660 Training err. 2.21312 Training err. RA 2.70300 Valid. err. 2.30506
2018-02-03 23:39:59,605 training [INFO ] Epoch  4 Batch  680 Training err. 2.25374 Training err. RA 2.68979 Valid. err. 2.24382
2018-02-03 23:40:00,083 training [INFO ] Epoch  4 Batch  700 Training err. 2.36447 Training err. RA 2.68049 Valid. err. 2.33529
2018-02-03 23:40:00,564 training [INFO ] Epoch  4 Batch  720 Training err. 2.20069 Training err. RA 2.66716 Valid. err. 2.27002
2018-02-03 23:40:01,041 training [INFO ] Epoch  4 Batch  740 Training err. 2.24120 Training err. RA 2.65565 Valid. err. 2.24741
2018-02-03 23:40:01,520 training [INFO ] Epoch  4 Batch  760 Training err. 2.21455 Training err. RA 2.64404 Valid. err. 2.20023
2018-02-03 23:40:01,995 training [INFO ] Epoch  4 Batch  780 Training err. 2.11843 Training err. RA 2.63057 Valid. err. 2.19276
2018-02-03 23:40:02,475 training [INFO ] Epoch  4 Batch  800 Training err. 2.16310 Training err. RA 2.61888 Valid. err. 2.18580
2018-02-03 23:40:02,948 training [INFO ] Epoch  4 Batch  820 Training err. 2.11496 Training err. RA 2.60659 Valid. err. 2.17482
2018-02-03 23:40:03,805 training [INFO ] Epoch  5 Batch  840 Training err. 2.13154 Training err. RA 2.59528 Valid. err. 2.19607
2018-02-03 23:40:04,290 training [INFO ] Epoch  5 Batch  860 Training err. 2.06446 Training err. RA 2.58293 Valid. err. 2.16924
2018-02-03 23:40:04,768 training [INFO ] Epoch  5 Batch  880 Training err. 2.17556 Training err. RA 2.57368 Valid. err. 2.16106
2018-02-03 23:40:05,250 training [INFO ] Epoch  5 Batch  900 Training err. 2.13003 Training err. RA 2.56382 Valid. err. 2.15836
2018-02-03 23:40:05,727 training [INFO ] Epoch  5 Batch  920 Training err. 2.07244 Training err. RA 2.55313 Valid. err. 2.13615
2018-02-03 23:40:06,209 training [INFO ] Epoch  5 Batch  940 Training err. 2.08110 Training err. RA 2.54309 Valid. err. 2.13793
2018-02-03 23:40:06,685 training [INFO ] Epoch  5 Batch  960 Training err. 2.15442 Training err. RA 2.53499 Valid. err. 2.12750
2018-02-03 23:40:07,170 training [INFO ] Epoch  5 Batch  980 Training err. 2.05998 Training err. RA 2.52530 Valid. err. 2.14654
2018-02-03 23:40:07,641 training [INFO ] Epoch  5 Batch 1000 Training err. 2.02820 Training err. RA 2.51536 Valid. err. 2.10543
2018-02-03 23:40:08,117 training [INFO ] Epoch  5 Batch 1020 Training err. 2.06499 Training err. RA 2.50653 Valid. err. 2.11193
2018-02-03 23:40:08,595 training [INFO ] Epoch  5 Batch 1040 Training err. 2.02084 Training err. RA 2.49719 Valid. err. 2.10763
2018-02-03 23:40:09,455 training [INFO ] Epoch  6 Batch 1060 Training err. 2.03903 Training err. RA 2.48854 Valid. err. 2.07306
2018-02-03 23:40:09,933 training [INFO ] Epoch  6 Batch 1080 Training err. 2.01503 Training err. RA 2.47977 Valid. err. 2.14022
2018-02-03 23:40:10,411 training [INFO ] Epoch  6 Batch 1100 Training err. 2.05636 Training err. RA 2.47208 Valid. err. 2.08171
2018-02-03 23:40:10,890 training [INFO ] Epoch  6 Batch 1120 Training err. 2.04983 Training err. RA 2.46454 Valid. err. 2.09709
2018-02-03 23:40:11,365 training [INFO ] Epoch  6 Batch 1140 Training err. 2.01653 Training err. RA 2.45668 Valid. err. 2.06928
2018-02-03 23:40:11,843 training [INFO ] Epoch  6 Batch 1160 Training err. 2.08391 Training err. RA 2.45025 Valid. err. 2.07742
2018-02-03 23:40:12,319 training [INFO ] Epoch  6 Batch 1180 Training err. 2.00507 Training err. RA 2.44270 Valid. err. 2.07309
2018-02-03 23:40:12,792 training [INFO ] Epoch  6 Batch 1200 Training err. 1.97391 Training err. RA 2.43489 Valid. err. 2.11683
2018-02-03 23:40:13,277 training [INFO ] Epoch  6 Batch 1220 Training err. 1.99481 Training err. RA 2.42768 Valid. err. 2.05841
2018-02-03 23:40:13,751 training [INFO ] Epoch  6 Batch 1240 Training err. 1.97004 Training err. RA 2.42029 Valid. err. 2.03331
2018-02-03 23:40:14,598 training [INFO ] Epoch  7 Batch 1260 Training err. 1.99708 Training err. RA 2.41358 Valid. err. 2.03738
2018-02-03 23:40:15,078 training [INFO ] Epoch  7 Batch 1280 Training err. 1.91951 Training err. RA 2.40586 Valid. err. 2.11980
2018-02-03 23:40:15,556 training [INFO ] Epoch  7 Batch 1300 Training err. 2.01163 Training err. RA 2.39979 Valid. err. 2.01924
2018-02-03 23:40:16,035 training [INFO ] Epoch  7 Batch 1320 Training err. 2.01878 Training err. RA 2.39402 Valid. err. 2.02641
2018-02-03 23:40:16,509 training [INFO ] Epoch  7 Batch 1340 Training err. 1.95951 Training err. RA 2.38753 Valid. err. 2.05868
2018-02-03 23:40:16,984 training [INFO ] Epoch  7 Batch 1360 Training err. 2.00423 Training err. RA 2.38190 Valid. err. 2.02207
2018-02-03 23:40:17,459 training [INFO ] Epoch  7 Batch 1380 Training err. 2.01343 Training err. RA 2.37656 Valid. err. 2.02836
2018-02-03 23:40:17,934 training [INFO ] Epoch  7 Batch 1400 Training err. 1.92416 Training err. RA 2.37009 Valid. err. 2.01477
2018-02-03 23:40:18,415 training [INFO ] Epoch  7 Batch 1420 Training err. 1.95705 Training err. RA 2.36428 Valid. err. 2.00725
2018-02-03 23:40:18,892 training [INFO ] Epoch  7 Batch 1440 Training err. 1.93027 Training err. RA 2.35825 Valid. err. 1.98106
2018-02-03 23:40:19,759 training [INFO ] Epoch  8 Batch 1460 Training err. 1.92753 Training err. RA 2.35235 Valid. err. 1.99467
2018-02-03 23:40:20,238 training [INFO ] Epoch  8 Batch 1480 Training err. 1.93009 Training err. RA 2.34664 Valid. err. 1.98683
2018-02-03 23:40:20,714 training [INFO ] Epoch  8 Batch 1500 Training err. 1.92102 Training err. RA 2.34097 Valid. err. 1.98512
2018-02-03 23:40:21,196 training [INFO ] Epoch  8 Batch 1520 Training err. 1.96460 Training err. RA 2.33601 Valid. err. 1.97463
2018-02-03 23:40:21,677 training [INFO ] Epoch  8 Batch 1540 Training err. 1.93466 Training err. RA 2.33080 Valid. err. 2.01267
2018-02-03 23:40:22,161 training [INFO ] Epoch  8 Batch 1560 Training err. 1.95268 Training err. RA 2.32595 Valid. err. 2.01295
2018-02-03 23:40:22,640 training [INFO ] Epoch  8 Batch 1580 Training err. 1.99431 Training err. RA 2.32176 Valid. err. 1.97459
2018-02-03 23:40:23,114 training [INFO ] Epoch  8 Batch 1600 Training err. 1.89065 Training err. RA 2.31637 Valid. err. 1.98973
2018-02-03 23:40:23,590 training [INFO ] Epoch  8 Batch 1620 Training err. 1.89780 Training err. RA 2.31120 Valid. err. 1.97739
2018-02-03 23:40:24,070 training [INFO ] Epoch  8 Batch 1640 Training err. 1.90388 Training err. RA 2.30623 Valid. err. 1.94019
2018-02-03 23:40:24,545 training [INFO ] Epoch  8 Batch 1660 Training err. 1.89229 Training err. RA 2.30125 Valid. err. 1.96586
2018-02-03 23:40:25,389 training [INFO ] Epoch  9 Batch 1680 Training err. 1.90610 Training err. RA 2.29654 Valid. err. 1.98147
2018-02-03 23:40:25,863 training [INFO ] Epoch  9 Batch 1700 Training err. 1.85404 Training err. RA 2.29134 Valid. err. 1.95786
2018-02-03 23:40:26,335 training [INFO ] Epoch  9 Batch 1720 Training err. 1.90976 Training err. RA 2.28690 Valid. err. 1.97044
2018-02-03 23:40:26,807 training [INFO ] Epoch  9 Batch 1740 Training err. 1.93040 Training err. RA 2.28280 Valid. err. 1.96035
2018-02-03 23:40:27,290 training [INFO ] Epoch  9 Batch 1760 Training err. 1.88846 Training err. RA 2.27832 Valid. err. 1.99969
2018-02-03 23:40:27,770 training [INFO ] Epoch  9 Batch 1780 Training err. 1.95360 Training err. RA 2.27467 Valid. err. 1.93901
2018-02-03 23:40:28,255 training [INFO ] Epoch  9 Batch 1800 Training err. 1.90495 Training err. RA 2.27056 Valid. err. 1.94023
2018-02-03 23:40:28,748 training [INFO ] Epoch  9 Batch 1820 Training err. 1.85528 Training err. RA 2.26600 Valid. err. 1.98137
2018-02-03 23:40:29,236 training [INFO ] Epoch  9 Batch 1840 Training err. 1.87659 Training err. RA 2.26177 Valid. err. 1.95220
2018-02-03 23:40:29,722 training [INFO ] Epoch  9 Batch 1860 Training err. 1.93198 Training err. RA 2.25822 Valid. err. 1.94497
2018-02-03 23:40:30,604 training [INFO ] Epoch 10 Batch 1880 Training err. 1.85342 Training err. RA 2.25391 Valid. err. 1.93343
2018-02-03 23:40:31,093 training [INFO ] Epoch 10 Batch 1900 Training err. 1.82779 Training err. RA 2.24943 Valid. err. 1.93045
2018-02-03 23:40:31,570 training [INFO ] Epoch 10 Batch 1920 Training err. 1.88047 Training err. RA 2.24559 Valid. err. 1.92442
2018-02-03 23:40:32,059 training [INFO ] Epoch 10 Batch 1940 Training err. 1.90032 Training err. RA 2.24203 Valid. err. 1.91854
2018-02-03 23:40:32,544 training [INFO ] Epoch 10 Batch 1960 Training err. 1.84893 Training err. RA 2.23802 Valid. err. 1.92295
2018-02-03 23:40:33,040 training [INFO ] Epoch 10 Batch 1980 Training err. 1.87051 Training err. RA 2.23430 Valid. err. 1.93805
2018-02-03 23:40:33,516 training [INFO ] Epoch 10 Batch 2000 Training err. 1.92701 Training err. RA 2.23123 Valid. err. 1.89597
2018-02-03 23:40:33,998 training [INFO ] Epoch 10 Batch 2020 Training err. 1.83241 Training err. RA 2.22728 Valid. err. 1.92781
2018-02-03 23:40:34,471 training [INFO ] Epoch 10 Batch 2040 Training err. 1.83164 Training err. RA 2.22340 Valid. err. 1.91231
2018-02-03 23:40:34,945 training [INFO ] Epoch 10 Batch 2060 Training err. 1.84890 Training err. RA 2.21977 Valid. err. 1.91652
2018-02-03 23:40:35,418 training [INFO ] Epoch 10 Batch 2080 Training err. 1.81389 Training err. RA 2.21586 Valid. err. 1.90833
2018-02-03 23:40:36,287 training [INFO ] Epoch 11 Batch 2100 Training err. 1.84321 Training err. RA 2.21231 Valid. err. 1.88594
2018-02-03 23:40:36,765 training [INFO ] Epoch 11 Batch 2120 Training err. 1.79204 Training err. RA 2.20835 Valid. err. 1.94659
2018-02-03 23:40:37,246 training [INFO ] Epoch 11 Batch 2140 Training err. 1.86577 Training err. RA 2.20515 Valid. err. 1.90540
2018-02-03 23:40:37,723 training [INFO ] Epoch 11 Batch 2160 Training err. 1.86918 Training err. RA 2.20204 Valid. err. 1.92951
2018-02-03 23:40:38,201 training [INFO ] Epoch 11 Batch 2180 Training err. 1.82875 Training err. RA 2.19861 Valid. err. 1.89413
2018-02-03 23:40:38,681 training [INFO ] Epoch 11 Batch 2200 Training err. 1.89117 Training err. RA 2.19582 Valid. err. 1.88281
2018-02-03 23:40:39,162 training [INFO ] Epoch 11 Batch 2220 Training err. 1.83398 Training err. RA 2.19256 Valid. err. 1.90197
2018-02-03 23:40:39,638 training [INFO ] Epoch 11 Batch 2240 Training err. 1.80398 Training err. RA 2.18909 Valid. err. 1.92093
2018-02-03 23:40:40,117 training [INFO ] Epoch 11 Batch 2260 Training err. 1.81721 Training err. RA 2.18580 Valid. err. 1.90699
2018-02-03 23:40:40,591 training [INFO ] Epoch 11 Batch 2280 Training err. 1.80721 Training err. RA 2.18248 Valid. err. 1.88179
2018-02-03 23:40:41,453 training [INFO ] Epoch 12 Batch 2300 Training err. 1.81149 Training err. RA 2.17925 Valid. err. 1.87886
2018-02-03 23:40:41,926 training [INFO ] Epoch 12 Batch 2320 Training err. 1.75758 Training err. RA 2.17562 Valid. err. 1.87271
2018-02-03 23:40:42,411 training [INFO ] Epoch 12 Batch 2340 Training err. 1.83994 Training err. RA 2.17275 Valid. err. 1.88591
2018-02-03 23:40:42,884 training [INFO ] Epoch 12 Batch 2360 Training err. 1.85436 Training err. RA 2.17005 Valid. err. 1.89216
2018-02-03 23:40:43,366 training [INFO ] Epoch 12 Batch 2380 Training err. 1.79883 Training err. RA 2.16693 Valid. err. 1.92327
2018-02-03 23:40:43,842 training [INFO ] Epoch 12 Batch 2400 Training err. 1.83746 Training err. RA 2.16418 Valid. err. 1.90510
2018-02-03 23:40:44,320 training [INFO ] Epoch 12 Batch 2420 Training err. 1.86486 Training err. RA 2.16171 Valid. err. 1.89709
2018-02-03 23:40:44,799 training [INFO ] Epoch 12 Batch 2440 Training err. 1.77429 Training err. RA 2.15853 Valid. err. 1.87886
2018-02-03 23:40:45,281 training [INFO ] Epoch 12 Batch 2460 Training err. 1.80621 Training err. RA 2.15567 Valid. err. 1.87407
2018-02-03 23:40:45,761 training [INFO ] Epoch 12 Batch 2480 Training err. 1.78524 Training err. RA 2.15268 Valid. err. 1.86861
2018-02-03 23:40:46,632 training [INFO ] Epoch 13 Batch 2500 Training err. 1.77109 Training err. RA 2.14963 Valid. err. 1.85859
2018-02-03 23:40:47,113 training [INFO ] Epoch 13 Batch 2520 Training err. 1.76500 Training err. RA 2.14658 Valid. err. 1.86708
2018-02-03 23:40:47,589 training [INFO ] Epoch 13 Batch 2540 Training err. 1.77894 Training err. RA 2.14368 Valid. err. 1.86204
2018-02-03 23:40:48,071 training [INFO ] Epoch 13 Batch 2560 Training err. 1.81845 Training err. RA 2.14114 Valid. err. 1.85505
2018-02-03 23:40:48,545 training [INFO ] Epoch 13 Batch 2580 Training err. 1.80249 Training err. RA 2.13852 Valid. err. 1.88173
2018-02-03 23:40:49,024 training [INFO ] Epoch 13 Batch 2600 Training err. 1.80222 Training err. RA 2.13593 Valid. err. 1.84549
2018-02-03 23:40:49,500 training [INFO ] Epoch 13 Batch 2620 Training err. 1.85406 Training err. RA 2.13378 Valid. err. 1.86288
2018-02-03 23:40:49,973 training [INFO ] Epoch 13 Batch 2640 Training err. 1.75837 Training err. RA 2.13093 Valid. err. 1.87081
2018-02-03 23:40:50,451 training [INFO ] Epoch 13 Batch 2660 Training err. 1.76694 Training err. RA 2.12820 Valid. err. 1.86206
2018-02-03 23:40:50,923 training [INFO ] Epoch 13 Batch 2680 Training err. 1.76867 Training err. RA 2.12551 Valid. err. 1.84274
2018-02-03 23:40:51,409 training [INFO ] Epoch 13 Batch 2700 Training err. 1.76552 Training err. RA 2.12285 Valid. err. 1.84740
2018-02-03 23:40:52,288 training [INFO ] Epoch 14 Batch 2720 Training err. 1.74595 Training err. RA 2.12008 Valid. err. 1.86194
2018-02-03 23:40:52,768 training [INFO ] Epoch 14 Batch 2740 Training err. 1.72739 Training err. RA 2.11721 Valid. err. 1.85640
2018-02-03 23:40:53,248 training [INFO ] Epoch 14 Batch 2760 Training err. 1.78705 Training err. RA 2.11482 Valid. err. 1.86551
2018-02-03 23:40:53,731 training [INFO ] Epoch 14 Batch 2780 Training err. 1.80540 Training err. RA 2.11259 Valid. err. 1.85238
2018-02-03 23:40:54,214 training [INFO ] Epoch 14 Batch 2800 Training err. 1.76347 Training err. RA 2.11010 Valid. err. 1.88705
2018-02-03 23:40:54,693 training [INFO ] Epoch 14 Batch 2820 Training err. 1.81960 Training err. RA 2.10804 Valid. err. 1.83591
2018-02-03 23:40:55,176 training [INFO ] Epoch 14 Batch 2840 Training err. 1.78604 Training err. RA 2.10577 Valid. err. 1.83801
2018-02-03 23:40:55,650 training [INFO ] Epoch 14 Batch 2860 Training err. 1.73996 Training err. RA 2.10321 Valid. err. 1.87237
2018-02-03 23:40:56,127 training [INFO ] Epoch 14 Batch 2880 Training err. 1.75858 Training err. RA 2.10082 Valid. err. 1.82466
2018-02-03 23:40:56,603 training [INFO ] Epoch 14 Batch 2900 Training err. 1.74388 Training err. RA 2.09836 Valid. err. 1.83714
2018-02-03 23:40:57,461 training [INFO ] Epoch 15 Batch 2920 Training err. 1.72102 Training err. RA 2.09577 Valid. err. 1.81764
2018-02-03 23:40:57,932 training [INFO ] Epoch 15 Batch 2940 Training err. 1.70452 Training err. RA 2.09311 Valid. err. 1.82431
2018-02-03 23:40:58,414 training [INFO ] Epoch 15 Batch 2960 Training err. 1.77044 Training err. RA 2.09093 Valid. err. 1.84096
2018-02-03 23:40:58,891 training [INFO ] Epoch 15 Batch 2980 Training err. 1.78367 Training err. RA 2.08887 Valid. err. 1.82553
2018-02-03 23:40:59,366 training [INFO ] Epoch 15 Batch 3000 Training err. 1.74327 Training err. RA 2.08656 Valid. err. 1.84483
2018-02-03 23:40:59,851 training [INFO ] Epoch 15 Batch 3020 Training err. 1.75505 Training err. RA 2.08437 Valid. err. 1.86137
2018-02-03 23:41:00,337 training [INFO ] Epoch 15 Batch 3040 Training err. 1.80921 Training err. RA 2.08256 Valid. err. 1.81998
2018-02-03 23:41:00,821 training [INFO ] Epoch 15 Batch 3060 Training err. 1.73042 Training err. RA 2.08026 Valid. err. 1.85802
2018-02-03 23:41:01,305 training [INFO ] Epoch 15 Batch 3080 Training err. 1.72091 Training err. RA 2.07792 Valid. err. 1.82860
2018-02-03 23:41:01,790 training [INFO ] Epoch 15 Batch 3100 Training err. 1.73610 Training err. RA 2.07572 Valid. err. 1.80458
2018-02-03 23:41:02,272 training [INFO ] Epoch 15 Batch 3120 Training err. 1.71514 Training err. RA 2.07341 Valid. err. 1.81040
2018-02-03 23:41:03,147 training [INFO ] Epoch 16 Batch 3140 Training err. 1.71581 Training err. RA 2.07113 Valid. err. 1.79307
2018-02-03 23:41:03,622 training [INFO ] Epoch 16 Batch 3160 Training err. 1.68717 Training err. RA 2.06870 Valid. err. 1.82155
2018-02-03 23:41:04,104 training [INFO ] Epoch 16 Batch 3180 Training err. 1.75356 Training err. RA 2.06672 Valid. err. 1.83837
2018-02-03 23:41:04,581 training [INFO ] Epoch 16 Batch 3200 Training err. 1.77832 Training err. RA 2.06491 Valid. err. 1.82601
2018-02-03 23:41:05,054 training [INFO ] Epoch 16 Batch 3220 Training err. 1.72068 Training err. RA 2.06278 Valid. err. 1.83736
2018-02-03 23:41:05,529 training [INFO ] Epoch 16 Batch 3240 Training err. 1.77627 Training err. RA 2.06101 Valid. err. 1.81369
2018-02-03 23:41:06,006 training [INFO ] Epoch 16 Batch 3260 Training err. 1.74136 Training err. RA 2.05905 Valid. err. 1.82187
2018-02-03 23:41:06,483 training [INFO ] Epoch 16 Batch 3280 Training err. 1.70852 Training err. RA 2.05691 Valid. err. 1.85058
2018-02-03 23:41:06,961 training [INFO ] Epoch 16 Batch 3300 Training err. 1.70922 Training err. RA 2.05480 Valid. err. 1.83533
2018-02-03 23:41:07,439 training [INFO ] Epoch 16 Batch 3320 Training err. 1.72093 Training err. RA 2.05279 Valid. err. 1.79991
2018-02-03 23:41:08,313 training [INFO ] Epoch 17 Batch 3340 Training err. 1.69715 Training err. RA 2.05066 Valid. err. 1.79296
2018-02-03 23:41:08,795 training [INFO ] Epoch 17 Batch 3360 Training err. 1.65865 Training err. RA 2.04833 Valid. err. 1.80738
2018-02-03 23:41:09,284 training [INFO ] Epoch 17 Batch 3380 Training err. 1.74205 Training err. RA 2.04652 Valid. err. 1.79311
2018-02-03 23:41:09,768 training [INFO ] Epoch 17 Batch 3400 Training err. 1.75388 Training err. RA 2.04479 Valid. err. 1.82867
2018-02-03 23:41:10,254 training [INFO ] Epoch 17 Batch 3420 Training err. 1.70465 Training err. RA 2.04280 Valid. err. 1.82416
2018-02-03 23:41:10,730 training [INFO ] Epoch 17 Batch 3440 Training err. 1.73345 Training err. RA 2.04101 Valid. err. 1.82274
2018-02-03 23:41:11,209 training [INFO ] Epoch 17 Batch 3460 Training err. 1.76748 Training err. RA 2.03943 Valid. err. 1.81612
2018-02-03 23:41:11,678 training [INFO ] Epoch 17 Batch 3480 Training err. 1.68986 Training err. RA 2.03742 Valid. err. 1.81303
2018-02-03 23:41:12,166 training [INFO ] Epoch 17 Batch 3500 Training err. 1.71096 Training err. RA 2.03555 Valid. err. 1.81458
2018-02-03 23:41:12,644 training [INFO ] Epoch 17 Batch 3520 Training err. 1.69815 Training err. RA 2.03363 Valid. err. 1.79917
2018-02-03 23:41:13,502 training [INFO ] Epoch 18 Batch 3540 Training err. 1.68151 Training err. RA 2.03164 Valid. err. 1.78332
2018-02-03 23:41:13,977 training [INFO ] Epoch 18 Batch 3560 Training err. 1.66890 Training err. RA 2.02961 Valid. err. 1.78933
2018-02-03 23:41:14,450 training [INFO ] Epoch 18 Batch 3580 Training err. 1.68673 Training err. RA 2.02769 Valid. err. 1.79901
2018-02-03 23:41:14,929 training [INFO ] Epoch 18 Batch 3600 Training err. 1.72542 Training err. RA 2.02601 Valid. err. 1.78918
2018-02-03 23:41:15,412 training [INFO ] Epoch 18 Batch 3620 Training err. 1.72436 Training err. RA 2.02435 Valid. err. 1.80512
2018-02-03 23:41:15,895 training [INFO ] Epoch 18 Batch 3640 Training err. 1.70496 Training err. RA 2.02259 Valid. err. 1.78501
2018-02-03 23:41:16,380 training [INFO ] Epoch 18 Batch 3660 Training err. 1.76006 Training err. RA 2.02116 Valid. err. 1.79744
2018-02-03 23:41:16,869 training [INFO ] Epoch 18 Batch 3680 Training err. 1.68144 Training err. RA 2.01931 Valid. err. 1.79670
2018-02-03 23:41:17,347 training [INFO ] Epoch 18 Batch 3700 Training err. 1.68290 Training err. RA 2.01749 Valid. err. 1.80276
2018-02-03 23:41:17,827 training [INFO ] Epoch 18 Batch 3720 Training err. 1.68455 Training err. RA 2.01570 Valid. err. 1.77598
2018-02-03 23:41:18,316 training [INFO ] Epoch 18 Batch 3740 Training err. 1.69007 Training err. RA 2.01396 Valid. err. 1.81098
2018-02-03 23:41:19,211 training [INFO ] Epoch 19 Batch 3760 Training err. 1.66098 Training err. RA 2.01208 Valid. err. 1.81304
2018-02-03 23:41:19,684 training [INFO ] Epoch 19 Batch 3780 Training err. 1.64408 Training err. RA 2.01013 Valid. err. 1.79063
2018-02-03 23:41:20,163 training [INFO ] Epoch 19 Batch 3800 Training err. 1.70101 Training err. RA 2.00851 Valid. err. 1.79815
2018-02-03 23:41:20,643 training [INFO ] Epoch 19 Batch 3820 Training err. 1.73150 Training err. RA 2.00706 Valid. err. 1.78112
2018-02-03 23:41:21,124 training [INFO ] Epoch 19 Batch 3840 Training err. 1.68118 Training err. RA 2.00536 Valid. err. 1.86578
2018-02-03 23:41:21,603 training [INFO ] Epoch 19 Batch 3860 Training err. 1.73429 Training err. RA 2.00396 Valid. err. 1.78777
2018-02-03 23:41:22,082 training [INFO ] Epoch 19 Batch 3880 Training err. 1.71205 Training err. RA 2.00245 Valid. err. 1.80258
2018-02-03 23:41:22,559 training [INFO ] Epoch 19 Batch 3900 Training err. 1.66599 Training err. RA 2.00073 Valid. err. 1.80486
2018-02-03 23:41:23,031 training [INFO ] Epoch 19 Batch 3920 Training err. 1.68064 Training err. RA 1.99909 Valid. err. 1.77693
2018-02-03 23:41:23,506 training [INFO ] Epoch 19 Batch 3940 Training err. 1.68040 Training err. RA 1.99747 Valid. err. 1.77235
2018-02-03 23:41:24,377 training [INFO ] Epoch 20 Batch 3960 Training err. 1.65499 Training err. RA 1.99575 Valid. err. 1.76491
2018-02-03 23:41:24,858 training [INFO ] Epoch 20 Batch 3980 Training err. 1.62819 Training err. RA 1.99390 Valid. err. 1.77752
2018-02-03 23:41:25,346 training [INFO ] Epoch 20 Batch 4000 Training err. 1.68709 Training err. RA 1.99236 Valid. err. 1.77195
2018-02-03 23:41:25,826 training [INFO ] Epoch 20 Batch 4020 Training err. 1.70871 Training err. RA 1.99095 Valid. err. 1.78075
2018-02-03 23:41:26,308 training [INFO ] Epoch 20 Batch 4040 Training err. 1.67406 Training err. RA 1.98938 Valid. err. 1.78122
2018-02-03 23:41:26,786 training [INFO ] Epoch 20 Batch 4060 Training err. 1.67595 Training err. RA 1.98784 Valid. err. 1.77990
2018-02-03 23:41:27,269 training [INFO ] Epoch 20 Batch 4080 Training err. 1.73696 Training err. RA 1.98661 Valid. err. 1.77159
2018-02-03 23:41:27,744 training [INFO ] Epoch 20 Batch 4100 Training err. 1.66528 Training err. RA 1.98504 Valid. err. 1.79843
2018-02-03 23:41:28,222 training [INFO ] Epoch 20 Batch 4120 Training err. 1.65396 Training err. RA 1.98344 Valid. err. 1.77171
2018-02-03 23:41:28,700 training [INFO ] Epoch 20 Batch 4140 Training err. 1.66477 Training err. RA 1.98190 Valid. err. 1.75249
2018-02-03 23:41:29,176 training [INFO ] Epoch 20 Batch 4160 Training err. 1.65902 Training err. RA 1.98034 Valid. err. 1.76525
2018-02-03 23:41:30,038 training [INFO ] Epoch 21 Batch 4180 Training err. 1.64950 Training err. RA 1.97876 Valid. err. 1.74927
2018-02-03 23:41:30,514 training [INFO ] Epoch 21 Batch 4200 Training err. 1.60593 Training err. RA 1.97699 Valid. err. 1.75947
2018-02-03 23:41:30,992 training [INFO ] Epoch 21 Batch 4220 Training err. 1.68429 Training err. RA 1.97560 Valid. err. 1.77929
2018-02-03 23:41:31,467 training [INFO ] Epoch 21 Batch 4240 Training err. 1.71337 Training err. RA 1.97436 Valid. err. 1.77588
2018-02-03 23:41:31,949 training [INFO ] Epoch 21 Batch 4260 Training err. 1.64755 Training err. RA 1.97283 Valid. err. 1.77632
2018-02-03 23:41:32,426 training [INFO ] Epoch 21 Batch 4280 Training err. 1.70774 Training err. RA 1.97159 Valid. err. 1.76113
2018-02-03 23:41:32,903 training [INFO ] Epoch 21 Batch 4300 Training err. 1.67862 Training err. RA 1.97023 Valid. err. 1.76716
2018-02-03 23:41:33,393 training [INFO ] Epoch 21 Batch 4320 Training err. 1.64478 Training err. RA 1.96872 Valid. err. 1.80218
2018-02-03 23:41:33,871 training [INFO ] Epoch 21 Batch 4340 Training err. 1.65293 Training err. RA 1.96726 Valid. err. 1.78257
2018-02-03 23:41:34,357 training [INFO ] Epoch 21 Batch 4360 Training err. 1.65732 Training err. RA 1.96584 Valid. err. 1.74136
2018-02-03 23:41:35,224 training [INFO ] Epoch 22 Batch 4380 Training err. 1.64464 Training err. RA 1.96438 Valid. err. 1.74396
2018-02-03 23:41:35,699 training [INFO ] Epoch 22 Batch 4400 Training err. 1.59410 Training err. RA 1.96269 Valid. err. 1.76289
2018-02-03 23:41:36,171 training [INFO ] Epoch 22 Batch 4420 Training err. 1.67177 Training err. RA 1.96138 Valid. err. 1.74792
2018-02-03 23:41:36,651 training [INFO ] Epoch 22 Batch 4440 Training err. 1.69462 Training err. RA 1.96017 Valid. err. 1.77498
2018-02-03 23:41:37,128 training [INFO ] Epoch 22 Batch 4460 Training err. 1.64130 Training err. RA 1.95874 Valid. err. 1.77300
2018-02-03 23:41:37,603 training [INFO ] Epoch 22 Batch 4480 Training err. 1.67279 Training err. RA 1.95747 Valid. err. 1.75241
2018-02-03 23:41:38,079 training [INFO ] Epoch 22 Batch 4500 Training err. 1.70604 Training err. RA 1.95635 Valid. err. 1.77020
2018-02-03 23:41:38,552 training [INFO ] Epoch 22 Batch 4520 Training err. 1.63692 Training err. RA 1.95494 Valid. err. 1.76068
2018-02-03 23:41:39,033 training [INFO ] Epoch 22 Batch 4540 Training err. 1.65658 Training err. RA 1.95362 Valid. err. 1.75675
2018-02-03 23:41:39,509 training [INFO ] Epoch 22 Batch 4560 Training err. 1.63915 Training err. RA 1.95224 Valid. err. 1.75463
2018-02-03 23:41:40,381 training [INFO ] Epoch 23 Batch 4580 Training err. 1.63157 Training err. RA 1.95084 Valid. err. 1.74605
2018-02-03 23:41:40,856 training [INFO ] Epoch 23 Batch 4600 Training err. 1.61199 Training err. RA 1.94937 Valid. err. 1.75413
2018-02-03 23:41:41,339 training [INFO ] Epoch 23 Batch 4620 Training err. 1.62350 Training err. RA 1.94796 Valid. err. 1.75218
2018-02-03 23:41:41,818 training [INFO ] Epoch 23 Batch 4640 Training err. 1.66755 Training err. RA 1.94675 Valid. err. 1.74645
2018-02-03 23:41:42,303 training [INFO ] Epoch 23 Batch 4660 Training err. 1.66296 Training err. RA 1.94553 Valid. err. 1.77183
2018-02-03 23:41:42,782 training [INFO ] Epoch 23 Batch 4680 Training err. 1.65180 Training err. RA 1.94428 Valid. err. 1.75487
2018-02-03 23:41:43,266 training [INFO ] Epoch 23 Batch 4700 Training err. 1.69908 Training err. RA 1.94323 Valid. err. 1.76502
2018-02-03 23:41:43,742 training [INFO ] Epoch 23 Batch 4720 Training err. 1.63221 Training err. RA 1.94192 Valid. err. 1.76182
2018-02-03 23:41:44,220 training [INFO ] Epoch 23 Batch 4740 Training err. 1.62848 Training err. RA 1.94059 Valid. err. 1.75834
2018-02-03 23:41:44,695 training [INFO ] Epoch 23 Batch 4760 Training err. 1.63197 Training err. RA 1.93930 Valid. err. 1.73369
2018-02-03 23:41:45,176 training [INFO ] Epoch 23 Batch 4780 Training err. 1.64269 Training err. RA 1.93806 Valid. err. 1.76041
2018-02-03 23:41:46,039 training [INFO ] Epoch 24 Batch 4800 Training err. 1.61177 Training err. RA 1.93670 Valid. err. 1.76792
2018-02-03 23:41:46,514 training [INFO ] Epoch 24 Batch 4820 Training err. 1.58464 Training err. RA 1.93524 Valid. err. 1.75181
2018-02-03 23:41:46,990 training [INFO ] Epoch 24 Batch 4840 Training err. 1.64705 Training err. RA 1.93404 Valid. err. 1.75492
2018-02-03 23:41:47,465 training [INFO ] Epoch 24 Batch 4860 Training err. 1.67465 Training err. RA 1.93298 Valid. err. 1.74778
2018-02-03 23:41:47,941 training [INFO ] Epoch 24 Batch 4880 Training err. 1.62543 Training err. RA 1.93172 Valid. err. 1.82601
2018-02-03 23:41:48,425 training [INFO ] Epoch 24 Batch 4900 Training err. 1.68424 Training err. RA 1.93071 Valid. err. 1.75829
2018-02-03 23:41:48,905 training [INFO ] Epoch 24 Batch 4920 Training err. 1.65805 Training err. RA 1.92960 Valid. err. 1.78039
2018-02-03 23:41:49,389 training [INFO ] Epoch 24 Batch 4940 Training err. 1.61140 Training err. RA 1.92831 Valid. err. 1.75446
2018-02-03 23:41:49,866 training [INFO ] Epoch 24 Batch 4960 Training err. 1.63200 Training err. RA 1.92711 Valid. err. 1.74743
2018-02-03 23:41:50,345 training [INFO ] Epoch 24 Batch 4980 Training err. 1.62826 Training err. RA 1.92591 Valid. err. 1.74057
2018-02-03 23:41:51,218 training [INFO ] Epoch 25 Batch 5000 Training err. 1.60750 Training err. RA 1.92464 Valid. err. 1.73927
2018-02-03 23:41:51,692 training [INFO ] Epoch 25 Batch 5020 Training err. 1.57971 Training err. RA 1.92327 Valid. err. 1.74850
2018-02-03 23:41:52,173 training [INFO ] Epoch 25 Batch 5040 Training err. 1.63690 Training err. RA 1.92213 Valid. err. 1.73752
2018-02-03 23:41:52,648 training [INFO ] Epoch 25 Batch 5060 Training err. 1.66030 Training err. RA 1.92110 Valid. err. 1.73543
2018-02-03 23:41:53,123 training [INFO ] Epoch 25 Batch 5080 Training err. 1.62108 Training err. RA 1.91991 Valid. err. 1.76372
2018-02-03 23:41:53,602 training [INFO ] Epoch 25 Batch 5100 Training err. 1.63353 Training err. RA 1.91879 Valid. err. 1.76149
2018-02-03 23:41:54,082 training [INFO ] Epoch 25 Batch 5120 Training err. 1.68115 Training err. RA 1.91786 Valid. err. 1.74760
2018-02-03 23:41:54,555 training [INFO ] Epoch 25 Batch 5140 Training err. 1.61568 Training err. RA 1.91669 Valid. err. 1.80476
2018-02-03 23:41:55,034 training [INFO ] Epoch 25 Batch 5160 Training err. 1.60611 Training err. RA 1.91548 Valid. err. 1.75303
2018-02-03 23:41:55,514 training [INFO ] Epoch 25 Batch 5180 Training err. 1.61622 Training err. RA 1.91433 Valid. err. 1.72015
2018-02-03 23:41:55,989 training [INFO ] Epoch 25 Batch 5200 Training err. 1.61375 Training err. RA 1.91317 Valid. err. 1.74455
2018-02-03 23:41:56,853 training [INFO ] Epoch 26 Batch 5220 Training err. 1.60325 Training err. RA 1.91198 Valid. err. 1.73677
2018-02-03 23:41:57,334 training [INFO ] Epoch 26 Batch 5240 Training err. 1.56088 Training err. RA 1.91064 Valid. err. 1.75022
2018-02-03 23:41:57,813 training [INFO ] Epoch 26 Batch 5260 Training err. 1.64020 Training err. RA 1.90962 Valid. err. 1.75029
2018-02-03 23:41:58,300 training [INFO ] Epoch 26 Batch 5280 Training err. 1.66258 Training err. RA 1.90868 Valid. err. 1.75846
2018-02-03 23:41:58,782 training [INFO ] Epoch 26 Batch 5300 Training err. 1.60070 Training err. RA 1.90752 Valid. err. 1.75316
2018-02-03 23:41:59,261 training [INFO ] Epoch 26 Batch 5320 Training err. 1.66474 Training err. RA 1.90661 Valid. err. 1.73511
2018-02-03 23:41:59,734 training [INFO ] Epoch 26 Batch 5340 Training err. 1.63096 Training err. RA 1.90557 Valid. err. 1.72954
2018-02-03 23:42:00,216 training [INFO ] Epoch 26 Batch 5360 Training err. 1.59626 Training err. RA 1.90442 Valid. err. 1.76586
2018-02-03 23:42:00,692 training [INFO ] Epoch 26 Batch 5380 Training err. 1.60338 Training err. RA 1.90330 Valid. err. 1.74346
2018-02-03 23:42:01,173 training [INFO ] Epoch 26 Batch 5400 Training err. 1.61610 Training err. RA 1.90224 Valid. err. 1.71853
2018-02-03 23:42:02,030 training [INFO ] Epoch 27 Batch 5420 Training err. 1.59805 Training err. RA 1.90111 Valid. err. 1.71782
2018-02-03 23:42:02,506 training [INFO ] Epoch 27 Batch 5440 Training err. 1.54858 Training err. RA 1.89982 Valid. err. 1.74788
2018-02-03 23:42:02,986 training [INFO ] Epoch 27 Batch 5460 Training err. 1.62883 Training err. RA 1.89882 Valid. err. 1.73622
2018-02-03 23:42:03,465 training [INFO ] Epoch 27 Batch 5480 Training err. 1.65121 Training err. RA 1.89792 Valid. err. 1.75004
2018-02-03 23:42:03,944 training [INFO ] Epoch 27 Batch 5500 Training err. 1.59267 Training err. RA 1.89681 Valid. err. 1.73862
2018-02-03 23:42:04,425 training [INFO ] Epoch 27 Batch 5520 Training err. 1.62476 Training err. RA 1.89583 Valid. err. 1.72206
2018-02-03 23:42:04,905 training [INFO ] Epoch 27 Batch 5540 Training err. 1.65960 Training err. RA 1.89497 Valid. err. 1.73874
2018-02-03 23:42:05,383 training [INFO ] Epoch 27 Batch 5560 Training err. 1.59246 Training err. RA 1.89388 Valid. err. 1.74599
2018-02-03 23:42:05,866 training [INFO ] Epoch 27 Batch 5580 Training err. 1.60473 Training err. RA 1.89285 Valid. err. 1.71888
2018-02-03 23:42:06,348 training [INFO ] Epoch 27 Batch 5600 Training err. 1.59497 Training err. RA 1.89178 Valid. err. 1.72836
2018-02-03 23:42:07,215 training [INFO ] Epoch 28 Batch 5620 Training err. 1.58865 Training err. RA 1.89071 Valid. err. 1.72045
2018-02-03 23:42:07,697 training [INFO ] Epoch 28 Batch 5640 Training err. 1.56409 Training err. RA 1.88955 Valid. err. 1.73202
2018-02-03 23:42:08,177 training [INFO ] Epoch 28 Batch 5660 Training err. 1.58060 Training err. RA 1.88846 Valid. err. 1.71856
2018-02-03 23:42:08,655 training [INFO ] Epoch 28 Batch 5680 Training err. 1.62317 Training err. RA 1.88752 Valid. err. 1.72912
2018-02-03 23:42:09,139 training [INFO ] Epoch 28 Batch 5700 Training err. 1.62222 Training err. RA 1.88659 Valid. err. 1.75660
2018-02-03 23:42:09,617 training [INFO ] Epoch 28 Batch 5720 Training err. 1.61324 Training err. RA 1.88563 Valid. err. 1.73280
2018-02-03 23:42:10,098 training [INFO ] Epoch 28 Batch 5740 Training err. 1.65640 Training err. RA 1.88484 Valid. err. 1.73784
2018-02-03 23:42:10,573 training [INFO ] Epoch 28 Batch 5760 Training err. 1.59042 Training err. RA 1.88381 Valid. err. 1.76386
2018-02-03 23:42:11,045 training [INFO ] Epoch 28 Batch 5780 Training err. 1.57911 Training err. RA 1.88276 Valid. err. 1.72956
2018-02-03 23:42:11,518 training [INFO ] Epoch 28 Batch 5800 Training err. 1.58728 Training err. RA 1.88174 Valid. err. 1.71213
2018-02-03 23:42:11,997 training [INFO ] Epoch 28 Batch 5820 Training err. 1.60598 Training err. RA 1.88079 Valid. err. 1.72743
2018-02-03 23:42:12,863 training [INFO ] Epoch 29 Batch 5840 Training err. 1.56779 Training err. RA 1.87972 Valid. err. 1.74409
2018-02-03 23:42:13,347 training [INFO ] Epoch 29 Batch 5860 Training err. 1.53928 Training err. RA 1.87856 Valid. err. 1.73187
2018-02-03 23:42:13,821 training [INFO ] Epoch 29 Batch 5880 Training err. 1.60813 Training err. RA 1.87764 Valid. err. 1.72833
2018-02-03 23:42:14,300 training [INFO ] Epoch 29 Batch 5900 Training err. 1.63383 Training err. RA 1.87681 Valid. err. 1.72251
2018-02-03 23:42:14,775 training [INFO ] Epoch 29 Batch 5920 Training err. 1.58091 Training err. RA 1.87581 Valid. err. 1.80423
2018-02-03 23:42:15,260 training [INFO ] Epoch 29 Batch 5940 Training err. 1.64756 Training err. RA 1.87504 Valid. err. 1.73237
2018-02-03 23:42:15,728 training [INFO ] Epoch 29 Batch 5960 Training err. 1.61606 Training err. RA 1.87418 Valid. err. 1.76327
2018-02-03 23:42:16,213 training [INFO ] Epoch 29 Batch 5980 Training err. 1.57143 Training err. RA 1.87316 Valid. err. 1.73835
2018-02-03 23:42:16,686 training [INFO ] Epoch 29 Batch 6000 Training err. 1.58235 Training err. RA 1.87219 Valid. err. 1.70827
2018-02-03 23:42:17,162 training [INFO ] Epoch 29 Batch 6020 Training err. 1.58885 Training err. RA 1.87125 Valid. err. 1.71348
2018-02-03 23:42:18,023 training [INFO ] Epoch 30 Batch 6040 Training err. 1.56288 Training err. RA 1.87023 Valid. err. 1.72196
2018-02-03 23:42:18,494 training [INFO ] Epoch 30 Batch 6060 Training err. 1.53373 Training err. RA 1.86912 Valid. err. 1.72058
2018-02-03 23:42:18,970 training [INFO ] Epoch 30 Batch 6080 Training err. 1.59623 Training err. RA 1.86822 Valid. err. 1.72980
2018-02-03 23:42:19,445 training [INFO ] Epoch 30 Batch 6100 Training err. 1.62468 Training err. RA 1.86742 Valid. err. 1.70829
2018-02-03 23:42:19,918 training [INFO ] Epoch 30 Batch 6120 Training err. 1.58044 Training err. RA 1.86649 Valid. err. 1.73980
2018-02-03 23:42:20,395 training [INFO ] Epoch 30 Batch 6140 Training err. 1.59348 Training err. RA 1.86560 Valid. err. 1.72971
2018-02-03 23:42:20,875 training [INFO ] Epoch 30 Batch 6160 Training err. 1.63951 Training err. RA 1.86486 Valid. err. 1.71405
2018-02-03 23:42:21,356 training [INFO ] Epoch 30 Batch 6180 Training err. 1.58008 Training err. RA 1.86394 Valid. err. 1.74960
2018-02-03 23:42:21,834 training [INFO ] Epoch 30 Batch 6200 Training err. 1.55811 Training err. RA 1.86296 Valid. err. 1.73117
2018-02-03 23:42:22,315 training [INFO ] Epoch 30 Batch 6220 Training err. 1.57646 Training err. RA 1.86203 Valid. err. 1.68961
2018-02-03 23:42:22,790 training [INFO ] Epoch 30 Batch 6240 Training err. 1.57622 Training err. RA 1.86112 Valid. err. 1.71228
2018-02-03 23:42:23,644 training [INFO ] Epoch 31 Batch 6260 Training err. 1.56074 Training err. RA 1.86016 Valid. err. 1.71196
2018-02-03 23:42:24,128 training [INFO ] Epoch 31 Batch 6280 Training err. 1.51622 Training err. RA 1.85906 Valid. err. 1.72346
2018-02-03 23:42:24,610 training [INFO ] Epoch 31 Batch 6300 Training err. 1.60089 Training err. RA 1.85824 Valid. err. 1.72759
2018-02-03 23:42:25,092 training [INFO ] Epoch 31 Batch 6320 Training err. 1.63012 Training err. RA 1.85752 Valid. err. 1.73128
2018-02-03 23:42:25,574 training [INFO ] Epoch 31 Batch 6340 Training err. 1.56012 Training err. RA 1.85658 Valid. err. 1.72474
2018-02-03 23:42:26,052 training [INFO ] Epoch 31 Batch 6360 Training err. 1.62599 Training err. RA 1.85586 Valid. err. 1.70229
2018-02-03 23:42:26,529 training [INFO ] Epoch 31 Batch 6380 Training err. 1.59511 Training err. RA 1.85504 Valid. err. 1.70959
2018-02-03 23:42:27,016 training [INFO ] Epoch 31 Batch 6400 Training err. 1.55674 Training err. RA 1.85411 Valid. err. 1.75021
2018-02-03 23:42:27,488 training [INFO ] Epoch 31 Batch 6420 Training err. 1.56706 Training err. RA 1.85321 Valid. err. 1.72477
2018-02-03 23:42:27,974 training [INFO ] Epoch 31 Batch 6440 Training err. 1.58050 Training err. RA 1.85237 Valid. err. 1.68917
2018-02-03 23:42:28,867 training [INFO ] Epoch 32 Batch 6460 Training err. 1.55336 Training err. RA 1.85144 Valid. err. 1.69902
2018-02-03 23:42:29,344 training [INFO ] Epoch 32 Batch 6480 Training err. 1.51355 Training err. RA 1.85040 Valid. err. 1.71198
2018-02-03 23:42:29,822 training [INFO ] Epoch 32 Batch 6500 Training err. 1.58600 Training err. RA 1.84959 Valid. err. 1.69619
2018-02-03 23:42:30,312 training [INFO ] Epoch 32 Batch 6520 Training err. 1.61642 Training err. RA 1.84887 Valid. err. 1.73442
2018-02-03 23:42:30,786 training [INFO ] Epoch 32 Batch 6540 Training err. 1.55305 Training err. RA 1.84797 Valid. err. 1.71945
2018-02-03 23:42:31,266 training [INFO ] Epoch 32 Batch 6560 Training err. 1.58860 Training err. RA 1.84717 Valid. err. 1.71274
2018-02-03 23:42:31,739 training [INFO ] Epoch 32 Batch 6580 Training err. 1.61596 Training err. RA 1.84647 Valid. err. 1.72179
2018-02-03 23:42:32,219 training [INFO ] Epoch 32 Batch 6600 Training err. 1.56013 Training err. RA 1.84560 Valid. err. 1.71919
2018-02-03 23:42:32,695 training [INFO ] Epoch 32 Batch 6620 Training err. 1.56317 Training err. RA 1.84475 Valid. err. 1.69694
2018-02-03 23:42:33,173 training [INFO ] Epoch 32 Batch 6640 Training err. 1.55470 Training err. RA 1.84388 Valid. err. 1.71273
2018-02-03 23:42:34,031 training [INFO ] Epoch 33 Batch 6660 Training err. 1.55299 Training err. RA 1.84300 Valid. err. 1.69053
2018-02-03 23:42:34,503 training [INFO ] Epoch 33 Batch 6680 Training err. 1.52572 Training err. RA 1.84205 Valid. err. 1.70818
2018-02-03 23:42:34,981 training [INFO ] Epoch 33 Batch 6700 Training err. 1.54517 Training err. RA 1.84117 Valid. err. 1.69197
2018-02-03 23:42:35,459 training [INFO ] Epoch 33 Batch 6720 Training err. 1.59038 Training err. RA 1.84042 Valid. err. 1.71720
2018-02-03 23:42:35,945 training [INFO ] Epoch 33 Batch 6740 Training err. 1.60000 Training err. RA 1.83971 Valid. err. 1.71542
2018-02-03 23:42:36,423 training [INFO ] Epoch 33 Batch 6760 Training err. 1.57097 Training err. RA 1.83891 Valid. err. 1.69966
2018-02-03 23:42:36,906 training [INFO ] Epoch 33 Batch 6780 Training err. 1.62204 Training err. RA 1.83827 Valid. err. 1.71040
2018-02-03 23:42:37,395 training [INFO ] Epoch 33 Batch 6800 Training err. 1.55329 Training err. RA 1.83743 Valid. err. 1.70885
2018-02-03 23:42:37,873 training [INFO ] Epoch 33 Batch 6820 Training err. 1.54240 Training err. RA 1.83657 Valid. err. 1.72223
2018-02-03 23:42:38,353 training [INFO ] Epoch 33 Batch 6840 Training err. 1.54354 Training err. RA 1.83571 Valid. err. 1.68137
2018-02-03 23:42:38,831 training [INFO ] Epoch 33 Batch 6860 Training err. 1.56659 Training err. RA 1.83493 Valid. err. 1.69571
2018-02-03 23:42:39,694 training [INFO ] Epoch 34 Batch 6880 Training err. 1.52867 Training err. RA 1.83404 Valid. err. 1.71699
2018-02-03 23:42:40,169 training [INFO ] Epoch 34 Batch 6900 Training err. 1.51030 Training err. RA 1.83310 Valid. err. 1.68836
2018-02-03 23:42:40,645 training [INFO ] Epoch 34 Batch 6920 Training err. 1.57004 Training err. RA 1.83234 Valid. err. 1.71419
2018-02-03 23:42:41,122 training [INFO ] Epoch 34 Batch 6940 Training err. 1.59643 Training err. RA 1.83166 Valid. err. 1.69575
2018-02-03 23:42:41,595 training [INFO ] Epoch 34 Batch 6960 Training err. 1.53984 Training err. RA 1.83082 Valid. err. 1.76111
2018-02-03 23:42:42,079 training [INFO ] Epoch 34 Batch 6980 Training err. 1.60228 Training err. RA 1.83017 Valid. err. 1.70929
2018-02-03 23:42:42,553 training [INFO ] Epoch 34 Batch 7000 Training err. 1.58382 Training err. RA 1.82946 Valid. err. 1.73942
2018-02-03 23:42:43,033 training [INFO ] Epoch 34 Batch 7020 Training err. 1.53978 Training err. RA 1.82864 Valid. err. 1.71950
2018-02-03 23:42:43,512 training [INFO ] Epoch 34 Batch 7040 Training err. 1.54370 Training err. RA 1.82783 Valid. err. 1.69304
2018-02-03 23:42:43,990 training [INFO ] Epoch 34 Batch 7060 Training err. 1.55322 Training err. RA 1.82705 Valid. err. 1.69236
2018-02-03 23:42:44,858 training [INFO ] Epoch 35 Batch 7080 Training err. 1.52608 Training err. RA 1.82620 Valid. err. 1.70045
2018-02-03 23:42:45,342 training [INFO ] Epoch 35 Batch 7100 Training err. 1.50330 Training err. RA 1.82529 Valid. err. 1.68312
2018-02-03 23:42:45,821 training [INFO ] Epoch 35 Batch 7120 Training err. 1.56459 Training err. RA 1.82456 Valid. err. 1.68597
2018-02-03 23:42:46,310 training [INFO ] Epoch 35 Batch 7140 Training err. 1.58562 Training err. RA 1.82389 Valid. err. 1.68934
2018-02-03 23:42:46,789 training [INFO ] Epoch 35 Batch 7160 Training err. 1.54318 Training err. RA 1.82310 Valid. err. 1.71732
2018-02-03 23:42:47,263 training [INFO ] Epoch 35 Batch 7180 Training err. 1.54964 Training err. RA 1.82234 Valid. err. 1.70393
2018-02-03 23:42:47,735 training [INFO ] Epoch 35 Batch 7200 Training err. 1.60396 Training err. RA 1.82174 Valid. err. 1.69647
2018-02-03 23:42:48,216 training [INFO ] Epoch 35 Batch 7220 Training err. 1.54827 Training err. RA 1.82098 Valid. err. 1.72857
2018-02-03 23:42:48,692 training [INFO ] Epoch 35 Batch 7240 Training err. 1.51871 Training err. RA 1.82014 Valid. err. 1.70232
2018-02-03 23:42:49,173 training [INFO ] Epoch 35 Batch 7260 Training err. 1.53453 Training err. RA 1.81936 Valid. err. 1.67628
2018-02-03 23:42:49,650 training [INFO ] Epoch 35 Batch 7280 Training err. 1.54200 Training err. RA 1.81859 Valid. err. 1.69761
2018-02-03 23:42:50,501 training [INFO ] Epoch 36 Batch 7300 Training err. 1.53082 Training err. RA 1.81781 Valid. err. 1.67723
2018-02-03 23:42:50,978 training [INFO ] Epoch 36 Batch 7320 Training err. 1.48095 Training err. RA 1.81689 Valid. err. 1.69804
2018-02-03 23:42:51,453 training [INFO ] Epoch 36 Batch 7340 Training err. 1.57272 Training err. RA 1.81622 Valid. err. 1.69006
2018-02-03 23:42:51,924 training [INFO ] Epoch 36 Batch 7360 Training err. 1.59369 Training err. RA 1.81562 Valid. err. 1.69911
2018-02-03 23:42:52,411 training [INFO ] Epoch 36 Batch 7380 Training err. 1.52074 Training err. RA 1.81482 Valid. err. 1.70544
2018-02-03 23:42:52,888 training [INFO ] Epoch 36 Batch 7400 Training err. 1.58707 Training err. RA 1.81420 Valid. err. 1.67301
2018-02-03 23:42:53,360 training [INFO ] Epoch 36 Batch 7420 Training err. 1.55982 Training err. RA 1.81351 Valid. err. 1.68368
2018-02-03 23:42:53,836 training [INFO ] Epoch 36 Batch 7440 Training err. 1.52282 Training err. RA 1.81273 Valid. err. 1.71214
2018-02-03 23:42:54,315 training [INFO ] Epoch 36 Batch 7460 Training err. 1.52319 Training err. RA 1.81196 Valid. err. 1.70263
2018-02-03 23:42:54,792 training [INFO ] Epoch 36 Batch 7480 Training err. 1.54291 Training err. RA 1.81124 Valid. err. 1.67355
2018-02-03 23:42:55,649 training [INFO ] Epoch 37 Batch 7500 Training err. 1.51910 Training err. RA 1.81046 Valid. err. 1.67440
2018-02-03 23:42:56,131 training [INFO ] Epoch 37 Batch 7520 Training err. 1.48218 Training err. RA 1.80959 Valid. err. 1.67558
2018-02-03 23:42:56,609 training [INFO ] Epoch 37 Batch 7540 Training err. 1.55638 Training err. RA 1.80891 Valid. err. 1.66540
2018-02-03 23:42:57,095 training [INFO ] Epoch 37 Batch 7560 Training err. 1.57904 Training err. RA 1.80831 Valid. err. 1.71596
2018-02-03 23:42:57,575 training [INFO ] Epoch 37 Batch 7580 Training err. 1.51878 Training err. RA 1.80754 Valid. err. 1.70233
2018-02-03 23:42:58,056 training [INFO ] Epoch 37 Batch 7600 Training err. 1.55252 Training err. RA 1.80687 Valid. err. 1.69047
2018-02-03 23:42:58,534 training [INFO ] Epoch 37 Batch 7620 Training err. 1.58465 Training err. RA 1.80629 Valid. err. 1.70258
2018-02-03 23:42:59,012 training [INFO ] Epoch 37 Batch 7640 Training err. 1.52434 Training err. RA 1.80555 Valid. err. 1.70187
2018-02-03 23:42:59,492 training [INFO ] Epoch 37 Batch 7660 Training err. 1.52802 Training err. RA 1.80482 Valid. err. 1.66943
2018-02-03 23:42:59,971 training [INFO ] Epoch 37 Batch 7680 Training err. 1.51943 Training err. RA 1.80408 Valid. err. 1.68101
2018-02-03 23:43:00,828 training [INFO ] Epoch 38 Batch 7700 Training err. 1.51680 Training err. RA 1.80334 Valid. err. 1.66501
2018-02-03 23:43:01,307 training [INFO ] Epoch 38 Batch 7720 Training err. 1.50383 Training err. RA 1.80256 Valid. err. 1.67640
2018-02-03 23:43:01,781 training [INFO ] Epoch 38 Batch 7740 Training err. 1.51198 Training err. RA 1.80181 Valid. err. 1.66726
2018-02-03 23:43:02,253 training [INFO ] Epoch 38 Batch 7760 Training err. 1.55922 Training err. RA 1.80118 Valid. err. 1.70512
2018-02-03 23:43:02,729 training [INFO ] Epoch 38 Batch 7780 Training err. 1.54700 Training err. RA 1.80053 Valid. err. 1.69825
2018-02-03 23:43:03,209 training [INFO ] Epoch 38 Batch 7800 Training err. 1.52162 Training err. RA 1.79981 Valid. err. 1.68317
2018-02-03 23:43:03,688 training [INFO ] Epoch 38 Batch 7820 Training err. 1.58224 Training err. RA 1.79926 Valid. err. 1.69654
2018-02-03 23:43:04,173 training [INFO ] Epoch 38 Batch 7840 Training err. 1.52296 Training err. RA 1.79855 Valid. err. 1.69397
2018-02-03 23:43:04,652 training [INFO ] Epoch 38 Batch 7860 Training err. 1.50930 Training err. RA 1.79782 Valid. err. 1.68616
2018-02-03 23:43:05,134 training [INFO ] Epoch 38 Batch 7880 Training err. 1.51188 Training err. RA 1.79709 Valid. err. 1.68172
2018-02-03 23:43:05,610 training [INFO ] Epoch 38 Batch 7900 Training err. 1.53444 Training err. RA 1.79643 Valid. err. 1.66578
2018-02-03 23:43:06,461 training [INFO ] Epoch 39 Batch 7920 Training err. 1.50029 Training err. RA 1.79568 Valid. err. 1.68099
2018-02-03 23:43:06,941 training [INFO ] Epoch 39 Batch 7940 Training err. 1.47444 Training err. RA 1.79487 Valid. err. 1.66888
2018-02-03 23:43:07,423 training [INFO ] Epoch 39 Batch 7960 Training err. 1.54148 Training err. RA 1.79423 Valid. err. 1.70170
2018-02-03 23:43:07,901 training [INFO ] Epoch 39 Batch 7980 Training err. 1.57110 Training err. RA 1.79367 Valid. err. 1.67604
2018-02-03 23:43:08,376 training [INFO ] Epoch 39 Batch 8000 Training err. 1.50795 Training err. RA 1.79296 Valid. err. 1.72759
2018-02-03 23:43:08,855 training [INFO ] Epoch 39 Batch 8020 Training err. 1.68981 Training err. RA 1.79270 Valid. err. 1.68727
2018-02-03 23:43:09,335 training [INFO ] Epoch 39 Batch 8040 Training err. 1.54906 Training err. RA 1.79210 Valid. err. 1.70389
2018-02-03 23:43:09,820 training [INFO ] Epoch 39 Batch 8060 Training err. 1.51069 Training err. RA 1.79140 Valid. err. 1.69762
2018-02-03 23:43:10,300 training [INFO ] Epoch 39 Batch 8080 Training err. 1.51177 Training err. RA 1.79071 Valid. err. 1.67347
2018-02-03 23:43:10,771 training [INFO ] Epoch 39 Batch 8100 Training err. 1.52042 Training err. RA 1.79004 Valid. err. 1.67757
2018-02-03 23:43:11,630 training [INFO ] Epoch 40 Batch 8120 Training err. 1.49527 Training err. RA 1.78931 Valid. err. 1.67294
2018-02-03 23:43:12,112 training [INFO ] Epoch 40 Batch 8140 Training err. 1.47238 Training err. RA 1.78853 Valid. err. 1.66353
2018-02-03 23:43:12,593 training [INFO ] Epoch 40 Batch 8160 Training err. 1.53779 Training err. RA 1.78792 Valid. err. 1.66389
2018-02-03 23:43:13,073 training [INFO ] Epoch 40 Batch 8180 Training err. 1.55369 Training err. RA 1.78735 Valid. err. 1.66420
2018-02-03 23:43:13,554 training [INFO ] Epoch 40 Batch 8200 Training err. 1.50524 Training err. RA 1.78666 Valid. err. 1.69045
2018-02-03 23:43:14,032 training [INFO ] Epoch 40 Batch 8220 Training err. 1.51442 Training err. RA 1.78600 Valid. err. 1.67615
2018-02-03 23:43:14,514 training [INFO ] Epoch 40 Batch 8240 Training err. 1.57001 Training err. RA 1.78547 Valid. err. 1.68245
2018-02-03 23:43:14,997 training [INFO ] Epoch 40 Batch 8260 Training err. 1.51391 Training err. RA 1.78481 Valid. err. 1.70081
2018-02-03 23:43:15,474 training [INFO ] Epoch 40 Batch 8280 Training err. 1.49476 Training err. RA 1.78411 Valid. err. 1.70917
2018-02-03 23:43:15,952 training [INFO ] Epoch 40 Batch 8300 Training err. 1.50317 Training err. RA 1.78344 Valid. err. 1.65119
2018-02-03 23:43:16,432 training [INFO ] Epoch 40 Batch 8320 Training err. 1.50504 Training err. RA 1.78277 Valid. err. 1.67031
2018-02-03 23:43:17,257 training [INFO ] Epoch 41 Batch 8340 Training err. 1.49910 Training err. RA 1.78209 Valid. err. 1.65834
2018-02-03 23:43:17,732 training [INFO ] Epoch 41 Batch 8360 Training err. 1.45523 Training err. RA 1.78131 Valid. err. 1.67115
2018-02-03 23:43:18,214 training [INFO ] Epoch 41 Batch 8380 Training err. 1.53571 Training err. RA 1.78072 Valid. err. 1.68469
2018-02-03 23:43:18,690 training [INFO ] Epoch 41 Batch 8400 Training err. 1.55673 Training err. RA 1.78019 Valid. err. 1.69654
2018-02-03 23:43:19,169 training [INFO ] Epoch 41 Batch 8420 Training err. 1.48131 Training err. RA 1.77948 Valid. err. 1.69676
2018-02-03 23:43:19,649 training [INFO ] Epoch 41 Batch 8440 Training err. 1.56241 Training err. RA 1.77896 Valid. err. 1.68116
2018-02-03 23:43:20,128 training [INFO ] Epoch 41 Batch 8460 Training err. 1.53323 Training err. RA 1.77838 Valid. err. 1.66969
2018-02-03 23:43:20,606 training [INFO ] Epoch 41 Batch 8480 Training err. 1.49349 Training err. RA 1.77771 Valid. err. 1.69128
2018-02-03 23:43:21,088 training [INFO ] Epoch 41 Batch 8500 Training err. 1.49004 Training err. RA 1.77703 Valid. err. 1.67855
2018-02-03 23:43:21,564 training [INFO ] Epoch 41 Batch 8520 Training err. 1.50926 Training err. RA 1.77640 Valid. err. 1.65137
2018-02-03 23:43:22,441 training [INFO ] Epoch 42 Batch 8540 Training err. 1.48884 Training err. RA 1.77573 Valid. err. 1.66381
2018-02-03 23:43:22,920 training [INFO ] Epoch 42 Batch 8560 Training err. 1.45317 Training err. RA 1.77498 Valid. err. 1.67996
2018-02-03 23:43:23,397 training [INFO ] Epoch 42 Batch 8580 Training err. 1.53047 Training err. RA 1.77441 Valid. err. 1.66761
2018-02-03 23:43:23,875 training [INFO ] Epoch 42 Batch 8600 Training err. 1.55003 Training err. RA 1.77388 Valid. err. 1.69499
2018-02-03 23:43:24,357 training [INFO ] Epoch 42 Batch 8620 Training err. 1.48556 Training err. RA 1.77322 Valid. err. 1.68986
2018-02-03 23:43:24,831 training [INFO ] Epoch 42 Batch 8640 Training err. 1.51443 Training err. RA 1.77262 Valid. err. 1.67759
2018-02-03 23:43:25,311 training [INFO ] Epoch 42 Batch 8660 Training err. 1.55463 Training err. RA 1.77211 Valid. err. 1.70794
2018-02-03 23:43:25,784 training [INFO ] Epoch 42 Batch 8680 Training err. 1.49704 Training err. RA 1.77148 Valid. err. 1.69180
2018-02-03 23:43:26,263 training [INFO ] Epoch 42 Batch 8700 Training err. 1.50535 Training err. RA 1.77087 Valid. err. 1.66587
2018-02-03 23:43:26,742 training [INFO ] Epoch 42 Batch 8720 Training err. 1.49338 Training err. RA 1.77023 Valid. err. 1.67332
2018-02-03 23:43:27,603 training [INFO ] Epoch 43 Batch 8740 Training err. 1.48215 Training err. RA 1.76957 Valid. err. 1.64234
2018-02-03 23:43:28,082 training [INFO ] Epoch 43 Batch 8760 Training err. 1.47393 Training err. RA 1.76890 Valid. err. 1.66453
2018-02-03 23:43:28,558 training [INFO ] Epoch 43 Batch 8780 Training err. 1.48679 Training err. RA 1.76825 Valid. err. 1.65261
2018-02-03 23:43:29,033 training [INFO ] Epoch 43 Batch 8800 Training err. 1.52563 Training err. RA 1.76770 Valid. err. 1.68234
2018-02-03 23:43:29,508 training [INFO ] Epoch 43 Batch 8820 Training err. 1.52240 Training err. RA 1.76715 Valid. err. 1.68606
2018-02-03 23:43:30,002 training [INFO ] Epoch 43 Batch 8840 Training err. 1.48933 Training err. RA 1.76652 Valid. err. 1.66199
2018-02-03 23:43:30,475 training [INFO ] Epoch 43 Batch 8860 Training err. 1.55584 Training err. RA 1.76604 Valid. err. 1.67922
2018-02-03 23:43:30,958 training [INFO ] Epoch 43 Batch 8880 Training err. 1.49165 Training err. RA 1.76542 Valid. err. 1.67744
2018-02-03 23:43:31,438 training [INFO ] Epoch 43 Batch 8900 Training err. 1.47858 Training err. RA 1.76478 Valid. err. 1.68227
2018-02-03 23:43:31,916 training [INFO ] Epoch 43 Batch 8920 Training err. 1.48312 Training err. RA 1.76415 Valid. err. 1.65315
2018-02-03 23:43:32,396 training [INFO ] Epoch 43 Batch 8940 Training err. 1.50279 Training err. RA 1.76356 Valid. err. 1.66140
2018-02-03 23:43:33,263 training [INFO ] Epoch 44 Batch 8960 Training err. 1.47011 Training err. RA 1.76291 Valid. err. 1.66914
2018-02-03 23:43:33,747 training [INFO ] Epoch 44 Batch 8980 Training err. 1.44726 Training err. RA 1.76221 Valid. err. 1.65503
2018-02-03 23:43:34,229 training [INFO ] Epoch 44 Batch 9000 Training err. 1.51116 Training err. RA 1.76165 Valid. err. 1.68070
2018-02-03 23:43:34,712 training [INFO ] Epoch 44 Batch 9020 Training err. 1.53026 Training err. RA 1.76113 Valid. err. 1.67080
2018-02-03 23:43:35,190 training [INFO ] Epoch 44 Batch 9040 Training err. 1.47260 Training err. RA 1.76050 Valid. err. 1.69096
2018-02-03 23:43:35,670 training [INFO ] Epoch 44 Batch 9060 Training err. 1.52885 Training err. RA 1.75999 Valid. err. 1.69550
2018-02-03 23:43:36,156 training [INFO ] Epoch 44 Batch 9080 Training err. 1.52271 Training err. RA 1.75946 Valid. err. 1.68679
2018-02-03 23:43:36,629 training [INFO ] Epoch 44 Batch 9100 Training err. 1.47233 Training err. RA 1.75883 Valid. err. 1.66848
2018-02-03 23:43:37,107 training [INFO ] Epoch 44 Batch 9120 Training err. 1.48592 Training err. RA 1.75823 Valid. err. 1.65883
2018-02-03 23:43:37,577 training [INFO ] Epoch 44 Batch 9140 Training err. 1.49544 Training err. RA 1.75766 Valid. err. 1.65092
2018-02-03 23:43:38,439 training [INFO ] Epoch 45 Batch 9160 Training err. 1.46423 Training err. RA 1.75702 Valid. err. 1.65350
2018-02-03 23:43:38,913 training [INFO ] Epoch 45 Batch 9180 Training err. 1.44557 Training err. RA 1.75634 Valid. err. 1.65688
2018-02-03 23:43:39,395 training [INFO ] Epoch 45 Batch 9200 Training err. 1.50830 Training err. RA 1.75580 Valid. err. 1.64824
2018-02-03 23:43:39,871 training [INFO ] Epoch 45 Batch 9220 Training err. 1.52119 Training err. RA 1.75529 Valid. err. 1.64326
2018-02-03 23:43:40,354 training [INFO ] Epoch 45 Batch 9240 Training err. 1.48254 Training err. RA 1.75470 Valid. err. 1.68158
2018-02-03 23:43:40,827 training [INFO ] Epoch 45 Batch 9260 Training err. 1.47774 Training err. RA 1.75410 Valid. err. 1.67262
2018-02-03 23:43:41,299 training [INFO ] Epoch 45 Batch 9280 Training err. 1.55841 Training err. RA 1.75368 Valid. err. 1.65955
2018-02-03 23:43:41,780 training [INFO ] Epoch 45 Batch 9300 Training err. 1.48843 Training err. RA 1.75311 Valid. err. 1.67679
2018-02-03 23:43:42,260 training [INFO ] Epoch 45 Batch 9320 Training err. 1.45882 Training err. RA 1.75248 Valid. err. 1.69779
2018-02-03 23:43:42,741 training [INFO ] Epoch 45 Batch 9340 Training err. 1.47447 Training err. RA 1.75188 Valid. err. 1.63753
2018-02-03 23:43:43,219 training [INFO ] Epoch 45 Batch 9360 Training err. 1.47953 Training err. RA 1.75130 Valid. err. 1.63934
2018-02-03 23:43:44,067 training [INFO ] Epoch 46 Batch 9380 Training err. 1.46973 Training err. RA 1.75070 Valid. err. 1.64467
2018-02-03 23:43:44,542 training [INFO ] Epoch 46 Batch 9400 Training err. 1.43244 Training err. RA 1.75002 Valid. err. 1.65835
2018-02-03 23:43:45,025 training [INFO ] Epoch 46 Batch 9420 Training err. 1.51361 Training err. RA 1.74952 Valid. err. 1.67534
2018-02-03 23:43:45,504 training [INFO ] Epoch 46 Batch 9440 Training err. 1.52675 Training err. RA 1.74905 Valid. err. 1.69405
2018-02-03 23:43:45,984 training [INFO ] Epoch 46 Batch 9460 Training err. 1.46051 Training err. RA 1.74844 Valid. err. 1.66917
2018-02-03 23:43:46,463 training [INFO ] Epoch 46 Batch 9480 Training err. 1.51980 Training err. RA 1.74796 Valid. err. 1.64676
2018-02-03 23:43:46,939 training [INFO ] Epoch 46 Batch 9500 Training err. 1.50545 Training err. RA 1.74745 Valid. err. 1.64866
2018-02-03 23:43:47,417 training [INFO ] Epoch 46 Batch 9520 Training err. 1.46087 Training err. RA 1.74684 Valid. err. 1.66999
2018-02-03 23:43:47,898 training [INFO ] Epoch 46 Batch 9540 Training err. 1.45660 Training err. RA 1.74624 Valid. err. 1.65100
2018-02-03 23:43:48,383 training [INFO ] Epoch 46 Batch 9560 Training err. 1.48264 Training err. RA 1.74568 Valid. err. 1.65157
2018-02-03 23:43:49,257 training [INFO ] Epoch 47 Batch 9580 Training err. 1.46038 Training err. RA 1.74509 Valid. err. 1.63406
2018-02-03 23:43:49,741 training [INFO ] Epoch 47 Batch 9600 Training err. 1.42939 Training err. RA 1.74443 Valid. err. 1.66296
2018-02-03 23:43:50,221 training [INFO ] Epoch 47 Batch 9620 Training err. 1.50363 Training err. RA 1.74393 Valid. err. 1.65042
2018-02-03 23:43:50,703 training [INFO ] Epoch 47 Batch 9640 Training err. 1.51612 Training err. RA 1.74346 Valid. err. 1.66608
2018-02-03 23:43:51,189 training [INFO ] Epoch 47 Batch 9660 Training err. 1.45935 Training err. RA 1.74287 Valid. err. 1.68204
2018-02-03 23:43:51,666 training [INFO ] Epoch 47 Batch 9680 Training err. 1.48866 Training err. RA 1.74234 Valid. err. 1.64151
2018-02-03 23:43:52,147 training [INFO ] Epoch 47 Batch 9700 Training err. 1.52420 Training err. RA 1.74189 Valid. err. 1.68587
2018-02-03 23:43:52,618 training [INFO ] Epoch 47 Batch 9720 Training err. 1.47226 Training err. RA 1.74134 Valid. err. 1.66630
2018-02-03 23:43:53,095 training [INFO ] Epoch 47 Batch 9740 Training err. 1.45829 Training err. RA 1.74076 Valid. err. 1.63990
2018-02-03 23:43:53,573 training [INFO ] Epoch 47 Batch 9760 Training err. 1.46248 Training err. RA 1.74019 Valid. err. 1.65454
2018-02-03 23:43:54,431 training [INFO ] Epoch 48 Batch 9780 Training err. 1.45767 Training err. RA 1.73961 Valid. err. 1.63808
2018-02-03 23:43:54,906 training [INFO ] Epoch 48 Batch 9800 Training err. 1.44952 Training err. RA 1.73902 Valid. err. 1.63709
2018-02-03 23:43:55,392 training [INFO ] Epoch 48 Batch 9820 Training err. 1.46732 Training err. RA 1.73847 Valid. err. 1.64770
2018-02-03 23:43:55,870 training [INFO ] Epoch 48 Batch 9840 Training err. 1.49732 Training err. RA 1.73798 Valid. err. 1.67237
2018-02-03 23:43:56,344 training [INFO ] Epoch 48 Batch 9860 Training err. 1.49659 Training err. RA 1.73749 Valid. err. 1.68987
2018-02-03 23:43:56,823 training [INFO ] Epoch 48 Batch 9880 Training err. 1.47240 Training err. RA 1.73695 Valid. err. 1.64870
2018-02-03 23:43:57,306 training [INFO ] Epoch 48 Batch 9900 Training err. 1.52812 Training err. RA 1.73653 Valid. err. 1.67151
2018-02-03 23:43:57,786 training [INFO ] Epoch 48 Batch 9920 Training err. 1.46451 Training err. RA 1.73598 Valid. err. 1.66337
2018-02-03 23:43:58,267 training [INFO ] Epoch 48 Batch 9940 Training err. 1.45126 Training err. RA 1.73541 Valid. err. 1.65755
2018-02-03 23:43:58,744 training [INFO ] Epoch 48 Batch 9960 Training err. 1.43992 Training err. RA 1.73481 Valid. err. 1.63935
2018-02-03 23:43:59,218 training [INFO ] Epoch 48 Batch 9980 Training err. 1.48232 Training err. RA 1.73431 Valid. err. 1.63793
2018-02-03 23:44:00,087 training [INFO ] Epoch 49 Batch10000 Training err. 1.44219 Training err. RA 1.73372 Valid. err. 1.63663
2018-02-03 23:44:00,564 training [INFO ] Epoch 49 Batch10020 Training err. 1.42191 Training err. RA 1.73310 Valid. err. 1.63675
2018-02-03 23:44:01,040 training [INFO ] Epoch 49 Batch10040 Training err. 1.48648 Training err. RA 1.73261 Valid. err. 1.67894
2018-02-03 23:44:01,517 training [INFO ] Epoch 49 Batch10060 Training err. 1.50789 Training err. RA 1.73216 Valid. err. 1.64015
2018-02-03 23:44:01,990 training [INFO ] Epoch 49 Batch10080 Training err. 1.44695 Training err. RA 1.73160 Valid. err. 1.67023
2018-02-03 23:44:02,464 training [INFO ] Epoch 49 Batch10100 Training err. 1.50698 Training err. RA 1.73115 Valid. err. 1.64752
2018-02-03 23:44:02,938 training [INFO ] Epoch 49 Batch10120 Training err. 1.49403 Training err. RA 1.73068 Valid. err. 1.64815
2018-02-03 23:44:03,415 training [INFO ] Epoch 49 Batch10140 Training err. 1.45530 Training err. RA 1.73014 Valid. err. 1.68248
2018-02-03 23:44:03,889 training [INFO ] Epoch 49 Batch10160 Training err. 1.45299 Training err. RA 1.72959 Valid. err. 1.63989
2018-02-03 23:44:04,363 training [INFO ] Epoch 49 Batch10180 Training err. 1.45861 Training err. RA 1.72906 Valid. err. 1.65309
2018-02-03 23:44:05,209 training [INFO ] Epoch 50 Batch10200 Training err. 1.43983 Training err. RA 1.72849 Valid. err. 1.63111
2018-02-03 23:44:05,681 training [INFO ] Epoch 50 Batch10220 Training err. 1.42485 Training err. RA 1.72790 Valid. err. 1.64219
2018-02-03 23:44:06,166 training [INFO ] Epoch 50 Batch10240 Training err. 1.48653 Training err. RA 1.72743 Valid. err. 1.64269
2018-02-03 23:44:06,641 training [INFO ] Epoch 50 Batch10260 Training err. 1.49693 Training err. RA 1.72698 Valid. err. 1.63347
2018-02-03 23:44:07,123 training [INFO ] Epoch 50 Batch10280 Training err. 1.45425 Training err. RA 1.72645 Valid. err. 1.67145
2018-02-03 23:44:07,600 training [INFO ] Epoch 50 Batch10300 Training err. 1.46232 Training err. RA 1.72594 Valid. err. 1.67462
2018-02-03 23:44:08,080 training [INFO ] Epoch 50 Batch10320 Training err. 1.51934 Training err. RA 1.72554 Valid. err. 1.66014
2018-02-03 23:44:08,562 training [INFO ] Epoch 50 Batch10340 Training err. 1.46541 Training err. RA 1.72503 Valid. err. 1.68550
2018-02-03 23:44:09,049 training [INFO ] Epoch 50 Batch10360 Training err. 1.43121 Training err. RA 1.72447 Valid. err. 1.66089
2018-02-03 23:44:09,535 training [INFO ] Epoch 50 Batch10380 Training err. 1.44409 Training err. RA 1.72392 Valid. err. 1.63837
2018-02-03 23:44:10,018 training [INFO ] Epoch 50 Batch10400 Training err. 1.45433 Training err. RA 1.72341 Valid. err. 1.62653
2018-02-03 23:44:10,900 training [INFO ] Epoch 51 Batch10420 Training err. 1.44540 Training err. RA 1.72287 Valid. err. 1.63256
2018-02-03 23:44:11,373 training [INFO ] Epoch 51 Batch10440 Training err. 1.40737 Training err. RA 1.72227 Valid. err. 1.64902
2018-02-03 23:44:11,845 training [INFO ] Epoch 51 Batch10460 Training err. 1.48831 Training err. RA 1.72182 Valid. err. 1.66586
2018-02-03 23:44:12,322 training [INFO ] Epoch 51 Batch10480 Training err. 1.50563 Training err. RA 1.72141 Valid. err. 1.67054
2018-02-03 23:44:12,795 training [INFO ] Epoch 51 Batch10500 Training err. 1.43301 Training err. RA 1.72086 Valid. err. 1.64399
2018-02-03 23:44:13,276 training [INFO ] Epoch 51 Batch10520 Training err. 1.50789 Training err. RA 1.72045 Valid. err. 1.64649
2018-02-03 23:44:13,748 training [INFO ] Epoch 51 Batch10540 Training err. 1.48491 Training err. RA 1.72001 Valid. err. 1.64377
2018-02-03 23:44:14,222 training [INFO ] Epoch 51 Batch10560 Training err. 1.44394 Training err. RA 1.71948 Valid. err. 1.66403
2018-02-03 23:44:14,696 training [INFO ] Epoch 51 Batch10580 Training err. 1.42751 Training err. RA 1.71893 Valid. err. 1.63292
2018-02-03 23:44:15,177 training [INFO ] Epoch 51 Batch10600 Training err. 1.45985 Training err. RA 1.71844 Valid. err. 1.62944
2018-02-03 23:44:16,064 training [INFO ] Epoch 52 Batch10620 Training err. 1.43422 Training err. RA 1.71791 Valid. err. 1.62076
2018-02-03 23:44:16,546 training [INFO ] Epoch 52 Batch10640 Training err. 1.40762 Training err. RA 1.71733 Valid. err. 1.65104
2018-02-03 23:44:17,026 training [INFO ] Epoch 52 Batch10660 Training err. 1.48231 Training err. RA 1.71688 Valid. err. 1.64299
2018-02-03 23:44:17,505 training [INFO ] Epoch 52 Batch10680 Training err. 1.48756 Training err. RA 1.71645 Valid. err. 1.64686
2018-02-03 23:44:17,989 training [INFO ] Epoch 52 Batch10700 Training err. 1.43312 Training err. RA 1.71593 Valid. err. 1.65577
2018-02-03 23:44:18,468 training [INFO ] Epoch 52 Batch10720 Training err. 1.46864 Training err. RA 1.71546 Valid. err. 1.62796
2018-02-03 23:44:18,948 training [INFO ] Epoch 52 Batch10740 Training err. 1.49839 Training err. RA 1.71506 Valid. err. 1.65605
2018-02-03 23:44:19,422 training [INFO ] Epoch 52 Batch10760 Training err. 1.44437 Training err. RA 1.71456 Valid. err. 1.65874
2018-02-03 23:44:19,900 training [INFO ] Epoch 52 Batch10780 Training err. 1.44653 Training err. RA 1.71406 Valid. err. 1.62934
2018-02-03 23:44:20,373 training [INFO ] Epoch 52 Batch10800 Training err. 1.51698 Training err. RA 1.71369 Valid. err. 1.63784
2018-02-03 23:44:21,232 training [INFO ] Epoch 53 Batch10820 Training err. 1.45792 Training err. RA 1.71322 Valid. err. 1.62266
2018-02-03 23:44:21,706 training [INFO ] Epoch 53 Batch10840 Training err. 1.44221 Training err. RA 1.71272 Valid. err. 1.61567
2018-02-03 23:44:22,184 training [INFO ] Epoch 53 Batch10860 Training err. 1.44797 Training err. RA 1.71223 Valid. err. 1.65142
2018-02-03 23:44:22,660 training [INFO ] Epoch 53 Batch10880 Training err. 1.49010 Training err. RA 1.71183 Valid. err. 1.67892
2018-02-03 23:44:23,131 training [INFO ] Epoch 53 Batch10900 Training err. 1.47357 Training err. RA 1.71139 Valid. err. 1.64559
2018-02-03 23:44:23,608 training [INFO ] Epoch 53 Batch10920 Training err. 1.44620 Training err. RA 1.71090 Valid. err. 1.62307
2018-02-03 23:44:24,085 training [INFO ] Epoch 53 Batch10940 Training err. 1.50715 Training err. RA 1.71053 Valid. err. 1.65309
2018-02-03 23:44:24,562 training [INFO ] Epoch 53 Batch10960 Training err. 1.44352 Training err. RA 1.71004 Valid. err. 1.63277
2018-02-03 23:44:25,040 training [INFO ] Epoch 53 Batch10980 Training err. 1.42752 Training err. RA 1.70953 Valid. err. 1.65098
2018-02-03 23:44:25,513 training [INFO ] Epoch 53 Batch11000 Training err. 1.41891 Training err. RA 1.70900 Valid. err. 1.62744
2018-02-03 23:44:25,991 training [INFO ] Epoch 53 Batch11020 Training err. 1.46651 Training err. RA 1.70856 Valid. err. 1.60759
2018-02-03 23:44:26,835 training [INFO ] Epoch 54 Batch11040 Training err. 1.41674 Training err. RA 1.70803 Valid. err. 1.61939
2018-02-03 23:44:27,318 training [INFO ] Epoch 54 Batch11060 Training err. 1.40554 Training err. RA 1.70748 Valid. err. 1.62437
2018-02-03 23:44:27,790 training [INFO ] Epoch 54 Batch11080 Training err. 1.46679 Training err. RA 1.70705 Valid. err. 1.66056
2018-02-03 23:44:28,267 training [INFO ] Epoch 54 Batch11100 Training err. 1.48837 Training err. RA 1.70666 Valid. err. 1.64144
2018-02-03 23:44:28,743 training [INFO ] Epoch 54 Batch11120 Training err. 1.43010 Training err. RA 1.70616 Valid. err. 1.66277
2018-02-03 23:44:29,216 training [INFO ] Epoch 54 Batch11140 Training err. 1.48796 Training err. RA 1.70577 Valid. err. 1.63844
2018-02-03 23:44:29,691 training [INFO ] Epoch 54 Batch11160 Training err. 1.46922 Training err. RA 1.70534 Valid. err. 1.64054
2018-02-03 23:44:30,167 training [INFO ] Epoch 54 Batch11180 Training err. 1.43648 Training err. RA 1.70486 Valid. err. 1.66000
2018-02-03 23:44:30,639 training [INFO ] Epoch 54 Batch11200 Training err. 1.46643 Training err. RA 1.70444 Valid. err. 1.63343
2018-02-03 23:44:31,119 training [INFO ] Epoch 54 Batch11220 Training err. 1.44881 Training err. RA 1.70398 Valid. err. 1.62443
2018-02-03 23:44:31,991 training [INFO ] Epoch 55 Batch11240 Training err. 1.42085 Training err. RA 1.70348 Valid. err. 1.61116
2018-02-03 23:44:32,468 training [INFO ] Epoch 55 Batch11260 Training err. 1.40604 Training err. RA 1.70295 Valid. err. 1.62902
2018-02-03 23:44:32,950 training [INFO ] Epoch 55 Batch11280 Training err. 1.46750 Training err. RA 1.70253 Valid. err. 1.63266
2018-02-03 23:44:33,429 training [INFO ] Epoch 55 Batch11300 Training err. 1.47675 Training err. RA 1.70213 Valid. err. 1.61455
2018-02-03 23:44:33,905 training [INFO ] Epoch 55 Batch11320 Training err. 1.43748 Training err. RA 1.70166 Valid. err. 1.66682
2018-02-03 23:44:34,388 training [INFO ] Epoch 55 Batch11340 Training err. 1.45080 Training err. RA 1.70122 Valid. err. 1.63649
2018-02-03 23:44:34,863 training [INFO ] Epoch 55 Batch11360 Training err. 1.51809 Training err. RA 1.70090 Valid. err. 1.63080
2018-02-03 23:44:35,340 training [INFO ] Epoch 55 Batch11380 Training err. 1.45658 Training err. RA 1.70047 Valid. err. 1.65166
2018-02-03 23:44:35,815 training [INFO ] Epoch 55 Batch11400 Training err. 1.41342 Training err. RA 1.69997 Valid. err. 1.65815
2018-02-03 23:44:36,296 training [INFO ] Epoch 55 Batch11420 Training err. 1.42463 Training err. RA 1.69948 Valid. err. 1.62360
2018-02-03 23:44:36,769 training [INFO ] Epoch 55 Batch11440 Training err. 1.44097 Training err. RA 1.69903 Valid. err. 1.61557
2018-02-03 23:44:37,624 training [INFO ] Epoch 56 Batch11460 Training err. 1.43196 Training err. RA 1.69857 Valid. err. 1.61665
2018-02-03 23:44:38,099 training [INFO ] Epoch 56 Batch11480 Training err. 1.39494 Training err. RA 1.69804 Valid. err. 1.63012
2018-02-03 23:44:38,574 training [INFO ] Epoch 56 Batch11500 Training err. 1.46319 Training err. RA 1.69763 Valid. err. 1.64693
2018-02-03 23:44:39,053 training [INFO ] Epoch 56 Batch11520 Training err. 1.47767 Training err. RA 1.69725 Valid. err. 1.68111
2018-02-03 23:44:39,527 training [INFO ] Epoch 56 Batch11540 Training err. 1.42755 Training err. RA 1.69678 Valid. err. 1.64073
2018-02-03 23:44:40,012 training [INFO ] Epoch 56 Batch11560 Training err. 1.47802 Training err. RA 1.69640 Valid. err. 1.63263
2018-02-03 23:44:40,490 training [INFO ] Epoch 56 Batch11580 Training err. 1.45650 Training err. RA 1.69599 Valid. err. 1.61809
2018-02-03 23:44:40,972 training [INFO ] Epoch 56 Batch11600 Training err. 1.42349 Training err. RA 1.69552 Valid. err. 1.64532
2018-02-03 23:44:41,451 training [INFO ] Epoch 56 Batch11620 Training err. 1.40918 Training err. RA 1.69502 Valid. err. 1.62495
2018-02-03 23:44:41,930 training [INFO ] Epoch 56 Batch11640 Training err. 1.44479 Training err. RA 1.69459 Valid. err. 1.60755
2018-02-03 23:44:42,852 training [INFO ] Epoch 57 Batch11660 Training err. 1.41995 Training err. RA 1.69412 Valid. err. 1.61271
2018-02-03 23:44:43,335 training [INFO ] Epoch 57 Batch11680 Training err. 1.39389 Training err. RA 1.69361 Valid. err. 1.64777
2018-02-03 23:44:43,808 training [INFO ] Epoch 57 Batch11700 Training err. 1.46615 Training err. RA 1.69322 Valid. err. 1.64834
2018-02-03 23:44:44,280 training [INFO ] Epoch 57 Batch11720 Training err. 1.47471 Training err. RA 1.69285 Valid. err. 1.64740
2018-02-03 23:44:44,768 training [INFO ] Epoch 57 Batch11740 Training err. 1.41467 Training err. RA 1.69237 Valid. err. 1.63749
2018-02-03 23:44:45,250 training [INFO ] Epoch 57 Batch11760 Training err. 1.44826 Training err. RA 1.69196 Valid. err. 1.61678
2018-02-03 23:44:45,739 training [INFO ] Epoch 57 Batch11780 Training err. 1.48208 Training err. RA 1.69160 Valid. err. 1.65499
2018-02-03 23:44:46,225 training [INFO ] Epoch 57 Batch11800 Training err. 1.42236 Training err. RA 1.69114 Valid. err. 1.65332
2018-02-03 23:44:46,712 training [INFO ] Epoch 57 Batch11820 Training err. 1.44307 Training err. RA 1.69073 Valid. err. 1.62837
2018-02-03 23:44:47,199 training [INFO ] Epoch 57 Batch11840 Training err. 1.42893 Training err. RA 1.69028 Valid. err. 1.66982
2018-02-03 23:44:48,092 training [INFO ] Epoch 58 Batch11860 Training err. 1.43725 Training err. RA 1.68986 Valid. err. 1.61353
2018-02-03 23:44:48,579 training [INFO ] Epoch 58 Batch11880 Training err. 1.41305 Training err. RA 1.68939 Valid. err. 1.62420
2018-02-03 23:44:49,076 training [INFO ] Epoch 58 Batch11900 Training err. 1.42292 Training err. RA 1.68894 Valid. err. 1.62199
2018-02-03 23:44:49,552 training [INFO ] Epoch 58 Batch11920 Training err. 1.45334 Training err. RA 1.68855 Valid. err. 1.64178
2018-02-03 23:44:50,031 training [INFO ] Epoch 58 Batch11940 Training err. 1.44718 Training err. RA 1.68814 Valid. err. 1.64789
2018-02-03 23:44:50,510 training [INFO ] Epoch 58 Batch11960 Training err. 1.42749 Training err. RA 1.68771 Valid. err. 1.62172
2018-02-03 23:44:50,994 training [INFO ] Epoch 58 Batch11980 Training err. 1.47993 Training err. RA 1.68736 Valid. err. 1.64885
2018-02-03 23:44:51,470 training [INFO ] Epoch 58 Batch12000 Training err. 1.42424 Training err. RA 1.68692 Valid. err. 1.63257
2018-02-03 23:44:51,943 training [INFO ] Epoch 58 Batch12020 Training err. 1.40947 Training err. RA 1.68646 Valid. err. 1.64070
2018-02-03 23:44:52,421 training [INFO ] Epoch 58 Batch12040 Training err. 1.39828 Training err. RA 1.68598 Valid. err. 1.61536
2018-02-03 23:44:52,891 training [INFO ] Epoch 58 Batch12060 Training err. 1.44576 Training err. RA 1.68558 Valid. err. 1.59830
2018-02-03 23:44:53,757 training [INFO ] Epoch 59 Batch12080 Training err. 1.40193 Training err. RA 1.68511 Valid. err. 1.61096
2018-02-03 23:44:54,237 training [INFO ] Epoch 59 Batch12100 Training err. 1.39241 Training err. RA 1.68463 Valid. err. 1.63358
2018-02-03 23:44:54,715 training [INFO ] Epoch 59 Batch12120 Training err. 1.45155 Training err. RA 1.68424 Valid. err. 1.65836
2018-02-03 23:44:55,192 training [INFO ] Epoch 59 Batch12140 Training err. 1.47567 Training err. RA 1.68390 Valid. err. 1.63991
2018-02-03 23:44:55,690 training [INFO ] Epoch 59 Batch12160 Training err. 1.41122 Training err. RA 1.68345 Valid. err. 1.68193
2018-02-03 23:44:56,166 training [INFO ] Epoch 59 Batch12180 Training err. 1.47912 Training err. RA 1.68312 Valid. err. 1.62928
2018-02-03 23:44:56,644 training [INFO ] Epoch 59 Batch12200 Training err. 1.45340 Training err. RA 1.68274 Valid. err. 1.63122
2018-02-03 23:44:57,130 training [INFO ] Epoch 59 Batch12220 Training err. 1.40591 Training err. RA 1.68229 Valid. err. 1.65002
2018-02-03 23:44:57,606 training [INFO ] Epoch 59 Batch12240 Training err. 1.41354 Training err. RA 1.68185 Valid. err. 1.61585
2018-02-03 23:44:58,095 training [INFO ] Epoch 59 Batch12260 Training err. 1.42162 Training err. RA 1.68142 Valid. err. 1.62837
2018-02-03 23:44:58,967 training [INFO ] Epoch 60 Batch12280 Training err. 1.42571 Training err. RA 1.68101 Valid. err. 1.60041
2018-02-03 23:44:59,443 training [INFO ] Epoch 60 Batch12300 Training err. 1.39348 Training err. RA 1.68054 Valid. err. 1.65400
2018-02-03 23:44:59,913 training [INFO ] Epoch 60 Batch12320 Training err. 1.44420 Training err. RA 1.68016 Valid. err. 1.61201
2018-02-03 23:45:00,397 training [INFO ] Epoch 60 Batch12340 Training err. 1.45945 Training err. RA 1.67980 Valid. err. 1.61903
2018-02-03 23:45:00,872 training [INFO ] Epoch 60 Batch12360 Training err. 1.41287 Training err. RA 1.67937 Valid. err. 1.62852
2018-02-03 23:45:01,350 training [INFO ] Epoch 60 Batch12380 Training err. 1.43567 Training err. RA 1.67897 Valid. err. 1.62584
2018-02-03 23:45:01,826 training [INFO ] Epoch 60 Batch12400 Training err. 1.47558 Training err. RA 1.67864 Valid. err. 1.62811
2018-02-03 23:45:02,299 training [INFO ] Epoch 60 Batch12420 Training err. 1.42720 Training err. RA 1.67824 Valid. err. 1.65542
2018-02-03 23:45:02,774 training [INFO ] Epoch 60 Batch12440 Training err. 1.39207 Training err. RA 1.67778 Valid. err. 1.63903
2018-02-03 23:45:03,255 training [INFO ] Epoch 60 Batch12460 Training err. 1.39982 Training err. RA 1.67733 Valid. err. 1.61909
2018-02-03 23:45:03,732 training [INFO ] Epoch 60 Batch12480 Training err. 1.42668 Training err. RA 1.67693 Valid. err. 1.60669
2018-02-03 23:45:04,010 __main__ [INFO ] End of training
2018-02-03 23:45:04,263 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 10,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 23:45:04,263 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 23:45:04,970 training [INFO ] Epoch  1 Batch   20 Training err. 4.24151 Training err. RA 4.24151 Valid. err. 4.16857
2018-02-03 23:45:05,480 training [INFO ] Epoch  1 Batch   40 Training err. 4.07570 Training err. RA 4.15861 Valid. err. 4.01682
2018-02-03 23:45:05,993 training [INFO ] Epoch  1 Batch   60 Training err. 3.92384 Training err. RA 4.08035 Valid. err. 3.85700
2018-02-03 23:45:06,507 training [INFO ] Epoch  1 Batch   80 Training err. 3.77625 Training err. RA 4.00433 Valid. err. 3.70086
2018-02-03 23:45:07,026 training [INFO ] Epoch  1 Batch  100 Training err. 3.61321 Training err. RA 3.92610 Valid. err. 3.56961
2018-02-03 23:45:07,866 training [INFO ] Epoch  2 Batch  120 Training err. 3.48513 Training err. RA 3.85261 Valid. err. 3.46413
2018-02-03 23:45:08,363 training [INFO ] Epoch  2 Batch  140 Training err. 3.35223 Training err. RA 3.78112 Valid. err. 3.38368
2018-02-03 23:45:08,865 training [INFO ] Epoch  2 Batch  160 Training err. 3.31376 Training err. RA 3.72270 Valid. err. 3.31855
2018-02-03 23:45:09,365 training [INFO ] Epoch  2 Batch  180 Training err. 3.26718 Training err. RA 3.67209 Valid. err. 3.28047
2018-02-03 23:45:09,870 training [INFO ] Epoch  2 Batch  200 Training err. 3.23559 Training err. RA 3.62844 Valid. err. 3.25646
2018-02-03 23:45:10,726 training [INFO ] Epoch  3 Batch  220 Training err. 3.22615 Training err. RA 3.59187 Valid. err. 3.24062
2018-02-03 23:45:11,230 training [INFO ] Epoch  3 Batch  240 Training err. 3.15460 Training err. RA 3.55543 Valid. err. 3.23669
2018-02-03 23:45:11,730 training [INFO ] Epoch  3 Batch  260 Training err. 3.18947 Training err. RA 3.52728 Valid. err. 3.21821
2018-02-03 23:45:12,237 training [INFO ] Epoch  3 Batch  280 Training err. 3.16403 Training err. RA 3.50133 Valid. err. 3.21077
2018-02-03 23:45:12,736 training [INFO ] Epoch  3 Batch  300 Training err. 3.16789 Training err. RA 3.47910 Valid. err. 3.20573
2018-02-03 23:45:13,592 training [INFO ] Epoch  4 Batch  320 Training err. 3.18312 Training err. RA 3.46060 Valid. err. 3.20006
2018-02-03 23:45:14,092 training [INFO ] Epoch  4 Batch  340 Training err. 3.13096 Training err. RA 3.44121 Valid. err. 3.20283
2018-02-03 23:45:14,591 training [INFO ] Epoch  4 Batch  360 Training err. 3.15145 Training err. RA 3.42512 Valid. err. 3.19408
2018-02-03 23:45:15,096 training [INFO ] Epoch  4 Batch  380 Training err. 3.13492 Training err. RA 3.40984 Valid. err. 3.19133
2018-02-03 23:45:15,612 training [INFO ] Epoch  4 Batch  400 Training err. 3.14363 Training err. RA 3.39653 Valid. err. 3.19016
2018-02-03 23:45:16,499 training [INFO ] Epoch  5 Batch  420 Training err. 3.16916 Training err. RA 3.38570 Valid. err. 3.18941
2018-02-03 23:45:17,010 training [INFO ] Epoch  5 Batch  440 Training err. 3.13738 Training err. RA 3.37442 Valid. err. 3.18938
2018-02-03 23:45:17,526 training [INFO ] Epoch  5 Batch  460 Training err. 3.12894 Training err. RA 3.36374 Valid. err. 3.18500
2018-02-03 23:45:18,046 training [INFO ] Epoch  5 Batch  480 Training err. 3.11089 Training err. RA 3.35321 Valid. err. 3.18438
2018-02-03 23:45:18,562 training [INFO ] Epoch  5 Batch  500 Training err. 3.14414 Training err. RA 3.34485 Valid. err. 3.18424
2018-02-03 23:45:19,079 training [INFO ] Epoch  5 Batch  520 Training err. 3.16339 Training err. RA 3.33787 Valid. err. 3.18142
2018-02-03 23:45:19,922 training [INFO ] Epoch  6 Batch  540 Training err. 3.13903 Training err. RA 3.33050 Valid. err. 3.18198
2018-02-03 23:45:20,420 training [INFO ] Epoch  6 Batch  560 Training err. 3.11386 Training err. RA 3.32276 Valid. err. 3.18193
2018-02-03 23:45:20,921 training [INFO ] Epoch  6 Batch  580 Training err. 3.09968 Training err. RA 3.31507 Valid. err. 3.18257
2018-02-03 23:45:21,416 training [INFO ] Epoch  6 Batch  600 Training err. 3.14843 Training err. RA 3.30952 Valid. err. 3.17975
2018-02-03 23:45:21,912 training [INFO ] Epoch  6 Batch  620 Training err. 3.14655 Training err. RA 3.30426 Valid. err. 3.17850
2018-02-03 23:45:22,760 training [INFO ] Epoch  7 Batch  640 Training err. 3.14874 Training err. RA 3.29940 Valid. err. 3.17866
2018-02-03 23:45:23,256 training [INFO ] Epoch  7 Batch  660 Training err. 3.10093 Training err. RA 3.29339 Valid. err. 3.17988
2018-02-03 23:45:23,755 training [INFO ] Epoch  7 Batch  680 Training err. 3.11558 Training err. RA 3.28816 Valid. err. 3.17848
2018-02-03 23:45:24,272 training [INFO ] Epoch  7 Batch  700 Training err. 3.13240 Training err. RA 3.28371 Valid. err. 3.17732
2018-02-03 23:45:24,781 training [INFO ] Epoch  7 Batch  720 Training err. 3.13492 Training err. RA 3.27957 Valid. err. 3.17677
2018-02-03 23:45:25,666 training [INFO ] Epoch  8 Batch  740 Training err. 3.15492 Training err. RA 3.27620 Valid. err. 3.17684
2018-02-03 23:45:26,181 training [INFO ] Epoch  8 Batch  760 Training err. 3.09017 Training err. RA 3.27131 Valid. err. 3.18703
2018-02-03 23:45:26,698 training [INFO ] Epoch  8 Batch  780 Training err. 3.13137 Training err. RA 3.26772 Valid. err. 3.17575
2018-02-03 23:45:27,218 training [INFO ] Epoch  8 Batch  800 Training err. 3.11806 Training err. RA 3.26398 Valid. err. 3.17517
2018-02-03 23:45:27,721 training [INFO ] Epoch  8 Batch  820 Training err. 3.13017 Training err. RA 3.26072 Valid. err. 3.17572
2018-02-03 23:45:28,582 training [INFO ] Epoch  9 Batch  840 Training err. 3.15280 Training err. RA 3.25815 Valid. err. 3.17307
2018-02-03 23:45:29,083 training [INFO ] Epoch  9 Batch  860 Training err. 3.10277 Training err. RA 3.25453 Valid. err. 3.18054
2018-02-03 23:45:29,588 training [INFO ] Epoch  9 Batch  880 Training err. 3.12387 Training err. RA 3.25156 Valid. err. 3.17329
2018-02-03 23:45:30,100 training [INFO ] Epoch  9 Batch  900 Training err. 3.10945 Training err. RA 3.24841 Valid. err. 3.17271
2018-02-03 23:45:30,601 training [INFO ] Epoch  9 Batch  920 Training err. 3.12270 Training err. RA 3.24567 Valid. err. 3.17300
2018-02-03 23:45:31,452 training [INFO ] Epoch 10 Batch  940 Training err. 3.15039 Training err. RA 3.24364 Valid. err. 3.17345
2018-02-03 23:45:31,957 training [INFO ] Epoch 10 Batch  960 Training err. 3.11897 Training err. RA 3.24105 Valid. err. 3.17499
2018-02-03 23:45:32,454 training [INFO ] Epoch 10 Batch  980 Training err. 3.11090 Training err. RA 3.23839 Valid. err. 3.17046
2018-02-03 23:45:32,959 training [INFO ] Epoch 10 Batch 1000 Training err. 3.09317 Training err. RA 3.23549 Valid. err. 3.17043
2018-02-03 23:45:33,453 training [INFO ] Epoch 10 Batch 1020 Training err. 3.12758 Training err. RA 3.23337 Valid. err. 3.17089
2018-02-03 23:45:33,960 training [INFO ] Epoch 10 Batch 1040 Training err. 3.14711 Training err. RA 3.23171 Valid. err. 3.16812
2018-02-03 23:45:34,809 training [INFO ] Epoch 11 Batch 1060 Training err. 3.12462 Training err. RA 3.22969 Valid. err. 3.16883
2018-02-03 23:45:35,313 training [INFO ] Epoch 11 Batch 1080 Training err. 3.09895 Training err. RA 3.22727 Valid. err. 3.16889
2018-02-03 23:45:35,827 training [INFO ] Epoch 11 Batch 1100 Training err. 3.08410 Training err. RA 3.22467 Valid. err. 3.16971
2018-02-03 23:45:36,350 training [INFO ] Epoch 11 Batch 1120 Training err. 3.13282 Training err. RA 3.22303 Valid. err. 3.16668
2018-02-03 23:45:36,866 training [INFO ] Epoch 11 Batch 1140 Training err. 3.13163 Training err. RA 3.22142 Valid. err. 3.16525
2018-02-03 23:45:37,742 training [INFO ] Epoch 12 Batch 1160 Training err. 3.13455 Training err. RA 3.21993 Valid. err. 3.16518
2018-02-03 23:45:38,255 training [INFO ] Epoch 12 Batch 1180 Training err. 3.08672 Training err. RA 3.21767 Valid. err. 3.16606
2018-02-03 23:45:38,769 training [INFO ] Epoch 12 Batch 1200 Training err. 3.09952 Training err. RA 3.21570 Valid. err. 3.16467
2018-02-03 23:45:39,287 training [INFO ] Epoch 12 Batch 1220 Training err. 3.11749 Training err. RA 3.21409 Valid. err. 3.16315
2018-02-03 23:45:39,787 training [INFO ] Epoch 12 Batch 1240 Training err. 3.11936 Training err. RA 3.21256 Valid. err. 3.16211
2018-02-03 23:45:40,651 training [INFO ] Epoch 13 Batch 1260 Training err. 3.13963 Training err. RA 3.21140 Valid. err. 3.16218
2018-02-03 23:45:41,154 training [INFO ] Epoch 13 Batch 1280 Training err. 3.07543 Training err. RA 3.20928 Valid. err. 3.17213
2018-02-03 23:45:41,658 training [INFO ] Epoch 13 Batch 1300 Training err. 3.11401 Training err. RA 3.20781 Valid. err. 3.16008
2018-02-03 23:45:42,163 training [INFO ] Epoch 13 Batch 1320 Training err. 3.10190 Training err. RA 3.20621 Valid. err. 3.15897
2018-02-03 23:45:42,665 training [INFO ] Epoch 13 Batch 1340 Training err. 3.11261 Training err. RA 3.20481 Valid. err. 3.15903
2018-02-03 23:45:43,525 training [INFO ] Epoch 14 Batch 1360 Training err. 3.13546 Training err. RA 3.20379 Valid. err. 3.15567
2018-02-03 23:45:44,042 training [INFO ] Epoch 14 Batch 1380 Training err. 3.08597 Training err. RA 3.20208 Valid. err. 3.16303
2018-02-03 23:45:44,549 training [INFO ] Epoch 14 Batch 1400 Training err. 3.10568 Training err. RA 3.20071 Valid. err. 3.15488
2018-02-03 23:45:45,066 training [INFO ] Epoch 14 Batch 1420 Training err. 3.09043 Training err. RA 3.19915 Valid. err. 3.15364
2018-02-03 23:45:45,575 training [INFO ] Epoch 14 Batch 1440 Training err. 3.10278 Training err. RA 3.19782 Valid. err. 3.15302
2018-02-03 23:45:46,458 training [INFO ] Epoch 15 Batch 1460 Training err. 3.13053 Training err. RA 3.19689 Valid. err. 3.15310
2018-02-03 23:45:46,969 training [INFO ] Epoch 15 Batch 1480 Training err. 3.09817 Training err. RA 3.19556 Valid. err. 3.15452
2018-02-03 23:45:47,476 training [INFO ] Epoch 15 Batch 1500 Training err. 3.09095 Training err. RA 3.19416 Valid. err. 3.14818
2018-02-03 23:45:47,971 training [INFO ] Epoch 15 Batch 1520 Training err. 3.07061 Training err. RA 3.19254 Valid. err. 3.14704
2018-02-03 23:45:48,467 training [INFO ] Epoch 15 Batch 1540 Training err. 3.10392 Training err. RA 3.19139 Valid. err. 3.14672
2018-02-03 23:45:48,972 training [INFO ] Epoch 15 Batch 1560 Training err. 3.12258 Training err. RA 3.19051 Valid. err. 3.14270
2018-02-03 23:45:49,822 training [INFO ] Epoch 16 Batch 1580 Training err. 3.09965 Training err. RA 3.18936 Valid. err. 3.14213
2018-02-03 23:45:50,324 training [INFO ] Epoch 16 Batch 1600 Training err. 3.07534 Training err. RA 3.18793 Valid. err. 3.14135
2018-02-03 23:45:50,827 training [INFO ] Epoch 16 Batch 1620 Training err. 3.05639 Training err. RA 3.18631 Valid. err. 3.14104
2018-02-03 23:45:51,334 training [INFO ] Epoch 16 Batch 1640 Training err. 3.10328 Training err. RA 3.18529 Valid. err. 3.13611
2018-02-03 23:45:51,839 training [INFO ] Epoch 16 Batch 1660 Training err. 3.10149 Training err. RA 3.18428 Valid. err. 3.13307
2018-02-03 23:45:52,699 training [INFO ] Epoch 17 Batch 1680 Training err. 3.10362 Training err. RA 3.18332 Valid. err. 3.13137
2018-02-03 23:45:53,207 training [INFO ] Epoch 17 Batch 1700 Training err. 3.05679 Training err. RA 3.18184 Valid. err. 3.13079
2018-02-03 23:45:53,716 training [INFO ] Epoch 17 Batch 1720 Training err. 3.06374 Training err. RA 3.18046 Valid. err. 3.12780
2018-02-03 23:45:54,225 training [INFO ] Epoch 17 Batch 1740 Training err. 3.08153 Training err. RA 3.17933 Valid. err. 3.12382
2018-02-03 23:45:54,733 training [INFO ] Epoch 17 Batch 1760 Training err. 3.08052 Training err. RA 3.17820 Valid. err. 3.12019
2018-02-03 23:45:55,595 training [INFO ] Epoch 18 Batch 1780 Training err. 3.09989 Training err. RA 3.17732 Valid. err. 3.12053
2018-02-03 23:45:56,114 training [INFO ] Epoch 18 Batch 1800 Training err. 3.03650 Training err. RA 3.17576 Valid. err. 3.12594
2018-02-03 23:45:56,630 training [INFO ] Epoch 18 Batch 1820 Training err. 3.06759 Training err. RA 3.17457 Valid. err. 3.11148
2018-02-03 23:45:57,153 training [INFO ] Epoch 18 Batch 1840 Training err. 3.05510 Training err. RA 3.17327 Valid. err. 3.10705
2018-02-03 23:45:57,669 training [INFO ] Epoch 18 Batch 1860 Training err. 3.06061 Training err. RA 3.17206 Valid. err. 3.10472
2018-02-03 23:45:58,575 training [INFO ] Epoch 19 Batch 1880 Training err. 3.08290 Training err. RA 3.17111 Valid. err. 3.09752
2018-02-03 23:45:59,094 training [INFO ] Epoch 19 Batch 1900 Training err. 3.03220 Training err. RA 3.16965 Valid. err. 3.10256
2018-02-03 23:45:59,590 training [INFO ] Epoch 19 Batch 1920 Training err. 3.04839 Training err. RA 3.16839 Valid. err. 3.09093
2018-02-03 23:46:00,099 training [INFO ] Epoch 19 Batch 1940 Training err. 3.02732 Training err. RA 3.16693 Valid. err. 3.08551
2018-02-03 23:46:00,593 training [INFO ] Epoch 19 Batch 1960 Training err. 3.03472 Training err. RA 3.16558 Valid. err. 3.08018
2018-02-03 23:46:01,442 training [INFO ] Epoch 20 Batch 1980 Training err. 3.06161 Training err. RA 3.16453 Valid. err. 3.07854
2018-02-03 23:46:01,944 training [INFO ] Epoch 20 Batch 2000 Training err. 3.02383 Training err. RA 3.16312 Valid. err. 3.07801
2018-02-03 23:46:02,444 training [INFO ] Epoch 20 Batch 2020 Training err. 3.01888 Training err. RA 3.16170 Valid. err. 3.06331
2018-02-03 23:46:02,943 training [INFO ] Epoch 20 Batch 2040 Training err. 2.98765 Training err. RA 3.15999 Valid. err. 3.05737
2018-02-03 23:46:03,458 training [INFO ] Epoch 20 Batch 2060 Training err. 3.01623 Training err. RA 3.15859 Valid. err. 3.05236
2018-02-03 23:46:03,977 training [INFO ] Epoch 20 Batch 2080 Training err. 3.03188 Training err. RA 3.15738 Valid. err. 3.04484
2018-02-03 23:46:04,863 training [INFO ] Epoch 21 Batch 2100 Training err. 3.00559 Training err. RA 3.15593 Valid. err. 3.03774
2018-02-03 23:46:05,379 training [INFO ] Epoch 21 Batch 2120 Training err. 2.98358 Training err. RA 3.15430 Valid. err. 3.03405
2018-02-03 23:46:05,895 training [INFO ] Epoch 21 Batch 2140 Training err. 2.95219 Training err. RA 3.15242 Valid. err. 3.02749
2018-02-03 23:46:06,412 training [INFO ] Epoch 21 Batch 2160 Training err. 2.99212 Training err. RA 3.15093 Valid. err. 3.01753
2018-02-03 23:46:06,926 training [INFO ] Epoch 21 Batch 2180 Training err. 2.98816 Training err. RA 3.14944 Valid. err. 3.00882
2018-02-03 23:46:07,794 training [INFO ] Epoch 22 Batch 2200 Training err. 2.98863 Training err. RA 3.14798 Valid. err. 3.00497
2018-02-03 23:46:08,296 training [INFO ] Epoch 22 Batch 2220 Training err. 2.94118 Training err. RA 3.14611 Valid. err. 2.99935
2018-02-03 23:46:08,800 training [INFO ] Epoch 22 Batch 2240 Training err. 2.93542 Training err. RA 3.14423 Valid. err. 2.98953
2018-02-03 23:46:09,308 training [INFO ] Epoch 22 Batch 2260 Training err. 2.95349 Training err. RA 3.14254 Valid. err. 2.98034
2018-02-03 23:46:09,816 training [INFO ] Epoch 22 Batch 2280 Training err. 2.94234 Training err. RA 3.14079 Valid. err. 2.97249
2018-02-03 23:46:10,665 training [INFO ] Epoch 23 Batch 2300 Training err. 2.96276 Training err. RA 3.13924 Valid. err. 2.98255
2018-02-03 23:46:11,162 training [INFO ] Epoch 23 Batch 2320 Training err. 2.89810 Training err. RA 3.13716 Valid. err. 2.97190
2018-02-03 23:46:11,668 training [INFO ] Epoch 23 Batch 2340 Training err. 2.91819 Training err. RA 3.13529 Valid. err. 2.95042
2018-02-03 23:46:12,189 training [INFO ] Epoch 23 Batch 2360 Training err. 2.91111 Training err. RA 3.13339 Valid. err. 2.94497
2018-02-03 23:46:12,699 training [INFO ] Epoch 23 Batch 2380 Training err. 2.90047 Training err. RA 3.13143 Valid. err. 2.93720
2018-02-03 23:46:13,582 training [INFO ] Epoch 24 Batch 2400 Training err. 2.92601 Training err. RA 3.12972 Valid. err. 2.92802
2018-02-03 23:46:14,097 training [INFO ] Epoch 24 Batch 2420 Training err. 2.87533 Training err. RA 3.12762 Valid. err. 2.95395
2018-02-03 23:46:14,608 training [INFO ] Epoch 24 Batch 2440 Training err. 2.88771 Training err. RA 3.12565 Valid. err. 2.91490
2018-02-03 23:46:15,119 training [INFO ] Epoch 24 Batch 2460 Training err. 2.86793 Training err. RA 3.12356 Valid. err. 2.90841
2018-02-03 23:46:15,774 training [INFO ] Epoch 24 Batch 2480 Training err. 2.86180 Training err. RA 3.12145 Valid. err. 2.89917
2018-02-03 23:46:16,950 training [INFO ] Epoch 25 Batch 2500 Training err. 2.88832 Training err. RA 3.11958 Valid. err. 2.92353
2018-02-03 23:46:17,626 training [INFO ] Epoch 25 Batch 2520 Training err. 2.85717 Training err. RA 3.11750 Valid. err. 2.89337
2018-02-03 23:46:18,329 training [INFO ] Epoch 25 Batch 2540 Training err. 2.84929 Training err. RA 3.11539 Valid. err. 2.87914
2018-02-03 23:46:19,040 training [INFO ] Epoch 25 Batch 2560 Training err. 2.81560 Training err. RA 3.11304 Valid. err. 2.88677
2018-02-03 23:46:19,641 training [INFO ] Epoch 25 Batch 2580 Training err. 2.83705 Training err. RA 3.11090 Valid. err. 2.87242
2018-02-03 23:46:20,224 training [INFO ] Epoch 25 Batch 2600 Training err. 2.85209 Training err. RA 3.10891 Valid. err. 2.87787
2018-02-03 23:46:21,231 training [INFO ] Epoch 26 Batch 2620 Training err. 2.83829 Training err. RA 3.10685 Valid. err. 2.85383
2018-02-03 23:46:21,809 training [INFO ] Epoch 26 Batch 2640 Training err. 2.80560 Training err. RA 3.10457 Valid. err. 2.85912
2018-02-03 23:46:22,356 training [INFO ] Epoch 26 Batch 2660 Training err. 2.77394 Training err. RA 3.10208 Valid. err. 2.87470
2018-02-03 23:46:22,897 training [INFO ] Epoch 26 Batch 2680 Training err. 2.81683 Training err. RA 3.09995 Valid. err. 2.83412
2018-02-03 23:46:23,416 training [INFO ] Epoch 26 Batch 2700 Training err. 2.80610 Training err. RA 3.09777 Valid. err. 2.82602
2018-02-03 23:46:24,319 training [INFO ] Epoch 27 Batch 2720 Training err. 2.82154 Training err. RA 3.09574 Valid. err. 2.82825
2018-02-03 23:46:24,826 training [INFO ] Epoch 27 Batch 2740 Training err. 2.76824 Training err. RA 3.09335 Valid. err. 2.82685
2018-02-03 23:46:25,341 training [INFO ] Epoch 27 Batch 2760 Training err. 2.77303 Training err. RA 3.09103 Valid. err. 2.81678
2018-02-03 23:46:25,850 training [INFO ] Epoch 27 Batch 2780 Training err. 2.77872 Training err. RA 3.08878 Valid. err. 2.80792
2018-02-03 23:46:26,362 training [INFO ] Epoch 27 Batch 2800 Training err. 2.76238 Training err. RA 3.08645 Valid. err. 2.79957
2018-02-03 23:46:27,238 training [INFO ] Epoch 28 Batch 2820 Training err. 2.79836 Training err. RA 3.08441 Valid. err. 2.80437
2018-02-03 23:46:27,737 training [INFO ] Epoch 28 Batch 2840 Training err. 2.71721 Training err. RA 3.08182 Valid. err. 2.81479
2018-02-03 23:46:28,241 training [INFO ] Epoch 28 Batch 2860 Training err. 2.76031 Training err. RA 3.07958 Valid. err. 2.78370
2018-02-03 23:46:28,737 training [INFO ] Epoch 28 Batch 2880 Training err. 2.73575 Training err. RA 3.07719 Valid. err. 2.77779
2018-02-03 23:46:29,237 training [INFO ] Epoch 28 Batch 2900 Training err. 2.73363 Training err. RA 3.07482 Valid. err. 2.77409
2018-02-03 23:46:30,208 training [INFO ] Epoch 29 Batch 2920 Training err. 2.77043 Training err. RA 3.07273 Valid. err. 2.77456
2018-02-03 23:46:30,709 training [INFO ] Epoch 29 Batch 2940 Training err. 2.71081 Training err. RA 3.07027 Valid. err. 2.81388
2018-02-03 23:46:31,211 training [INFO ] Epoch 29 Batch 2960 Training err. 2.74305 Training err. RA 3.06806 Valid. err. 2.76342
2018-02-03 23:46:31,724 training [INFO ] Epoch 29 Batch 2980 Training err. 2.70525 Training err. RA 3.06563 Valid. err. 2.75642
2018-02-03 23:46:32,232 training [INFO ] Epoch 29 Batch 3000 Training err. 2.70249 Training err. RA 3.06320 Valid. err. 2.74761
2018-02-03 23:46:33,112 training [INFO ] Epoch 30 Batch 3020 Training err. 2.73434 Training err. RA 3.06103 Valid. err. 2.78059
2018-02-03 23:46:33,623 training [INFO ] Epoch 30 Batch 3040 Training err. 2.71120 Training err. RA 3.05873 Valid. err. 2.74121
2018-02-03 23:46:34,136 training [INFO ] Epoch 30 Batch 3060 Training err. 2.69625 Training err. RA 3.05636 Valid. err. 2.74719
2018-02-03 23:46:34,648 training [INFO ] Epoch 30 Batch 3080 Training err. 2.66482 Training err. RA 3.05381 Valid. err. 2.73333
2018-02-03 23:46:35,155 training [INFO ] Epoch 30 Batch 3100 Training err. 2.68997 Training err. RA 3.05147 Valid. err. 2.72600
2018-02-03 23:46:35,652 training [INFO ] Epoch 30 Batch 3120 Training err. 2.71393 Training err. RA 3.04930 Valid. err. 2.74933
2018-02-03 23:46:36,485 training [INFO ] Epoch 31 Batch 3140 Training err. 2.70320 Training err. RA 3.04710 Valid. err. 2.71674
2018-02-03 23:46:36,989 training [INFO ] Epoch 31 Batch 3160 Training err. 2.69079 Training err. RA 3.04484 Valid. err. 2.72936
2018-02-03 23:46:37,480 training [INFO ] Epoch 31 Batch 3180 Training err. 2.65625 Training err. RA 3.04240 Valid. err. 2.71879
2018-02-03 23:46:37,978 training [INFO ] Epoch 31 Batch 3200 Training err. 2.68831 Training err. RA 3.04019 Valid. err. 2.70734
2018-02-03 23:46:38,470 training [INFO ] Epoch 31 Batch 3220 Training err. 2.68222 Training err. RA 3.03796 Valid. err. 2.70095
2018-02-03 23:46:39,320 training [INFO ] Epoch 32 Batch 3240 Training err. 2.69941 Training err. RA 3.03587 Valid. err. 2.70926
2018-02-03 23:46:39,821 training [INFO ] Epoch 32 Batch 3260 Training err. 2.63226 Training err. RA 3.03340 Valid. err. 2.69828
2018-02-03 23:46:40,334 training [INFO ] Epoch 32 Batch 3280 Training err. 2.65466 Training err. RA 3.03109 Valid. err. 2.69126
2018-02-03 23:46:40,839 training [INFO ] Epoch 32 Batch 3300 Training err. 2.66003 Training err. RA 3.02884 Valid. err. 2.69260
2018-02-03 23:46:41,348 training [INFO ] Epoch 32 Batch 3320 Training err. 2.64440 Training err. RA 3.02652 Valid. err. 2.68758
2018-02-03 23:46:42,225 training [INFO ] Epoch 33 Batch 3340 Training err. 2.68490 Training err. RA 3.02448 Valid. err. 2.69317
2018-02-03 23:46:42,739 training [INFO ] Epoch 33 Batch 3360 Training err. 2.60594 Training err. RA 3.02199 Valid. err. 2.69326
2018-02-03 23:46:43,254 training [INFO ] Epoch 33 Batch 3380 Training err. 2.65325 Training err. RA 3.01980 Valid. err. 2.66843
2018-02-03 23:46:43,751 training [INFO ] Epoch 33 Batch 3400 Training err. 2.62666 Training err. RA 3.01749 Valid. err. 2.66659
2018-02-03 23:46:44,245 training [INFO ] Epoch 33 Batch 3420 Training err. 2.62394 Training err. RA 3.01519 Valid. err. 2.66369
2018-02-03 23:46:45,101 training [INFO ] Epoch 34 Batch 3440 Training err. 2.65613 Training err. RA 3.01310 Valid. err. 2.66057
2018-02-03 23:46:45,597 training [INFO ] Epoch 34 Batch 3460 Training err. 2.61164 Training err. RA 3.01078 Valid. err. 2.67288
2018-02-03 23:46:46,101 training [INFO ] Epoch 34 Batch 3480 Training err. 2.62939 Training err. RA 3.00859 Valid. err. 2.65389
2018-02-03 23:46:46,594 training [INFO ] Epoch 34 Batch 3500 Training err. 2.60419 Training err. RA 3.00628 Valid. err. 2.64959
2018-02-03 23:46:47,090 training [INFO ] Epoch 34 Batch 3520 Training err. 2.60100 Training err. RA 3.00398 Valid. err. 2.64207
2018-02-03 23:46:47,946 training [INFO ] Epoch 35 Batch 3540 Training err. 2.62797 Training err. RA 3.00185 Valid. err. 2.67202
2018-02-03 23:46:48,457 training [INFO ] Epoch 35 Batch 3560 Training err. 2.61671 Training err. RA 2.99969 Valid. err. 2.64045
2018-02-03 23:46:48,971 training [INFO ] Epoch 35 Batch 3580 Training err. 2.59693 Training err. RA 2.99744 Valid. err. 2.64536
2018-02-03 23:46:49,482 training [INFO ] Epoch 35 Batch 3600 Training err. 2.57259 Training err. RA 2.99508 Valid. err. 2.63664
2018-02-03 23:46:49,990 training [INFO ] Epoch 35 Batch 3620 Training err. 2.59540 Training err. RA 2.99287 Valid. err. 2.62712
2018-02-03 23:46:50,503 training [INFO ] Epoch 35 Batch 3640 Training err. 2.61287 Training err. RA 2.99078 Valid. err. 2.64877
2018-02-03 23:46:51,377 training [INFO ] Epoch 36 Batch 3660 Training err. 2.60991 Training err. RA 2.98870 Valid. err. 2.62884
2018-02-03 23:46:51,873 training [INFO ] Epoch 36 Batch 3680 Training err. 2.56238 Training err. RA 2.98638 Valid. err. 2.61931
2018-02-03 23:46:52,381 training [INFO ] Epoch 36 Batch 3700 Training err. 2.55978 Training err. RA 2.98408 Valid. err. 2.61148
2018-02-03 23:46:52,886 training [INFO ] Epoch 36 Batch 3720 Training err. 2.58996 Training err. RA 2.98196 Valid. err. 2.60656
2018-02-03 23:46:53,384 training [INFO ] Epoch 36 Batch 3740 Training err. 2.57917 Training err. RA 2.97980 Valid. err. 2.60162
2018-02-03 23:46:54,242 training [INFO ] Epoch 37 Batch 3760 Training err. 2.59915 Training err. RA 2.97778 Valid. err. 2.62270
2018-02-03 23:46:54,742 training [INFO ] Epoch 37 Batch 3780 Training err. 2.54121 Training err. RA 2.97547 Valid. err. 2.60030
2018-02-03 23:46:55,241 training [INFO ] Epoch 37 Batch 3800 Training err. 2.56923 Training err. RA 2.97333 Valid. err. 2.59756
2018-02-03 23:46:55,748 training [INFO ] Epoch 37 Batch 3820 Training err. 2.56467 Training err. RA 2.97119 Valid. err. 2.60357
2018-02-03 23:46:56,260 training [INFO ] Epoch 37 Batch 3840 Training err. 2.54938 Training err. RA 2.96900 Valid. err. 2.58781
2018-02-03 23:46:57,143 training [INFO ] Epoch 38 Batch 3860 Training err. 2.58951 Training err. RA 2.96703 Valid. err. 2.59048
2018-02-03 23:46:57,657 training [INFO ] Epoch 38 Batch 3880 Training err. 2.52321 Training err. RA 2.96474 Valid. err. 2.59572
2018-02-03 23:46:58,176 training [INFO ] Epoch 38 Batch 3900 Training err. 2.56975 Training err. RA 2.96272 Valid. err. 2.57970
2018-02-03 23:46:58,694 training [INFO ] Epoch 38 Batch 3920 Training err. 2.54036 Training err. RA 2.96056 Valid. err. 2.57537
2018-02-03 23:46:59,215 training [INFO ] Epoch 38 Batch 3940 Training err. 2.53410 Training err. RA 2.95840 Valid. err. 2.57798
2018-02-03 23:47:00,089 training [INFO ] Epoch 39 Batch 3960 Training err. 2.56668 Training err. RA 2.95642 Valid. err. 2.57075
2018-02-03 23:47:00,593 training [INFO ] Epoch 39 Batch 3980 Training err. 2.53279 Training err. RA 2.95429 Valid. err. 2.58352
2018-02-03 23:47:01,096 training [INFO ] Epoch 39 Batch 4000 Training err. 2.54838 Training err. RA 2.95226 Valid. err. 2.56912
2018-02-03 23:47:01,603 training [INFO ] Epoch 39 Batch 4020 Training err. 2.52404 Training err. RA 2.95013 Valid. err. 2.56852
2018-02-03 23:47:02,104 training [INFO ] Epoch 39 Batch 4040 Training err. 2.51665 Training err. RA 2.94798 Valid. err. 2.55796
2018-02-03 23:47:02,941 training [INFO ] Epoch 40 Batch 4060 Training err. 2.54116 Training err. RA 2.94598 Valid. err. 2.58277
2018-02-03 23:47:03,444 training [INFO ] Epoch 40 Batch 4080 Training err. 2.54093 Training err. RA 2.94399 Valid. err. 2.56117
2018-02-03 23:47:03,947 training [INFO ] Epoch 40 Batch 4100 Training err. 2.51735 Training err. RA 2.94191 Valid. err. 2.56788
2018-02-03 23:47:04,453 training [INFO ] Epoch 40 Batch 4120 Training err. 2.49828 Training err. RA 2.93976 Valid. err. 2.55586
2018-02-03 23:47:04,951 training [INFO ] Epoch 40 Batch 4140 Training err. 2.51510 Training err. RA 2.93771 Valid. err. 2.54598
2018-02-03 23:47:05,455 training [INFO ] Epoch 40 Batch 4160 Training err. 2.52977 Training err. RA 2.93575 Valid. err. 2.56454
2018-02-03 23:47:06,307 training [INFO ] Epoch 41 Batch 4180 Training err. 2.53716 Training err. RA 2.93384 Valid. err. 2.55600
2018-02-03 23:47:06,810 training [INFO ] Epoch 41 Batch 4200 Training err. 2.48488 Training err. RA 2.93170 Valid. err. 2.53972
2018-02-03 23:47:07,325 training [INFO ] Epoch 41 Batch 4220 Training err. 2.48884 Training err. RA 2.92960 Valid. err. 2.53353
2018-02-03 23:47:07,852 training [INFO ] Epoch 41 Batch 4240 Training err. 2.51345 Training err. RA 2.92764 Valid. err. 2.52902
2018-02-03 23:47:08,366 training [INFO ] Epoch 41 Batch 4260 Training err. 2.50115 Training err. RA 2.92564 Valid. err. 2.52478
2018-02-03 23:47:09,324 training [INFO ] Epoch 42 Batch 4280 Training err. 2.52498 Training err. RA 2.92376 Valid. err. 2.55149
2018-02-03 23:47:09,848 training [INFO ] Epoch 42 Batch 4300 Training err. 2.46986 Training err. RA 2.92165 Valid. err. 2.52410
2018-02-03 23:47:10,366 training [INFO ] Epoch 42 Batch 4320 Training err. 2.49874 Training err. RA 2.91970 Valid. err. 2.52354
2018-02-03 23:47:10,879 training [INFO ] Epoch 42 Batch 4340 Training err. 2.49110 Training err. RA 2.91772 Valid. err. 2.52459
2018-02-03 23:47:11,391 training [INFO ] Epoch 42 Batch 4360 Training err. 2.47508 Training err. RA 2.91569 Valid. err. 2.51392
2018-02-03 23:47:12,258 training [INFO ] Epoch 43 Batch 4380 Training err. 2.51624 Training err. RA 2.91387 Valid. err. 2.52324
2018-02-03 23:47:12,761 training [INFO ] Epoch 43 Batch 4400 Training err. 2.45603 Training err. RA 2.91179 Valid. err. 2.51933
2018-02-03 23:47:13,275 training [INFO ] Epoch 43 Batch 4420 Training err. 2.49921 Training err. RA 2.90992 Valid. err. 2.50914
2018-02-03 23:47:13,777 training [INFO ] Epoch 43 Batch 4440 Training err. 2.47231 Training err. RA 2.90795 Valid. err. 2.50148
2018-02-03 23:47:14,283 training [INFO ] Epoch 43 Batch 4460 Training err. 2.46049 Training err. RA 2.90594 Valid. err. 2.50806
2018-02-03 23:47:15,132 training [INFO ] Epoch 44 Batch 4480 Training err. 2.49330 Training err. RA 2.90410 Valid. err. 2.50031
2018-02-03 23:47:15,648 training [INFO ] Epoch 44 Batch 4500 Training err. 2.46998 Training err. RA 2.90217 Valid. err. 2.50787
2018-02-03 23:47:16,167 training [INFO ] Epoch 44 Batch 4520 Training err. 2.47960 Training err. RA 2.90030 Valid. err. 2.49910
2018-02-03 23:47:16,682 training [INFO ] Epoch 44 Batch 4540 Training err. 2.45797 Training err. RA 2.89835 Valid. err. 2.50935
2018-02-03 23:47:17,197 training [INFO ] Epoch 44 Batch 4560 Training err. 2.44746 Training err. RA 2.89637 Valid. err. 2.48864
2018-02-03 23:47:18,080 training [INFO ] Epoch 45 Batch 4580 Training err. 2.46928 Training err. RA 2.89451 Valid. err. 2.51064
2018-02-03 23:47:18,590 training [INFO ] Epoch 45 Batch 4600 Training err. 2.47994 Training err. RA 2.89271 Valid. err. 2.49137
2018-02-03 23:47:19,109 training [INFO ] Epoch 45 Batch 4620 Training err. 2.45008 Training err. RA 2.89079 Valid. err. 2.49810
2018-02-03 23:47:19,713 training [INFO ] Epoch 45 Batch 4640 Training err. 2.43467 Training err. RA 2.88882 Valid. err. 2.48509
2018-02-03 23:47:20,385 training [INFO ] Epoch 45 Batch 4660 Training err. 2.44837 Training err. RA 2.88693 Valid. err. 2.47839
2018-02-03 23:47:21,062 training [INFO ] Epoch 45 Batch 4680 Training err. 2.46096 Training err. RA 2.88511 Valid. err. 2.49081
2018-02-03 23:47:22,216 training [INFO ] Epoch 46 Batch 4700 Training err. 2.47861 Training err. RA 2.88338 Valid. err. 2.48882
2018-02-03 23:47:22,905 training [INFO ] Epoch 46 Batch 4720 Training err. 2.41856 Training err. RA 2.88141 Valid. err. 2.47036
2018-02-03 23:47:23,534 training [INFO ] Epoch 46 Batch 4740 Training err. 2.42620 Training err. RA 2.87949 Valid. err. 2.46660
2018-02-03 23:47:24,107 training [INFO ] Epoch 46 Batch 4760 Training err. 2.44869 Training err. RA 2.87768 Valid. err. 2.46299
2018-02-03 23:47:24,660 training [INFO ] Epoch 46 Batch 4780 Training err. 2.43712 Training err. RA 2.87584 Valid. err. 2.46082
2018-02-03 23:47:25,606 training [INFO ] Epoch 47 Batch 4800 Training err. 2.46422 Training err. RA 2.87412 Valid. err. 2.50374
2018-02-03 23:47:26,156 training [INFO ] Epoch 47 Batch 4820 Training err. 2.40771 Training err. RA 2.87219 Valid. err. 2.45852
2018-02-03 23:47:26,706 training [INFO ] Epoch 47 Batch 4840 Training err. 2.43569 Training err. RA 2.87038 Valid. err. 2.46111
2018-02-03 23:47:27,256 training [INFO ] Epoch 47 Batch 4860 Training err. 2.42899 Training err. RA 2.86857 Valid. err. 2.45875
2018-02-03 23:47:27,768 training [INFO ] Epoch 47 Batch 4880 Training err. 2.41372 Training err. RA 2.86670 Valid. err. 2.45293
2018-02-03 23:47:28,638 training [INFO ] Epoch 48 Batch 4900 Training err. 2.45412 Training err. RA 2.86502 Valid. err. 2.47432
2018-02-03 23:47:29,148 training [INFO ] Epoch 48 Batch 4920 Training err. 2.39878 Training err. RA 2.86312 Valid. err. 2.45408
2018-02-03 23:47:29,657 training [INFO ] Epoch 48 Batch 4940 Training err. 2.43648 Training err. RA 2.86140 Valid. err. 2.44837
2018-02-03 23:47:30,167 training [INFO ] Epoch 48 Batch 4960 Training err. 2.41330 Training err. RA 2.85959 Valid. err. 2.44177
2018-02-03 23:47:30,680 training [INFO ] Epoch 48 Batch 4980 Training err. 2.39931 Training err. RA 2.85774 Valid. err. 2.44863
2018-02-03 23:47:31,544 training [INFO ] Epoch 49 Batch 5000 Training err. 2.43034 Training err. RA 2.85603 Valid. err. 2.44136
2018-02-03 23:47:32,042 training [INFO ] Epoch 49 Batch 5020 Training err. 2.41594 Training err. RA 2.85428 Valid. err. 2.44112
2018-02-03 23:47:32,537 training [INFO ] Epoch 49 Batch 5040 Training err. 2.41802 Training err. RA 2.85255 Valid. err. 2.43773
2018-02-03 23:47:33,038 training [INFO ] Epoch 49 Batch 5060 Training err. 2.39902 Training err. RA 2.85076 Valid. err. 2.45697
2018-02-03 23:47:33,535 training [INFO ] Epoch 49 Batch 5080 Training err. 2.39008 Training err. RA 2.84894 Valid. err. 2.42893
2018-02-03 23:47:34,373 training [INFO ] Epoch 50 Batch 5100 Training err. 2.40818 Training err. RA 2.84721 Valid. err. 2.44096
2018-02-03 23:47:34,867 training [INFO ] Epoch 50 Batch 5120 Training err. 2.42719 Training err. RA 2.84557 Valid. err. 2.42996
2018-02-03 23:47:35,373 training [INFO ] Epoch 50 Batch 5140 Training err. 2.38952 Training err. RA 2.84380 Valid. err. 2.43340
2018-02-03 23:47:35,882 training [INFO ] Epoch 50 Batch 5160 Training err. 2.37776 Training err. RA 2.84199 Valid. err. 2.42140
2018-02-03 23:47:36,398 training [INFO ] Epoch 50 Batch 5180 Training err. 2.39175 Training err. RA 2.84025 Valid. err. 2.41932
2018-02-03 23:47:36,907 training [INFO ] Epoch 50 Batch 5200 Training err. 2.40228 Training err. RA 2.83857 Valid. err. 2.42335
2018-02-03 23:47:37,782 training [INFO ] Epoch 51 Batch 5220 Training err. 2.42586 Training err. RA 2.83699 Valid. err. 2.43256
2018-02-03 23:47:38,295 training [INFO ] Epoch 51 Batch 5240 Training err. 2.36001 Training err. RA 2.83517 Valid. err. 2.41287
2018-02-03 23:47:38,807 training [INFO ] Epoch 51 Batch 5260 Training err. 2.37020 Training err. RA 2.83340 Valid. err. 2.40952
2018-02-03 23:47:39,325 training [INFO ] Epoch 51 Batch 5280 Training err. 2.39413 Training err. RA 2.83174 Valid. err. 2.40760
2018-02-03 23:47:39,819 training [INFO ] Epoch 51 Batch 5300 Training err. 2.38203 Training err. RA 2.83004 Valid. err. 2.40610
2018-02-03 23:47:40,666 training [INFO ] Epoch 52 Batch 5320 Training err. 2.40894 Training err. RA 2.82846 Valid. err. 2.46026
2018-02-03 23:47:41,161 training [INFO ] Epoch 52 Batch 5340 Training err. 2.35353 Training err. RA 2.82668 Valid. err. 2.40246
2018-02-03 23:47:41,659 training [INFO ] Epoch 52 Batch 5360 Training err. 2.38004 Training err. RA 2.82501 Valid. err. 2.41031
2018-02-03 23:47:42,162 training [INFO ] Epoch 52 Batch 5380 Training err. 2.37596 Training err. RA 2.82334 Valid. err. 2.40623
2018-02-03 23:47:42,659 training [INFO ] Epoch 52 Batch 5400 Training err. 2.36135 Training err. RA 2.82163 Valid. err. 2.40119
2018-02-03 23:47:43,507 training [INFO ] Epoch 53 Batch 5420 Training err. 2.39958 Training err. RA 2.82007 Valid. err. 2.42795
2018-02-03 23:47:44,023 training [INFO ] Epoch 53 Batch 5440 Training err. 2.34741 Training err. RA 2.81833 Valid. err. 2.39929
2018-02-03 23:47:44,536 training [INFO ] Epoch 53 Batch 5460 Training err. 2.38218 Training err. RA 2.81674 Valid. err. 2.39614
2018-02-03 23:47:45,058 training [INFO ] Epoch 53 Batch 5480 Training err. 2.36241 Training err. RA 2.81508 Valid. err. 2.39312
2018-02-03 23:47:45,570 training [INFO ] Epoch 53 Batch 5500 Training err. 2.34779 Training err. RA 2.81338 Valid. err. 2.39634
2018-02-03 23:47:46,444 training [INFO ] Epoch 54 Batch 5520 Training err. 2.37607 Training err. RA 2.81179 Valid. err. 2.39188
2018-02-03 23:47:46,954 training [INFO ] Epoch 54 Batch 5540 Training err. 2.36785 Training err. RA 2.81019 Valid. err. 2.38740
2018-02-03 23:47:47,496 training [INFO ] Epoch 54 Batch 5560 Training err. 2.36487 Training err. RA 2.80859 Valid. err. 2.38549
2018-02-03 23:47:48,176 training [INFO ] Epoch 54 Batch 5580 Training err. 2.34823 Training err. RA 2.80694 Valid. err. 2.40759
2018-02-03 23:47:48,851 training [INFO ] Epoch 54 Batch 5600 Training err. 2.34128 Training err. RA 2.80528 Valid. err. 2.37821
2018-02-03 23:47:50,005 training [INFO ] Epoch 55 Batch 5620 Training err. 2.35666 Training err. RA 2.80368 Valid. err. 2.38502
2018-02-03 23:47:50,677 training [INFO ] Epoch 55 Batch 5640 Training err. 2.37835 Training err. RA 2.80217 Valid. err. 2.37933
2018-02-03 23:47:51,340 training [INFO ] Epoch 55 Batch 5660 Training err. 2.33933 Training err. RA 2.80054 Valid. err. 2.37973
2018-02-03 23:47:51,904 training [INFO ] Epoch 55 Batch 5680 Training err. 2.32897 Training err. RA 2.79888 Valid. err. 2.36855
2018-02-03 23:47:52,467 training [INFO ] Epoch 55 Batch 5700 Training err. 2.34249 Training err. RA 2.79728 Valid. err. 2.36859
2018-02-03 23:47:53,028 training [INFO ] Epoch 55 Batch 5720 Training err. 2.35188 Training err. RA 2.79572 Valid. err. 2.36867
2018-02-03 23:47:53,978 training [INFO ] Epoch 56 Batch 5740 Training err. 2.37854 Training err. RA 2.79426 Valid. err. 2.38326
2018-02-03 23:47:54,516 training [INFO ] Epoch 56 Batch 5760 Training err. 2.31177 Training err. RA 2.79259 Valid. err. 2.36458
2018-02-03 23:47:55,061 training [INFO ] Epoch 56 Batch 5780 Training err. 2.32195 Training err. RA 2.79096 Valid. err. 2.36089
2018-02-03 23:47:55,578 training [INFO ] Epoch 56 Batch 5800 Training err. 2.34591 Training err. RA 2.78943 Valid. err. 2.35920
2018-02-03 23:47:56,089 training [INFO ] Epoch 56 Batch 5820 Training err. 2.33470 Training err. RA 2.78786 Valid. err. 2.35954
2018-02-03 23:47:56,950 training [INFO ] Epoch 57 Batch 5840 Training err. 2.36191 Training err. RA 2.78640 Valid. err. 2.40421
2018-02-03 23:47:57,462 training [INFO ] Epoch 57 Batch 5860 Training err. 2.30710 Training err. RA 2.78477 Valid. err. 2.35482
2018-02-03 23:47:57,977 training [INFO ] Epoch 57 Batch 5880 Training err. 2.33147 Training err. RA 2.78323 Valid. err. 2.36779
2018-02-03 23:47:58,491 training [INFO ] Epoch 57 Batch 5900 Training err. 2.32896 Training err. RA 2.78169 Valid. err. 2.36133
2018-02-03 23:47:59,001 training [INFO ] Epoch 57 Batch 5920 Training err. 2.31598 Training err. RA 2.78011 Valid. err. 2.35878
2018-02-03 23:47:59,844 training [INFO ] Epoch 58 Batch 5940 Training err. 2.35428 Training err. RA 2.77868 Valid. err. 2.38592
2018-02-03 23:48:00,349 training [INFO ] Epoch 58 Batch 5960 Training err. 2.30128 Training err. RA 2.77708 Valid. err. 2.35457
2018-02-03 23:48:00,850 training [INFO ] Epoch 58 Batch 5980 Training err. 2.33456 Training err. RA 2.77560 Valid. err. 2.35180
2018-02-03 23:48:01,360 training [INFO ] Epoch 58 Batch 6000 Training err. 2.31709 Training err. RA 2.77407 Valid. err. 2.34851
2018-02-03 23:48:01,865 training [INFO ] Epoch 58 Batch 6020 Training err. 2.30283 Training err. RA 2.77250 Valid. err. 2.35203
2018-02-03 23:48:02,722 training [INFO ] Epoch 59 Batch 6040 Training err. 2.33033 Training err. RA 2.77104 Valid. err. 2.35224
2018-02-03 23:48:03,231 training [INFO ] Epoch 59 Batch 6060 Training err. 2.32450 Training err. RA 2.76957 Valid. err. 2.34253
2018-02-03 23:48:03,732 training [INFO ] Epoch 59 Batch 6080 Training err. 2.31825 Training err. RA 2.76808 Valid. err. 2.34069
2018-02-03 23:48:04,242 training [INFO ] Epoch 59 Batch 6100 Training err. 2.30462 Training err. RA 2.76656 Valid. err. 2.35594
2018-02-03 23:48:04,744 training [INFO ] Epoch 59 Batch 6120 Training err. 2.29699 Training err. RA 2.76503 Valid. err. 2.33363
2018-02-03 23:48:05,589 training [INFO ] Epoch 60 Batch 6140 Training err. 2.31243 Training err. RA 2.76355 Valid. err. 2.34143
2018-02-03 23:48:06,092 training [INFO ] Epoch 60 Batch 6160 Training err. 2.33533 Training err. RA 2.76216 Valid. err. 2.33605
2018-02-03 23:48:06,589 training [INFO ] Epoch 60 Batch 6180 Training err. 2.29490 Training err. RA 2.76065 Valid. err. 2.33474
2018-02-03 23:48:07,091 training [INFO ] Epoch 60 Batch 6200 Training err. 2.28704 Training err. RA 2.75912 Valid. err. 2.32571
2018-02-03 23:48:07,595 training [INFO ] Epoch 60 Batch 6220 Training err. 2.29741 Training err. RA 2.75764 Valid. err. 2.32582
2018-02-03 23:48:08,103 training [INFO ] Epoch 60 Batch 6240 Training err. 2.30842 Training err. RA 2.75620 Valid. err. 2.32514
2018-02-03 23:48:08,352 __main__ [INFO ] End of training
2018-02-03 23:48:08,647 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 23:48:08,647 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 23:48:09,329 training [INFO ] Epoch  1 Batch   20 Training err. 3.63755 Training err. RA 3.63755 Valid. err. 3.25904
2018-02-03 23:48:09,843 training [INFO ] Epoch  1 Batch   40 Training err. 3.16611 Training err. RA 3.40183 Valid. err. 3.19632
2018-02-03 23:48:10,357 training [INFO ] Epoch  1 Batch   60 Training err. 3.13805 Training err. RA 3.31390 Valid. err. 3.43535
2018-02-03 23:48:10,866 training [INFO ] Epoch  1 Batch   80 Training err. 3.16892 Training err. RA 3.27766 Valid. err. 3.18056
2018-02-03 23:48:11,368 training [INFO ] Epoch  1 Batch  100 Training err. 3.14478 Training err. RA 3.25108 Valid. err. 3.17009
2018-02-03 23:48:12,209 training [INFO ] Epoch  2 Batch  120 Training err. 3.14906 Training err. RA 3.23408 Valid. err. 3.17691
2018-02-03 23:48:12,700 training [INFO ] Epoch  2 Batch  140 Training err. 3.09824 Training err. RA 3.21467 Valid. err. 3.16151
2018-02-03 23:48:13,209 training [INFO ] Epoch  2 Batch  160 Training err. 3.09072 Training err. RA 3.19918 Valid. err. 3.17018
2018-02-03 23:48:13,710 training [INFO ] Epoch  2 Batch  180 Training err. 3.12133 Training err. RA 3.19053 Valid. err. 3.12922
2018-02-03 23:48:14,211 training [INFO ] Epoch  2 Batch  200 Training err. 3.08857 Training err. RA 3.18033 Valid. err. 3.10736
2018-02-03 23:48:15,065 training [INFO ] Epoch  3 Batch  220 Training err. 3.08259 Training err. RA 3.17145 Valid. err. 3.15071
2018-02-03 23:48:15,565 training [INFO ] Epoch  3 Batch  240 Training err. 2.99620 Training err. RA 3.15684 Valid. err. 3.05540
2018-02-03 23:48:16,068 training [INFO ] Epoch  3 Batch  260 Training err. 2.99777 Training err. RA 3.14461 Valid. err. 3.03677
2018-02-03 23:48:16,568 training [INFO ] Epoch  3 Batch  280 Training err. 2.96853 Training err. RA 3.13203 Valid. err. 2.96235
2018-02-03 23:48:17,068 training [INFO ] Epoch  3 Batch  300 Training err. 2.91161 Training err. RA 3.11734 Valid. err. 2.91293
2018-02-03 23:48:17,912 training [INFO ] Epoch  4 Batch  320 Training err. 2.90793 Training err. RA 3.10425 Valid. err. 2.87763
2018-02-03 23:48:18,416 training [INFO ] Epoch  4 Batch  340 Training err. 2.83310 Training err. RA 3.08830 Valid. err. 2.97606
2018-02-03 23:48:18,919 training [INFO ] Epoch  4 Batch  360 Training err. 2.82458 Training err. RA 3.07365 Valid. err. 2.81979
2018-02-03 23:48:19,420 training [INFO ] Epoch  4 Batch  380 Training err. 2.75418 Training err. RA 3.05683 Valid. err. 2.78565
2018-02-03 23:48:19,922 training [INFO ] Epoch  4 Batch  400 Training err. 2.74987 Training err. RA 3.04149 Valid. err. 2.75502
2018-02-03 23:48:20,771 training [INFO ] Epoch  5 Batch  420 Training err. 2.75280 Training err. RA 3.02774 Valid. err. 2.74763
2018-02-03 23:48:21,283 training [INFO ] Epoch  5 Batch  440 Training err. 2.70544 Training err. RA 3.01309 Valid. err. 2.71777
2018-02-03 23:48:21,785 training [INFO ] Epoch  5 Batch  460 Training err. 2.70332 Training err. RA 2.99962 Valid. err. 2.73810
2018-02-03 23:48:22,288 training [INFO ] Epoch  5 Batch  480 Training err. 2.64157 Training err. RA 2.98470 Valid. err. 2.66245
2018-02-03 23:48:22,787 training [INFO ] Epoch  5 Batch  500 Training err. 2.61860 Training err. RA 2.97006 Valid. err. 2.65164
2018-02-03 23:48:23,292 training [INFO ] Epoch  5 Batch  520 Training err. 2.63208 Training err. RA 2.95706 Valid. err. 2.62143
2018-02-03 23:48:24,163 training [INFO ] Epoch  6 Batch  540 Training err. 2.60688 Training err. RA 2.94409 Valid. err. 2.60355
2018-02-03 23:48:24,676 training [INFO ] Epoch  6 Batch  560 Training err. 2.54523 Training err. RA 2.92984 Valid. err. 2.62866
2018-02-03 23:48:25,193 training [INFO ] Epoch  6 Batch  580 Training err. 2.53066 Training err. RA 2.91608 Valid. err. 2.57609
2018-02-03 23:48:25,709 training [INFO ] Epoch  6 Batch  600 Training err. 2.52830 Training err. RA 2.90315 Valid. err. 2.53965
2018-02-03 23:48:26,226 training [INFO ] Epoch  6 Batch  620 Training err. 2.51798 Training err. RA 2.89073 Valid. err. 2.56140
2018-02-03 23:48:27,119 training [INFO ] Epoch  7 Batch  640 Training err. 2.52015 Training err. RA 2.87915 Valid. err. 2.51424
2018-02-03 23:48:27,624 training [INFO ] Epoch  7 Batch  660 Training err. 2.43928 Training err. RA 2.86582 Valid. err. 2.49881
2018-02-03 23:48:28,123 training [INFO ] Epoch  7 Batch  680 Training err. 2.45744 Training err. RA 2.85381 Valid. err. 2.52789
2018-02-03 23:48:28,623 training [INFO ] Epoch  7 Batch  700 Training err. 2.43957 Training err. RA 2.84197 Valid. err. 2.43521
2018-02-03 23:48:29,121 training [INFO ] Epoch  7 Batch  720 Training err. 2.41378 Training err. RA 2.83008 Valid. err. 2.41757
2018-02-03 23:48:29,957 training [INFO ] Epoch  8 Batch  740 Training err. 2.43268 Training err. RA 2.81934 Valid. err. 2.41210
2018-02-03 23:48:30,455 training [INFO ] Epoch  8 Batch  760 Training err. 2.35807 Training err. RA 2.80720 Valid. err. 2.39590
2018-02-03 23:48:30,964 training [INFO ] Epoch  8 Batch  780 Training err. 2.38950 Training err. RA 2.79649 Valid. err. 2.36992
2018-02-03 23:48:31,461 training [INFO ] Epoch  8 Batch  800 Training err. 2.33740 Training err. RA 2.78501 Valid. err. 2.38390
2018-02-03 23:48:31,962 training [INFO ] Epoch  8 Batch  820 Training err. 2.33047 Training err. RA 2.77392 Valid. err. 2.38838
2018-02-03 23:48:32,806 training [INFO ] Epoch  9 Batch  840 Training err. 2.35732 Training err. RA 2.76401 Valid. err. 2.33959
2018-02-03 23:48:33,312 training [INFO ] Epoch  9 Batch  860 Training err. 2.31463 Training err. RA 2.75355 Valid. err. 2.33092
2018-02-03 23:48:33,812 training [INFO ] Epoch  9 Batch  880 Training err. 2.29122 Training err. RA 2.74305 Valid. err. 2.33998
2018-02-03 23:48:34,318 training [INFO ] Epoch  9 Batch  900 Training err. 2.29966 Training err. RA 2.73319 Valid. err. 2.33486
2018-02-03 23:48:34,817 training [INFO ] Epoch  9 Batch  920 Training err. 2.26329 Training err. RA 2.72298 Valid. err. 2.30907
2018-02-03 23:48:35,660 training [INFO ] Epoch 10 Batch  940 Training err. 2.27156 Training err. RA 2.71337 Valid. err. 2.29023
2018-02-03 23:48:36,174 training [INFO ] Epoch 10 Batch  960 Training err. 2.27010 Training err. RA 2.70414 Valid. err. 2.27066
2018-02-03 23:48:36,693 training [INFO ] Epoch 10 Batch  980 Training err. 2.22113 Training err. RA 2.69428 Valid. err. 2.24822
2018-02-03 23:48:37,210 training [INFO ] Epoch 10 Batch 1000 Training err. 2.22316 Training err. RA 2.68486 Valid. err. 2.24544
2018-02-03 23:48:37,722 training [INFO ] Epoch 10 Batch 1020 Training err. 2.21864 Training err. RA 2.67572 Valid. err. 2.27207
2018-02-03 23:48:38,237 training [INFO ] Epoch 10 Batch 1040 Training err. 2.21759 Training err. RA 2.66691 Valid. err. 2.26161
2018-02-03 23:48:39,108 training [INFO ] Epoch 11 Batch 1060 Training err. 2.23793 Training err. RA 2.65881 Valid. err. 2.22159
2018-02-03 23:48:39,608 training [INFO ] Epoch 11 Batch 1080 Training err. 2.15248 Training err. RA 2.64944 Valid. err. 2.23826
2018-02-03 23:48:40,110 training [INFO ] Epoch 11 Batch 1100 Training err. 2.17383 Training err. RA 2.64079 Valid. err. 2.19597
2018-02-03 23:48:40,604 training [INFO ] Epoch 11 Batch 1120 Training err. 2.18792 Training err. RA 2.63270 Valid. err. 2.20054
2018-02-03 23:48:41,097 training [INFO ] Epoch 11 Batch 1140 Training err. 2.15340 Training err. RA 2.62429 Valid. err. 2.19170
2018-02-03 23:48:41,926 training [INFO ] Epoch 12 Batch 1160 Training err. 2.18452 Training err. RA 2.61671 Valid. err. 2.24879
2018-02-03 23:48:42,424 training [INFO ] Epoch 12 Batch 1180 Training err. 2.12680 Training err. RA 2.60841 Valid. err. 2.17470
2018-02-03 23:48:42,922 training [INFO ] Epoch 12 Batch 1200 Training err. 2.13387 Training err. RA 2.60050 Valid. err. 2.23508
2018-02-03 23:48:43,426 training [INFO ] Epoch 12 Batch 1220 Training err. 2.14269 Training err. RA 2.59299 Valid. err. 2.14943
2018-02-03 23:48:43,929 training [INFO ] Epoch 12 Batch 1240 Training err. 2.11267 Training err. RA 2.58525 Valid. err. 2.15468
2018-02-03 23:48:44,802 training [INFO ] Epoch 13 Batch 1260 Training err. 2.65615 Training err. RA 2.58637 Valid. err. 2.71053
2018-02-03 23:48:45,315 training [INFO ] Epoch 13 Batch 1280 Training err. 2.35619 Training err. RA 2.58278 Valid. err. 2.30433
2018-02-03 23:48:45,826 training [INFO ] Epoch 13 Batch 1300 Training err. 2.26791 Training err. RA 2.57793 Valid. err. 2.24232
2018-02-03 23:48:46,339 training [INFO ] Epoch 13 Batch 1320 Training err. 2.22823 Training err. RA 2.57263 Valid. err. 2.22191
2018-02-03 23:48:46,853 training [INFO ] Epoch 13 Batch 1340 Training err. 2.16964 Training err. RA 2.56662 Valid. err. 2.19254
2018-02-03 23:48:47,747 training [INFO ] Epoch 14 Batch 1360 Training err. 2.18602 Training err. RA 2.56102 Valid. err. 2.18995
2018-02-03 23:48:48,248 training [INFO ] Epoch 14 Batch 1380 Training err. 2.16609 Training err. RA 2.55530 Valid. err. 2.18029
2018-02-03 23:48:48,749 training [INFO ] Epoch 14 Batch 1400 Training err. 2.13880 Training err. RA 2.54935 Valid. err. 2.18278
2018-02-03 23:48:49,246 training [INFO ] Epoch 14 Batch 1420 Training err. 2.13977 Training err. RA 2.54358 Valid. err. 2.20063
2018-02-03 23:48:49,750 training [INFO ] Epoch 14 Batch 1440 Training err. 2.11390 Training err. RA 2.53761 Valid. err. 2.15728
2018-02-03 23:48:50,622 training [INFO ] Epoch 15 Batch 1460 Training err. 2.11157 Training err. RA 2.53178 Valid. err. 2.14000
2018-02-03 23:48:51,119 training [INFO ] Epoch 15 Batch 1480 Training err. 2.12755 Training err. RA 2.52631 Valid. err. 2.13887
2018-02-03 23:48:51,616 training [INFO ] Epoch 15 Batch 1500 Training err. 2.07584 Training err. RA 2.52031 Valid. err. 2.11530
2018-02-03 23:48:52,133 training [INFO ] Epoch 15 Batch 1520 Training err. 2.07890 Training err. RA 2.51450 Valid. err. 2.10236
2018-02-03 23:48:52,643 training [INFO ] Epoch 15 Batch 1540 Training err. 2.08116 Training err. RA 2.50887 Valid. err. 2.10499
2018-02-03 23:48:53,152 training [INFO ] Epoch 15 Batch 1560 Training err. 2.07640 Training err. RA 2.50333 Valid. err. 2.11644
2018-02-03 23:48:54,011 training [INFO ] Epoch 16 Batch 1580 Training err. 2.10183 Training err. RA 2.49824 Valid. err. 2.10055
2018-02-03 23:48:54,520 training [INFO ] Epoch 16 Batch 1600 Training err. 2.02248 Training err. RA 2.49230 Valid. err. 2.10140
2018-02-03 23:48:55,034 training [INFO ] Epoch 16 Batch 1620 Training err. 2.03637 Training err. RA 2.48667 Valid. err. 2.07697
2018-02-03 23:48:55,540 training [INFO ] Epoch 16 Batch 1640 Training err. 2.06098 Training err. RA 2.48148 Valid. err. 2.08921
2018-02-03 23:48:56,035 training [INFO ] Epoch 16 Batch 1660 Training err. 2.02654 Training err. RA 2.47600 Valid. err. 2.07631
2018-02-03 23:48:56,883 training [INFO ] Epoch 17 Batch 1680 Training err. 2.06413 Training err. RA 2.47109 Valid. err. 2.08294
2018-02-03 23:48:57,381 training [INFO ] Epoch 17 Batch 1700 Training err. 2.00876 Training err. RA 2.46565 Valid. err. 2.06851
2018-02-03 23:48:57,879 training [INFO ] Epoch 17 Batch 1720 Training err. 2.00953 Training err. RA 2.46035 Valid. err. 2.07739
2018-02-03 23:48:58,377 training [INFO ] Epoch 17 Batch 1740 Training err. 2.02658 Training err. RA 2.45536 Valid. err. 2.04256
2018-02-03 23:48:58,875 training [INFO ] Epoch 17 Batch 1760 Training err. 2.00183 Training err. RA 2.45021 Valid. err. 2.02848
2018-02-03 23:48:59,712 training [INFO ] Epoch 18 Batch 1780 Training err. 2.03577 Training err. RA 2.44555 Valid. err. 2.02386
2018-02-03 23:49:00,237 training [INFO ] Epoch 18 Batch 1800 Training err. 1.98365 Training err. RA 2.44042 Valid. err. 2.03389
2018-02-03 23:49:00,746 training [INFO ] Epoch 18 Batch 1820 Training err. 1.98803 Training err. RA 2.43545 Valid. err. 2.04095
2018-02-03 23:49:01,258 training [INFO ] Epoch 18 Batch 1840 Training err. 1.99988 Training err. RA 2.43072 Valid. err. 2.03081
2018-02-03 23:49:01,771 training [INFO ] Epoch 18 Batch 1860 Training err. 1.97268 Training err. RA 2.42579 Valid. err. 2.02287
2018-02-03 23:49:02,647 training [INFO ] Epoch 19 Batch 1880 Training err. 1.98748 Training err. RA 2.42113 Valid. err. 2.01960
2018-02-03 23:49:03,165 training [INFO ] Epoch 19 Batch 1900 Training err. 1.98576 Training err. RA 2.41654 Valid. err. 2.00335
2018-02-03 23:49:03,667 training [INFO ] Epoch 19 Batch 1920 Training err. 1.96103 Training err. RA 2.41180 Valid. err. 2.02104
2018-02-03 23:49:04,168 training [INFO ] Epoch 19 Batch 1940 Training err. 1.97108 Training err. RA 2.40726 Valid. err. 2.00170
2018-02-03 23:49:04,662 training [INFO ] Epoch 19 Batch 1960 Training err. 1.95739 Training err. RA 2.40267 Valid. err. 2.00137
2018-02-03 23:49:05,500 training [INFO ] Epoch 20 Batch 1980 Training err. 1.94676 Training err. RA 2.39806 Valid. err. 1.99730
2018-02-03 23:49:06,007 training [INFO ] Epoch 20 Batch 2000 Training err. 1.98032 Training err. RA 2.39388 Valid. err. 1.98373
2018-02-03 23:49:06,508 training [INFO ] Epoch 20 Batch 2020 Training err. 1.92836 Training err. RA 2.38927 Valid. err. 1.98806
2018-02-03 23:49:07,014 training [INFO ] Epoch 20 Batch 2040 Training err. 1.93418 Training err. RA 2.38481 Valid. err. 1.97100
2018-02-03 23:49:07,515 training [INFO ] Epoch 20 Batch 2060 Training err. 1.94322 Training err. RA 2.38052 Valid. err. 1.97231
2018-02-03 23:49:08,026 training [INFO ] Epoch 20 Batch 2080 Training err. 1.93132 Training err. RA 2.37621 Valid. err. 1.99758
2018-02-03 23:49:08,909 training [INFO ] Epoch 21 Batch 2100 Training err. 1.96753 Training err. RA 2.37231 Valid. err. 1.98076
2018-02-03 23:49:09,432 training [INFO ] Epoch 21 Batch 2120 Training err. 1.89088 Training err. RA 2.36777 Valid. err. 1.97425
2018-02-03 23:49:09,952 training [INFO ] Epoch 21 Batch 2140 Training err. 1.90914 Training err. RA 2.36349 Valid. err. 1.95839
2018-02-03 23:49:10,472 training [INFO ] Epoch 21 Batch 2160 Training err. 1.93455 Training err. RA 2.35951 Valid. err. 1.96062
2018-02-03 23:49:10,986 training [INFO ] Epoch 21 Batch 2180 Training err. 1.90236 Training err. RA 2.35532 Valid. err. 1.97287
2018-02-03 23:49:11,823 training [INFO ] Epoch 22 Batch 2200 Training err. 1.93358 Training err. RA 2.35149 Valid. err. 1.97461
2018-02-03 23:49:12,325 training [INFO ] Epoch 22 Batch 2220 Training err. 1.89126 Training err. RA 2.34734 Valid. err. 1.95846
2018-02-03 23:49:12,823 training [INFO ] Epoch 22 Batch 2240 Training err. 1.89094 Training err. RA 2.34326 Valid. err. 1.96887
2018-02-03 23:49:13,322 training [INFO ] Epoch 22 Batch 2260 Training err. 1.90952 Training err. RA 2.33943 Valid. err. 1.95199
2018-02-03 23:49:13,818 training [INFO ] Epoch 22 Batch 2280 Training err. 1.88650 Training err. RA 2.33545 Valid. err. 1.92762
2018-02-03 23:49:14,666 training [INFO ] Epoch 23 Batch 2300 Training err. 1.91434 Training err. RA 2.33179 Valid. err. 1.92425
2018-02-03 23:49:15,167 training [INFO ] Epoch 23 Batch 2320 Training err. 1.87216 Training err. RA 2.32783 Valid. err. 1.94729
2018-02-03 23:49:15,666 training [INFO ] Epoch 23 Batch 2340 Training err. 1.87793 Training err. RA 2.32398 Valid. err. 1.93603
2018-02-03 23:49:16,178 training [INFO ] Epoch 23 Batch 2360 Training err. 1.88894 Training err. RA 2.32030 Valid. err. 1.93904
2018-02-03 23:49:16,684 training [INFO ] Epoch 23 Batch 2380 Training err. 1.87257 Training err. RA 2.31653 Valid. err. 1.92322
2018-02-03 23:49:17,539 training [INFO ] Epoch 24 Batch 2400 Training err. 1.86857 Training err. RA 2.31280 Valid. err. 1.91990
2018-02-03 23:49:18,048 training [INFO ] Epoch 24 Batch 2420 Training err. 1.87587 Training err. RA 2.30919 Valid. err. 1.91670
2018-02-03 23:49:18,555 training [INFO ] Epoch 24 Batch 2440 Training err. 1.86397 Training err. RA 2.30554 Valid. err. 1.93550
2018-02-03 23:49:19,068 training [INFO ] Epoch 24 Batch 2460 Training err. 1.86928 Training err. RA 2.30199 Valid. err. 1.90953
2018-02-03 23:49:19,573 training [INFO ] Epoch 24 Batch 2480 Training err. 1.86005 Training err. RA 2.29843 Valid. err. 1.91207
2018-02-03 23:49:20,419 training [INFO ] Epoch 25 Batch 2500 Training err. 1.83862 Training err. RA 2.29475 Valid. err. 1.90154
2018-02-03 23:49:20,916 training [INFO ] Epoch 25 Batch 2520 Training err. 1.87203 Training err. RA 2.29140 Valid. err. 1.89985
2018-02-03 23:49:21,414 training [INFO ] Epoch 25 Batch 2540 Training err. 1.83678 Training err. RA 2.28782 Valid. err. 1.90620
2018-02-03 23:49:21,914 training [INFO ] Epoch 25 Batch 2560 Training err. 1.84148 Training err. RA 2.28433 Valid. err. 1.89680
2018-02-03 23:49:22,412 training [INFO ] Epoch 25 Batch 2580 Training err. 1.85439 Training err. RA 2.28100 Valid. err. 1.88772
2018-02-03 23:49:22,909 training [INFO ] Epoch 25 Batch 2600 Training err. 1.82649 Training err. RA 2.27750 Valid. err. 1.89524
2018-02-03 23:49:23,741 training [INFO ] Epoch 26 Batch 2620 Training err. 1.86717 Training err. RA 2.27437 Valid. err. 1.90421
2018-02-03 23:49:24,257 training [INFO ] Epoch 26 Batch 2640 Training err. 1.80266 Training err. RA 2.27079 Valid. err. 1.89588
2018-02-03 23:49:24,769 training [INFO ] Epoch 26 Batch 2660 Training err. 1.82510 Training err. RA 2.26744 Valid. err. 1.88632
2018-02-03 23:49:25,288 training [INFO ] Epoch 26 Batch 2680 Training err. 1.84790 Training err. RA 2.26431 Valid. err. 1.88781
2018-02-03 23:49:25,802 training [INFO ] Epoch 26 Batch 2700 Training err. 1.81194 Training err. RA 2.26096 Valid. err. 1.87127
2018-02-03 23:49:26,677 training [INFO ] Epoch 27 Batch 2720 Training err. 1.83700 Training err. RA 2.25784 Valid. err. 1.89032
2018-02-03 23:49:27,193 training [INFO ] Epoch 27 Batch 2740 Training err. 1.80367 Training err. RA 2.25453 Valid. err. 1.88689
2018-02-03 23:49:27,701 training [INFO ] Epoch 27 Batch 2760 Training err. 1.80998 Training err. RA 2.25131 Valid. err. 1.88370
2018-02-03 23:49:28,206 training [INFO ] Epoch 27 Batch 2780 Training err. 1.82551 Training err. RA 2.24824 Valid. err. 1.89124
2018-02-03 23:49:28,711 training [INFO ] Epoch 27 Batch 2800 Training err. 1.80427 Training err. RA 2.24507 Valid. err. 1.86030
2018-02-03 23:49:29,549 training [INFO ] Epoch 28 Batch 2820 Training err. 1.82278 Training err. RA 2.24208 Valid. err. 1.85702
2018-02-03 23:49:30,066 training [INFO ] Epoch 28 Batch 2840 Training err. 1.79039 Training err. RA 2.23890 Valid. err. 1.88248
2018-02-03 23:49:30,567 training [INFO ] Epoch 28 Batch 2860 Training err. 1.79970 Training err. RA 2.23583 Valid. err. 1.86700
2018-02-03 23:49:31,077 training [INFO ] Epoch 28 Batch 2880 Training err. 1.81001 Training err. RA 2.23287 Valid. err. 1.86542
2018-02-03 23:49:31,579 training [INFO ] Epoch 28 Batch 2900 Training err. 1.79140 Training err. RA 2.22982 Valid. err. 1.86324
2018-02-03 23:49:32,460 training [INFO ] Epoch 29 Batch 2920 Training err. 1.79198 Training err. RA 2.22683 Valid. err. 1.84812
2018-02-03 23:49:32,984 training [INFO ] Epoch 29 Batch 2940 Training err. 1.79330 Training err. RA 2.22388 Valid. err. 1.85536
2018-02-03 23:49:33,499 training [INFO ] Epoch 29 Batch 2960 Training err. 1.78868 Training err. RA 2.22094 Valid. err. 1.85794
2018-02-03 23:49:34,024 training [INFO ] Epoch 29 Batch 2980 Training err. 1.80040 Training err. RA 2.21811 Valid. err. 1.85550
2018-02-03 23:49:34,536 training [INFO ] Epoch 29 Batch 3000 Training err. 1.77917 Training err. RA 2.21519 Valid. err. 1.83825
2018-02-03 23:49:35,395 training [INFO ] Epoch 30 Batch 3020 Training err. 1.76424 Training err. RA 2.21220 Valid. err. 1.84178
2018-02-03 23:49:35,903 training [INFO ] Epoch 30 Batch 3040 Training err. 1.79399 Training err. RA 2.20945 Valid. err. 1.84017
2018-02-03 23:49:36,409 training [INFO ] Epoch 30 Batch 3060 Training err. 1.76459 Training err. RA 2.20654 Valid. err. 1.84605
2018-02-03 23:49:36,912 training [INFO ] Epoch 30 Batch 3080 Training err. 1.77120 Training err. RA 2.20372 Valid. err. 1.82919
2018-02-03 23:49:37,418 training [INFO ] Epoch 30 Batch 3100 Training err. 1.77749 Training err. RA 2.20097 Valid. err. 1.83716
2018-02-03 23:49:37,917 training [INFO ] Epoch 30 Batch 3120 Training err. 1.75797 Training err. RA 2.19813 Valid. err. 1.81881
2018-02-03 23:49:38,775 training [INFO ] Epoch 31 Batch 3140 Training err. 1.79257 Training err. RA 2.19554 Valid. err. 1.83624
2018-02-03 23:49:39,285 training [INFO ] Epoch 31 Batch 3160 Training err. 1.73028 Training err. RA 2.19260 Valid. err. 1.83625
2018-02-03 23:49:39,802 training [INFO ] Epoch 31 Batch 3180 Training err. 1.75690 Training err. RA 2.18986 Valid. err. 1.84285
2018-02-03 23:49:40,328 training [INFO ] Epoch 31 Batch 3200 Training err. 1.77329 Training err. RA 2.18725 Valid. err. 1.82432
2018-02-03 23:49:40,841 training [INFO ] Epoch 31 Batch 3220 Training err. 1.74962 Training err. RA 2.18454 Valid. err. 1.82212
2018-02-03 23:49:41,705 training [INFO ] Epoch 32 Batch 3240 Training err. 1.76561 Training err. RA 2.18195 Valid. err. 1.83215
2018-02-03 23:49:42,220 training [INFO ] Epoch 32 Batch 3260 Training err. 1.73445 Training err. RA 2.17920 Valid. err. 1.82915
2018-02-03 23:49:42,739 training [INFO ] Epoch 32 Batch 3280 Training err. 1.74098 Training err. RA 2.17653 Valid. err. 1.83029
2018-02-03 23:49:43,255 training [INFO ] Epoch 32 Batch 3300 Training err. 1.76089 Training err. RA 2.17401 Valid. err. 1.80887
2018-02-03 23:49:43,760 training [INFO ] Epoch 32 Batch 3320 Training err. 1.73945 Training err. RA 2.17140 Valid. err. 1.82130
2018-02-03 23:49:44,605 training [INFO ] Epoch 33 Batch 3340 Training err. 1.75771 Training err. RA 2.16892 Valid. err. 1.80922
2018-02-03 23:49:45,114 training [INFO ] Epoch 33 Batch 3360 Training err. 1.72482 Training err. RA 2.16627 Valid. err. 1.82342
2018-02-03 23:49:45,612 training [INFO ] Epoch 33 Batch 3380 Training err. 1.73295 Training err. RA 2.16371 Valid. err. 1.80988
2018-02-03 23:49:46,119 training [INFO ] Epoch 33 Batch 3400 Training err. 1.74865 Training err. RA 2.16127 Valid. err. 1.81198
2018-02-03 23:49:46,621 training [INFO ] Epoch 33 Batch 3420 Training err. 1.73054 Training err. RA 2.15875 Valid. err. 1.80234
2018-02-03 23:49:47,460 training [INFO ] Epoch 34 Batch 3440 Training err. 1.72514 Training err. RA 2.15623 Valid. err. 1.81998
2018-02-03 23:49:47,985 training [INFO ] Epoch 34 Batch 3460 Training err. 1.73670 Training err. RA 2.15380 Valid. err. 1.80602
2018-02-03 23:49:48,502 training [INFO ] Epoch 34 Batch 3480 Training err. 1.72567 Training err. RA 2.15134 Valid. err. 1.79901
2018-02-03 23:49:49,020 training [INFO ] Epoch 34 Batch 3500 Training err. 1.73565 Training err. RA 2.14897 Valid. err. 1.79296
2018-02-03 23:49:49,536 training [INFO ] Epoch 34 Batch 3520 Training err. 1.72394 Training err. RA 2.14655 Valid. err. 1.80904
2018-02-03 23:49:50,415 training [INFO ] Epoch 35 Batch 3540 Training err. 1.70588 Training err. RA 2.14406 Valid. err. 1.78751
2018-02-03 23:49:50,928 training [INFO ] Epoch 35 Batch 3560 Training err. 1.73353 Training err. RA 2.14176 Valid. err. 1.79166
2018-02-03 23:49:51,444 training [INFO ] Epoch 35 Batch 3580 Training err. 1.70464 Training err. RA 2.13932 Valid. err. 1.79329
2018-02-03 23:49:51,946 training [INFO ] Epoch 35 Batch 3600 Training err. 1.70983 Training err. RA 2.13693 Valid. err. 1.79402
2018-02-03 23:49:52,446 training [INFO ] Epoch 35 Batch 3620 Training err. 1.72364 Training err. RA 2.13465 Valid. err. 1.78868
2018-02-03 23:49:52,939 training [INFO ] Epoch 35 Batch 3640 Training err. 1.70247 Training err. RA 2.13227 Valid. err. 1.78553
2018-02-03 23:49:53,773 training [INFO ] Epoch 36 Batch 3660 Training err. 1.73382 Training err. RA 2.13009 Valid. err. 1.79503
2018-02-03 23:49:54,285 training [INFO ] Epoch 36 Batch 3680 Training err. 1.67269 Training err. RA 2.12761 Valid. err. 1.78858
2018-02-03 23:49:54,787 training [INFO ] Epoch 36 Batch 3700 Training err. 1.70013 Training err. RA 2.12530 Valid. err. 1.78582
2018-02-03 23:49:55,291 training [INFO ] Epoch 36 Batch 3720 Training err. 1.72202 Training err. RA 2.12313 Valid. err. 1.77994
2018-02-03 23:49:55,802 training [INFO ] Epoch 36 Batch 3740 Training err. 1.69542 Training err. RA 2.12084 Valid. err. 1.77551
2018-02-03 23:49:56,678 training [INFO ] Epoch 37 Batch 3760 Training err. 1.70885 Training err. RA 2.11865 Valid. err. 1.78848
2018-02-03 23:49:57,197 training [INFO ] Epoch 37 Batch 3780 Training err. 1.67985 Training err. RA 2.11633 Valid. err. 1.78404
2018-02-03 23:49:57,710 training [INFO ] Epoch 37 Batch 3800 Training err. 1.68819 Training err. RA 2.11408 Valid. err. 1.79030
2018-02-03 23:49:58,226 training [INFO ] Epoch 37 Batch 3820 Training err. 1.70548 Training err. RA 2.11194 Valid. err. 1.76462
2018-02-03 23:49:58,742 training [INFO ] Epoch 37 Batch 3840 Training err. 1.69402 Training err. RA 2.10976 Valid. err. 1.78237
2018-02-03 23:49:59,598 training [INFO ] Epoch 38 Batch 3860 Training err. 1.70385 Training err. RA 2.10766 Valid. err. 1.76900
2018-02-03 23:50:00,116 training [INFO ] Epoch 38 Batch 3880 Training err. 1.67121 Training err. RA 2.10541 Valid. err. 1.77826
2018-02-03 23:50:00,615 training [INFO ] Epoch 38 Batch 3900 Training err. 1.68108 Training err. RA 2.10323 Valid. err. 1.77294
2018-02-03 23:50:01,121 training [INFO ] Epoch 38 Batch 3920 Training err. 1.69942 Training err. RA 2.10117 Valid. err. 1.77896
2018-02-03 23:50:01,613 training [INFO ] Epoch 38 Batch 3940 Training err. 1.68478 Training err. RA 2.09906 Valid. err. 1.77181
2018-02-03 23:50:02,463 training [INFO ] Epoch 39 Batch 3960 Training err. 1.67379 Training err. RA 2.09691 Valid. err. 1.75900
2018-02-03 23:50:02,954 training [INFO ] Epoch 39 Batch 3980 Training err. 1.67768 Training err. RA 2.09480 Valid. err. 1.77007
2018-02-03 23:50:03,454 training [INFO ] Epoch 39 Batch 4000 Training err. 1.67657 Training err. RA 2.09271 Valid. err. 1.76564
2018-02-03 23:50:03,965 training [INFO ] Epoch 39 Batch 4020 Training err. 1.68683 Training err. RA 2.09069 Valid. err. 1.75708
2018-02-03 23:50:04,479 training [INFO ] Epoch 39 Batch 4040 Training err. 1.67382 Training err. RA 2.08863 Valid. err. 1.76446
2018-02-03 23:50:05,339 training [INFO ] Epoch 40 Batch 4060 Training err. 1.65594 Training err. RA 2.08650 Valid. err. 1.75292
2018-02-03 23:50:05,856 training [INFO ] Epoch 40 Batch 4080 Training err. 1.68198 Training err. RA 2.08451 Valid. err. 1.75530
2018-02-03 23:50:06,375 training [INFO ] Epoch 40 Batch 4100 Training err. 1.65895 Training err. RA 2.08244 Valid. err. 1.75123
2018-02-03 23:50:06,892 training [INFO ] Epoch 40 Batch 4120 Training err. 1.66270 Training err. RA 2.08040 Valid. err. 1.76400
2018-02-03 23:50:07,406 training [INFO ] Epoch 40 Batch 4140 Training err. 1.67388 Training err. RA 2.07844 Valid. err. 1.75233
2018-02-03 23:50:07,904 training [INFO ] Epoch 40 Batch 4160 Training err. 1.65547 Training err. RA 2.07640 Valid. err. 1.74289
2018-02-03 23:50:08,751 training [INFO ] Epoch 41 Batch 4180 Training err. 1.68544 Training err. RA 2.07453 Valid. err. 1.75853
2018-02-03 23:50:09,252 training [INFO ] Epoch 41 Batch 4200 Training err. 1.62822 Training err. RA 2.07241 Valid. err. 1.75282
2018-02-03 23:50:09,758 training [INFO ] Epoch 41 Batch 4220 Training err. 1.65675 Training err. RA 2.07044 Valid. err. 1.74884
2018-02-03 23:50:10,261 training [INFO ] Epoch 41 Batch 4240 Training err. 1.67225 Training err. RA 2.06856 Valid. err. 1.74137
2018-02-03 23:50:10,758 training [INFO ] Epoch 41 Batch 4260 Training err. 1.64865 Training err. RA 2.06659 Valid. err. 1.74308
2018-02-03 23:50:11,595 training [INFO ] Epoch 42 Batch 4280 Training err. 1.66394 Training err. RA 2.06471 Valid. err. 1.75002
2018-02-03 23:50:12,108 training [INFO ] Epoch 42 Batch 4300 Training err. 1.63752 Training err. RA 2.06272 Valid. err. 1.74827
2018-02-03 23:50:12,620 training [INFO ] Epoch 42 Batch 4320 Training err. 1.64729 Training err. RA 2.06080 Valid. err. 1.75253
2018-02-03 23:50:13,127 training [INFO ] Epoch 42 Batch 4340 Training err. 1.65997 Training err. RA 2.05895 Valid. err. 1.73636
2018-02-03 23:50:13,636 training [INFO ] Epoch 42 Batch 4360 Training err. 1.64440 Training err. RA 2.05705 Valid. err. 1.73531
2018-02-03 23:50:14,510 training [INFO ] Epoch 43 Batch 4380 Training err. 1.65713 Training err. RA 2.05522 Valid. err. 1.73880
2018-02-03 23:50:15,024 training [INFO ] Epoch 43 Batch 4400 Training err. 1.63185 Training err. RA 2.05330 Valid. err. 1.75088
2018-02-03 23:50:15,526 training [INFO ] Epoch 43 Batch 4420 Training err. 1.64010 Training err. RA 2.05143 Valid. err. 1.74099
2018-02-03 23:50:16,027 training [INFO ] Epoch 43 Batch 4440 Training err. 1.65225 Training err. RA 2.04963 Valid. err. 1.74425
2018-02-03 23:50:16,524 training [INFO ] Epoch 43 Batch 4460 Training err. 1.63742 Training err. RA 2.04778 Valid. err. 1.74364
2018-02-03 23:50:17,360 training [INFO ] Epoch 44 Batch 4480 Training err. 1.63207 Training err. RA 2.04592 Valid. err. 1.72057
2018-02-03 23:50:17,858 training [INFO ] Epoch 44 Batch 4500 Training err. 1.63532 Training err. RA 2.04410 Valid. err. 1.74099
2018-02-03 23:50:18,362 training [INFO ] Epoch 44 Batch 4520 Training err. 1.63640 Training err. RA 2.04230 Valid. err. 1.74407
2018-02-03 23:50:18,861 training [INFO ] Epoch 44 Batch 4540 Training err. 1.64541 Training err. RA 2.04055 Valid. err. 1.72744
2018-02-03 23:50:19,365 training [INFO ] Epoch 44 Batch 4560 Training err. 1.63032 Training err. RA 2.03875 Valid. err. 1.72701
2018-02-03 23:50:20,244 training [INFO ] Epoch 45 Batch 4580 Training err. 1.61427 Training err. RA 2.03689 Valid. err. 1.72579
2018-02-03 23:50:20,756 training [INFO ] Epoch 45 Batch 4600 Training err. 1.63968 Training err. RA 2.03517 Valid. err. 1.72367
2018-02-03 23:50:21,271 training [INFO ] Epoch 45 Batch 4620 Training err. 1.61978 Training err. RA 2.03337 Valid. err. 1.71822
2018-02-03 23:50:21,786 training [INFO ] Epoch 45 Batch 4640 Training err. 1.62233 Training err. RA 2.03160 Valid. err. 1.72447
2018-02-03 23:50:22,303 training [INFO ] Epoch 45 Batch 4660 Training err. 1.63189 Training err. RA 2.02988 Valid. err. 1.72672
2018-02-03 23:50:22,815 training [INFO ] Epoch 45 Batch 4680 Training err. 1.61359 Training err. RA 2.02810 Valid. err. 1.71454
2018-02-03 23:50:23,665 training [INFO ] Epoch 46 Batch 4700 Training err. 1.64741 Training err. RA 2.02648 Valid. err. 1.72564
2018-02-03 23:50:24,161 training [INFO ] Epoch 46 Batch 4720 Training err. 1.58895 Training err. RA 2.02463 Valid. err. 1.72465
2018-02-03 23:50:24,661 training [INFO ] Epoch 46 Batch 4740 Training err. 1.61645 Training err. RA 2.02291 Valid. err. 1.73287
2018-02-03 23:50:25,159 training [INFO ] Epoch 46 Batch 4760 Training err. 1.63629 Training err. RA 2.02128 Valid. err. 1.71253
2018-02-03 23:50:25,653 training [INFO ] Epoch 46 Batch 4780 Training err. 1.60773 Training err. RA 2.01955 Valid. err. 1.71516
2018-02-03 23:50:26,505 training [INFO ] Epoch 47 Batch 4800 Training err. 1.62582 Training err. RA 2.01791 Valid. err. 1.72479
2018-02-03 23:50:27,012 training [INFO ] Epoch 47 Batch 4820 Training err. 1.59999 Training err. RA 2.01618 Valid. err. 1.71917
2018-02-03 23:50:27,517 training [INFO ] Epoch 47 Batch 4840 Training err. 1.60599 Training err. RA 2.01448 Valid. err. 1.71459
2018-02-03 23:50:28,036 training [INFO ] Epoch 47 Batch 4860 Training err. 1.62320 Training err. RA 2.01287 Valid. err. 1.72659
2018-02-03 23:50:28,548 training [INFO ] Epoch 47 Batch 4880 Training err. 1.60902 Training err. RA 2.01122 Valid. err. 1.70809
2018-02-03 23:50:29,414 training [INFO ] Epoch 48 Batch 4900 Training err. 1.61883 Training err. RA 2.00962 Valid. err. 1.71783
2018-02-03 23:50:29,938 training [INFO ] Epoch 48 Batch 4920 Training err. 1.59574 Training err. RA 2.00793 Valid. err. 1.72213
2018-02-03 23:50:30,459 training [INFO ] Epoch 48 Batch 4940 Training err. 1.59977 Training err. RA 2.00628 Valid. err. 1.70954
2018-02-03 23:50:30,985 training [INFO ] Epoch 48 Batch 4960 Training err. 1.61696 Training err. RA 2.00471 Valid. err. 1.72372
2018-02-03 23:50:31,501 training [INFO ] Epoch 48 Batch 4980 Training err. 1.59958 Training err. RA 2.00308 Valid. err. 1.71518
2018-02-03 23:50:32,362 training [INFO ] Epoch 49 Batch 5000 Training err. 1.60072 Training err. RA 2.00147 Valid. err. 1.69115
2018-02-03 23:50:32,862 training [INFO ] Epoch 49 Batch 5020 Training err. 1.60092 Training err. RA 1.99988 Valid. err. 1.71453
2018-02-03 23:50:33,371 training [INFO ] Epoch 49 Batch 5040 Training err. 1.59932 Training err. RA 1.99829 Valid. err. 1.70489
2018-02-03 23:50:33,877 training [INFO ] Epoch 49 Batch 5060 Training err. 1.61066 Training err. RA 1.99676 Valid. err. 1.70107
2018-02-03 23:50:34,388 training [INFO ] Epoch 49 Batch 5080 Training err. 1.59148 Training err. RA 1.99516 Valid. err. 1.69384
2018-02-03 23:50:35,229 training [INFO ] Epoch 50 Batch 5100 Training err. 1.58113 Training err. RA 1.99354 Valid. err. 1.70222
2018-02-03 23:50:35,733 training [INFO ] Epoch 50 Batch 5120 Training err. 1.60433 Training err. RA 1.99202 Valid. err. 1.69771
2018-02-03 23:50:36,238 training [INFO ] Epoch 50 Batch 5140 Training err. 1.58445 Training err. RA 1.99043 Valid. err. 1.69485
2018-02-03 23:50:36,742 training [INFO ] Epoch 50 Batch 5160 Training err. 1.58749 Training err. RA 1.98887 Valid. err. 1.70586
2018-02-03 23:50:37,245 training [INFO ] Epoch 50 Batch 5180 Training err. 1.60011 Training err. RA 1.98737 Valid. err. 1.70056
2018-02-03 23:50:37,748 training [INFO ] Epoch 50 Batch 5200 Training err. 1.57935 Training err. RA 1.98580 Valid. err. 1.68494
2018-02-03 23:50:38,609 training [INFO ] Epoch 51 Batch 5220 Training err. 1.61126 Training err. RA 1.98436 Valid. err. 1.70986
2018-02-03 23:50:39,112 training [INFO ] Epoch 51 Batch 5240 Training err. 1.55502 Training err. RA 1.98273 Valid. err. 1.69901
2018-02-03 23:50:39,615 training [INFO ] Epoch 51 Batch 5260 Training err. 1.58338 Training err. RA 1.98121 Valid. err. 1.70089
2018-02-03 23:50:40,132 training [INFO ] Epoch 51 Batch 5280 Training err. 1.59752 Training err. RA 1.97975 Valid. err. 1.69038
2018-02-03 23:50:40,648 training [INFO ] Epoch 51 Batch 5300 Training err. 1.57499 Training err. RA 1.97823 Valid. err. 1.69022
2018-02-03 23:50:41,504 training [INFO ] Epoch 52 Batch 5320 Training err. 1.59820 Training err. RA 1.97680 Valid. err. 1.69438
2018-02-03 23:50:42,025 training [INFO ] Epoch 52 Batch 5340 Training err. 1.56697 Training err. RA 1.97526 Valid. err. 1.69301
2018-02-03 23:50:42,538 training [INFO ] Epoch 52 Batch 5360 Training err. 1.57398 Training err. RA 1.97377 Valid. err. 1.69153
2018-02-03 23:50:43,063 training [INFO ] Epoch 52 Batch 5380 Training err. 1.58940 Training err. RA 1.97234 Valid. err. 1.68446
2018-02-03 23:50:43,572 training [INFO ] Epoch 52 Batch 5400 Training err. 1.57215 Training err. RA 1.97085 Valid. err. 1.68766
2018-02-03 23:50:44,425 training [INFO ] Epoch 53 Batch 5420 Training err. 1.58495 Training err. RA 1.96943 Valid. err. 1.67210
2018-02-03 23:50:44,932 training [INFO ] Epoch 53 Batch 5440 Training err. 1.56558 Training err. RA 1.96795 Valid. err. 1.69248
2018-02-03 23:50:45,440 training [INFO ] Epoch 53 Batch 5460 Training err. 1.56923 Training err. RA 1.96648 Valid. err. 1.68669
2018-02-03 23:50:45,938 training [INFO ] Epoch 53 Batch 5480 Training err. 1.58816 Training err. RA 1.96510 Valid. err. 1.69688
2018-02-03 23:50:46,440 training [INFO ] Epoch 53 Batch 5500 Training err. 1.56844 Training err. RA 1.96366 Valid. err. 1.69136
2018-02-03 23:50:47,342 training [INFO ] Epoch 54 Batch 5520 Training err. 1.56425 Training err. RA 1.96221 Valid. err. 1.67295
2018-02-03 23:50:47,851 training [INFO ] Epoch 54 Batch 5540 Training err. 1.56958 Training err. RA 1.96080 Valid. err. 1.69409
2018-02-03 23:50:48,363 training [INFO ] Epoch 54 Batch 5560 Training err. 1.56977 Training err. RA 1.95939 Valid. err. 1.68721
2018-02-03 23:50:48,872 training [INFO ] Epoch 54 Batch 5580 Training err. 1.58315 Training err. RA 1.95804 Valid. err. 1.68045
2018-02-03 23:50:49,392 training [INFO ] Epoch 54 Batch 5600 Training err. 1.55978 Training err. RA 1.95662 Valid. err. 1.67796
2018-02-03 23:50:50,273 training [INFO ] Epoch 55 Batch 5620 Training err. 1.55231 Training err. RA 1.95518 Valid. err. 1.69128
2018-02-03 23:50:50,795 training [INFO ] Epoch 55 Batch 5640 Training err. 1.57636 Training err. RA 1.95384 Valid. err. 1.67193
2018-02-03 23:50:51,308 training [INFO ] Epoch 55 Batch 5660 Training err. 1.55490 Training err. RA 1.95243 Valid. err. 1.67309
2018-02-03 23:50:51,809 training [INFO ] Epoch 55 Batch 5680 Training err. 1.55761 Training err. RA 1.95104 Valid. err. 1.67918
2018-02-03 23:50:52,312 training [INFO ] Epoch 55 Batch 5700 Training err. 1.57124 Training err. RA 1.94971 Valid. err. 1.68057
2018-02-03 23:50:52,812 training [INFO ] Epoch 55 Batch 5720 Training err. 1.54826 Training err. RA 1.94830 Valid. err. 1.66601
2018-02-03 23:50:53,642 training [INFO ] Epoch 56 Batch 5740 Training err. 1.58247 Training err. RA 1.94703 Valid. err. 1.68537
2018-02-03 23:50:54,143 training [INFO ] Epoch 56 Batch 5760 Training err. 1.52594 Training err. RA 1.94556 Valid. err. 1.68451
2018-02-03 23:50:54,640 training [INFO ] Epoch 56 Batch 5780 Training err. 1.55611 Training err. RA 1.94422 Valid. err. 1.68379
2018-02-03 23:50:55,147 training [INFO ] Epoch 56 Batch 5800 Training err. 1.56781 Training err. RA 1.94292 Valid. err. 1.67457
2018-02-03 23:50:55,650 training [INFO ] Epoch 56 Batch 5820 Training err. 1.54548 Training err. RA 1.94155 Valid. err. 1.66889
2018-02-03 23:50:56,533 training [INFO ] Epoch 57 Batch 5840 Training err. 1.56258 Training err. RA 1.94026 Valid. err. 1.69059
2018-02-03 23:50:57,054 training [INFO ] Epoch 57 Batch 5860 Training err. 1.54364 Training err. RA 1.93890 Valid. err. 1.67448
2018-02-03 23:50:57,571 training [INFO ] Epoch 57 Batch 5880 Training err. 1.54570 Training err. RA 1.93756 Valid. err. 1.67009
2018-02-03 23:50:58,093 training [INFO ] Epoch 57 Batch 5900 Training err. 1.56403 Training err. RA 1.93630 Valid. err. 1.66569
2018-02-03 23:50:58,603 training [INFO ] Epoch 57 Batch 5920 Training err. 1.54354 Training err. RA 1.93497 Valid. err. 1.67205
2018-02-03 23:50:59,467 training [INFO ] Epoch 58 Batch 5940 Training err. 1.55776 Training err. RA 1.93370 Valid. err. 1.65300
2018-02-03 23:50:59,972 training [INFO ] Epoch 58 Batch 5960 Training err. 1.53880 Training err. RA 1.93238 Valid. err. 1.67182
2018-02-03 23:51:00,485 training [INFO ] Epoch 58 Batch 5980 Training err. 1.54065 Training err. RA 1.93107 Valid. err. 1.66537
2018-02-03 23:51:00,993 training [INFO ] Epoch 58 Batch 6000 Training err. 1.55987 Training err. RA 1.92983 Valid. err. 1.67726
2018-02-03 23:51:01,497 training [INFO ] Epoch 58 Batch 6020 Training err. 1.54077 Training err. RA 1.92854 Valid. err. 1.66903
2018-02-03 23:51:02,357 training [INFO ] Epoch 59 Batch 6040 Training err. 1.53821 Training err. RA 1.92724 Valid. err. 1.65573
2018-02-03 23:51:02,860 training [INFO ] Epoch 59 Batch 6060 Training err. 1.54195 Training err. RA 1.92597 Valid. err. 1.67514
2018-02-03 23:51:03,369 training [INFO ] Epoch 59 Batch 6080 Training err. 1.54195 Training err. RA 1.92471 Valid. err. 1.67194
2018-02-03 23:51:03,884 training [INFO ] Epoch 59 Batch 6100 Training err. 1.55494 Training err. RA 1.92350 Valid. err. 1.66308
2018-02-03 23:51:04,405 training [INFO ] Epoch 59 Batch 6120 Training err. 1.53278 Training err. RA 1.92222 Valid. err. 1.65860
2018-02-03 23:51:05,268 training [INFO ] Epoch 60 Batch 6140 Training err. 1.52507 Training err. RA 1.92093 Valid. err. 1.67518
2018-02-03 23:51:05,791 training [INFO ] Epoch 60 Batch 6160 Training err. 1.54854 Training err. RA 1.91972 Valid. err. 1.65908
2018-02-03 23:51:06,307 training [INFO ] Epoch 60 Batch 6180 Training err. 1.52800 Training err. RA 1.91845 Valid. err. 1.65543
2018-02-03 23:51:06,881 training [INFO ] Epoch 60 Batch 6200 Training err. 1.53232 Training err. RA 1.91720 Valid. err. 1.66234
2018-02-03 23:51:07,398 training [INFO ] Epoch 60 Batch 6220 Training err. 1.54488 Training err. RA 1.91601 Valid. err. 1.66483
2018-02-03 23:51:07,900 training [INFO ] Epoch 60 Batch 6240 Training err. 1.52322 Training err. RA 1.91475 Valid. err. 1.64973
2018-02-03 23:51:08,144 __main__ [INFO ] End of training
2018-02-03 23:51:08,381 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 10,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 23:51:08,381 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 74
2018-02-03 23:51:09,025 training [INFO ] Epoch  1 Batch   20 Training err. 6.86979 Training err. RA 6.86979 Valid. err. 5.23495
2018-02-03 23:51:09,522 training [INFO ] Epoch  1 Batch   40 Training err. 5.43110 Training err. RA 6.15044 Valid. err. 6.48231
2018-02-03 23:51:10,047 training [INFO ] Epoch  1 Batch   60 Training err. 4.64479 Training err. RA 5.64856 Valid. err. 4.66602
2018-02-03 23:51:10,602 training [INFO ] Epoch  1 Batch   80 Training err. 4.37707 Training err. RA 5.33069 Valid. err. 4.82431
2018-02-03 23:51:11,115 training [INFO ] Epoch  1 Batch  100 Training err. 3.96628 Training err. RA 5.05781 Valid. err. 3.26173
2018-02-03 23:51:11,962 training [INFO ] Epoch  2 Batch  120 Training err. 3.94596 Training err. RA 4.87250 Valid. err. 3.14812
2018-02-03 23:51:12,471 training [INFO ] Epoch  2 Batch  140 Training err. 3.26824 Training err. RA 4.64332 Valid. err. 3.16011
2018-02-03 23:51:12,983 training [INFO ] Epoch  2 Batch  160 Training err. 3.16870 Training err. RA 4.45899 Valid. err. 3.36296
2018-02-03 23:51:13,494 training [INFO ] Epoch  2 Batch  180 Training err. 3.27175 Training err. RA 4.32708 Valid. err. 3.07677
2018-02-03 23:51:14,002 training [INFO ] Epoch  2 Batch  200 Training err. 3.12659 Training err. RA 4.20703 Valid. err. 3.13063
2018-02-03 23:51:14,875 training [INFO ] Epoch  3 Batch  220 Training err. 3.13350 Training err. RA 4.10943 Valid. err. 3.16886
2018-02-03 23:51:15,388 training [INFO ] Epoch  3 Batch  240 Training err. 3.06136 Training err. RA 4.02209 Valid. err. 3.41372
2018-02-03 23:51:15,886 training [INFO ] Epoch  3 Batch  260 Training err. 2.95915 Training err. RA 3.94033 Valid. err. 2.87520
2018-02-03 23:51:16,392 training [INFO ] Epoch  3 Batch  280 Training err. 3.09275 Training err. RA 3.87979 Valid. err. 3.23598
2018-02-03 23:51:16,888 training [INFO ] Epoch  3 Batch  300 Training err. 2.89978 Training err. RA 3.81445 Valid. err. 2.98416
2018-02-03 23:51:17,718 training [INFO ] Epoch  4 Batch  320 Training err. 3.03473 Training err. RA 3.76572 Valid. err. 2.85844
2018-02-03 23:51:18,235 training [INFO ] Epoch  4 Batch  340 Training err. 2.86996 Training err. RA 3.71303 Valid. err. 3.28802
2018-02-03 23:51:18,733 training [INFO ] Epoch  4 Batch  360 Training err. 2.85029 Training err. RA 3.66510 Valid. err. 2.81019
2018-02-03 23:51:19,235 training [INFO ] Epoch  4 Batch  380 Training err. 2.72989 Training err. RA 3.61588 Valid. err. 2.67957
2018-02-03 23:51:19,738 training [INFO ] Epoch  4 Batch  400 Training err. 2.75235 Training err. RA 3.57270 Valid. err. 2.77522
2018-02-03 23:51:20,607 training [INFO ] Epoch  5 Batch  420 Training err. 2.80343 Training err. RA 3.53607 Valid. err. 2.61294
2018-02-03 23:51:21,120 training [INFO ] Epoch  5 Batch  440 Training err. 2.65532 Training err. RA 3.49604 Valid. err. 2.81042
2018-02-03 23:51:21,633 training [INFO ] Epoch  5 Batch  460 Training err. 2.65150 Training err. RA 3.45932 Valid. err. 2.63603
2018-02-03 23:51:22,152 training [INFO ] Epoch  5 Batch  480 Training err. 2.57849 Training err. RA 3.42261 Valid. err. 2.56236
2018-02-03 23:51:22,668 training [INFO ] Epoch  5 Batch  500 Training err. 2.49186 Training err. RA 3.38538 Valid. err. 2.58647
2018-02-03 23:51:23,186 training [INFO ] Epoch  5 Batch  520 Training err. 2.52254 Training err. RA 3.35220 Valid. err. 2.42905
2018-02-03 23:51:24,024 training [INFO ] Epoch  6 Batch  540 Training err. 2.50313 Training err. RA 3.32075 Valid. err. 2.52653
2018-02-03 23:51:24,523 training [INFO ] Epoch  6 Batch  560 Training err. 2.49193 Training err. RA 3.29115 Valid. err. 2.45927
2018-02-03 23:51:25,027 training [INFO ] Epoch  6 Batch  580 Training err. 2.40049 Training err. RA 3.26044 Valid. err. 2.43431
2018-02-03 23:51:25,534 training [INFO ] Epoch  6 Batch  600 Training err. 2.41687 Training err. RA 3.23232 Valid. err. 2.41518
2018-02-03 23:51:26,037 training [INFO ] Epoch  6 Batch  620 Training err. 2.38103 Training err. RA 3.20486 Valid. err. 2.38608
2018-02-03 23:51:26,893 training [INFO ] Epoch  7 Batch  640 Training err. 2.37675 Training err. RA 3.17898 Valid. err. 2.33914
2018-02-03 23:51:27,393 training [INFO ] Epoch  7 Batch  660 Training err. 2.46227 Training err. RA 3.15726 Valid. err. 2.38484
2018-02-03 23:51:27,906 training [INFO ] Epoch  7 Batch  680 Training err. 2.34209 Training err. RA 3.13329 Valid. err. 2.36910
2018-02-03 23:51:28,421 training [INFO ] Epoch  7 Batch  700 Training err. 2.32949 Training err. RA 3.11032 Valid. err. 2.29554
2018-02-03 23:51:28,934 training [INFO ] Epoch  7 Batch  720 Training err. 2.30865 Training err. RA 3.08805 Valid. err. 2.31604
2018-02-03 23:51:29,791 training [INFO ] Epoch  8 Batch  740 Training err. 2.39902 Training err. RA 3.06943 Valid. err. 2.38152
2018-02-03 23:51:30,306 training [INFO ] Epoch  8 Batch  760 Training err. 2.28786 Training err. RA 3.04886 Valid. err. 2.35575
2018-02-03 23:51:30,815 training [INFO ] Epoch  8 Batch  780 Training err. 2.28584 Training err. RA 3.02930 Valid. err. 2.29370
2018-02-03 23:51:31,334 training [INFO ] Epoch  8 Batch  800 Training err. 2.25680 Training err. RA 3.00998 Valid. err. 2.25977
2018-02-03 23:51:31,982 training [INFO ] Epoch  8 Batch  820 Training err. 2.24553 Training err. RA 2.99134 Valid. err. 2.24536
2018-02-03 23:51:33,143 training [INFO ] Epoch  9 Batch  840 Training err. 2.30036 Training err. RA 2.97489 Valid. err. 2.29690
2018-02-03 23:51:33,821 training [INFO ] Epoch  9 Batch  860 Training err. 2.25658 Training err. RA 2.95818 Valid. err. 2.31887
2018-02-03 23:51:34,530 training [INFO ] Epoch  9 Batch  880 Training err. 2.23234 Training err. RA 2.94169 Valid. err. 2.24542
2018-02-03 23:51:35,232 training [INFO ] Epoch  9 Batch  900 Training err. 2.20187 Training err. RA 2.92525 Valid. err. 2.21595
2018-02-03 23:51:35,850 training [INFO ] Epoch  9 Batch  920 Training err. 2.20469 Training err. RA 2.90958 Valid. err. 2.20769
2018-02-03 23:51:36,774 training [INFO ] Epoch 10 Batch  940 Training err. 2.20890 Training err. RA 2.89467 Valid. err. 2.22115
2018-02-03 23:51:37,284 training [INFO ] Epoch 10 Batch  960 Training err. 2.22908 Training err. RA 2.88081 Valid. err. 2.19250
2018-02-03 23:51:37,786 training [INFO ] Epoch 10 Batch  980 Training err. 2.15514 Training err. RA 2.86600 Valid. err. 2.17658
2018-02-03 23:51:38,290 training [INFO ] Epoch 10 Batch 1000 Training err. 2.17312 Training err. RA 2.85214 Valid. err. 2.15931
2018-02-03 23:51:38,794 training [INFO ] Epoch 10 Batch 1020 Training err. 2.14149 Training err. RA 2.83821 Valid. err. 2.14653
2018-02-03 23:51:39,304 training [INFO ] Epoch 10 Batch 1040 Training err. 2.14838 Training err. RA 2.82494 Valid. err. 2.13978
2018-02-03 23:51:40,173 training [INFO ] Epoch 11 Batch 1060 Training err. 2.20667 Training err. RA 2.81327 Valid. err. 2.18033
2018-02-03 23:51:40,686 training [INFO ] Epoch 11 Batch 1080 Training err. 2.11393 Training err. RA 2.80032 Valid. err. 2.14497
2018-02-03 23:51:41,200 training [INFO ] Epoch 11 Batch 1100 Training err. 2.12881 Training err. RA 2.78811 Valid. err. 2.13202
2018-02-03 23:51:41,716 training [INFO ] Epoch 11 Batch 1120 Training err. 2.11308 Training err. RA 2.77606 Valid. err. 2.13064
2018-02-03 23:51:42,234 training [INFO ] Epoch 11 Batch 1140 Training err. 2.13269 Training err. RA 2.76477 Valid. err. 2.10098
2018-02-03 23:51:43,096 training [INFO ] Epoch 12 Batch 1160 Training err. 2.13329 Training err. RA 2.75388 Valid. err. 2.15583
2018-02-03 23:51:43,604 training [INFO ] Epoch 12 Batch 1180 Training err. 2.08884 Training err. RA 2.74261 Valid. err. 2.13837
2018-02-03 23:51:44,110 training [INFO ] Epoch 12 Batch 1200 Training err. 2.09305 Training err. RA 2.73179 Valid. err. 2.13516
2018-02-03 23:51:44,608 training [INFO ] Epoch 12 Batch 1220 Training err. 2.09008 Training err. RA 2.72127 Valid. err. 2.07713
2018-02-03 23:51:45,131 training [INFO ] Epoch 12 Batch 1240 Training err. 2.06495 Training err. RA 2.71068 Valid. err. 2.12489
2018-02-03 23:51:46,001 training [INFO ] Epoch 13 Batch 1260 Training err. 2.09506 Training err. RA 2.70091 Valid. err. 2.14538
2018-02-03 23:51:46,515 training [INFO ] Epoch 13 Batch 1280 Training err. 2.06336 Training err. RA 2.69095 Valid. err. 2.10286
2018-02-03 23:51:47,026 training [INFO ] Epoch 13 Batch 1300 Training err. 2.05236 Training err. RA 2.68112 Valid. err. 2.13962
2018-02-03 23:51:47,535 training [INFO ] Epoch 13 Batch 1320 Training err. 2.06843 Training err. RA 2.67184 Valid. err. 2.04466
2018-02-03 23:51:48,062 training [INFO ] Epoch 13 Batch 1340 Training err. 2.01635 Training err. RA 2.66206 Valid. err. 2.05236
2018-02-03 23:51:48,936 training [INFO ] Epoch 14 Batch 1360 Training err. 2.08433 Training err. RA 2.65356 Valid. err. 2.05856
2018-02-03 23:51:49,462 training [INFO ] Epoch 14 Batch 1380 Training err. 2.03872 Training err. RA 2.64465 Valid. err. 2.04863
2018-02-03 23:51:49,976 training [INFO ] Epoch 14 Batch 1400 Training err. 2.01269 Training err. RA 2.63562 Valid. err. 2.05183
2018-02-03 23:51:50,495 training [INFO ] Epoch 14 Batch 1420 Training err. 2.04022 Training err. RA 2.62724 Valid. err. 2.05792
2018-02-03 23:51:51,018 training [INFO ] Epoch 14 Batch 1440 Training err. 1.99753 Training err. RA 2.61849 Valid. err. 2.02731
2018-02-03 23:51:51,886 training [INFO ] Epoch 15 Batch 1460 Training err. 2.05128 Training err. RA 2.61072 Valid. err. 2.09465
2018-02-03 23:51:52,390 training [INFO ] Epoch 15 Batch 1480 Training err. 2.04318 Training err. RA 2.60305 Valid. err. 2.01110
2018-02-03 23:51:52,890 training [INFO ] Epoch 15 Batch 1500 Training err. 1.98011 Training err. RA 2.59474 Valid. err. 2.02052
2018-02-03 23:51:53,390 training [INFO ] Epoch 15 Batch 1520 Training err. 1.99276 Training err. RA 2.58682 Valid. err. 2.03065
2018-02-03 23:51:53,885 training [INFO ] Epoch 15 Batch 1540 Training err. 1.99648 Training err. RA 2.57916 Valid. err. 2.01990
2018-02-03 23:51:54,389 training [INFO ] Epoch 15 Batch 1560 Training err. 2.02279 Training err. RA 2.57202 Valid. err. 2.08818
2018-02-03 23:51:55,219 training [INFO ] Epoch 16 Batch 1580 Training err. 2.03921 Training err. RA 2.56528 Valid. err. 2.00229
2018-02-03 23:51:55,719 training [INFO ] Epoch 16 Batch 1600 Training err. 1.93807 Training err. RA 2.55744 Valid. err. 2.01235
2018-02-03 23:51:56,226 training [INFO ] Epoch 16 Batch 1620 Training err. 1.96150 Training err. RA 2.55008 Valid. err. 2.01046
2018-02-03 23:51:56,737 training [INFO ] Epoch 16 Batch 1640 Training err. 1.99423 Training err. RA 2.54330 Valid. err. 2.02282
2018-02-03 23:51:57,249 training [INFO ] Epoch 16 Batch 1660 Training err. 1.96318 Training err. RA 2.53631 Valid. err. 2.05334
2018-02-03 23:51:58,127 training [INFO ] Epoch 17 Batch 1680 Training err. 2.03306 Training err. RA 2.53032 Valid. err. 2.01601
2018-02-03 23:51:58,636 training [INFO ] Epoch 17 Batch 1700 Training err. 1.94265 Training err. RA 2.52341 Valid. err. 2.02715
2018-02-03 23:51:59,151 training [INFO ] Epoch 17 Batch 1720 Training err. 1.94108 Training err. RA 2.51664 Valid. err. 2.00887
2018-02-03 23:51:59,657 training [INFO ] Epoch 17 Batch 1740 Training err. 1.97041 Training err. RA 2.51036 Valid. err. 2.00576
2018-02-03 23:52:00,171 training [INFO ] Epoch 17 Batch 1760 Training err. 1.94419 Training err. RA 2.50393 Valid. err. 2.01128
2018-02-03 23:52:01,013 training [INFO ] Epoch 18 Batch 1780 Training err. 2.02915 Training err. RA 2.49859 Valid. err. 2.01748
2018-02-03 23:52:01,516 training [INFO ] Epoch 18 Batch 1800 Training err. 1.91988 Training err. RA 2.49216 Valid. err. 2.00127
2018-02-03 23:52:02,010 training [INFO ] Epoch 18 Batch 1820 Training err. 1.93064 Training err. RA 2.48599 Valid. err. 1.99763
2018-02-03 23:52:02,508 training [INFO ] Epoch 18 Batch 1840 Training err. 1.94860 Training err. RA 2.48015 Valid. err. 1.97170
2018-02-03 23:52:03,009 training [INFO ] Epoch 18 Batch 1860 Training err. 1.91592 Training err. RA 2.47408 Valid. err. 1.93656
2018-02-03 23:52:03,864 training [INFO ] Epoch 19 Batch 1880 Training err. 1.96231 Training err. RA 2.46864 Valid. err. 1.96190
2018-02-03 23:52:04,378 training [INFO ] Epoch 19 Batch 1900 Training err. 1.93761 Training err. RA 2.46305 Valid. err. 1.96949
2018-02-03 23:52:04,892 training [INFO ] Epoch 19 Batch 1920 Training err. 1.92222 Training err. RA 2.45741 Valid. err. 1.94415
2018-02-03 23:52:05,401 training [INFO ] Epoch 19 Batch 1940 Training err. 1.91927 Training err. RA 2.45187 Valid. err. 1.93121
2018-02-03 23:52:05,916 training [INFO ] Epoch 19 Batch 1960 Training err. 1.90341 Training err. RA 2.44627 Valid. err. 1.93146
2018-02-03 23:52:06,878 training [INFO ] Epoch 20 Batch 1980 Training err. 1.92827 Training err. RA 2.44104 Valid. err. 1.97093
2018-02-03 23:52:07,409 training [INFO ] Epoch 20 Batch 2000 Training err. 1.93445 Training err. RA 2.43597 Valid. err. 1.95266
2018-02-03 23:52:07,913 training [INFO ] Epoch 20 Batch 2020 Training err. 1.90535 Training err. RA 2.43072 Valid. err. 1.91746
2018-02-03 23:52:08,415 training [INFO ] Epoch 20 Batch 2040 Training err. 1.89025 Training err. RA 2.42542 Valid. err. 1.92421
2018-02-03 23:52:08,925 training [INFO ] Epoch 20 Batch 2060 Training err. 1.89663 Training err. RA 2.42029 Valid. err. 1.91120
2018-02-03 23:52:09,434 training [INFO ] Epoch 20 Batch 2080 Training err. 1.90689 Training err. RA 2.41535 Valid. err. 1.96386
2018-02-03 23:52:10,303 training [INFO ] Epoch 21 Batch 2100 Training err. 1.93570 Training err. RA 2.41078 Valid. err. 1.91609
2018-02-03 23:52:10,806 training [INFO ] Epoch 21 Batch 2120 Training err. 1.85398 Training err. RA 2.40553 Valid. err. 1.96879
2018-02-03 23:52:11,303 training [INFO ] Epoch 21 Batch 2140 Training err. 1.87408 Training err. RA 2.40056 Valid. err. 1.92323
2018-02-03 23:52:11,806 training [INFO ] Epoch 21 Batch 2160 Training err. 1.89922 Training err. RA 2.39592 Valid. err. 1.93301
2018-02-03 23:52:12,327 training [INFO ] Epoch 21 Batch 2180 Training err. 1.86306 Training err. RA 2.39103 Valid. err. 1.90488
2018-02-03 23:52:13,215 training [INFO ] Epoch 22 Batch 2200 Training err. 1.92111 Training err. RA 2.38676 Valid. err. 1.93065
2018-02-03 23:52:13,722 training [INFO ] Epoch 22 Batch 2220 Training err. 1.85273 Training err. RA 2.38195 Valid. err. 1.93682
2018-02-03 23:52:14,235 training [INFO ] Epoch 22 Batch 2240 Training err. 1.86682 Training err. RA 2.37735 Valid. err. 1.90524
2018-02-03 23:52:14,745 training [INFO ] Epoch 22 Batch 2260 Training err. 1.88718 Training err. RA 2.37301 Valid. err. 1.88398
2018-02-03 23:52:15,261 training [INFO ] Epoch 22 Batch 2280 Training err. 1.85376 Training err. RA 2.36846 Valid. err. 1.88319
2018-02-03 23:52:16,350 training [INFO ] Epoch 23 Batch 2300 Training err. 1.91139 Training err. RA 2.36448 Valid. err. 1.90249
2018-02-03 23:52:17,025 training [INFO ] Epoch 23 Batch 2320 Training err. 1.84026 Training err. RA 2.35996 Valid. err. 1.95451
2018-02-03 23:52:17,699 training [INFO ] Epoch 23 Batch 2340 Training err. 1.86197 Training err. RA 2.35571 Valid. err. 1.90706
2018-02-03 23:52:18,383 training [INFO ] Epoch 23 Batch 2360 Training err. 1.85757 Training err. RA 2.35148 Valid. err. 1.87517
2018-02-03 23:52:19,056 training [INFO ] Epoch 23 Batch 2380 Training err. 1.84003 Training err. RA 2.34719 Valid. err. 1.86524
2018-02-03 23:52:20,076 training [INFO ] Epoch 24 Batch 2400 Training err. 1.87640 Training err. RA 2.34326 Valid. err. 1.88426
2018-02-03 23:52:20,641 training [INFO ] Epoch 24 Batch 2420 Training err. 1.84653 Training err. RA 2.33916 Valid. err. 1.89556
2018-02-03 23:52:21,207 training [INFO ] Epoch 24 Batch 2440 Training err. 1.85329 Training err. RA 2.33518 Valid. err. 1.87869
2018-02-03 23:52:21,767 training [INFO ] Epoch 24 Batch 2460 Training err. 1.83534 Training err. RA 2.33111 Valid. err. 1.85759
2018-02-03 23:52:22,326 training [INFO ] Epoch 24 Batch 2480 Training err. 1.83429 Training err. RA 2.32710 Valid. err. 1.85185
2018-02-03 23:52:23,179 training [INFO ] Epoch 25 Batch 2500 Training err. 1.84634 Training err. RA 2.32326 Valid. err. 1.88367
2018-02-03 23:52:23,684 training [INFO ] Epoch 25 Batch 2520 Training err. 1.85003 Training err. RA 2.31950 Valid. err. 1.87139
2018-02-03 23:52:24,188 training [INFO ] Epoch 25 Batch 2540 Training err. 1.82777 Training err. RA 2.31563 Valid. err. 1.85753
2018-02-03 23:52:24,685 training [INFO ] Epoch 25 Batch 2560 Training err. 1.81083 Training err. RA 2.31169 Valid. err. 1.85188
2018-02-03 23:52:25,183 training [INFO ] Epoch 25 Batch 2580 Training err. 1.83230 Training err. RA 2.30797 Valid. err. 1.85277
2018-02-03 23:52:25,676 training [INFO ] Epoch 25 Batch 2600 Training err. 1.82962 Training err. RA 2.30429 Valid. err. 1.89202
2018-02-03 23:52:26,510 training [INFO ] Epoch 26 Batch 2620 Training err. 1.85080 Training err. RA 2.30083 Valid. err. 1.85077
2018-02-03 23:52:27,013 training [INFO ] Epoch 26 Batch 2640 Training err. 1.78303 Training err. RA 2.29691 Valid. err. 1.90119
2018-02-03 23:52:27,508 training [INFO ] Epoch 26 Batch 2660 Training err. 1.80357 Training err. RA 2.29320 Valid. err. 1.83825
2018-02-03 23:52:28,009 training [INFO ] Epoch 26 Batch 2680 Training err. 1.81940 Training err. RA 2.28966 Valid. err. 1.85778
2018-02-03 23:52:28,504 training [INFO ] Epoch 26 Batch 2700 Training err. 1.80554 Training err. RA 2.28608 Valid. err. 1.83440
2018-02-03 23:52:29,359 training [INFO ] Epoch 27 Batch 2720 Training err. 1.82539 Training err. RA 2.28269 Valid. err. 1.85772
2018-02-03 23:52:29,853 training [INFO ] Epoch 27 Batch 2740 Training err. 1.78511 Training err. RA 2.27906 Valid. err. 1.85434
2018-02-03 23:52:30,355 training [INFO ] Epoch 27 Batch 2760 Training err. 1.79817 Training err. RA 2.27557 Valid. err. 1.84499
2018-02-03 23:52:30,850 training [INFO ] Epoch 27 Batch 2780 Training err. 1.80581 Training err. RA 2.27219 Valid. err. 1.83113
2018-02-03 23:52:31,352 training [INFO ] Epoch 27 Batch 2800 Training err. 1.79466 Training err. RA 2.26878 Valid. err. 1.86297
2018-02-03 23:52:32,190 training [INFO ] Epoch 28 Batch 2820 Training err. 1.81818 Training err. RA 2.26559 Valid. err. 1.83040
2018-02-03 23:52:32,685 training [INFO ] Epoch 28 Batch 2840 Training err. 1.78050 Training err. RA 2.26217 Valid. err. 1.87183
2018-02-03 23:52:33,183 training [INFO ] Epoch 28 Batch 2860 Training err. 1.78392 Training err. RA 2.25882 Valid. err. 1.84331
2018-02-03 23:52:33,676 training [INFO ] Epoch 28 Batch 2880 Training err. 1.79626 Training err. RA 2.25561 Valid. err. 1.86381
2018-02-03 23:52:34,173 training [INFO ] Epoch 28 Batch 2900 Training err. 1.78311 Training err. RA 2.25235 Valid. err. 1.82710
2018-02-03 23:52:35,097 training [INFO ] Epoch 29 Batch 2920 Training err. 1.79139 Training err. RA 2.24920 Valid. err. 1.81341
2018-02-03 23:52:35,601 training [INFO ] Epoch 29 Batch 2940 Training err. 1.76639 Training err. RA 2.24591 Valid. err. 1.83380
2018-02-03 23:52:36,107 training [INFO ] Epoch 29 Batch 2960 Training err. 1.77213 Training err. RA 2.24271 Valid. err. 1.83637
2018-02-03 23:52:36,610 training [INFO ] Epoch 29 Batch 2980 Training err. 1.79786 Training err. RA 2.23973 Valid. err. 1.81300
2018-02-03 23:52:37,120 training [INFO ] Epoch 29 Batch 3000 Training err. 1.77019 Training err. RA 2.23660 Valid. err. 1.80591
2018-02-03 23:52:37,965 training [INFO ] Epoch 30 Batch 3020 Training err. 1.76628 Training err. RA 2.23348 Valid. err. 1.83505
2018-02-03 23:52:38,466 training [INFO ] Epoch 30 Batch 3040 Training err. 1.77391 Training err. RA 2.23046 Valid. err. 1.82597
2018-02-03 23:52:38,974 training [INFO ] Epoch 30 Batch 3060 Training err. 1.75299 Training err. RA 2.22734 Valid. err. 1.79919
2018-02-03 23:52:39,475 training [INFO ] Epoch 30 Batch 3080 Training err. 1.76352 Training err. RA 2.22432 Valid. err. 1.79215
2018-02-03 23:52:39,987 training [INFO ] Epoch 30 Batch 3100 Training err. 1.76390 Training err. RA 2.22135 Valid. err. 1.80735
2018-02-03 23:52:40,490 training [INFO ] Epoch 30 Batch 3120 Training err. 1.76749 Training err. RA 2.21844 Valid. err. 1.87827
2018-02-03 23:52:41,343 training [INFO ] Epoch 31 Batch 3140 Training err. 1.80043 Training err. RA 2.21578 Valid. err. 1.82059
2018-02-03 23:52:41,846 training [INFO ] Epoch 31 Batch 3160 Training err. 1.72024 Training err. RA 2.21265 Valid. err. 1.87432
2018-02-03 23:52:42,358 training [INFO ] Epoch 31 Batch 3180 Training err. 1.74420 Training err. RA 2.20970 Valid. err. 1.78657
2018-02-03 23:52:42,862 training [INFO ] Epoch 31 Batch 3200 Training err. 1.77046 Training err. RA 2.20695 Valid. err. 1.79368
2018-02-03 23:52:43,373 training [INFO ] Epoch 31 Batch 3220 Training err. 1.75196 Training err. RA 2.20413 Valid. err. 1.79451
2018-02-03 23:52:44,240 training [INFO ] Epoch 32 Batch 3240 Training err. 1.76619 Training err. RA 2.20143 Valid. err. 1.83004
2018-02-03 23:52:44,755 training [INFO ] Epoch 32 Batch 3260 Training err. 1.72221 Training err. RA 2.19849 Valid. err. 1.83093
2018-02-03 23:52:45,277 training [INFO ] Epoch 32 Batch 3280 Training err. 1.73491 Training err. RA 2.19566 Valid. err. 1.78939
2018-02-03 23:52:45,796 training [INFO ] Epoch 32 Batch 3300 Training err. 1.76092 Training err. RA 2.19302 Valid. err. 1.79288
2018-02-03 23:52:46,315 training [INFO ] Epoch 32 Batch 3320 Training err. 1.74377 Training err. RA 2.19032 Valid. err. 1.80100
2018-02-03 23:52:47,193 training [INFO ] Epoch 33 Batch 3340 Training err. 1.76800 Training err. RA 2.18779 Valid. err. 1.78245
2018-02-03 23:52:47,702 training [INFO ] Epoch 33 Batch 3360 Training err. 1.72167 Training err. RA 2.18501 Valid. err. 1.80034
2018-02-03 23:52:48,211 training [INFO ] Epoch 33 Batch 3380 Training err. 1.73830 Training err. RA 2.18237 Valid. err. 1.78511
2018-02-03 23:52:48,709 training [INFO ] Epoch 33 Batch 3400 Training err. 1.74345 Training err. RA 2.17979 Valid. err. 1.79495
2018-02-03 23:52:49,212 training [INFO ] Epoch 33 Batch 3420 Training err. 1.73015 Training err. RA 2.17716 Valid. err. 1.79678
2018-02-03 23:52:50,062 training [INFO ] Epoch 34 Batch 3440 Training err. 1.75110 Training err. RA 2.17468 Valid. err. 1.77877
2018-02-03 23:52:50,562 training [INFO ] Epoch 34 Batch 3460 Training err. 1.73010 Training err. RA 2.17211 Valid. err. 1.79514
2018-02-03 23:52:51,072 training [INFO ] Epoch 34 Batch 3480 Training err. 1.72480 Training err. RA 2.16954 Valid. err. 1.77602
2018-02-03 23:52:51,565 training [INFO ] Epoch 34 Batch 3500 Training err. 1.72315 Training err. RA 2.16699 Valid. err. 1.76808
2018-02-03 23:52:52,081 training [INFO ] Epoch 34 Batch 3520 Training err. 1.73105 Training err. RA 2.16451 Valid. err. 1.77335
2018-02-03 23:52:52,957 training [INFO ] Epoch 35 Batch 3540 Training err. 1.72678 Training err. RA 2.16204 Valid. err. 1.78755
2018-02-03 23:52:53,470 training [INFO ] Epoch 35 Batch 3560 Training err. 1.73230 Training err. RA 2.15963 Valid. err. 1.76531
2018-02-03 23:52:53,987 training [INFO ] Epoch 35 Batch 3580 Training err. 1.70657 Training err. RA 2.15710 Valid. err. 1.76815
2018-02-03 23:52:54,499 training [INFO ] Epoch 35 Batch 3600 Training err. 1.70067 Training err. RA 2.15456 Valid. err. 1.78773
2018-02-03 23:52:55,014 training [INFO ] Epoch 35 Batch 3620 Training err. 1.72725 Training err. RA 2.15220 Valid. err. 1.75525
2018-02-03 23:52:55,523 training [INFO ] Epoch 35 Batch 3640 Training err. 1.72512 Training err. RA 2.14985 Valid. err. 1.89305
2018-02-03 23:52:56,354 training [INFO ] Epoch 36 Batch 3660 Training err. 1.76107 Training err. RA 2.14773 Valid. err. 1.78376
2018-02-03 23:52:56,852 training [INFO ] Epoch 36 Batch 3680 Training err. 1.66709 Training err. RA 2.14512 Valid. err. 1.81285
2018-02-03 23:52:57,357 training [INFO ] Epoch 36 Batch 3700 Training err. 1.69698 Training err. RA 2.14269 Valid. err. 1.74940
2018-02-03 23:52:57,858 training [INFO ] Epoch 36 Batch 3720 Training err. 1.72721 Training err. RA 2.14046 Valid. err. 1.76408
2018-02-03 23:52:58,358 training [INFO ] Epoch 36 Batch 3740 Training err. 1.71117 Training err. RA 2.13816 Valid. err. 1.76490
2018-02-03 23:52:59,212 training [INFO ] Epoch 37 Batch 3760 Training err. 1.73088 Training err. RA 2.13600 Valid. err. 1.79907
2018-02-03 23:52:59,707 training [INFO ] Epoch 37 Batch 3780 Training err. 1.68689 Training err. RA 2.13362 Valid. err. 1.77963
2018-02-03 23:53:00,228 training [INFO ] Epoch 37 Batch 3800 Training err. 1.69769 Training err. RA 2.13133 Valid. err. 1.75771
2018-02-03 23:53:00,736 training [INFO ] Epoch 37 Batch 3820 Training err. 1.70888 Training err. RA 2.12912 Valid. err. 1.75182
2018-02-03 23:53:01,257 training [INFO ] Epoch 37 Batch 3840 Training err. 1.69983 Training err. RA 2.12688 Valid. err. 1.75366
2018-02-03 23:53:02,127 training [INFO ] Epoch 38 Batch 3860 Training err. 1.72679 Training err. RA 2.12481 Valid. err. 1.74651
2018-02-03 23:53:02,645 training [INFO ] Epoch 38 Batch 3880 Training err. 1.68340 Training err. RA 2.12253 Valid. err. 1.76377
2018-02-03 23:53:03,166 training [INFO ] Epoch 38 Batch 3900 Training err. 1.70428 Training err. RA 2.12039 Valid. err. 1.74246
2018-02-03 23:53:03,680 training [INFO ] Epoch 38 Batch 3920 Training err. 1.69291 Training err. RA 2.11821 Valid. err. 1.75380
2018-02-03 23:53:04,185 training [INFO ] Epoch 38 Batch 3940 Training err. 1.69335 Training err. RA 2.11605 Valid. err. 1.78039
2018-02-03 23:53:05,043 training [INFO ] Epoch 39 Batch 3960 Training err. 1.69767 Training err. RA 2.11394 Valid. err. 1.73776
2018-02-03 23:53:05,543 training [INFO ] Epoch 39 Batch 3980 Training err. 1.68528 Training err. RA 2.11178 Valid. err. 1.77301
2018-02-03 23:53:06,045 training [INFO ] Epoch 39 Batch 4000 Training err. 1.69342 Training err. RA 2.10969 Valid. err. 1.74243
2018-02-03 23:53:06,548 training [INFO ] Epoch 39 Batch 4020 Training err. 1.68897 Training err. RA 2.10760 Valid. err. 1.76975
2018-02-03 23:53:07,054 training [INFO ] Epoch 39 Batch 4040 Training err. 1.70430 Training err. RA 2.10560 Valid. err. 1.75369
2018-02-03 23:53:07,900 training [INFO ] Epoch 40 Batch 4060 Training err. 1.68854 Training err. RA 2.10355 Valid. err. 1.78512
2018-02-03 23:53:08,400 training [INFO ] Epoch 40 Batch 4080 Training err. 1.68978 Training err. RA 2.10152 Valid. err. 1.72934
2018-02-03 23:53:08,903 training [INFO ] Epoch 40 Batch 4100 Training err. 1.69205 Training err. RA 2.09952 Valid. err. 1.74364
2018-02-03 23:53:09,408 training [INFO ] Epoch 40 Batch 4120 Training err. 1.67155 Training err. RA 2.09744 Valid. err. 1.78143
2018-02-03 23:53:09,910 training [INFO ] Epoch 40 Batch 4140 Training err. 1.67880 Training err. RA 2.09542 Valid. err. 1.72756
2018-02-03 23:53:10,414 training [INFO ] Epoch 40 Batch 4160 Training err. 1.69105 Training err. RA 2.09348 Valid. err. 1.81578
2018-02-03 23:53:11,263 training [INFO ] Epoch 41 Batch 4180 Training err. 1.70297 Training err. RA 2.09161 Valid. err. 1.72127
2018-02-03 23:53:11,769 training [INFO ] Epoch 41 Batch 4200 Training err. 1.64091 Training err. RA 2.08946 Valid. err. 1.79104
2018-02-03 23:53:12,297 training [INFO ] Epoch 41 Batch 4220 Training err. 1.67873 Training err. RA 2.08751 Valid. err. 1.72552
2018-02-03 23:53:12,816 training [INFO ] Epoch 41 Batch 4240 Training err. 1.67285 Training err. RA 2.08556 Valid. err. 1.72956
2018-02-03 23:53:13,341 training [INFO ] Epoch 41 Batch 4260 Training err. 1.69069 Training err. RA 2.08371 Valid. err. 1.73717
2018-02-03 23:53:14,220 training [INFO ] Epoch 42 Batch 4280 Training err. 1.68027 Training err. RA 2.08182 Valid. err. 1.73909
2018-02-03 23:53:14,735 training [INFO ] Epoch 42 Batch 4300 Training err. 1.65057 Training err. RA 2.07981 Valid. err. 1.79241
2018-02-03 23:53:15,252 training [INFO ] Epoch 42 Batch 4320 Training err. 1.68081 Training err. RA 2.07797 Valid. err. 1.73820
2018-02-03 23:53:15,759 training [INFO ] Epoch 42 Batch 4340 Training err. 1.67315 Training err. RA 2.07610 Valid. err. 1.71979
2018-02-03 23:53:16,261 training [INFO ] Epoch 42 Batch 4360 Training err. 1.66880 Training err. RA 2.07423 Valid. err. 1.73377
2018-02-03 23:53:17,121 training [INFO ] Epoch 43 Batch 4380 Training err. 1.69710 Training err. RA 2.07251 Valid. err. 1.70607
2018-02-03 23:53:17,629 training [INFO ] Epoch 43 Batch 4400 Training err. 1.63648 Training err. RA 2.07053 Valid. err. 1.72040
2018-02-03 23:53:18,139 training [INFO ] Epoch 43 Batch 4420 Training err. 1.67701 Training err. RA 2.06875 Valid. err. 1.72372
2018-02-03 23:53:18,644 training [INFO ] Epoch 43 Batch 4440 Training err. 1.65966 Training err. RA 2.06691 Valid. err. 1.71582
2018-02-03 23:53:19,154 training [INFO ] Epoch 43 Batch 4460 Training err. 1.65422 Training err. RA 2.06505 Valid. err. 1.72814
2018-02-03 23:53:20,027 training [INFO ] Epoch 44 Batch 4480 Training err. 1.67086 Training err. RA 2.06330 Valid. err. 1.71795
2018-02-03 23:53:20,545 training [INFO ] Epoch 44 Batch 4500 Training err. 1.65205 Training err. RA 2.06147 Valid. err. 1.72708
2018-02-03 23:53:21,067 training [INFO ] Epoch 44 Batch 4520 Training err. 1.67458 Training err. RA 2.05976 Valid. err. 1.72799
2018-02-03 23:53:21,587 training [INFO ] Epoch 44 Batch 4540 Training err. 1.66683 Training err. RA 2.05802 Valid. err. 1.70594
2018-02-03 23:53:22,108 training [INFO ] Epoch 44 Batch 4560 Training err. 1.66530 Training err. RA 2.05630 Valid. err. 1.71934
2018-02-03 23:53:22,989 training [INFO ] Epoch 45 Batch 4580 Training err. 1.66261 Training err. RA 2.05458 Valid. err. 1.73295
2018-02-03 23:53:23,504 training [INFO ] Epoch 45 Batch 4600 Training err. 1.65822 Training err. RA 2.05286 Valid. err. 1.69714
2018-02-03 23:53:24,013 training [INFO ] Epoch 45 Batch 4620 Training err. 1.65656 Training err. RA 2.05114 Valid. err. 1.75950
2018-02-03 23:53:24,533 training [INFO ] Epoch 45 Batch 4640 Training err. 1.64970 Training err. RA 2.04941 Valid. err. 1.72192
2018-02-03 23:53:25,073 training [INFO ] Epoch 45 Batch 4660 Training err. 1.64143 Training err. RA 2.04766 Valid. err. 1.71140
2018-02-03 23:53:25,589 training [INFO ] Epoch 45 Batch 4680 Training err. 1.66344 Training err. RA 2.04602 Valid. err. 1.75943
2018-02-03 23:53:26,480 training [INFO ] Epoch 46 Batch 4700 Training err. 1.67348 Training err. RA 2.04444 Valid. err. 1.69816
2018-02-03 23:53:27,042 training [INFO ] Epoch 46 Batch 4720 Training err. 1.60655 Training err. RA 2.04258 Valid. err. 1.77375
2018-02-03 23:53:27,599 training [INFO ] Epoch 46 Batch 4740 Training err. 1.64130 Training err. RA 2.04089 Valid. err. 1.70601
2018-02-03 23:53:28,149 training [INFO ] Epoch 46 Batch 4760 Training err. 1.66956 Training err. RA 2.03933 Valid. err. 1.70367
2018-02-03 23:53:28,690 training [INFO ] Epoch 46 Batch 4780 Training err. 1.64628 Training err. RA 2.03768 Valid. err. 1.72582
2018-02-03 23:53:29,596 training [INFO ] Epoch 47 Batch 4800 Training err. 1.65203 Training err. RA 2.03608 Valid. err. 1.70760
2018-02-03 23:53:30,120 training [INFO ] Epoch 47 Batch 4820 Training err. 1.61347 Training err. RA 2.03432 Valid. err. 1.72844
2018-02-03 23:53:30,659 training [INFO ] Epoch 47 Batch 4840 Training err. 1.64525 Training err. RA 2.03271 Valid. err. 1.72494
2018-02-03 23:53:31,263 training [INFO ] Epoch 47 Batch 4860 Training err. 1.64483 Training err. RA 2.03112 Valid. err. 1.71032
2018-02-03 23:53:31,844 training [INFO ] Epoch 47 Batch 4880 Training err. 1.63803 Training err. RA 2.02951 Valid. err. 1.70690
2018-02-03 23:53:32,714 training [INFO ] Epoch 48 Batch 4900 Training err. 1.65837 Training err. RA 2.02799 Valid. err. 1.69288
2018-02-03 23:53:33,216 training [INFO ] Epoch 48 Batch 4920 Training err. 1.61299 Training err. RA 2.02630 Valid. err. 1.70314
2018-02-03 23:53:33,713 training [INFO ] Epoch 48 Batch 4940 Training err. 1.64434 Training err. RA 2.02476 Valid. err. 1.70708
2018-02-03 23:53:34,212 training [INFO ] Epoch 48 Batch 4960 Training err. 1.64264 Training err. RA 2.02322 Valid. err. 1.70471
2018-02-03 23:53:34,711 training [INFO ] Epoch 48 Batch 4980 Training err. 1.62899 Training err. RA 2.02163 Valid. err. 1.69141
2018-02-03 23:53:35,565 training [INFO ] Epoch 49 Batch 5000 Training err. 1.63701 Training err. RA 2.02010 Valid. err. 1.68934
2018-02-03 23:53:36,070 training [INFO ] Epoch 49 Batch 5020 Training err. 1.62400 Training err. RA 2.01852 Valid. err. 1.69994
2018-02-03 23:53:36,568 training [INFO ] Epoch 49 Batch 5040 Training err. 1.63825 Training err. RA 2.01701 Valid. err. 1.70731
2018-02-03 23:53:37,076 training [INFO ] Epoch 49 Batch 5060 Training err. 1.64121 Training err. RA 2.01552 Valid. err. 1.68049
2018-02-03 23:53:37,573 training [INFO ] Epoch 49 Batch 5080 Training err. 1.61805 Training err. RA 2.01396 Valid. err. 1.67874
2018-02-03 23:53:38,427 training [INFO ] Epoch 50 Batch 5100 Training err. 1.62712 Training err. RA 2.01244 Valid. err. 1.71471
2018-02-03 23:53:38,940 training [INFO ] Epoch 50 Batch 5120 Training err. 1.63564 Training err. RA 2.01097 Valid. err. 1.69206
2018-02-03 23:53:39,447 training [INFO ] Epoch 50 Batch 5140 Training err. 1.62630 Training err. RA 2.00947 Valid. err. 1.69796
2018-02-03 23:53:39,980 training [INFO ] Epoch 50 Batch 5160 Training err. 1.61258 Training err. RA 2.00793 Valid. err. 1.72990
2018-02-03 23:53:40,513 training [INFO ] Epoch 50 Batch 5180 Training err. 1.62762 Training err. RA 2.00647 Valid. err. 1.69586
2018-02-03 23:53:41,099 training [INFO ] Epoch 50 Batch 5200 Training err. 1.63050 Training err. RA 2.00502 Valid. err. 1.69724
2018-02-03 23:53:42,092 training [INFO ] Epoch 51 Batch 5220 Training err. 1.63864 Training err. RA 2.00362 Valid. err. 1.68998
2018-02-03 23:53:42,634 training [INFO ] Epoch 51 Batch 5240 Training err. 1.59075 Training err. RA 2.00204 Valid. err. 1.79459
2018-02-03 23:53:43,184 training [INFO ] Epoch 51 Batch 5260 Training err. 1.64182 Training err. RA 2.00067 Valid. err. 1.69429
2018-02-03 23:53:43,708 training [INFO ] Epoch 51 Batch 5280 Training err. 1.61930 Training err. RA 1.99923 Valid. err. 1.67090
2018-02-03 23:53:44,233 training [INFO ] Epoch 51 Batch 5300 Training err. 1.62121 Training err. RA 1.99780 Valid. err. 1.70185
2018-02-03 23:53:45,110 training [INFO ] Epoch 52 Batch 5320 Training err. 1.63069 Training err. RA 1.99642 Valid. err. 1.69889
2018-02-03 23:53:45,608 training [INFO ] Epoch 52 Batch 5340 Training err. 1.59175 Training err. RA 1.99490 Valid. err. 1.69054
2018-02-03 23:53:46,112 training [INFO ] Epoch 52 Batch 5360 Training err. 1.64128 Training err. RA 1.99358 Valid. err. 1.67728
2018-02-03 23:53:46,609 training [INFO ] Epoch 52 Batch 5380 Training err. 1.61451 Training err. RA 1.99218 Valid. err. 1.68331
2018-02-03 23:53:47,111 training [INFO ] Epoch 52 Batch 5400 Training err. 1.61284 Training err. RA 1.99077 Valid. err. 1.68315
2018-02-03 23:53:47,985 training [INFO ] Epoch 53 Batch 5420 Training err. 1.63535 Training err. RA 1.98946 Valid. err. 1.68464
2018-02-03 23:53:48,498 training [INFO ] Epoch 53 Batch 5440 Training err. 1.59182 Training err. RA 1.98800 Valid. err. 1.67554
2018-02-03 23:53:49,018 training [INFO ] Epoch 53 Batch 5460 Training err. 1.60832 Training err. RA 1.98661 Valid. err. 1.67712
2018-02-03 23:53:49,531 training [INFO ] Epoch 53 Batch 5480 Training err. 1.63473 Training err. RA 1.98532 Valid. err. 1.69717
2018-02-03 23:53:50,044 training [INFO ] Epoch 53 Batch 5500 Training err. 1.61216 Training err. RA 1.98397 Valid. err. 1.66452
2018-02-03 23:53:51,041 training [INFO ] Epoch 54 Batch 5520 Training err. 1.60832 Training err. RA 1.98260 Valid. err. 1.67511
2018-02-03 23:53:51,560 training [INFO ] Epoch 54 Batch 5540 Training err. 1.60216 Training err. RA 1.98123 Valid. err. 1.66894
2018-02-03 23:53:52,235 training [INFO ] Epoch 54 Batch 5560 Training err. 1.62079 Training err. RA 1.97993 Valid. err. 1.69728
2018-02-03 23:53:52,908 training [INFO ] Epoch 54 Batch 5580 Training err. 1.61930 Training err. RA 1.97864 Valid. err. 1.66235
2018-02-03 23:53:53,583 training [INFO ] Epoch 54 Batch 5600 Training err. 1.59330 Training err. RA 1.97727 Valid. err. 1.65242
2018-02-03 23:53:54,817 training [INFO ] Epoch 55 Batch 5620 Training err. 1.59498 Training err. RA 1.97590 Valid. err. 1.68084
2018-02-03 23:53:55,520 training [INFO ] Epoch 55 Batch 5640 Training err. 1.61446 Training err. RA 1.97462 Valid. err. 1.66801
2018-02-03 23:53:56,102 training [INFO ] Epoch 55 Batch 5660 Training err. 1.59111 Training err. RA 1.97327 Valid. err. 1.68669
2018-02-03 23:53:56,680 training [INFO ] Epoch 55 Batch 5680 Training err. 1.59613 Training err. RA 1.97194 Valid. err. 1.74873
2018-02-03 23:53:57,244 training [INFO ] Epoch 55 Batch 5700 Training err. 1.61724 Training err. RA 1.97070 Valid. err. 1.68091
2018-02-03 23:53:57,800 training [INFO ] Epoch 55 Batch 5720 Training err. 1.60219 Training err. RA 1.96941 Valid. err. 1.67491
2018-02-03 23:53:58,768 training [INFO ] Epoch 56 Batch 5740 Training err. 1.61954 Training err. RA 1.96819 Valid. err. 1.65883
2018-02-03 23:53:59,331 training [INFO ] Epoch 56 Batch 5760 Training err. 1.56793 Training err. RA 1.96680 Valid. err. 1.78253
2018-02-03 23:54:00,159 training [INFO ] Epoch 56 Batch 5780 Training err. 1.61568 Training err. RA 1.96558 Valid. err. 1.66818
2018-02-03 23:54:00,766 training [INFO ] Epoch 56 Batch 5800 Training err. 1.59323 Training err. RA 1.96430 Valid. err. 1.65130
2018-02-03 23:54:01,313 training [INFO ] Epoch 56 Batch 5820 Training err. 1.59629 Training err. RA 1.96303 Valid. err. 1.68210
2018-02-03 23:54:02,235 training [INFO ] Epoch 57 Batch 5840 Training err. 1.60688 Training err. RA 1.96181 Valid. err. 1.67523
2018-02-03 23:54:02,752 training [INFO ] Epoch 57 Batch 5860 Training err. 1.57634 Training err. RA 1.96050 Valid. err. 1.67223
2018-02-03 23:54:03,281 training [INFO ] Epoch 57 Batch 5880 Training err. 1.59625 Training err. RA 1.95926 Valid. err. 1.67261
2018-02-03 23:54:03,799 training [INFO ] Epoch 57 Batch 5900 Training err. 1.60458 Training err. RA 1.95806 Valid. err. 1.67211
2018-02-03 23:54:04,317 training [INFO ] Epoch 57 Batch 5920 Training err. 1.59713 Training err. RA 1.95684 Valid. err. 1.65052
2018-02-03 23:54:05,192 training [INFO ] Epoch 58 Batch 5940 Training err. 1.60473 Training err. RA 1.95565 Valid. err. 1.66176
2018-02-03 23:54:05,718 training [INFO ] Epoch 58 Batch 5960 Training err. 1.56930 Training err. RA 1.95436 Valid. err. 1.65741
2018-02-03 23:54:06,242 training [INFO ] Epoch 58 Batch 5980 Training err. 1.60692 Training err. RA 1.95319 Valid. err. 1.66156
2018-02-03 23:54:06,733 training [INFO ] Epoch 58 Batch 6000 Training err. 1.59685 Training err. RA 1.95201 Valid. err. 1.65749
2018-02-03 23:54:07,259 training [INFO ] Epoch 58 Batch 6020 Training err. 1.58586 Training err. RA 1.95079 Valid. err. 1.64208
2018-02-03 23:54:08,163 training [INFO ] Epoch 59 Batch 6040 Training err. 1.59090 Training err. RA 1.94960 Valid. err. 1.66172
2018-02-03 23:54:08,673 training [INFO ] Epoch 59 Batch 6060 Training err. 1.58998 Training err. RA 1.94841 Valid. err. 1.66281
2018-02-03 23:54:09,208 training [INFO ] Epoch 59 Batch 6080 Training err. 1.58587 Training err. RA 1.94722 Valid. err. 1.66952
2018-02-03 23:54:09,720 training [INFO ] Epoch 59 Batch 6100 Training err. 1.60166 Training err. RA 1.94609 Valid. err. 1.64855
2018-02-03 23:54:10,330 training [INFO ] Epoch 59 Batch 6120 Training err. 1.58593 Training err. RA 1.94491 Valid. err. 1.63890
2018-02-03 23:54:11,405 training [INFO ] Epoch 60 Batch 6140 Training err. 1.57416 Training err. RA 1.94370 Valid. err. 1.64171
2018-02-03 23:54:12,419 training [INFO ] Epoch 60 Batch 6160 Training err. 1.58828 Training err. RA 1.94255 Valid. err. 1.66701
2018-02-03 23:54:13,351 training [INFO ] Epoch 60 Batch 6180 Training err. 1.58565 Training err. RA 1.94139 Valid. err. 1.69328
2018-02-03 23:54:14,359 training [INFO ] Epoch 60 Batch 6200 Training err. 1.59012 Training err. RA 1.94026 Valid. err. 1.67139
2018-02-03 23:54:15,361 training [INFO ] Epoch 60 Batch 6220 Training err. 1.57816 Training err. RA 1.93910 Valid. err. 1.65331
2018-02-03 23:54:16,105 training [INFO ] Epoch 60 Batch 6240 Training err. 1.57966 Training err. RA 1.93794 Valid. err. 1.65994
2018-02-03 23:54:16,471 __main__ [INFO ] End of training
2018-02-03 23:54:17,192 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 10,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-03 23:54:18,460 training [INFO ] Epoch  1 Batch   20 Training err. 4.23200 Training err. RA 4.23200 Valid. err. 4.15878
2018-02-03 23:54:19,241 training [INFO ] Epoch  1 Batch   40 Training err. 4.05239 Training err. RA 4.14220 Valid. err. 3.99617
2018-02-03 23:54:20,029 training [INFO ] Epoch  1 Batch   60 Training err. 3.89805 Training err. RA 4.06082 Valid. err. 3.82542
2018-02-03 23:54:20,562 training [INFO ] Epoch  1 Batch   80 Training err. 3.72414 Training err. RA 3.97665 Valid. err. 3.65016
2018-02-03 23:54:21,655 training [INFO ] Epoch  1 Batch  100 Training err. 3.53621 Training err. RA 3.88856 Valid. err. 3.51038
2018-02-03 23:54:22,589 training [INFO ] Epoch  1 Batch  120 Training err. 3.43117 Training err. RA 3.81233 Valid. err. 3.39884
2018-02-03 23:54:23,229 training [INFO ] Epoch  1 Batch  140 Training err. 3.31355 Training err. RA 3.74108 Valid. err. 3.32102
2018-02-03 23:54:23,958 training [INFO ] Epoch  1 Batch  160 Training err. 3.23218 Training err. RA 3.67746 Valid. err. 3.27647
2018-02-03 23:54:24,508 training [INFO ] Epoch  1 Batch  180 Training err. 3.23970 Training err. RA 3.62882 Valid. err. 3.25215
2018-02-03 23:54:25,703 training [INFO ] Epoch  1 Batch  200 Training err. 3.22765 Training err. RA 3.58871 Valid. err. 3.23358
2018-02-03 23:54:26,977 training [INFO ] Epoch  2 Batch  220 Training err. 3.19297 Training err. RA 3.55273 Valid. err. 3.22777
2018-02-03 23:54:27,602 training [INFO ] Epoch  2 Batch  240 Training err. 3.10741 Training err. RA 3.51562 Valid. err. 3.24653
2018-02-03 23:54:28,427 training [INFO ] Epoch  2 Batch  260 Training err. 3.19026 Training err. RA 3.49059 Valid. err. 3.20885
2018-02-03 23:54:29,113 training [INFO ] Epoch  2 Batch  280 Training err. 3.14494 Training err. RA 3.46590 Valid. err. 3.20466
2018-02-03 23:54:30,119 training [INFO ] Epoch  2 Batch  300 Training err. 3.13858 Training err. RA 3.44408 Valid. err. 3.20391
2018-02-03 23:54:30,864 training [INFO ] Epoch  2 Batch  320 Training err. 3.17087 Training err. RA 3.42701 Valid. err. 3.19702
2018-02-03 23:54:31,564 training [INFO ] Epoch  2 Batch  340 Training err. 3.14691 Training err. RA 3.41053 Valid. err. 3.19677
2018-02-03 23:54:32,176 training [INFO ] Epoch  2 Batch  360 Training err. 3.13354 Training err. RA 3.39514 Valid. err. 3.19439
2018-02-03 23:54:32,805 training [INFO ] Epoch  2 Batch  380 Training err. 3.12594 Training err. RA 3.38097 Valid. err. 3.19079
2018-02-03 23:54:33,397 training [INFO ] Epoch  2 Batch  400 Training err. 3.16975 Training err. RA 3.37041 Valid. err. 3.18838
2018-02-03 23:54:34,613 training [INFO ] Epoch  3 Batch  420 Training err. 3.16463 Training err. RA 3.36061 Valid. err. 3.18807
2018-02-03 23:54:35,358 training [INFO ] Epoch  3 Batch  440 Training err. 3.12729 Training err. RA 3.35001 Valid. err. 3.19230
2018-02-03 23:54:35,992 training [INFO ] Epoch  3 Batch  460 Training err. 3.11427 Training err. RA 3.33976 Valid. err. 3.18546
2018-02-03 23:54:36,530 training [INFO ] Epoch  3 Batch  480 Training err. 3.12075 Training err. RA 3.33063 Valid. err. 3.18629
2018-02-03 23:54:37,089 training [INFO ] Epoch  3 Batch  500 Training err. 3.10783 Training err. RA 3.32172 Valid. err. 3.19204
2018-02-03 23:54:37,628 training [INFO ] Epoch  3 Batch  520 Training err. 3.16296 Training err. RA 3.31561 Valid. err. 3.18762
2018-02-03 23:54:38,150 training [INFO ] Epoch  3 Batch  540 Training err. 3.15269 Training err. RA 3.30958 Valid. err. 3.18593
2018-02-03 23:54:38,701 training [INFO ] Epoch  3 Batch  560 Training err. 3.11920 Training err. RA 3.30278 Valid. err. 3.18569
2018-02-03 23:54:39,207 training [INFO ] Epoch  3 Batch  580 Training err. 3.08246 Training err. RA 3.29518 Valid. err. 3.18839
2018-02-03 23:54:39,842 training [INFO ] Epoch  3 Batch  600 Training err. 3.16298 Training err. RA 3.29078 Valid. err. 3.18260
2018-02-03 23:54:40,493 training [INFO ] Epoch  3 Batch  620 Training err. 3.16331 Training err. RA 3.28666 Valid. err. 3.17938
2018-02-03 23:54:41,783 training [INFO ] Epoch  4 Batch  640 Training err. 3.13494 Training err. RA 3.28192 Valid. err. 3.18208
2018-02-03 23:54:42,384 training [INFO ] Epoch  4 Batch  660 Training err. 3.07745 Training err. RA 3.27573 Valid. err. 3.18272
2018-02-03 23:54:43,002 training [INFO ] Epoch  4 Batch  680 Training err. 3.13531 Training err. RA 3.27160 Valid. err. 3.18227
2018-02-03 23:54:43,615 training [INFO ] Epoch  4 Batch  700 Training err. 3.11988 Training err. RA 3.26726 Valid. err. 3.18108
2018-02-03 23:54:44,234 training [INFO ] Epoch  4 Batch  720 Training err. 3.11157 Training err. RA 3.26294 Valid. err. 3.18366
2018-02-03 23:54:44,800 training [INFO ] Epoch  4 Batch  740 Training err. 3.16561 Training err. RA 3.26031 Valid. err. 3.17940
2018-02-03 23:54:45,355 training [INFO ] Epoch  4 Batch  760 Training err. 3.11290 Training err. RA 3.25643 Valid. err. 3.18213
2018-02-03 23:54:45,921 training [INFO ] Epoch  4 Batch  780 Training err. 3.11241 Training err. RA 3.25273 Valid. err. 3.17999
2018-02-03 23:54:46,461 training [INFO ] Epoch  4 Batch  800 Training err. 3.12170 Training err. RA 3.24946 Valid. err. 3.17936
2018-02-03 23:54:46,964 training [INFO ] Epoch  4 Batch  820 Training err. 3.14690 Training err. RA 3.24696 Valid. err. 3.17763
2018-02-03 23:54:48,003 training [INFO ] Epoch  5 Batch  840 Training err. 3.15597 Training err. RA 3.24479 Valid. err. 3.17497
2018-02-03 23:54:48,630 training [INFO ] Epoch  5 Batch  860 Training err. 3.07857 Training err. RA 3.24093 Valid. err. 3.20201
2018-02-03 23:54:49,259 training [INFO ] Epoch  5 Batch  880 Training err. 3.13210 Training err. RA 3.23845 Valid. err. 3.17688
2018-02-03 23:54:49,847 training [INFO ] Epoch  5 Batch  900 Training err. 3.11349 Training err. RA 3.23568 Valid. err. 3.17669
2018-02-03 23:54:50,366 training [INFO ] Epoch  5 Batch  920 Training err. 3.09108 Training err. RA 3.23253 Valid. err. 3.18060
2018-02-03 23:54:50,879 training [INFO ] Epoch  5 Batch  940 Training err. 3.15299 Training err. RA 3.23084 Valid. err. 3.17940
2018-02-03 23:54:51,399 training [INFO ] Epoch  5 Batch  960 Training err. 3.12470 Training err. RA 3.22863 Valid. err. 3.17961
2018-02-03 23:54:51,909 training [INFO ] Epoch  5 Batch  980 Training err. 3.11708 Training err. RA 3.22635 Valid. err. 3.17535
2018-02-03 23:54:52,410 training [INFO ] Epoch  5 Batch 1000 Training err. 3.08074 Training err. RA 3.22344 Valid. err. 3.17476
2018-02-03 23:54:52,901 training [INFO ] Epoch  5 Batch 1020 Training err. 3.15843 Training err. RA 3.22216 Valid. err. 3.17281
2018-02-03 23:54:53,496 training [INFO ] Epoch  5 Batch 1040 Training err. 3.14399 Training err. RA 3.22066 Valid. err. 3.16945
2018-02-03 23:54:54,376 training [INFO ] Epoch  6 Batch 1060 Training err. 3.11024 Training err. RA 3.21858 Valid. err. 3.17207
2018-02-03 23:54:54,906 training [INFO ] Epoch  6 Batch 1080 Training err. 3.08984 Training err. RA 3.21619 Valid. err. 3.17190
2018-02-03 23:54:55,402 training [INFO ] Epoch  6 Batch 1100 Training err. 3.09951 Training err. RA 3.21407 Valid. err. 3.17321
2018-02-03 23:54:55,955 training [INFO ] Epoch  6 Batch 1120 Training err. 3.11656 Training err. RA 3.21233 Valid. err. 3.17268
2018-02-03 23:54:56,619 training [INFO ] Epoch  6 Batch 1140 Training err. 3.11328 Training err. RA 3.21059 Valid. err. 3.17127
2018-02-03 23:54:57,208 training [INFO ] Epoch  6 Batch 1160 Training err. 3.14747 Training err. RA 3.20951 Valid. err. 3.16950
2018-02-03 23:54:57,710 training [INFO ] Epoch  6 Batch 1180 Training err. 3.10414 Training err. RA 3.20772 Valid. err. 3.17030
2018-02-03 23:54:58,221 training [INFO ] Epoch  6 Batch 1200 Training err. 3.07738 Training err. RA 3.20555 Valid. err. 3.16979
2018-02-03 23:54:58,837 training [INFO ] Epoch  6 Batch 1220 Training err. 3.12907 Training err. RA 3.20429 Valid. err. 3.16845
2018-02-03 23:54:59,467 training [INFO ] Epoch  6 Batch 1240 Training err. 3.13966 Training err. RA 3.20325 Valid. err. 3.16434
2018-02-03 23:55:00,723 training [INFO ] Epoch  7 Batch 1260 Training err. 3.12889 Training err. RA 3.20207 Valid. err. 3.17589
2018-02-03 23:55:01,339 training [INFO ] Epoch  7 Batch 1280 Training err. 3.04978 Training err. RA 3.19969 Valid. err. 3.20097
2018-02-03 23:55:02,165 training [INFO ] Epoch  7 Batch 1300 Training err. 3.13182 Training err. RA 3.19865 Valid. err. 3.16529
2018-02-03 23:55:02,817 training [INFO ] Epoch  7 Batch 1320 Training err. 3.09939 Training err. RA 3.19714 Valid. err. 3.16351
2018-02-03 23:55:03,417 training [INFO ] Epoch  7 Batch 1340 Training err. 3.09391 Training err. RA 3.19560 Valid. err. 3.16751
2018-02-03 23:55:04,006 training [INFO ] Epoch  7 Batch 1360 Training err. 3.13306 Training err. RA 3.19468 Valid. err. 3.16091
2018-02-03 23:55:04,542 training [INFO ] Epoch  7 Batch 1380 Training err. 3.10711 Training err. RA 3.19341 Valid. err. 3.16264
2018-02-03 23:55:05,073 training [INFO ] Epoch  7 Batch 1400 Training err. 3.09300 Training err. RA 3.19198 Valid. err. 3.16153
2018-02-03 23:55:05,584 training [INFO ] Epoch  7 Batch 1420 Training err. 3.08678 Training err. RA 3.19050 Valid. err. 3.15848
2018-02-03 23:55:06,153 training [INFO ] Epoch  7 Batch 1440 Training err. 3.13195 Training err. RA 3.18968 Valid. err. 3.15570
2018-02-03 23:55:07,074 training [INFO ] Epoch  8 Batch 1460 Training err. 3.12795 Training err. RA 3.18884 Valid. err. 3.15559
2018-02-03 23:55:07,577 training [INFO ] Epoch  8 Batch 1480 Training err. 3.09231 Training err. RA 3.18753 Valid. err. 3.16203
2018-02-03 23:55:08,066 training [INFO ] Epoch  8 Batch 1500 Training err. 3.08417 Training err. RA 3.18616 Valid. err. 3.15287
2018-02-03 23:55:08,545 training [INFO ] Epoch  8 Batch 1520 Training err. 3.08470 Training err. RA 3.18482 Valid. err. 3.15297
2018-02-03 23:55:09,025 training [INFO ] Epoch  8 Batch 1540 Training err. 3.07385 Training err. RA 3.18338 Valid. err. 3.15823
2018-02-03 23:55:09,551 training [INFO ] Epoch  8 Batch 1560 Training err. 3.12725 Training err. RA 3.18266 Valid. err. 3.15291
2018-02-03 23:55:10,053 training [INFO ] Epoch  8 Batch 1580 Training err. 3.11572 Training err. RA 3.18181 Valid. err. 3.15014
2018-02-03 23:55:10,574 training [INFO ] Epoch  8 Batch 1600 Training err. 3.07941 Training err. RA 3.18053 Valid. err. 3.14868
2018-02-03 23:55:11,103 training [INFO ] Epoch  8 Batch 1620 Training err. 3.04286 Training err. RA 3.17883 Valid. err. 3.15018
2018-02-03 23:55:11,607 training [INFO ] Epoch  8 Batch 1640 Training err. 3.12030 Training err. RA 3.17812 Valid. err. 3.14306
2018-02-03 23:55:12,113 training [INFO ] Epoch  8 Batch 1660 Training err. 3.12078 Training err. RA 3.17743 Valid. err. 3.13841
2018-02-03 23:55:13,090 training [INFO ] Epoch  9 Batch 1680 Training err. 3.09426 Training err. RA 3.17644 Valid. err. 3.13948
2018-02-03 23:55:13,579 training [INFO ] Epoch  9 Batch 1700 Training err. 3.04444 Training err. RA 3.17489 Valid. err. 3.13876
2018-02-03 23:55:14,201 training [INFO ] Epoch  9 Batch 1720 Training err. 3.09002 Training err. RA 3.17390 Valid. err. 3.13746
2018-02-03 23:55:14,746 training [INFO ] Epoch  9 Batch 1740 Training err. 3.07622 Training err. RA 3.17278 Valid. err. 3.13450
2018-02-03 23:55:15,308 training [INFO ] Epoch  9 Batch 1760 Training err. 3.06567 Training err. RA 3.17156 Valid. err. 3.13472
2018-02-03 23:55:15,903 training [INFO ] Epoch  9 Batch 1780 Training err. 3.11800 Training err. RA 3.17096 Valid. err. 3.12962
2018-02-03 23:55:16,421 training [INFO ] Epoch  9 Batch 1800 Training err. 3.06134 Training err. RA 3.16974 Valid. err. 3.12937
2018-02-03 23:55:16,955 training [INFO ] Epoch  9 Batch 1820 Training err. 3.05657 Training err. RA 3.16850 Valid. err. 3.12490
2018-02-03 23:55:17,568 training [INFO ] Epoch  9 Batch 1840 Training err. 3.06644 Training err. RA 3.16739 Valid. err. 3.12196
2018-02-03 23:55:18,112 training [INFO ] Epoch  9 Batch 1860 Training err. 3.08752 Training err. RA 3.16653 Valid. err. 3.11717
2018-02-03 23:55:19,163 training [INFO ] Epoch 10 Batch 1880 Training err. 3.09504 Training err. RA 3.16577 Valid. err. 3.11164
2018-02-03 23:55:19,736 training [INFO ] Epoch 10 Batch 1900 Training err. 3.02526 Training err. RA 3.16429 Valid. err. 3.14542
2018-02-03 23:55:20,281 training [INFO ] Epoch 10 Batch 1920 Training err. 3.07604 Training err. RA 3.16337 Valid. err. 3.10927
2018-02-03 23:55:20,865 training [INFO ] Epoch 10 Batch 1940 Training err. 3.04731 Training err. RA 3.16217 Valid. err. 3.10570
2018-02-03 23:55:21,476 training [INFO ] Epoch 10 Batch 1960 Training err. 3.02286 Training err. RA 3.16075 Valid. err. 3.10666
2018-02-03 23:55:22,131 training [INFO ] Epoch 10 Batch 1980 Training err. 3.08505 Training err. RA 3.15999 Valid. err. 3.10211
2018-02-03 23:55:22,648 training [INFO ] Epoch 10 Batch 2000 Training err. 3.04909 Training err. RA 3.15888 Valid. err. 3.09932
2018-02-03 23:55:23,143 training [INFO ] Epoch 10 Batch 2020 Training err. 3.03202 Training err. RA 3.15762 Valid. err. 3.09106
2018-02-03 23:55:23,623 training [INFO ] Epoch 10 Batch 2040 Training err. 2.99587 Training err. RA 3.15603 Valid. err. 3.08397
2018-02-03 23:55:24,111 training [INFO ] Epoch 10 Batch 2060 Training err. 3.06469 Training err. RA 3.15515 Valid. err. 3.07710
2018-02-03 23:55:24,589 training [INFO ] Epoch 10 Batch 2080 Training err. 3.04662 Training err. RA 3.15410 Valid. err. 3.06821
2018-02-03 23:55:25,499 training [INFO ] Epoch 11 Batch 2100 Training err. 3.01504 Training err. RA 3.15278 Valid. err. 3.06612
2018-02-03 23:55:25,974 training [INFO ] Epoch 11 Batch 2120 Training err. 3.01829 Training err. RA 3.15151 Valid. err. 3.06547
2018-02-03 23:55:26,470 training [INFO ] Epoch 11 Batch 2140 Training err. 2.99547 Training err. RA 3.15005 Valid. err. 3.05974
2018-02-03 23:55:26,957 training [INFO ] Epoch 11 Batch 2160 Training err. 3.00444 Training err. RA 3.14870 Valid. err. 3.05391
2018-02-03 23:55:27,435 training [INFO ] Epoch 11 Batch 2180 Training err. 3.00197 Training err. RA 3.14736 Valid. err. 3.04712
2018-02-03 23:55:27,934 training [INFO ] Epoch 11 Batch 2200 Training err. 3.03290 Training err. RA 3.14632 Valid. err. 3.03987
2018-02-03 23:55:28,446 training [INFO ] Epoch 11 Batch 2220 Training err. 2.97473 Training err. RA 3.14477 Valid. err. 3.03454
2018-02-03 23:55:28,935 training [INFO ] Epoch 11 Batch 2240 Training err. 2.94028 Training err. RA 3.14295 Valid. err. 3.02814
2018-02-03 23:55:29,416 training [INFO ] Epoch 11 Batch 2260 Training err. 2.99564 Training err. RA 3.14164 Valid. err. 3.02038
2018-02-03 23:55:29,907 training [INFO ] Epoch 11 Batch 2280 Training err. 2.99365 Training err. RA 3.14034 Valid. err. 3.01013
2018-02-03 23:55:30,818 training [INFO ] Epoch 12 Batch 2300 Training err. 2.98395 Training err. RA 3.13898 Valid. err. 3.07945
2018-02-03 23:55:31,316 training [INFO ] Epoch 12 Batch 2320 Training err. 2.92287 Training err. RA 3.13712 Valid. err. 3.04341
2018-02-03 23:55:31,802 training [INFO ] Epoch 12 Batch 2340 Training err. 2.97694 Training err. RA 3.13575 Valid. err. 2.99709
2018-02-03 23:55:32,278 training [INFO ] Epoch 12 Batch 2360 Training err. 2.94331 Training err. RA 3.13412 Valid. err. 2.98905
2018-02-03 23:55:32,773 training [INFO ] Epoch 12 Batch 2380 Training err. 2.91784 Training err. RA 3.13230 Valid. err. 2.99885
2018-02-03 23:55:33,251 training [INFO ] Epoch 12 Batch 2400 Training err. 2.96849 Training err. RA 3.13094 Valid. err. 2.97574
2018-02-03 23:55:33,734 training [INFO ] Epoch 12 Batch 2420 Training err. 2.92917 Training err. RA 3.12927 Valid. err. 2.97101
2018-02-03 23:55:34,224 training [INFO ] Epoch 12 Batch 2440 Training err. 2.90300 Training err. RA 3.12742 Valid. err. 2.96401
2018-02-03 23:55:34,701 training [INFO ] Epoch 12 Batch 2460 Training err. 2.90235 Training err. RA 3.12559 Valid. err. 2.95420
2018-02-03 23:55:35,175 training [INFO ] Epoch 12 Batch 2480 Training err. 2.92722 Training err. RA 3.12399 Valid. err. 2.94540
2018-02-03 23:55:36,008 training [INFO ] Epoch 13 Batch 2500 Training err. 2.92279 Training err. RA 3.12238 Valid. err. 2.93986
2018-02-03 23:55:36,487 training [INFO ] Epoch 13 Batch 2520 Training err. 2.88215 Training err. RA 3.12047 Valid. err. 2.96782
2018-02-03 23:55:37,053 training [INFO ] Epoch 13 Batch 2540 Training err. 2.90654 Training err. RA 3.11879 Valid. err. 2.92928
2018-02-03 23:55:37,578 training [INFO ] Epoch 13 Batch 2560 Training err. 2.86583 Training err. RA 3.11681 Valid. err. 2.92044
2018-02-03 23:55:38,077 training [INFO ] Epoch 13 Batch 2580 Training err. 2.85096 Training err. RA 3.11475 Valid. err. 2.92040
2018-02-03 23:55:38,556 training [INFO ] Epoch 13 Batch 2600 Training err. 2.89581 Training err. RA 3.11307 Valid. err. 2.91917
2018-02-03 23:55:39,054 training [INFO ] Epoch 13 Batch 2620 Training err. 2.88957 Training err. RA 3.11136 Valid. err. 2.90075
2018-02-03 23:55:39,539 training [INFO ] Epoch 13 Batch 2640 Training err. 2.83592 Training err. RA 3.10927 Valid. err. 2.89394
2018-02-03 23:55:40,030 training [INFO ] Epoch 13 Batch 2660 Training err. 2.80029 Training err. RA 3.10695 Valid. err. 2.97010
2018-02-03 23:55:40,533 training [INFO ] Epoch 13 Batch 2680 Training err. 2.86782 Training err. RA 3.10516 Valid. err. 2.87965
2018-02-03 23:55:41,012 training [INFO ] Epoch 13 Batch 2700 Training err. 2.86680 Training err. RA 3.10340 Valid. err. 2.86858
2018-02-03 23:55:41,920 training [INFO ] Epoch 14 Batch 2720 Training err. 2.82718 Training err. RA 3.10137 Valid. err. 2.87504
2018-02-03 23:55:42,439 training [INFO ] Epoch 14 Batch 2740 Training err. 2.80601 Training err. RA 3.09921 Valid. err. 2.88295
2018-02-03 23:55:43,132 training [INFO ] Epoch 14 Batch 2760 Training err. 2.83257 Training err. RA 3.09728 Valid. err. 2.85913
2018-02-03 23:55:43,648 training [INFO ] Epoch 14 Batch 2780 Training err. 2.79831 Training err. RA 3.09513 Valid. err. 2.85011
2018-02-03 23:55:44,227 training [INFO ] Epoch 14 Batch 2800 Training err. 2.76412 Training err. RA 3.09276 Valid. err. 2.84139
2018-02-03 23:55:44,865 training [INFO ] Epoch 14 Batch 2820 Training err. 2.84660 Training err. RA 3.09102 Valid. err. 2.83975
2018-02-03 23:55:45,448 training [INFO ] Epoch 14 Batch 2840 Training err. 2.78213 Training err. RA 3.08884 Valid. err. 2.85301
2018-02-03 23:55:45,936 training [INFO ] Epoch 14 Batch 2860 Training err. 2.77184 Training err. RA 3.08663 Valid. err. 2.82127
2018-02-03 23:55:46,425 training [INFO ] Epoch 14 Batch 2880 Training err. 2.77645 Training err. RA 3.08447 Valid. err. 2.81725
2018-02-03 23:55:46,908 training [INFO ] Epoch 14 Batch 2900 Training err. 2.79022 Training err. RA 3.08244 Valid. err. 2.81322
2018-02-03 23:55:47,860 training [INFO ] Epoch 15 Batch 2920 Training err. 2.78960 Training err. RA 3.08044 Valid. err. 2.80424
2018-02-03 23:55:48,332 training [INFO ] Epoch 15 Batch 2940 Training err. 2.70517 Training err. RA 3.07788 Valid. err. 2.86364
2018-02-03 23:55:48,905 training [INFO ] Epoch 15 Batch 2960 Training err. 2.79145 Training err. RA 3.07595 Valid. err. 2.79910
2018-02-03 23:55:49,446 training [INFO ] Epoch 15 Batch 2980 Training err. 2.74276 Training err. RA 3.07371 Valid. err. 2.79073
2018-02-03 23:55:49,932 training [INFO ] Epoch 15 Batch 3000 Training err. 2.70074 Training err. RA 3.07123 Valid. err. 2.80449
2018-02-03 23:55:50,432 training [INFO ] Epoch 15 Batch 3020 Training err. 2.76237 Training err. RA 3.06918 Valid. err. 2.81430
2018-02-03 23:55:50,927 training [INFO ] Epoch 15 Batch 3040 Training err. 2.75842 Training err. RA 3.06714 Valid. err. 2.77574
2018-02-03 23:55:51,426 training [INFO ] Epoch 15 Batch 3060 Training err. 2.73643 Training err. RA 3.06498 Valid. err. 2.78539
2018-02-03 23:55:51,931 training [INFO ] Epoch 15 Batch 3080 Training err. 2.67835 Training err. RA 3.06247 Valid. err. 2.78033
2018-02-03 23:55:52,454 training [INFO ] Epoch 15 Batch 3100 Training err. 2.75202 Training err. RA 3.06046 Valid. err. 2.75982
2018-02-03 23:55:52,941 training [INFO ] Epoch 15 Batch 3120 Training err. 2.74629 Training err. RA 3.05845 Valid. err. 2.75251
2018-02-03 23:55:53,771 training [INFO ] Epoch 16 Batch 3140 Training err. 2.68280 Training err. RA 3.05606 Valid. err. 2.75786
2018-02-03 23:55:54,251 training [INFO ] Epoch 16 Batch 3160 Training err. 2.69407 Training err. RA 3.05376 Valid. err. 2.78130
2018-02-03 23:55:54,730 training [INFO ] Epoch 16 Batch 3180 Training err. 2.69358 Training err. RA 3.05150 Valid. err. 2.74625
2018-02-03 23:55:55,206 training [INFO ] Epoch 16 Batch 3200 Training err. 2.69960 Training err. RA 3.04930 Valid. err. 2.74142
2018-02-03 23:55:55,683 training [INFO ] Epoch 16 Batch 3220 Training err. 2.67752 Training err. RA 3.04699 Valid. err. 2.73541
2018-02-03 23:55:56,164 training [INFO ] Epoch 16 Batch 3240 Training err. 2.73962 Training err. RA 3.04509 Valid. err. 2.74059
2018-02-03 23:55:56,647 training [INFO ] Epoch 16 Batch 3260 Training err. 2.68390 Training err. RA 3.04288 Valid. err. 2.73791
2018-02-03 23:55:57,125 training [INFO ] Epoch 16 Batch 3280 Training err. 2.65138 Training err. RA 3.04049 Valid. err. 2.73907
2018-02-03 23:55:57,603 training [INFO ] Epoch 16 Batch 3300 Training err. 2.69047 Training err. RA 3.03837 Valid. err. 2.72214
2018-02-03 23:55:58,083 training [INFO ] Epoch 16 Batch 3320 Training err. 2.69463 Training err. RA 3.03630 Valid. err. 2.70262
2018-02-03 23:55:58,927 training [INFO ] Epoch 17 Batch 3340 Training err. 2.66939 Training err. RA 3.03410 Valid. err. 2.71608
2018-02-03 23:55:59,407 training [INFO ] Epoch 17 Batch 3360 Training err. 2.71230 Training err. RA 3.03219 Valid. err. 2.79947
2018-02-03 23:55:59,884 training [INFO ] Epoch 17 Batch 3380 Training err. 2.74677 Training err. RA 3.03050 Valid. err. 2.75007
2018-02-03 23:56:00,364 training [INFO ] Epoch 17 Batch 3400 Training err. 2.71554 Training err. RA 3.02864 Valid. err. 2.73192
2018-02-03 23:56:00,840 training [INFO ] Epoch 17 Batch 3420 Training err. 2.66020 Training err. RA 3.02649 Valid. err. 2.72201
2018-02-03 23:56:01,316 training [INFO ] Epoch 17 Batch 3440 Training err. 2.69634 Training err. RA 3.02457 Valid. err. 2.69359
2018-02-03 23:56:01,798 training [INFO ] Epoch 17 Batch 3460 Training err. 2.67422 Training err. RA 3.02254 Valid. err. 2.69465
2018-02-03 23:56:02,275 training [INFO ] Epoch 17 Batch 3480 Training err. 2.63728 Training err. RA 3.02033 Valid. err. 2.69166
2018-02-03 23:56:02,753 training [INFO ] Epoch 17 Batch 3500 Training err. 2.63532 Training err. RA 3.01813 Valid. err. 2.68369
2018-02-03 23:56:03,228 training [INFO ] Epoch 17 Batch 3520 Training err. 2.65261 Training err. RA 3.01605 Valid. err. 2.67618
2018-02-03 23:56:04,090 training [INFO ] Epoch 18 Batch 3540 Training err. 2.65357 Training err. RA 3.01401 Valid. err. 2.66198
2018-02-03 23:56:04,570 training [INFO ] Epoch 18 Batch 3560 Training err. 2.60661 Training err. RA 3.01172 Valid. err. 2.66222
2018-02-03 23:56:05,051 training [INFO ] Epoch 18 Batch 3580 Training err. 2.60999 Training err. RA 3.00947 Valid. err. 2.70795
2018-02-03 23:56:05,530 training [INFO ] Epoch 18 Batch 3600 Training err. 2.62207 Training err. RA 3.00732 Valid. err. 2.66527
2018-02-03 23:56:06,009 training [INFO ] Epoch 18 Batch 3620 Training err. 2.60004 Training err. RA 3.00507 Valid. err. 2.68768
2018-02-03 23:56:06,491 training [INFO ] Epoch 18 Batch 3640 Training err. 2.64195 Training err. RA 3.00308 Valid. err. 2.67310
2018-02-03 23:56:06,970 training [INFO ] Epoch 18 Batch 3660 Training err. 2.66356 Training err. RA 3.00122 Valid. err. 2.65298
2018-02-03 23:56:07,449 training [INFO ] Epoch 18 Batch 3680 Training err. 2.59983 Training err. RA 2.99904 Valid. err. 2.64721
2018-02-03 23:56:07,926 training [INFO ] Epoch 18 Batch 3700 Training err. 2.56210 Training err. RA 2.99668 Valid. err. 2.64226
2018-02-03 23:56:08,401 training [INFO ] Epoch 18 Batch 3720 Training err. 2.62014 Training err. RA 2.99465 Valid. err. 2.63019
2018-02-03 23:56:08,874 training [INFO ] Epoch 18 Batch 3740 Training err. 2.62476 Training err. RA 2.99267 Valid. err. 2.62966
2018-02-03 23:56:09,703 training [INFO ] Epoch 19 Batch 3760 Training err. 2.59429 Training err. RA 2.99056 Valid. err. 2.62560
2018-02-03 23:56:10,175 training [INFO ] Epoch 19 Batch 3780 Training err. 2.51663 Training err. RA 2.98805 Valid. err. 2.62542
2018-02-03 23:56:10,654 training [INFO ] Epoch 19 Batch 3800 Training err. 2.62886 Training err. RA 2.98616 Valid. err. 2.64184
2018-02-03 23:56:11,128 training [INFO ] Epoch 19 Batch 3820 Training err. 2.58974 Training err. RA 2.98408 Valid. err. 2.62809
2018-02-03 23:56:11,607 training [INFO ] Epoch 19 Batch 3840 Training err. 2.54983 Training err. RA 2.98182 Valid. err. 2.62403
2018-02-03 23:56:12,086 training [INFO ] Epoch 19 Batch 3860 Training err. 2.63767 Training err. RA 2.98004 Valid. err. 2.62275
2018-02-03 23:56:12,565 training [INFO ] Epoch 19 Batch 3880 Training err. 2.58441 Training err. RA 2.97800 Valid. err. 2.61646
2018-02-03 23:56:13,045 training [INFO ] Epoch 19 Batch 3900 Training err. 2.55986 Training err. RA 2.97585 Valid. err. 2.59979
2018-02-03 23:56:13,526 training [INFO ] Epoch 19 Batch 3920 Training err. 2.56944 Training err. RA 2.97378 Valid. err. 2.59967
2018-02-03 23:56:14,007 training [INFO ] Epoch 19 Batch 3940 Training err. 2.56378 Training err. RA 2.97170 Valid. err. 2.59043
2018-02-03 23:56:14,853 training [INFO ] Epoch 20 Batch 3960 Training err. 2.58600 Training err. RA 2.96975 Valid. err. 2.59034
2018-02-03 23:56:15,331 training [INFO ] Epoch 20 Batch 3980 Training err. 2.49331 Training err. RA 2.96736 Valid. err. 2.58913
2018-02-03 23:56:15,811 training [INFO ] Epoch 20 Batch 4000 Training err. 2.58756 Training err. RA 2.96546 Valid. err. 2.59009
2018-02-03 23:56:16,356 training [INFO ] Epoch 20 Batch 4020 Training err. 2.55375 Training err. RA 2.96341 Valid. err. 2.58039
2018-02-03 23:56:16,888 training [INFO ] Epoch 20 Batch 4040 Training err. 2.51781 Training err. RA 2.96120 Valid. err. 2.59630
2018-02-03 23:56:17,455 training [INFO ] Epoch 20 Batch 4060 Training err. 2.56152 Training err. RA 2.95923 Valid. err. 2.61758
2018-02-03 23:56:17,960 training [INFO ] Epoch 20 Batch 4080 Training err. 2.58797 Training err. RA 2.95741 Valid. err. 2.57803
2018-02-03 23:56:18,458 training [INFO ] Epoch 20 Batch 4100 Training err. 2.54575 Training err. RA 2.95541 Valid. err. 2.58564
2018-02-03 23:56:18,980 training [INFO ] Epoch 20 Batch 4120 Training err. 2.49118 Training err. RA 2.95315 Valid. err. 2.57873
2018-02-03 23:56:19,485 training [INFO ] Epoch 20 Batch 4140 Training err. 2.55451 Training err. RA 2.95123 Valid. err. 2.55608
2018-02-03 23:56:19,980 training [INFO ] Epoch 20 Batch 4160 Training err. 2.54935 Training err. RA 2.94929 Valid. err. 2.57303
2018-02-03 23:56:20,840 training [INFO ] Epoch 21 Batch 4180 Training err. 2.51022 Training err. RA 2.94719 Valid. err. 2.55468
2018-02-03 23:56:21,317 training [INFO ] Epoch 21 Batch 4200 Training err. 2.47797 Training err. RA 2.94496 Valid. err. 2.55861
2018-02-03 23:56:21,848 training [INFO ] Epoch 21 Batch 4220 Training err. 2.52692 Training err. RA 2.94298 Valid. err. 2.55091
2018-02-03 23:56:22,384 training [INFO ] Epoch 21 Batch 4240 Training err. 2.52747 Training err. RA 2.94102 Valid. err. 2.54340
2018-02-03 23:56:22,982 training [INFO ] Epoch 21 Batch 4260 Training err. 2.50344 Training err. RA 2.93896 Valid. err. 2.54353
2018-02-03 23:56:23,509 training [INFO ] Epoch 21 Batch 4280 Training err. 2.56977 Training err. RA 2.93724 Valid. err. 2.54852
2018-02-03 23:56:24,016 training [INFO ] Epoch 21 Batch 4300 Training err. 2.51296 Training err. RA 2.93527 Valid. err. 2.54786
2018-02-03 23:56:24,584 training [INFO ] Epoch 21 Batch 4320 Training err. 2.48001 Training err. RA 2.93316 Valid. err. 2.54752
2018-02-03 23:56:25,094 training [INFO ] Epoch 21 Batch 4340 Training err. 2.51170 Training err. RA 2.93122 Valid. err. 2.52910
2018-02-03 23:56:25,571 training [INFO ] Epoch 21 Batch 4360 Training err. 2.50193 Training err. RA 2.92925 Valid. err. 2.53608
2018-02-03 23:56:26,401 training [INFO ] Epoch 22 Batch 4380 Training err. 2.50566 Training err. RA 2.92731 Valid. err. 2.53545
2018-02-03 23:56:26,875 training [INFO ] Epoch 22 Batch 4400 Training err. 2.40252 Training err. RA 2.92493 Valid. err. 2.52867
2018-02-03 23:56:27,353 training [INFO ] Epoch 22 Batch 4420 Training err. 2.54222 Training err. RA 2.92319 Valid. err. 2.51205
2018-02-03 23:56:27,830 training [INFO ] Epoch 22 Batch 4440 Training err. 2.49257 Training err. RA 2.92126 Valid. err. 2.51110
2018-02-03 23:56:28,308 training [INFO ] Epoch 22 Batch 4460 Training err. 2.46242 Training err. RA 2.91920 Valid. err. 2.51599
2018-02-03 23:56:28,942 training [INFO ] Epoch 22 Batch 4480 Training err. 2.50527 Training err. RA 2.91735 Valid. err. 2.52438
2018-02-03 23:56:29,420 training [INFO ] Epoch 22 Batch 4500 Training err. 2.52976 Training err. RA 2.91563 Valid. err. 2.51917
2018-02-03 23:56:29,894 training [INFO ] Epoch 22 Batch 4520 Training err. 2.46894 Training err. RA 2.91365 Valid. err. 2.50078
2018-02-03 23:56:30,372 training [INFO ] Epoch 22 Batch 4540 Training err. 2.46420 Training err. RA 2.91167 Valid. err. 2.51677
2018-02-03 23:56:30,852 training [INFO ] Epoch 22 Batch 4560 Training err. 2.46971 Training err. RA 2.90973 Valid. err. 2.49759
2018-02-03 23:56:31,691 training [INFO ] Epoch 23 Batch 4580 Training err. 2.48272 Training err. RA 2.90787 Valid. err. 2.48706
2018-02-03 23:56:32,167 training [INFO ] Epoch 23 Batch 4600 Training err. 2.43743 Training err. RA 2.90582 Valid. err. 2.48922
2018-02-03 23:56:32,646 training [INFO ] Epoch 23 Batch 4620 Training err. 2.44235 Training err. RA 2.90382 Valid. err. 2.51352
2018-02-03 23:56:33,126 training [INFO ] Epoch 23 Batch 4640 Training err. 2.46700 Training err. RA 2.90193 Valid. err. 2.49591
2018-02-03 23:56:33,603 training [INFO ] Epoch 23 Batch 4660 Training err. 2.43299 Training err. RA 2.89992 Valid. err. 2.55949
2018-02-03 23:56:34,081 training [INFO ] Epoch 23 Batch 4680 Training err. 2.47542 Training err. RA 2.89811 Valid. err. 2.49571
2018-02-03 23:56:34,559 training [INFO ] Epoch 23 Batch 4700 Training err. 2.52156 Training err. RA 2.89650 Valid. err. 2.49026
2018-02-03 23:56:35,037 training [INFO ] Epoch 23 Batch 4720 Training err. 2.43761 Training err. RA 2.89456 Valid. err. 2.47858
2018-02-03 23:56:35,520 training [INFO ] Epoch 23 Batch 4740 Training err. 2.41273 Training err. RA 2.89253 Valid. err. 2.47663
2018-02-03 23:56:36,101 training [INFO ] Epoch 23 Batch 4760 Training err. 2.45213 Training err. RA 2.89068 Valid. err. 2.45995
2018-02-03 23:56:36,866 training [INFO ] Epoch 23 Batch 4780 Training err. 2.45801 Training err. RA 2.88887 Valid. err. 2.48836
2018-02-03 23:56:37,713 training [INFO ] Epoch 24 Batch 4800 Training err. 2.43593 Training err. RA 2.88698 Valid. err. 2.46753
2018-02-03 23:56:38,187 training [INFO ] Epoch 24 Batch 4820 Training err. 2.35947 Training err. RA 2.88479 Valid. err. 2.46032
2018-02-03 23:56:38,667 training [INFO ] Epoch 24 Batch 4840 Training err. 2.47318 Training err. RA 2.88309 Valid. err. 2.47211
2018-02-03 23:56:39,145 training [INFO ] Epoch 24 Batch 4860 Training err. 2.43490 Training err. RA 2.88124 Valid. err. 2.45767
2018-02-03 23:56:39,621 training [INFO ] Epoch 24 Batch 4880 Training err. 2.40235 Training err. RA 2.87928 Valid. err. 2.46458
2018-02-03 23:56:40,100 training [INFO ] Epoch 24 Batch 4900 Training err. 2.48856 Training err. RA 2.87769 Valid. err. 2.47381
2018-02-03 23:56:40,576 training [INFO ] Epoch 24 Batch 4920 Training err. 2.44243 Training err. RA 2.87592 Valid. err. 2.45793
2018-02-03 23:56:41,059 training [INFO ] Epoch 24 Batch 4940 Training err. 2.41091 Training err. RA 2.87403 Valid. err. 2.44484
2018-02-03 23:56:41,542 training [INFO ] Epoch 24 Batch 4960 Training err. 2.41893 Training err. RA 2.87220 Valid. err. 2.43914
2018-02-03 23:56:42,024 training [INFO ] Epoch 24 Batch 4980 Training err. 2.40376 Training err. RA 2.87032 Valid. err. 2.43743
2018-02-03 23:56:42,989 training [INFO ] Epoch 25 Batch 5000 Training err. 2.43899 Training err. RA 2.86859 Valid. err. 2.43379
2018-02-03 23:56:43,529 training [INFO ] Epoch 25 Batch 5020 Training err. 2.34377 Training err. RA 2.86650 Valid. err. 2.43888
2018-02-03 23:56:44,099 training [INFO ] Epoch 25 Batch 5040 Training err. 2.43712 Training err. RA 2.86480 Valid. err. 2.43642
2018-02-03 23:56:44,582 training [INFO ] Epoch 25 Batch 5060 Training err. 2.41425 Training err. RA 2.86302 Valid. err. 2.43242
2018-02-03 23:56:45,141 training [INFO ] Epoch 25 Batch 5080 Training err. 2.37407 Training err. RA 2.86109 Valid. err. 2.45145
2018-02-03 23:56:45,614 training [INFO ] Epoch 25 Batch 5100 Training err. 2.40797 Training err. RA 2.85932 Valid. err. 2.47314
2018-02-03 23:56:46,090 training [INFO ] Epoch 25 Batch 5120 Training err. 2.46396 Training err. RA 2.85777 Valid. err. 2.43318
2018-02-03 23:56:46,568 training [INFO ] Epoch 25 Batch 5140 Training err. 2.40376 Training err. RA 2.85600 Valid. err. 2.45471
2018-02-03 23:56:47,053 training [INFO ] Epoch 25 Batch 5160 Training err. 2.35568 Training err. RA 2.85407 Valid. err. 2.41737
2018-02-03 23:56:47,610 training [INFO ] Epoch 25 Batch 5180 Training err. 2.40294 Training err. RA 2.85232 Valid. err. 2.41021
2018-02-03 23:56:48,090 training [INFO ] Epoch 25 Batch 5200 Training err. 2.40657 Training err. RA 2.85061 Valid. err. 2.42044
2018-02-03 23:56:49,118 training [INFO ] Epoch 26 Batch 5220 Training err. 2.37300 Training err. RA 2.84878 Valid. err. 2.42464
2018-02-03 23:56:49,699 training [INFO ] Epoch 26 Batch 5240 Training err. 2.33132 Training err. RA 2.84680 Valid. err. 2.41391
2018-02-03 23:56:50,269 training [INFO ] Epoch 26 Batch 5260 Training err. 2.39713 Training err. RA 2.84509 Valid. err. 2.40812
2018-02-03 23:56:50,774 training [INFO ] Epoch 26 Batch 5280 Training err. 2.39352 Training err. RA 2.84338 Valid. err. 2.40398
2018-02-03 23:56:51,327 training [INFO ] Epoch 26 Batch 5300 Training err. 2.36921 Training err. RA 2.84159 Valid. err. 2.40705
2018-02-03 23:56:51,882 training [INFO ] Epoch 26 Batch 5320 Training err. 2.44017 Training err. RA 2.84009 Valid. err. 2.40463
2018-02-03 23:56:52,379 training [INFO ] Epoch 26 Batch 5340 Training err. 2.38190 Training err. RA 2.83837 Valid. err. 2.41369
2018-02-03 23:56:52,888 training [INFO ] Epoch 26 Batch 5360 Training err. 2.35053 Training err. RA 2.83655 Valid. err. 2.42861
2018-02-03 23:56:53,363 training [INFO ] Epoch 26 Batch 5380 Training err. 2.37162 Training err. RA 2.83482 Valid. err. 2.39704
2018-02-03 23:56:53,976 training [INFO ] Epoch 26 Batch 5400 Training err. 2.36773 Training err. RA 2.83309 Valid. err. 2.40986
2018-02-03 23:56:54,907 training [INFO ] Epoch 27 Batch 5420 Training err. 2.37775 Training err. RA 2.83141 Valid. err. 2.39470
2018-02-03 23:56:55,477 training [INFO ] Epoch 27 Batch 5440 Training err. 2.27420 Training err. RA 2.82936 Valid. err. 2.39495
2018-02-03 23:56:55,953 training [INFO ] Epoch 27 Batch 5460 Training err. 2.40656 Training err. RA 2.82781 Valid. err. 2.38426
2018-02-03 23:56:56,425 training [INFO ] Epoch 27 Batch 5480 Training err. 2.36844 Training err. RA 2.82614 Valid. err. 2.38140
2018-02-03 23:56:56,907 training [INFO ] Epoch 27 Batch 5500 Training err. 2.33427 Training err. RA 2.82435 Valid. err. 2.39593
2018-02-03 23:56:57,388 training [INFO ] Epoch 27 Batch 5520 Training err. 2.37779 Training err. RA 2.82273 Valid. err. 2.40010
2018-02-03 23:56:57,976 training [INFO ] Epoch 27 Batch 5540 Training err. 2.40986 Training err. RA 2.82124 Valid. err. 2.39145
2018-02-03 23:56:58,547 training [INFO ] Epoch 27 Batch 5560 Training err. 2.34429 Training err. RA 2.81952 Valid. err. 2.37435
2018-02-03 23:56:59,099 training [INFO ] Epoch 27 Batch 5580 Training err. 2.33679 Training err. RA 2.81779 Valid. err. 2.39674
2018-02-03 23:56:59,668 training [INFO ] Epoch 27 Batch 5600 Training err. 2.34386 Training err. RA 2.81610 Valid. err. 2.37439
2018-02-03 23:57:00,547 training [INFO ] Epoch 28 Batch 5620 Training err. 2.35819 Training err. RA 2.81447 Valid. err. 2.36609
2018-02-03 23:57:01,039 training [INFO ] Epoch 28 Batch 5640 Training err. 2.31315 Training err. RA 2.81269 Valid. err. 2.37231
2018-02-03 23:57:01,539 training [INFO ] Epoch 28 Batch 5660 Training err. 2.31011 Training err. RA 2.81092 Valid. err. 2.40329
2018-02-03 23:57:02,034 training [INFO ] Epoch 28 Batch 5680 Training err. 2.35535 Training err. RA 2.80931 Valid. err. 2.36936
2018-02-03 23:57:02,593 training [INFO ] Epoch 28 Batch 5700 Training err. 2.31496 Training err. RA 2.80758 Valid. err. 2.42191
2018-02-03 23:57:03,094 training [INFO ] Epoch 28 Batch 5720 Training err. 2.35496 Training err. RA 2.80600 Valid. err. 2.36741
2018-02-03 23:57:03,614 training [INFO ] Epoch 28 Batch 5740 Training err. 2.40817 Training err. RA 2.80461 Valid. err. 2.36641
2018-02-03 23:57:04,138 training [INFO ] Epoch 28 Batch 5760 Training err. 2.31618 Training err. RA 2.80291 Valid. err. 2.36208
2018-02-03 23:57:04,649 training [INFO ] Epoch 28 Batch 5780 Training err. 2.29944 Training err. RA 2.80117 Valid. err. 2.36531
2018-02-03 23:57:05,146 training [INFO ] Epoch 28 Batch 5800 Training err. 2.32802 Training err. RA 2.79954 Valid. err. 2.34494
2018-02-03 23:57:05,634 training [INFO ] Epoch 28 Batch 5820 Training err. 2.33689 Training err. RA 2.79795 Valid. err. 2.37600
2018-02-03 23:57:06,556 training [INFO ] Epoch 29 Batch 5840 Training err. 2.31974 Training err. RA 2.79631 Valid. err. 2.35970
2018-02-03 23:57:07,048 training [INFO ] Epoch 29 Batch 5860 Training err. 2.24783 Training err. RA 2.79444 Valid. err. 2.35025
2018-02-03 23:57:07,632 training [INFO ] Epoch 29 Batch 5880 Training err. 2.35076 Training err. RA 2.79293 Valid. err. 2.36107
2018-02-03 23:57:08,325 training [INFO ] Epoch 29 Batch 5900 Training err. 2.32347 Training err. RA 2.79134 Valid. err. 2.34651
2018-02-03 23:57:09,121 training [INFO ] Epoch 29 Batch 5920 Training err. 2.29691 Training err. RA 2.78967 Valid. err. 2.36311
2018-02-03 23:57:09,739 training [INFO ] Epoch 29 Batch 5940 Training err. 2.37454 Training err. RA 2.78827 Valid. err. 2.36520
2018-02-03 23:57:10,311 training [INFO ] Epoch 29 Batch 5960 Training err. 2.33046 Training err. RA 2.78674 Valid. err. 2.34341
2018-02-03 23:57:10,912 training [INFO ] Epoch 29 Batch 5980 Training err. 2.29601 Training err. RA 2.78510 Valid. err. 2.33449
2018-02-03 23:57:11,482 training [INFO ] Epoch 29 Batch 6000 Training err. 2.30653 Training err. RA 2.78350 Valid. err. 2.32774
2018-02-03 23:57:12,051 training [INFO ] Epoch 29 Batch 6020 Training err. 2.29211 Training err. RA 2.78187 Valid. err. 2.33065
2018-02-03 23:57:13,035 training [INFO ] Epoch 30 Batch 6040 Training err. 2.32469 Training err. RA 2.78035 Valid. err. 2.32517
2018-02-03 23:57:13,543 training [INFO ] Epoch 30 Batch 6060 Training err. 2.23553 Training err. RA 2.77856 Valid. err. 2.32752
2018-02-03 23:57:14,056 training [INFO ] Epoch 30 Batch 6080 Training err. 2.31786 Training err. RA 2.77704 Valid. err. 2.33951
2018-02-03 23:57:14,549 training [INFO ] Epoch 30 Batch 6100 Training err. 2.31164 Training err. RA 2.77551 Valid. err. 2.32651
2018-02-03 23:57:15,047 training [INFO ] Epoch 30 Batch 6120 Training err. 2.27194 Training err. RA 2.77387 Valid. err. 2.34075
2018-02-03 23:57:15,558 training [INFO ] Epoch 30 Batch 6140 Training err. 2.29979 Training err. RA 2.77232 Valid. err. 2.36659
2018-02-03 23:57:16,096 training [INFO ] Epoch 30 Batch 6160 Training err. 2.36021 Training err. RA 2.77099 Valid. err. 2.32357
2018-02-03 23:57:16,793 training [INFO ] Epoch 30 Batch 6180 Training err. 2.29133 Training err. RA 2.76943 Valid. err. 2.35810
2018-02-03 23:57:17,391 training [INFO ] Epoch 30 Batch 6200 Training err. 2.25319 Training err. RA 2.76777 Valid. err. 2.31087
2018-02-03 23:57:17,990 training [INFO ] Epoch 30 Batch 6220 Training err. 2.29487 Training err. RA 2.76625 Valid. err. 2.30571
2018-02-03 23:57:18,589 training [INFO ] Epoch 30 Batch 6240 Training err. 2.29425 Training err. RA 2.76474 Valid. err. 2.31726
2018-02-03 23:57:19,572 training [INFO ] Epoch 31 Batch 6260 Training err. 2.26998 Training err. RA 2.76315 Valid. err. 2.32542
2018-02-03 23:57:20,130 training [INFO ] Epoch 31 Batch 6280 Training err. 2.22623 Training err. RA 2.76144 Valid. err. 2.31157
2018-02-03 23:57:20,701 training [INFO ] Epoch 31 Batch 6300 Training err. 2.29206 Training err. RA 2.75995 Valid. err. 2.30775
2018-02-03 23:57:21,244 training [INFO ] Epoch 31 Batch 6320 Training err. 2.29403 Training err. RA 2.75848 Valid. err. 2.30430
2018-02-03 23:57:21,727 training [INFO ] Epoch 31 Batch 6340 Training err. 2.27358 Training err. RA 2.75695 Valid. err. 2.31431
2018-02-03 23:57:22,204 training [INFO ] Epoch 31 Batch 6360 Training err. 2.33544 Training err. RA 2.75562 Valid. err. 2.30010
2018-02-03 23:57:22,682 training [INFO ] Epoch 31 Batch 6380 Training err. 2.27924 Training err. RA 2.75413 Valid. err. 2.30661
2018-02-03 23:57:23,160 training [INFO ] Epoch 31 Batch 6400 Training err. 2.24709 Training err. RA 2.75255 Valid. err. 2.34005
2018-02-03 23:57:23,638 training [INFO ] Epoch 31 Batch 6420 Training err. 2.26941 Training err. RA 2.75104 Valid. err. 2.30081
2018-02-03 23:57:24,113 training [INFO ] Epoch 31 Batch 6440 Training err. 2.26669 Training err. RA 2.74954 Valid. err. 2.30364
2018-02-03 23:57:25,140 training [INFO ] Epoch 32 Batch 6460 Training err. 2.27332 Training err. RA 2.74806 Valid. err. 2.29609
2018-02-03 23:57:25,772 training [INFO ] Epoch 32 Batch 6480 Training err. 2.17982 Training err. RA 2.74631 Valid. err. 2.29479
2018-02-03 23:57:26,366 training [INFO ] Epoch 32 Batch 6500 Training err. 2.29741 Training err. RA 2.74493 Valid. err. 2.28992
2018-02-03 23:57:26,870 training [INFO ] Epoch 32 Batch 6520 Training err. 2.27569 Training err. RA 2.74349 Valid. err. 2.29132
2018-02-03 23:57:27,348 training [INFO ] Epoch 32 Batch 6540 Training err. 2.24183 Training err. RA 2.74195 Valid. err. 2.30451
2018-02-03 23:57:27,845 training [INFO ] Epoch 32 Batch 6560 Training err. 2.27928 Training err. RA 2.74054 Valid. err. 2.30946
2018-02-03 23:57:28,343 training [INFO ] Epoch 32 Batch 6580 Training err. 2.31507 Training err. RA 2.73925 Valid. err. 2.29212
2018-02-03 23:57:28,825 training [INFO ] Epoch 32 Batch 6600 Training err. 2.24063 Training err. RA 2.73774 Valid. err. 2.28544
2018-02-03 23:57:29,334 training [INFO ] Epoch 32 Batch 6620 Training err. 2.24076 Training err. RA 2.73624 Valid. err. 2.31308
2018-02-03 23:57:29,824 training [INFO ] Epoch 32 Batch 6640 Training err. 2.24959 Training err. RA 2.73477 Valid. err. 2.28059
2018-02-03 23:57:30,705 training [INFO ] Epoch 33 Batch 6660 Training err. 2.25545 Training err. RA 2.73333 Valid. err. 2.27529
2018-02-03 23:57:31,290 training [INFO ] Epoch 33 Batch 6680 Training err. 2.21765 Training err. RA 2.73179 Valid. err. 2.27960
2018-02-03 23:57:31,939 training [INFO ] Epoch 33 Batch 6700 Training err. 2.21491 Training err. RA 2.73025 Valid. err. 2.29958
2018-02-03 23:57:32,525 training [INFO ] Epoch 33 Batch 6720 Training err. 2.26185 Training err. RA 2.72885 Valid. err. 2.27599
2018-02-03 23:57:33,129 training [INFO ] Epoch 33 Batch 6740 Training err. 2.22707 Training err. RA 2.72736 Valid. err. 2.33310
2018-02-03 23:57:33,692 training [INFO ] Epoch 33 Batch 6760 Training err. 2.26461 Training err. RA 2.72599 Valid. err. 2.27727
2018-02-03 23:57:34,313 training [INFO ] Epoch 33 Batch 6780 Training err. 2.31414 Training err. RA 2.72478 Valid. err. 2.27461
2018-02-03 23:57:34,948 training [INFO ] Epoch 33 Batch 6800 Training err. 2.21918 Training err. RA 2.72329 Valid. err. 2.27090
2018-02-03 23:57:35,538 training [INFO ] Epoch 33 Batch 6820 Training err. 2.20675 Training err. RA 2.72178 Valid. err. 2.27686
2018-02-03 23:57:36,097 training [INFO ] Epoch 33 Batch 6840 Training err. 2.23592 Training err. RA 2.72036 Valid. err. 2.25925
2018-02-03 23:57:36,653 training [INFO ] Epoch 33 Batch 6860 Training err. 2.23926 Training err. RA 2.71895 Valid. err. 2.27708
2018-02-03 23:57:37,654 training [INFO ] Epoch 34 Batch 6880 Training err. 2.22660 Training err. RA 2.71752 Valid. err. 2.27941
2018-02-03 23:57:38,217 training [INFO ] Epoch 34 Batch 6900 Training err. 2.16153 Training err. RA 2.71591 Valid. err. 2.26380
2018-02-03 23:57:38,772 training [INFO ] Epoch 34 Batch 6920 Training err. 2.25563 Training err. RA 2.71458 Valid. err. 2.26954
2018-02-03 23:57:39,294 training [INFO ] Epoch 34 Batch 6940 Training err. 2.23768 Training err. RA 2.71321 Valid. err. 2.26166
2018-02-03 23:57:39,819 training [INFO ] Epoch 34 Batch 6960 Training err. 2.21469 Training err. RA 2.71177 Valid. err. 2.30600
2018-02-03 23:57:40,308 training [INFO ] Epoch 34 Batch 6980 Training err. 2.28136 Training err. RA 2.71054 Valid. err. 2.27603
2018-02-03 23:57:40,795 training [INFO ] Epoch 34 Batch 7000 Training err. 2.24419 Training err. RA 2.70921 Valid. err. 2.25657
2018-02-03 23:57:41,302 training [INFO ] Epoch 34 Batch 7020 Training err. 2.20039 Training err. RA 2.70776 Valid. err. 2.24908
2018-02-03 23:57:41,803 training [INFO ] Epoch 34 Batch 7040 Training err. 2.21871 Training err. RA 2.70637 Valid. err. 2.24321
2018-02-03 23:57:42,300 training [INFO ] Epoch 34 Batch 7060 Training err. 2.20472 Training err. RA 2.70495 Valid. err. 2.24674
2018-02-03 23:57:43,213 training [INFO ] Epoch 35 Batch 7080 Training err. 2.22986 Training err. RA 2.70361 Valid. err. 2.24260
2018-02-03 23:57:43,713 training [INFO ] Epoch 35 Batch 7100 Training err. 2.15159 Training err. RA 2.70205 Valid. err. 2.24372
2018-02-03 23:57:44,218 training [INFO ] Epoch 35 Batch 7120 Training err. 2.22703 Training err. RA 2.70072 Valid. err. 2.26049
2018-02-03 23:57:44,725 training [INFO ] Epoch 35 Batch 7140 Training err. 2.22867 Training err. RA 2.69939 Valid. err. 2.25129
2018-02-03 23:57:45,248 training [INFO ] Epoch 35 Batch 7160 Training err. 2.19005 Training err. RA 2.69797 Valid. err. 2.25474
2018-02-03 23:57:45,790 training [INFO ] Epoch 35 Batch 7180 Training err. 2.21538 Training err. RA 2.69663 Valid. err. 2.27452
2018-02-03 23:57:46,308 training [INFO ] Epoch 35 Batch 7200 Training err. 2.27653 Training err. RA 2.69546 Valid. err. 2.24218
2018-02-03 23:57:46,804 training [INFO ] Epoch 35 Batch 7220 Training err. 2.19908 Training err. RA 2.69409 Valid. err. 2.26342
2018-02-03 23:57:47,281 training [INFO ] Epoch 35 Batch 7240 Training err. 2.16992 Training err. RA 2.69264 Valid. err. 2.22815
2018-02-03 23:57:47,759 training [INFO ] Epoch 35 Batch 7260 Training err. 2.21057 Training err. RA 2.69131 Valid. err. 2.22676
2018-02-03 23:57:48,251 training [INFO ] Epoch 35 Batch 7280 Training err. 2.20268 Training err. RA 2.68997 Valid. err. 2.23479
2018-02-03 23:57:49,256 training [INFO ] Epoch 36 Batch 7300 Training err. 2.18783 Training err. RA 2.68859 Valid. err. 2.24707
2018-02-03 23:57:49,755 training [INFO ] Epoch 36 Batch 7320 Training err. 2.14419 Training err. RA 2.68710 Valid. err. 2.23725
2018-02-03 23:57:50,245 training [INFO ] Epoch 36 Batch 7340 Training err. 2.20846 Training err. RA 2.68580 Valid. err. 2.22810
2018-02-03 23:57:50,735 training [INFO ] Epoch 36 Batch 7360 Training err. 2.21602 Training err. RA 2.68452 Valid. err. 2.22997
2018-02-03 23:57:51,246 training [INFO ] Epoch 36 Batch 7380 Training err. 2.19399 Training err. RA 2.68319 Valid. err. 2.23485
2018-02-03 23:57:51,774 training [INFO ] Epoch 36 Batch 7400 Training err. 2.24981 Training err. RA 2.68202 Valid. err. 2.22484
2018-02-03 23:57:52,272 training [INFO ] Epoch 36 Batch 7420 Training err. 2.19922 Training err. RA 2.68072 Valid. err. 2.22369
2018-02-03 23:57:52,778 training [INFO ] Epoch 36 Batch 7440 Training err. 2.16205 Training err. RA 2.67933 Valid. err. 2.26655
2018-02-03 23:57:53,344 training [INFO ] Epoch 36 Batch 7460 Training err. 2.18739 Training err. RA 2.67801 Valid. err. 2.22349
2018-02-03 23:57:53,861 training [INFO ] Epoch 36 Batch 7480 Training err. 2.18347 Training err. RA 2.67669 Valid. err. 2.22323
2018-02-03 23:57:54,749 training [INFO ] Epoch 37 Batch 7500 Training err. 2.18913 Training err. RA 2.67539 Valid. err. 2.22035
2018-02-03 23:57:55,285 training [INFO ] Epoch 37 Batch 7520 Training err. 2.10513 Training err. RA 2.67387 Valid. err. 2.21980
2018-02-03 23:57:55,823 training [INFO ] Epoch 37 Batch 7540 Training err. 2.21211 Training err. RA 2.67264 Valid. err. 2.21631
2018-02-03 23:57:56,396 training [INFO ] Epoch 37 Batch 7560 Training err. 2.20077 Training err. RA 2.67140 Valid. err. 2.21961
2018-02-03 23:57:56,878 training [INFO ] Epoch 37 Batch 7580 Training err. 2.16425 Training err. RA 2.67006 Valid. err. 2.23461
2018-02-03 23:57:57,368 training [INFO ] Epoch 37 Batch 7600 Training err. 2.19932 Training err. RA 2.66882 Valid. err. 2.23080
2018-02-03 23:57:57,888 training [INFO ] Epoch 37 Batch 7620 Training err. 2.24073 Training err. RA 2.66770 Valid. err. 2.21828
2018-02-03 23:57:58,411 training [INFO ] Epoch 37 Batch 7640 Training err. 2.15662 Training err. RA 2.66636 Valid. err. 2.21467
2018-02-03 23:57:58,929 training [INFO ] Epoch 37 Batch 7660 Training err. 2.16254 Training err. RA 2.66504 Valid. err. 2.23773
2018-02-03 23:57:59,428 training [INFO ] Epoch 37 Batch 7680 Training err. 2.17183 Training err. RA 2.66376 Valid. err. 2.20572
2018-02-03 23:58:00,332 training [INFO ] Epoch 38 Batch 7700 Training err. 2.17192 Training err. RA 2.66248 Valid. err. 2.20339
2018-02-03 23:58:00,813 training [INFO ] Epoch 38 Batch 7720 Training err. 2.14083 Training err. RA 2.66113 Valid. err. 2.20468
2018-02-03 23:58:01,306 training [INFO ] Epoch 38 Batch 7740 Training err. 2.13977 Training err. RA 2.65978 Valid. err. 2.20546
2018-02-03 23:58:01,787 training [INFO ] Epoch 38 Batch 7760 Training err. 2.18549 Training err. RA 2.65856 Valid. err. 2.20428
2018-02-03 23:58:02,291 training [INFO ] Epoch 38 Batch 7780 Training err. 2.15507 Training err. RA 2.65727 Valid. err. 2.24204
2018-02-03 23:58:02,788 training [INFO ] Epoch 38 Batch 7800 Training err. 2.18803 Training err. RA 2.65606 Valid. err. 2.20566
2018-02-03 23:58:03,274 training [INFO ] Epoch 38 Batch 7820 Training err. 2.23863 Training err. RA 2.65499 Valid. err. 2.20600
2018-02-03 23:58:03,755 training [INFO ] Epoch 38 Batch 7840 Training err. 2.14495 Training err. RA 2.65369 Valid. err. 2.20407
2018-02-03 23:58:04,244 training [INFO ] Epoch 38 Batch 7860 Training err. 2.12981 Training err. RA 2.65236 Valid. err. 2.20309
2018-02-03 23:58:04,721 training [INFO ] Epoch 38 Batch 7880 Training err. 2.15931 Training err. RA 2.65111 Valid. err. 2.18981
2018-02-03 23:58:05,205 training [INFO ] Epoch 38 Batch 7900 Training err. 2.16010 Training err. RA 2.64987 Valid. err. 2.20590
2018-02-03 23:58:06,060 training [INFO ] Epoch 39 Batch 7920 Training err. 2.15059 Training err. RA 2.64860 Valid. err. 2.20516
2018-02-03 23:58:06,539 training [INFO ] Epoch 39 Batch 7940 Training err. 2.09132 Training err. RA 2.64720 Valid. err. 2.19804
2018-02-03 23:58:07,024 training [INFO ] Epoch 39 Batch 7960 Training err. 2.17855 Training err. RA 2.64602 Valid. err. 2.19754
2018-02-03 23:58:07,505 training [INFO ] Epoch 39 Batch 7980 Training err. 2.16645 Training err. RA 2.64482 Valid. err. 2.19545
2018-02-03 23:58:07,986 training [INFO ] Epoch 39 Batch 8000 Training err. 2.14629 Training err. RA 2.64358 Valid. err. 2.24484
2018-02-03 23:58:08,463 training [INFO ] Epoch 39 Batch 8020 Training err. 2.20445 Training err. RA 2.64248 Valid. err. 2.20876
2018-02-03 23:58:09,025 training [INFO ] Epoch 39 Batch 8040 Training err. 2.17661 Training err. RA 2.64132 Valid. err. 2.18914
2018-02-03 23:58:09,530 training [INFO ] Epoch 39 Batch 8060 Training err. 2.12521 Training err. RA 2.64004 Valid. err. 2.18041
2018-02-03 23:58:10,053 training [INFO ] Epoch 39 Batch 8080 Training err. 2.14406 Training err. RA 2.63881 Valid. err. 2.17481
2018-02-03 23:58:10,557 training [INFO ] Epoch 39 Batch 8100 Training err. 2.13231 Training err. RA 2.63756 Valid. err. 2.17612
2018-02-03 23:58:11,469 training [INFO ] Epoch 40 Batch 8120 Training err. 2.15352 Training err. RA 2.63637 Valid. err. 2.17785
2018-02-03 23:58:12,013 training [INFO ] Epoch 40 Batch 8140 Training err. 2.08174 Training err. RA 2.63501 Valid. err. 2.17596
2018-02-03 23:58:12,524 training [INFO ] Epoch 40 Batch 8160 Training err. 2.15268 Training err. RA 2.63383 Valid. err. 2.19224
2018-02-03 23:58:13,034 training [INFO ] Epoch 40 Batch 8180 Training err. 2.16170 Training err. RA 2.63267 Valid. err. 2.18181
2018-02-03 23:58:13,545 training [INFO ] Epoch 40 Batch 8200 Training err. 2.12057 Training err. RA 2.63142 Valid. err. 2.18374
2018-02-03 23:58:14,092 training [INFO ] Epoch 40 Batch 8220 Training err. 2.14359 Training err. RA 2.63023 Valid. err. 2.20579
2018-02-03 23:58:14,608 training [INFO ] Epoch 40 Batch 8240 Training err. 2.21074 Training err. RA 2.62922 Valid. err. 2.17593
2018-02-03 23:58:15,099 training [INFO ] Epoch 40 Batch 8260 Training err. 2.13045 Training err. RA 2.62801 Valid. err. 2.19060
2018-02-03 23:58:15,669 training [INFO ] Epoch 40 Batch 8280 Training err. 2.09808 Training err. RA 2.62673 Valid. err. 2.16181
2018-02-03 23:58:16,210 training [INFO ] Epoch 40 Batch 8300 Training err. 2.13978 Training err. RA 2.62556 Valid. err. 2.16352
2018-02-03 23:58:16,691 training [INFO ] Epoch 40 Batch 8320 Training err. 2.12648 Training err. RA 2.62436 Valid. err. 2.16984
2018-02-03 23:58:17,571 training [INFO ] Epoch 41 Batch 8340 Training err. 2.12133 Training err. RA 2.62315 Valid. err. 2.17718
2018-02-03 23:58:18,059 training [INFO ] Epoch 41 Batch 8360 Training err. 2.07662 Training err. RA 2.62184 Valid. err. 2.17229
2018-02-03 23:58:18,547 training [INFO ] Epoch 41 Batch 8380 Training err. 2.13879 Training err. RA 2.62069 Valid. err. 2.16292
2018-02-03 23:58:19,058 training [INFO ] Epoch 41 Batch 8400 Training err. 2.14925 Training err. RA 2.61957 Valid. err. 2.16801
2018-02-03 23:58:19,585 training [INFO ] Epoch 41 Batch 8420 Training err. 2.12690 Training err. RA 2.61840 Valid. err. 2.17516
2018-02-03 23:58:20,097 training [INFO ] Epoch 41 Batch 8440 Training err. 2.18207 Training err. RA 2.61736 Valid. err. 2.16709
2018-02-03 23:58:20,599 training [INFO ] Epoch 41 Batch 8460 Training err. 2.13469 Training err. RA 2.61622 Valid. err. 2.16067
2018-02-03 23:58:21,216 training [INFO ] Epoch 41 Batch 8480 Training err. 2.09479 Training err. RA 2.61499 Valid. err. 2.19409
2018-02-03 23:58:21,784 training [INFO ] Epoch 41 Batch 8500 Training err. 2.11811 Training err. RA 2.61382 Valid. err. 2.16115
2018-02-03 23:58:22,439 training [INFO ] Epoch 41 Batch 8520 Training err. 2.11309 Training err. RA 2.61265 Valid. err. 2.15453
2018-02-03 23:58:23,546 training [INFO ] Epoch 42 Batch 8540 Training err. 2.12297 Training err. RA 2.61150 Valid. err. 2.15572
2018-02-03 23:58:24,046 training [INFO ] Epoch 42 Batch 8560 Training err. 2.04117 Training err. RA 2.61017 Valid. err. 2.15958
2018-02-03 23:58:24,609 training [INFO ] Epoch 42 Batch 8580 Training err. 2.14140 Training err. RA 2.60908 Valid. err. 2.15176
2018-02-03 23:58:25,223 training [INFO ] Epoch 42 Batch 8600 Training err. 2.13712 Training err. RA 2.60798 Valid. err. 2.15427
2018-02-03 23:58:25,701 training [INFO ] Epoch 42 Batch 8620 Training err. 2.10024 Training err. RA 2.60680 Valid. err. 2.16877
2018-02-03 23:58:26,198 training [INFO ] Epoch 42 Batch 8640 Training err. 2.13241 Training err. RA 2.60570 Valid. err. 2.16230
2018-02-03 23:58:26,687 training [INFO ] Epoch 42 Batch 8660 Training err. 2.17992 Training err. RA 2.60472 Valid. err. 2.15630
2018-02-03 23:58:27,162 training [INFO ] Epoch 42 Batch 8680 Training err. 2.09160 Training err. RA 2.60354 Valid. err. 2.14710
2018-02-03 23:58:27,640 training [INFO ] Epoch 42 Batch 8700 Training err. 2.09631 Training err. RA 2.60237 Valid. err. 2.17316
2018-02-03 23:58:28,119 training [INFO ] Epoch 42 Batch 8720 Training err. 2.10534 Training err. RA 2.60123 Valid. err. 2.14452
2018-02-03 23:58:28,980 training [INFO ] Epoch 43 Batch 8740 Training err. 2.10598 Training err. RA 2.60010 Valid. err. 2.14807
2018-02-03 23:58:29,462 training [INFO ] Epoch 43 Batch 8760 Training err. 2.07631 Training err. RA 2.59890 Valid. err. 2.14187
2018-02-03 23:58:29,949 training [INFO ] Epoch 43 Batch 8780 Training err. 2.07864 Training err. RA 2.59772 Valid. err. 2.13827
2018-02-03 23:58:30,448 training [INFO ] Epoch 43 Batch 8800 Training err. 2.12001 Training err. RA 2.59663 Valid. err. 2.14772
2018-02-03 23:58:30,937 training [INFO ] Epoch 43 Batch 8820 Training err. 2.09418 Training err. RA 2.59549 Valid. err. 2.16919
2018-02-03 23:58:31,418 training [INFO ] Epoch 43 Batch 8840 Training err. 2.12211 Training err. RA 2.59442 Valid. err. 2.14603
2018-02-03 23:58:31,896 training [INFO ] Epoch 43 Batch 8860 Training err. 2.17871 Training err. RA 2.59348 Valid. err. 2.14937
2018-02-03 23:58:32,373 training [INFO ] Epoch 43 Batch 8880 Training err. 2.08371 Training err. RA 2.59233 Valid. err. 2.14193
2018-02-03 23:58:32,847 training [INFO ] Epoch 43 Batch 8900 Training err. 2.06715 Training err. RA 2.59115 Valid. err. 2.13845
2018-02-03 23:58:33,322 training [INFO ] Epoch 43 Batch 8920 Training err. 2.09594 Training err. RA 2.59004 Valid. err. 2.13021
2018-02-03 23:58:33,799 training [INFO ] Epoch 43 Batch 8940 Training err. 2.09280 Training err. RA 2.58893 Valid. err. 2.14363
2018-02-03 23:58:34,640 training [INFO ] Epoch 44 Batch 8960 Training err. 2.09066 Training err. RA 2.58782 Valid. err. 2.13570
2018-02-03 23:58:35,116 training [INFO ] Epoch 44 Batch 8980 Training err. 2.03248 Training err. RA 2.58658 Valid. err. 2.14704
2018-02-03 23:58:35,587 training [INFO ] Epoch 44 Batch 9000 Training err. 2.11525 Training err. RA 2.58553 Valid. err. 2.13107
2018-02-03 23:58:36,065 training [INFO ] Epoch 44 Batch 9020 Training err. 2.10554 Training err. RA 2.58447 Valid. err. 2.13674
2018-02-03 23:58:36,553 training [INFO ] Epoch 44 Batch 9040 Training err. 2.08713 Training err. RA 2.58337 Valid. err. 2.17824
2018-02-03 23:58:37,049 training [INFO ] Epoch 44 Batch 9060 Training err. 2.14226 Training err. RA 2.58240 Valid. err. 2.15472
2018-02-03 23:58:37,545 training [INFO ] Epoch 44 Batch 9080 Training err. 2.12016 Training err. RA 2.58138 Valid. err. 2.13179
2018-02-03 23:58:38,042 training [INFO ] Epoch 44 Batch 9100 Training err. 2.06482 Training err. RA 2.58024 Valid. err. 2.12352
2018-02-03 23:58:38,530 training [INFO ] Epoch 44 Batch 9120 Training err. 2.08114 Training err. RA 2.57915 Valid. err. 2.11718
2018-02-03 23:58:39,025 training [INFO ] Epoch 44 Batch 9140 Training err. 2.07194 Training err. RA 2.57804 Valid. err. 2.11945
2018-02-03 23:58:39,914 training [INFO ] Epoch 45 Batch 9160 Training err. 2.09316 Training err. RA 2.57698 Valid. err. 2.12442
2018-02-03 23:58:40,410 training [INFO ] Epoch 45 Batch 9180 Training err. 2.02214 Training err. RA 2.57577 Valid. err. 2.12133
2018-02-03 23:58:40,911 training [INFO ] Epoch 45 Batch 9200 Training err. 2.09524 Training err. RA 2.57473 Valid. err. 2.12537
2018-02-03 23:58:41,404 training [INFO ] Epoch 45 Batch 9220 Training err. 2.10253 Training err. RA 2.57370 Valid. err. 2.12796
2018-02-03 23:58:41,895 training [INFO ] Epoch 45 Batch 9240 Training err. 2.06485 Training err. RA 2.57260 Valid. err. 2.12641
2018-02-03 23:58:42,394 training [INFO ] Epoch 45 Batch 9260 Training err. 2.08111 Training err. RA 2.57154 Valid. err. 2.14746
2018-02-03 23:58:42,882 training [INFO ] Epoch 45 Batch 9280 Training err. 2.15527 Training err. RA 2.57064 Valid. err. 2.11943
2018-02-03 23:58:43,371 training [INFO ] Epoch 45 Batch 9300 Training err. 2.07415 Training err. RA 2.56957 Valid. err. 2.13345
2018-02-03 23:58:43,863 training [INFO ] Epoch 45 Batch 9320 Training err. 2.03870 Training err. RA 2.56843 Valid. err. 2.10705
2018-02-03 23:58:44,366 training [INFO ] Epoch 45 Batch 9340 Training err. 2.08055 Training err. RA 2.56739 Valid. err. 2.10597
2018-02-03 23:58:44,871 training [INFO ] Epoch 45 Batch 9360 Training err. 2.06294 Training err. RA 2.56631 Valid. err. 2.11548
2018-02-03 23:58:45,713 training [INFO ] Epoch 46 Batch 9380 Training err. 2.06864 Training err. RA 2.56525 Valid. err. 2.11802
2018-02-03 23:58:46,196 training [INFO ] Epoch 46 Batch 9400 Training err. 2.02107 Training err. RA 2.56409 Valid. err. 2.11689
2018-02-03 23:58:46,682 training [INFO ] Epoch 46 Batch 9420 Training err. 2.08240 Training err. RA 2.56307 Valid. err. 2.10505
2018-02-03 23:58:47,169 training [INFO ] Epoch 46 Batch 9440 Training err. 2.09535 Training err. RA 2.56208 Valid. err. 2.11633
2018-02-03 23:58:47,658 training [INFO ] Epoch 46 Batch 9460 Training err. 2.06627 Training err. RA 2.56103 Valid. err. 2.11732
2018-02-03 23:58:48,143 training [INFO ] Epoch 46 Batch 9480 Training err. 2.12705 Training err. RA 2.56012 Valid. err. 2.12476
2018-02-03 23:58:48,710 training [INFO ] Epoch 46 Batch 9500 Training err. 2.08050 Training err. RA 2.55911 Valid. err. 2.10820
2018-02-03 23:58:49,203 training [INFO ] Epoch 46 Batch 9520 Training err. 2.03892 Training err. RA 2.55801 Valid. err. 2.13396
2018-02-03 23:58:49,683 training [INFO ] Epoch 46 Batch 9540 Training err. 2.06052 Training err. RA 2.55697 Valid. err. 2.10926
2018-02-03 23:58:50,163 training [INFO ] Epoch 46 Batch 9560 Training err. 2.05502 Training err. RA 2.55592 Valid. err. 2.09753
2018-02-03 23:58:51,012 training [INFO ] Epoch 47 Batch 9580 Training err. 2.06911 Training err. RA 2.55490 Valid. err. 2.10095
2018-02-03 23:58:51,498 training [INFO ] Epoch 47 Batch 9600 Training err. 1.98822 Training err. RA 2.55372 Valid. err. 2.11240
2018-02-03 23:58:51,976 training [INFO ] Epoch 47 Batch 9620 Training err. 2.08768 Training err. RA 2.55275 Valid. err. 2.09994
2018-02-03 23:58:52,454 training [INFO ] Epoch 47 Batch 9640 Training err. 2.08371 Training err. RA 2.55178 Valid. err. 2.10677
2018-02-03 23:58:52,932 training [INFO ] Epoch 47 Batch 9660 Training err. 2.04559 Training err. RA 2.55073 Valid. err. 2.10473
2018-02-03 23:58:53,408 training [INFO ] Epoch 47 Batch 9680 Training err. 2.07510 Training err. RA 2.54975 Valid. err. 2.10722
2018-02-03 23:58:53,884 training [INFO ] Epoch 47 Batch 9700 Training err. 2.12790 Training err. RA 2.54888 Valid. err. 2.10361
2018-02-03 23:58:54,358 training [INFO ] Epoch 47 Batch 9720 Training err. 2.03860 Training err. RA 2.54783 Valid. err. 2.09293
2018-02-03 23:58:54,833 training [INFO ] Epoch 47 Batch 9740 Training err. 2.04081 Training err. RA 2.54679 Valid. err. 2.11412
2018-02-03 23:58:55,311 training [INFO ] Epoch 47 Batch 9760 Training err. 2.04989 Training err. RA 2.54577 Valid. err. 2.09145
2018-02-03 23:58:56,192 training [INFO ] Epoch 48 Batch 9780 Training err. 2.05022 Training err. RA 2.54476 Valid. err. 2.10671
2018-02-03 23:58:56,668 training [INFO ] Epoch 48 Batch 9800 Training err. 2.02319 Training err. RA 2.54369 Valid. err. 2.08844
2018-02-03 23:58:57,142 training [INFO ] Epoch 48 Batch 9820 Training err. 2.02909 Training err. RA 2.54264 Valid. err. 2.08839
2018-02-03 23:58:57,613 training [INFO ] Epoch 48 Batch 9840 Training err. 2.06829 Training err. RA 2.54168 Valid. err. 2.09858
2018-02-03 23:58:58,110 training [INFO ] Epoch 48 Batch 9860 Training err. 2.04569 Training err. RA 2.54067 Valid. err. 2.11172
2018-02-03 23:58:58,595 training [INFO ] Epoch 48 Batch 9880 Training err. 2.06304 Training err. RA 2.53971 Valid. err. 2.09529
2018-02-03 23:58:59,094 training [INFO ] Epoch 48 Batch 9900 Training err. 2.12937 Training err. RA 2.53888 Valid. err. 2.10174
2018-02-03 23:58:59,578 training [INFO ] Epoch 48 Batch 9920 Training err. 2.03129 Training err. RA 2.53786 Valid. err. 2.09110
2018-02-03 23:59:00,073 training [INFO ] Epoch 48 Batch 9940 Training err. 2.01543 Training err. RA 2.53680 Valid. err. 2.08732
2018-02-03 23:59:00,557 training [INFO ] Epoch 48 Batch 9960 Training err. 2.04301 Training err. RA 2.53581 Valid. err. 2.08094
2018-02-03 23:59:01,038 training [INFO ] Epoch 48 Batch 9980 Training err. 2.03723 Training err. RA 2.53481 Valid. err. 2.09000
2018-02-03 23:59:01,914 training [INFO ] Epoch 49 Batch10000 Training err. 2.03681 Training err. RA 2.53382 Valid. err. 2.08079
2018-02-03 23:59:02,392 training [INFO ] Epoch 49 Batch10020 Training err. 1.98535 Training err. RA 2.53272 Valid. err. 2.10009
2018-02-03 23:59:02,873 training [INFO ] Epoch 49 Batch10040 Training err. 2.06549 Training err. RA 2.53179 Valid. err. 2.08110
2018-02-03 23:59:03,351 training [INFO ] Epoch 49 Batch10060 Training err. 2.05639 Training err. RA 2.53085 Valid. err. 2.08784
2018-02-03 23:59:03,832 training [INFO ] Epoch 49 Batch10080 Training err. 2.03499 Training err. RA 2.52986 Valid. err. 2.10604
2018-02-03 23:59:04,309 training [INFO ] Epoch 49 Batch10100 Training err. 2.08942 Training err. RA 2.52899 Valid. err. 2.10791
2018-02-03 23:59:04,788 training [INFO ] Epoch 49 Batch10120 Training err. 2.07272 Training err. RA 2.52809 Valid. err. 2.08472
2018-02-03 23:59:05,266 training [INFO ] Epoch 49 Batch10140 Training err. 2.01493 Training err. RA 2.52708 Valid. err. 2.07547
2018-02-03 23:59:05,742 training [INFO ] Epoch 49 Batch10160 Training err. 2.02843 Training err. RA 2.52610 Valid. err. 2.07001
2018-02-03 23:59:06,223 training [INFO ] Epoch 49 Batch10180 Training err. 2.02179 Training err. RA 2.52510 Valid. err. 2.07496
2018-02-03 23:59:07,070 training [INFO ] Epoch 50 Batch10200 Training err. 2.03595 Training err. RA 2.52415 Valid. err. 2.07204
2018-02-03 23:59:07,554 training [INFO ] Epoch 50 Batch10220 Training err. 1.97084 Training err. RA 2.52306 Valid. err. 2.07525
2018-02-03 23:59:08,035 training [INFO ] Epoch 50 Batch10240 Training err. 2.04995 Training err. RA 2.52214 Valid. err. 2.07491
2018-02-03 23:59:08,510 training [INFO ] Epoch 50 Batch10260 Training err. 2.05575 Training err. RA 2.52123 Valid. err. 2.08655
2018-02-03 23:59:08,986 training [INFO ] Epoch 50 Batch10280 Training err. 2.01638 Training err. RA 2.52025 Valid. err. 2.07853
2018-02-03 23:59:09,462 training [INFO ] Epoch 50 Batch10300 Training err. 2.02739 Training err. RA 2.51929 Valid. err. 2.10226
2018-02-03 23:59:09,939 training [INFO ] Epoch 50 Batch10320 Training err. 2.11040 Training err. RA 2.51850 Valid. err. 2.07296
2018-02-03 23:59:10,416 training [INFO ] Epoch 50 Batch10340 Training err. 2.02644 Training err. RA 2.51755 Valid. err. 2.08520
2018-02-03 23:59:10,894 training [INFO ] Epoch 50 Batch10360 Training err. 1.98976 Training err. RA 2.51653 Valid. err. 2.06148
2018-02-03 23:59:11,372 training [INFO ] Epoch 50 Batch10380 Training err. 2.03009 Training err. RA 2.51559 Valid. err. 2.06032
2018-02-03 23:59:11,851 training [INFO ] Epoch 50 Batch10400 Training err. 2.01026 Training err. RA 2.51462 Valid. err. 2.06847
2018-02-03 23:59:12,704 training [INFO ] Epoch 51 Batch10420 Training err. 2.01276 Training err. RA 2.51366 Valid. err. 2.06782
2018-02-03 23:59:13,186 training [INFO ] Epoch 51 Batch10440 Training err. 1.97692 Training err. RA 2.51263 Valid. err. 2.07132
2018-02-03 23:59:13,666 training [INFO ] Epoch 51 Batch10460 Training err. 2.03652 Training err. RA 2.51172 Valid. err. 2.05963
2018-02-03 23:59:14,143 training [INFO ] Epoch 51 Batch10480 Training err. 2.04835 Training err. RA 2.51083 Valid. err. 2.06956
2018-02-03 23:59:14,621 training [INFO ] Epoch 51 Batch10500 Training err. 2.01482 Training err. RA 2.50989 Valid. err. 2.06545
2018-02-03 23:59:15,101 training [INFO ] Epoch 51 Batch10520 Training err. 2.08231 Training err. RA 2.50907 Valid. err. 2.13857
2018-02-03 23:59:15,583 training [INFO ] Epoch 51 Batch10540 Training err. 2.03707 Training err. RA 2.50818 Valid. err. 2.06549
2018-02-03 23:59:16,061 training [INFO ] Epoch 51 Batch10560 Training err. 1.99203 Training err. RA 2.50720 Valid. err. 2.08330
2018-02-03 23:59:16,538 training [INFO ] Epoch 51 Batch10580 Training err. 2.01109 Training err. RA 2.50626 Valid. err. 2.06450
2018-02-03 23:59:17,018 training [INFO ] Epoch 51 Batch10600 Training err. 2.00751 Training err. RA 2.50532 Valid. err. 2.05178
2018-02-03 23:59:17,872 training [INFO ] Epoch 52 Batch10620 Training err. 2.00986 Training err. RA 2.50439 Valid. err. 2.05304
2018-02-03 23:59:18,348 training [INFO ] Epoch 52 Batch10640 Training err. 1.94574 Training err. RA 2.50334 Valid. err. 2.07391
2018-02-03 23:59:18,826 training [INFO ] Epoch 52 Batch10660 Training err. 2.04173 Training err. RA 2.50247 Valid. err. 2.05678
2018-02-03 23:59:19,303 training [INFO ] Epoch 52 Batch10680 Training err. 2.04005 Training err. RA 2.50161 Valid. err. 2.06329
2018-02-03 23:59:19,778 training [INFO ] Epoch 52 Batch10700 Training err. 1.99802 Training err. RA 2.50067 Valid. err. 2.05561
2018-02-03 23:59:20,255 training [INFO ] Epoch 52 Batch10720 Training err. 2.02786 Training err. RA 2.49978 Valid. err. 2.06278
2018-02-03 23:59:20,736 training [INFO ] Epoch 52 Batch10740 Training err. 2.08799 Training err. RA 2.49902 Valid. err. 2.06339
2018-02-03 23:59:21,217 training [INFO ] Epoch 52 Batch10760 Training err. 1.99461 Training err. RA 2.49808 Valid. err. 2.05122
2018-02-03 23:59:21,716 training [INFO ] Epoch 52 Batch10780 Training err. 1.99382 Training err. RA 2.49714 Valid. err. 2.06086
2018-02-03 23:59:22,224 training [INFO ] Epoch 52 Batch10800 Training err. 2.00238 Training err. RA 2.49623 Valid. err. 2.04644
2018-02-03 23:59:23,086 training [INFO ] Epoch 53 Batch10820 Training err. 1.99343 Training err. RA 2.49530 Valid. err. 2.04915
2018-02-03 23:59:23,572 training [INFO ] Epoch 53 Batch10840 Training err. 1.97530 Training err. RA 2.49434 Valid. err. 2.04379
2018-02-03 23:59:24,060 training [INFO ] Epoch 53 Batch10860 Training err. 1.98810 Training err. RA 2.49341 Valid. err. 2.04557
2018-02-03 23:59:24,555 training [INFO ] Epoch 53 Batch10880 Training err. 2.02522 Training err. RA 2.49255 Valid. err. 2.05925
2018-02-03 23:59:25,050 training [INFO ] Epoch 53 Batch10900 Training err. 2.00221 Training err. RA 2.49165 Valid. err. 2.06504
2018-02-03 23:59:25,561 training [INFO ] Epoch 53 Batch10920 Training err. 2.01580 Training err. RA 2.49077 Valid. err. 2.05507
2018-02-03 23:59:26,145 training [INFO ] Epoch 53 Batch10940 Training err. 2.09181 Training err. RA 2.49005 Valid. err. 2.07109
2018-02-03 23:59:26,660 training [INFO ] Epoch 53 Batch10960 Training err. 1.98718 Training err. RA 2.48913 Valid. err. 2.05116
2018-02-03 23:59:27,179 training [INFO ] Epoch 53 Batch10980 Training err. 1.97228 Training err. RA 2.48819 Valid. err. 2.04629
2018-02-03 23:59:27,676 training [INFO ] Epoch 53 Batch11000 Training err. 1.99668 Training err. RA 2.48729 Valid. err. 2.04038
2018-02-03 23:59:28,195 training [INFO ] Epoch 53 Batch11020 Training err. 1.99130 Training err. RA 2.48639 Valid. err. 2.04700
2018-02-03 23:59:29,077 training [INFO ] Epoch 54 Batch11040 Training err. 1.98143 Training err. RA 2.48548 Valid. err. 2.03997
2018-02-03 23:59:29,553 training [INFO ] Epoch 54 Batch11060 Training err. 1.94538 Training err. RA 2.48450 Valid. err. 2.05403
2018-02-03 23:59:30,035 training [INFO ] Epoch 54 Batch11080 Training err. 2.02170 Training err. RA 2.48367 Valid. err. 2.04175
2018-02-03 23:59:30,513 training [INFO ] Epoch 54 Batch11100 Training err. 2.01572 Training err. RA 2.48282 Valid. err. 2.04711
2018-02-03 23:59:30,996 training [INFO ] Epoch 54 Batch11120 Training err. 1.98963 Training err. RA 2.48194 Valid. err. 2.05186
2018-02-03 23:59:31,478 training [INFO ] Epoch 54 Batch11140 Training err. 2.04777 Training err. RA 2.48116 Valid. err. 2.06545
2018-02-03 23:59:31,971 training [INFO ] Epoch 54 Batch11160 Training err. 2.03433 Training err. RA 2.48036 Valid. err. 2.04599
2018-02-03 23:59:32,469 training [INFO ] Epoch 54 Batch11180 Training err. 1.97296 Training err. RA 2.47945 Valid. err. 2.03552
2018-02-03 23:59:33,000 training [INFO ] Epoch 54 Batch11200 Training err. 1.98297 Training err. RA 2.47856 Valid. err. 2.03098
2018-02-03 23:59:33,536 training [INFO ] Epoch 54 Batch11220 Training err. 1.97908 Training err. RA 2.47767 Valid. err. 2.04150
2018-02-03 23:59:34,820 training [INFO ] Epoch 55 Batch11240 Training err. 1.98246 Training err. RA 2.47679 Valid. err. 2.03062
2018-02-03 23:59:35,363 training [INFO ] Epoch 55 Batch11260 Training err. 1.92923 Training err. RA 2.47582 Valid. err. 2.03831
2018-02-03 23:59:35,899 training [INFO ] Epoch 55 Batch11280 Training err. 2.00897 Training err. RA 2.47499 Valid. err. 2.03174
2018-02-03 23:59:36,413 training [INFO ] Epoch 55 Batch11300 Training err. 2.01673 Training err. RA 2.47418 Valid. err. 2.04867
2018-02-03 23:59:36,917 training [INFO ] Epoch 55 Batch11320 Training err. 1.97401 Training err. RA 2.47329 Valid. err. 2.04037
2018-02-03 23:59:37,416 training [INFO ] Epoch 55 Batch11340 Training err. 1.98471 Training err. RA 2.47243 Valid. err. 2.06706
2018-02-03 23:59:37,904 training [INFO ] Epoch 55 Batch11360 Training err. 2.06958 Training err. RA 2.47172 Valid. err. 2.03316
2018-02-03 23:59:38,391 training [INFO ] Epoch 55 Batch11380 Training err. 1.98532 Training err. RA 2.47087 Valid. err. 2.04404
2018-02-03 23:59:38,876 training [INFO ] Epoch 55 Batch11400 Training err. 1.94849 Training err. RA 2.46995 Valid. err. 2.02312
2018-02-03 23:59:39,362 training [INFO ] Epoch 55 Batch11420 Training err. 1.98560 Training err. RA 2.46910 Valid. err. 2.02439
2018-02-03 23:59:39,864 training [INFO ] Epoch 55 Batch11440 Training err. 1.96723 Training err. RA 2.46823 Valid. err. 2.03107
2018-02-03 23:59:40,842 training [INFO ] Epoch 56 Batch11460 Training err. 1.96715 Training err. RA 2.46735 Valid. err. 2.02776
2018-02-03 23:59:41,450 training [INFO ] Epoch 56 Batch11480 Training err. 1.93622 Training err. RA 2.46643 Valid. err. 2.03353
2018-02-03 23:59:42,030 training [INFO ] Epoch 56 Batch11500 Training err. 1.99671 Training err. RA 2.46561 Valid. err. 2.02234
2018-02-03 23:59:42,608 training [INFO ] Epoch 56 Batch11520 Training err. 2.00923 Training err. RA 2.46482 Valid. err. 2.03127
2018-02-03 23:59:43,194 training [INFO ] Epoch 56 Batch11540 Training err. 1.97199 Training err. RA 2.46396 Valid. err. 2.02910
2018-02-03 23:59:43,781 training [INFO ] Epoch 56 Batch11560 Training err. 2.04250 Training err. RA 2.46323 Valid. err. 2.06018
2018-02-03 23:59:44,323 training [INFO ] Epoch 56 Batch11580 Training err. 1.99501 Training err. RA 2.46243 Valid. err. 2.02915
2018-02-03 23:59:44,826 training [INFO ] Epoch 56 Batch11600 Training err. 1.95183 Training err. RA 2.46155 Valid. err. 2.03938
2018-02-03 23:59:45,335 training [INFO ] Epoch 56 Batch11620 Training err. 1.96839 Training err. RA 2.46070 Valid. err. 2.02566
2018-02-03 23:59:45,855 training [INFO ] Epoch 56 Batch11640 Training err. 1.96828 Training err. RA 2.45985 Valid. err. 2.01514
2018-02-03 23:59:46,847 training [INFO ] Epoch 57 Batch11660 Training err. 1.96535 Training err. RA 2.45900 Valid. err. 2.01689
2018-02-03 23:59:47,395 training [INFO ] Epoch 57 Batch11680 Training err. 1.90704 Training err. RA 2.45806 Valid. err. 2.03308
2018-02-03 23:59:47,913 training [INFO ] Epoch 57 Batch11700 Training err. 2.00035 Training err. RA 2.45727 Valid. err. 2.02058
2018-02-03 23:59:48,402 training [INFO ] Epoch 57 Batch11720 Training err. 2.00385 Training err. RA 2.45650 Valid. err. 2.02498
2018-02-03 23:59:48,895 training [INFO ] Epoch 57 Batch11740 Training err. 1.95769 Training err. RA 2.45565 Valid. err. 2.01676
2018-02-03 23:59:49,396 training [INFO ] Epoch 57 Batch11760 Training err. 1.98916 Training err. RA 2.45486 Valid. err. 2.02670
2018-02-03 23:59:49,952 training [INFO ] Epoch 57 Batch11780 Training err. 2.04294 Training err. RA 2.45416 Valid. err. 2.02384
2018-02-03 23:59:50,585 training [INFO ] Epoch 57 Batch11800 Training err. 1.95628 Training err. RA 2.45331 Valid. err. 2.01625
2018-02-03 23:59:51,183 training [INFO ] Epoch 57 Batch11820 Training err. 1.95299 Training err. RA 2.45247 Valid. err. 2.01895
2018-02-03 23:59:51,737 training [INFO ] Epoch 57 Batch11840 Training err. 1.96287 Training err. RA 2.45164 Valid. err. 2.01054
2018-02-03 23:59:52,678 training [INFO ] Epoch 58 Batch11860 Training err. 1.95138 Training err. RA 2.45080 Valid. err. 2.01225
2018-02-03 23:59:53,351 training [INFO ] Epoch 58 Batch11880 Training err. 1.93691 Training err. RA 2.44993 Valid. err. 2.01002
2018-02-03 23:59:53,882 training [INFO ] Epoch 58 Batch11900 Training err. 1.94962 Training err. RA 2.44909 Valid. err. 2.00910
2018-02-03 23:59:54,420 training [INFO ] Epoch 58 Batch11920 Training err. 1.98787 Training err. RA 2.44832 Valid. err. 2.02829
2018-02-03 23:59:55,020 training [INFO ] Epoch 58 Batch11940 Training err. 1.96630 Training err. RA 2.44751 Valid. err. 2.02575
2018-02-03 23:59:55,505 training [INFO ] Epoch 58 Batch11960 Training err. 1.97654 Training err. RA 2.44672 Valid. err. 2.01963
2018-02-03 23:59:56,008 training [INFO ] Epoch 58 Batch11980 Training err. 2.04745 Training err. RA 2.44606 Valid. err. 2.02762
2018-02-03 23:59:56,489 training [INFO ] Epoch 58 Batch12000 Training err. 1.94751 Training err. RA 2.44522 Valid. err. 2.01250
2018-02-03 23:59:57,108 training [INFO ] Epoch 58 Batch12020 Training err. 1.93509 Training err. RA 2.44438 Valid. err. 2.01161
2018-02-03 23:59:57,739 training [INFO ] Epoch 58 Batch12040 Training err. 1.95733 Training err. RA 2.44357 Valid. err. 2.00475
2018-02-03 23:59:58,291 training [INFO ] Epoch 58 Batch12060 Training err. 1.95313 Training err. RA 2.44275 Valid. err. 2.01348
2018-02-03 23:59:59,285 training [INFO ] Epoch 59 Batch12080 Training err. 1.94268 Training err. RA 2.44193 Valid. err. 2.00762
2018-02-03 23:59:59,797 training [INFO ] Epoch 59 Batch12100 Training err. 1.90811 Training err. RA 2.44104 Valid. err. 2.01386
2018-02-04 00:00:00,300 training [INFO ] Epoch 59 Batch12120 Training err. 1.98266 Training err. RA 2.44029 Valid. err. 2.00991
2018-02-04 00:00:00,858 training [INFO ] Epoch 59 Batch12140 Training err. 1.98167 Training err. RA 2.43953 Valid. err. 2.01272
2018-02-04 00:00:01,404 training [INFO ] Epoch 59 Batch12160 Training err. 1.95162 Training err. RA 2.43873 Valid. err. 2.01098
2018-02-04 00:00:02,003 training [INFO ] Epoch 59 Batch12180 Training err. 2.01242 Training err. RA 2.43803 Valid. err. 2.03980
2018-02-04 00:00:02,877 training [INFO ] Epoch 59 Batch12200 Training err. 1.99014 Training err. RA 2.43729 Valid. err. 2.01190
2018-02-04 00:00:03,509 training [INFO ] Epoch 59 Batch12220 Training err. 1.93629 Training err. RA 2.43647 Valid. err. 1.99960
2018-02-04 00:00:04,193 training [INFO ] Epoch 59 Batch12240 Training err. 1.94321 Training err. RA 2.43567 Valid. err. 1.99719
2018-02-04 00:00:04,845 training [INFO ] Epoch 59 Batch12260 Training err. 1.94397 Training err. RA 2.43487 Valid. err. 2.01295
2018-02-04 00:00:06,046 training [INFO ] Epoch 60 Batch12280 Training err. 1.94445 Training err. RA 2.43407 Valid. err. 2.00120
2018-02-04 00:00:06,705 training [INFO ] Epoch 60 Batch12300 Training err. 1.89334 Training err. RA 2.43319 Valid. err. 2.00571
2018-02-04 00:00:07,385 training [INFO ] Epoch 60 Batch12320 Training err. 1.97119 Training err. RA 2.43244 Valid. err. 1.99611
2018-02-04 00:00:07,928 training [INFO ] Epoch 60 Batch12340 Training err. 1.98280 Training err. RA 2.43171 Valid. err. 2.01266
2018-02-04 00:00:08,593 training [INFO ] Epoch 60 Batch12360 Training err. 1.93880 Training err. RA 2.43091 Valid. err. 2.00948
2018-02-04 00:00:09,187 training [INFO ] Epoch 60 Batch12380 Training err. 1.94788 Training err. RA 2.43013 Valid. err. 2.03584
2018-02-04 00:00:09,759 training [INFO ] Epoch 60 Batch12400 Training err. 2.02941 Training err. RA 2.42949 Valid. err. 1.99942
2018-02-04 00:00:10,345 training [INFO ] Epoch 60 Batch12420 Training err. 1.94932 Training err. RA 2.42871 Valid. err. 2.00931
2018-02-04 00:00:10,924 training [INFO ] Epoch 60 Batch12440 Training err. 1.91333 Training err. RA 2.42788 Valid. err. 1.99060
2018-02-04 00:00:11,494 training [INFO ] Epoch 60 Batch12460 Training err. 1.94762 Training err. RA 2.42711 Valid. err. 1.99324
2018-02-04 00:00:12,082 training [INFO ] Epoch 60 Batch12480 Training err. 1.93147 Training err. RA 2.42632 Valid. err. 2.00184
2018-02-04 00:00:12,406 __main__ [INFO ] End of training
2018-02-04 00:00:14,431 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-04 00:00:15,220 training [INFO ] Epoch  1 Batch   20 Training err. 3.55549 Training err. RA 3.55549 Valid. err. 3.22915
2018-02-04 00:00:15,733 training [INFO ] Epoch  1 Batch   40 Training err. 3.17873 Training err. RA 3.36711 Valid. err. 3.20575
2018-02-04 00:00:16,249 training [INFO ] Epoch  1 Batch   60 Training err. 3.16397 Training err. RA 3.29940 Valid. err. 3.19950
2018-02-04 00:00:16,749 training [INFO ] Epoch  1 Batch   80 Training err. 3.14643 Training err. RA 3.26115 Valid. err. 3.20237
2018-02-04 00:00:17,240 training [INFO ] Epoch  1 Batch  100 Training err. 3.13418 Training err. RA 3.23576 Valid. err. 3.18252
2018-02-04 00:00:17,731 training [INFO ] Epoch  1 Batch  120 Training err. 3.16008 Training err. RA 3.22315 Valid. err. 3.18262
2018-02-04 00:00:18,214 training [INFO ] Epoch  1 Batch  140 Training err. 3.11213 Training err. RA 3.20729 Valid. err. 3.17885
2018-02-04 00:00:18,695 training [INFO ] Epoch  1 Batch  160 Training err. 3.07529 Training err. RA 3.19079 Valid. err. 3.17769
2018-02-04 00:00:19,176 training [INFO ] Epoch  1 Batch  180 Training err. 3.13794 Training err. RA 3.18492 Valid. err. 3.15168
2018-02-04 00:00:19,658 training [INFO ] Epoch  1 Batch  200 Training err. 3.11130 Training err. RA 3.17755 Valid. err. 3.12295
2018-02-04 00:00:20,541 training [INFO ] Epoch  2 Batch  220 Training err. 3.08393 Training err. RA 3.16904 Valid. err. 3.26741
2018-02-04 00:00:21,015 training [INFO ] Epoch  2 Batch  240 Training err. 3.01195 Training err. RA 3.15595 Valid. err. 3.17567
2018-02-04 00:00:21,488 training [INFO ] Epoch  2 Batch  260 Training err. 3.03822 Training err. RA 3.14690 Valid. err. 3.04608
2018-02-04 00:00:21,965 training [INFO ] Epoch  2 Batch  280 Training err. 2.97789 Training err. RA 3.13482 Valid. err. 2.98763
2018-02-04 00:00:22,442 training [INFO ] Epoch  2 Batch  300 Training err. 2.91681 Training err. RA 3.12029 Valid. err. 2.96540
2018-02-04 00:00:22,920 training [INFO ] Epoch  2 Batch  320 Training err. 2.92523 Training err. RA 3.10810 Valid. err. 2.90704
2018-02-04 00:00:23,395 training [INFO ] Epoch  2 Batch  340 Training err. 2.85528 Training err. RA 3.09323 Valid. err. 2.87423
2018-02-04 00:00:23,876 training [INFO ] Epoch  2 Batch  360 Training err. 2.82031 Training err. RA 3.07807 Valid. err. 2.85004
2018-02-04 00:00:24,436 training [INFO ] Epoch  2 Batch  380 Training err. 2.77454 Training err. RA 3.06209 Valid. err. 2.78502
2018-02-04 00:00:24,949 training [INFO ] Epoch  2 Batch  400 Training err. 2.77249 Training err. RA 3.04761 Valid. err. 2.77907
2018-02-04 00:00:25,991 training [INFO ] Epoch  3 Batch  420 Training err. 2.74017 Training err. RA 3.03297 Valid. err. 2.72899
2018-02-04 00:00:26,810 training [INFO ] Epoch  3 Batch  440 Training err. 2.72277 Training err. RA 3.01887 Valid. err. 2.71090
2018-02-04 00:00:27,406 training [INFO ] Epoch  3 Batch  460 Training err. 2.67992 Training err. RA 3.00413 Valid. err. 2.69395
2018-02-04 00:00:28,110 training [INFO ] Epoch  3 Batch  480 Training err. 2.63504 Training err. RA 2.98875 Valid. err. 2.67709
2018-02-04 00:00:28,873 training [INFO ] Epoch  3 Batch  500 Training err. 2.60208 Training err. RA 2.97329 Valid. err. 2.67569
2018-02-04 00:00:29,562 training [INFO ] Epoch  3 Batch  520 Training err. 2.60814 Training err. RA 2.95924 Valid. err. 2.65442
2018-02-04 00:00:30,221 training [INFO ] Epoch  3 Batch  540 Training err. 2.61952 Training err. RA 2.94666 Valid. err. 2.58740
2018-02-04 00:00:30,853 training [INFO ] Epoch  3 Batch  560 Training err. 2.53108 Training err. RA 2.93182 Valid. err. 2.55610
2018-02-04 00:00:31,500 training [INFO ] Epoch  3 Batch  580 Training err. 2.48878 Training err. RA 2.91654 Valid. err. 2.53297
2018-02-04 00:00:32,170 training [INFO ] Epoch  3 Batch  600 Training err. 2.51054 Training err. RA 2.90301 Valid. err. 2.53911
2018-02-04 00:00:32,762 training [INFO ] Epoch  3 Batch  620 Training err. 2.50706 Training err. RA 2.89024 Valid. err. 2.49053
2018-02-04 00:00:33,884 training [INFO ] Epoch  4 Batch  640 Training err. 2.44787 Training err. RA 2.87641 Valid. err. 2.48601
2018-02-04 00:00:34,478 training [INFO ] Epoch  4 Batch  660 Training err. 2.37382 Training err. RA 2.86118 Valid. err. 2.44763
2018-02-04 00:00:35,090 training [INFO ] Epoch  4 Batch  680 Training err. 2.45510 Training err. RA 2.84924 Valid. err. 2.45532
2018-02-04 00:00:35,792 training [INFO ] Epoch  4 Batch  700 Training err. 2.40701 Training err. RA 2.83660 Valid. err. 2.46240
2018-02-04 00:00:36,707 training [INFO ] Epoch  4 Batch  720 Training err. 2.37303 Training err. RA 2.82373 Valid. err. 2.42048
2018-02-04 00:00:37,611 training [INFO ] Epoch  4 Batch  740 Training err. 2.44140 Training err. RA 2.81339 Valid. err. 2.40839
2018-02-04 00:00:38,380 training [INFO ] Epoch  4 Batch  760 Training err. 2.37832 Training err. RA 2.80194 Valid. err. 2.40775
2018-02-04 00:00:39,089 training [INFO ] Epoch  4 Batch  780 Training err. 2.33897 Training err. RA 2.79007 Valid. err. 2.37455
2018-02-04 00:00:39,931 training [INFO ] Epoch  4 Batch  800 Training err. 2.33709 Training err. RA 2.77875 Valid. err. 2.34505
2018-02-04 00:00:40,601 training [INFO ] Epoch  4 Batch  820 Training err. 2.30225 Training err. RA 2.76713 Valid. err. 2.34373
2018-02-04 00:00:44,339 training [INFO ] Epoch  5 Batch  840 Training err. 2.32795 Training err. RA 2.75667 Valid. err. 2.32770
2018-02-04 00:00:45,283 training [INFO ] Epoch  5 Batch  860 Training err. 2.22976 Training err. RA 2.74442 Valid. err. 2.31354
2018-02-04 00:00:46,057 training [INFO ] Epoch  5 Batch  880 Training err. 2.29072 Training err. RA 2.73410 Valid. err. 2.31149
2018-02-04 00:00:46,779 training [INFO ] Epoch  5 Batch  900 Training err. 2.27549 Training err. RA 2.72391 Valid. err. 2.31830
2018-02-04 00:00:47,461 training [INFO ] Epoch  5 Batch  920 Training err. 2.26257 Training err. RA 2.71388 Valid. err. 2.30718
2018-02-04 00:00:48,583 training [INFO ] Epoch  5 Batch  940 Training err. 2.25251 Training err. RA 2.70407 Valid. err. 2.31915
2018-02-04 00:00:49,314 training [INFO ] Epoch  5 Batch  960 Training err. 2.29947 Training err. RA 2.69564 Valid. err. 2.26676
2018-02-04 00:00:50,082 training [INFO ] Epoch  5 Batch  980 Training err. 2.23004 Training err. RA 2.68614 Valid. err. 2.31028
2018-02-04 00:00:50,877 training [INFO ] Epoch  5 Batch 1000 Training err. 2.19421 Training err. RA 2.67630 Valid. err. 2.23231
2018-02-04 00:00:51,564 training [INFO ] Epoch  5 Batch 1020 Training err. 2.20697 Training err. RA 2.66709 Valid. err. 2.24094
2018-02-04 00:00:52,261 training [INFO ] Epoch  5 Batch 1040 Training err. 2.19366 Training err. RA 2.65799 Valid. err. 2.23863
2018-02-04 00:00:56,130 training [INFO ] Epoch  6 Batch 1060 Training err. 2.17470 Training err. RA 2.64887 Valid. err. 2.22370
2018-02-04 00:00:56,930 training [INFO ] Epoch  6 Batch 1080 Training err. 2.11356 Training err. RA 2.63896 Valid. err. 2.22965
2018-02-04 00:00:57,635 training [INFO ] Epoch  6 Batch 1100 Training err. 2.18718 Training err. RA 2.63074 Valid. err. 2.19845
2018-02-04 00:00:58,446 training [INFO ] Epoch  6 Batch 1120 Training err. 2.17242 Training err. RA 2.62256 Valid. err. 2.22293
2018-02-04 00:00:59,352 training [INFO ] Epoch  6 Batch 1140 Training err. 2.14566 Training err. RA 2.61419 Valid. err. 2.17509
2018-02-04 00:01:00,053 training [INFO ] Epoch  6 Batch 1160 Training err. 2.20705 Training err. RA 2.60717 Valid. err. 2.18115
2018-02-04 00:01:00,649 training [INFO ] Epoch  6 Batch 1180 Training err. 2.13246 Training err. RA 2.59913 Valid. err. 2.20340
2018-02-04 00:01:01,303 training [INFO ] Epoch  6 Batch 1200 Training err. 2.11874 Training err. RA 2.59112 Valid. err. 2.21851
2018-02-04 00:01:02,251 training [INFO ] Epoch  6 Batch 1220 Training err. 2.11482 Training err. RA 2.58331 Valid. err. 2.15356
2018-02-04 00:01:02,913 training [INFO ] Epoch  6 Batch 1240 Training err. 2.10106 Training err. RA 2.57553 Valid. err. 2.26386
2018-02-04 00:01:05,924 training [INFO ] Epoch  7 Batch 1260 Training err. 2.11080 Training err. RA 2.56816 Valid. err. 2.13479
2018-02-04 00:01:06,647 training [INFO ] Epoch  7 Batch 1280 Training err. 2.00722 Training err. RA 2.55939 Valid. err. 2.12028
2018-02-04 00:01:07,326 training [INFO ] Epoch  7 Batch 1300 Training err. 2.10485 Training err. RA 2.55240 Valid. err. 2.12321
2018-02-04 00:01:08,048 training [INFO ] Epoch  7 Batch 1320 Training err. 2.10495 Training err. RA 2.54562 Valid. err. 2.14948
2018-02-04 00:01:08,859 training [INFO ] Epoch  7 Batch 1340 Training err. 2.05851 Training err. RA 2.53835 Valid. err. 2.10716
2018-02-04 00:01:09,609 training [INFO ] Epoch  7 Batch 1360 Training err. 2.08953 Training err. RA 2.53175 Valid. err. 2.11277
2018-02-04 00:01:10,174 training [INFO ] Epoch  7 Batch 1380 Training err. 2.11749 Training err. RA 2.52575 Valid. err. 2.12220
2018-02-04 00:01:10,731 training [INFO ] Epoch  7 Batch 1400 Training err. 2.03153 Training err. RA 2.51869 Valid. err. 2.11083
2018-02-04 00:01:11,375 training [INFO ] Epoch  7 Batch 1420 Training err. 2.05449 Training err. RA 2.51215 Valid. err. 2.09933
2018-02-04 00:01:12,235 training [INFO ] Epoch  7 Batch 1440 Training err. 2.02991 Training err. RA 2.50545 Valid. err. 2.07156
2018-02-04 00:01:14,823 training [INFO ] Epoch  8 Batch 1460 Training err. 2.02029 Training err. RA 2.49880 Valid. err. 2.07049
2018-02-04 00:01:15,406 training [INFO ] Epoch  8 Batch 1480 Training err. 1.99886 Training err. RA 2.49205 Valid. err. 2.05903
2018-02-04 00:01:15,978 training [INFO ] Epoch  8 Batch 1500 Training err. 1.98407 Training err. RA 2.48528 Valid. err. 2.04476
2018-02-04 00:01:16,611 training [INFO ] Epoch  8 Batch 1520 Training err. 2.03320 Training err. RA 2.47933 Valid. err. 2.04182
2018-02-04 00:01:17,248 training [INFO ] Epoch  8 Batch 1540 Training err. 2.00624 Training err. RA 2.47318 Valid. err. 2.10114
2018-02-04 00:01:17,802 training [INFO ] Epoch  8 Batch 1560 Training err. 2.01085 Training err. RA 2.46726 Valid. err. 2.04649
2018-02-04 00:01:18,331 training [INFO ] Epoch  8 Batch 1580 Training err. 2.07490 Training err. RA 2.46229 Valid. err. 2.03965
2018-02-04 00:01:18,932 training [INFO ] Epoch  8 Batch 1600 Training err. 1.96720 Training err. RA 2.45610 Valid. err. 2.05105
2018-02-04 00:01:19,563 training [INFO ] Epoch  8 Batch 1620 Training err. 1.97280 Training err. RA 2.45013 Valid. err. 2.03891
2018-02-04 00:01:20,202 training [INFO ] Epoch  8 Batch 1640 Training err. 1.96678 Training err. RA 2.44424 Valid. err. 2.02000
2018-02-04 00:01:20,852 training [INFO ] Epoch  8 Batch 1660 Training err. 1.97397 Training err. RA 2.43857 Valid. err. 2.02572
2018-02-04 00:01:22,130 training [INFO ] Epoch  9 Batch 1680 Training err. 1.95710 Training err. RA 2.43284 Valid. err. 2.01867
2018-02-04 00:01:22,655 training [INFO ] Epoch  9 Batch 1700 Training err. 1.89057 Training err. RA 2.42646 Valid. err. 2.03490
2018-02-04 00:01:23,168 training [INFO ] Epoch  9 Batch 1720 Training err. 1.97882 Training err. RA 2.42126 Valid. err. 2.00404
2018-02-04 00:01:23,714 training [INFO ] Epoch  9 Batch 1740 Training err. 1.96639 Training err. RA 2.41603 Valid. err. 2.01594
2018-02-04 00:01:24,709 training [INFO ] Epoch  9 Batch 1760 Training err. 1.93664 Training err. RA 2.41058 Valid. err. 2.02201
2018-02-04 00:01:25,224 training [INFO ] Epoch  9 Batch 1780 Training err. 1.99800 Training err. RA 2.40594 Valid. err. 2.02050
2018-02-04 00:01:25,804 training [INFO ] Epoch  9 Batch 1800 Training err. 1.96175 Training err. RA 2.40101 Valid. err. 1.98837
2018-02-04 00:01:26,641 training [INFO ] Epoch  9 Batch 1820 Training err. 1.90444 Training err. RA 2.39555 Valid. err. 2.00585
2018-02-04 00:01:27,234 training [INFO ] Epoch  9 Batch 1840 Training err. 1.93115 Training err. RA 2.39050 Valid. err. 1.97352
2018-02-04 00:01:28,287 training [INFO ] Epoch  9 Batch 1860 Training err. 1.92446 Training err. RA 2.38549 Valid. err. 1.97032
2018-02-04 00:01:29,701 training [INFO ] Epoch 10 Batch 1880 Training err. 1.91178 Training err. RA 2.38045 Valid. err. 1.95244
2018-02-04 00:01:30,316 training [INFO ] Epoch 10 Batch 1900 Training err. 1.85124 Training err. RA 2.37488 Valid. err. 1.96045
2018-02-04 00:01:31,077 training [INFO ] Epoch 10 Batch 1920 Training err. 1.91438 Training err. RA 2.37009 Valid. err. 1.97183
2018-02-04 00:01:31,690 training [INFO ] Epoch 10 Batch 1940 Training err. 1.92577 Training err. RA 2.36551 Valid. err. 1.95239
2018-02-04 00:01:32,291 training [INFO ] Epoch 10 Batch 1960 Training err. 1.88554 Training err. RA 2.36061 Valid. err. 1.96337
2018-02-04 00:01:32,823 training [INFO ] Epoch 10 Batch 1980 Training err. 1.88529 Training err. RA 2.35581 Valid. err. 1.98574
2018-02-04 00:01:33,322 training [INFO ] Epoch 10 Batch 2000 Training err. 1.95879 Training err. RA 2.35184 Valid. err. 1.93708
2018-02-04 00:01:33,824 training [INFO ] Epoch 10 Batch 2020 Training err. 1.87856 Training err. RA 2.34715 Valid. err. 1.94316
2018-02-04 00:01:34,327 training [INFO ] Epoch 10 Batch 2040 Training err. 1.85675 Training err. RA 2.34234 Valid. err. 1.92521
2018-02-04 00:01:34,832 training [INFO ] Epoch 10 Batch 2060 Training err. 1.87658 Training err. RA 2.33782 Valid. err. 1.92970
2018-02-04 00:01:35,337 training [INFO ] Epoch 10 Batch 2080 Training err. 1.84739 Training err. RA 2.33311 Valid. err. 1.92198
2018-02-04 00:01:36,698 training [INFO ] Epoch 11 Batch 2100 Training err. 1.86609 Training err. RA 2.32866 Valid. err. 1.90433
2018-02-04 00:01:37,218 training [INFO ] Epoch 11 Batch 2120 Training err. 1.79853 Training err. RA 2.32366 Valid. err. 1.93282
2018-02-04 00:01:37,715 training [INFO ] Epoch 11 Batch 2140 Training err. 1.87644 Training err. RA 2.31948 Valid. err. 1.92448
2018-02-04 00:01:38,259 training [INFO ] Epoch 11 Batch 2160 Training err. 1.88121 Training err. RA 2.31542 Valid. err. 1.92150
2018-02-04 00:01:38,840 training [INFO ] Epoch 11 Batch 2180 Training err. 1.83328 Training err. RA 2.31100 Valid. err. 1.90490
2018-02-04 00:01:39,420 training [INFO ] Epoch 11 Batch 2200 Training err. 1.90741 Training err. RA 2.30733 Valid. err. 1.89620
2018-02-04 00:01:39,924 training [INFO ] Epoch 11 Batch 2220 Training err. 1.84748 Training err. RA 2.30318 Valid. err. 1.90554
2018-02-04 00:01:40,417 training [INFO ] Epoch 11 Batch 2240 Training err. 1.81859 Training err. RA 2.29886 Valid. err. 1.95240
2018-02-04 00:01:40,913 training [INFO ] Epoch 11 Batch 2260 Training err. 1.82641 Training err. RA 2.29468 Valid. err. 1.88794
2018-02-04 00:01:41,487 training [INFO ] Epoch 11 Batch 2280 Training err. 1.82204 Training err. RA 2.29053 Valid. err. 1.91221
2018-02-04 00:01:42,630 training [INFO ] Epoch 12 Batch 2300 Training err. 1.82188 Training err. RA 2.28645 Valid. err. 1.88305
2018-02-04 00:01:43,269 training [INFO ] Epoch 12 Batch 2320 Training err. 1.74778 Training err. RA 2.28181 Valid. err. 1.89050
2018-02-04 00:01:43,907 training [INFO ] Epoch 12 Batch 2340 Training err. 1.83582 Training err. RA 2.27800 Valid. err. 1.88296
2018-02-04 00:01:44,428 training [INFO ] Epoch 12 Batch 2360 Training err. 1.84547 Training err. RA 2.27433 Valid. err. 1.89894
2018-02-04 00:01:45,054 training [INFO ] Epoch 12 Batch 2380 Training err. 1.79382 Training err. RA 2.27030 Valid. err. 1.88341
2018-02-04 00:01:45,645 training [INFO ] Epoch 12 Batch 2400 Training err. 1.82426 Training err. RA 2.26658 Valid. err. 1.88329
2018-02-04 00:01:46,170 training [INFO ] Epoch 12 Batch 2420 Training err. 1.86109 Training err. RA 2.26323 Valid. err. 1.88432
2018-02-04 00:01:46,678 training [INFO ] Epoch 12 Batch 2440 Training err. 1.78232 Training err. RA 2.25929 Valid. err. 1.86885
2018-02-04 00:01:47,170 training [INFO ] Epoch 12 Batch 2460 Training err. 1.79221 Training err. RA 2.25549 Valid. err. 1.88475
2018-02-04 00:01:47,690 training [INFO ] Epoch 12 Batch 2480 Training err. 1.78703 Training err. RA 2.25171 Valid. err. 1.84571
2018-02-04 00:01:48,644 training [INFO ] Epoch 13 Batch 2500 Training err. 1.76057 Training err. RA 2.24778 Valid. err. 1.85337
2018-02-04 00:01:49,150 training [INFO ] Epoch 13 Batch 2520 Training err. 1.74974 Training err. RA 2.24383 Valid. err. 1.85582
2018-02-04 00:01:49,649 training [INFO ] Epoch 13 Batch 2540 Training err. 1.75821 Training err. RA 2.24001 Valid. err. 1.85236
2018-02-04 00:01:50,288 training [INFO ] Epoch 13 Batch 2560 Training err. 1.80175 Training err. RA 2.23658 Valid. err. 1.84891
2018-02-04 00:01:50,885 training [INFO ] Epoch 13 Batch 2580 Training err. 1.78328 Training err. RA 2.23307 Valid. err. 1.87332
2018-02-04 00:01:51,486 training [INFO ] Epoch 13 Batch 2600 Training err. 1.77343 Training err. RA 2.22953 Valid. err. 1.85507
2018-02-04 00:01:52,008 training [INFO ] Epoch 13 Batch 2620 Training err. 1.84034 Training err. RA 2.22656 Valid. err. 1.86102
2018-02-04 00:01:52,539 training [INFO ] Epoch 13 Batch 2640 Training err. 1.74489 Training err. RA 2.22291 Valid. err. 1.85531
2018-02-04 00:01:53,214 training [INFO ] Epoch 13 Batch 2660 Training err. 1.74962 Training err. RA 2.21935 Valid. err. 1.86846
2018-02-04 00:01:53,896 training [INFO ] Epoch 13 Batch 2680 Training err. 1.74834 Training err. RA 2.21584 Valid. err. 1.82034
2018-02-04 00:01:54,598 training [INFO ] Epoch 13 Batch 2700 Training err. 1.75114 Training err. RA 2.21240 Valid. err. 1.84217
2018-02-04 00:01:55,925 training [INFO ] Epoch 14 Batch 2720 Training err. 1.72339 Training err. RA 2.20880 Valid. err. 1.82343
2018-02-04 00:01:56,465 training [INFO ] Epoch 14 Batch 2740 Training err. 1.69146 Training err. RA 2.20502 Valid. err. 1.83718
2018-02-04 00:01:56,994 training [INFO ] Epoch 14 Batch 2760 Training err. 1.76411 Training err. RA 2.20183 Valid. err. 1.83258
2018-02-04 00:01:57,488 training [INFO ] Epoch 14 Batch 2780 Training err. 1.77025 Training err. RA 2.19872 Valid. err. 1.84290
2018-02-04 00:01:57,991 training [INFO ] Epoch 14 Batch 2800 Training err. 1.72849 Training err. RA 2.19537 Valid. err. 1.82793
2018-02-04 00:01:58,500 training [INFO ] Epoch 14 Batch 2820 Training err. 1.78967 Training err. RA 2.19249 Valid. err. 1.81299
2018-02-04 00:01:58,997 training [INFO ] Epoch 14 Batch 2840 Training err. 1.75804 Training err. RA 2.18943 Valid. err. 1.81556
2018-02-04 00:01:59,504 training [INFO ] Epoch 14 Batch 2860 Training err. 1.71028 Training err. RA 2.18608 Valid. err. 1.82039
2018-02-04 00:02:00,002 training [INFO ] Epoch 14 Batch 2880 Training err. 1.72463 Training err. RA 2.18287 Valid. err. 1.80041
2018-02-04 00:02:00,508 training [INFO ] Epoch 14 Batch 2900 Training err. 1.71969 Training err. RA 2.17968 Valid. err. 1.81009
2018-02-04 00:02:01,453 training [INFO ] Epoch 15 Batch 2920 Training err. 1.70150 Training err. RA 2.17640 Valid. err. 1.80414
2018-02-04 00:02:01,939 training [INFO ] Epoch 15 Batch 2940 Training err. 1.66176 Training err. RA 2.17290 Valid. err. 1.81753
2018-02-04 00:02:02,428 training [INFO ] Epoch 15 Batch 2960 Training err. 1.72923 Training err. RA 2.16990 Valid. err. 1.80053
2018-02-04 00:02:02,943 training [INFO ] Epoch 15 Batch 2980 Training err. 1.74719 Training err. RA 2.16707 Valid. err. 1.79729
2018-02-04 00:02:03,422 training [INFO ] Epoch 15 Batch 3000 Training err. 1.69925 Training err. RA 2.16395 Valid. err. 1.81263
2018-02-04 00:02:03,907 training [INFO ] Epoch 15 Batch 3020 Training err. 1.70054 Training err. RA 2.16088 Valid. err. 1.81752
2018-02-04 00:02:04,404 training [INFO ] Epoch 15 Batch 3040 Training err. 1.76673 Training err. RA 2.15829 Valid. err. 1.78512
2018-02-04 00:02:04,893 training [INFO ] Epoch 15 Batch 3060 Training err. 1.70085 Training err. RA 2.15530 Valid. err. 1.79119
2018-02-04 00:02:05,371 training [INFO ] Epoch 15 Batch 3080 Training err. 1.67948 Training err. RA 2.15221 Valid. err. 1.77829
2018-02-04 00:02:05,855 training [INFO ] Epoch 15 Batch 3100 Training err. 1.69283 Training err. RA 2.14924 Valid. err. 1.77562
2018-02-04 00:02:06,371 training [INFO ] Epoch 15 Batch 3120 Training err. 1.67418 Training err. RA 2.14620 Valid. err. 1.77842
2018-02-04 00:02:07,283 training [INFO ] Epoch 16 Batch 3140 Training err. 1.66829 Training err. RA 2.14315 Valid. err. 1.75284
2018-02-04 00:02:07,764 training [INFO ] Epoch 16 Batch 3160 Training err. 1.63535 Training err. RA 2.13994 Valid. err. 1.77064
2018-02-04 00:02:08,249 training [INFO ] Epoch 16 Batch 3180 Training err. 1.70333 Training err. RA 2.13719 Valid. err. 1.79615
2018-02-04 00:02:08,733 training [INFO ] Epoch 16 Batch 3200 Training err. 1.72098 Training err. RA 2.13459 Valid. err. 1.77793
2018-02-04 00:02:09,218 training [INFO ] Epoch 16 Batch 3220 Training err. 1.66245 Training err. RA 2.13166 Valid. err. 1.77771
2018-02-04 00:02:09,704 training [INFO ] Epoch 16 Batch 3240 Training err. 1.73247 Training err. RA 2.12920 Valid. err. 1.76418
2018-02-04 00:02:10,192 training [INFO ] Epoch 16 Batch 3260 Training err. 1.68628 Training err. RA 2.12648 Valid. err. 1.76044
2018-02-04 00:02:10,684 training [INFO ] Epoch 16 Batch 3280 Training err. 1.66056 Training err. RA 2.12364 Valid. err. 1.78714
2018-02-04 00:02:11,193 training [INFO ] Epoch 16 Batch 3300 Training err. 1.65874 Training err. RA 2.12082 Valid. err. 1.75051
2018-02-04 00:02:11,757 training [INFO ] Epoch 16 Batch 3320 Training err. 1.66799 Training err. RA 2.11809 Valid. err. 1.74475
2018-02-04 00:02:12,842 training [INFO ] Epoch 17 Batch 3340 Training err. 1.64473 Training err. RA 2.11526 Valid. err. 1.74432
2018-02-04 00:02:13,425 training [INFO ] Epoch 17 Batch 3360 Training err. 1.59611 Training err. RA 2.11217 Valid. err. 1.75687
2018-02-04 00:02:14,445 training [INFO ] Epoch 17 Batch 3380 Training err. 1.68153 Training err. RA 2.10962 Valid. err. 1.75858
2018-02-04 00:02:15,064 training [INFO ] Epoch 17 Batch 3400 Training err. 1.68998 Training err. RA 2.10715 Valid. err. 1.77118
2018-02-04 00:02:15,658 training [INFO ] Epoch 17 Batch 3420 Training err. 1.64187 Training err. RA 2.10443 Valid. err. 1.74969
2018-02-04 00:02:16,232 training [INFO ] Epoch 17 Batch 3440 Training err. 1.66793 Training err. RA 2.10189 Valid. err. 1.75911
2018-02-04 00:02:16,758 training [INFO ] Epoch 17 Batch 3460 Training err. 1.70369 Training err. RA 2.09959 Valid. err. 1.74721
2018-02-04 00:02:17,294 training [INFO ] Epoch 17 Batch 3480 Training err. 1.63645 Training err. RA 2.09693 Valid. err. 1.74648
2018-02-04 00:02:17,826 training [INFO ] Epoch 17 Batch 3500 Training err. 1.64312 Training err. RA 2.09434 Valid. err. 1.74564
2018-02-04 00:02:18,351 training [INFO ] Epoch 17 Batch 3520 Training err. 1.63775 Training err. RA 2.09174 Valid. err. 1.71321
2018-02-04 00:02:19,209 training [INFO ] Epoch 18 Batch 3540 Training err. 1.61296 Training err. RA 2.08904 Valid. err. 1.74337
2018-02-04 00:02:19,693 training [INFO ] Epoch 18 Batch 3560 Training err. 1.60110 Training err. RA 2.08630 Valid. err. 1.73554
2018-02-04 00:02:20,248 training [INFO ] Epoch 18 Batch 3580 Training err. 1.62070 Training err. RA 2.08369 Valid. err. 1.72574
2018-02-04 00:02:20,823 training [INFO ] Epoch 18 Batch 3600 Training err. 1.65737 Training err. RA 2.08133 Valid. err. 1.73506
2018-02-04 00:02:21,403 training [INFO ] Epoch 18 Batch 3620 Training err. 1.64640 Training err. RA 2.07892 Valid. err. 1.74197
2018-02-04 00:02:21,945 training [INFO ] Epoch 18 Batch 3640 Training err. 1.62440 Training err. RA 2.07643 Valid. err. 1.73043
2018-02-04 00:02:22,444 training [INFO ] Epoch 18 Batch 3660 Training err. 1.69682 Training err. RA 2.07435 Valid. err. 1.74845
2018-02-04 00:02:22,929 training [INFO ] Epoch 18 Batch 3680 Training err. 1.60292 Training err. RA 2.07179 Valid. err. 1.74145
2018-02-04 00:02:23,422 training [INFO ] Epoch 18 Batch 3700 Training err. 1.61249 Training err. RA 2.06931 Valid. err. 1.76260
2018-02-04 00:02:23,905 training [INFO ] Epoch 18 Batch 3720 Training err. 1.60437 Training err. RA 2.06681 Valid. err. 1.71028
2018-02-04 00:02:24,403 training [INFO ] Epoch 18 Batch 3740 Training err. 1.62367 Training err. RA 2.06444 Valid. err. 1.72335
2018-02-04 00:02:25,325 training [INFO ] Epoch 19 Batch 3760 Training err. 1.58160 Training err. RA 2.06187 Valid. err. 1.71323
2018-02-04 00:02:25,820 training [INFO ] Epoch 19 Batch 3780 Training err. 1.56258 Training err. RA 2.05923 Valid. err. 1.71534
2018-02-04 00:02:26,321 training [INFO ] Epoch 19 Batch 3800 Training err. 1.62929 Training err. RA 2.05696 Valid. err. 1.72111
2018-02-04 00:02:26,826 training [INFO ] Epoch 19 Batch 3820 Training err. 1.64021 Training err. RA 2.05478 Valid. err. 1.73844
2018-02-04 00:02:27,356 training [INFO ] Epoch 19 Batch 3840 Training err. 1.59390 Training err. RA 2.05238 Valid. err. 1.72431
2018-02-04 00:02:27,843 training [INFO ] Epoch 19 Batch 3860 Training err. 1.65707 Training err. RA 2.05033 Valid. err. 1.71414
2018-02-04 00:02:28,357 training [INFO ] Epoch 19 Batch 3880 Training err. 1.62576 Training err. RA 2.04815 Valid. err. 1.70883
2018-02-04 00:02:28,839 training [INFO ] Epoch 19 Batch 3900 Training err. 1.58119 Training err. RA 2.04575 Valid. err. 1.70845
2018-02-04 00:02:29,328 training [INFO ] Epoch 19 Batch 3920 Training err. 1.59734 Training err. RA 2.04346 Valid. err. 1.69333
2018-02-04 00:02:29,874 training [INFO ] Epoch 19 Batch 3940 Training err. 1.59792 Training err. RA 2.04120 Valid. err. 1.70296
2018-02-04 00:02:30,732 training [INFO ] Epoch 20 Batch 3960 Training err. 1.57101 Training err. RA 2.03883 Valid. err. 1.70377
2018-02-04 00:02:31,219 training [INFO ] Epoch 20 Batch 3980 Training err. 1.54138 Training err. RA 2.03633 Valid. err. 1.70788
2018-02-04 00:02:31,743 training [INFO ] Epoch 20 Batch 4000 Training err. 1.60344 Training err. RA 2.03416 Valid. err. 1.69953
2018-02-04 00:02:32,367 training [INFO ] Epoch 20 Batch 4020 Training err. 1.62631 Training err. RA 2.03213 Valid. err. 1.69511
2018-02-04 00:02:32,869 training [INFO ] Epoch 20 Batch 4040 Training err. 1.57424 Training err. RA 2.02987 Valid. err. 1.71065
2018-02-04 00:02:33,425 training [INFO ] Epoch 20 Batch 4060 Training err. 1.57654 Training err. RA 2.02763 Valid. err. 1.71450
2018-02-04 00:02:34,029 training [INFO ] Epoch 20 Batch 4080 Training err. 1.64340 Training err. RA 2.02575 Valid. err. 1.69913
2018-02-04 00:02:34,505 training [INFO ] Epoch 20 Batch 4100 Training err. 1.57613 Training err. RA 2.02356 Valid. err. 1.69376
2018-02-04 00:02:35,106 training [INFO ] Epoch 20 Batch 4120 Training err. 1.55607 Training err. RA 2.02129 Valid. err. 1.69137
2018-02-04 00:02:35,667 training [INFO ] Epoch 20 Batch 4140 Training err. 1.57001 Training err. RA 2.01911 Valid. err. 1.67479
2018-02-04 00:02:36,166 training [INFO ] Epoch 20 Batch 4160 Training err. 1.55567 Training err. RA 2.01688 Valid. err. 1.68675
2018-02-04 00:02:37,166 training [INFO ] Epoch 21 Batch 4180 Training err. 1.55280 Training err. RA 2.01466 Valid. err. 1.66258
2018-02-04 00:02:37,664 training [INFO ] Epoch 21 Batch 4200 Training err. 1.52008 Training err. RA 2.01230 Valid. err. 1.69385
2018-02-04 00:02:38,290 training [INFO ] Epoch 21 Batch 4220 Training err. 1.58722 Training err. RA 2.01029 Valid. err. 1.71944
2018-02-04 00:02:38,834 training [INFO ] Epoch 21 Batch 4240 Training err. 1.60688 Training err. RA 2.00839 Valid. err. 1.69263
2018-02-04 00:02:39,413 training [INFO ] Epoch 21 Batch 4260 Training err. 1.54157 Training err. RA 2.00619 Valid. err. 1.68779
2018-02-04 00:02:40,039 training [INFO ] Epoch 21 Batch 4280 Training err. 1.61841 Training err. RA 2.00438 Valid. err. 1.69142
2018-02-04 00:02:40,617 training [INFO ] Epoch 21 Batch 4300 Training err. 1.57193 Training err. RA 2.00237 Valid. err. 1.68315
2018-02-04 00:02:41,254 training [INFO ] Epoch 21 Batch 4320 Training err. 1.54153 Training err. RA 2.00024 Valid. err. 1.69106
2018-02-04 00:02:41,806 training [INFO ] Epoch 21 Batch 4340 Training err. 1.54200 Training err. RA 1.99813 Valid. err. 1.65990
2018-02-04 00:02:42,301 training [INFO ] Epoch 21 Batch 4360 Training err. 1.56036 Training err. RA 1.99612 Valid. err. 1.65312
2018-02-04 00:02:43,337 training [INFO ] Epoch 22 Batch 4380 Training err. 1.53081 Training err. RA 1.99399 Valid. err. 1.66015
2018-02-04 00:02:43,865 training [INFO ] Epoch 22 Batch 4400 Training err. 1.49288 Training err. RA 1.99172 Valid. err. 1.68252
2018-02-04 00:02:44,493 training [INFO ] Epoch 22 Batch 4420 Training err. 1.56909 Training err. RA 1.98980 Valid. err. 1.67910
2018-02-04 00:02:45,102 training [INFO ] Epoch 22 Batch 4440 Training err. 1.58145 Training err. RA 1.98796 Valid. err. 1.69466
2018-02-04 00:02:45,688 training [INFO ] Epoch 22 Batch 4460 Training err. 1.53312 Training err. RA 1.98592 Valid. err. 1.67697
2018-02-04 00:02:46,298 training [INFO ] Epoch 22 Batch 4480 Training err. 1.55705 Training err. RA 1.98401 Valid. err. 1.67126
2018-02-04 00:02:46,794 training [INFO ] Epoch 22 Batch 4500 Training err. 1.59555 Training err. RA 1.98228 Valid. err. 1.66361
2018-02-04 00:02:47,406 training [INFO ] Epoch 22 Batch 4520 Training err. 1.52474 Training err. RA 1.98026 Valid. err. 1.66873
2018-02-04 00:02:47,985 training [INFO ] Epoch 22 Batch 4540 Training err. 1.53050 Training err. RA 1.97828 Valid. err. 1.67455
2018-02-04 00:02:48,530 training [INFO ] Epoch 22 Batch 4560 Training err. 1.52984 Training err. RA 1.97631 Valid. err. 1.64224
2018-02-04 00:02:49,538 training [INFO ] Epoch 23 Batch 4580 Training err. 1.51175 Training err. RA 1.97428 Valid. err. 1.67305
2018-02-04 00:02:50,079 training [INFO ] Epoch 23 Batch 4600 Training err. 1.49796 Training err. RA 1.97221 Valid. err. 1.66449
2018-02-04 00:02:50,711 training [INFO ] Epoch 23 Batch 4620 Training err. 1.51456 Training err. RA 1.97023 Valid. err. 1.65811
2018-02-04 00:02:51,195 training [INFO ] Epoch 23 Batch 4640 Training err. 1.55491 Training err. RA 1.96844 Valid. err. 1.66057
2018-02-04 00:02:51,774 training [INFO ] Epoch 23 Batch 4660 Training err. 1.54672 Training err. RA 1.96663 Valid. err. 1.68549
2018-02-04 00:02:52,361 training [INFO ] Epoch 23 Batch 4680 Training err. 1.51912 Training err. RA 1.96472 Valid. err. 1.66456
2018-02-04 00:02:52,876 training [INFO ] Epoch 23 Batch 4700 Training err. 1.59489 Training err. RA 1.96314 Valid. err. 1.68018
2018-02-04 00:02:53,507 training [INFO ] Epoch 23 Batch 4720 Training err. 1.50016 Training err. RA 1.96118 Valid. err. 1.67179
2018-02-04 00:02:54,298 training [INFO ] Epoch 23 Batch 4740 Training err. 1.50590 Training err. RA 1.95926 Valid. err. 1.67202
2018-02-04 00:02:55,053 training [INFO ] Epoch 23 Batch 4760 Training err. 1.49836 Training err. RA 1.95732 Valid. err. 1.65907
2018-02-04 00:02:55,656 training [INFO ] Epoch 23 Batch 4780 Training err. 1.52745 Training err. RA 1.95552 Valid. err. 1.64335
2018-02-04 00:02:56,787 training [INFO ] Epoch 24 Batch 4800 Training err. 1.47996 Training err. RA 1.95354 Valid. err. 1.66620
2018-02-04 00:02:57,421 training [INFO ] Epoch 24 Batch 4820 Training err. 1.46767 Training err. RA 1.95153 Valid. err. 1.64984
2018-02-04 00:02:58,059 training [INFO ] Epoch 24 Batch 4840 Training err. 1.52771 Training err. RA 1.94978 Valid. err. 1.66228
2018-02-04 00:02:58,567 training [INFO ] Epoch 24 Batch 4860 Training err. 1.54518 Training err. RA 1.94811 Valid. err. 1.67847
2018-02-04 00:02:59,183 training [INFO ] Epoch 24 Batch 4880 Training err. 1.49575 Training err. RA 1.94626 Valid. err. 1.68018
2018-02-04 00:02:59,784 training [INFO ] Epoch 24 Batch 4900 Training err. 1.55860 Training err. RA 1.94467 Valid. err. 1.65505
2018-02-04 00:03:00,371 training [INFO ] Epoch 24 Batch 4920 Training err. 1.52952 Training err. RA 1.94299 Valid. err. 1.65837
2018-02-04 00:03:01,067 training [INFO ] Epoch 24 Batch 4940 Training err. 1.48086 Training err. RA 1.94112 Valid. err. 1.65514
2018-02-04 00:03:01,652 training [INFO ] Epoch 24 Batch 4960 Training err. 1.48917 Training err. RA 1.93929 Valid. err. 1.64334
2018-02-04 00:03:02,331 training [INFO ] Epoch 24 Batch 4980 Training err. 1.50192 Training err. RA 1.93754 Valid. err. 1.65019
2018-02-04 00:03:03,672 training [INFO ] Epoch 25 Batch 5000 Training err. 1.47514 Training err. RA 1.93569 Valid. err. 1.64065
2018-02-04 00:03:04,324 training [INFO ] Epoch 25 Batch 5020 Training err. 1.44807 Training err. RA 1.93374 Valid. err. 1.65968
2018-02-04 00:03:04,994 training [INFO ] Epoch 25 Batch 5040 Training err. 1.50516 Training err. RA 1.93204 Valid. err. 1.64536
2018-02-04 00:03:05,640 training [INFO ] Epoch 25 Batch 5060 Training err. 1.53576 Training err. RA 1.93048 Valid. err. 1.64918
2018-02-04 00:03:06,215 training [INFO ] Epoch 25 Batch 5080 Training err. 1.48335 Training err. RA 1.92872 Valid. err. 1.65644
2018-02-04 00:03:06,848 training [INFO ] Epoch 25 Batch 5100 Training err. 1.48323 Training err. RA 1.92697 Valid. err. 1.67538
2018-02-04 00:03:07,409 training [INFO ] Epoch 25 Batch 5120 Training err. 1.54879 Training err. RA 1.92549 Valid. err. 1.64361
2018-02-04 00:03:08,081 training [INFO ] Epoch 25 Batch 5140 Training err. 1.48053 Training err. RA 1.92376 Valid. err. 1.64266
2018-02-04 00:03:08,650 training [INFO ] Epoch 25 Batch 5160 Training err. 1.45921 Training err. RA 1.92196 Valid. err. 1.64311
2018-02-04 00:03:09,214 training [INFO ] Epoch 25 Batch 5180 Training err. 1.47628 Training err. RA 1.92024 Valid. err. 1.62473
2018-02-04 00:03:09,828 training [INFO ] Epoch 25 Batch 5200 Training err. 1.46673 Training err. RA 1.91850 Valid. err. 1.63658
2018-02-04 00:03:10,915 training [INFO ] Epoch 26 Batch 5220 Training err. 1.46109 Training err. RA 1.91674 Valid. err. 1.62348
2018-02-04 00:03:11,480 training [INFO ] Epoch 26 Batch 5240 Training err. 1.43029 Training err. RA 1.91489 Valid. err. 1.65401
2018-02-04 00:03:12,019 training [INFO ] Epoch 26 Batch 5260 Training err. 1.49817 Training err. RA 1.91330 Valid. err. 1.67941
2018-02-04 00:03:12,681 training [INFO ] Epoch 26 Batch 5280 Training err. 1.51954 Training err. RA 1.91181 Valid. err. 1.65009
2018-02-04 00:03:13,298 training [INFO ] Epoch 26 Batch 5300 Training err. 1.45160 Training err. RA 1.91007 Valid. err. 1.64840
2018-02-04 00:03:13,955 training [INFO ] Epoch 26 Batch 5320 Training err. 1.53007 Training err. RA 1.90865 Valid. err. 1.65049
2018-02-04 00:03:14,593 training [INFO ] Epoch 26 Batch 5340 Training err. 1.48459 Training err. RA 1.90706 Valid. err. 1.63858
2018-02-04 00:03:15,263 training [INFO ] Epoch 26 Batch 5360 Training err. 1.44998 Training err. RA 1.90535 Valid. err. 1.64465
2018-02-04 00:03:15,930 training [INFO ] Epoch 26 Batch 5380 Training err. 1.44965 Training err. RA 1.90366 Valid. err. 1.62604
2018-02-04 00:03:16,599 training [INFO ] Epoch 26 Batch 5400 Training err. 1.47604 Training err. RA 1.90207 Valid. err. 1.60848
2018-02-04 00:03:17,556 training [INFO ] Epoch 27 Batch 5420 Training err. 1.43897 Training err. RA 1.90037 Valid. err. 1.62053
2018-02-04 00:03:18,160 training [INFO ] Epoch 27 Batch 5440 Training err. 1.41293 Training err. RA 1.89857 Valid. err. 1.65131
2018-02-04 00:03:18,761 training [INFO ] Epoch 27 Batch 5460 Training err. 1.48037 Training err. RA 1.89704 Valid. err. 1.63974
2018-02-04 00:03:19,373 training [INFO ] Epoch 27 Batch 5480 Training err. 1.49839 Training err. RA 1.89559 Valid. err. 1.65358
2018-02-04 00:03:20,015 training [INFO ] Epoch 27 Batch 5500 Training err. 1.44798 Training err. RA 1.89396 Valid. err. 1.64592
2018-02-04 00:03:20,602 training [INFO ] Epoch 27 Batch 5520 Training err. 1.47301 Training err. RA 1.89243 Valid. err. 1.62047
2018-02-04 00:03:21,218 training [INFO ] Epoch 27 Batch 5540 Training err. 1.51441 Training err. RA 1.89107 Valid. err. 1.63123
2018-02-04 00:03:21,783 training [INFO ] Epoch 27 Batch 5560 Training err. 1.43603 Training err. RA 1.88943 Valid. err. 1.65148
2018-02-04 00:03:22,390 training [INFO ] Epoch 27 Batch 5580 Training err. 1.44776 Training err. RA 1.88785 Valid. err. 1.64047
2018-02-04 00:03:23,037 training [INFO ] Epoch 27 Batch 5600 Training err. 1.44445 Training err. RA 1.88627 Valid. err. 1.61687
2018-02-04 00:03:24,174 training [INFO ] Epoch 28 Batch 5620 Training err. 1.43066 Training err. RA 1.88464 Valid. err. 1.64778
2018-02-04 00:03:24,669 training [INFO ] Epoch 28 Batch 5640 Training err. 1.42003 Training err. RA 1.88300 Valid. err. 1.64002
2018-02-04 00:03:25,300 training [INFO ] Epoch 28 Batch 5660 Training err. 1.42656 Training err. RA 1.88138 Valid. err. 1.63414
2018-02-04 00:03:25,986 training [INFO ] Epoch 28 Batch 5680 Training err. 1.47721 Training err. RA 1.87996 Valid. err. 1.63216
2018-02-04 00:03:26,599 training [INFO ] Epoch 28 Batch 5700 Training err. 1.46866 Training err. RA 1.87852 Valid. err. 1.66120
2018-02-04 00:03:27,289 training [INFO ] Epoch 28 Batch 5720 Training err. 1.43765 Training err. RA 1.87698 Valid. err. 1.63113
2018-02-04 00:03:27,838 training [INFO ] Epoch 28 Batch 5740 Training err. 1.51213 Training err. RA 1.87570 Valid. err. 1.64210
2018-02-04 00:03:28,855 training [INFO ] Epoch 28 Batch 5760 Training err. 1.42134 Training err. RA 1.87413 Valid. err. 1.63774
2018-02-04 00:03:29,660 training [INFO ] Epoch 28 Batch 5780 Training err. 1.42771 Training err. RA 1.87258 Valid. err. 1.66476
2018-02-04 00:03:30,421 training [INFO ] Epoch 28 Batch 5800 Training err. 1.41837 Training err. RA 1.87102 Valid. err. 1.63475
2018-02-04 00:03:31,224 training [INFO ] Epoch 28 Batch 5820 Training err. 1.45174 Training err. RA 1.86958 Valid. err. 1.60773
2018-02-04 00:03:34,285 training [INFO ] Epoch 29 Batch 5840 Training err. 1.40039 Training err. RA 1.86797 Valid. err. 1.64321
2018-02-04 00:03:35,024 training [INFO ] Epoch 29 Batch 5860 Training err. 1.39069 Training err. RA 1.86634 Valid. err. 1.63453
2018-02-04 00:03:35,822 training [INFO ] Epoch 29 Batch 5880 Training err. 1.44948 Training err. RA 1.86492 Valid. err. 1.63333
2018-02-04 00:03:36,831 training [INFO ] Epoch 29 Batch 5900 Training err. 1.46802 Training err. RA 1.86358 Valid. err. 1.65156
2018-02-04 00:03:37,932 training [INFO ] Epoch 29 Batch 5920 Training err. 1.41730 Training err. RA 1.86207 Valid. err. 1.66750
2018-02-04 00:03:38,534 training [INFO ] Epoch 29 Batch 5940 Training err. 1.48170 Training err. RA 1.86079 Valid. err. 1.62499
2018-02-04 00:03:39,222 training [INFO ] Epoch 29 Batch 5960 Training err. 1.45992 Training err. RA 1.85944 Valid. err. 1.63202
2018-02-04 00:03:39,884 training [INFO ] Epoch 29 Batch 5980 Training err. 1.40638 Training err. RA 1.85793 Valid. err. 1.64333
2018-02-04 00:03:40,500 training [INFO ] Epoch 29 Batch 6000 Training err. 1.41616 Training err. RA 1.85645 Valid. err. 1.61455
2018-02-04 00:03:41,103 training [INFO ] Epoch 29 Batch 6020 Training err. 1.42626 Training err. RA 1.85503 Valid. err. 1.63662
2018-02-04 00:03:47,514 training [INFO ] Epoch 30 Batch 6040 Training err. 1.39673 Training err. RA 1.85351 Valid. err. 1.62437
2018-02-04 00:03:48,272 training [INFO ] Epoch 30 Batch 6060 Training err. 1.37994 Training err. RA 1.85195 Valid. err. 1.63585
2018-02-04 00:03:49,762 training [INFO ] Epoch 30 Batch 6080 Training err. 1.42964 Training err. RA 1.85056 Valid. err. 1.62826
2018-02-04 00:03:50,520 training [INFO ] Epoch 30 Batch 6100 Training err. 1.46303 Training err. RA 1.84929 Valid. err. 1.62645
2018-02-04 00:03:51,195 training [INFO ] Epoch 30 Batch 6120 Training err. 1.40952 Training err. RA 1.84785 Valid. err. 1.63091
2018-02-04 00:03:51,917 training [INFO ] Epoch 30 Batch 6140 Training err. 1.41664 Training err. RA 1.84644 Valid. err. 1.63811
2018-02-04 00:03:52,796 training [INFO ] Epoch 30 Batch 6160 Training err. 1.47188 Training err. RA 1.84523 Valid. err. 1.62225
2018-02-04 00:03:53,849 training [INFO ] Epoch 30 Batch 6180 Training err. 1.40684 Training err. RA 1.84381 Valid. err. 1.61669
2018-02-04 00:03:54,446 training [INFO ] Epoch 30 Batch 6200 Training err. 1.39474 Training err. RA 1.84236 Valid. err. 1.62326
2018-02-04 00:03:55,467 training [INFO ] Epoch 30 Batch 6220 Training err. 1.40206 Training err. RA 1.84094 Valid. err. 1.60886
2018-02-04 00:03:56,393 training [INFO ] Epoch 30 Batch 6240 Training err. 1.39614 Training err. RA 1.83952 Valid. err. 1.61570
2018-02-04 00:04:03,263 training [INFO ] Epoch 31 Batch 6260 Training err. 1.39026 Training err. RA 1.83808 Valid. err. 1.62049
2018-02-04 00:04:04,380 training [INFO ] Epoch 31 Batch 6280 Training err. 1.36308 Training err. RA 1.83657 Valid. err. 1.63229
2018-02-04 00:04:05,093 training [INFO ] Epoch 31 Batch 6300 Training err. 1.42775 Training err. RA 1.83527 Valid. err. 1.65790
2018-02-04 00:04:06,121 training [INFO ] Epoch 31 Batch 6320 Training err. 1.44758 Training err. RA 1.83405 Valid. err. 1.63420
2018-02-04 00:04:06,989 training [INFO ] Epoch 31 Batch 6340 Training err. 1.37849 Training err. RA 1.83261 Valid. err. 1.63274
2018-02-04 00:04:07,954 training [INFO ] Epoch 31 Batch 6360 Training err. 1.46044 Training err. RA 1.83144 Valid. err. 1.62754
2018-02-04 00:04:08,965 training [INFO ] Epoch 31 Batch 6380 Training err. 1.41475 Training err. RA 1.83013 Valid. err. 1.62194
2018-02-04 00:04:09,850 training [INFO ] Epoch 31 Batch 6400 Training err. 1.38048 Training err. RA 1.82873 Valid. err. 1.63250
2018-02-04 00:04:10,695 training [INFO ] Epoch 31 Batch 6420 Training err. 1.38221 Training err. RA 1.82734 Valid. err. 1.61181
2018-02-04 00:04:11,613 training [INFO ] Epoch 31 Batch 6440 Training err. 1.40824 Training err. RA 1.82603 Valid. err. 1.59889
2018-02-04 00:04:17,577 training [INFO ] Epoch 32 Batch 6460 Training err. 1.36884 Training err. RA 1.82462 Valid. err. 1.60432
2018-02-04 00:04:18,262 training [INFO ] Epoch 32 Batch 6480 Training err. 1.34914 Training err. RA 1.82315 Valid. err. 1.63133
2018-02-04 00:04:19,390 training [INFO ] Epoch 32 Batch 6500 Training err. 1.41148 Training err. RA 1.82188 Valid. err. 1.63386
2018-02-04 00:04:20,160 training [INFO ] Epoch 32 Batch 6520 Training err. 1.42976 Training err. RA 1.82068 Valid. err. 1.63996
2018-02-04 00:04:20,764 training [INFO ] Epoch 32 Batch 6540 Training err. 1.37714 Training err. RA 1.81933 Valid. err. 1.64221
2018-02-04 00:04:21,702 training [INFO ] Epoch 32 Batch 6560 Training err. 1.41504 Training err. RA 1.81809 Valid. err. 1.60504
2018-02-04 00:04:22,556 training [INFO ] Epoch 32 Batch 6580 Training err. 1.44420 Training err. RA 1.81696 Valid. err. 1.62182
2018-02-04 00:04:23,176 training [INFO ] Epoch 32 Batch 6600 Training err. 1.36653 Training err. RA 1.81559 Valid. err. 1.63732
2018-02-04 00:04:24,014 training [INFO ] Epoch 32 Batch 6620 Training err. 1.38240 Training err. RA 1.81428 Valid. err. 1.62466
2018-02-04 00:04:24,668 training [INFO ] Epoch 32 Batch 6640 Training err. 1.37714 Training err. RA 1.81297 Valid. err. 1.60544
2018-02-04 00:04:29,385 training [INFO ] Epoch 33 Batch 6660 Training err. 1.37042 Training err. RA 1.81164 Valid. err. 1.62257
2018-02-04 00:04:30,164 training [INFO ] Epoch 33 Batch 6680 Training err. 1.35667 Training err. RA 1.81028 Valid. err. 1.63268
2018-02-04 00:04:30,739 training [INFO ] Epoch 33 Batch 6700 Training err. 1.36104 Training err. RA 1.80893 Valid. err. 1.63432
2018-02-04 00:04:31,511 training [INFO ] Epoch 33 Batch 6720 Training err. 1.41215 Training err. RA 1.80775 Valid. err. 1.62869
2018-02-04 00:04:32,374 training [INFO ] Epoch 33 Batch 6740 Training err. 1.40655 Training err. RA 1.80656 Valid. err. 1.64641
2018-02-04 00:04:33,139 training [INFO ] Epoch 33 Batch 6760 Training err. 1.37347 Training err. RA 1.80528 Valid. err. 1.61393
2018-02-04 00:04:34,206 training [INFO ] Epoch 33 Batch 6780 Training err. 1.44259 Training err. RA 1.80421 Valid. err. 1.63013
2018-02-04 00:04:35,039 training [INFO ] Epoch 33 Batch 6800 Training err. 1.35779 Training err. RA 1.80290 Valid. err. 1.62871
2018-02-04 00:04:35,666 training [INFO ] Epoch 33 Batch 6820 Training err. 1.36051 Training err. RA 1.80160 Valid. err. 1.65580
2018-02-04 00:04:36,256 training [INFO ] Epoch 33 Batch 6840 Training err. 1.35303 Training err. RA 1.80029 Valid. err. 1.63382
2018-02-04 00:04:36,811 training [INFO ] Epoch 33 Batch 6860 Training err. 1.38621 Training err. RA 1.79908 Valid. err. 1.60860
2018-02-04 00:04:38,458 training [INFO ] Epoch 34 Batch 6880 Training err. 1.33831 Training err. RA 1.79774 Valid. err. 1.63783
2018-02-04 00:04:39,058 training [INFO ] Epoch 34 Batch 6900 Training err. 1.33128 Training err. RA 1.79639 Valid. err. 1.63330
2018-02-04 00:04:39,624 training [INFO ] Epoch 34 Batch 6920 Training err. 1.38927 Training err. RA 1.79521 Valid. err. 1.64010
2018-02-04 00:04:40,338 training [INFO ] Epoch 34 Batch 6940 Training err. 1.40407 Training err. RA 1.79409 Valid. err. 1.64190
2018-02-04 00:04:40,964 training [INFO ] Epoch 34 Batch 6960 Training err. 1.35160 Training err. RA 1.79282 Valid. err. 1.66563
2018-02-04 00:04:41,642 training [INFO ] Epoch 34 Batch 6980 Training err. 1.41984 Training err. RA 1.79175 Valid. err. 1.62716
2018-02-04 00:04:42,147 training [INFO ] Epoch 34 Batch 7000 Training err. 1.38706 Training err. RA 1.79059 Valid. err. 1.64356
2018-02-04 00:04:42,649 training [INFO ] Epoch 34 Batch 7020 Training err. 1.34197 Training err. RA 1.78931 Valid. err. 1.66456
2018-02-04 00:04:43,225 training [INFO ] Epoch 34 Batch 7040 Training err. 1.35821 Training err. RA 1.78809 Valid. err. 1.62229
2018-02-04 00:04:43,825 training [INFO ] Epoch 34 Batch 7060 Training err. 1.36567 Training err. RA 1.78689 Valid. err. 1.64499
2018-02-04 00:04:44,805 training [INFO ] Epoch 35 Batch 7080 Training err. 1.33856 Training err. RA 1.78562 Valid. err. 1.61050
2018-02-04 00:04:45,326 training [INFO ] Epoch 35 Batch 7100 Training err. 1.32468 Training err. RA 1.78433 Valid. err. 1.62383
2018-02-04 00:04:45,839 training [INFO ] Epoch 35 Batch 7120 Training err. 1.37012 Training err. RA 1.78316 Valid. err. 1.63716
2018-02-04 00:04:46,338 training [INFO ] Epoch 35 Batch 7140 Training err. 1.40018 Training err. RA 1.78209 Valid. err. 1.63212
2018-02-04 00:04:46,918 training [INFO ] Epoch 35 Batch 7160 Training err. 1.34959 Training err. RA 1.78088 Valid. err. 1.63128
2018-02-04 00:04:47,469 training [INFO ] Epoch 35 Batch 7180 Training err. 1.35052 Training err. RA 1.77968 Valid. err. 1.64184
2018-02-04 00:04:47,966 training [INFO ] Epoch 35 Batch 7200 Training err. 1.40569 Training err. RA 1.77864 Valid. err. 1.63078
2018-02-04 00:04:48,460 training [INFO ] Epoch 35 Batch 7220 Training err. 1.34211 Training err. RA 1.77743 Valid. err. 1.62507
2018-02-04 00:04:49,028 training [INFO ] Epoch 35 Batch 7240 Training err. 1.33145 Training err. RA 1.77620 Valid. err. 1.61858
2018-02-04 00:04:49,608 training [INFO ] Epoch 35 Batch 7260 Training err. 1.34595 Training err. RA 1.77502 Valid. err. 1.62265
2018-02-04 00:04:50,101 training [INFO ] Epoch 35 Batch 7280 Training err. 1.34094 Training err. RA 1.77383 Valid. err. 1.65748
2018-02-04 00:04:51,065 training [INFO ] Epoch 36 Batch 7300 Training err. 1.34794 Training err. RA 1.77266 Valid. err. 1.63022
2018-02-04 00:04:51,565 training [INFO ] Epoch 36 Batch 7320 Training err. 1.31090 Training err. RA 1.77140 Valid. err. 1.64640
2018-02-04 00:04:52,067 training [INFO ] Epoch 36 Batch 7340 Training err. 1.37017 Training err. RA 1.77030 Valid. err. 1.66046
2018-02-04 00:04:52,565 training [INFO ] Epoch 36 Batch 7360 Training err. 1.39051 Training err. RA 1.76927 Valid. err. 1.63272
2018-02-04 00:04:53,063 training [INFO ] Epoch 36 Batch 7380 Training err. 1.31843 Training err. RA 1.76805 Valid. err. 1.63026
2018-02-04 00:04:53,558 training [INFO ] Epoch 36 Batch 7400 Training err. 1.39690 Training err. RA 1.76705 Valid. err. 1.63651
2018-02-04 00:04:54,051 training [INFO ] Epoch 36 Batch 7420 Training err. 1.35426 Training err. RA 1.76593 Valid. err. 1.64910
2018-02-04 00:04:54,549 training [INFO ] Epoch 36 Batch 7440 Training err. 1.32111 Training err. RA 1.76474 Valid. err. 1.64279
2018-02-04 00:04:55,047 training [INFO ] Epoch 36 Batch 7460 Training err. 1.32536 Training err. RA 1.76356 Valid. err. 1.62159
2018-02-04 00:04:55,542 training [INFO ] Epoch 36 Batch 7480 Training err. 1.35362 Training err. RA 1.76246 Valid. err. 1.61143
2018-02-04 00:04:56,422 training [INFO ] Epoch 37 Batch 7500 Training err. 1.31809 Training err. RA 1.76128 Valid. err. 1.61327
2018-02-04 00:04:56,915 training [INFO ] Epoch 37 Batch 7520 Training err. 1.30037 Training err. RA 1.76005 Valid. err. 1.63319
2018-02-04 00:04:57,415 training [INFO ] Epoch 37 Batch 7540 Training err. 1.36144 Training err. RA 1.75900 Valid. err. 1.64443
2018-02-04 00:04:57,913 training [INFO ] Epoch 37 Batch 7560 Training err. 1.37559 Training err. RA 1.75798 Valid. err. 1.64443
2018-02-04 00:04:58,410 training [INFO ] Epoch 37 Batch 7580 Training err. 1.31950 Training err. RA 1.75682 Valid. err. 1.65923
2018-02-04 00:04:58,903 training [INFO ] Epoch 37 Batch 7600 Training err. 1.34986 Training err. RA 1.75575 Valid. err. 1.60462
2018-02-04 00:04:59,410 training [INFO ] Epoch 37 Batch 7620 Training err. 1.38415 Training err. RA 1.75478 Valid. err. 1.61809
2018-02-04 00:04:59,915 training [INFO ] Epoch 37 Batch 7640 Training err. 1.30500 Training err. RA 1.75360 Valid. err. 1.63596
2018-02-04 00:05:00,415 training [INFO ] Epoch 37 Batch 7660 Training err. 1.33017 Training err. RA 1.75250 Valid. err. 1.62908
2018-02-04 00:05:00,908 training [INFO ] Epoch 37 Batch 7680 Training err. 1.32093 Training err. RA 1.75137 Valid. err. 1.61060
2018-02-04 00:05:01,917 training [INFO ] Epoch 38 Batch 7700 Training err. 1.31227 Training err. RA 1.75023 Valid. err. 1.63141
2018-02-04 00:05:02,631 training [INFO ] Epoch 38 Batch 7720 Training err. 1.30824 Training err. RA 1.74909 Valid. err. 1.64201
2018-02-04 00:05:03,275 training [INFO ] Epoch 38 Batch 7740 Training err. 1.30912 Training err. RA 1.74795 Valid. err. 1.67133
2018-02-04 00:05:03,909 training [INFO ] Epoch 38 Batch 7760 Training err. 1.36071 Training err. RA 1.74695 Valid. err. 1.63760
2018-02-04 00:05:04,468 training [INFO ] Epoch 38 Batch 7780 Training err. 1.34983 Training err. RA 1.74593 Valid. err. 1.64693
2018-02-04 00:05:05,017 training [INFO ] Epoch 38 Batch 7800 Training err. 1.31924 Training err. RA 1.74484 Valid. err. 1.61233
2018-02-04 00:05:05,603 training [INFO ] Epoch 38 Batch 7820 Training err. 1.38404 Training err. RA 1.74391 Valid. err. 1.64108
2018-02-04 00:05:06,188 training [INFO ] Epoch 38 Batch 7840 Training err. 1.30102 Training err. RA 1.74278 Valid. err. 1.63940
2018-02-04 00:05:06,716 training [INFO ] Epoch 38 Batch 7860 Training err. 1.30990 Training err. RA 1.74168 Valid. err. 1.68390
2018-02-04 00:05:07,254 training [INFO ] Epoch 38 Batch 7880 Training err. 1.29944 Training err. RA 1.74056 Valid. err. 1.63601
2018-02-04 00:05:07,764 training [INFO ] Epoch 38 Batch 7900 Training err. 1.33543 Training err. RA 1.73953 Valid. err. 1.61592
2018-02-04 00:05:08,802 training [INFO ] Epoch 39 Batch 7920 Training err. 1.28831 Training err. RA 1.73839 Valid. err. 1.64434
2018-02-04 00:05:09,294 training [INFO ] Epoch 39 Batch 7940 Training err. 1.28193 Training err. RA 1.73724 Valid. err. 1.66067
2018-02-04 00:05:09,771 training [INFO ] Epoch 39 Batch 7960 Training err. 1.34092 Training err. RA 1.73625 Valid. err. 1.64630
2018-02-04 00:05:10,249 training [INFO ] Epoch 39 Batch 7980 Training err. 1.35541 Training err. RA 1.73529 Valid. err. 1.64913
2018-02-04 00:05:10,819 training [INFO ] Epoch 39 Batch 8000 Training err. 1.29398 Training err. RA 1.73419 Valid. err. 1.68400
2018-02-04 00:05:11,386 training [INFO ] Epoch 39 Batch 8020 Training err. 1.36454 Training err. RA 1.73327 Valid. err. 1.64053
2018-02-04 00:05:11,859 training [INFO ] Epoch 39 Batch 8040 Training err. 1.33793 Training err. RA 1.73229 Valid. err. 1.65982
2018-02-04 00:05:12,452 training [INFO ] Epoch 39 Batch 8060 Training err. 1.29107 Training err. RA 1.73119 Valid. err. 1.66821
2018-02-04 00:05:12,998 training [INFO ] Epoch 39 Batch 8080 Training err. 1.30623 Training err. RA 1.73014 Valid. err. 1.62410
2018-02-04 00:05:13,632 training [INFO ] Epoch 39 Batch 8100 Training err. 1.31217 Training err. RA 1.72911 Valid. err. 1.63137
2018-02-04 00:05:14,650 training [INFO ] Epoch 40 Batch 8120 Training err. 1.29789 Training err. RA 1.72804 Valid. err. 1.60995
2018-02-04 00:05:15,135 training [INFO ] Epoch 40 Batch 8140 Training err. 1.28131 Training err. RA 1.72695 Valid. err. 1.64363
2018-02-04 00:05:15,621 training [INFO ] Epoch 40 Batch 8160 Training err. 1.32552 Training err. RA 1.72596 Valid. err. 1.62728
2018-02-04 00:05:16,113 training [INFO ] Epoch 40 Batch 8180 Training err. 1.34740 Training err. RA 1.72504 Valid. err. 1.64011
2018-02-04 00:05:16,622 training [INFO ] Epoch 40 Batch 8200 Training err. 1.29185 Training err. RA 1.72398 Valid. err. 1.64418
2018-02-04 00:05:17,124 training [INFO ] Epoch 40 Batch 8220 Training err. 1.30720 Training err. RA 1.72297 Valid. err. 1.64307
2018-02-04 00:05:17,599 training [INFO ] Epoch 40 Batch 8240 Training err. 1.35388 Training err. RA 1.72207 Valid. err. 1.63198
2018-02-04 00:05:18,082 training [INFO ] Epoch 40 Batch 8260 Training err. 1.29799 Training err. RA 1.72104 Valid. err. 1.63184
2018-02-04 00:05:18,565 training [INFO ] Epoch 40 Batch 8280 Training err. 1.28303 Training err. RA 1.71999 Valid. err. 1.63408
2018-02-04 00:05:19,048 training [INFO ] Epoch 40 Batch 8300 Training err. 1.29133 Training err. RA 1.71895 Valid. err. 1.62858
2018-02-04 00:05:19,531 training [INFO ] Epoch 40 Batch 8320 Training err. 1.28943 Training err. RA 1.71792 Valid. err. 1.65631
2018-02-04 00:05:20,504 training [INFO ] Epoch 41 Batch 8340 Training err. 1.30245 Training err. RA 1.71692 Valid. err. 1.63518
2018-02-04 00:05:20,985 training [INFO ] Epoch 41 Batch 8360 Training err. 1.26149 Training err. RA 1.71584 Valid. err. 1.67814
2018-02-04 00:05:21,470 training [INFO ] Epoch 41 Batch 8380 Training err. 1.33005 Training err. RA 1.71491 Valid. err. 1.66994
2018-02-04 00:05:21,967 training [INFO ] Epoch 41 Batch 8400 Training err. 1.33706 Training err. RA 1.71401 Valid. err. 1.63534
2018-02-04 00:05:22,458 training [INFO ] Epoch 41 Batch 8420 Training err. 1.27217 Training err. RA 1.71297 Valid. err. 1.63331
2018-02-04 00:05:22,940 training [INFO ] Epoch 41 Batch 8440 Training err. 1.34542 Training err. RA 1.71209 Valid. err. 1.64613
2018-02-04 00:05:23,432 training [INFO ] Epoch 41 Batch 8460 Training err. 1.31019 Training err. RA 1.71114 Valid. err. 1.66028
2018-02-04 00:05:23,920 training [INFO ] Epoch 41 Batch 8480 Training err. 1.27869 Training err. RA 1.71012 Valid. err. 1.66718
2018-02-04 00:05:24,404 training [INFO ] Epoch 41 Batch 8500 Training err. 1.27675 Training err. RA 1.70910 Valid. err. 1.63189
2018-02-04 00:05:24,887 training [INFO ] Epoch 41 Batch 8520 Training err. 1.31380 Training err. RA 1.70818 Valid. err. 1.63413
2018-02-04 00:05:25,791 training [INFO ] Epoch 42 Batch 8540 Training err. 1.26844 Training err. RA 1.70715 Valid. err. 1.62328
2018-02-04 00:05:26,277 training [INFO ] Epoch 42 Batch 8560 Training err. 1.25533 Training err. RA 1.70609 Valid. err. 1.64243
2018-02-04 00:05:26,768 training [INFO ] Epoch 42 Batch 8580 Training err. 1.31502 Training err. RA 1.70518 Valid. err. 1.64598
2018-02-04 00:05:27,251 training [INFO ] Epoch 42 Batch 8600 Training err. 1.33188 Training err. RA 1.70431 Valid. err. 1.64787
2018-02-04 00:05:27,734 training [INFO ] Epoch 42 Batch 8620 Training err. 1.28484 Training err. RA 1.70334 Valid. err. 1.65797
2018-02-04 00:05:28,216 training [INFO ] Epoch 42 Batch 8640 Training err. 1.30384 Training err. RA 1.70241 Valid. err. 1.62007
2018-02-04 00:05:28,702 training [INFO ] Epoch 42 Batch 8660 Training err. 1.34091 Training err. RA 1.70158 Valid. err. 1.63135
2018-02-04 00:05:29,186 training [INFO ] Epoch 42 Batch 8680 Training err. 1.28302 Training err. RA 1.70061 Valid. err. 1.65262
2018-02-04 00:05:29,668 training [INFO ] Epoch 42 Batch 8700 Training err. 1.28255 Training err. RA 1.69965 Valid. err. 1.65105
2018-02-04 00:05:30,159 training [INFO ] Epoch 42 Batch 8720 Training err. 1.27593 Training err. RA 1.69868 Valid. err. 1.63381
2018-02-04 00:05:31,035 training [INFO ] Epoch 43 Batch 8740 Training err. 1.26954 Training err. RA 1.69770 Valid. err. 1.63641
2018-02-04 00:05:31,515 training [INFO ] Epoch 43 Batch 8760 Training err. 1.26601 Training err. RA 1.69671 Valid. err. 1.65456
2018-02-04 00:05:32,002 training [INFO ] Epoch 43 Batch 8780 Training err. 1.27207 Training err. RA 1.69575 Valid. err. 1.66172
2018-02-04 00:05:32,485 training [INFO ] Epoch 43 Batch 8800 Training err. 1.31638 Training err. RA 1.69488 Valid. err. 1.63323
2018-02-04 00:05:32,968 training [INFO ] Epoch 43 Batch 8820 Training err. 1.30581 Training err. RA 1.69400 Valid. err. 1.64669
2018-02-04 00:05:33,479 training [INFO ] Epoch 43 Batch 8840 Training err. 1.26483 Training err. RA 1.69303 Valid. err. 1.62100
2018-02-04 00:05:33,966 training [INFO ] Epoch 43 Batch 8860 Training err. 1.34146 Training err. RA 1.69224 Valid. err. 1.64814
2018-02-04 00:05:34,448 training [INFO ] Epoch 43 Batch 8880 Training err. 1.26118 Training err. RA 1.69127 Valid. err. 1.64938
2018-02-04 00:05:34,945 training [INFO ] Epoch 43 Batch 8900 Training err. 1.27064 Training err. RA 1.69032 Valid. err. 1.68617
2018-02-04 00:05:35,667 training [INFO ] Epoch 43 Batch 8920 Training err. 1.25171 Training err. RA 1.68934 Valid. err. 1.63856
2018-02-04 00:05:36,151 training [INFO ] Epoch 43 Batch 8940 Training err. 1.29945 Training err. RA 1.68847 Valid. err. 1.62942
2018-02-04 00:05:37,031 training [INFO ] Epoch 44 Batch 8960 Training err. 1.24894 Training err. RA 1.68748 Valid. err. 1.64938
2018-02-04 00:05:37,540 training [INFO ] Epoch 44 Batch 8980 Training err. 1.23945 Training err. RA 1.68649 Valid. err. 1.64767
2018-02-04 00:05:38,025 training [INFO ] Epoch 44 Batch 9000 Training err. 1.30364 Training err. RA 1.68564 Valid. err. 1.66486
2018-02-04 00:05:38,509 training [INFO ] Epoch 44 Batch 9020 Training err. 1.31297 Training err. RA 1.68481 Valid. err. 1.65199
2018-02-04 00:05:38,995 training [INFO ] Epoch 44 Batch 9040 Training err. 1.25636 Training err. RA 1.68386 Valid. err. 1.66323
2018-02-04 00:05:39,478 training [INFO ] Epoch 44 Batch 9060 Training err. 1.32244 Training err. RA 1.68306 Valid. err. 1.62389
2018-02-04 00:05:39,962 training [INFO ] Epoch 44 Batch 9080 Training err. 1.29557 Training err. RA 1.68221 Valid. err. 1.66222
2018-02-04 00:05:40,445 training [INFO ] Epoch 44 Batch 9100 Training err. 1.25661 Training err. RA 1.68127 Valid. err. 1.67987
2018-02-04 00:05:40,928 training [INFO ] Epoch 44 Batch 9120 Training err. 1.26246 Training err. RA 1.68036 Valid. err. 1.62328
2018-02-04 00:05:41,413 training [INFO ] Epoch 44 Batch 9140 Training err. 1.26819 Training err. RA 1.67945 Valid. err. 1.65510
2018-02-04 00:05:42,267 training [INFO ] Epoch 45 Batch 9160 Training err. 1.24615 Training err. RA 1.67851 Valid. err. 1.63293
2018-02-04 00:05:42,751 training [INFO ] Epoch 45 Batch 9180 Training err. 1.24277 Training err. RA 1.67756 Valid. err. 1.64895
2018-02-04 00:05:43,239 training [INFO ] Epoch 45 Batch 9200 Training err. 1.28179 Training err. RA 1.67670 Valid. err. 1.64484
2018-02-04 00:05:43,718 training [INFO ] Epoch 45 Batch 9220 Training err. 1.30803 Training err. RA 1.67590 Valid. err. 1.63921
2018-02-04 00:05:44,199 training [INFO ] Epoch 45 Batch 9240 Training err. 1.25415 Training err. RA 1.67499 Valid. err. 1.66334
2018-02-04 00:05:44,687 training [INFO ] Epoch 45 Batch 9260 Training err. 1.26213 Training err. RA 1.67409 Valid. err. 1.63684
2018-02-04 00:05:45,171 training [INFO ] Epoch 45 Batch 9280 Training err. 1.31770 Training err. RA 1.67333 Valid. err. 1.64195
2018-02-04 00:05:45,656 training [INFO ] Epoch 45 Batch 9300 Training err. 1.24730 Training err. RA 1.67241 Valid. err. 1.64904
2018-02-04 00:05:46,133 training [INFO ] Epoch 45 Batch 9320 Training err. 1.24243 Training err. RA 1.67149 Valid. err. 1.64329
2018-02-04 00:05:46,613 training [INFO ] Epoch 45 Batch 9340 Training err. 1.24900 Training err. RA 1.67058 Valid. err. 1.67737
2018-02-04 00:05:47,110 training [INFO ] Epoch 45 Batch 9360 Training err. 1.25422 Training err. RA 1.66969 Valid. err. 1.68645
2018-02-04 00:05:47,965 training [INFO ] Epoch 46 Batch 9380 Training err. 1.25657 Training err. RA 1.66881 Valid. err. 1.65034
2018-02-04 00:05:48,445 training [INFO ] Epoch 46 Batch 9400 Training err. 1.22450 Training err. RA 1.66787 Valid. err. 1.68866
2018-02-04 00:05:48,925 training [INFO ] Epoch 46 Batch 9420 Training err. 1.28529 Training err. RA 1.66705 Valid. err. 1.65917
2018-02-04 00:05:49,408 training [INFO ] Epoch 46 Batch 9440 Training err. 1.29985 Training err. RA 1.66628 Valid. err. 1.64062
2018-02-04 00:05:49,891 training [INFO ] Epoch 46 Batch 9460 Training err. 1.23013 Training err. RA 1.66535 Valid. err. 1.64205
2018-02-04 00:05:50,366 training [INFO ] Epoch 46 Batch 9480 Training err. 1.30700 Training err. RA 1.66460 Valid. err. 1.65566
2018-02-04 00:05:50,848 training [INFO ] Epoch 46 Batch 9500 Training err. 1.27169 Training err. RA 1.66377 Valid. err. 1.66749
2018-02-04 00:05:51,328 training [INFO ] Epoch 46 Batch 9520 Training err. 1.23224 Training err. RA 1.66286 Valid. err. 1.66941
2018-02-04 00:05:51,805 training [INFO ] Epoch 46 Batch 9540 Training err. 1.23676 Training err. RA 1.66197 Valid. err. 1.63879
2018-02-04 00:05:52,287 training [INFO ] Epoch 46 Batch 9560 Training err. 1.27304 Training err. RA 1.66116 Valid. err. 1.63468
2018-02-04 00:05:53,168 training [INFO ] Epoch 47 Batch 9580 Training err. 1.23563 Training err. RA 1.66027 Valid. err. 1.64240
2018-02-04 00:05:53,653 training [INFO ] Epoch 47 Batch 9600 Training err. 1.22926 Training err. RA 1.65937 Valid. err. 1.67332
2018-02-04 00:05:54,135 training [INFO ] Epoch 47 Batch 9620 Training err. 1.27864 Training err. RA 1.65858 Valid. err. 1.65028
2018-02-04 00:05:54,617 training [INFO ] Epoch 47 Batch 9640 Training err. 1.29277 Training err. RA 1.65782 Valid. err. 1.65132
2018-02-04 00:05:55,098 training [INFO ] Epoch 47 Batch 9660 Training err. 1.23359 Training err. RA 1.65694 Valid. err. 1.68880
2018-02-04 00:05:55,584 training [INFO ] Epoch 47 Batch 9680 Training err. 1.26358 Training err. RA 1.65613 Valid. err. 1.63776
2018-02-04 00:05:56,071 training [INFO ] Epoch 47 Batch 9700 Training err. 1.31013 Training err. RA 1.65542 Valid. err. 1.60977
2018-02-04 00:05:56,578 training [INFO ] Epoch 47 Batch 9720 Training err. 1.22783 Training err. RA 1.65454 Valid. err. 1.65550
2018-02-04 00:05:57,253 training [INFO ] Epoch 47 Batch 9740 Training err. 1.24567 Training err. RA 1.65370 Valid. err. 1.65102
2018-02-04 00:05:57,975 training [INFO ] Epoch 47 Batch 9760 Training err. 1.24339 Training err. RA 1.65286 Valid. err. 1.64354
2018-02-04 00:05:59,165 training [INFO ] Epoch 48 Batch 9780 Training err. 1.23898 Training err. RA 1.65201 Valid. err. 1.65705
2018-02-04 00:05:59,729 training [INFO ] Epoch 48 Batch 9800 Training err. 1.23368 Training err. RA 1.65116 Valid. err. 1.66583
2018-02-04 00:06:00,300 training [INFO ] Epoch 48 Batch 9820 Training err. 1.23619 Training err. RA 1.65031 Valid. err. 1.67825
2018-02-04 00:06:00,805 training [INFO ] Epoch 48 Batch 9840 Training err. 1.27761 Training err. RA 1.64955 Valid. err. 1.65344
2018-02-04 00:06:01,315 training [INFO ] Epoch 48 Batch 9860 Training err. 1.26641 Training err. RA 1.64878 Valid. err. 1.65023
2018-02-04 00:06:01,819 training [INFO ] Epoch 48 Batch 9880 Training err. 1.23459 Training err. RA 1.64794 Valid. err. 1.62828
2018-02-04 00:06:02,326 training [INFO ] Epoch 48 Batch 9900 Training err. 1.30381 Training err. RA 1.64724 Valid. err. 1.65188
2018-02-04 00:06:02,823 training [INFO ] Epoch 48 Batch 9920 Training err. 1.21978 Training err. RA 1.64638 Valid. err. 1.66827
2018-02-04 00:06:03,323 training [INFO ] Epoch 48 Batch 9940 Training err. 1.22962 Training err. RA 1.64554 Valid. err. 1.71659
2018-02-04 00:06:03,819 training [INFO ] Epoch 48 Batch 9960 Training err. 1.21820 Training err. RA 1.64468 Valid. err. 1.65433
2018-02-04 00:06:04,311 training [INFO ] Epoch 48 Batch 9980 Training err. 1.26146 Training err. RA 1.64392 Valid. err. 1.62437
2018-02-04 00:06:05,191 training [INFO ] Epoch 49 Batch10000 Training err. 1.21378 Training err. RA 1.64306 Valid. err. 1.65295
2018-02-04 00:06:05,674 training [INFO ] Epoch 49 Batch10020 Training err. 1.21261 Training err. RA 1.64220 Valid. err. 1.66233
2018-02-04 00:06:06,161 training [INFO ] Epoch 49 Batch10040 Training err. 1.26785 Training err. RA 1.64145 Valid. err. 1.68534
2018-02-04 00:06:06,643 training [INFO ] Epoch 49 Batch10060 Training err. 1.27706 Training err. RA 1.64073 Valid. err. 1.65684
2018-02-04 00:06:07,127 training [INFO ] Epoch 49 Batch10080 Training err. 1.21044 Training err. RA 1.63987 Valid. err. 1.67223
2018-02-04 00:06:07,613 training [INFO ] Epoch 49 Batch10100 Training err. 1.29221 Training err. RA 1.63918 Valid. err. 1.62858
2018-02-04 00:06:08,095 training [INFO ] Epoch 49 Batch10120 Training err. 1.26241 Training err. RA 1.63844 Valid. err. 1.66293
2018-02-04 00:06:08,577 training [INFO ] Epoch 49 Batch10140 Training err. 1.21264 Training err. RA 1.63760 Valid. err. 1.70398
2018-02-04 00:06:09,061 training [INFO ] Epoch 49 Batch10160 Training err. 1.23559 Training err. RA 1.63681 Valid. err. 1.63374
2018-02-04 00:06:09,540 training [INFO ] Epoch 49 Batch10180 Training err. 1.23711 Training err. RA 1.63602 Valid. err. 1.64462
2018-02-04 00:06:10,399 training [INFO ] Epoch 50 Batch10200 Training err. 1.21505 Training err. RA 1.63520 Valid. err. 1.63351
2018-02-04 00:06:10,883 training [INFO ] Epoch 50 Batch10220 Training err. 1.20798 Training err. RA 1.63436 Valid. err. 1.67205
2018-02-04 00:06:11,368 training [INFO ] Epoch 50 Batch10240 Training err. 1.25180 Training err. RA 1.63361 Valid. err. 1.64959
2018-02-04 00:06:11,872 training [INFO ] Epoch 50 Batch10260 Training err. 1.27250 Training err. RA 1.63291 Valid. err. 1.65492
2018-02-04 00:06:12,372 training [INFO ] Epoch 50 Batch10280 Training err. 1.21816 Training err. RA 1.63210 Valid. err. 1.67357
2018-02-04 00:06:12,859 training [INFO ] Epoch 50 Batch10300 Training err. 1.22705 Training err. RA 1.63132 Valid. err. 1.65479
2018-02-04 00:06:13,349 training [INFO ] Epoch 50 Batch10320 Training err. 1.27891 Training err. RA 1.63063 Valid. err. 1.66510
2018-02-04 00:06:13,839 training [INFO ] Epoch 50 Batch10340 Training err. 1.22174 Training err. RA 1.62984 Valid. err. 1.65660
2018-02-04 00:06:14,352 training [INFO ] Epoch 50 Batch10360 Training err. 1.20868 Training err. RA 1.62903 Valid. err. 1.65252
2018-02-04 00:06:14,838 training [INFO ] Epoch 50 Batch10380 Training err. 1.21750 Training err. RA 1.62824 Valid. err. 1.68558
2018-02-04 00:06:15,339 training [INFO ] Epoch 50 Batch10400 Training err. 1.22813 Training err. RA 1.62747 Valid. err. 1.67155
2018-02-04 00:06:16,212 training [INFO ] Epoch 51 Batch10420 Training err. 1.22469 Training err. RA 1.62670 Valid. err. 1.65170
2018-02-04 00:06:16,689 training [INFO ] Epoch 51 Batch10440 Training err. 1.19352 Training err. RA 1.62587 Valid. err. 1.66396
2018-02-04 00:06:17,168 training [INFO ] Epoch 51 Batch10460 Training err. 1.25479 Training err. RA 1.62516 Valid. err. 1.67575
2018-02-04 00:06:17,645 training [INFO ] Epoch 51 Batch10480 Training err. 1.26560 Training err. RA 1.62447 Valid. err. 1.65012
2018-02-04 00:06:18,128 training [INFO ] Epoch 51 Batch10500 Training err. 1.20207 Training err. RA 1.62367 Valid. err. 1.65563
2018-02-04 00:06:18,616 training [INFO ] Epoch 51 Batch10520 Training err. 1.26976 Training err. RA 1.62299 Valid. err. 1.64610
2018-02-04 00:06:19,095 training [INFO ] Epoch 51 Batch10540 Training err. 1.24771 Training err. RA 1.62228 Valid. err. 1.66272
2018-02-04 00:06:19,580 training [INFO ] Epoch 51 Batch10560 Training err. 1.19366 Training err. RA 1.62147 Valid. err. 1.68755
2018-02-04 00:06:20,070 training [INFO ] Epoch 51 Batch10580 Training err. 1.19959 Training err. RA 1.62067 Valid. err. 1.64798
2018-02-04 00:06:20,551 training [INFO ] Epoch 51 Batch10600 Training err. 1.23721 Training err. RA 1.61995 Valid. err. 1.64175
2018-02-04 00:06:21,435 training [INFO ] Epoch 52 Batch10620 Training err. 1.19970 Training err. RA 1.61916 Valid. err. 1.64345
2018-02-04 00:06:21,920 training [INFO ] Epoch 52 Batch10640 Training err. 1.18819 Training err. RA 1.61835 Valid. err. 1.68445
2018-02-04 00:06:22,402 training [INFO ] Epoch 52 Batch10660 Training err. 1.23967 Training err. RA 1.61764 Valid. err. 1.67435
2018-02-04 00:06:22,886 training [INFO ] Epoch 52 Batch10680 Training err. 1.26138 Training err. RA 1.61697 Valid. err. 1.63898
2018-02-04 00:06:23,382 training [INFO ] Epoch 52 Batch10700 Training err. 1.20044 Training err. RA 1.61619 Valid. err. 1.68080
2018-02-04 00:06:23,880 training [INFO ] Epoch 52 Batch10720 Training err. 1.22884 Training err. RA 1.61547 Valid. err. 1.63799
2018-02-04 00:06:24,370 training [INFO ] Epoch 52 Batch10740 Training err. 1.27340 Training err. RA 1.61483 Valid. err. 1.62283
2018-02-04 00:06:24,859 training [INFO ] Epoch 52 Batch10760 Training err. 1.18929 Training err. RA 1.61404 Valid. err. 1.65866
2018-02-04 00:06:25,353 training [INFO ] Epoch 52 Batch10780 Training err. 1.21420 Training err. RA 1.61330 Valid. err. 1.65032
2018-02-04 00:06:25,853 training [INFO ] Epoch 52 Batch10800 Training err. 1.21243 Training err. RA 1.61255 Valid. err. 1.62540
2018-02-04 00:06:26,733 training [INFO ] Epoch 53 Batch10820 Training err. 1.21052 Training err. RA 1.61181 Valid. err. 1.63665
2018-02-04 00:06:27,216 training [INFO ] Epoch 53 Batch10840 Training err. 1.20322 Training err. RA 1.61106 Valid. err. 1.65793
2018-02-04 00:06:27,707 training [INFO ] Epoch 53 Batch10860 Training err. 1.20394 Training err. RA 1.61031 Valid. err. 1.67852
2018-02-04 00:06:28,192 training [INFO ] Epoch 53 Batch10880 Training err. 1.24453 Training err. RA 1.60964 Valid. err. 1.67388
2018-02-04 00:06:28,687 training [INFO ] Epoch 53 Batch10900 Training err. 1.23513 Training err. RA 1.60895 Valid. err. 1.67022
2018-02-04 00:06:29,182 training [INFO ] Epoch 53 Batch10920 Training err. 1.20426 Training err. RA 1.60821 Valid. err. 1.63132
2018-02-04 00:06:29,662 training [INFO ] Epoch 53 Batch10940 Training err. 1.26979 Training err. RA 1.60759 Valid. err. 1.65028
2018-02-04 00:06:30,151 training [INFO ] Epoch 53 Batch10960 Training err. 1.19913 Training err. RA 1.60684 Valid. err. 1.67032
2018-02-04 00:06:30,645 training [INFO ] Epoch 53 Batch10980 Training err. 1.19351 Training err. RA 1.60609 Valid. err. 1.72271
2018-02-04 00:06:31,133 training [INFO ] Epoch 53 Batch11000 Training err. 1.18723 Training err. RA 1.60533 Valid. err. 1.65883
2018-02-04 00:06:31,640 training [INFO ] Epoch 53 Batch11020 Training err. 1.23359 Training err. RA 1.60465 Valid. err. 1.63938
2018-02-04 00:06:32,516 training [INFO ] Epoch 54 Batch11040 Training err. 1.18076 Training err. RA 1.60389 Valid. err. 1.66374
2018-02-04 00:06:32,993 training [INFO ] Epoch 54 Batch11060 Training err. 1.18030 Training err. RA 1.60312 Valid. err. 1.68738
2018-02-04 00:06:33,473 training [INFO ] Epoch 54 Batch11080 Training err. 1.22668 Training err. RA 1.60244 Valid. err. 1.68230
2018-02-04 00:06:33,958 training [INFO ] Epoch 54 Batch11100 Training err. 1.25149 Training err. RA 1.60181 Valid. err. 1.69258
2018-02-04 00:06:34,440 training [INFO ] Epoch 54 Batch11120 Training err. 1.18214 Training err. RA 1.60105 Valid. err. 1.70256
2018-02-04 00:06:34,919 training [INFO ] Epoch 54 Batch11140 Training err. 1.26059 Training err. RA 1.60044 Valid. err. 1.65039
2018-02-04 00:06:35,415 training [INFO ] Epoch 54 Batch11160 Training err. 1.22536 Training err. RA 1.59977 Valid. err. 1.65146
2018-02-04 00:06:35,916 training [INFO ] Epoch 54 Batch11180 Training err. 1.18166 Training err. RA 1.59902 Valid. err. 1.70526
2018-02-04 00:06:36,408 training [INFO ] Epoch 54 Batch11200 Training err. 1.21343 Training err. RA 1.59833 Valid. err. 1.65350
2018-02-04 00:06:36,892 training [INFO ] Epoch 54 Batch11220 Training err. 1.20780 Training err. RA 1.59764 Valid. err. 1.66234
2018-02-04 00:06:37,773 training [INFO ] Epoch 55 Batch11240 Training err. 1.18261 Training err. RA 1.59690 Valid. err. 1.65953
2018-02-04 00:06:38,267 training [INFO ] Epoch 55 Batch11260 Training err. 1.18131 Training err. RA 1.59616 Valid. err. 1.69458
2018-02-04 00:06:38,756 training [INFO ] Epoch 55 Batch11280 Training err. 1.21181 Training err. RA 1.59548 Valid. err. 1.65914
2018-02-04 00:06:39,254 training [INFO ] Epoch 55 Batch11300 Training err. 1.24530 Training err. RA 1.59486 Valid. err. 1.65908
2018-02-04 00:06:39,745 training [INFO ] Epoch 55 Batch11320 Training err. 1.18750 Training err. RA 1.59414 Valid. err. 1.69428
2018-02-04 00:06:40,233 training [INFO ] Epoch 55 Batch11340 Training err. 1.20232 Training err. RA 1.59345 Valid. err. 1.65571
2018-02-04 00:06:40,727 training [INFO ] Epoch 55 Batch11360 Training err. 1.25299 Training err. RA 1.59285 Valid. err. 1.67498
2018-02-04 00:06:41,232 training [INFO ] Epoch 55 Batch11380 Training err. 1.18768 Training err. RA 1.59214 Valid. err. 1.66153
2018-02-04 00:06:41,725 training [INFO ] Epoch 55 Batch11400 Training err. 1.18248 Training err. RA 1.59142 Valid. err. 1.65540
2018-02-04 00:06:42,207 training [INFO ] Epoch 55 Batch11420 Training err. 1.18506 Training err. RA 1.59071 Valid. err. 1.68907
2018-02-04 00:06:42,702 training [INFO ] Epoch 55 Batch11440 Training err. 1.20067 Training err. RA 1.59003 Valid. err. 1.69153
2018-02-04 00:06:43,582 training [INFO ] Epoch 56 Batch11460 Training err. 1.20406 Training err. RA 1.58935 Valid. err. 1.66789
2018-02-04 00:06:44,053 training [INFO ] Epoch 56 Batch11480 Training err. 1.16445 Training err. RA 1.58861 Valid. err. 1.70069
2018-02-04 00:06:44,532 training [INFO ] Epoch 56 Batch11500 Training err. 1.22405 Training err. RA 1.58798 Valid. err. 1.70655
2018-02-04 00:06:45,013 training [INFO ] Epoch 56 Batch11520 Training err. 1.23884 Training err. RA 1.58737 Valid. err. 1.68903
2018-02-04 00:06:45,494 training [INFO ] Epoch 56 Batch11540 Training err. 1.16682 Training err. RA 1.58664 Valid. err. 1.67622
2018-02-04 00:06:45,974 training [INFO ] Epoch 56 Batch11560 Training err. 1.24393 Training err. RA 1.58605 Valid. err. 1.66276
2018-02-04 00:06:46,454 training [INFO ] Epoch 56 Batch11580 Training err. 1.20322 Training err. RA 1.58539 Valid. err. 1.69110
2018-02-04 00:06:46,933 training [INFO ] Epoch 56 Batch11600 Training err. 1.16713 Training err. RA 1.58467 Valid. err. 1.68939
2018-02-04 00:06:47,418 training [INFO ] Epoch 56 Batch11620 Training err. 1.17382 Training err. RA 1.58396 Valid. err. 1.65238
2018-02-04 00:06:47,898 training [INFO ] Epoch 56 Batch11640 Training err. 1.20794 Training err. RA 1.58331 Valid. err. 1.69056
2018-02-04 00:06:48,814 training [INFO ] Epoch 57 Batch11660 Training err. 1.17777 Training err. RA 1.58262 Valid. err. 1.66148
2018-02-04 00:06:49,288 training [INFO ] Epoch 57 Batch11680 Training err. 1.16928 Training err. RA 1.58191 Valid. err. 1.70221
2018-02-04 00:06:49,762 training [INFO ] Epoch 57 Batch11700 Training err. 1.20942 Training err. RA 1.58127 Valid. err. 1.67720
2018-02-04 00:06:50,240 training [INFO ] Epoch 57 Batch11720 Training err. 1.23310 Training err. RA 1.58068 Valid. err. 1.66623
2018-02-04 00:06:50,717 training [INFO ] Epoch 57 Batch11740 Training err. 1.16876 Training err. RA 1.57998 Valid. err. 1.71683
2018-02-04 00:06:51,193 training [INFO ] Epoch 57 Batch11760 Training err. 1.20682 Training err. RA 1.57934 Valid. err. 1.64936
2018-02-04 00:06:51,669 training [INFO ] Epoch 57 Batch11780 Training err. 1.24588 Training err. RA 1.57878 Valid. err. 1.63984
2018-02-04 00:06:52,142 training [INFO ] Epoch 57 Batch11800 Training err. 1.16782 Training err. RA 1.57808 Valid. err. 1.67540
2018-02-04 00:06:52,619 training [INFO ] Epoch 57 Batch11820 Training err. 1.18703 Training err. RA 1.57742 Valid. err. 1.68200
2018-02-04 00:06:53,099 training [INFO ] Epoch 57 Batch11840 Training err. 1.18407 Training err. RA 1.57675 Valid. err. 1.66623
2018-02-04 00:06:53,953 training [INFO ] Epoch 58 Batch11860 Training err. 1.18042 Training err. RA 1.57609 Valid. err. 1.65546
2018-02-04 00:06:54,430 training [INFO ] Epoch 58 Batch11880 Training err. 1.18513 Training err. RA 1.57543 Valid. err. 1.65830
2018-02-04 00:06:54,914 training [INFO ] Epoch 58 Batch11900 Training err. 1.16953 Training err. RA 1.57475 Valid. err. 1.67707
2018-02-04 00:06:55,392 training [INFO ] Epoch 58 Batch11920 Training err. 1.21516 Training err. RA 1.57414 Valid. err. 1.69144
2018-02-04 00:06:55,876 training [INFO ] Epoch 58 Batch11940 Training err. 1.20415 Training err. RA 1.57352 Valid. err. 1.68033
2018-02-04 00:06:56,369 training [INFO ] Epoch 58 Batch11960 Training err. 1.17508 Training err. RA 1.57286 Valid. err. 1.65252
2018-02-04 00:06:56,920 training [INFO ] Epoch 58 Batch11980 Training err. 1.24645 Training err. RA 1.57231 Valid. err. 1.65937
2018-02-04 00:06:57,487 training [INFO ] Epoch 58 Batch12000 Training err. 1.16894 Training err. RA 1.57164 Valid. err. 1.69324
2018-02-04 00:06:58,065 training [INFO ] Epoch 58 Batch12020 Training err. 1.16896 Training err. RA 1.57097 Valid. err. 1.71295
2018-02-04 00:06:58,672 training [INFO ] Epoch 58 Batch12040 Training err. 1.16284 Training err. RA 1.57029 Valid. err. 1.67617
2018-02-04 00:06:59,287 training [INFO ] Epoch 58 Batch12060 Training err. 1.20459 Training err. RA 1.56968 Valid. err. 1.64288
2018-02-04 00:07:00,393 training [INFO ] Epoch 59 Batch12080 Training err. 1.14915 Training err. RA 1.56899 Valid. err. 1.66787
2018-02-04 00:07:00,915 training [INFO ] Epoch 59 Batch12100 Training err. 1.15874 Training err. RA 1.56831 Valid. err. 1.69206
2018-02-04 00:07:01,425 training [INFO ] Epoch 59 Batch12120 Training err. 1.21483 Training err. RA 1.56773 Valid. err. 1.69371
2018-02-04 00:07:01,931 training [INFO ] Epoch 59 Batch12140 Training err. 1.21813 Training err. RA 1.56715 Valid. err. 1.68316
2018-02-04 00:07:02,435 training [INFO ] Epoch 59 Batch12160 Training err. 1.15903 Training err. RA 1.56648 Valid. err. 1.69091
2018-02-04 00:07:02,937 training [INFO ] Epoch 59 Batch12180 Training err. 1.22658 Training err. RA 1.56592 Valid. err. 1.66109
2018-02-04 00:07:03,438 training [INFO ] Epoch 59 Batch12200 Training err. 1.20688 Training err. RA 1.56533 Valid. err. 1.66099
2018-02-04 00:07:03,938 training [INFO ] Epoch 59 Batch12220 Training err. 1.14606 Training err. RA 1.56465 Valid. err. 1.71605
2018-02-04 00:07:04,437 training [INFO ] Epoch 59 Batch12240 Training err. 1.16961 Training err. RA 1.56400 Valid. err. 1.64163
2018-02-04 00:07:04,939 training [INFO ] Epoch 59 Batch12260 Training err. 1.18470 Training err. RA 1.56338 Valid. err. 1.65386
2018-02-04 00:07:05,865 training [INFO ] Epoch 60 Batch12280 Training err. 1.16204 Training err. RA 1.56273 Valid. err. 1.67748
2018-02-04 00:07:06,366 training [INFO ] Epoch 60 Batch12300 Training err. 1.15480 Training err. RA 1.56207 Valid. err. 1.69019
2018-02-04 00:07:06,869 training [INFO ] Epoch 60 Batch12320 Training err. 1.19683 Training err. RA 1.56147 Valid. err. 1.66058
2018-02-04 00:07:07,367 training [INFO ] Epoch 60 Batch12340 Training err. 1.22056 Training err. RA 1.56092 Valid. err. 1.66538
2018-02-04 00:07:07,842 training [INFO ] Epoch 60 Batch12360 Training err. 1.16565 Training err. RA 1.56028 Valid. err. 1.70783
2018-02-04 00:07:08,322 training [INFO ] Epoch 60 Batch12380 Training err. 1.16939 Training err. RA 1.55965 Valid. err. 1.66948
2018-02-04 00:07:08,802 training [INFO ] Epoch 60 Batch12400 Training err. 1.22084 Training err. RA 1.55910 Valid. err. 1.68207
2018-02-04 00:07:09,281 training [INFO ] Epoch 60 Batch12420 Training err. 1.15546 Training err. RA 1.55845 Valid. err. 1.66116
2018-02-04 00:07:09,761 training [INFO ] Epoch 60 Batch12440 Training err. 1.14567 Training err. RA 1.55779 Valid. err. 1.69546
2018-02-04 00:07:10,243 training [INFO ] Epoch 60 Batch12460 Training err. 1.16271 Training err. RA 1.55715 Valid. err. 1.70359
2018-02-04 00:07:10,724 training [INFO ] Epoch 60 Batch12480 Training err. 1.16604 Training err. RA 1.55653 Valid. err. 1.69451
2018-02-04 00:07:10,987 __main__ [INFO ] End of training
2018-02-04 00:07:12,303 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 10,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-04 00:07:13,038 training [INFO ] Epoch  1 Batch   20 Training err. 3.44670 Training err. RA 3.44670 Valid. err. 3.17347
2018-02-04 00:07:13,509 training [INFO ] Epoch  1 Batch   40 Training err. 4.33270 Training err. RA 3.88970 Valid. err. 3.20542
2018-02-04 00:07:13,984 training [INFO ] Epoch  1 Batch   60 Training err. 3.13873 Training err. RA 3.63938 Valid. err. 3.21887
2018-02-04 00:07:14,461 training [INFO ] Epoch  1 Batch   80 Training err. 3.05080 Training err. RA 3.49223 Valid. err. 3.28901
2018-02-04 00:07:14,938 training [INFO ] Epoch  1 Batch  100 Training err. 2.97610 Training err. RA 3.38901 Valid. err. 2.89005
2018-02-04 00:07:15,414 training [INFO ] Epoch  1 Batch  120 Training err. 2.89106 Training err. RA 3.30602 Valid. err. 2.81242
2018-02-04 00:07:15,898 training [INFO ] Epoch  1 Batch  140 Training err. 2.75913 Training err. RA 3.22789 Valid. err. 2.73562
2018-02-04 00:07:16,399 training [INFO ] Epoch  1 Batch  160 Training err. 2.61063 Training err. RA 3.15073 Valid. err. 2.66680
2018-02-04 00:07:16,945 training [INFO ] Epoch  1 Batch  180 Training err. 3.63557 Training err. RA 3.20460 Valid. err. 3.02924
2018-02-04 00:07:17,638 training [INFO ] Epoch  1 Batch  200 Training err. 3.48257 Training err. RA 3.23240 Valid. err. 3.62385
2018-02-04 00:07:18,958 training [INFO ] Epoch  2 Batch  220 Training err. 3.32049 Training err. RA 3.24041 Valid. err. 3.92467
2018-02-04 00:07:19,559 training [INFO ] Epoch  2 Batch  240 Training err. 3.70376 Training err. RA 3.27902 Valid. err. 3.44652
2018-02-04 00:07:20,227 training [INFO ] Epoch  2 Batch  260 Training err. 3.11603 Training err. RA 3.26648 Valid. err. 3.26420
2018-02-04 00:07:21,253 training [INFO ] Epoch  2 Batch  280 Training err. 3.10905 Training err. RA 3.25524 Valid. err. 3.78639
2018-02-04 00:07:22,031 training [INFO ] Epoch  2 Batch  300 Training err. 3.12771 Training err. RA 3.24673 Valid. err. 2.69398
2018-02-04 00:07:22,686 training [INFO ] Epoch  2 Batch  320 Training err. 2.71169 Training err. RA 3.21329 Valid. err. 2.59750
2018-02-04 00:07:23,553 training [INFO ] Epoch  2 Batch  340 Training err. 2.56865 Training err. RA 3.17537 Valid. err. 2.56814
2018-02-04 00:07:24,134 training [INFO ] Epoch  2 Batch  360 Training err. 2.49974 Training err. RA 3.13784 Valid. err. 2.51188
2018-02-04 00:07:24,669 training [INFO ] Epoch  2 Batch  380 Training err. 2.61757 Training err. RA 3.11046 Valid. err. 2.61028
2018-02-04 00:07:25,145 training [INFO ] Epoch  2 Batch  400 Training err. 2.52014 Training err. RA 3.08094 Valid. err. 2.54124
2018-02-04 00:07:25,987 training [INFO ] Epoch  3 Batch  420 Training err. 2.46304 Training err. RA 3.05152 Valid. err. 2.61110
2018-02-04 00:07:26,464 training [INFO ] Epoch  3 Batch  440 Training err. 2.40371 Training err. RA 3.02207 Valid. err. 2.40243
2018-02-04 00:07:26,941 training [INFO ] Epoch  3 Batch  460 Training err. 2.39459 Training err. RA 2.99479 Valid. err. 2.48126
2018-02-04 00:07:27,418 training [INFO ] Epoch  3 Batch  480 Training err. 2.39948 Training err. RA 2.96998 Valid. err. 2.34205
2018-02-04 00:07:27,889 training [INFO ] Epoch  3 Batch  500 Training err. 2.31019 Training err. RA 2.94359 Valid. err. 2.33781
2018-02-04 00:07:28,367 training [INFO ] Epoch  3 Batch  520 Training err. 2.31610 Training err. RA 2.91946 Valid. err. 2.31494
2018-02-04 00:07:28,849 training [INFO ] Epoch  3 Batch  540 Training err. 2.34757 Training err. RA 2.89828 Valid. err. 2.31374
2018-02-04 00:07:29,330 training [INFO ] Epoch  3 Batch  560 Training err. 2.20786 Training err. RA 2.87362 Valid. err. 2.22139
2018-02-04 00:07:29,817 training [INFO ] Epoch  3 Batch  580 Training err. 2.16346 Training err. RA 2.84913 Valid. err. 2.41424
2018-02-04 00:07:30,304 training [INFO ] Epoch  3 Batch  600 Training err. 2.24501 Training err. RA 2.82899 Valid. err. 2.19254
2018-02-04 00:07:30,785 training [INFO ] Epoch  3 Batch  620 Training err. 2.15366 Training err. RA 2.80721 Valid. err. 2.23735
2018-02-04 00:07:31,627 training [INFO ] Epoch  4 Batch  640 Training err. 2.17735 Training err. RA 2.78753 Valid. err. 2.23730
2018-02-04 00:07:32,108 training [INFO ] Epoch  4 Batch  660 Training err. 2.07179 Training err. RA 2.76584 Valid. err. 2.21661
2018-02-04 00:07:32,586 training [INFO ] Epoch  4 Batch  680 Training err. 2.12570 Training err. RA 2.74701 Valid. err. 2.12271
2018-02-04 00:07:33,071 training [INFO ] Epoch  4 Batch  700 Training err. 2.13020 Training err. RA 2.72939 Valid. err. 2.16676
2018-02-04 00:07:33,550 training [INFO ] Epoch  4 Batch  720 Training err. 2.08448 Training err. RA 2.71147 Valid. err. 2.16550
2018-02-04 00:07:34,026 training [INFO ] Epoch  4 Batch  740 Training err. 2.14776 Training err. RA 2.69624 Valid. err. 2.12243
2018-02-04 00:07:34,505 training [INFO ] Epoch  4 Batch  760 Training err. 2.07953 Training err. RA 2.68001 Valid. err. 2.09945
2018-02-04 00:07:34,980 training [INFO ] Epoch  4 Batch  780 Training err. 2.01618 Training err. RA 2.66299 Valid. err. 2.06701
2018-02-04 00:07:35,692 training [INFO ] Epoch  4 Batch  800 Training err. 2.03586 Training err. RA 2.64731 Valid. err. 2.04869
2018-02-04 00:07:36,221 training [INFO ] Epoch  4 Batch  820 Training err. 2.01508 Training err. RA 2.63189 Valid. err. 2.07215
2018-02-04 00:07:37,114 training [INFO ] Epoch  5 Batch  840 Training err. 2.01218 Training err. RA 2.61713 Valid. err. 2.02696
2018-02-04 00:07:37,603 training [INFO ] Epoch  5 Batch  860 Training err. 1.95211 Training err. RA 2.60167 Valid. err. 2.06126
2018-02-04 00:07:38,124 training [INFO ] Epoch  5 Batch  880 Training err. 1.99031 Training err. RA 2.58777 Valid. err. 2.00991
2018-02-04 00:07:38,617 training [INFO ] Epoch  5 Batch  900 Training err. 2.00721 Training err. RA 2.57487 Valid. err. 2.00957
2018-02-04 00:07:39,100 training [INFO ] Epoch  5 Batch  920 Training err. 1.97022 Training err. RA 2.56173 Valid. err. 2.00617
2018-02-04 00:07:39,619 training [INFO ] Epoch  5 Batch  940 Training err. 1.96148 Training err. RA 2.54896 Valid. err. 2.02215
2018-02-04 00:07:40,196 training [INFO ] Epoch  5 Batch  960 Training err. 2.02982 Training err. RA 2.53814 Valid. err. 1.99238
2018-02-04 00:07:40,783 training [INFO ] Epoch  5 Batch  980 Training err. 1.93722 Training err. RA 2.52588 Valid. err. 1.97323
2018-02-04 00:07:41,366 training [INFO ] Epoch  5 Batch 1000 Training err. 1.90476 Training err. RA 2.51345 Valid. err. 1.95607
2018-02-04 00:07:41,897 training [INFO ] Epoch  5 Batch 1020 Training err. 1.93309 Training err. RA 2.50207 Valid. err. 1.97187
2018-02-04 00:07:42,418 training [INFO ] Epoch  5 Batch 1040 Training err. 1.89805 Training err. RA 2.49046 Valid. err. 1.99260
2018-02-04 00:07:43,437 training [INFO ] Epoch  6 Batch 1060 Training err. 1.96691 Training err. RA 2.48058 Valid. err. 1.95965
2018-02-04 00:07:44,019 training [INFO ] Epoch  6 Batch 1080 Training err. 1.84852 Training err. RA 2.46888 Valid. err. 1.96679
2018-02-04 00:07:44,603 training [INFO ] Epoch  6 Batch 1100 Training err. 1.91694 Training err. RA 2.45884 Valid. err. 1.95109
2018-02-04 00:07:45,174 training [INFO ] Epoch  6 Batch 1120 Training err. 1.93278 Training err. RA 2.44945 Valid. err. 1.93648
2018-02-04 00:07:45,743 training [INFO ] Epoch  6 Batch 1140 Training err. 1.88730 Training err. RA 2.43958 Valid. err. 1.91686
2018-02-04 00:07:46,226 training [INFO ] Epoch  6 Batch 1160 Training err. 1.93550 Training err. RA 2.43089 Valid. err. 1.90589
2018-02-04 00:07:46,703 training [INFO ] Epoch  6 Batch 1180 Training err. 1.87932 Training err. RA 2.42154 Valid. err. 1.92578
2018-02-04 00:07:47,239 training [INFO ] Epoch  6 Batch 1200 Training err. 1.83634 Training err. RA 2.41179 Valid. err. 2.04386
2018-02-04 00:07:47,826 training [INFO ] Epoch  6 Batch 1220 Training err. 1.85725 Training err. RA 2.40270 Valid. err. 1.89172
2018-02-04 00:07:48,408 training [INFO ] Epoch  6 Batch 1240 Training err. 1.83471 Training err. RA 2.39354 Valid. err. 1.88855
2018-02-04 00:07:49,308 training [INFO ] Epoch  7 Batch 1260 Training err. 1.87865 Training err. RA 2.38537 Valid. err. 1.91299
2018-02-04 00:07:49,802 training [INFO ] Epoch  7 Batch 1280 Training err. 1.76483 Training err. RA 2.37567 Valid. err. 1.87564
2018-02-04 00:07:50,297 training [INFO ] Epoch  7 Batch 1300 Training err. 1.84459 Training err. RA 2.36750 Valid. err. 1.86306
2018-02-04 00:07:50,789 training [INFO ] Epoch  7 Batch 1320 Training err. 1.88020 Training err. RA 2.36012 Valid. err. 1.86837
2018-02-04 00:07:51,277 training [INFO ] Epoch  7 Batch 1340 Training err. 1.82026 Training err. RA 2.35206 Valid. err. 1.87689
2018-02-04 00:07:51,757 training [INFO ] Epoch  7 Batch 1360 Training err. 1.83775 Training err. RA 2.34450 Valid. err. 1.85162
2018-02-04 00:07:52,237 training [INFO ] Epoch  7 Batch 1380 Training err. 1.85686 Training err. RA 2.33743 Valid. err. 1.84208
2018-02-04 00:07:52,832 training [INFO ] Epoch  7 Batch 1400 Training err. 1.78260 Training err. RA 2.32950 Valid. err. 1.83346
2018-02-04 00:07:53,479 training [INFO ] Epoch  7 Batch 1420 Training err. 1.80800 Training err. RA 2.32216 Valid. err. 1.86498
2018-02-04 00:07:54,032 training [INFO ] Epoch  7 Batch 1440 Training err. 1.77878 Training err. RA 2.31461 Valid. err. 1.82144
2018-02-04 00:07:55,260 training [INFO ] Epoch  8 Batch 1460 Training err. 1.81118 Training err. RA 2.30771 Valid. err. 1.88613
2018-02-04 00:07:55,916 training [INFO ] Epoch  8 Batch 1480 Training err. 1.78248 Training err. RA 2.30062 Valid. err. 1.81438
2018-02-04 00:07:56,495 training [INFO ] Epoch  8 Batch 1500 Training err. 1.74714 Training err. RA 2.29324 Valid. err. 1.82190
2018-02-04 00:07:57,004 training [INFO ] Epoch  8 Batch 1520 Training err. 1.80688 Training err. RA 2.28684 Valid. err. 1.80963
2018-02-04 00:07:57,585 training [INFO ] Epoch  8 Batch 1540 Training err. 1.78750 Training err. RA 2.28035 Valid. err. 1.84922
2018-02-04 00:07:58,193 training [INFO ] Epoch  8 Batch 1560 Training err. 1.78445 Training err. RA 2.27399 Valid. err. 1.81613
2018-02-04 00:07:58,796 training [INFO ] Epoch  8 Batch 1580 Training err. 1.82167 Training err. RA 2.26827 Valid. err. 1.81342
2018-02-04 00:07:59,302 training [INFO ] Epoch  8 Batch 1600 Training err. 1.72806 Training err. RA 2.26152 Valid. err. 1.80805
2018-02-04 00:07:59,888 training [INFO ] Epoch  8 Batch 1620 Training err. 1.73453 Training err. RA 2.25501 Valid. err. 1.79064
2018-02-04 00:08:00,683 training [INFO ] Epoch  8 Batch 1640 Training err. 1.73487 Training err. RA 2.24867 Valid. err. 1.82386
2018-02-04 00:08:01,254 training [INFO ] Epoch  8 Batch 1660 Training err. 1.74508 Training err. RA 2.24260 Valid. err. 1.77720
2018-02-04 00:08:02,260 training [INFO ] Epoch  9 Batch 1680 Training err. 1.75605 Training err. RA 2.23681 Valid. err. 1.78444
2018-02-04 00:08:02,778 training [INFO ] Epoch  9 Batch 1700 Training err. 1.67763 Training err. RA 2.23023 Valid. err. 1.77360
2018-02-04 00:08:03,281 training [INFO ] Epoch  9 Batch 1720 Training err. 1.73654 Training err. RA 2.22449 Valid. err. 1.78601
2018-02-04 00:08:03,772 training [INFO ] Epoch  9 Batch 1740 Training err. 1.77146 Training err. RA 2.21928 Valid. err. 1.78130
2018-02-04 00:08:04,256 training [INFO ] Epoch  9 Batch 1760 Training err. 1.73107 Training err. RA 2.21373 Valid. err. 1.84175
2018-02-04 00:08:04,738 training [INFO ] Epoch  9 Batch 1780 Training err. 1.77123 Training err. RA 2.20876 Valid. err. 1.75331
2018-02-04 00:08:05,230 training [INFO ] Epoch  9 Batch 1800 Training err. 1.72608 Training err. RA 2.20340 Valid. err. 1.77708
2018-02-04 00:08:05,715 training [INFO ] Epoch  9 Batch 1820 Training err. 1.68879 Training err. RA 2.19774 Valid. err. 1.77968
2018-02-04 00:08:06,202 training [INFO ] Epoch  9 Batch 1840 Training err. 1.70985 Training err. RA 2.19244 Valid. err. 1.73839
2018-02-04 00:08:06,696 training [INFO ] Epoch  9 Batch 1860 Training err. 1.70004 Training err. RA 2.18715 Valid. err. 1.77605
2018-02-04 00:08:07,560 training [INFO ] Epoch 10 Batch 1880 Training err. 1.68845 Training err. RA 2.18184 Valid. err. 1.78283
2018-02-04 00:08:08,043 training [INFO ] Epoch 10 Batch 1900 Training err. 1.65649 Training err. RA 2.17631 Valid. err. 1.75593
2018-02-04 00:08:08,544 training [INFO ] Epoch 10 Batch 1920 Training err. 1.69777 Training err. RA 2.17133 Valid. err. 1.74415
2018-02-04 00:08:09,032 training [INFO ] Epoch 10 Batch 1940 Training err. 1.72851 Training err. RA 2.16676 Valid. err. 1.77186
2018-02-04 00:08:09,528 training [INFO ] Epoch 10 Batch 1960 Training err. 1.68648 Training err. RA 2.16186 Valid. err. 1.79120
2018-02-04 00:08:10,010 training [INFO ] Epoch 10 Batch 1980 Training err. 1.69570 Training err. RA 2.15715 Valid. err. 1.76327
2018-02-04 00:08:10,505 training [INFO ] Epoch 10 Batch 2000 Training err. 1.72746 Training err. RA 2.15285 Valid. err. 1.72301
2018-02-04 00:08:11,020 training [INFO ] Epoch 10 Batch 2020 Training err. 1.66186 Training err. RA 2.14799 Valid. err. 1.73278
2018-02-04 00:08:11,521 training [INFO ] Epoch 10 Batch 2040 Training err. 1.65561 Training err. RA 2.14317 Valid. err. 1.71857
2018-02-04 00:08:12,029 training [INFO ] Epoch 10 Batch 2060 Training err. 1.67258 Training err. RA 2.13860 Valid. err. 1.71400
2018-02-04 00:08:12,535 training [INFO ] Epoch 10 Batch 2080 Training err. 1.65656 Training err. RA 2.13396 Valid. err. 1.74597
2018-02-04 00:08:13,403 training [INFO ] Epoch 11 Batch 2100 Training err. 1.66163 Training err. RA 2.12946 Valid. err. 1.71949
2018-02-04 00:08:13,889 training [INFO ] Epoch 11 Batch 2120 Training err. 1.60470 Training err. RA 2.12451 Valid. err. 1.73901
2018-02-04 00:08:14,374 training [INFO ] Epoch 11 Batch 2140 Training err. 1.67923 Training err. RA 2.12035 Valid. err. 1.71655
2018-02-04 00:08:14,856 training [INFO ] Epoch 11 Batch 2160 Training err. 1.70513 Training err. RA 2.11651 Valid. err. 1.71019
2018-02-04 00:08:15,366 training [INFO ] Epoch 11 Batch 2180 Training err. 1.65565 Training err. RA 2.11228 Valid. err. 1.69737
2018-02-04 00:08:15,840 training [INFO ] Epoch 11 Batch 2200 Training err. 1.69070 Training err. RA 2.10845 Valid. err. 1.69956
2018-02-04 00:08:16,315 training [INFO ] Epoch 11 Batch 2220 Training err. 1.65407 Training err. RA 2.10435 Valid. err. 1.69903
2018-02-04 00:08:16,793 training [INFO ] Epoch 11 Batch 2240 Training err. 1.61952 Training err. RA 2.10002 Valid. err. 1.71895
2018-02-04 00:08:17,281 training [INFO ] Epoch 11 Batch 2260 Training err. 1.63384 Training err. RA 2.09590 Valid. err. 1.70739
2018-02-04 00:08:17,768 training [INFO ] Epoch 11 Batch 2280 Training err. 1.64891 Training err. RA 2.09198 Valid. err. 1.68671
2018-02-04 00:08:18,658 training [INFO ] Epoch 12 Batch 2300 Training err. 1.62503 Training err. RA 2.08792 Valid. err. 1.68002
2018-02-04 00:08:19,143 training [INFO ] Epoch 12 Batch 2320 Training err. 1.57846 Training err. RA 2.08352 Valid. err. 1.69768
2018-02-04 00:08:19,655 training [INFO ] Epoch 12 Batch 2340 Training err. 1.65072 Training err. RA 2.07983 Valid. err. 1.69003
2018-02-04 00:08:20,140 training [INFO ] Epoch 12 Batch 2360 Training err. 1.67486 Training err. RA 2.07639 Valid. err. 1.69930
2018-02-04 00:08:20,624 training [INFO ] Epoch 12 Batch 2380 Training err. 1.62934 Training err. RA 2.07264 Valid. err. 1.71423
2018-02-04 00:08:21,107 training [INFO ] Epoch 12 Batch 2400 Training err. 1.63705 Training err. RA 2.06901 Valid. err. 1.68941
2018-02-04 00:08:21,582 training [INFO ] Epoch 12 Batch 2420 Training err. 1.66621 Training err. RA 2.06568 Valid. err. 1.68124
2018-02-04 00:08:22,066 training [INFO ] Epoch 12 Batch 2440 Training err. 1.59619 Training err. RA 2.06183 Valid. err. 1.68075
2018-02-04 00:08:22,546 training [INFO ] Epoch 12 Batch 2460 Training err. 1.61537 Training err. RA 2.05820 Valid. err. 1.71075
2018-02-04 00:08:23,032 training [INFO ] Epoch 12 Batch 2480 Training err. 1.60470 Training err. RA 2.05454 Valid. err. 1.68264
2018-02-04 00:08:23,901 training [INFO ] Epoch 13 Batch 2500 Training err. 1.60279 Training err. RA 2.05093 Valid. err. 1.65516
2018-02-04 00:08:24,399 training [INFO ] Epoch 13 Batch 2520 Training err. 1.58590 Training err. RA 2.04724 Valid. err. 1.66458
2018-02-04 00:08:24,892 training [INFO ] Epoch 13 Batch 2540 Training err. 1.58578 Training err. RA 2.04360 Valid. err. 1.66338
2018-02-04 00:08:25,402 training [INFO ] Epoch 13 Batch 2560 Training err. 1.63445 Training err. RA 2.04041 Valid. err. 1.68590
2018-02-04 00:08:25,880 training [INFO ] Epoch 13 Batch 2580 Training err. 1.62652 Training err. RA 2.03720 Valid. err. 1.69873
2018-02-04 00:08:26,366 training [INFO ] Epoch 13 Batch 2600 Training err. 1.61560 Training err. RA 2.03396 Valid. err. 1.67651
2018-02-04 00:08:26,847 training [INFO ] Epoch 13 Batch 2620 Training err. 1.65827 Training err. RA 2.03109 Valid. err. 1.68799
2018-02-04 00:08:27,328 training [INFO ] Epoch 13 Batch 2640 Training err. 1.57694 Training err. RA 2.02765 Valid. err. 1.67381
2018-02-04 00:08:27,808 training [INFO ] Epoch 13 Batch 2660 Training err. 1.57817 Training err. RA 2.02427 Valid. err. 1.65841
2018-02-04 00:08:28,289 training [INFO ] Epoch 13 Batch 2680 Training err. 1.56726 Training err. RA 2.02086 Valid. err. 1.67397
2018-02-04 00:08:28,764 training [INFO ] Epoch 13 Batch 2700 Training err. 1.60327 Training err. RA 2.01776 Valid. err. 1.64677
2018-02-04 00:08:29,597 training [INFO ] Epoch 14 Batch 2720 Training err. 1.57205 Training err. RA 2.01449 Valid. err. 1.66090
2018-02-04 00:08:30,082 training [INFO ] Epoch 14 Batch 2740 Training err. 1.53457 Training err. RA 2.01098 Valid. err. 1.65815
2018-02-04 00:08:30,562 training [INFO ] Epoch 14 Batch 2760 Training err. 1.60157 Training err. RA 2.00802 Valid. err. 1.66783
2018-02-04 00:08:31,041 training [INFO ] Epoch 14 Batch 2780 Training err. 1.62767 Training err. RA 2.00528 Valid. err. 1.66224
2018-02-04 00:08:31,517 training [INFO ] Epoch 14 Batch 2800 Training err. 1.58488 Training err. RA 2.00228 Valid. err. 1.68701
2018-02-04 00:08:31,991 training [INFO ] Epoch 14 Batch 2820 Training err. 1.62443 Training err. RA 1.99960 Valid. err. 1.65898
2018-02-04 00:08:32,472 training [INFO ] Epoch 14 Batch 2840 Training err. 1.59484 Training err. RA 1.99675 Valid. err. 1.66445
2018-02-04 00:08:32,952 training [INFO ] Epoch 14 Batch 2860 Training err. 1.54683 Training err. RA 1.99360 Valid. err. 1.66093
2018-02-04 00:08:33,436 training [INFO ] Epoch 14 Batch 2880 Training err. 1.56670 Training err. RA 1.99064 Valid. err. 1.64937
2018-02-04 00:08:33,925 training [INFO ] Epoch 14 Batch 2900 Training err. 1.56992 Training err. RA 1.98774 Valid. err. 1.65378
2018-02-04 00:08:34,825 training [INFO ] Epoch 15 Batch 2920 Training err. 1.54968 Training err. RA 1.98474 Valid. err. 1.63255
2018-02-04 00:08:35,308 training [INFO ] Epoch 15 Batch 2940 Training err. 1.52983 Training err. RA 1.98164 Valid. err. 1.65343
2018-02-04 00:08:35,800 training [INFO ] Epoch 15 Batch 2960 Training err. 1.57192 Training err. RA 1.97887 Valid. err. 1.64506
2018-02-04 00:08:36,291 training [INFO ] Epoch 15 Batch 2980 Training err. 1.60835 Training err. RA 1.97639 Valid. err. 1.65052
2018-02-04 00:08:36,852 training [INFO ] Epoch 15 Batch 3000 Training err. 1.56261 Training err. RA 1.97363 Valid. err. 1.66954
2018-02-04 00:08:37,423 training [INFO ] Epoch 15 Batch 3020 Training err. 1.56655 Training err. RA 1.97093 Valid. err. 1.66570
2018-02-04 00:08:38,005 training [INFO ] Epoch 15 Batch 3040 Training err. 1.60941 Training err. RA 1.96855 Valid. err. 1.63114
2018-02-04 00:08:38,625 training [INFO ] Epoch 15 Batch 3060 Training err. 1.54089 Training err. RA 1.96576 Valid. err. 1.64521
2018-02-04 00:08:39,187 training [INFO ] Epoch 15 Batch 3080 Training err. 1.53433 Training err. RA 1.96296 Valid. err. 1.63295
2018-02-04 00:08:39,878 training [INFO ] Epoch 15 Batch 3100 Training err. 1.53755 Training err. RA 1.96021 Valid. err. 1.62554
2018-02-04 00:08:40,439 training [INFO ] Epoch 15 Batch 3120 Training err. 1.54777 Training err. RA 1.95757 Valid. err. 1.64512
2018-02-04 00:08:41,342 training [INFO ] Epoch 16 Batch 3140 Training err. 1.54199 Training err. RA 1.95492 Valid. err. 1.61292
2018-02-04 00:08:41,831 training [INFO ] Epoch 16 Batch 3160 Training err. 1.49298 Training err. RA 1.95200 Valid. err. 1.67084
2018-02-04 00:08:42,324 training [INFO ] Epoch 16 Batch 3180 Training err. 1.57370 Training err. RA 1.94962 Valid. err. 1.65177
2018-02-04 00:08:42,815 training [INFO ] Epoch 16 Batch 3200 Training err. 1.59577 Training err. RA 1.94741 Valid. err. 1.63694
2018-02-04 00:08:43,306 training [INFO ] Epoch 16 Batch 3220 Training err. 1.53116 Training err. RA 1.94482 Valid. err. 1.63888
2018-02-04 00:08:43,796 training [INFO ] Epoch 16 Batch 3240 Training err. 1.58929 Training err. RA 1.94263 Valid. err. 1.62942
2018-02-04 00:08:44,285 training [INFO ] Epoch 16 Batch 3260 Training err. 1.55224 Training err. RA 1.94023 Valid. err. 1.63149
2018-02-04 00:08:44,764 training [INFO ] Epoch 16 Batch 3280 Training err. 1.50933 Training err. RA 1.93760 Valid. err. 1.64181
2018-02-04 00:08:45,240 training [INFO ] Epoch 16 Batch 3300 Training err. 1.52174 Training err. RA 1.93508 Valid. err. 1.62164
2018-02-04 00:08:45,718 training [INFO ] Epoch 16 Batch 3320 Training err. 1.53933 Training err. RA 1.93270 Valid. err. 1.60913
2018-02-04 00:08:46,578 training [INFO ] Epoch 17 Batch 3340 Training err. 1.52388 Training err. RA 1.93025 Valid. err. 1.60775
2018-02-04 00:08:47,056 training [INFO ] Epoch 17 Batch 3360 Training err. 1.48339 Training err. RA 1.92759 Valid. err. 1.63415
2018-02-04 00:08:47,536 training [INFO ] Epoch 17 Batch 3380 Training err. 1.55375 Training err. RA 1.92538 Valid. err. 1.62972
2018-02-04 00:08:48,021 training [INFO ] Epoch 17 Batch 3400 Training err. 1.57666 Training err. RA 1.92333 Valid. err. 1.64795
2018-02-04 00:08:48,496 training [INFO ] Epoch 17 Batch 3420 Training err. 1.52178 Training err. RA 1.92098 Valid. err. 1.64457
2018-02-04 00:08:48,970 training [INFO ] Epoch 17 Batch 3440 Training err. 1.53652 Training err. RA 1.91874 Valid. err. 1.61939
2018-02-04 00:08:49,445 training [INFO ] Epoch 17 Batch 3460 Training err. 1.57259 Training err. RA 1.91674 Valid. err. 1.62574
2018-02-04 00:08:49,917 training [INFO ] Epoch 17 Batch 3480 Training err. 1.49551 Training err. RA 1.91432 Valid. err. 1.63249
2018-02-04 00:08:50,399 training [INFO ] Epoch 17 Batch 3500 Training err. 1.51922 Training err. RA 1.91207 Valid. err. 1.63042
2018-02-04 00:08:50,905 training [INFO ] Epoch 17 Batch 3520 Training err. 1.49993 Training err. RA 1.90972 Valid. err. 1.61601
2018-02-04 00:08:51,743 training [INFO ] Epoch 18 Batch 3540 Training err. 1.50887 Training err. RA 1.90746 Valid. err. 1.60839
2018-02-04 00:08:52,225 training [INFO ] Epoch 18 Batch 3560 Training err. 1.49436 Training err. RA 1.90514 Valid. err. 1.61340
2018-02-04 00:08:52,708 training [INFO ] Epoch 18 Batch 3580 Training err. 1.49728 Training err. RA 1.90286 Valid. err. 1.60498
2018-02-04 00:08:53,188 training [INFO ] Epoch 18 Batch 3600 Training err. 1.54862 Training err. RA 1.90089 Valid. err. 1.62695
2018-02-04 00:08:53,668 training [INFO ] Epoch 18 Batch 3620 Training err. 1.53709 Training err. RA 1.89888 Valid. err. 1.64437
2018-02-04 00:08:54,155 training [INFO ] Epoch 18 Batch 3640 Training err. 1.51117 Training err. RA 1.89675 Valid. err. 1.61812
2018-02-04 00:08:54,636 training [INFO ] Epoch 18 Batch 3660 Training err. 1.57323 Training err. RA 1.89498 Valid. err. 1.64454
2018-02-04 00:08:55,118 training [INFO ] Epoch 18 Batch 3680 Training err. 1.48376 Training err. RA 1.89275 Valid. err. 1.63001
2018-02-04 00:08:55,608 training [INFO ] Epoch 18 Batch 3700 Training err. 1.49200 Training err. RA 1.89058 Valid. err. 1.63255
2018-02-04 00:08:56,101 training [INFO ] Epoch 18 Batch 3720 Training err. 1.47130 Training err. RA 1.88833 Valid. err. 1.60979
2018-02-04 00:08:56,605 training [INFO ] Epoch 18 Batch 3740 Training err. 1.52012 Training err. RA 1.88636 Valid. err. 1.59752
2018-02-04 00:08:57,483 training [INFO ] Epoch 19 Batch 3760 Training err. 1.48200 Training err. RA 1.88421 Valid. err. 1.60892
2018-02-04 00:08:57,962 training [INFO ] Epoch 19 Batch 3780 Training err. 1.45746 Training err. RA 1.88195 Valid. err. 1.61480
2018-02-04 00:08:58,439 training [INFO ] Epoch 19 Batch 3800 Training err. 1.52520 Training err. RA 1.88007 Valid. err. 1.60934
2018-02-04 00:08:58,910 training [INFO ] Epoch 19 Batch 3820 Training err. 1.54334 Training err. RA 1.87831 Valid. err. 1.61586
2018-02-04 00:08:59,391 training [INFO ] Epoch 19 Batch 3840 Training err. 1.49127 Training err. RA 1.87629 Valid. err. 1.65004
2018-02-04 00:08:59,871 training [INFO ] Epoch 19 Batch 3860 Training err. 1.54308 Training err. RA 1.87457 Valid. err. 1.66698
2018-02-04 00:09:00,357 training [INFO ] Epoch 19 Batch 3880 Training err. 1.51361 Training err. RA 1.87271 Valid. err. 1.62435
2018-02-04 00:09:00,841 training [INFO ] Epoch 19 Batch 3900 Training err. 1.46503 Training err. RA 1.87062 Valid. err. 1.63047
2018-02-04 00:09:01,323 training [INFO ] Epoch 19 Batch 3920 Training err. 1.48324 Training err. RA 1.86864 Valid. err. 1.61106
2018-02-04 00:09:01,806 training [INFO ] Epoch 19 Batch 3940 Training err. 1.48877 Training err. RA 1.86671 Valid. err. 1.62591
2018-02-04 00:09:02,656 training [INFO ] Epoch 20 Batch 3960 Training err. 1.47376 Training err. RA 1.86473 Valid. err. 1.57957
2018-02-04 00:09:03,137 training [INFO ] Epoch 20 Batch 3980 Training err. 1.45734 Training err. RA 1.86268 Valid. err. 1.60634
2018-02-04 00:09:03,620 training [INFO ] Epoch 20 Batch 4000 Training err. 1.49715 Training err. RA 1.86085 Valid. err. 1.59739
2018-02-04 00:09:04,100 training [INFO ] Epoch 20 Batch 4020 Training err. 1.52986 Training err. RA 1.85921 Valid. err. 1.60282
2018-02-04 00:09:04,579 training [INFO ] Epoch 20 Batch 4040 Training err. 1.48502 Training err. RA 1.85735 Valid. err. 1.62661
2018-02-04 00:09:05,060 training [INFO ] Epoch 20 Batch 4060 Training err. 1.48162 Training err. RA 1.85550 Valid. err. 1.62371
2018-02-04 00:09:05,541 training [INFO ] Epoch 20 Batch 4080 Training err. 1.53623 Training err. RA 1.85394 Valid. err. 1.59601
2018-02-04 00:09:06,024 training [INFO ] Epoch 20 Batch 4100 Training err. 1.46367 Training err. RA 1.85203 Valid. err. 1.62682
2018-02-04 00:09:06,505 training [INFO ] Epoch 20 Batch 4120 Training err. 1.45695 Training err. RA 1.85012 Valid. err. 1.59772
2018-02-04 00:09:06,988 training [INFO ] Epoch 20 Batch 4140 Training err. 1.45926 Training err. RA 1.84823 Valid. err. 1.59528
2018-02-04 00:09:07,467 training [INFO ] Epoch 20 Batch 4160 Training err. 1.47940 Training err. RA 1.84645 Valid. err. 1.60484
2018-02-04 00:09:08,317 training [INFO ] Epoch 21 Batch 4180 Training err. 1.46769 Training err. RA 1.84464 Valid. err. 1.57819
2018-02-04 00:09:08,795 training [INFO ] Epoch 21 Batch 4200 Training err. 1.42407 Training err. RA 1.84264 Valid. err. 1.62776
2018-02-04 00:09:09,278 training [INFO ] Epoch 21 Batch 4220 Training err. 1.50711 Training err. RA 1.84105 Valid. err. 1.62221
2018-02-04 00:09:09,760 training [INFO ] Epoch 21 Batch 4240 Training err. 1.52243 Training err. RA 1.83955 Valid. err. 1.61175
2018-02-04 00:09:10,251 training [INFO ] Epoch 21 Batch 4260 Training err. 1.44942 Training err. RA 1.83771 Valid. err. 1.60668
2018-02-04 00:09:10,734 training [INFO ] Epoch 21 Batch 4280 Training err. 1.52699 Training err. RA 1.83626 Valid. err. 1.59529
2018-02-04 00:09:11,222 training [INFO ] Epoch 21 Batch 4300 Training err. 1.48192 Training err. RA 1.83461 Valid. err. 1.59787
2018-02-04 00:09:11,705 training [INFO ] Epoch 21 Batch 4320 Training err. 1.44164 Training err. RA 1.83279 Valid. err. 1.62779
2018-02-04 00:09:12,190 training [INFO ] Epoch 21 Batch 4340 Training err. 1.44383 Training err. RA 1.83100 Valid. err. 1.58404
2018-02-04 00:09:12,667 training [INFO ] Epoch 21 Batch 4360 Training err. 1.46984 Training err. RA 1.82935 Valid. err. 1.57791
2018-02-04 00:09:13,497 training [INFO ] Epoch 22 Batch 4380 Training err. 1.45348 Training err. RA 1.82763 Valid. err. 1.57296
2018-02-04 00:09:13,982 training [INFO ] Epoch 22 Batch 4400 Training err. 1.42012 Training err. RA 1.82578 Valid. err. 1.60222
2018-02-04 00:09:14,460 training [INFO ] Epoch 22 Batch 4420 Training err. 1.48997 Training err. RA 1.82426 Valid. err. 1.58631
2018-02-04 00:09:14,935 training [INFO ] Epoch 22 Batch 4440 Training err. 1.50555 Training err. RA 1.82282 Valid. err. 1.61389
2018-02-04 00:09:15,414 training [INFO ] Epoch 22 Batch 4460 Training err. 1.45253 Training err. RA 1.82116 Valid. err. 1.60792
2018-02-04 00:09:15,934 training [INFO ] Epoch 22 Batch 4480 Training err. 1.47027 Training err. RA 1.81959 Valid. err. 1.59169
2018-02-04 00:09:16,412 training [INFO ] Epoch 22 Batch 4500 Training err. 1.51386 Training err. RA 1.81824 Valid. err. 1.59362
2018-02-04 00:09:17,011 training [INFO ] Epoch 22 Batch 4520 Training err. 1.43395 Training err. RA 1.81654 Valid. err. 1.60272
2018-02-04 00:09:17,496 training [INFO ] Epoch 22 Batch 4540 Training err. 1.44738 Training err. RA 1.81491 Valid. err. 1.63575
2018-02-04 00:09:17,974 training [INFO ] Epoch 22 Batch 4560 Training err. 1.43742 Training err. RA 1.81325 Valid. err. 1.60096
2018-02-04 00:09:18,833 training [INFO ] Epoch 23 Batch 4580 Training err. 1.44808 Training err. RA 1.81166 Valid. err. 1.57549
2018-02-04 00:09:19,317 training [INFO ] Epoch 23 Batch 4600 Training err. 1.43001 Training err. RA 1.81000 Valid. err. 1.59784
2018-02-04 00:09:19,799 training [INFO ] Epoch 23 Batch 4620 Training err. 1.43516 Training err. RA 1.80838 Valid. err. 1.58024
2018-02-04 00:09:20,282 training [INFO ] Epoch 23 Batch 4640 Training err. 1.48429 Training err. RA 1.80698 Valid. err. 1.62678
2018-02-04 00:09:20,765 training [INFO ] Epoch 23 Batch 4660 Training err. 1.47556 Training err. RA 1.80556 Valid. err. 1.62565
2018-02-04 00:09:21,250 training [INFO ] Epoch 23 Batch 4680 Training err. 1.44425 Training err. RA 1.80401 Valid. err. 1.58484
2018-02-04 00:09:21,738 training [INFO ] Epoch 23 Batch 4700 Training err. 1.52139 Training err. RA 1.80281 Valid. err. 1.61949
2018-02-04 00:09:22,227 training [INFO ] Epoch 23 Batch 4720 Training err. 1.42587 Training err. RA 1.80121 Valid. err. 1.59878
2018-02-04 00:09:22,698 training [INFO ] Epoch 23 Batch 4740 Training err. 1.42377 Training err. RA 1.79962 Valid. err. 1.61616
2018-02-04 00:09:23,176 training [INFO ] Epoch 23 Batch 4760 Training err. 1.40877 Training err. RA 1.79798 Valid. err. 1.59600
2018-02-04 00:09:23,655 training [INFO ] Epoch 23 Batch 4780 Training err. 1.46258 Training err. RA 1.79658 Valid. err. 1.57352
2018-02-04 00:09:24,489 training [INFO ] Epoch 24 Batch 4800 Training err. 1.42182 Training err. RA 1.79501 Valid. err. 1.58631
2018-02-04 00:09:25,001 training [INFO ] Epoch 24 Batch 4820 Training err. 1.40523 Training err. RA 1.79340 Valid. err. 1.60052
2018-02-04 00:09:25,478 training [INFO ] Epoch 24 Batch 4840 Training err. 1.46519 Training err. RA 1.79204 Valid. err. 1.59770
2018-02-04 00:09:25,954 training [INFO ] Epoch 24 Batch 4860 Training err. 1.48483 Training err. RA 1.79078 Valid. err. 1.56636
2018-02-04 00:09:26,438 training [INFO ] Epoch 24 Batch 4880 Training err. 1.42911 Training err. RA 1.78929 Valid. err. 1.63584
2018-02-04 00:09:26,919 training [INFO ] Epoch 24 Batch 4900 Training err. 1.48506 Training err. RA 1.78805 Valid. err. 1.61894
2018-02-04 00:09:27,399 training [INFO ] Epoch 24 Batch 4920 Training err. 1.45978 Training err. RA 1.78672 Valid. err. 1.59594
2018-02-04 00:09:27,884 training [INFO ] Epoch 24 Batch 4940 Training err. 1.40939 Training err. RA 1.78519 Valid. err. 1.61409
2018-02-04 00:09:28,370 training [INFO ] Epoch 24 Batch 4960 Training err. 1.42382 Training err. RA 1.78373 Valid. err. 1.59118
2018-02-04 00:09:28,846 training [INFO ] Epoch 24 Batch 4980 Training err. 1.42634 Training err. RA 1.78230 Valid. err. 1.59481
2018-02-04 00:09:29,693 training [INFO ] Epoch 25 Batch 5000 Training err. 1.41386 Training err. RA 1.78082 Valid. err. 1.56453
2018-02-04 00:09:30,180 training [INFO ] Epoch 25 Batch 5020 Training err. 1.40605 Training err. RA 1.77933 Valid. err. 1.58644
2018-02-04 00:09:30,662 training [INFO ] Epoch 25 Batch 5040 Training err. 1.44469 Training err. RA 1.77800 Valid. err. 1.57911
2018-02-04 00:09:31,145 training [INFO ] Epoch 25 Batch 5060 Training err. 1.47505 Training err. RA 1.77681 Valid. err. 1.57207
2018-02-04 00:09:31,627 training [INFO ] Epoch 25 Batch 5080 Training err. 1.42606 Training err. RA 1.77542 Valid. err. 1.60631
2018-02-04 00:09:32,102 training [INFO ] Epoch 25 Batch 5100 Training err. 1.42463 Training err. RA 1.77405 Valid. err. 1.59820
2018-02-04 00:09:32,577 training [INFO ] Epoch 25 Batch 5120 Training err. 1.48973 Training err. RA 1.77294 Valid. err. 1.56370
2018-02-04 00:09:33,053 training [INFO ] Epoch 25 Batch 5140 Training err. 1.41196 Training err. RA 1.77153 Valid. err. 1.59765
2018-02-04 00:09:33,530 training [INFO ] Epoch 25 Batch 5160 Training err. 1.39444 Training err. RA 1.77007 Valid. err. 1.59047
2018-02-04 00:09:34,003 training [INFO ] Epoch 25 Batch 5180 Training err. 1.40259 Training err. RA 1.76865 Valid. err. 1.57356
2018-02-04 00:09:34,473 training [INFO ] Epoch 25 Batch 5200 Training err. 1.42369 Training err. RA 1.76733 Valid. err. 1.56572
2018-02-04 00:09:35,449 training [INFO ] Epoch 26 Batch 5220 Training err. 1.41359 Training err. RA 1.76597 Valid. err. 1.56461
2018-02-04 00:09:35,954 training [INFO ] Epoch 26 Batch 5240 Training err. 1.37988 Training err. RA 1.76450 Valid. err. 1.59016
2018-02-04 00:09:36,433 training [INFO ] Epoch 26 Batch 5260 Training err. 1.45460 Training err. RA 1.76332 Valid. err. 1.59761
2018-02-04 00:09:36,912 training [INFO ] Epoch 26 Batch 5280 Training err. 1.46998 Training err. RA 1.76221 Valid. err. 1.57939
2018-02-04 00:09:37,392 training [INFO ] Epoch 26 Batch 5300 Training err. 1.39757 Training err. RA 1.76083 Valid. err. 1.60277
2018-02-04 00:09:37,906 training [INFO ] Epoch 26 Batch 5320 Training err. 1.47178 Training err. RA 1.75975 Valid. err. 1.57848
2018-02-04 00:09:38,391 training [INFO ] Epoch 26 Batch 5340 Training err. 1.43095 Training err. RA 1.75851 Valid. err. 1.58204
2018-02-04 00:09:38,888 training [INFO ] Epoch 26 Batch 5360 Training err. 1.38883 Training err. RA 1.75713 Valid. err. 1.59640
2018-02-04 00:09:39,369 training [INFO ] Epoch 26 Batch 5380 Training err. 1.39615 Training err. RA 1.75579 Valid. err. 1.56642
2018-02-04 00:09:39,856 training [INFO ] Epoch 26 Batch 5400 Training err. 1.42333 Training err. RA 1.75456 Valid. err. 1.55433
2018-02-04 00:09:40,725 training [INFO ] Epoch 27 Batch 5420 Training err. 1.39626 Training err. RA 1.75324 Valid. err. 1.55407
2018-02-04 00:09:41,211 training [INFO ] Epoch 27 Batch 5440 Training err. 1.37711 Training err. RA 1.75186 Valid. err. 1.58700
2018-02-04 00:09:41,692 training [INFO ] Epoch 27 Batch 5460 Training err. 1.43696 Training err. RA 1.75070 Valid. err. 1.57086
2018-02-04 00:09:42,174 training [INFO ] Epoch 27 Batch 5480 Training err. 1.45359 Training err. RA 1.74962 Valid. err. 1.59825
2018-02-04 00:09:42,655 training [INFO ] Epoch 27 Batch 5500 Training err. 1.39764 Training err. RA 1.74834 Valid. err. 1.58100
2018-02-04 00:09:43,139 training [INFO ] Epoch 27 Batch 5520 Training err. 1.42203 Training err. RA 1.74716 Valid. err. 1.56314
2018-02-04 00:09:43,635 training [INFO ] Epoch 27 Batch 5540 Training err. 1.46672 Training err. RA 1.74614 Valid. err. 1.56315
2018-02-04 00:09:44,138 training [INFO ] Epoch 27 Batch 5560 Training err. 1.38142 Training err. RA 1.74483 Valid. err. 1.58459
2018-02-04 00:09:44,615 training [INFO ] Epoch 27 Batch 5580 Training err. 1.39373 Training err. RA 1.74357 Valid. err. 1.60751
2018-02-04 00:09:45,097 training [INFO ] Epoch 27 Batch 5600 Training err. 1.38713 Training err. RA 1.74230 Valid. err. 1.57011
2018-02-04 00:09:45,948 training [INFO ] Epoch 28 Batch 5620 Training err. 1.40008 Training err. RA 1.74108 Valid. err. 1.56955
2018-02-04 00:09:46,447 training [INFO ] Epoch 28 Batch 5640 Training err. 1.38234 Training err. RA 1.73981 Valid. err. 1.57335
2018-02-04 00:09:46,961 training [INFO ] Epoch 28 Batch 5660 Training err. 1.39597 Training err. RA 1.73860 Valid. err. 1.57320
2018-02-04 00:09:47,472 training [INFO ] Epoch 28 Batch 5680 Training err. 1.43914 Training err. RA 1.73754 Valid. err. 1.58858
2018-02-04 00:09:47,965 training [INFO ] Epoch 28 Batch 5700 Training err. 1.42742 Training err. RA 1.73645 Valid. err. 1.61606
2018-02-04 00:09:48,456 training [INFO ] Epoch 28 Batch 5720 Training err. 1.39602 Training err. RA 1.73526 Valid. err. 1.57111
2018-02-04 00:09:48,950 training [INFO ] Epoch 28 Batch 5740 Training err. 1.46697 Training err. RA 1.73433 Valid. err. 1.59075
2018-02-04 00:09:49,432 training [INFO ] Epoch 28 Batch 5760 Training err. 1.37575 Training err. RA 1.73308 Valid. err. 1.59133
2018-02-04 00:09:49,927 training [INFO ] Epoch 28 Batch 5780 Training err. 1.37425 Training err. RA 1.73184 Valid. err. 1.59292
2018-02-04 00:09:50,506 training [INFO ] Epoch 28 Batch 5800 Training err. 1.35791 Training err. RA 1.73055 Valid. err. 1.57113
2018-02-04 00:09:51,034 training [INFO ] Epoch 28 Batch 5820 Training err. 1.41300 Training err. RA 1.72946 Valid. err. 1.55907
2018-02-04 00:09:52,111 training [INFO ] Epoch 29 Batch 5840 Training err. 1.37182 Training err. RA 1.72824 Valid. err. 1.56682
2018-02-04 00:09:52,596 training [INFO ] Epoch 29 Batch 5860 Training err. 1.37166 Training err. RA 1.72702 Valid. err. 1.59536
2018-02-04 00:09:53,086 training [INFO ] Epoch 29 Batch 5880 Training err. 1.42565 Training err. RA 1.72599 Valid. err. 1.57854
2018-02-04 00:09:53,571 training [INFO ] Epoch 29 Batch 5900 Training err. 1.43664 Training err. RA 1.72501 Valid. err. 1.56810
2018-02-04 00:09:54,057 training [INFO ] Epoch 29 Batch 5920 Training err. 1.38496 Training err. RA 1.72386 Valid. err. 1.60116
2018-02-04 00:09:54,549 training [INFO ] Epoch 29 Batch 5940 Training err. 1.43300 Training err. RA 1.72288 Valid. err. 1.58878
2018-02-04 00:09:55,031 training [INFO ] Epoch 29 Batch 5960 Training err. 1.41386 Training err. RA 1.72185 Valid. err. 1.57407
2018-02-04 00:09:55,521 training [INFO ] Epoch 29 Batch 5980 Training err. 1.35487 Training err. RA 1.72062 Valid. err. 1.59350
2018-02-04 00:09:56,057 training [INFO ] Epoch 29 Batch 6000 Training err. 1.38051 Training err. RA 1.71949 Valid. err. 1.57865
2018-02-04 00:09:56,535 training [INFO ] Epoch 29 Batch 6020 Training err. 1.38629 Training err. RA 1.71838 Valid. err. 1.59073
2018-02-04 00:09:57,421 training [INFO ] Epoch 30 Batch 6040 Training err. 1.36560 Training err. RA 1.71721 Valid. err. 1.54926
2018-02-04 00:09:57,906 training [INFO ] Epoch 30 Batch 6060 Training err. 1.36718 Training err. RA 1.71606 Valid. err. 1.58215
2018-02-04 00:09:58,390 training [INFO ] Epoch 30 Batch 6080 Training err. 1.40464 Training err. RA 1.71503 Valid. err. 1.56481
2018-02-04 00:09:58,926 training [INFO ] Epoch 30 Batch 6100 Training err. 1.43198 Training err. RA 1.71410 Valid. err. 1.55670
2018-02-04 00:09:59,403 training [INFO ] Epoch 30 Batch 6120 Training err. 1.38573 Training err. RA 1.71303 Valid. err. 1.59592
2018-02-04 00:09:59,893 training [INFO ] Epoch 30 Batch 6140 Training err. 1.38054 Training err. RA 1.71195 Valid. err. 1.57768
2018-02-04 00:10:00,393 training [INFO ] Epoch 30 Batch 6160 Training err. 1.43856 Training err. RA 1.71106 Valid. err. 1.55958
2018-02-04 00:10:00,877 training [INFO ] Epoch 30 Batch 6180 Training err. 1.36384 Training err. RA 1.70994 Valid. err. 1.59861
2018-02-04 00:10:01,370 training [INFO ] Epoch 30 Batch 6200 Training err. 1.35437 Training err. RA 1.70879 Valid. err. 1.58074
2018-02-04 00:10:01,866 training [INFO ] Epoch 30 Batch 6220 Training err. 1.36170 Training err. RA 1.70767 Valid. err. 1.57588
2018-02-04 00:10:02,371 training [INFO ] Epoch 30 Batch 6240 Training err. 1.38342 Training err. RA 1.70663 Valid. err. 1.57788
2018-02-04 00:10:03,222 training [INFO ] Epoch 31 Batch 6260 Training err. 1.37870 Training err. RA 1.70559 Valid. err. 1.55041
2018-02-04 00:10:03,708 training [INFO ] Epoch 31 Batch 6280 Training err. 1.34725 Training err. RA 1.70445 Valid. err. 1.59591
2018-02-04 00:10:04,220 training [INFO ] Epoch 31 Batch 6300 Training err. 1.41865 Training err. RA 1.70354 Valid. err. 1.59138
2018-02-04 00:10:04,714 training [INFO ] Epoch 31 Batch 6320 Training err. 1.42301 Training err. RA 1.70265 Valid. err. 1.56287
2018-02-04 00:10:05,198 training [INFO ] Epoch 31 Batch 6340 Training err. 1.36558 Training err. RA 1.70159 Valid. err. 1.58034
2018-02-04 00:10:05,684 training [INFO ] Epoch 31 Batch 6360 Training err. 1.42501 Training err. RA 1.70072 Valid. err. 1.56676
2018-02-04 00:10:06,170 training [INFO ] Epoch 31 Batch 6380 Training err. 1.38976 Training err. RA 1.69974 Valid. err. 1.57285
2018-02-04 00:10:06,689 training [INFO ] Epoch 31 Batch 6400 Training err. 1.34557 Training err. RA 1.69864 Valid. err. 1.60894
2018-02-04 00:10:07,160 training [INFO ] Epoch 31 Batch 6420 Training err. 1.34642 Training err. RA 1.69754 Valid. err. 1.55829
2018-02-04 00:10:07,646 training [INFO ] Epoch 31 Batch 6440 Training err. 1.38459 Training err. RA 1.69657 Valid. err. 1.55403
2018-02-04 00:10:08,554 training [INFO ] Epoch 32 Batch 6460 Training err. 1.36980 Training err. RA 1.69555 Valid. err. 1.55070
2018-02-04 00:10:09,032 training [INFO ] Epoch 32 Batch 6480 Training err. 1.34603 Training err. RA 1.69448 Valid. err. 1.57965
2018-02-04 00:10:09,514 training [INFO ] Epoch 32 Batch 6500 Training err. 1.40241 Training err. RA 1.69358 Valid. err. 1.55503
2018-02-04 00:10:09,998 training [INFO ] Epoch 32 Batch 6520 Training err. 1.41816 Training err. RA 1.69273 Valid. err. 1.56716
2018-02-04 00:10:10,487 training [INFO ] Epoch 32 Batch 6540 Training err. 1.36409 Training err. RA 1.69173 Valid. err. 1.57191
2018-02-04 00:10:10,981 training [INFO ] Epoch 32 Batch 6560 Training err. 1.38460 Training err. RA 1.69079 Valid. err. 1.55637
2018-02-04 00:10:11,474 training [INFO ] Epoch 32 Batch 6580 Training err. 1.42677 Training err. RA 1.68999 Valid. err. 1.56377
2018-02-04 00:10:11,962 training [INFO ] Epoch 32 Batch 6600 Training err. 1.33799 Training err. RA 1.68892 Valid. err. 1.58484
2018-02-04 00:10:12,499 training [INFO ] Epoch 32 Batch 6620 Training err. 1.35552 Training err. RA 1.68791 Valid. err. 1.58694
2018-02-04 00:10:13,068 training [INFO ] Epoch 32 Batch 6640 Training err. 1.34559 Training err. RA 1.68688 Valid. err. 1.58709
2018-02-04 00:10:14,117 training [INFO ] Epoch 33 Batch 6660 Training err. 1.36968 Training err. RA 1.68593 Valid. err. 1.55340
2018-02-04 00:10:14,745 training [INFO ] Epoch 33 Batch 6680 Training err. 1.35511 Training err. RA 1.68494 Valid. err. 1.55131
2018-02-04 00:10:15,308 training [INFO ] Epoch 33 Batch 6700 Training err. 1.35867 Training err. RA 1.68397 Valid. err. 1.55573
2018-02-04 00:10:15,884 training [INFO ] Epoch 33 Batch 6720 Training err. 1.40283 Training err. RA 1.68313 Valid. err. 1.56903
2018-02-04 00:10:16,447 training [INFO ] Epoch 33 Batch 6740 Training err. 1.38771 Training err. RA 1.68225 Valid. err. 1.61778
2018-02-04 00:10:16,992 training [INFO ] Epoch 33 Batch 6760 Training err. 1.35750 Training err. RA 1.68129 Valid. err. 1.55915
2018-02-04 00:10:17,481 training [INFO ] Epoch 33 Batch 6780 Training err. 1.42405 Training err. RA 1.68053 Valid. err. 1.59999
2018-02-04 00:10:17,976 training [INFO ] Epoch 33 Batch 6800 Training err. 1.34122 Training err. RA 1.67954 Valid. err. 1.59431
2018-02-04 00:10:18,479 training [INFO ] Epoch 33 Batch 6820 Training err. 1.34285 Training err. RA 1.67855 Valid. err. 1.60077
2018-02-04 00:10:18,974 training [INFO ] Epoch 33 Batch 6840 Training err. 1.31667 Training err. RA 1.67749 Valid. err. 1.56704
2018-02-04 00:10:19,503 training [INFO ] Epoch 33 Batch 6860 Training err. 1.37969 Training err. RA 1.67662 Valid. err. 1.56766
2018-02-04 00:10:20,454 training [INFO ] Epoch 34 Batch 6880 Training err. 1.35223 Training err. RA 1.67568 Valid. err. 1.56087
2018-02-04 00:10:20,932 training [INFO ] Epoch 34 Batch 6900 Training err. 1.32842 Training err. RA 1.67467 Valid. err. 1.56713
2018-02-04 00:10:21,417 training [INFO ] Epoch 34 Batch 6920 Training err. 1.38388 Training err. RA 1.67383 Valid. err. 1.56037
2018-02-04 00:10:21,896 training [INFO ] Epoch 34 Batch 6940 Training err. 1.39648 Training err. RA 1.67303 Valid. err. 1.56255
2018-02-04 00:10:22,377 training [INFO ] Epoch 34 Batch 6960 Training err. 1.34825 Training err. RA 1.67210 Valid. err. 1.60168
2018-02-04 00:10:22,860 training [INFO ] Epoch 34 Batch 6980 Training err. 1.39679 Training err. RA 1.67131 Valid. err. 1.56587
2018-02-04 00:10:23,338 training [INFO ] Epoch 34 Batch 7000 Training err. 1.38178 Training err. RA 1.67048 Valid. err. 1.57255
2018-02-04 00:10:23,815 training [INFO ] Epoch 34 Batch 7020 Training err. 1.32380 Training err. RA 1.66950 Valid. err. 1.58502
2018-02-04 00:10:24,306 training [INFO ] Epoch 34 Batch 7040 Training err. 1.34049 Training err. RA 1.66856 Valid. err. 1.57947
2018-02-04 00:10:24,783 training [INFO ] Epoch 34 Batch 7060 Training err. 1.34796 Training err. RA 1.66765 Valid. err. 1.58616
2018-02-04 00:10:25,649 training [INFO ] Epoch 35 Batch 7080 Training err. 1.33137 Training err. RA 1.66670 Valid. err. 1.55941
2018-02-04 00:10:26,132 training [INFO ] Epoch 35 Batch 7100 Training err. 1.33467 Training err. RA 1.66577 Valid. err. 1.56791
2018-02-04 00:10:26,620 training [INFO ] Epoch 35 Batch 7120 Training err. 1.36129 Training err. RA 1.66491 Valid. err. 1.55238
2018-02-04 00:10:27,106 training [INFO ] Epoch 35 Batch 7140 Training err. 1.40701 Training err. RA 1.66419 Valid. err. 1.54423
2018-02-04 00:10:27,595 training [INFO ] Epoch 35 Batch 7160 Training err. 1.34887 Training err. RA 1.66331 Valid. err. 1.58363
2018-02-04 00:10:28,083 training [INFO ] Epoch 35 Batch 7180 Training err. 1.34470 Training err. RA 1.66242 Valid. err. 1.57289
2018-02-04 00:10:28,563 training [INFO ] Epoch 35 Batch 7200 Training err. 1.42201 Training err. RA 1.66175 Valid. err. 1.55218
2018-02-04 00:10:29,050 training [INFO ] Epoch 35 Batch 7220 Training err. 1.33111 Training err. RA 1.66084 Valid. err. 1.58388
2018-02-04 00:10:29,531 training [INFO ] Epoch 35 Batch 7240 Training err. 1.32085 Training err. RA 1.65990 Valid. err. 1.58522
2018-02-04 00:10:30,019 training [INFO ] Epoch 35 Batch 7260 Training err. 1.32141 Training err. RA 1.65897 Valid. err. 1.55237
2018-02-04 00:10:30,548 training [INFO ] Epoch 35 Batch 7280 Training err. 1.34107 Training err. RA 1.65809 Valid. err. 1.57624
2018-02-04 00:10:31,387 training [INFO ] Epoch 36 Batch 7300 Training err. 1.35484 Training err. RA 1.65726 Valid. err. 1.54611
2018-02-04 00:10:31,873 training [INFO ] Epoch 36 Batch 7320 Training err. 1.29929 Training err. RA 1.65628 Valid. err. 1.58259
2018-02-04 00:10:32,357 training [INFO ] Epoch 36 Batch 7340 Training err. 1.37919 Training err. RA 1.65553 Valid. err. 1.58387
2018-02-04 00:10:32,841 training [INFO ] Epoch 36 Batch 7360 Training err. 1.39119 Training err. RA 1.65481 Valid. err. 1.55795
2018-02-04 00:10:33,329 training [INFO ] Epoch 36 Batch 7380 Training err. 1.31802 Training err. RA 1.65390 Valid. err. 1.56190
2018-02-04 00:10:33,814 training [INFO ] Epoch 36 Batch 7400 Training err. 1.39398 Training err. RA 1.65320 Valid. err. 1.55878
2018-02-04 00:10:34,298 training [INFO ] Epoch 36 Batch 7420 Training err. 1.36141 Training err. RA 1.65241 Valid. err. 1.56512
2018-02-04 00:10:34,786 training [INFO ] Epoch 36 Batch 7440 Training err. 1.31825 Training err. RA 1.65151 Valid. err. 1.57923
2018-02-04 00:10:35,267 training [INFO ] Epoch 36 Batch 7460 Training err. 1.31226 Training err. RA 1.65060 Valid. err. 1.54832
2018-02-04 00:10:35,754 training [INFO ] Epoch 36 Batch 7480 Training err. 1.37100 Training err. RA 1.64985 Valid. err. 1.55168
2018-02-04 00:10:36,630 training [INFO ] Epoch 37 Batch 7500 Training err. 1.32910 Training err. RA 1.64900 Valid. err. 1.54434
2018-02-04 00:10:37,111 training [INFO ] Epoch 37 Batch 7520 Training err. 1.31025 Training err. RA 1.64810 Valid. err. 1.57032
2018-02-04 00:10:37,598 training [INFO ] Epoch 37 Batch 7540 Training err. 1.36649 Training err. RA 1.64735 Valid. err. 1.55708
2018-02-04 00:10:38,082 training [INFO ] Epoch 37 Batch 7560 Training err. 1.38120 Training err. RA 1.64665 Valid. err. 1.56823
2018-02-04 00:10:38,564 training [INFO ] Epoch 37 Batch 7580 Training err. 1.31965 Training err. RA 1.64578 Valid. err. 1.57573
2018-02-04 00:10:39,043 training [INFO ] Epoch 37 Batch 7600 Training err. 1.34548 Training err. RA 1.64499 Valid. err. 1.54986
2018-02-04 00:10:39,531 training [INFO ] Epoch 37 Batch 7620 Training err. 1.39814 Training err. RA 1.64435 Valid. err. 1.55701
2018-02-04 00:10:40,011 training [INFO ] Epoch 37 Batch 7640 Training err. 1.30345 Training err. RA 1.64345 Valid. err. 1.58027
2018-02-04 00:10:40,500 training [INFO ] Epoch 37 Batch 7660 Training err. 1.33183 Training err. RA 1.64264 Valid. err. 1.57920
2018-02-04 00:10:40,995 training [INFO ] Epoch 37 Batch 7680 Training err. 1.32197 Training err. RA 1.64180 Valid. err. 1.56046
2018-02-04 00:10:41,852 training [INFO ] Epoch 38 Batch 7700 Training err. 1.32734 Training err. RA 1.64099 Valid. err. 1.53750
2018-02-04 00:10:42,337 training [INFO ] Epoch 38 Batch 7720 Training err. 1.31334 Training err. RA 1.64014 Valid. err. 1.55985
2018-02-04 00:10:42,825 training [INFO ] Epoch 38 Batch 7740 Training err. 1.31883 Training err. RA 1.63931 Valid. err. 1.55136
2018-02-04 00:10:43,364 training [INFO ] Epoch 38 Batch 7760 Training err. 1.37394 Training err. RA 1.63862 Valid. err. 1.56389
2018-02-04 00:10:43,841 training [INFO ] Epoch 38 Batch 7780 Training err. 1.36249 Training err. RA 1.63791 Valid. err. 1.58958
2018-02-04 00:10:44,322 training [INFO ] Epoch 38 Batch 7800 Training err. 1.31973 Training err. RA 1.63710 Valid. err. 1.54819
2018-02-04 00:10:44,799 training [INFO ] Epoch 38 Batch 7820 Training err. 1.38996 Training err. RA 1.63647 Valid. err. 1.58022
2018-02-04 00:10:45,283 training [INFO ] Epoch 38 Batch 7840 Training err. 1.30425 Training err. RA 1.63562 Valid. err. 1.57517
2018-02-04 00:10:45,760 training [INFO ] Epoch 38 Batch 7860 Training err. 1.31354 Training err. RA 1.63480 Valid. err. 1.58098
2018-02-04 00:10:46,236 training [INFO ] Epoch 38 Batch 7880 Training err. 1.28178 Training err. RA 1.63390 Valid. err. 1.56525
2018-02-04 00:10:46,714 training [INFO ] Epoch 38 Batch 7900 Training err. 1.34662 Training err. RA 1.63318 Valid. err. 1.56756
2018-02-04 00:10:47,555 training [INFO ] Epoch 39 Batch 7920 Training err. 1.30944 Training err. RA 1.63236 Valid. err. 1.54474
2018-02-04 00:10:48,026 training [INFO ] Epoch 39 Batch 7940 Training err. 1.28765 Training err. RA 1.63149 Valid. err. 1.56328
2018-02-04 00:10:48,543 training [INFO ] Epoch 39 Batch 7960 Training err. 1.34667 Training err. RA 1.63077 Valid. err. 1.55171
2018-02-04 00:10:49,023 training [INFO ] Epoch 39 Batch 7980 Training err. 1.36530 Training err. RA 1.63011 Valid. err. 1.54399
2018-02-04 00:10:49,501 training [INFO ] Epoch 39 Batch 8000 Training err. 1.31072 Training err. RA 1.62931 Valid. err. 1.59332
2018-02-04 00:10:49,987 training [INFO ] Epoch 39 Batch 8020 Training err. 1.35601 Training err. RA 1.62863 Valid. err. 1.55250
2018-02-04 00:10:50,468 training [INFO ] Epoch 39 Batch 8040 Training err. 1.34697 Training err. RA 1.62793 Valid. err. 1.56197
2018-02-04 00:10:50,950 training [INFO ] Epoch 39 Batch 8060 Training err. 1.28708 Training err. RA 1.62708 Valid. err. 1.57841
2018-02-04 00:10:51,436 training [INFO ] Epoch 39 Batch 8080 Training err. 1.30603 Training err. RA 1.62629 Valid. err. 1.54617
2018-02-04 00:10:51,917 training [INFO ] Epoch 39 Batch 8100 Training err. 1.31097 Training err. RA 1.62551 Valid. err. 1.57215
2018-02-04 00:10:52,772 training [INFO ] Epoch 40 Batch 8120 Training err. 1.30071 Training err. RA 1.62471 Valid. err. 1.53898
2018-02-04 00:10:53,248 training [INFO ] Epoch 40 Batch 8140 Training err. 1.30004 Training err. RA 1.62391 Valid. err. 1.55130
2018-02-04 00:10:53,725 training [INFO ] Epoch 40 Batch 8160 Training err. 1.32646 Training err. RA 1.62318 Valid. err. 1.54953
2018-02-04 00:10:54,209 training [INFO ] Epoch 40 Batch 8180 Training err. 1.36956 Training err. RA 1.62256 Valid. err. 1.53742
2018-02-04 00:10:54,684 training [INFO ] Epoch 40 Batch 8200 Training err. 1.31732 Training err. RA 1.62182 Valid. err. 1.57561
2018-02-04 00:10:55,162 training [INFO ] Epoch 40 Batch 8220 Training err. 1.31557 Training err. RA 1.62107 Valid. err. 1.56256
2018-02-04 00:10:55,647 training [INFO ] Epoch 40 Batch 8240 Training err. 1.37937 Training err. RA 1.62049 Valid. err. 1.53817
2018-02-04 00:10:56,124 training [INFO ] Epoch 40 Batch 8260 Training err. 1.29697 Training err. RA 1.61970 Valid. err. 1.57213
2018-02-04 00:10:56,598 training [INFO ] Epoch 40 Batch 8280 Training err. 1.28773 Training err. RA 1.61890 Valid. err. 1.56872
2018-02-04 00:10:57,077 training [INFO ] Epoch 40 Batch 8300 Training err. 1.29255 Training err. RA 1.61811 Valid. err. 1.54425
2018-02-04 00:10:57,559 training [INFO ] Epoch 40 Batch 8320 Training err. 1.31851 Training err. RA 1.61739 Valid. err. 1.55395
2018-02-04 00:10:58,423 training [INFO ] Epoch 41 Batch 8340 Training err. 1.32187 Training err. RA 1.61669 Valid. err. 1.54705
2018-02-04 00:10:58,903 training [INFO ] Epoch 41 Batch 8360 Training err. 1.27062 Training err. RA 1.61586 Valid. err. 1.56553
2018-02-04 00:10:59,384 training [INFO ] Epoch 41 Batch 8380 Training err. 1.34219 Training err. RA 1.61520 Valid. err. 1.56151
2018-02-04 00:10:59,865 training [INFO ] Epoch 41 Batch 8400 Training err. 1.35841 Training err. RA 1.61459 Valid. err. 1.54470
2018-02-04 00:11:00,359 training [INFO ] Epoch 41 Batch 8420 Training err. 1.28298 Training err. RA 1.61381 Valid. err. 1.56238
2018-02-04 00:11:00,842 training [INFO ] Epoch 41 Batch 8440 Training err. 1.35122 Training err. RA 1.61318 Valid. err. 1.56125
2018-02-04 00:11:01,318 training [INFO ] Epoch 41 Batch 8460 Training err. 1.32771 Training err. RA 1.61251 Valid. err. 1.55109
2018-02-04 00:11:01,800 training [INFO ] Epoch 41 Batch 8480 Training err. 1.28586 Training err. RA 1.61174 Valid. err. 1.57578
2018-02-04 00:11:02,276 training [INFO ] Epoch 41 Batch 8500 Training err. 1.28941 Training err. RA 1.61098 Valid. err. 1.53200
2018-02-04 00:11:02,752 training [INFO ] Epoch 41 Batch 8520 Training err. 1.31967 Training err. RA 1.61030 Valid. err. 1.52098
2018-02-04 00:11:03,591 training [INFO ] Epoch 42 Batch 8540 Training err. 1.30228 Training err. RA 1.60957 Valid. err. 1.52210
2018-02-04 00:11:04,062 training [INFO ] Epoch 42 Batch 8560 Training err. 1.28352 Training err. RA 1.60881 Valid. err. 1.54007
2018-02-04 00:11:04,537 training [INFO ] Epoch 42 Batch 8580 Training err. 1.32879 Training err. RA 1.60816 Valid. err. 1.54116
2018-02-04 00:11:05,021 training [INFO ] Epoch 42 Batch 8600 Training err. 1.34988 Training err. RA 1.60756 Valid. err. 1.54325
2018-02-04 00:11:05,501 training [INFO ] Epoch 42 Batch 8620 Training err. 1.28814 Training err. RA 1.60682 Valid. err. 1.55719
2018-02-04 00:11:05,983 training [INFO ] Epoch 42 Batch 8640 Training err. 1.30813 Training err. RA 1.60613 Valid. err. 1.57826
2018-02-04 00:11:06,469 training [INFO ] Epoch 42 Batch 8660 Training err. 1.37051 Training err. RA 1.60558 Valid. err. 1.54661
2018-02-04 00:11:06,949 training [INFO ] Epoch 42 Batch 8680 Training err. 1.27183 Training err. RA 1.60481 Valid. err. 1.56246
2018-02-04 00:11:07,429 training [INFO ] Epoch 42 Batch 8700 Training err. 1.28865 Training err. RA 1.60409 Valid. err. 1.54888
2018-02-04 00:11:07,914 training [INFO ] Epoch 42 Batch 8720 Training err. 1.29283 Training err. RA 1.60337 Valid. err. 1.55407
2018-02-04 00:11:08,830 training [INFO ] Epoch 43 Batch 8740 Training err. 1.31604 Training err. RA 1.60272 Valid. err. 1.54083
2018-02-04 00:11:09,394 training [INFO ] Epoch 43 Batch 8760 Training err. 1.29808 Training err. RA 1.60202 Valid. err. 1.53894
2018-02-04 00:11:09,955 training [INFO ] Epoch 43 Batch 8780 Training err. 1.28853 Training err. RA 1.60131 Valid. err. 1.54622
2018-02-04 00:11:10,517 training [INFO ] Epoch 43 Batch 8800 Training err. 1.33832 Training err. RA 1.60071 Valid. err. 1.53557
2018-02-04 00:11:11,085 training [INFO ] Epoch 43 Batch 8820 Training err. 1.32183 Training err. RA 1.60008 Valid. err. 1.56427
2018-02-04 00:11:11,647 training [INFO ] Epoch 43 Batch 8840 Training err. 1.29291 Training err. RA 1.59938 Valid. err. 1.53996
2018-02-04 00:11:12,330 training [INFO ] Epoch 43 Batch 8860 Training err. 1.36307 Training err. RA 1.59885 Valid. err. 1.56956
2018-02-04 00:11:12,848 training [INFO ] Epoch 43 Batch 8880 Training err. 1.27422 Training err. RA 1.59812 Valid. err. 1.55631
2018-02-04 00:11:13,464 training [INFO ] Epoch 43 Batch 8900 Training err. 1.27957 Training err. RA 1.59740 Valid. err. 1.59305
2018-02-04 00:11:13,958 training [INFO ] Epoch 43 Batch 8920 Training err. 1.26115 Training err. RA 1.59665 Valid. err. 1.57166
2018-02-04 00:11:14,450 training [INFO ] Epoch 43 Batch 8940 Training err. 1.32096 Training err. RA 1.59603 Valid. err. 1.53494
2018-02-04 00:11:15,358 training [INFO ] Epoch 44 Batch 8960 Training err. 1.28506 Training err. RA 1.59534 Valid. err. 1.53485
2018-02-04 00:11:15,855 training [INFO ] Epoch 44 Batch 8980 Training err. 1.27037 Training err. RA 1.59461 Valid. err. 1.54640
2018-02-04 00:11:16,347 training [INFO ] Epoch 44 Batch 9000 Training err. 1.32505 Training err. RA 1.59401 Valid. err. 1.52887
2018-02-04 00:11:16,840 training [INFO ] Epoch 44 Batch 9020 Training err. 1.33996 Training err. RA 1.59345 Valid. err. 1.52067
2018-02-04 00:11:17,318 training [INFO ] Epoch 44 Batch 9040 Training err. 1.28254 Training err. RA 1.59276 Valid. err. 1.56980
2018-02-04 00:11:17,795 training [INFO ] Epoch 44 Batch 9060 Training err. 1.32891 Training err. RA 1.59218 Valid. err. 1.52472
2018-02-04 00:11:18,286 training [INFO ] Epoch 44 Batch 9080 Training err. 1.32298 Training err. RA 1.59159 Valid. err. 1.55499
2018-02-04 00:11:18,766 training [INFO ] Epoch 44 Batch 9100 Training err. 1.26283 Training err. RA 1.59086 Valid. err. 1.57535
2018-02-04 00:11:19,250 training [INFO ] Epoch 44 Batch 9120 Training err. 1.28790 Training err. RA 1.59020 Valid. err. 1.57613
2018-02-04 00:11:19,756 training [INFO ] Epoch 44 Batch 9140 Training err. 1.29411 Training err. RA 1.58955 Valid. err. 1.55690
2018-02-04 00:11:20,634 training [INFO ] Epoch 45 Batch 9160 Training err. 1.27493 Training err. RA 1.58886 Valid. err. 1.52968
2018-02-04 00:11:21,127 training [INFO ] Epoch 45 Batch 9180 Training err. 1.27039 Training err. RA 1.58817 Valid. err. 1.52697
2018-02-04 00:11:21,612 training [INFO ] Epoch 45 Batch 9200 Training err. 1.29526 Training err. RA 1.58753 Valid. err. 1.52690
2018-02-04 00:11:22,084 training [INFO ] Epoch 45 Batch 9220 Training err. 1.33785 Training err. RA 1.58699 Valid. err. 1.52485
2018-02-04 00:11:22,561 training [INFO ] Epoch 45 Batch 9240 Training err. 1.28040 Training err. RA 1.58633 Valid. err. 1.55064
2018-02-04 00:11:23,042 training [INFO ] Epoch 45 Batch 9260 Training err. 1.27888 Training err. RA 1.58566 Valid. err. 1.54790
2018-02-04 00:11:23,518 training [INFO ] Epoch 45 Batch 9280 Training err. 1.35616 Training err. RA 1.58517 Valid. err. 1.53046
2018-02-04 00:11:23,994 training [INFO ] Epoch 45 Batch 9300 Training err. 1.26736 Training err. RA 1.58449 Valid. err. 1.56149
2018-02-04 00:11:24,475 training [INFO ] Epoch 45 Batch 9320 Training err. 1.26199 Training err. RA 1.58379 Valid. err. 1.55221
2018-02-04 00:11:24,955 training [INFO ] Epoch 45 Batch 9340 Training err. 1.26041 Training err. RA 1.58310 Valid. err. 1.53516
2018-02-04 00:11:25,436 training [INFO ] Epoch 45 Batch 9360 Training err. 1.28365 Training err. RA 1.58246 Valid. err. 1.54053
2018-02-04 00:11:26,284 training [INFO ] Epoch 46 Batch 9380 Training err. 1.29060 Training err. RA 1.58184 Valid. err. 1.52995
2018-02-04 00:11:26,764 training [INFO ] Epoch 46 Batch 9400 Training err. 1.24249 Training err. RA 1.58112 Valid. err. 1.55118
2018-02-04 00:11:27,251 training [INFO ] Epoch 46 Batch 9420 Training err. 1.31319 Training err. RA 1.58055 Valid. err. 1.56597
2018-02-04 00:11:27,731 training [INFO ] Epoch 46 Batch 9440 Training err. 1.33213 Training err. RA 1.58002 Valid. err. 1.55352
2018-02-04 00:11:28,213 training [INFO ] Epoch 46 Batch 9460 Training err. 1.25798 Training err. RA 1.57934 Valid. err. 1.54851
2018-02-04 00:11:28,698 training [INFO ] Epoch 46 Batch 9480 Training err. 1.31643 Training err. RA 1.57879 Valid. err. 1.53567
2018-02-04 00:11:29,173 training [INFO ] Epoch 46 Batch 9500 Training err. 1.29361 Training err. RA 1.57819 Valid. err. 1.54666
2018-02-04 00:11:29,647 training [INFO ] Epoch 46 Batch 9520 Training err. 1.30231 Training err. RA 1.57761 Valid. err. 1.58471
2018-02-04 00:11:30,140 training [INFO ] Epoch 46 Batch 9540 Training err. 1.27324 Training err. RA 1.57697 Valid. err. 1.53621
2018-02-04 00:11:30,618 training [INFO ] Epoch 46 Batch 9560 Training err. 1.29496 Training err. RA 1.57638 Valid. err. 1.51356
2018-02-04 00:11:31,466 training [INFO ] Epoch 47 Batch 9580 Training err. 1.26876 Training err. RA 1.57574 Valid. err. 1.53284
2018-02-04 00:11:31,944 training [INFO ] Epoch 47 Batch 9600 Training err. 1.26246 Training err. RA 1.57508 Valid. err. 1.53271
2018-02-04 00:11:32,421 training [INFO ] Epoch 47 Batch 9620 Training err. 1.30399 Training err. RA 1.57452 Valid. err. 1.53223
2018-02-04 00:11:32,899 training [INFO ] Epoch 47 Batch 9640 Training err. 1.32640 Training err. RA 1.57401 Valid. err. 1.53669
2018-02-04 00:11:33,384 training [INFO ] Epoch 47 Batch 9660 Training err. 1.27589 Training err. RA 1.57339 Valid. err. 1.55116
2018-02-04 00:11:33,867 training [INFO ] Epoch 47 Batch 9680 Training err. 1.27941 Training err. RA 1.57278 Valid. err. 1.52922
2018-02-04 00:11:34,349 training [INFO ] Epoch 47 Batch 9700 Training err. 1.33446 Training err. RA 1.57229 Valid. err. 1.53635
2018-02-04 00:11:34,833 training [INFO ] Epoch 47 Batch 9720 Training err. 1.24955 Training err. RA 1.57163 Valid. err. 1.55812
2018-02-04 00:11:35,322 training [INFO ] Epoch 47 Batch 9740 Training err. 1.26713 Training err. RA 1.57100 Valid. err. 1.53056
2018-02-04 00:11:35,823 training [INFO ] Epoch 47 Batch 9760 Training err. 1.26895 Training err. RA 1.57038 Valid. err. 1.52053
2018-02-04 00:11:36,725 training [INFO ] Epoch 48 Batch 9780 Training err. 1.27165 Training err. RA 1.56977 Valid. err. 1.51528
2018-02-04 00:11:37,198 training [INFO ] Epoch 48 Batch 9800 Training err. 1.26153 Training err. RA 1.56914 Valid. err. 1.52684
2018-02-04 00:11:37,714 training [INFO ] Epoch 48 Batch 9820 Training err. 1.25179 Training err. RA 1.56850 Valid. err. 1.53124
2018-02-04 00:11:38,192 training [INFO ] Epoch 48 Batch 9840 Training err. 1.31585 Training err. RA 1.56798 Valid. err. 1.54730
2018-02-04 00:11:38,667 training [INFO ] Epoch 48 Batch 9860 Training err. 1.30161 Training err. RA 1.56744 Valid. err. 1.58320
2018-02-04 00:11:39,151 training [INFO ] Epoch 48 Batch 9880 Training err. 1.26260 Training err. RA 1.56682 Valid. err. 1.54798
2018-02-04 00:11:39,625 training [INFO ] Epoch 48 Batch 9900 Training err. 1.32728 Training err. RA 1.56634 Valid. err. 1.56832
2018-02-04 00:11:40,098 training [INFO ] Epoch 48 Batch 9920 Training err. 1.25007 Training err. RA 1.56570 Valid. err. 1.54852
2018-02-04 00:11:40,576 training [INFO ] Epoch 48 Batch 9940 Training err. 1.25487 Training err. RA 1.56508 Valid. err. 1.60602
2018-02-04 00:11:41,062 training [INFO ] Epoch 48 Batch 9960 Training err. 1.23648 Training err. RA 1.56442 Valid. err. 1.54590
2018-02-04 00:11:41,541 training [INFO ] Epoch 48 Batch 9980 Training err. 1.30318 Training err. RA 1.56389 Valid. err. 1.52050
2018-02-04 00:11:42,430 training [INFO ] Epoch 49 Batch10000 Training err. 1.25194 Training err. RA 1.56327 Valid. err. 1.53219
2018-02-04 00:11:42,906 training [INFO ] Epoch 49 Batch10020 Training err. 1.23298 Training err. RA 1.56261 Valid. err. 1.53178
2018-02-04 00:11:43,388 training [INFO ] Epoch 49 Batch10040 Training err. 1.28833 Training err. RA 1.56206 Valid. err. 1.54001
2018-02-04 00:11:43,871 training [INFO ] Epoch 49 Batch10060 Training err. 1.31058 Training err. RA 1.56156 Valid. err. 1.54407
2018-02-04 00:11:44,348 training [INFO ] Epoch 49 Batch10080 Training err. 1.25528 Training err. RA 1.56096 Valid. err. 1.57721
2018-02-04 00:11:44,824 training [INFO ] Epoch 49 Batch10100 Training err. 1.29092 Training err. RA 1.56042 Valid. err. 1.53704
2018-02-04 00:11:45,306 training [INFO ] Epoch 49 Batch10120 Training err. 1.29282 Training err. RA 1.55989 Valid. err. 1.55074
2018-02-04 00:11:45,781 training [INFO ] Epoch 49 Batch10140 Training err. 1.23395 Training err. RA 1.55925 Valid. err. 1.55311
2018-02-04 00:11:46,258 training [INFO ] Epoch 49 Batch10160 Training err. 1.26111 Training err. RA 1.55866 Valid. err. 1.53647
2018-02-04 00:11:46,737 training [INFO ] Epoch 49 Batch10180 Training err. 1.26263 Training err. RA 1.55808 Valid. err. 1.55128
2018-02-04 00:11:47,691 training [INFO ] Epoch 50 Batch10200 Training err. 1.26034 Training err. RA 1.55750 Valid. err. 1.53052
2018-02-04 00:11:48,172 training [INFO ] Epoch 50 Batch10220 Training err. 1.24967 Training err. RA 1.55690 Valid. err. 1.53581
2018-02-04 00:11:48,645 training [INFO ] Epoch 50 Batch10240 Training err. 1.27101 Training err. RA 1.55634 Valid. err. 1.53148
2018-02-04 00:11:49,120 training [INFO ] Epoch 50 Batch10260 Training err. 1.31693 Training err. RA 1.55587 Valid. err. 1.53649
2018-02-04 00:11:49,597 training [INFO ] Epoch 50 Batch10280 Training err. 1.26766 Training err. RA 1.55531 Valid. err. 1.56176
2018-02-04 00:11:50,080 training [INFO ] Epoch 50 Batch10300 Training err. 1.24890 Training err. RA 1.55472 Valid. err. 1.54240
2018-02-04 00:11:50,561 training [INFO ] Epoch 50 Batch10320 Training err. 1.31253 Training err. RA 1.55425 Valid. err. 1.52658
2018-02-04 00:11:51,041 training [INFO ] Epoch 50 Batch10340 Training err. 1.24694 Training err. RA 1.55365 Valid. err. 1.54844
2018-02-04 00:11:51,528 training [INFO ] Epoch 50 Batch10360 Training err. 1.23594 Training err. RA 1.55304 Valid. err. 1.54976
2018-02-04 00:11:52,009 training [INFO ] Epoch 50 Batch10380 Training err. 1.25777 Training err. RA 1.55247 Valid. err. 1.52747
2018-02-04 00:11:52,489 training [INFO ] Epoch 50 Batch10400 Training err. 1.26778 Training err. RA 1.55192 Valid. err. 1.55568
2018-02-04 00:11:53,338 training [INFO ] Epoch 51 Batch10420 Training err. 1.26412 Training err. RA 1.55137 Valid. err. 1.51393
2018-02-04 00:11:53,814 training [INFO ] Epoch 51 Batch10440 Training err. 1.21924 Training err. RA 1.55073 Valid. err. 1.53153
2018-02-04 00:11:54,294 training [INFO ] Epoch 51 Batch10460 Training err. 1.28598 Training err. RA 1.55023 Valid. err. 1.55751
2018-02-04 00:11:54,769 training [INFO ] Epoch 51 Batch10480 Training err. 1.30142 Training err. RA 1.54975 Valid. err. 1.53851
2018-02-04 00:11:55,243 training [INFO ] Epoch 51 Batch10500 Training err. 1.22943 Training err. RA 1.54914 Valid. err. 1.55662
2018-02-04 00:11:55,723 training [INFO ] Epoch 51 Batch10520 Training err. 1.28142 Training err. RA 1.54863 Valid. err. 1.53700
2018-02-04 00:11:56,202 training [INFO ] Epoch 51 Batch10540 Training err. 1.27352 Training err. RA 1.54811 Valid. err. 1.55055
2018-02-04 00:11:56,681 training [INFO ] Epoch 51 Batch10560 Training err. 1.22759 Training err. RA 1.54750 Valid. err. 1.59000
2018-02-04 00:11:57,167 training [INFO ] Epoch 51 Batch10580 Training err. 1.24239 Training err. RA 1.54693 Valid. err. 1.53800
2018-02-04 00:11:57,648 training [INFO ] Epoch 51 Batch10600 Training err. 1.26130 Training err. RA 1.54639 Valid. err. 1.52833
2018-02-04 00:11:58,482 training [INFO ] Epoch 52 Batch10620 Training err. 1.26049 Training err. RA 1.54585 Valid. err. 1.53137
2018-02-04 00:11:58,963 training [INFO ] Epoch 52 Batch10640 Training err. 1.23236 Training err. RA 1.54526 Valid. err. 1.54844
2018-02-04 00:11:59,444 training [INFO ] Epoch 52 Batch10660 Training err. 1.28318 Training err. RA 1.54477 Valid. err. 1.52635
2018-02-04 00:11:59,925 training [INFO ] Epoch 52 Batch10680 Training err. 1.30090 Training err. RA 1.54431 Valid. err. 1.53655
2018-02-04 00:12:00,420 training [INFO ] Epoch 52 Batch10700 Training err. 1.23625 Training err. RA 1.54374 Valid. err. 1.55190
2018-02-04 00:12:00,902 training [INFO ] Epoch 52 Batch10720 Training err. 1.24639 Training err. RA 1.54318 Valid. err. 1.53139
2018-02-04 00:12:01,376 training [INFO ] Epoch 52 Batch10740 Training err. 1.30516 Training err. RA 1.54274 Valid. err. 1.53504
2018-02-04 00:12:01,859 training [INFO ] Epoch 52 Batch10760 Training err. 1.21542 Training err. RA 1.54213 Valid. err. 1.53105
2018-02-04 00:12:02,332 training [INFO ] Epoch 52 Batch10780 Training err. 1.24675 Training err. RA 1.54158 Valid. err. 1.63077
2018-02-04 00:12:02,809 training [INFO ] Epoch 52 Batch10800 Training err. 1.25061 Training err. RA 1.54104 Valid. err. 1.52360
2018-02-04 00:12:03,673 training [INFO ] Epoch 53 Batch10820 Training err. 1.24122 Training err. RA 1.54049 Valid. err. 1.52486
2018-02-04 00:12:04,148 training [INFO ] Epoch 53 Batch10840 Training err. 1.23525 Training err. RA 1.53993 Valid. err. 1.51761
2018-02-04 00:12:04,628 training [INFO ] Epoch 53 Batch10860 Training err. 1.25016 Training err. RA 1.53939 Valid. err. 1.53275
2018-02-04 00:12:05,108 training [INFO ] Epoch 53 Batch10880 Training err. 1.28682 Training err. RA 1.53893 Valid. err. 1.53389
2018-02-04 00:12:05,589 training [INFO ] Epoch 53 Batch10900 Training err. 1.27841 Training err. RA 1.53845 Valid. err. 1.54741
2018-02-04 00:12:06,069 training [INFO ] Epoch 53 Batch10920 Training err. 1.23868 Training err. RA 1.53790 Valid. err. 1.53646
2018-02-04 00:12:06,556 training [INFO ] Epoch 53 Batch10940 Training err. 1.29860 Training err. RA 1.53746 Valid. err. 1.54906
2018-02-04 00:12:07,036 training [INFO ] Epoch 53 Batch10960 Training err. 1.22876 Training err. RA 1.53690 Valid. err. 1.53284
2018-02-04 00:12:07,547 training [INFO ] Epoch 53 Batch10980 Training err. 1.23135 Training err. RA 1.53634 Valid. err. 1.59978
2018-02-04 00:12:08,036 training [INFO ] Epoch 53 Batch11000 Training err. 1.21537 Training err. RA 1.53576 Valid. err. 1.53831
2018-02-04 00:12:08,515 training [INFO ] Epoch 53 Batch11020 Training err. 1.26340 Training err. RA 1.53527 Valid. err. 1.52666
2018-02-04 00:12:09,370 training [INFO ] Epoch 54 Batch11040 Training err. 1.24441 Training err. RA 1.53474 Valid. err. 1.53634
2018-02-04 00:12:09,847 training [INFO ] Epoch 54 Batch11060 Training err. 1.21055 Training err. RA 1.53415 Valid. err. 1.53517
2018-02-04 00:12:10,321 training [INFO ] Epoch 54 Batch11080 Training err. 1.26178 Training err. RA 1.53366 Valid. err. 1.53705
2018-02-04 00:12:10,801 training [INFO ] Epoch 54 Batch11100 Training err. 1.28490 Training err. RA 1.53321 Valid. err. 1.53465
2018-02-04 00:12:11,278 training [INFO ] Epoch 54 Batch11120 Training err. 1.22193 Training err. RA 1.53265 Valid. err. 1.60115
2018-02-04 00:12:11,751 training [INFO ] Epoch 54 Batch11140 Training err. 1.28427 Training err. RA 1.53221 Valid. err. 1.54293
2018-02-04 00:12:12,235 training [INFO ] Epoch 54 Batch11160 Training err. 1.27758 Training err. RA 1.53175 Valid. err. 1.55687
2018-02-04 00:12:12,713 training [INFO ] Epoch 54 Batch11180 Training err. 1.21535 Training err. RA 1.53118 Valid. err. 1.54624
2018-02-04 00:12:13,192 training [INFO ] Epoch 54 Batch11200 Training err. 1.23529 Training err. RA 1.53066 Valid. err. 1.53704
2018-02-04 00:12:13,673 training [INFO ] Epoch 54 Batch11220 Training err. 1.22634 Training err. RA 1.53011 Valid. err. 1.55407
2018-02-04 00:12:14,520 training [INFO ] Epoch 55 Batch11240 Training err. 1.23139 Training err. RA 1.52958 Valid. err. 1.49831
2018-02-04 00:12:14,997 training [INFO ] Epoch 55 Batch11260 Training err. 1.22579 Training err. RA 1.52904 Valid. err. 1.53383
2018-02-04 00:12:15,485 training [INFO ] Epoch 55 Batch11280 Training err. 1.24152 Training err. RA 1.52853 Valid. err. 1.52812
2018-02-04 00:12:15,967 training [INFO ] Epoch 55 Batch11300 Training err. 1.29724 Training err. RA 1.52812 Valid. err. 1.53513
2018-02-04 00:12:16,447 training [INFO ] Epoch 55 Batch11320 Training err. 1.25319 Training err. RA 1.52764 Valid. err. 1.55650
2018-02-04 00:12:16,939 training [INFO ] Epoch 55 Batch11340 Training err. 1.25017 Training err. RA 1.52715 Valid. err. 1.55470
2018-02-04 00:12:17,416 training [INFO ] Epoch 55 Batch11360 Training err. 1.29827 Training err. RA 1.52674 Valid. err. 1.53743
2018-02-04 00:12:17,899 training [INFO ] Epoch 55 Batch11380 Training err. 1.21825 Training err. RA 1.52620 Valid. err. 1.53249
2018-02-04 00:12:18,379 training [INFO ] Epoch 55 Batch11400 Training err. 1.22017 Training err. RA 1.52567 Valid. err. 1.55869
2018-02-04 00:12:18,856 training [INFO ] Epoch 55 Batch11420 Training err. 1.22691 Training err. RA 1.52514 Valid. err. 1.52986
2018-02-04 00:12:19,334 training [INFO ] Epoch 55 Batch11440 Training err. 1.24932 Training err. RA 1.52466 Valid. err. 1.53374
2018-02-04 00:12:20,149 training [INFO ] Epoch 56 Batch11460 Training err. 1.24936 Training err. RA 1.52418 Valid. err. 1.50928
2018-02-04 00:12:20,623 training [INFO ] Epoch 56 Batch11480 Training err. 1.19223 Training err. RA 1.52360 Valid. err. 1.54728
2018-02-04 00:12:21,104 training [INFO ] Epoch 56 Batch11500 Training err. 1.26975 Training err. RA 1.52316 Valid. err. 1.54868
2018-02-04 00:12:21,587 training [INFO ] Epoch 56 Batch11520 Training err. 1.28101 Training err. RA 1.52274 Valid. err. 1.53220
2018-02-04 00:12:22,067 training [INFO ] Epoch 56 Batch11540 Training err. 1.21021 Training err. RA 1.52220 Valid. err. 1.53216
2018-02-04 00:12:22,550 training [INFO ] Epoch 56 Batch11560 Training err. 1.26588 Training err. RA 1.52175 Valid. err. 1.53621
2018-02-04 00:12:23,036 training [INFO ] Epoch 56 Batch11580 Training err. 1.25515 Training err. RA 1.52129 Valid. err. 1.52283
2018-02-04 00:12:23,518 training [INFO ] Epoch 56 Batch11600 Training err. 1.20726 Training err. RA 1.52075 Valid. err. 1.57105
2018-02-04 00:12:23,997 training [INFO ] Epoch 56 Batch11620 Training err. 1.23183 Training err. RA 1.52026 Valid. err. 1.51917
2018-02-04 00:12:24,482 training [INFO ] Epoch 56 Batch11640 Training err. 1.24558 Training err. RA 1.51978 Valid. err. 1.52350
2018-02-04 00:12:25,332 training [INFO ] Epoch 57 Batch11660 Training err. 1.22245 Training err. RA 1.51927 Valid. err. 1.51691
2018-02-04 00:12:25,821 training [INFO ] Epoch 57 Batch11680 Training err. 1.20583 Training err. RA 1.51874 Valid. err. 1.52186
2018-02-04 00:12:26,296 training [INFO ] Epoch 57 Batch11700 Training err. 1.24368 Training err. RA 1.51827 Valid. err. 1.50821
2018-02-04 00:12:26,771 training [INFO ] Epoch 57 Batch11720 Training err. 1.26606 Training err. RA 1.51784 Valid. err. 1.54271
2018-02-04 00:12:27,255 training [INFO ] Epoch 57 Batch11740 Training err. 1.22901 Training err. RA 1.51734 Valid. err. 1.53813
2018-02-04 00:12:27,728 training [INFO ] Epoch 57 Batch11760 Training err. 1.23392 Training err. RA 1.51686 Valid. err. 1.51498
2018-02-04 00:12:28,203 training [INFO ] Epoch 57 Batch11780 Training err. 1.29639 Training err. RA 1.51649 Valid. err. 1.54949
2018-02-04 00:12:28,683 training [INFO ] Epoch 57 Batch11800 Training err. 1.20142 Training err. RA 1.51595 Valid. err. 1.54577
2018-02-04 00:12:29,159 training [INFO ] Epoch 57 Batch11820 Training err. 1.23448 Training err. RA 1.51548 Valid. err. 1.56797
2018-02-04 00:12:29,637 training [INFO ] Epoch 57 Batch11840 Training err. 1.22507 Training err. RA 1.51499 Valid. err. 1.51565
2018-02-04 00:12:30,485 training [INFO ] Epoch 58 Batch11860 Training err. 1.22888 Training err. RA 1.51450 Valid. err. 1.53964
2018-02-04 00:12:30,967 training [INFO ] Epoch 58 Batch11880 Training err. 1.21580 Training err. RA 1.51400 Valid. err. 1.53559
2018-02-04 00:12:31,448 training [INFO ] Epoch 58 Batch11900 Training err. 1.20998 Training err. RA 1.51349 Valid. err. 1.54892
2018-02-04 00:12:31,935 training [INFO ] Epoch 58 Batch11920 Training err. 1.26607 Training err. RA 1.51308 Valid. err. 1.54236
2018-02-04 00:12:32,415 training [INFO ] Epoch 58 Batch11940 Training err. 1.25070 Training err. RA 1.51264 Valid. err. 1.55840
2018-02-04 00:12:32,894 training [INFO ] Epoch 58 Batch11960 Training err. 1.21237 Training err. RA 1.51213 Valid. err. 1.51883
2018-02-04 00:12:33,374 training [INFO ] Epoch 58 Batch11980 Training err. 1.27782 Training err. RA 1.51174 Valid. err. 1.54456
2018-02-04 00:12:33,850 training [INFO ] Epoch 58 Batch12000 Training err. 1.21392 Training err. RA 1.51125 Valid. err. 1.54711
2018-02-04 00:12:34,325 training [INFO ] Epoch 58 Batch12020 Training err. 1.22919 Training err. RA 1.51078 Valid. err. 1.62441
2018-02-04 00:12:34,807 training [INFO ] Epoch 58 Batch12040 Training err. 1.20825 Training err. RA 1.51027 Valid. err. 1.53036
2018-02-04 00:12:35,282 training [INFO ] Epoch 58 Batch12060 Training err. 1.24019 Training err. RA 1.50983 Valid. err. 1.50981
2018-02-04 00:12:36,141 training [INFO ] Epoch 59 Batch12080 Training err. 1.20828 Training err. RA 1.50933 Valid. err. 1.52164
2018-02-04 00:12:36,613 training [INFO ] Epoch 59 Batch12100 Training err. 1.18472 Training err. RA 1.50879 Valid. err. 1.52710
2018-02-04 00:12:37,094 training [INFO ] Epoch 59 Batch12120 Training err. 1.23987 Training err. RA 1.50835 Valid. err. 1.52338
2018-02-04 00:12:37,575 training [INFO ] Epoch 59 Batch12140 Training err. 1.26565 Training err. RA 1.50795 Valid. err. 1.53750
2018-02-04 00:12:38,061 training [INFO ] Epoch 59 Batch12160 Training err. 1.20686 Training err. RA 1.50745 Valid. err. 1.57425
2018-02-04 00:12:38,541 training [INFO ] Epoch 59 Batch12180 Training err. 1.25927 Training err. RA 1.50704 Valid. err. 1.54161
2018-02-04 00:12:39,023 training [INFO ] Epoch 59 Batch12200 Training err. 1.26001 Training err. RA 1.50664 Valid. err. 1.54847
2018-02-04 00:12:39,506 training [INFO ] Epoch 59 Batch12220 Training err. 1.20032 Training err. RA 1.50614 Valid. err. 1.53469
2018-02-04 00:12:39,986 training [INFO ] Epoch 59 Batch12240 Training err. 1.21627 Training err. RA 1.50566 Valid. err. 1.52296
2018-02-04 00:12:40,466 training [INFO ] Epoch 59 Batch12260 Training err. 1.20912 Training err. RA 1.50518 Valid. err. 1.55025
2018-02-04 00:12:41,302 training [INFO ] Epoch 60 Batch12280 Training err. 1.21677 Training err. RA 1.50471 Valid. err. 1.53296
2018-02-04 00:12:41,779 training [INFO ] Epoch 60 Batch12300 Training err. 1.20882 Training err. RA 1.50423 Valid. err. 1.56464
2018-02-04 00:12:42,261 training [INFO ] Epoch 60 Batch12320 Training err. 1.22446 Training err. RA 1.50378 Valid. err. 1.52571
2018-02-04 00:12:42,736 training [INFO ] Epoch 60 Batch12340 Training err. 1.26845 Training err. RA 1.50339 Valid. err. 1.51513
2018-02-04 00:12:43,212 training [INFO ] Epoch 60 Batch12360 Training err. 1.21804 Training err. RA 1.50293 Valid. err. 1.55831
2018-02-04 00:12:43,693 training [INFO ] Epoch 60 Batch12380 Training err. 1.20823 Training err. RA 1.50246 Valid. err. 1.55136
2018-02-04 00:12:44,164 training [INFO ] Epoch 60 Batch12400 Training err. 1.26682 Training err. RA 1.50208 Valid. err. 1.53810
2018-02-04 00:12:44,642 training [INFO ] Epoch 60 Batch12420 Training err. 1.20687 Training err. RA 1.50160 Valid. err. 1.52081
2018-02-04 00:12:45,127 training [INFO ] Epoch 60 Batch12440 Training err. 1.19065 Training err. RA 1.50110 Valid. err. 1.54338
2018-02-04 00:12:45,608 training [INFO ] Epoch 60 Batch12460 Training err. 1.20019 Training err. RA 1.50062 Valid. err. 1.52766
2018-02-04 00:12:46,088 training [INFO ] Epoch 60 Batch12480 Training err. 1.21963 Training err. RA 1.50017 Valid. err. 1.53125
2018-02-04 00:12:46,356 __main__ [INFO ] End of training
2018-02-04 00:12:46,671 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 10,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-04 00:12:47,499 training [INFO ] Epoch  1 Batch   20 Training err. 4.22586 Training err. RA 4.22586 Valid. err. 4.14682
2018-02-04 00:12:47,999 training [INFO ] Epoch  1 Batch   40 Training err. 4.03778 Training err. RA 4.13182 Valid. err. 3.95536
2018-02-04 00:12:48,508 training [INFO ] Epoch  1 Batch   60 Training err. 3.81806 Training err. RA 4.02723 Valid. err. 3.70906
2018-02-04 00:12:49,001 training [INFO ] Epoch  1 Batch   80 Training err. 3.59906 Training err. RA 3.92019 Valid. err. 3.50614
2018-02-04 00:12:49,494 training [INFO ] Epoch  1 Batch  100 Training err. 3.41544 Training err. RA 3.81924 Valid. err. 3.36655
2018-02-04 00:12:50,311 training [INFO ] Epoch  2 Batch  120 Training err. 3.29822 Training err. RA 3.73240 Valid. err. 3.29072
2018-02-04 00:12:50,804 training [INFO ] Epoch  2 Batch  140 Training err. 3.20338 Training err. RA 3.65683 Valid. err. 3.25479
2018-02-04 00:12:51,303 training [INFO ] Epoch  2 Batch  160 Training err. 3.19334 Training err. RA 3.59889 Valid. err. 3.23046
2018-02-04 00:12:51,796 training [INFO ] Epoch  2 Batch  180 Training err. 3.18727 Training err. RA 3.55315 Valid. err. 3.21615
2018-02-04 00:12:52,290 training [INFO ] Epoch  2 Batch  200 Training err. 3.17677 Training err. RA 3.51552 Valid. err. 3.20683
2018-02-04 00:12:53,146 training [INFO ] Epoch  3 Batch  220 Training err. 3.18607 Training err. RA 3.48557 Valid. err. 3.20199
2018-02-04 00:12:53,648 training [INFO ] Epoch  3 Batch  240 Training err. 3.11936 Training err. RA 3.45505 Valid. err. 3.20864
2018-02-04 00:12:54,164 training [INFO ] Epoch  3 Batch  260 Training err. 3.15884 Training err. RA 3.43226 Valid. err. 3.19326
2018-02-04 00:12:54,670 training [INFO ] Epoch  3 Batch  280 Training err. 3.14087 Training err. RA 3.41145 Valid. err. 3.19023
2018-02-04 00:12:55,176 training [INFO ] Epoch  3 Batch  300 Training err. 3.15007 Training err. RA 3.39402 Valid. err. 3.18963
2018-02-04 00:12:56,013 training [INFO ] Epoch  4 Batch  320 Training err. 3.17091 Training err. RA 3.38008 Valid. err. 3.18533
2018-02-04 00:12:56,516 training [INFO ] Epoch  4 Batch  340 Training err. 3.11947 Training err. RA 3.36475 Valid. err. 3.19373
2018-02-04 00:12:57,174 training [INFO ] Epoch  4 Batch  360 Training err. 3.14089 Training err. RA 3.35231 Valid. err. 3.18450
2018-02-04 00:12:57,831 training [INFO ] Epoch  4 Batch  380 Training err. 3.12577 Training err. RA 3.34039 Valid. err. 3.18349
2018-02-04 00:12:58,489 training [INFO ] Epoch  4 Batch  400 Training err. 3.13783 Training err. RA 3.33026 Valid. err. 3.18372
2018-02-04 00:12:59,648 training [INFO ] Epoch  5 Batch  420 Training err. 3.16492 Training err. RA 3.32239 Valid. err. 3.18409
2018-02-04 00:13:00,350 training [INFO ] Epoch  5 Batch  440 Training err. 3.13327 Training err. RA 3.31379 Valid. err. 3.18767
2018-02-04 00:13:00,958 training [INFO ] Epoch  5 Batch  460 Training err. 3.12491 Training err. RA 3.30558 Valid. err. 3.18061
2018-02-04 00:13:01,479 training [INFO ] Epoch  5 Batch  480 Training err. 3.10762 Training err. RA 3.29733 Valid. err. 3.18102
2018-02-04 00:13:01,978 training [INFO ] Epoch  5 Batch  500 Training err. 3.14178 Training err. RA 3.29111 Valid. err. 3.18206
2018-02-04 00:13:02,470 training [INFO ] Epoch  5 Batch  520 Training err. 3.16144 Training err. RA 3.28612 Valid. err. 3.17858
2018-02-04 00:13:03,281 training [INFO ] Epoch  6 Batch  540 Training err. 3.13812 Training err. RA 3.28064 Valid. err. 3.18040
2018-02-04 00:13:03,774 training [INFO ] Epoch  6 Batch  560 Training err. 3.11247 Training err. RA 3.27463 Valid. err. 3.18027
2018-02-04 00:13:04,267 training [INFO ] Epoch  6 Batch  580 Training err. 3.09851 Training err. RA 3.26856 Valid. err. 3.18186
2018-02-04 00:13:04,770 training [INFO ] Epoch  6 Batch  600 Training err. 3.14734 Training err. RA 3.26452 Valid. err. 3.17844
2018-02-04 00:13:05,278 training [INFO ] Epoch  6 Batch  620 Training err. 3.14605 Training err. RA 3.26070 Valid. err. 3.17694
2018-02-04 00:13:06,142 training [INFO ] Epoch  7 Batch  640 Training err. 3.14889 Training err. RA 3.25720 Valid. err. 3.17781
2018-02-04 00:13:06,644 training [INFO ] Epoch  7 Batch  660 Training err. 3.10063 Training err. RA 3.25246 Valid. err. 3.17849
2018-02-04 00:13:07,152 training [INFO ] Epoch  7 Batch  680 Training err. 3.11463 Training err. RA 3.24841 Valid. err. 3.17822
2018-02-04 00:13:07,659 training [INFO ] Epoch  7 Batch  700 Training err. 3.13269 Training err. RA 3.24510 Valid. err. 3.17655
2018-02-04 00:13:08,163 training [INFO ] Epoch  7 Batch  720 Training err. 3.13497 Training err. RA 3.24204 Valid. err. 3.17546
2018-02-04 00:13:08,995 training [INFO ] Epoch  8 Batch  740 Training err. 3.15525 Training err. RA 3.23970 Valid. err. 3.17752
2018-02-04 00:13:09,494 training [INFO ] Epoch  8 Batch  760 Training err. 3.09046 Training err. RA 3.23577 Valid. err. 3.18769
2018-02-04 00:13:09,986 training [INFO ] Epoch  8 Batch  780 Training err. 3.13075 Training err. RA 3.23308 Valid. err. 3.17527
2018-02-04 00:13:10,478 training [INFO ] Epoch  8 Batch  800 Training err. 3.11844 Training err. RA 3.23021 Valid. err. 3.17441
2018-02-04 00:13:10,978 training [INFO ] Epoch  8 Batch  820 Training err. 3.13029 Training err. RA 3.22777 Valid. err. 3.17557
2018-02-04 00:13:11,812 training [INFO ] Epoch  9 Batch  840 Training err. 3.15313 Training err. RA 3.22599 Valid. err. 3.17192
2018-02-04 00:13:12,307 training [INFO ] Epoch  9 Batch  860 Training err. 3.10320 Training err. RA 3.22314 Valid. err. 3.18151
2018-02-04 00:13:12,799 training [INFO ] Epoch  9 Batch  880 Training err. 3.12376 Training err. RA 3.22088 Valid. err. 3.17261
2018-02-04 00:13:13,291 training [INFO ] Epoch  9 Batch  900 Training err. 3.10955 Training err. RA 3.21841 Valid. err. 3.17214
2018-02-04 00:13:13,787 training [INFO ] Epoch  9 Batch  920 Training err. 3.12313 Training err. RA 3.21634 Valid. err. 3.17242
2018-02-04 00:13:14,589 training [INFO ] Epoch 10 Batch  940 Training err. 3.15064 Training err. RA 3.21494 Valid. err. 3.17286
2018-02-04 00:13:15,080 training [INFO ] Epoch 10 Batch  960 Training err. 3.11910 Training err. RA 3.21294 Valid. err. 3.17721
2018-02-04 00:13:15,577 training [INFO ] Epoch 10 Batch  980 Training err. 3.11109 Training err. RA 3.21086 Valid. err. 3.16939
2018-02-04 00:13:16,069 training [INFO ] Epoch 10 Batch 1000 Training err. 3.09339 Training err. RA 3.20851 Valid. err. 3.16973
2018-02-04 00:13:16,566 training [INFO ] Epoch 10 Batch 1020 Training err. 3.12773 Training err. RA 3.20693 Valid. err. 3.17062
2018-02-04 00:13:17,075 training [INFO ] Epoch 10 Batch 1040 Training err. 3.14715 Training err. RA 3.20578 Valid. err. 3.16691
2018-02-04 00:13:17,937 training [INFO ] Epoch 11 Batch 1060 Training err. 3.12458 Training err. RA 3.20425 Valid. err. 3.16856
2018-02-04 00:13:18,447 training [INFO ] Epoch 11 Batch 1080 Training err. 3.09931 Training err. RA 3.20230 Valid. err. 3.16822
2018-02-04 00:13:18,953 training [INFO ] Epoch 11 Batch 1100 Training err. 3.08407 Training err. RA 3.20015 Valid. err. 3.16941
2018-02-04 00:13:19,459 training [INFO ] Epoch 11 Batch 1120 Training err. 3.13265 Training err. RA 3.19895 Valid. err. 3.16575
2018-02-04 00:13:19,969 training [INFO ] Epoch 11 Batch 1140 Training err. 3.13158 Training err. RA 3.19777 Valid. err. 3.16388
2018-02-04 00:13:20,799 training [INFO ] Epoch 12 Batch 1160 Training err. 3.13450 Training err. RA 3.19668 Valid. err. 3.16439
2018-02-04 00:13:21,300 training [INFO ] Epoch 12 Batch 1180 Training err. 3.08692 Training err. RA 3.19482 Valid. err. 3.16468
2018-02-04 00:13:21,794 training [INFO ] Epoch 12 Batch 1200 Training err. 3.09871 Training err. RA 3.19321 Valid. err. 3.16412
2018-02-04 00:13:22,287 training [INFO ] Epoch 12 Batch 1220 Training err. 3.11752 Training err. RA 3.19197 Valid. err. 3.16188
2018-02-04 00:13:22,787 training [INFO ] Epoch 12 Batch 1240 Training err. 3.11895 Training err. RA 3.19080 Valid. err. 3.16023
2018-02-04 00:13:23,615 training [INFO ] Epoch 13 Batch 1260 Training err. 3.13929 Training err. RA 3.18998 Valid. err. 3.16244
2018-02-04 00:13:24,104 training [INFO ] Epoch 13 Batch 1280 Training err. 3.07549 Training err. RA 3.18819 Valid. err. 3.17175
2018-02-04 00:13:24,597 training [INFO ] Epoch 13 Batch 1300 Training err. 3.11271 Training err. RA 3.18703 Valid. err. 3.15860
2018-02-04 00:13:25,106 training [INFO ] Epoch 13 Batch 1320 Training err. 3.10133 Training err. RA 3.18573 Valid. err. 3.15700
2018-02-04 00:13:25,615 training [INFO ] Epoch 13 Batch 1340 Training err. 3.11157 Training err. RA 3.18462 Valid. err. 3.15764
2018-02-04 00:13:26,447 training [INFO ] Epoch 14 Batch 1360 Training err. 3.13465 Training err. RA 3.18389 Valid. err. 3.15319
2018-02-04 00:13:26,954 training [INFO ] Epoch 14 Batch 1380 Training err. 3.08506 Training err. RA 3.18246 Valid. err. 3.16235
2018-02-04 00:13:27,463 training [INFO ] Epoch 14 Batch 1400 Training err. 3.10444 Training err. RA 3.18134 Valid. err. 3.15249
2018-02-04 00:13:27,966 training [INFO ] Epoch 14 Batch 1420 Training err. 3.08874 Training err. RA 3.18004 Valid. err. 3.15120
2018-02-04 00:13:28,472 training [INFO ] Epoch 14 Batch 1440 Training err. 3.10130 Training err. RA 3.17894 Valid. err. 3.15032
2018-02-04 00:13:29,317 training [INFO ] Epoch 15 Batch 1460 Training err. 3.12901 Training err. RA 3.17826 Valid. err. 3.14986
2018-02-04 00:13:29,811 training [INFO ] Epoch 15 Batch 1480 Training err. 3.09573 Training err. RA 3.17714 Valid. err. 3.15512
2018-02-04 00:13:30,304 training [INFO ] Epoch 15 Batch 1500 Training err. 3.08930 Training err. RA 3.17597 Valid. err. 3.14441
2018-02-04 00:13:30,797 training [INFO ] Epoch 15 Batch 1520 Training err. 3.06789 Training err. RA 3.17455 Valid. err. 3.14345
2018-02-04 00:13:31,289 training [INFO ] Epoch 15 Batch 1540 Training err. 3.10100 Training err. RA 3.17360 Valid. err. 3.14296
2018-02-04 00:13:31,784 training [INFO ] Epoch 15 Batch 1560 Training err. 3.11946 Training err. RA 3.17290 Valid. err. 3.13768
2018-02-04 00:13:32,589 training [INFO ] Epoch 16 Batch 1580 Training err. 3.09584 Training err. RA 3.17193 Valid. err. 3.13795
2018-02-04 00:13:33,076 training [INFO ] Epoch 16 Batch 1600 Training err. 3.07301 Training err. RA 3.17069 Valid. err. 3.13631
2018-02-04 00:13:33,574 training [INFO ] Epoch 16 Batch 1620 Training err. 3.05178 Training err. RA 3.16922 Valid. err. 3.13516
2018-02-04 00:13:34,081 training [INFO ] Epoch 16 Batch 1640 Training err. 3.09787 Training err. RA 3.16835 Valid. err. 3.13000
2018-02-04 00:13:34,587 training [INFO ] Epoch 16 Batch 1660 Training err. 3.09646 Training err. RA 3.16748 Valid. err. 3.12584
2018-02-04 00:13:35,456 training [INFO ] Epoch 17 Batch 1680 Training err. 3.09837 Training err. RA 3.16666 Valid. err. 3.12443
2018-02-04 00:13:35,965 training [INFO ] Epoch 17 Batch 1700 Training err. 3.05252 Training err. RA 3.16532 Valid. err. 3.12270
2018-02-04 00:13:36,474 training [INFO ] Epoch 17 Batch 1720 Training err. 3.05557 Training err. RA 3.16404 Valid. err. 3.12034
2018-02-04 00:13:36,967 training [INFO ] Epoch 17 Batch 1740 Training err. 3.07443 Training err. RA 3.16301 Valid. err. 3.11455
2018-02-04 00:13:37,457 training [INFO ] Epoch 17 Batch 1760 Training err. 3.07248 Training err. RA 3.16198 Valid. err. 3.11005
2018-02-04 00:13:38,270 training [INFO ] Epoch 18 Batch 1780 Training err. 3.09199 Training err. RA 3.16120 Valid. err. 3.11570
2018-02-04 00:13:38,765 training [INFO ] Epoch 18 Batch 1800 Training err. 3.03018 Training err. RA 3.15974 Valid. err. 3.11575
2018-02-04 00:13:39,266 training [INFO ] Epoch 18 Batch 1820 Training err. 3.05581 Training err. RA 3.15860 Valid. err. 3.09932
2018-02-04 00:13:39,767 training [INFO ] Epoch 18 Batch 1840 Training err. 3.04470 Training err. RA 3.15736 Valid. err. 3.09400
2018-02-04 00:13:40,264 training [INFO ] Epoch 18 Batch 1860 Training err. 3.04826 Training err. RA 3.15619 Valid. err. 3.09206
2018-02-04 00:13:41,104 training [INFO ] Epoch 19 Batch 1880 Training err. 3.07203 Training err. RA 3.15529 Valid. err. 3.08260
2018-02-04 00:13:41,594 training [INFO ] Epoch 19 Batch 1900 Training err. 3.02093 Training err. RA 3.15388 Valid. err. 3.09183
2018-02-04 00:13:42,102 training [INFO ] Epoch 19 Batch 1920 Training err. 3.03589 Training err. RA 3.15265 Valid. err. 3.07435
2018-02-04 00:13:42,609 training [INFO ] Epoch 19 Batch 1940 Training err. 3.01221 Training err. RA 3.15120 Valid. err. 3.06811
2018-02-04 00:13:43,117 training [INFO ] Epoch 19 Batch 1960 Training err. 3.01981 Training err. RA 3.14986 Valid. err. 3.06233
2018-02-04 00:13:43,959 training [INFO ] Epoch 20 Batch 1980 Training err. 3.04797 Training err. RA 3.14883 Valid. err. 3.05871
2018-02-04 00:13:44,457 training [INFO ] Epoch 20 Batch 2000 Training err. 3.00625 Training err. RA 3.14741 Valid. err. 3.06614
2018-02-04 00:13:44,947 training [INFO ] Epoch 20 Batch 2020 Training err. 3.00592 Training err. RA 3.14601 Valid. err. 3.04452
2018-02-04 00:13:45,442 training [INFO ] Epoch 20 Batch 2040 Training err. 2.97025 Training err. RA 3.14428 Valid. err. 3.03767
2018-02-04 00:13:45,939 training [INFO ] Epoch 20 Batch 2060 Training err. 2.99783 Training err. RA 3.14286 Valid. err. 3.03066
2018-02-04 00:13:46,432 training [INFO ] Epoch 20 Batch 2080 Training err. 3.01325 Training err. RA 3.14161 Valid. err. 3.02270
2018-02-04 00:13:47,265 training [INFO ] Epoch 21 Batch 2100 Training err. 2.98579 Training err. RA 3.14013 Valid. err. 3.01726
2018-02-04 00:13:47,756 training [INFO ] Epoch 21 Batch 2120 Training err. 2.97086 Training err. RA 3.13853 Valid. err. 3.01170
2018-02-04 00:13:48,252 training [INFO ] Epoch 21 Batch 2140 Training err. 2.93158 Training err. RA 3.13660 Valid. err. 3.02587
2018-02-04 00:13:48,739 training [INFO ] Epoch 21 Batch 2160 Training err. 2.97115 Training err. RA 3.13507 Valid. err. 2.99657
2018-02-04 00:13:49,236 training [INFO ] Epoch 21 Batch 2180 Training err. 2.96939 Training err. RA 3.13355 Valid. err. 2.98589
2018-02-04 00:13:50,074 training [INFO ] Epoch 22 Batch 2200 Training err. 2.97053 Training err. RA 3.13207 Valid. err. 2.98352
2018-02-04 00:13:50,570 training [INFO ] Epoch 22 Batch 2220 Training err. 2.92620 Training err. RA 3.13021 Valid. err. 2.97700
2018-02-04 00:13:51,071 training [INFO ] Epoch 22 Batch 2240 Training err. 2.91335 Training err. RA 3.12827 Valid. err. 2.96923
2018-02-04 00:13:51,575 training [INFO ] Epoch 22 Batch 2260 Training err. 2.93896 Training err. RA 3.12660 Valid. err. 2.96021
2018-02-04 00:13:52,079 training [INFO ] Epoch 22 Batch 2280 Training err. 2.92512 Training err. RA 3.12483 Valid. err. 2.95361
2018-02-04 00:13:52,941 training [INFO ] Epoch 23 Batch 2300 Training err. 2.94713 Training err. RA 3.12329 Valid. err. 2.97647
2018-02-04 00:13:53,436 training [INFO ] Epoch 23 Batch 2320 Training err. 2.88723 Training err. RA 3.12125 Valid. err. 2.95226
2018-02-04 00:13:53,927 training [INFO ] Epoch 23 Batch 2340 Training err. 2.90112 Training err. RA 3.11937 Valid. err. 2.93597
2018-02-04 00:13:54,423 training [INFO ] Epoch 23 Batch 2360 Training err. 2.90074 Training err. RA 3.11752 Valid. err. 2.92919
2018-02-04 00:13:54,911 training [INFO ] Epoch 23 Batch 2380 Training err. 2.88512 Training err. RA 3.11556 Valid. err. 2.92373
2018-02-04 00:13:55,723 training [INFO ] Epoch 24 Batch 2400 Training err. 2.91497 Training err. RA 3.11389 Valid. err. 2.91289
2018-02-04 00:13:56,213 training [INFO ] Epoch 24 Batch 2420 Training err. 2.86627 Training err. RA 3.11185 Valid. err. 2.94500
2018-02-04 00:13:56,711 training [INFO ] Epoch 24 Batch 2440 Training err. 2.87856 Training err. RA 3.10993 Valid. err. 2.91594
2018-02-04 00:13:57,223 training [INFO ] Epoch 24 Batch 2460 Training err. 2.86183 Training err. RA 3.10792 Valid. err. 2.89514
2018-02-04 00:13:57,733 training [INFO ] Epoch 24 Batch 2480 Training err. 2.85240 Training err. RA 3.10586 Valid. err. 2.89007
2018-02-04 00:13:58,580 training [INFO ] Epoch 25 Batch 2500 Training err. 2.88388 Training err. RA 3.10408 Valid. err. 2.89872
2018-02-04 00:13:59,083 training [INFO ] Epoch 25 Batch 2520 Training err. 2.84834 Training err. RA 3.10205 Valid. err. 2.89442
2018-02-04 00:13:59,583 training [INFO ] Epoch 25 Batch 2540 Training err. 2.84702 Training err. RA 3.10004 Valid. err. 2.87881
2018-02-04 00:14:00,084 training [INFO ] Epoch 25 Batch 2560 Training err. 2.81880 Training err. RA 3.09785 Valid. err. 2.87605
2018-02-04 00:14:00,590 training [INFO ] Epoch 25 Batch 2580 Training err. 2.83174 Training err. RA 3.09578 Valid. err. 2.86020
2018-02-04 00:14:01,082 training [INFO ] Epoch 25 Batch 2600 Training err. 2.85357 Training err. RA 3.09392 Valid. err. 2.86244
2018-02-04 00:14:01,901 training [INFO ] Epoch 26 Batch 2620 Training err. 2.83317 Training err. RA 3.09193 Valid. err. 2.84922
2018-02-04 00:14:02,390 training [INFO ] Epoch 26 Batch 2640 Training err. 2.80721 Training err. RA 3.08977 Valid. err. 2.84709
2018-02-04 00:14:02,878 training [INFO ] Epoch 26 Batch 2660 Training err. 2.78259 Training err. RA 3.08746 Valid. err. 2.92115
2018-02-04 00:14:03,376 training [INFO ] Epoch 26 Batch 2680 Training err. 2.81773 Training err. RA 3.08545 Valid. err. 2.83364
2018-02-04 00:14:03,869 training [INFO ] Epoch 26 Batch 2700 Training err. 2.81286 Training err. RA 3.08343 Valid. err. 2.84137
2018-02-04 00:14:04,702 training [INFO ] Epoch 27 Batch 2720 Training err. 2.82226 Training err. RA 3.08151 Valid. err. 2.84044
2018-02-04 00:14:05,200 training [INFO ] Epoch 27 Batch 2740 Training err. 2.76636 Training err. RA 3.07921 Valid. err. 2.81893
2018-02-04 00:14:05,700 training [INFO ] Epoch 27 Batch 2760 Training err. 2.77379 Training err. RA 3.07700 Valid. err. 2.81377
2018-02-04 00:14:06,207 training [INFO ] Epoch 27 Batch 2780 Training err. 2.79080 Training err. RA 3.07494 Valid. err. 2.81584
2018-02-04 00:14:06,705 training [INFO ] Epoch 27 Batch 2800 Training err. 2.76697 Training err. RA 3.07274 Valid. err. 2.80879
2018-02-04 00:14:07,543 training [INFO ] Epoch 28 Batch 2820 Training err. 2.80641 Training err. RA 3.07085 Valid. err. 2.85438
2018-02-04 00:14:08,055 training [INFO ] Epoch 28 Batch 2840 Training err. 2.73356 Training err. RA 3.06847 Valid. err. 2.82453
2018-02-04 00:14:08,581 training [INFO ] Epoch 28 Batch 2860 Training err. 2.77123 Training err. RA 3.06640 Valid. err. 2.77962
2018-02-04 00:14:09,091 training [INFO ] Epoch 28 Batch 2880 Training err. 2.74979 Training err. RA 3.06420 Valid. err. 2.77966
2018-02-04 00:14:09,626 training [INFO ] Epoch 28 Batch 2900 Training err. 2.73449 Training err. RA 3.06192 Valid. err. 2.77094
2018-02-04 00:14:10,532 training [INFO ] Epoch 29 Batch 2920 Training err. 2.77644 Training err. RA 3.05997 Valid. err. 2.77770
2018-02-04 00:14:11,222 training [INFO ] Epoch 29 Batch 2940 Training err. 2.72405 Training err. RA 3.05768 Valid. err. 2.79633
2018-02-04 00:14:11,835 training [INFO ] Epoch 29 Batch 2960 Training err. 2.74503 Training err. RA 3.05557 Valid. err. 2.75958
2018-02-04 00:14:12,430 training [INFO ] Epoch 29 Batch 2980 Training err. 2.71214 Training err. RA 3.05326 Valid. err. 2.75350
2018-02-04 00:14:13,022 training [INFO ] Epoch 29 Batch 3000 Training err. 2.70536 Training err. RA 3.05095 Valid. err. 2.74357
2018-02-04 00:14:14,070 training [INFO ] Epoch 30 Batch 3020 Training err. 2.73688 Training err. RA 3.04887 Valid. err. 2.77973
2018-02-04 00:14:14,705 training [INFO ] Epoch 30 Batch 3040 Training err. 2.72531 Training err. RA 3.04674 Valid. err. 2.74637
2018-02-04 00:14:15,339 training [INFO ] Epoch 30 Batch 3060 Training err. 2.70109 Training err. RA 3.04448 Valid. err. 2.76120
2018-02-04 00:14:15,946 training [INFO ] Epoch 30 Batch 3080 Training err. 2.67124 Training err. RA 3.04205 Valid. err. 2.74826
2018-02-04 00:14:16,544 training [INFO ] Epoch 30 Batch 3100 Training err. 2.69286 Training err. RA 3.03980 Valid. err. 2.72750
2018-02-04 00:14:17,157 training [INFO ] Epoch 30 Batch 3120 Training err. 2.70932 Training err. RA 3.03768 Valid. err. 2.75388
2018-02-04 00:14:18,165 training [INFO ] Epoch 31 Batch 3140 Training err. 2.71480 Training err. RA 3.03563 Valid. err. 2.72381
2018-02-04 00:14:18,766 training [INFO ] Epoch 31 Batch 3160 Training err. 2.66402 Training err. RA 3.03327 Valid. err. 2.72111
2018-02-04 00:14:19,371 training [INFO ] Epoch 31 Batch 3180 Training err. 2.64955 Training err. RA 3.03086 Valid. err. 2.70703
2018-02-04 00:14:19,969 training [INFO ] Epoch 31 Batch 3200 Training err. 2.68241 Training err. RA 3.02868 Valid. err. 2.70286
2018-02-04 00:14:20,564 training [INFO ] Epoch 31 Batch 3220 Training err. 2.67488 Training err. RA 3.02649 Valid. err. 2.69566
2018-02-04 00:14:21,640 training [INFO ] Epoch 32 Batch 3240 Training err. 2.69470 Training err. RA 3.02444 Valid. err. 2.69361
2018-02-04 00:14:22,234 training [INFO ] Epoch 32 Batch 3260 Training err. 2.62742 Training err. RA 3.02200 Valid. err. 2.70448
2018-02-04 00:14:22,839 training [INFO ] Epoch 32 Batch 3280 Training err. 2.66227 Training err. RA 3.01981 Valid. err. 2.68645
2018-02-04 00:14:23,448 training [INFO ] Epoch 32 Batch 3300 Training err. 2.65699 Training err. RA 3.01761 Valid. err. 2.70842
2018-02-04 00:14:24,045 training [INFO ] Epoch 32 Batch 3320 Training err. 2.64155 Training err. RA 3.01534 Valid. err. 2.66851
2018-02-04 00:14:25,026 training [INFO ] Epoch 33 Batch 3340 Training err. 2.68167 Training err. RA 3.01335 Valid. err. 2.67146
2018-02-04 00:14:25,622 training [INFO ] Epoch 33 Batch 3360 Training err. 2.61292 Training err. RA 3.01096 Valid. err. 2.67497
2018-02-04 00:14:26,222 training [INFO ] Epoch 33 Batch 3380 Training err. 2.65633 Training err. RA 3.00886 Valid. err. 2.66102
2018-02-04 00:14:26,817 training [INFO ] Epoch 33 Batch 3400 Training err. 2.62165 Training err. RA 3.00659 Valid. err. 2.65835
2018-02-04 00:14:27,423 training [INFO ] Epoch 33 Batch 3420 Training err. 2.62566 Training err. RA 3.00436 Valid. err. 2.65569
2018-02-04 00:14:28,396 training [INFO ] Epoch 34 Batch 3440 Training err. 2.66064 Training err. RA 3.00236 Valid. err. 2.66040
2018-02-04 00:14:28,994 training [INFO ] Epoch 34 Batch 3460 Training err. 2.60383 Training err. RA 3.00006 Valid. err. 2.65439
2018-02-04 00:14:29,601 training [INFO ] Epoch 34 Batch 3480 Training err. 2.63663 Training err. RA 2.99797 Valid. err. 2.64577
2018-02-04 00:14:30,207 training [INFO ] Epoch 34 Batch 3500 Training err. 2.60066 Training err. RA 2.99570 Valid. err. 2.64872
2018-02-04 00:14:30,803 training [INFO ] Epoch 34 Batch 3520 Training err. 2.61008 Training err. RA 2.99351 Valid. err. 2.64472
2018-02-04 00:14:31,804 training [INFO ] Epoch 35 Batch 3540 Training err. 2.63161 Training err. RA 2.99146 Valid. err. 2.65922
2018-02-04 00:14:32,415 training [INFO ] Epoch 35 Batch 3560 Training err. 2.60959 Training err. RA 2.98932 Valid. err. 2.64276
2018-02-04 00:14:33,011 training [INFO ] Epoch 35 Batch 3580 Training err. 2.60437 Training err. RA 2.98717 Valid. err. 2.64347
2018-02-04 00:14:33,609 training [INFO ] Epoch 35 Batch 3600 Training err. 2.56964 Training err. RA 2.98485 Valid. err. 2.63182
2018-02-04 00:14:34,204 training [INFO ] Epoch 35 Batch 3620 Training err. 2.60013 Training err. RA 2.98272 Valid. err. 2.63868
2018-02-04 00:14:34,812 training [INFO ] Epoch 35 Batch 3640 Training err. 2.61999 Training err. RA 2.98073 Valid. err. 2.66163
2018-02-04 00:14:35,769 training [INFO ] Epoch 36 Batch 3660 Training err. 2.60501 Training err. RA 2.97867 Valid. err. 2.61764
2018-02-04 00:14:36,362 training [INFO ] Epoch 36 Batch 3680 Training err. 2.56745 Training err. RA 2.97644 Valid. err. 2.61803
2018-02-04 00:14:36,960 training [INFO ] Epoch 36 Batch 3700 Training err. 2.56006 Training err. RA 2.97419 Valid. err. 2.60705
2018-02-04 00:14:37,561 training [INFO ] Epoch 36 Batch 3720 Training err. 2.59487 Training err. RA 2.97215 Valid. err. 2.60245
2018-02-04 00:14:38,168 training [INFO ] Epoch 36 Batch 3740 Training err. 2.58501 Training err. RA 2.97008 Valid. err. 2.60559
2018-02-04 00:14:39,198 training [INFO ] Epoch 37 Batch 3760 Training err. 2.60001 Training err. RA 2.96811 Valid. err. 2.61084
2018-02-04 00:14:39,807 training [INFO ] Epoch 37 Batch 3780 Training err. 2.54219 Training err. RA 2.96586 Valid. err. 2.59904
2018-02-04 00:14:40,403 training [INFO ] Epoch 37 Batch 3800 Training err. 2.57113 Training err. RA 2.96378 Valid. err. 2.59446
2018-02-04 00:14:41,025 training [INFO ] Epoch 37 Batch 3820 Training err. 2.56781 Training err. RA 2.96171 Valid. err. 2.60356
2018-02-04 00:14:41,631 training [INFO ] Epoch 37 Batch 3840 Training err. 2.55677 Training err. RA 2.95960 Valid. err. 2.58536
2018-02-04 00:14:42,603 training [INFO ] Epoch 38 Batch 3860 Training err. 2.59468 Training err. RA 2.95771 Valid. err. 2.58098
2018-02-04 00:14:43,193 training [INFO ] Epoch 38 Batch 3880 Training err. 2.52160 Training err. RA 2.95546 Valid. err. 2.59199
2018-02-04 00:14:43,715 training [INFO ] Epoch 38 Batch 3900 Training err. 2.57277 Training err. RA 2.95350 Valid. err. 2.57618
2018-02-04 00:14:44,235 training [INFO ] Epoch 38 Batch 3920 Training err. 2.54163 Training err. RA 2.95140 Valid. err. 2.57916
2018-02-04 00:14:44,772 training [INFO ] Epoch 38 Batch 3940 Training err. 2.54257 Training err. RA 2.94932 Valid. err. 2.57129
2018-02-04 00:14:45,633 training [INFO ] Epoch 39 Batch 3960 Training err. 2.57408 Training err. RA 2.94743 Valid. err. 2.56996
2018-02-04 00:14:46,153 training [INFO ] Epoch 39 Batch 3980 Training err. 2.52808 Training err. RA 2.94532 Valid. err. 2.57570
2018-02-04 00:14:46,666 training [INFO ] Epoch 39 Batch 4000 Training err. 2.55205 Training err. RA 2.94335 Valid. err. 2.57088
2018-02-04 00:14:47,160 training [INFO ] Epoch 39 Batch 4020 Training err. 2.52412 Training err. RA 2.94127 Valid. err. 2.56869
2018-02-04 00:14:47,766 training [INFO ] Epoch 39 Batch 4040 Training err. 2.52747 Training err. RA 2.93922 Valid. err. 2.56961
2018-02-04 00:14:48,592 training [INFO ] Epoch 40 Batch 4060 Training err. 2.55173 Training err. RA 2.93731 Valid. err. 2.56696
2018-02-04 00:14:49,087 training [INFO ] Epoch 40 Batch 4080 Training err. 2.53588 Training err. RA 2.93534 Valid. err. 2.55635
2018-02-04 00:14:49,587 training [INFO ] Epoch 40 Batch 4100 Training err. 2.51905 Training err. RA 2.93331 Valid. err. 2.56490
2018-02-04 00:14:50,092 training [INFO ] Epoch 40 Batch 4120 Training err. 2.49841 Training err. RA 2.93120 Valid. err. 2.54486
2018-02-04 00:14:50,598 training [INFO ] Epoch 40 Batch 4140 Training err. 2.52218 Training err. RA 2.92922 Valid. err. 2.56562
2018-02-04 00:14:51,121 training [INFO ] Epoch 40 Batch 4160 Training err. 2.54461 Training err. RA 2.92737 Valid. err. 2.57191
2018-02-04 00:14:51,978 training [INFO ] Epoch 41 Batch 4180 Training err. 2.53405 Training err. RA 2.92549 Valid. err. 2.55265
2018-02-04 00:14:52,479 training [INFO ] Epoch 41 Batch 4200 Training err. 2.48332 Training err. RA 2.92339 Valid. err. 2.53802
2018-02-04 00:14:53,106 training [INFO ] Epoch 41 Batch 4220 Training err. 2.49181 Training err. RA 2.92134 Valid. err. 2.52985
2018-02-04 00:14:53,804 training [INFO ] Epoch 41 Batch 4240 Training err. 2.51816 Training err. RA 2.91944 Valid. err. 2.52878
2018-02-04 00:14:54,463 training [INFO ] Epoch 41 Batch 4260 Training err. 2.51427 Training err. RA 2.91754 Valid. err. 2.53625
2018-02-04 00:14:55,570 training [INFO ] Epoch 42 Batch 4280 Training err. 2.52878 Training err. RA 2.91572 Valid. err. 2.54898
2018-02-04 00:14:56,344 training [INFO ] Epoch 42 Batch 4300 Training err. 2.46526 Training err. RA 2.91363 Valid. err. 2.52411
2018-02-04 00:14:56,962 training [INFO ] Epoch 42 Batch 4320 Training err. 2.50356 Training err. RA 2.91173 Valid. err. 2.52651
2018-02-04 00:14:57,498 training [INFO ] Epoch 42 Batch 4340 Training err. 2.49605 Training err. RA 2.90981 Valid. err. 2.52761
2018-02-04 00:14:58,130 training [INFO ] Epoch 42 Batch 4360 Training err. 2.48692 Training err. RA 2.90787 Valid. err. 2.51475
2018-02-04 00:14:59,080 training [INFO ] Epoch 43 Batch 4380 Training err. 2.52482 Training err. RA 2.90612 Valid. err. 2.52083
2018-02-04 00:14:59,675 training [INFO ] Epoch 43 Batch 4400 Training err. 2.44998 Training err. RA 2.90405 Valid. err. 2.51007
2018-02-04 00:15:00,293 training [INFO ] Epoch 43 Batch 4420 Training err. 2.50546 Training err. RA 2.90225 Valid. err. 2.51111
2018-02-04 00:15:00,905 training [INFO ] Epoch 43 Batch 4440 Training err. 2.47422 Training err. RA 2.90032 Valid. err. 2.51017
2018-02-04 00:15:01,515 training [INFO ] Epoch 43 Batch 4460 Training err. 2.47508 Training err. RA 2.89841 Valid. err. 2.50352
2018-02-04 00:15:02,517 training [INFO ] Epoch 44 Batch 4480 Training err. 2.50421 Training err. RA 2.89665 Valid. err. 2.49862
2018-02-04 00:15:03,133 training [INFO ] Epoch 44 Batch 4500 Training err. 2.46266 Training err. RA 2.89472 Valid. err. 2.50043
2018-02-04 00:15:03,730 training [INFO ] Epoch 44 Batch 4520 Training err. 2.48388 Training err. RA 2.89290 Valid. err. 2.51179
2018-02-04 00:15:04,325 training [INFO ] Epoch 44 Batch 4540 Training err. 2.46155 Training err. RA 2.89100 Valid. err. 2.49909
2018-02-04 00:15:04,934 training [INFO ] Epoch 44 Batch 4560 Training err. 2.46206 Training err. RA 2.88912 Valid. err. 2.50808
2018-02-04 00:15:05,925 training [INFO ] Epoch 45 Batch 4580 Training err. 2.48375 Training err. RA 2.88735 Valid. err. 2.49832
2018-02-04 00:15:06,519 training [INFO ] Epoch 45 Batch 4600 Training err. 2.47355 Training err. RA 2.88555 Valid. err. 2.48966
2018-02-04 00:15:07,123 training [INFO ] Epoch 45 Batch 4620 Training err. 2.45243 Training err. RA 2.88368 Valid. err. 2.50311
2018-02-04 00:15:07,735 training [INFO ] Epoch 45 Batch 4640 Training err. 2.44011 Training err. RA 2.88177 Valid. err. 2.47816
2018-02-04 00:15:08,329 training [INFO ] Epoch 45 Batch 4660 Training err. 2.45778 Training err. RA 2.87995 Valid. err. 2.49495
2018-02-04 00:15:08,925 training [INFO ] Epoch 45 Batch 4680 Training err. 2.47872 Training err. RA 2.87823 Valid. err. 2.50313
2018-02-04 00:15:09,899 training [INFO ] Epoch 46 Batch 4700 Training err. 2.47343 Training err. RA 2.87651 Valid. err. 2.49059
2018-02-04 00:15:10,494 training [INFO ] Epoch 46 Batch 4720 Training err. 2.41924 Training err. RA 2.87457 Valid. err. 2.47313
2018-02-04 00:15:11,087 training [INFO ] Epoch 46 Batch 4740 Training err. 2.43470 Training err. RA 2.87272 Valid. err. 2.46759
2018-02-04 00:15:11,681 training [INFO ] Epoch 46 Batch 4760 Training err. 2.45688 Training err. RA 2.87097 Valid. err. 2.46640
2018-02-04 00:15:12,279 training [INFO ] Epoch 46 Batch 4780 Training err. 2.44915 Training err. RA 2.86920 Valid. err. 2.47117
2018-02-04 00:15:13,269 training [INFO ] Epoch 47 Batch 4800 Training err. 2.46708 Training err. RA 2.86753 Valid. err. 2.48752
2018-02-04 00:15:13,872 training [INFO ] Epoch 47 Batch 4820 Training err. 2.40605 Training err. RA 2.86561 Valid. err. 2.46967
2018-02-04 00:15:14,475 training [INFO ] Epoch 47 Batch 4840 Training err. 2.44628 Training err. RA 2.86388 Valid. err. 2.46509
2018-02-04 00:15:15,068 training [INFO ] Epoch 47 Batch 4860 Training err. 2.43601 Training err. RA 2.86212 Valid. err. 2.46900
2018-02-04 00:15:15,680 training [INFO ] Epoch 47 Batch 4880 Training err. 2.42554 Training err. RA 2.86033 Valid. err. 2.45154
2018-02-04 00:15:16,695 training [INFO ] Epoch 48 Batch 4900 Training err. 2.46392 Training err. RA 2.85871 Valid. err. 2.44937
2018-02-04 00:15:17,435 training [INFO ] Epoch 48 Batch 4920 Training err. 2.39095 Training err. RA 2.85681 Valid. err. 2.44923
2018-02-04 00:15:18,162 training [INFO ] Epoch 48 Batch 4940 Training err. 2.44887 Training err. RA 2.85516 Valid. err. 2.44960
2018-02-04 00:15:18,895 training [INFO ] Epoch 48 Batch 4960 Training err. 2.41715 Training err. RA 2.85339 Valid. err. 2.44910
2018-02-04 00:15:19,636 training [INFO ] Epoch 48 Batch 4980 Training err. 2.41599 Training err. RA 2.85164 Valid. err. 2.44306
2018-02-04 00:15:20,863 training [INFO ] Epoch 49 Batch 5000 Training err. 2.44342 Training err. RA 2.85000 Valid. err. 2.43903
2018-02-04 00:15:21,506 training [INFO ] Epoch 49 Batch 5020 Training err. 2.40556 Training err. RA 2.84823 Valid. err. 2.44409
2018-02-04 00:15:22,121 training [INFO ] Epoch 49 Batch 5040 Training err. 2.42821 Training err. RA 2.84657 Valid. err. 2.45542
2018-02-04 00:15:22,743 training [INFO ] Epoch 49 Batch 5060 Training err. 2.40560 Training err. RA 2.84482 Valid. err. 2.44735
2018-02-04 00:15:23,354 training [INFO ] Epoch 49 Batch 5080 Training err. 2.40529 Training err. RA 2.84309 Valid. err. 2.45204
2018-02-04 00:15:24,416 training [INFO ] Epoch 50 Batch 5100 Training err. 2.42312 Training err. RA 2.84145 Valid. err. 2.44999
2018-02-04 00:15:25,034 training [INFO ] Epoch 50 Batch 5120 Training err. 2.41803 Training err. RA 2.83979 Valid. err. 2.43565
2018-02-04 00:15:25,656 training [INFO ] Epoch 50 Batch 5140 Training err. 2.39681 Training err. RA 2.83807 Valid. err. 2.44963
2018-02-04 00:15:26,272 training [INFO ] Epoch 50 Batch 5160 Training err. 2.38599 Training err. RA 2.83632 Valid. err. 2.42221
2018-02-04 00:15:26,914 training [INFO ] Epoch 50 Batch 5180 Training err. 2.40156 Training err. RA 2.83464 Valid. err. 2.43849
2018-02-04 00:15:27,525 training [INFO ] Epoch 50 Batch 5200 Training err. 2.42038 Training err. RA 2.83304 Valid. err. 2.44241
2018-02-04 00:15:28,611 training [INFO ] Epoch 51 Batch 5220 Training err. 2.41783 Training err. RA 2.83145 Valid. err. 2.44224
2018-02-04 00:15:29,209 training [INFO ] Epoch 51 Batch 5240 Training err. 2.36485 Training err. RA 2.82967 Valid. err. 2.42028
2018-02-04 00:15:29,806 training [INFO ] Epoch 51 Batch 5260 Training err. 2.38171 Training err. RA 2.82797 Valid. err. 2.41426
2018-02-04 00:15:30,405 training [INFO ] Epoch 51 Batch 5280 Training err. 2.40264 Training err. RA 2.82636 Valid. err. 2.41353
2018-02-04 00:15:31,010 training [INFO ] Epoch 51 Batch 5300 Training err. 2.39460 Training err. RA 2.82473 Valid. err. 2.41442
2018-02-04 00:15:31,998 training [INFO ] Epoch 52 Batch 5320 Training err. 2.41163 Training err. RA 2.82318 Valid. err. 2.42975
2018-02-04 00:15:32,495 training [INFO ] Epoch 52 Batch 5340 Training err. 2.35302 Training err. RA 2.82141 Valid. err. 2.41655
2018-02-04 00:15:33,025 training [INFO ] Epoch 52 Batch 5360 Training err. 2.39301 Training err. RA 2.81982 Valid. err. 2.41300
2018-02-04 00:15:33,552 training [INFO ] Epoch 52 Batch 5380 Training err. 2.38330 Training err. RA 2.81819 Valid. err. 2.41805
2018-02-04 00:15:34,059 training [INFO ] Epoch 52 Batch 5400 Training err. 2.37387 Training err. RA 2.81655 Valid. err. 2.39711
2018-02-04 00:15:34,952 training [INFO ] Epoch 53 Batch 5420 Training err. 2.40879 Training err. RA 2.81504 Valid. err. 2.40411
2018-02-04 00:15:35,502 training [INFO ] Epoch 53 Batch 5440 Training err. 2.34097 Training err. RA 2.81330 Valid. err. 2.39687
2018-02-04 00:15:36,008 training [INFO ] Epoch 53 Batch 5460 Training err. 2.39434 Training err. RA 2.81177 Valid. err. 2.39718
2018-02-04 00:15:36,518 training [INFO ] Epoch 53 Batch 5480 Training err. 2.36553 Training err. RA 2.81014 Valid. err. 2.39563
2018-02-04 00:15:37,016 training [INFO ] Epoch 53 Batch 5500 Training err. 2.36547 Training err. RA 2.80852 Valid. err. 2.39075
2018-02-04 00:15:37,856 training [INFO ] Epoch 54 Batch 5520 Training err. 2.38835 Training err. RA 2.80700 Valid. err. 2.38869
2018-02-04 00:15:38,347 training [INFO ] Epoch 54 Batch 5540 Training err. 2.35644 Training err. RA 2.80537 Valid. err. 2.39147
2018-02-04 00:15:38,837 training [INFO ] Epoch 54 Batch 5560 Training err. 2.37548 Training err. RA 2.80382 Valid. err. 2.40443
2018-02-04 00:15:39,333 training [INFO ] Epoch 54 Batch 5580 Training err. 2.35449 Training err. RA 2.80221 Valid. err. 2.39200
2018-02-04 00:15:39,837 training [INFO ] Epoch 54 Batch 5600 Training err. 2.35641 Training err. RA 2.80062 Valid. err. 2.40687
2018-02-04 00:15:40,729 training [INFO ] Epoch 55 Batch 5620 Training err. 2.36943 Training err. RA 2.79909 Valid. err. 2.40089
2018-02-04 00:15:41,240 training [INFO ] Epoch 55 Batch 5640 Training err. 2.36950 Training err. RA 2.79756 Valid. err. 2.38478
2018-02-04 00:15:41,802 training [INFO ] Epoch 55 Batch 5660 Training err. 2.34402 Training err. RA 2.79596 Valid. err. 2.40229
2018-02-04 00:15:42,366 training [INFO ] Epoch 55 Batch 5680 Training err. 2.33815 Training err. RA 2.79435 Valid. err. 2.37612
2018-02-04 00:15:42,939 training [INFO ] Epoch 55 Batch 5700 Training err. 2.35231 Training err. RA 2.79280 Valid. err. 2.39425
2018-02-04 00:15:43,505 training [INFO ] Epoch 55 Batch 5720 Training err. 2.36844 Training err. RA 2.79131 Valid. err. 2.39239
2018-02-04 00:15:44,426 training [INFO ] Epoch 56 Batch 5740 Training err. 2.37194 Training err. RA 2.78985 Valid. err. 2.39271
2018-02-04 00:15:45,038 training [INFO ] Epoch 56 Batch 5760 Training err. 2.31337 Training err. RA 2.78820 Valid. err. 2.37016
2018-02-04 00:15:45,760 training [INFO ] Epoch 56 Batch 5780 Training err. 2.33254 Training err. RA 2.78662 Valid. err. 2.36834
2018-02-04 00:15:46,454 training [INFO ] Epoch 56 Batch 5800 Training err. 2.35410 Training err. RA 2.78513 Valid. err. 2.36502
2018-02-04 00:15:47,170 training [INFO ] Epoch 56 Batch 5820 Training err. 2.34573 Training err. RA 2.78362 Valid. err. 2.36468
2018-02-04 00:15:48,364 training [INFO ] Epoch 57 Batch 5840 Training err. 2.36368 Training err. RA 2.78218 Valid. err. 2.38221
2018-02-04 00:15:49,028 training [INFO ] Epoch 57 Batch 5860 Training err. 2.30537 Training err. RA 2.78056 Valid. err. 2.36629
2018-02-04 00:15:49,640 training [INFO ] Epoch 57 Batch 5880 Training err. 2.34223 Training err. RA 2.77906 Valid. err. 2.36647
2018-02-04 00:15:50,258 training [INFO ] Epoch 57 Batch 5900 Training err. 2.33619 Training err. RA 2.77756 Valid. err. 2.37153
2018-02-04 00:15:50,880 training [INFO ] Epoch 57 Batch 5920 Training err. 2.32713 Training err. RA 2.77604 Valid. err. 2.35010
2018-02-04 00:15:51,886 training [INFO ] Epoch 58 Batch 5940 Training err. 2.36081 Training err. RA 2.77464 Valid. err. 2.36018
2018-02-04 00:15:52,466 training [INFO ] Epoch 58 Batch 5960 Training err. 2.29537 Training err. RA 2.77303 Valid. err. 2.35062
2018-02-04 00:15:53,047 training [INFO ] Epoch 58 Batch 5980 Training err. 2.34312 Training err. RA 2.77160 Valid. err. 2.35086
2018-02-04 00:15:53,607 training [INFO ] Epoch 58 Batch 6000 Training err. 2.32121 Training err. RA 2.77010 Valid. err. 2.34888
2018-02-04 00:15:54,196 training [INFO ] Epoch 58 Batch 6020 Training err. 2.31893 Training err. RA 2.76860 Valid. err. 2.34522
2018-02-04 00:15:55,119 training [INFO ] Epoch 59 Batch 6040 Training err. 2.33864 Training err. RA 2.76717 Valid. err. 2.34531
2018-02-04 00:15:55,695 training [INFO ] Epoch 59 Batch 6060 Training err. 2.31279 Training err. RA 2.76567 Valid. err. 2.34572
2018-02-04 00:15:56,266 training [INFO ] Epoch 59 Batch 6080 Training err. 2.32488 Training err. RA 2.76422 Valid. err. 2.36518
2018-02-04 00:15:56,822 training [INFO ] Epoch 59 Batch 6100 Training err. 2.31110 Training err. RA 2.76274 Valid. err. 2.34406
2018-02-04 00:15:57,399 training [INFO ] Epoch 59 Batch 6120 Training err. 2.31131 Training err. RA 2.76126 Valid. err. 2.36722
2018-02-04 00:15:58,334 training [INFO ] Epoch 60 Batch 6140 Training err. 2.31972 Training err. RA 2.75982 Valid. err. 2.36475
2018-02-04 00:15:58,873 training [INFO ] Epoch 60 Batch 6160 Training err. 2.32690 Training err. RA 2.75842 Valid. err. 2.33933
2018-02-04 00:15:59,445 training [INFO ] Epoch 60 Batch 6180 Training err. 2.29500 Training err. RA 2.75692 Valid. err. 2.35001
2018-02-04 00:16:00,002 training [INFO ] Epoch 60 Batch 6200 Training err. 2.29456 Training err. RA 2.75543 Valid. err. 2.33775
2018-02-04 00:16:00,573 training [INFO ] Epoch 60 Batch 6220 Training err. 2.30599 Training err. RA 2.75398 Valid. err. 2.35826
2018-02-04 00:16:01,113 training [INFO ] Epoch 60 Batch 6240 Training err. 2.32110 Training err. RA 2.75260 Valid. err. 2.35098
2018-02-04 00:16:01,355 __main__ [INFO ] End of training
2018-02-04 00:16:01,683 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-04 00:16:02,376 training [INFO ] Epoch  1 Batch   20 Training err. 3.63647 Training err. RA 3.63647 Valid. err. 3.25046
2018-02-04 00:16:02,941 training [INFO ] Epoch  1 Batch   40 Training err. 3.17616 Training err. RA 3.40631 Valid. err. 3.19396
2018-02-04 00:16:03,491 training [INFO ] Epoch  1 Batch   60 Training err. 3.14429 Training err. RA 3.31897 Valid. err. 3.38954
2018-02-04 00:16:03,997 training [INFO ] Epoch  1 Batch   80 Training err. 3.16566 Training err. RA 3.28064 Valid. err. 3.18160
2018-02-04 00:16:04,504 training [INFO ] Epoch  1 Batch  100 Training err. 3.14525 Training err. RA 3.25356 Valid. err. 3.17036
2018-02-04 00:16:05,499 training [INFO ] Epoch  2 Batch  120 Training err. 3.14835 Training err. RA 3.23603 Valid. err. 3.17714
2018-02-04 00:16:06,159 training [INFO ] Epoch  2 Batch  140 Training err. 3.09946 Training err. RA 3.21652 Valid. err. 3.16291
2018-02-04 00:16:06,815 training [INFO ] Epoch  2 Batch  160 Training err. 3.09205 Training err. RA 3.20096 Valid. err. 3.16423
2018-02-04 00:16:07,499 training [INFO ] Epoch  2 Batch  180 Training err. 3.12471 Training err. RA 3.19249 Valid. err. 3.14002
2018-02-04 00:16:08,201 training [INFO ] Epoch  2 Batch  200 Training err. 3.09125 Training err. RA 3.18236 Valid. err. 3.12262
2018-02-04 00:16:09,244 training [INFO ] Epoch  3 Batch  220 Training err. 3.09681 Training err. RA 3.17459 Valid. err. 3.15947
2018-02-04 00:16:09,807 training [INFO ] Epoch  3 Batch  240 Training err. 3.03069 Training err. RA 3.16259 Valid. err. 3.11464
2018-02-04 00:16:10,418 training [INFO ] Epoch  3 Batch  260 Training err. 3.02917 Training err. RA 3.15233 Valid. err. 3.03350
2018-02-04 00:16:11,002 training [INFO ] Epoch  3 Batch  280 Training err. 2.99192 Training err. RA 3.14087 Valid. err. 2.98803
2018-02-04 00:16:11,613 training [INFO ] Epoch  3 Batch  300 Training err. 2.93729 Training err. RA 3.12730 Valid. err. 2.93684
2018-02-04 00:16:12,567 training [INFO ] Epoch  4 Batch  320 Training err. 2.92831 Training err. RA 3.11486 Valid. err. 2.90021
2018-02-04 00:16:13,082 training [INFO ] Epoch  4 Batch  340 Training err. 2.86050 Training err. RA 3.09990 Valid. err. 2.94683
2018-02-04 00:16:13,584 training [INFO ] Epoch  4 Batch  360 Training err. 2.83715 Training err. RA 3.08530 Valid. err. 2.83676
2018-02-04 00:16:14,094 training [INFO ] Epoch  4 Batch  380 Training err. 2.77187 Training err. RA 3.06881 Valid. err. 2.84979
2018-02-04 00:16:14,600 training [INFO ] Epoch  4 Batch  400 Training err. 2.75556 Training err. RA 3.05314 Valid. err. 2.75569
2018-02-04 00:16:15,467 training [INFO ] Epoch  5 Batch  420 Training err. 2.74987 Training err. RA 3.03870 Valid. err. 2.73636
2018-02-04 00:16:15,984 training [INFO ] Epoch  5 Batch  440 Training err. 2.69931 Training err. RA 3.02328 Valid. err. 2.69074
2018-02-04 00:16:16,486 training [INFO ] Epoch  5 Batch  460 Training err. 2.66794 Training err. RA 3.00783 Valid. err. 2.66503
2018-02-04 00:16:16,987 training [INFO ] Epoch  5 Batch  480 Training err. 2.59792 Training err. RA 2.99075 Valid. err. 2.62452
2018-02-04 00:16:17,481 training [INFO ] Epoch  5 Batch  500 Training err. 2.61485 Training err. RA 2.97571 Valid. err. 2.61120
2018-02-04 00:16:17,976 training [INFO ] Epoch  5 Batch  520 Training err. 2.60081 Training err. RA 2.96129 Valid. err. 2.57505
2018-02-04 00:16:18,804 training [INFO ] Epoch  6 Batch  540 Training err. 2.58198 Training err. RA 2.94724 Valid. err. 2.61407
2018-02-04 00:16:19,293 training [INFO ] Epoch  6 Batch  560 Training err. 2.51081 Training err. RA 2.93166 Valid. err. 2.58006
2018-02-04 00:16:19,794 training [INFO ] Epoch  6 Batch  580 Training err. 2.49656 Training err. RA 2.91665 Valid. err. 2.52271
2018-02-04 00:16:20,291 training [INFO ] Epoch  6 Batch  600 Training err. 2.49289 Training err. RA 2.90253 Valid. err. 2.55698
2018-02-04 00:16:20,783 training [INFO ] Epoch  6 Batch  620 Training err. 2.48540 Training err. RA 2.88907 Valid. err. 2.46101
2018-02-04 00:16:21,645 training [INFO ] Epoch  7 Batch  640 Training err. 2.47130 Training err. RA 2.87602 Valid. err. 2.53880
2018-02-04 00:16:22,152 training [INFO ] Epoch  7 Batch  660 Training err. 2.40478 Training err. RA 2.86174 Valid. err. 2.44269
2018-02-04 00:16:22,663 training [INFO ] Epoch  7 Batch  680 Training err. 2.42217 Training err. RA 2.84881 Valid. err. 2.49138
2018-02-04 00:16:23,168 training [INFO ] Epoch  7 Batch  700 Training err. 2.39453 Training err. RA 2.83583 Valid. err. 2.41518
2018-02-04 00:16:23,670 training [INFO ] Epoch  7 Batch  720 Training err. 2.36459 Training err. RA 2.82274 Valid. err. 2.42104
2018-02-04 00:16:24,530 training [INFO ] Epoch  8 Batch  740 Training err. 2.40004 Training err. RA 2.81131 Valid. err. 2.37805
2018-02-04 00:16:25,028 training [INFO ] Epoch  8 Batch  760 Training err. 2.31411 Training err. RA 2.79823 Valid. err. 2.38484
2018-02-04 00:16:25,530 training [INFO ] Epoch  8 Batch  780 Training err. 2.34010 Training err. RA 2.78648 Valid. err. 2.32941
2018-02-04 00:16:26,033 training [INFO ] Epoch  8 Batch  800 Training err. 2.31694 Training err. RA 2.77475 Valid. err. 2.31636
2018-02-04 00:16:26,526 training [INFO ] Epoch  8 Batch  820 Training err. 2.27982 Training err. RA 2.76267 Valid. err. 2.30434
2018-02-04 00:16:27,365 training [INFO ] Epoch  9 Batch  840 Training err. 2.30566 Training err. RA 2.75179 Valid. err. 2.29880
2018-02-04 00:16:27,855 training [INFO ] Epoch  9 Batch  860 Training err. 2.27290 Training err. RA 2.74066 Valid. err. 2.29213
2018-02-04 00:16:28,348 training [INFO ] Epoch  9 Batch  880 Training err. 2.24983 Training err. RA 2.72950 Valid. err. 2.31633
2018-02-04 00:16:28,848 training [INFO ] Epoch  9 Batch  900 Training err. 2.25347 Training err. RA 2.71892 Valid. err. 2.27600
2018-02-04 00:16:29,351 training [INFO ] Epoch  9 Batch  920 Training err. 2.21916 Training err. RA 2.70806 Valid. err. 2.26104
2018-02-04 00:16:30,219 training [INFO ] Epoch 10 Batch  940 Training err. 2.22111 Training err. RA 2.69770 Valid. err. 2.28984
2018-02-04 00:16:30,719 training [INFO ] Epoch 10 Batch  960 Training err. 2.23965 Training err. RA 2.68815 Valid. err. 2.24007
2018-02-04 00:16:31,224 training [INFO ] Epoch 10 Batch  980 Training err. 2.17486 Training err. RA 2.67768 Valid. err. 2.22204
2018-02-04 00:16:31,726 training [INFO ] Epoch 10 Batch 1000 Training err. 2.17831 Training err. RA 2.66769 Valid. err. 2.22409
2018-02-04 00:16:32,226 training [INFO ] Epoch 10 Batch 1020 Training err. 2.16968 Training err. RA 2.65793 Valid. err. 2.21267
2018-02-04 00:16:32,725 training [INFO ] Epoch 10 Batch 1040 Training err. 2.17099 Training err. RA 2.64856 Valid. err. 2.20171
2018-02-04 00:16:33,566 training [INFO ] Epoch 11 Batch 1060 Training err. 2.19382 Training err. RA 2.63998 Valid. err. 2.19169
2018-02-04 00:16:34,057 training [INFO ] Epoch 11 Batch 1080 Training err. 2.10478 Training err. RA 2.63007 Valid. err. 2.17234
2018-02-04 00:16:34,547 training [INFO ] Epoch 11 Batch 1100 Training err. 2.11961 Training err. RA 2.62079 Valid. err. 2.16648
2018-02-04 00:16:35,042 training [INFO ] Epoch 11 Batch 1120 Training err. 2.13834 Training err. RA 2.61217 Valid. err. 2.14938
2018-02-04 00:16:35,536 training [INFO ] Epoch 11 Batch 1140 Training err. 2.11366 Training err. RA 2.60343 Valid. err. 2.15086
2018-02-04 00:16:36,378 training [INFO ] Epoch 12 Batch 1160 Training err. 2.14389 Training err. RA 2.59551 Valid. err. 2.13849
2018-02-04 00:16:36,866 training [INFO ] Epoch 12 Batch 1180 Training err. 2.06277 Training err. RA 2.58648 Valid. err. 2.12885
2018-02-04 00:16:37,365 training [INFO ] Epoch 12 Batch 1200 Training err. 2.08415 Training err. RA 2.57810 Valid. err. 2.13222
2018-02-04 00:16:37,869 training [INFO ] Epoch 12 Batch 1220 Training err. 2.08492 Training err. RA 2.57002 Valid. err. 2.12181
2018-02-04 00:16:38,375 training [INFO ] Epoch 12 Batch 1240 Training err. 2.06676 Training err. RA 2.56190 Valid. err. 2.16660
2018-02-04 00:16:39,243 training [INFO ] Epoch 13 Batch 1260 Training err. 2.09030 Training err. RA 2.55442 Valid. err. 2.09262
2018-02-04 00:16:39,744 training [INFO ] Epoch 13 Batch 1280 Training err. 2.03129 Training err. RA 2.54624 Valid. err. 2.09785
2018-02-04 00:16:40,243 training [INFO ] Epoch 13 Batch 1300 Training err. 2.03500 Training err. RA 2.53838 Valid. err. 2.09580
2018-02-04 00:16:40,764 training [INFO ] Epoch 13 Batch 1320 Training err. 2.04763 Training err. RA 2.53094 Valid. err. 2.08685
2018-02-04 00:16:41,275 training [INFO ] Epoch 13 Batch 1340 Training err. 2.01675 Training err. RA 2.52327 Valid. err. 2.08123
2018-02-04 00:16:42,120 training [INFO ] Epoch 14 Batch 1360 Training err. 2.03998 Training err. RA 2.51616 Valid. err. 2.05159
2018-02-04 00:16:42,612 training [INFO ] Epoch 14 Batch 1380 Training err. 2.00996 Training err. RA 2.50882 Valid. err. 2.07367
2018-02-04 00:16:43,114 training [INFO ] Epoch 14 Batch 1400 Training err. 2.00485 Training err. RA 2.50162 Valid. err. 2.05667
2018-02-04 00:16:43,604 training [INFO ] Epoch 14 Batch 1420 Training err. 2.00563 Training err. RA 2.49464 Valid. err. 2.02743
2018-02-04 00:16:44,183 training [INFO ] Epoch 14 Batch 1440 Training err. 2.00022 Training err. RA 2.48777 Valid. err. 2.03768
2018-02-04 00:16:45,133 training [INFO ] Epoch 15 Batch 1460 Training err. 1.99850 Training err. RA 2.48107 Valid. err. 2.22790
2018-02-04 00:16:45,697 training [INFO ] Epoch 15 Batch 1480 Training err. 2.03537 Training err. RA 2.47505 Valid. err. 2.05460
2018-02-04 00:16:46,277 training [INFO ] Epoch 15 Batch 1500 Training err. 1.96009 Training err. RA 2.46818 Valid. err. 2.02739
2018-02-04 00:16:46,869 training [INFO ] Epoch 15 Batch 1520 Training err. 1.96874 Training err. RA 2.46161 Valid. err. 2.01294
2018-02-04 00:16:47,432 training [INFO ] Epoch 15 Batch 1540 Training err. 1.96967 Training err. RA 2.45522 Valid. err. 2.01384
2018-02-04 00:16:47,982 training [INFO ] Epoch 15 Batch 1560 Training err. 1.95656 Training err. RA 2.44883 Valid. err. 2.02952
2018-02-04 00:16:48,944 training [INFO ] Epoch 16 Batch 1580 Training err. 1.98152 Training err. RA 2.44291 Valid. err. 1.99756
2018-02-04 00:16:49,509 training [INFO ] Epoch 16 Batch 1600 Training err. 1.91015 Training err. RA 2.43625 Valid. err. 2.02406
2018-02-04 00:16:50,172 training [INFO ] Epoch 16 Batch 1620 Training err. 1.92983 Training err. RA 2.43000 Valid. err. 1.99469
2018-02-04 00:16:50,924 training [INFO ] Epoch 16 Batch 1640 Training err. 1.94874 Training err. RA 2.42413 Valid. err. 1.98935
2018-02-04 00:16:51,665 training [INFO ] Epoch 16 Batch 1660 Training err. 1.91940 Training err. RA 2.41805 Valid. err. 1.97247
2018-02-04 00:16:52,851 training [INFO ] Epoch 17 Batch 1680 Training err. 1.94145 Training err. RA 2.41238 Valid. err. 1.98994
2018-02-04 00:16:53,425 training [INFO ] Epoch 17 Batch 1700 Training err. 1.89491 Training err. RA 2.40629 Valid. err. 1.98903
2018-02-04 00:16:53,978 training [INFO ] Epoch 17 Batch 1720 Training err. 1.89886 Training err. RA 2.40039 Valid. err. 2.00223
2018-02-04 00:16:54,537 training [INFO ] Epoch 17 Batch 1740 Training err. 1.91164 Training err. RA 2.39477 Valid. err. 1.97082
2018-02-04 00:16:55,092 training [INFO ] Epoch 17 Batch 1760 Training err. 1.89415 Training err. RA 2.38908 Valid. err. 2.00137
2018-02-04 00:16:56,044 training [INFO ] Epoch 18 Batch 1780 Training err. 1.91670 Training err. RA 2.38377 Valid. err. 1.92535
2018-02-04 00:16:56,596 training [INFO ] Epoch 18 Batch 1800 Training err. 1.86435 Training err. RA 2.37800 Valid. err. 1.95180
2018-02-04 00:16:57,142 training [INFO ] Epoch 18 Batch 1820 Training err. 1.87665 Training err. RA 2.37249 Valid. err. 1.94121
2018-02-04 00:16:57,642 training [INFO ] Epoch 18 Batch 1840 Training err. 1.88059 Training err. RA 2.36715 Valid. err. 1.94779
2018-02-04 00:16:58,143 training [INFO ] Epoch 18 Batch 1860 Training err. 1.86574 Training err. RA 2.36175 Valid. err. 1.94803
2018-02-04 00:16:59,028 training [INFO ] Epoch 19 Batch 1880 Training err. 1.87049 Training err. RA 2.35653 Valid. err. 1.93115
2018-02-04 00:16:59,532 training [INFO ] Epoch 19 Batch 1900 Training err. 1.87176 Training err. RA 2.35143 Valid. err. 1.92600
2018-02-04 00:17:00,037 training [INFO ] Epoch 19 Batch 1920 Training err. 1.85486 Training err. RA 2.34625 Valid. err. 1.91948
2018-02-04 00:17:00,555 training [INFO ] Epoch 19 Batch 1940 Training err. 1.85559 Training err. RA 2.34119 Valid. err. 1.93016
2018-02-04 00:17:01,062 training [INFO ] Epoch 19 Batch 1960 Training err. 1.84208 Training err. RA 2.33610 Valid. err. 1.91944
2018-02-04 00:17:01,904 training [INFO ] Epoch 20 Batch 1980 Training err. 1.84110 Training err. RA 2.33110 Valid. err. 1.93038
2018-02-04 00:17:02,392 training [INFO ] Epoch 20 Batch 2000 Training err. 1.84944 Training err. RA 2.32628 Valid. err. 1.90442
2018-02-04 00:17:02,884 training [INFO ] Epoch 20 Batch 2020 Training err. 1.81575 Training err. RA 2.32123 Valid. err. 1.89301
2018-02-04 00:17:03,381 training [INFO ] Epoch 20 Batch 2040 Training err. 1.82372 Training err. RA 2.31635 Valid. err. 1.88826
2018-02-04 00:17:03,873 training [INFO ] Epoch 20 Batch 2060 Training err. 1.82507 Training err. RA 2.31158 Valid. err. 1.88898
2018-02-04 00:17:04,374 training [INFO ] Epoch 20 Batch 2080 Training err. 1.81910 Training err. RA 2.30685 Valid. err. 1.89289
2018-02-04 00:17:05,254 training [INFO ] Epoch 21 Batch 2100 Training err. 1.84021 Training err. RA 2.30240 Valid. err. 1.87179
2018-02-04 00:17:05,763 training [INFO ] Epoch 21 Batch 2120 Training err. 1.77252 Training err. RA 2.29740 Valid. err. 1.88023
2018-02-04 00:17:06,271 training [INFO ] Epoch 21 Batch 2140 Training err. 1.80513 Training err. RA 2.29280 Valid. err. 1.86974
2018-02-04 00:17:06,776 training [INFO ] Epoch 21 Batch 2160 Training err. 1.81243 Training err. RA 2.28836 Valid. err. 1.87724
2018-02-04 00:17:07,292 training [INFO ] Epoch 21 Batch 2180 Training err. 1.79061 Training err. RA 2.28379 Valid. err. 1.85594
2018-02-04 00:17:08,198 training [INFO ] Epoch 22 Batch 2200 Training err. 1.80743 Training err. RA 2.27946 Valid. err. 1.86199
2018-02-04 00:17:08,698 training [INFO ] Epoch 22 Batch 2220 Training err. 1.76103 Training err. RA 2.27479 Valid. err. 1.87112
2018-02-04 00:17:09,197 training [INFO ] Epoch 22 Batch 2240 Training err. 1.78285 Training err. RA 2.27040 Valid. err. 1.87053
2018-02-04 00:17:09,693 training [INFO ] Epoch 22 Batch 2260 Training err. 1.79371 Training err. RA 2.26618 Valid. err. 1.85980
2018-02-04 00:17:10,186 training [INFO ] Epoch 22 Batch 2280 Training err. 1.76948 Training err. RA 2.26182 Valid. err. 1.85754
2018-02-04 00:17:11,054 training [INFO ] Epoch 23 Batch 2300 Training err. 1.79209 Training err. RA 2.25774 Valid. err. 1.83131
2018-02-04 00:17:11,543 training [INFO ] Epoch 23 Batch 2320 Training err. 1.74120 Training err. RA 2.25328 Valid. err. 1.85156
2018-02-04 00:17:12,034 training [INFO ] Epoch 23 Batch 2340 Training err. 1.76233 Training err. RA 2.24909 Valid. err. 1.83106
2018-02-04 00:17:12,533 training [INFO ] Epoch 23 Batch 2360 Training err. 1.76663 Training err. RA 2.24500 Valid. err. 1.85924
2018-02-04 00:17:13,030 training [INFO ] Epoch 23 Batch 2380 Training err. 1.74795 Training err. RA 2.24082 Valid. err. 1.84207
2018-02-04 00:17:13,888 training [INFO ] Epoch 24 Batch 2400 Training err. 1.75200 Training err. RA 2.23675 Valid. err. 1.80929
2018-02-04 00:17:14,382 training [INFO ] Epoch 24 Batch 2420 Training err. 1.74312 Training err. RA 2.23267 Valid. err. 1.82652
2018-02-04 00:17:14,881 training [INFO ] Epoch 24 Batch 2440 Training err. 1.74365 Training err. RA 2.22866 Valid. err. 1.82453
2018-02-04 00:17:15,386 training [INFO ] Epoch 24 Batch 2460 Training err. 1.74423 Training err. RA 2.22472 Valid. err. 1.81588
2018-02-04 00:17:15,885 training [INFO ] Epoch 24 Batch 2480 Training err. 1.72918 Training err. RA 2.22072 Valid. err. 1.81330
2018-02-04 00:17:16,770 training [INFO ] Epoch 25 Batch 2500 Training err. 1.72918 Training err. RA 2.21679 Valid. err. 1.85414
2018-02-04 00:17:17,257 training [INFO ] Epoch 25 Batch 2520 Training err. 1.73698 Training err. RA 2.21298 Valid. err. 1.81509
2018-02-04 00:17:17,749 training [INFO ] Epoch 25 Batch 2540 Training err. 1.71350 Training err. RA 2.20905 Valid. err. 1.79846
2018-02-04 00:17:18,257 training [INFO ] Epoch 25 Batch 2560 Training err. 1.71996 Training err. RA 2.20523 Valid. err. 1.82026
2018-02-04 00:17:18,747 training [INFO ] Epoch 25 Batch 2580 Training err. 1.72089 Training err. RA 2.20148 Valid. err. 1.79330
2018-02-04 00:17:19,241 training [INFO ] Epoch 25 Batch 2600 Training err. 1.71205 Training err. RA 2.19771 Valid. err. 1.79395
2018-02-04 00:17:20,086 training [INFO ] Epoch 26 Batch 2620 Training err. 1.73320 Training err. RA 2.19417 Valid. err. 1.78268
2018-02-04 00:17:20,580 training [INFO ] Epoch 26 Batch 2640 Training err. 1.66805 Training err. RA 2.19018 Valid. err. 1.79494
2018-02-04 00:17:21,080 training [INFO ] Epoch 26 Batch 2660 Training err. 1.70107 Training err. RA 2.18650 Valid. err. 1.81111
2018-02-04 00:17:21,585 training [INFO ] Epoch 26 Batch 2680 Training err. 1.71174 Training err. RA 2.18296 Valid. err. 1.78276
2018-02-04 00:17:22,088 training [INFO ] Epoch 26 Batch 2700 Training err. 1.69004 Training err. RA 2.17931 Valid. err. 1.77705
2018-02-04 00:17:22,963 training [INFO ] Epoch 27 Batch 2720 Training err. 1.70548 Training err. RA 2.17582 Valid. err. 1.78696
2018-02-04 00:17:23,463 training [INFO ] Epoch 27 Batch 2740 Training err. 1.66709 Training err. RA 2.17211 Valid. err. 1.77633
2018-02-04 00:17:23,964 training [INFO ] Epoch 27 Batch 2760 Training err. 1.68996 Training err. RA 2.16862 Valid. err. 1.78158
2018-02-04 00:17:24,470 training [INFO ] Epoch 27 Batch 2780 Training err. 1.69227 Training err. RA 2.16519 Valid. err. 1.78306
2018-02-04 00:17:24,966 training [INFO ] Epoch 27 Batch 2800 Training err. 1.67479 Training err. RA 2.16169 Valid. err. 1.77915
2018-02-04 00:17:25,822 training [INFO ] Epoch 28 Batch 2820 Training err. 1.69993 Training err. RA 2.15841 Valid. err. 1.75269
2018-02-04 00:17:26,313 training [INFO ] Epoch 28 Batch 2840 Training err. 1.64746 Training err. RA 2.15481 Valid. err. 1.78805
2018-02-04 00:17:26,805 training [INFO ] Epoch 28 Batch 2860 Training err. 1.67601 Training err. RA 2.15147 Valid. err. 1.77114
2018-02-04 00:17:27,301 training [INFO ] Epoch 28 Batch 2880 Training err. 1.67973 Training err. RA 2.14819 Valid. err. 1.78501
2018-02-04 00:17:27,793 training [INFO ] Epoch 28 Batch 2900 Training err. 1.66030 Training err. RA 2.14482 Valid. err. 1.76732
2018-02-04 00:17:28,640 training [INFO ] Epoch 29 Batch 2920 Training err. 1.66345 Training err. RA 2.14153 Valid. err. 1.73897
2018-02-04 00:17:29,138 training [INFO ] Epoch 29 Batch 2940 Training err. 1.65062 Training err. RA 2.13819 Valid. err. 1.75879
2018-02-04 00:17:29,639 training [INFO ] Epoch 29 Batch 2960 Training err. 1.65650 Training err. RA 2.13493 Valid. err. 1.76257
2018-02-04 00:17:30,149 training [INFO ] Epoch 29 Batch 2980 Training err. 1.66757 Training err. RA 2.13180 Valid. err. 1.74099
2018-02-04 00:17:30,651 training [INFO ] Epoch 29 Batch 3000 Training err. 1.64005 Training err. RA 2.12852 Valid. err. 1.75536
2018-02-04 00:17:31,515 training [INFO ] Epoch 30 Batch 3020 Training err. 1.64474 Training err. RA 2.12531 Valid. err. 1.76026
2018-02-04 00:17:32,024 training [INFO ] Epoch 30 Batch 3040 Training err. 1.65135 Training err. RA 2.12220 Valid. err. 1.74583
2018-02-04 00:17:32,528 training [INFO ] Epoch 30 Batch 3060 Training err. 1.62637 Training err. RA 2.11896 Valid. err. 1.73442
2018-02-04 00:17:33,091 training [INFO ] Epoch 30 Batch 3080 Training err. 1.64055 Training err. RA 2.11585 Valid. err. 1.76103
2018-02-04 00:17:33,675 training [INFO ] Epoch 30 Batch 3100 Training err. 1.63667 Training err. RA 2.11276 Valid. err. 1.74147
2018-02-04 00:17:34,259 training [INFO ] Epoch 30 Batch 3120 Training err. 1.63230 Training err. RA 2.10968 Valid. err. 1.73319
2018-02-04 00:17:35,262 training [INFO ] Epoch 31 Batch 3140 Training err. 1.65185 Training err. RA 2.10676 Valid. err. 1.72488
2018-02-04 00:17:35,869 training [INFO ] Epoch 31 Batch 3160 Training err. 1.59367 Training err. RA 2.10351 Valid. err. 1.74506
2018-02-04 00:17:36,478 training [INFO ] Epoch 31 Batch 3180 Training err. 1.62423 Training err. RA 2.10050 Valid. err. 1.76249
2018-02-04 00:17:37,025 training [INFO ] Epoch 31 Batch 3200 Training err. 1.63242 Training err. RA 2.09757 Valid. err. 1.73099
2018-02-04 00:17:37,616 training [INFO ] Epoch 31 Batch 3220 Training err. 1.61938 Training err. RA 2.09460 Valid. err. 1.73066
2018-02-04 00:17:38,559 training [INFO ] Epoch 32 Batch 3240 Training err. 1.62881 Training err. RA 2.09173 Valid. err. 1.73404
2018-02-04 00:17:39,187 training [INFO ] Epoch 32 Batch 3260 Training err. 1.59115 Training err. RA 2.08866 Valid. err. 1.72312
2018-02-04 00:17:39,804 training [INFO ] Epoch 32 Batch 3280 Training err. 1.61482 Training err. RA 2.08577 Valid. err. 1.72092
2018-02-04 00:17:40,385 training [INFO ] Epoch 32 Batch 3300 Training err. 1.61883 Training err. RA 2.08294 Valid. err. 1.72048
2018-02-04 00:17:40,941 training [INFO ] Epoch 32 Batch 3320 Training err. 1.60493 Training err. RA 2.08006 Valid. err. 1.72697
2018-02-04 00:17:41,819 training [INFO ] Epoch 33 Batch 3340 Training err. 1.62381 Training err. RA 2.07733 Valid. err. 1.71474
2018-02-04 00:17:42,329 training [INFO ] Epoch 33 Batch 3360 Training err. 1.58000 Training err. RA 2.07437 Valid. err. 1.73876
2018-02-04 00:17:42,829 training [INFO ] Epoch 33 Batch 3380 Training err. 1.59691 Training err. RA 2.07154 Valid. err. 1.70932
2018-02-04 00:17:43,334 training [INFO ] Epoch 33 Batch 3400 Training err. 1.60991 Training err. RA 2.06883 Valid. err. 1.71789
2018-02-04 00:17:43,833 training [INFO ] Epoch 33 Batch 3420 Training err. 1.58864 Training err. RA 2.06602 Valid. err. 1.71190
2018-02-04 00:17:44,724 training [INFO ] Epoch 34 Batch 3440 Training err. 1.59326 Training err. RA 2.06327 Valid. err. 1.69207
2018-02-04 00:17:45,257 training [INFO ] Epoch 34 Batch 3460 Training err. 1.58498 Training err. RA 2.06050 Valid. err. 1.71399
2018-02-04 00:17:45,787 training [INFO ] Epoch 34 Batch 3480 Training err. 1.58777 Training err. RA 2.05779 Valid. err. 1.72041
2018-02-04 00:17:46,303 training [INFO ] Epoch 34 Batch 3500 Training err. 1.59821 Training err. RA 2.05516 Valid. err. 1.68681
2018-02-04 00:17:46,811 training [INFO ] Epoch 34 Batch 3520 Training err. 1.57263 Training err. RA 2.05242 Valid. err. 1.70241
2018-02-04 00:17:47,685 training [INFO ] Epoch 35 Batch 3540 Training err. 1.57237 Training err. RA 2.04971 Valid. err. 1.71227
2018-02-04 00:17:48,224 training [INFO ] Epoch 35 Batch 3560 Training err. 1.58318 Training err. RA 2.04709 Valid. err. 1.71090
2018-02-04 00:17:48,726 training [INFO ] Epoch 35 Batch 3580 Training err. 1.56431 Training err. RA 2.04439 Valid. err. 1.69690
2018-02-04 00:17:49,302 training [INFO ] Epoch 35 Batch 3600 Training err. 1.57426 Training err. RA 2.04178 Valid. err. 1.71160
2018-02-04 00:17:49,963 training [INFO ] Epoch 35 Batch 3620 Training err. 1.56922 Training err. RA 2.03917 Valid. err. 1.70407
2018-02-04 00:17:50,625 training [INFO ] Epoch 35 Batch 3640 Training err. 1.57011 Training err. RA 2.03659 Valid. err. 1.69096
2018-02-04 00:17:51,762 training [INFO ] Epoch 36 Batch 3660 Training err. 1.58643 Training err. RA 2.03413 Valid. err. 1.69013
2018-02-04 00:17:52,467 training [INFO ] Epoch 36 Batch 3680 Training err. 1.52686 Training err. RA 2.03137 Valid. err. 1.68699
2018-02-04 00:17:53,117 training [INFO ] Epoch 36 Batch 3700 Training err. 1.55778 Training err. RA 2.02881 Valid. err. 1.72322
2018-02-04 00:17:53,678 training [INFO ] Epoch 36 Batch 3720 Training err. 1.57051 Training err. RA 2.02635 Valid. err. 1.68389
2018-02-04 00:17:54,227 training [INFO ] Epoch 36 Batch 3740 Training err. 1.55346 Training err. RA 2.02382 Valid. err. 1.68286
2018-02-04 00:17:55,193 training [INFO ] Epoch 37 Batch 3760 Training err. 1.56381 Training err. RA 2.02137 Valid. err. 1.69010
2018-02-04 00:17:55,746 training [INFO ] Epoch 37 Batch 3780 Training err. 1.53445 Training err. RA 2.01880 Valid. err. 1.68367
2018-02-04 00:17:56,297 training [INFO ] Epoch 37 Batch 3800 Training err. 1.54942 Training err. RA 2.01633 Valid. err. 1.68235
2018-02-04 00:17:56,844 training [INFO ] Epoch 37 Batch 3820 Training err. 1.55590 Training err. RA 2.01392 Valid. err. 1.68732
2018-02-04 00:17:57,371 training [INFO ] Epoch 37 Batch 3840 Training err. 1.54343 Training err. RA 2.01147 Valid. err. 1.68469
2018-02-04 00:17:58,251 training [INFO ] Epoch 38 Batch 3860 Training err. 1.55661 Training err. RA 2.00911 Valid. err. 1.67281
2018-02-04 00:17:58,774 training [INFO ] Epoch 38 Batch 3880 Training err. 1.51807 Training err. RA 2.00658 Valid. err. 1.70435
2018-02-04 00:17:59,355 training [INFO ] Epoch 38 Batch 3900 Training err. 1.53639 Training err. RA 2.00417 Valid. err. 1.67811
2018-02-04 00:17:59,890 training [INFO ] Epoch 38 Batch 3920 Training err. 1.55145 Training err. RA 2.00186 Valid. err. 1.68408
2018-02-04 00:18:00,434 training [INFO ] Epoch 38 Batch 3940 Training err. 1.53190 Training err. RA 1.99947 Valid. err. 1.67377
2018-02-04 00:18:01,342 training [INFO ] Epoch 39 Batch 3960 Training err. 1.53237 Training err. RA 1.99711 Valid. err. 1.66003
2018-02-04 00:18:01,878 training [INFO ] Epoch 39 Batch 3980 Training err. 1.52700 Training err. RA 1.99475 Valid. err. 1.68489
2018-02-04 00:18:02,410 training [INFO ] Epoch 39 Batch 4000 Training err. 1.52729 Training err. RA 1.99241 Valid. err. 1.67933
2018-02-04 00:18:02,924 training [INFO ] Epoch 39 Batch 4020 Training err. 1.53988 Training err. RA 1.99016 Valid. err. 1.65139
2018-02-04 00:18:03,481 training [INFO ] Epoch 39 Batch 4040 Training err. 1.51844 Training err. RA 1.98783 Valid. err. 1.66375
2018-02-04 00:18:04,416 training [INFO ] Epoch 40 Batch 4060 Training err. 1.51520 Training err. RA 1.98550 Valid. err. 1.68035
2018-02-04 00:18:04,941 training [INFO ] Epoch 40 Batch 4080 Training err. 1.52751 Training err. RA 1.98325 Valid. err. 1.66901
2018-02-04 00:18:05,454 training [INFO ] Epoch 40 Batch 4100 Training err. 1.50468 Training err. RA 1.98092 Valid. err. 1.67341
2018-02-04 00:18:06,071 training [INFO ] Epoch 40 Batch 4120 Training err. 1.52059 Training err. RA 1.97868 Valid. err. 1.67322
2018-02-04 00:18:06,624 training [INFO ] Epoch 40 Batch 4140 Training err. 1.51576 Training err. RA 1.97645 Valid. err. 1.67036
2018-02-04 00:18:07,160 training [INFO ] Epoch 40 Batch 4160 Training err. 1.51114 Training err. RA 1.97421 Valid. err. 1.65864
2018-02-04 00:18:08,051 training [INFO ] Epoch 41 Batch 4180 Training err. 1.53152 Training err. RA 1.97209 Valid. err. 1.67065
2018-02-04 00:18:08,639 training [INFO ] Epoch 41 Batch 4200 Training err. 1.47552 Training err. RA 1.96973 Valid. err. 1.66331
2018-02-04 00:18:09,194 training [INFO ] Epoch 41 Batch 4220 Training err. 1.50937 Training err. RA 1.96755 Valid. err. 1.70286
2018-02-04 00:18:09,758 training [INFO ] Epoch 41 Batch 4240 Training err. 1.51769 Training err. RA 1.96542 Valid. err. 1.64989
2018-02-04 00:18:10,286 training [INFO ] Epoch 41 Batch 4260 Training err. 1.49923 Training err. RA 1.96323 Valid. err. 1.64442
2018-02-04 00:18:11,181 training [INFO ] Epoch 42 Batch 4280 Training err. 1.50993 Training err. RA 1.96112 Valid. err. 1.65954
2018-02-04 00:18:11,736 training [INFO ] Epoch 42 Batch 4300 Training err. 1.48200 Training err. RA 1.95889 Valid. err. 1.66265
2018-02-04 00:18:12,303 training [INFO ] Epoch 42 Batch 4320 Training err. 1.49978 Training err. RA 1.95676 Valid. err. 1.65471
2018-02-04 00:18:12,839 training [INFO ] Epoch 42 Batch 4340 Training err. 1.50323 Training err. RA 1.95467 Valid. err. 1.66886
2018-02-04 00:18:13,382 training [INFO ] Epoch 42 Batch 4360 Training err. 1.49083 Training err. RA 1.95254 Valid. err. 1.65143
2018-02-04 00:18:14,296 training [INFO ] Epoch 43 Batch 4380 Training err. 1.50467 Training err. RA 1.95050 Valid. err. 1.63948
2018-02-04 00:18:14,861 training [INFO ] Epoch 43 Batch 4400 Training err. 1.47168 Training err. RA 1.94832 Valid. err. 1.66521
2018-02-04 00:18:15,457 training [INFO ] Epoch 43 Batch 4420 Training err. 1.48910 Training err. RA 1.94625 Valid. err. 1.65109
2018-02-04 00:18:16,067 training [INFO ] Epoch 43 Batch 4440 Training err. 1.49941 Training err. RA 1.94423 Valid. err. 1.66182
2018-02-04 00:18:16,695 training [INFO ] Epoch 43 Batch 4460 Training err. 1.48286 Training err. RA 1.94216 Valid. err. 1.65601
2018-02-04 00:18:17,610 training [INFO ] Epoch 44 Batch 4480 Training err. 1.47765 Training err. RA 1.94009 Valid. err. 1.63537
2018-02-04 00:18:18,160 training [INFO ] Epoch 44 Batch 4500 Training err. 1.48125 Training err. RA 1.93805 Valid. err. 1.67066
2018-02-04 00:18:18,703 training [INFO ] Epoch 44 Batch 4520 Training err. 1.48062 Training err. RA 1.93603 Valid. err. 1.65686
2018-02-04 00:18:19,232 training [INFO ] Epoch 44 Batch 4540 Training err. 1.49049 Training err. RA 1.93406 Valid. err. 1.63444
2018-02-04 00:18:19,767 training [INFO ] Epoch 44 Batch 4560 Training err. 1.46640 Training err. RA 1.93201 Valid. err. 1.63541
2018-02-04 00:18:20,677 training [INFO ] Epoch 45 Batch 4580 Training err. 1.46384 Training err. RA 1.92997 Valid. err. 1.66095
2018-02-04 00:18:21,217 training [INFO ] Epoch 45 Batch 4600 Training err. 1.47894 Training err. RA 1.92801 Valid. err. 1.65844
2018-02-04 00:18:21,759 training [INFO ] Epoch 45 Batch 4620 Training err. 1.45923 Training err. RA 1.92598 Valid. err. 1.64439
2018-02-04 00:18:22,333 training [INFO ] Epoch 45 Batch 4640 Training err. 1.47320 Training err. RA 1.92403 Valid. err. 1.64664
2018-02-04 00:18:22,949 training [INFO ] Epoch 45 Batch 4660 Training err. 1.46913 Training err. RA 1.92207 Valid. err. 1.63222
2018-02-04 00:18:23,517 training [INFO ] Epoch 45 Batch 4680 Training err. 1.46068 Training err. RA 1.92010 Valid. err. 1.64079
2018-02-04 00:18:24,449 training [INFO ] Epoch 46 Batch 4700 Training err. 1.48451 Training err. RA 1.91825 Valid. err. 1.64168
2018-02-04 00:18:25,028 training [INFO ] Epoch 46 Batch 4720 Training err. 1.42631 Training err. RA 1.91616 Valid. err. 1.63983
2018-02-04 00:18:25,548 training [INFO ] Epoch 46 Batch 4740 Training err. 1.46562 Training err. RA 1.91426 Valid. err. 1.66393
2018-02-04 00:18:26,099 training [INFO ] Epoch 46 Batch 4760 Training err. 1.46699 Training err. RA 1.91238 Valid. err. 1.62490
2018-02-04 00:18:26,626 training [INFO ] Epoch 46 Batch 4780 Training err. 1.45304 Training err. RA 1.91046 Valid. err. 1.62721
2018-02-04 00:18:27,573 training [INFO ] Epoch 47 Batch 4800 Training err. 1.46033 Training err. RA 1.90859 Valid. err. 1.64178
2018-02-04 00:18:28,150 training [INFO ] Epoch 47 Batch 4820 Training err. 1.43385 Training err. RA 1.90662 Valid. err. 1.65377
2018-02-04 00:18:28,762 training [INFO ] Epoch 47 Batch 4840 Training err. 1.45472 Training err. RA 1.90475 Valid. err. 1.64252
2018-02-04 00:18:29,347 training [INFO ] Epoch 47 Batch 4860 Training err. 1.45885 Training err. RA 1.90291 Valid. err. 1.63381
2018-02-04 00:18:29,886 training [INFO ] Epoch 47 Batch 4880 Training err. 1.44508 Training err. RA 1.90104 Valid. err. 1.64947
2018-02-04 00:18:30,813 training [INFO ] Epoch 48 Batch 4900 Training err. 1.45637 Training err. RA 1.89922 Valid. err. 1.62925
2018-02-04 00:18:31,405 training [INFO ] Epoch 48 Batch 4920 Training err. 1.42981 Training err. RA 1.89731 Valid. err. 1.64955
2018-02-04 00:18:31,945 training [INFO ] Epoch 48 Batch 4940 Training err. 1.43824 Training err. RA 1.89546 Valid. err. 1.64621
2018-02-04 00:18:32,494 training [INFO ] Epoch 48 Batch 4960 Training err. 1.45311 Training err. RA 1.89367 Valid. err. 1.65553
2018-02-04 00:18:33,023 training [INFO ] Epoch 48 Batch 4980 Training err. 1.43377 Training err. RA 1.89183 Valid. err. 1.64284
2018-02-04 00:18:33,960 training [INFO ] Epoch 49 Batch 5000 Training err. 1.43535 Training err. RA 1.89000 Valid. err. 1.62289
2018-02-04 00:18:34,540 training [INFO ] Epoch 49 Batch 5020 Training err. 1.44328 Training err. RA 1.88822 Valid. err. 1.65393
2018-02-04 00:18:35,128 training [INFO ] Epoch 49 Batch 5040 Training err. 1.43670 Training err. RA 1.88643 Valid. err. 1.63705
2018-02-04 00:18:35,686 training [INFO ] Epoch 49 Batch 5060 Training err. 1.45499 Training err. RA 1.88472 Valid. err. 1.61286
2018-02-04 00:18:36,271 training [INFO ] Epoch 49 Batch 5080 Training err. 1.41749 Training err. RA 1.88288 Valid. err. 1.61686
2018-02-04 00:18:37,165 training [INFO ] Epoch 50 Batch 5100 Training err. 1.41879 Training err. RA 1.88106 Valid. err. 1.63431
2018-02-04 00:18:37,699 training [INFO ] Epoch 50 Batch 5120 Training err. 1.44330 Training err. RA 1.87935 Valid. err. 1.63801
2018-02-04 00:18:38,275 training [INFO ] Epoch 50 Batch 5140 Training err. 1.41128 Training err. RA 1.87753 Valid. err. 1.63312
2018-02-04 00:18:38,949 training [INFO ] Epoch 50 Batch 5160 Training err. 1.43136 Training err. RA 1.87580 Valid. err. 1.66576
2018-02-04 00:18:39,539 training [INFO ] Epoch 50 Batch 5180 Training err. 1.42244 Training err. RA 1.87405 Valid. err. 1.62921
2018-02-04 00:18:40,062 training [INFO ] Epoch 50 Batch 5200 Training err. 1.41858 Training err. RA 1.87230 Valid. err. 1.63334
2018-02-04 00:18:40,955 training [INFO ] Epoch 51 Batch 5220 Training err. 1.45194 Training err. RA 1.87069 Valid. err. 1.63101
2018-02-04 00:18:41,478 training [INFO ] Epoch 51 Batch 5240 Training err. 1.38372 Training err. RA 1.86883 Valid. err. 1.63288
2018-02-04 00:18:42,003 training [INFO ] Epoch 51 Batch 5260 Training err. 1.41648 Training err. RA 1.86711 Valid. err. 1.64675
2018-02-04 00:18:42,535 training [INFO ] Epoch 51 Batch 5280 Training err. 1.42750 Training err. RA 1.86545 Valid. err. 1.61238
2018-02-04 00:18:43,075 training [INFO ] Epoch 51 Batch 5300 Training err. 1.41021 Training err. RA 1.86373 Valid. err. 1.61885
2018-02-04 00:18:43,982 training [INFO ] Epoch 52 Batch 5320 Training err. 1.42110 Training err. RA 1.86206 Valid. err. 1.63503
2018-02-04 00:18:44,497 training [INFO ] Epoch 52 Batch 5340 Training err. 1.39432 Training err. RA 1.86031 Valid. err. 1.64265
2018-02-04 00:18:45,026 training [INFO ] Epoch 52 Batch 5360 Training err. 1.41836 Training err. RA 1.85866 Valid. err. 1.63615
2018-02-04 00:18:45,542 training [INFO ] Epoch 52 Batch 5380 Training err. 1.41682 Training err. RA 1.85702 Valid. err. 1.63092
2018-02-04 00:18:46,068 training [INFO ] Epoch 52 Batch 5400 Training err. 1.39908 Training err. RA 1.85532 Valid. err. 1.63259
2018-02-04 00:18:46,962 training [INFO ] Epoch 53 Batch 5420 Training err. 1.42268 Training err. RA 1.85373 Valid. err. 1.61838
2018-02-04 00:18:47,485 training [INFO ] Epoch 53 Batch 5440 Training err. 1.38969 Training err. RA 1.85202 Valid. err. 1.63103
2018-02-04 00:18:48,002 training [INFO ] Epoch 53 Batch 5460 Training err. 1.40090 Training err. RA 1.85037 Valid. err. 1.62779
2018-02-04 00:18:48,532 training [INFO ] Epoch 53 Batch 5480 Training err. 1.42077 Training err. RA 1.84880 Valid. err. 1.62706
2018-02-04 00:18:49,044 training [INFO ] Epoch 53 Batch 5500 Training err. 1.39010 Training err. RA 1.84713 Valid. err. 1.62776
2018-02-04 00:18:49,908 training [INFO ] Epoch 54 Batch 5520 Training err. 1.39552 Training err. RA 1.84550 Valid. err. 1.61459
2018-02-04 00:18:50,411 training [INFO ] Epoch 54 Batch 5540 Training err. 1.40175 Training err. RA 1.84390 Valid. err. 1.64952
2018-02-04 00:18:50,920 training [INFO ] Epoch 54 Batch 5560 Training err. 1.39073 Training err. RA 1.84227 Valid. err. 1.63437
2018-02-04 00:18:51,425 training [INFO ] Epoch 54 Batch 5580 Training err. 1.41247 Training err. RA 1.84072 Valid. err. 1.61509
2018-02-04 00:18:51,931 training [INFO ] Epoch 54 Batch 5600 Training err. 1.38229 Training err. RA 1.83909 Valid. err. 1.61074
2018-02-04 00:18:52,827 training [INFO ] Epoch 55 Batch 5620 Training err. 1.38270 Training err. RA 1.83746 Valid. err. 1.64155
2018-02-04 00:18:53,330 training [INFO ] Epoch 55 Batch 5640 Training err. 1.40224 Training err. RA 1.83592 Valid. err. 1.63225
2018-02-04 00:18:53,844 training [INFO ] Epoch 55 Batch 5660 Training err. 1.38088 Training err. RA 1.83431 Valid. err. 1.63134
2018-02-04 00:18:54,367 training [INFO ] Epoch 55 Batch 5680 Training err. 1.39826 Training err. RA 1.83278 Valid. err. 1.64588
2018-02-04 00:18:54,890 training [INFO ] Epoch 55 Batch 5700 Training err. 1.38980 Training err. RA 1.83122 Valid. err. 1.62845
2018-02-04 00:18:55,406 training [INFO ] Epoch 55 Batch 5720 Training err. 1.38104 Training err. RA 1.82965 Valid. err. 1.61653
2018-02-04 00:18:56,295 training [INFO ] Epoch 56 Batch 5740 Training err. 1.40561 Training err. RA 1.82817 Valid. err. 1.62825
2018-02-04 00:18:56,812 training [INFO ] Epoch 56 Batch 5760 Training err. 1.34498 Training err. RA 1.82649 Valid. err. 1.64130
2018-02-04 00:18:57,329 training [INFO ] Epoch 56 Batch 5780 Training err. 1.38239 Training err. RA 1.82496 Valid. err. 1.63943
2018-02-04 00:18:57,837 training [INFO ] Epoch 56 Batch 5800 Training err. 1.38851 Training err. RA 1.82345 Valid. err. 1.61797
2018-02-04 00:18:58,342 training [INFO ] Epoch 56 Batch 5820 Training err. 1.37236 Training err. RA 1.82190 Valid. err. 1.62972
2018-02-04 00:18:59,218 training [INFO ] Epoch 57 Batch 5840 Training err. 1.38668 Training err. RA 1.82041 Valid. err. 1.63868
2018-02-04 00:18:59,718 training [INFO ] Epoch 57 Batch 5860 Training err. 1.35687 Training err. RA 1.81883 Valid. err. 1.63222
2018-02-04 00:19:00,234 training [INFO ] Epoch 57 Batch 5880 Training err. 1.38141 Training err. RA 1.81734 Valid. err. 1.63832
2018-02-04 00:19:00,743 training [INFO ] Epoch 57 Batch 5900 Training err. 1.37940 Training err. RA 1.81586 Valid. err. 1.62367
2018-02-04 00:19:01,261 training [INFO ] Epoch 57 Batch 5920 Training err. 1.37042 Training err. RA 1.81435 Valid. err. 1.62309
2018-02-04 00:19:02,145 training [INFO ] Epoch 58 Batch 5940 Training err. 1.38063 Training err. RA 1.81289 Valid. err. 1.61332
2018-02-04 00:19:02,665 training [INFO ] Epoch 58 Batch 5960 Training err. 1.35641 Training err. RA 1.81136 Valid. err. 1.62526
2018-02-04 00:19:03,191 training [INFO ] Epoch 58 Batch 5980 Training err. 1.36323 Training err. RA 1.80986 Valid. err. 1.63187
2018-02-04 00:19:03,707 training [INFO ] Epoch 58 Batch 6000 Training err. 1.37971 Training err. RA 1.80843 Valid. err. 1.63562
2018-02-04 00:19:04,226 training [INFO ] Epoch 58 Batch 6020 Training err. 1.35850 Training err. RA 1.80693 Valid. err. 1.63997
2018-02-04 00:19:05,157 training [INFO ] Epoch 59 Batch 6040 Training err. 1.36280 Training err. RA 1.80546 Valid. err. 1.62627
2018-02-04 00:19:05,827 training [INFO ] Epoch 59 Batch 6060 Training err. 1.36650 Training err. RA 1.80401 Valid. err. 1.63322
2018-02-04 00:19:06,510 training [INFO ] Epoch 59 Batch 6080 Training err. 1.35713 Training err. RA 1.80254 Valid. err. 1.63026
2018-02-04 00:19:07,198 training [INFO ] Epoch 59 Batch 6100 Training err. 1.37634 Training err. RA 1.80115 Valid. err. 1.61153
2018-02-04 00:19:07,876 training [INFO ] Epoch 59 Batch 6120 Training err. 1.34511 Training err. RA 1.79965 Valid. err. 1.61247
2018-02-04 00:19:09,044 training [INFO ] Epoch 60 Batch 6140 Training err. 1.35213 Training err. RA 1.79820 Valid. err. 1.64395
2018-02-04 00:19:09,615 training [INFO ] Epoch 60 Batch 6160 Training err. 1.36714 Training err. RA 1.79680 Valid. err. 1.63418
2018-02-04 00:19:10,165 training [INFO ] Epoch 60 Batch 6180 Training err. 1.34310 Training err. RA 1.79533 Valid. err. 1.63547
2018-02-04 00:19:10,712 training [INFO ] Epoch 60 Batch 6200 Training err. 1.35716 Training err. RA 1.79392 Valid. err. 1.63904
2018-02-04 00:19:11,276 training [INFO ] Epoch 60 Batch 6220 Training err. 1.35644 Training err. RA 1.79251 Valid. err. 1.61317
2018-02-04 00:19:11,839 training [INFO ] Epoch 60 Batch 6240 Training err. 1.34983 Training err. RA 1.79109 Valid. err. 1.62094
2018-02-04 00:19:12,095 __main__ [INFO ] End of training
2018-02-04 00:19:12,373 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 12 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 10,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-04 00:19:13,071 training [INFO ] Epoch  1 Batch   20 Training err. 25.77136 Training err. RA 25.77136 Valid. err. 117.28146
2018-02-04 00:19:13,611 training [INFO ] Epoch  1 Batch   40 Training err. 136.58561 Training err. RA 81.17848 Valid. err. 142.52658
2018-02-04 00:19:14,149 training [INFO ] Epoch  1 Batch   60 Training err. 145.15436 Training err. RA 102.50377 Valid. err. 152.82837
2018-02-04 00:19:14,687 training [INFO ] Epoch  1 Batch   80 Training err. 142.29381 Training err. RA 112.45128 Valid. err. 116.79444
2018-02-04 00:19:15,232 training [INFO ] Epoch  1 Batch  100 Training err. 137.59993 Training err. RA 117.48101 Valid. err. 140.94928
2018-02-04 00:19:16,147 training [INFO ] Epoch  2 Batch  120 Training err. 150.00782 Training err. RA 122.90215 Valid. err. 134.22075
2018-02-04 00:19:16,692 training [INFO ] Epoch  2 Batch  140 Training err. 148.54266 Training err. RA 126.56508 Valid. err. 120.02328
2018-02-04 00:19:17,226 training [INFO ] Epoch  2 Batch  160 Training err. 137.70540 Training err. RA 127.95762 Valid. err. 130.08618
2018-02-04 00:19:17,762 training [INFO ] Epoch  2 Batch  180 Training err. 149.23230 Training err. RA 130.32147 Valid. err. 123.98112
2018-02-04 00:19:18,299 training [INFO ] Epoch  2 Batch  200 Training err. 130.19496 Training err. RA 130.30882 Valid. err. 107.04776
2018-02-04 00:19:19,201 training [INFO ] Epoch  3 Batch  220 Training err. 137.98028 Training err. RA 131.00623 Valid. err. 105.93559
2018-02-04 00:19:19,742 training [INFO ] Epoch  3 Batch  240 Training err. 131.77273 Training err. RA 131.07010 Valid. err. 147.93177
2018-02-04 00:19:20,322 training [INFO ] Epoch  3 Batch  260 Training err. 153.01923 Training err. RA 132.75850 Valid. err. 118.08980
2018-02-04 00:19:20,855 training [INFO ] Epoch  3 Batch  280 Training err. 138.30522 Training err. RA 133.15469 Valid. err. 139.65862
2018-02-04 00:19:21,395 training [INFO ] Epoch  3 Batch  300 Training err. 120.19375 Training err. RA 132.29063 Valid. err. 104.51943
2018-02-04 00:19:22,318 training [INFO ] Epoch  4 Batch  320 Training err. 129.15329 Training err. RA 132.09454 Valid. err. 129.35128
2018-02-04 00:19:22,862 training [INFO ] Epoch  4 Batch  340 Training err. 137.36065 Training err. RA 132.40431 Valid. err. 161.79022
2018-02-04 00:19:23,402 training [INFO ] Epoch  4 Batch  360 Training err. 122.25705 Training err. RA 131.84058 Valid. err. 142.94066
2018-02-04 00:19:23,949 training [INFO ] Epoch  4 Batch  380 Training err. 120.27978 Training err. RA 131.23211 Valid. err. 143.82636
2018-02-04 00:19:24,499 training [INFO ] Epoch  4 Batch  400 Training err. 126.24693 Training err. RA 130.98286 Valid. err. 147.54256
2018-02-04 00:19:25,404 training [INFO ] Epoch  5 Batch  420 Training err. 119.65876 Training err. RA 130.44361 Valid. err. 135.26410
2018-02-04 00:19:25,937 training [INFO ] Epoch  5 Batch  440 Training err. 136.78115 Training err. RA 130.73168 Valid. err. 117.90888
2018-02-04 00:19:26,466 training [INFO ] Epoch  5 Batch  460 Training err. 120.78368 Training err. RA 130.29916 Valid. err. 130.52161
2018-02-04 00:19:26,998 training [INFO ] Epoch  5 Batch  480 Training err. 120.36160 Training err. RA 129.88510 Valid. err. 127.69028
2018-02-04 00:19:27,540 training [INFO ] Epoch  5 Batch  500 Training err. 109.96956 Training err. RA 129.08847 Valid. err. 162.84103
2018-02-04 00:19:28,072 training [INFO ] Epoch  5 Batch  520 Training err. 132.41039 Training err. RA 129.21624 Valid. err. 143.88409
2018-02-04 00:19:28,974 training [INFO ] Epoch  6 Batch  540 Training err. 128.87715 Training err. RA 129.20368 Valid. err. 121.99688
2018-02-04 00:19:29,510 training [INFO ] Epoch  6 Batch  560 Training err. 128.26658 Training err. RA 129.17021 Valid. err. 88.04081
2018-02-04 00:19:30,056 training [INFO ] Epoch  6 Batch  580 Training err. 122.88507 Training err. RA 128.95348 Valid. err. 160.04639
2018-02-04 00:19:30,612 training [INFO ] Epoch  6 Batch  600 Training err. 114.69055 Training err. RA 128.47805 Valid. err. 101.19996
2018-02-04 00:19:31,157 training [INFO ] Epoch  6 Batch  620 Training err. 108.01981 Training err. RA 127.81811 Valid. err. 119.88147
2018-02-04 00:19:32,072 training [INFO ] Epoch  7 Batch  640 Training err. 121.77095 Training err. RA 127.62914 Valid. err. 157.85652
2018-02-04 00:19:32,615 training [INFO ] Epoch  7 Batch  660 Training err. 124.45823 Training err. RA 127.53305 Valid. err. 111.14529
2018-02-04 00:19:33,163 training [INFO ] Epoch  7 Batch  680 Training err. 111.31899 Training err. RA 127.05616 Valid. err. 116.97590
2018-02-04 00:19:33,692 training [INFO ] Epoch  7 Batch  700 Training err. 110.37775 Training err. RA 126.57964 Valid. err. 113.83906
2018-02-04 00:19:34,221 training [INFO ] Epoch  7 Batch  720 Training err. 119.64353 Training err. RA 126.38697 Valid. err. 87.46390
2018-02-04 00:19:35,121 training [INFO ] Epoch  8 Batch  740 Training err. 109.96492 Training err. RA 125.94313 Valid. err. 105.67822
2018-02-04 00:19:35,655 training [INFO ] Epoch  8 Batch  760 Training err. 118.56053 Training err. RA 125.74885 Valid. err. 79.59614
2018-02-04 00:19:36,190 training [INFO ] Epoch  8 Batch  780 Training err. 105.35554 Training err. RA 125.22595 Valid. err. 102.89409
2018-02-04 00:19:36,720 training [INFO ] Epoch  8 Batch  800 Training err. 127.84191 Training err. RA 125.29134 Valid. err. 93.93873
2018-02-04 00:19:37,258 training [INFO ] Epoch  8 Batch  820 Training err. 129.06287 Training err. RA 125.38333 Valid. err. 149.77603
2018-02-04 00:19:38,188 training [INFO ] Epoch  9 Batch  840 Training err. 119.52097 Training err. RA 125.24375 Valid. err. 137.16166
2018-02-04 00:19:38,735 training [INFO ] Epoch  9 Batch  860 Training err. 109.03907 Training err. RA 124.86690 Valid. err. 100.79958
2018-02-04 00:19:39,283 training [INFO ] Epoch  9 Batch  880 Training err. 111.31003 Training err. RA 124.55879 Valid. err. 143.69713
2018-02-04 00:19:39,825 training [INFO ] Epoch  9 Batch  900 Training err. 124.52004 Training err. RA 124.55793 Valid. err. 104.15171
2018-02-04 00:19:40,366 training [INFO ] Epoch  9 Batch  920 Training err. 114.20786 Training err. RA 124.33293 Valid. err. 114.43076
2018-02-04 00:19:41,277 training [INFO ] Epoch 10 Batch  940 Training err. 119.49427 Training err. RA 124.22998 Valid. err. 128.91864
2018-02-04 00:19:41,808 training [INFO ] Epoch 10 Batch  960 Training err. 112.35832 Training err. RA 123.98265 Valid. err. 83.45582
2018-02-04 00:19:42,344 training [INFO ] Epoch 10 Batch  980 Training err. 110.36237 Training err. RA 123.70469 Valid. err. 114.07984
2018-02-04 00:19:42,878 training [INFO ] Epoch 10 Batch 1000 Training err. 117.58813 Training err. RA 123.58235 Valid. err. 136.23110
2018-02-04 00:19:43,404 training [INFO ] Epoch 10 Batch 1020 Training err. 114.64616 Training err. RA 123.40713 Valid. err. 147.89853
2018-02-04 00:19:43,939 training [INFO ] Epoch 10 Batch 1040 Training err. 119.03912 Training err. RA 123.32313 Valid. err. 105.10742
2018-02-04 00:19:44,834 training [INFO ] Epoch 11 Batch 1060 Training err. 130.30930 Training err. RA 123.45495 Valid. err. 109.53943
2018-02-04 00:19:45,372 training [INFO ] Epoch 11 Batch 1080 Training err. 109.87146 Training err. RA 123.20340 Valid. err. 111.23311
2018-02-04 00:19:45,909 training [INFO ] Epoch 11 Batch 1100 Training err. 121.08208 Training err. RA 123.16483 Valid. err. 146.55369
2018-02-04 00:19:46,438 training [INFO ] Epoch 11 Batch 1120 Training err. 102.95145 Training err. RA 122.80388 Valid. err. 91.78932
2018-02-04 00:19:46,977 training [INFO ] Epoch 11 Batch 1140 Training err. 116.55931 Training err. RA 122.69433 Valid. err. 93.99540
2018-02-04 00:19:47,887 training [INFO ] Epoch 12 Batch 1160 Training err. 114.23689 Training err. RA 122.54851 Valid. err. 95.98599
2018-02-04 00:19:48,433 training [INFO ] Epoch 12 Batch 1180 Training err. 104.19021 Training err. RA 122.23735 Valid. err. 123.31405
2018-02-04 00:19:49,009 training [INFO ] Epoch 12 Batch 1200 Training err. 96.79657 Training err. RA 121.81334 Valid. err. 121.98705
2018-02-04 00:19:49,556 training [INFO ] Epoch 12 Batch 1220 Training err. 126.17973 Training err. RA 121.88492 Valid. err. 132.25894
2018-02-04 00:19:50,113 training [INFO ] Epoch 12 Batch 1240 Training err. 116.70943 Training err. RA 121.80144 Valid. err. 114.19815
2018-02-04 00:19:51,075 training [INFO ] Epoch 13 Batch 1260 Training err. 99.48719 Training err. RA 121.44725 Valid. err. 97.27025
2018-02-04 00:19:51,649 training [INFO ] Epoch 13 Batch 1280 Training err. 109.60315 Training err. RA 121.26218 Valid. err. 120.08284
2018-02-04 00:19:52,217 training [INFO ] Epoch 13 Batch 1300 Training err. 103.46272 Training err. RA 120.98835 Valid. err. 112.24740
2018-02-04 00:19:52,790 training [INFO ] Epoch 13 Batch 1320 Training err. 113.27678 Training err. RA 120.87150 Valid. err. 134.98950
2018-02-04 00:19:53,364 training [INFO ] Epoch 13 Batch 1340 Training err. 114.11718 Training err. RA 120.77069 Valid. err. 95.56559
2018-02-04 00:19:54,416 training [INFO ] Epoch 14 Batch 1360 Training err. 111.09248 Training err. RA 120.62837 Valid. err. 135.82254
2018-02-04 00:19:54,978 training [INFO ] Epoch 14 Batch 1380 Training err. 100.59388 Training err. RA 120.33801 Valid. err. 113.90699
2018-02-04 00:19:55,549 training [INFO ] Epoch 14 Batch 1400 Training err. 100.96246 Training err. RA 120.06122 Valid. err. 116.50216
2018-02-04 00:19:56,098 training [INFO ] Epoch 14 Batch 1420 Training err. 99.17534 Training err. RA 119.76705 Valid. err. 83.12807
2018-02-04 00:19:56,648 training [INFO ] Epoch 14 Batch 1440 Training err. 103.51120 Training err. RA 119.54128 Valid. err. 130.29252
2018-02-04 00:19:57,584 training [INFO ] Epoch 15 Batch 1460 Training err. 110.25517 Training err. RA 119.41407 Valid. err. 140.33368
2018-02-04 00:19:58,126 training [INFO ] Epoch 15 Batch 1480 Training err. 108.62908 Training err. RA 119.26833 Valid. err. 104.55134
2018-02-04 00:19:58,674 training [INFO ] Epoch 15 Batch 1500 Training err. 106.68103 Training err. RA 119.10049 Valid. err. 104.55630
2018-02-04 00:19:59,220 training [INFO ] Epoch 15 Batch 1520 Training err. 114.54189 Training err. RA 119.04051 Valid. err. 120.31269
2018-02-04 00:19:59,779 training [INFO ] Epoch 15 Batch 1540 Training err. 115.39853 Training err. RA 118.99321 Valid. err. 108.60014
2018-02-04 00:20:00,348 training [INFO ] Epoch 15 Batch 1560 Training err. 105.18716 Training err. RA 118.81621 Valid. err. 105.80679
2018-02-04 00:20:01,266 training [INFO ] Epoch 16 Batch 1580 Training err. 100.47582 Training err. RA 118.58406 Valid. err. 98.33026
2018-02-04 00:20:01,807 training [INFO ] Epoch 16 Batch 1600 Training err. 101.42350 Training err. RA 118.36955 Valid. err. 77.45070
2018-02-04 00:20:02,348 training [INFO ] Epoch 16 Batch 1620 Training err. 97.29935 Training err. RA 118.10942 Valid. err. 130.61472
2018-02-04 00:20:02,885 training [INFO ] Epoch 16 Batch 1640 Training err. 100.93882 Training err. RA 117.90003 Valid. err. 105.80737
2018-02-04 00:20:03,424 training [INFO ] Epoch 16 Batch 1660 Training err. 105.29362 Training err. RA 117.74814 Valid. err. 107.23687
2018-02-04 00:20:04,324 training [INFO ] Epoch 17 Batch 1680 Training err. 99.99544 Training err. RA 117.53680 Valid. err. 89.87338
2018-02-04 00:20:04,866 training [INFO ] Epoch 17 Batch 1700 Training err. 98.90839 Training err. RA 117.31764 Valid. err. 109.41042
2018-02-04 00:20:05,407 training [INFO ] Epoch 17 Batch 1720 Training err. 114.98959 Training err. RA 117.29057 Valid. err. 126.20209
2018-02-04 00:20:05,955 training [INFO ] Epoch 17 Batch 1740 Training err. 111.59181 Training err. RA 117.22507 Valid. err. 82.68454
2018-02-04 00:20:06,498 training [INFO ] Epoch 17 Batch 1760 Training err. 103.78296 Training err. RA 117.07232 Valid. err. 61.02968
2018-02-04 00:20:07,419 training [INFO ] Epoch 18 Batch 1780 Training err. 103.01986 Training err. RA 116.91443 Valid. err. 110.52521
2018-02-04 00:20:07,971 training [INFO ] Epoch 18 Batch 1800 Training err. 112.13399 Training err. RA 116.86131 Valid. err. 102.46583
2018-02-04 00:20:08,513 training [INFO ] Epoch 18 Batch 1820 Training err. 87.39032 Training err. RA 116.53745 Valid. err. 108.45870
2018-02-04 00:20:09,055 training [INFO ] Epoch 18 Batch 1840 Training err. 114.67453 Training err. RA 116.51720 Valid. err. 91.51694
2018-02-04 00:20:09,594 training [INFO ] Epoch 18 Batch 1860 Training err. 116.28569 Training err. RA 116.51471 Valid. err. 133.97749
2018-02-04 00:20:10,497 training [INFO ] Epoch 19 Batch 1880 Training err. 109.63721 Training err. RA 116.44155 Valid. err. 73.73893
2018-02-04 00:20:11,041 training [INFO ] Epoch 19 Batch 1900 Training err. 103.70196 Training err. RA 116.30745 Valid. err. 83.49118
2018-02-04 00:20:11,572 training [INFO ] Epoch 19 Batch 1920 Training err. 111.19804 Training err. RA 116.25422 Valid. err. 93.93085
2018-02-04 00:20:12,104 training [INFO ] Epoch 19 Batch 1940 Training err. 114.35479 Training err. RA 116.23464 Valid. err. 101.61460
2018-02-04 00:20:12,637 training [INFO ] Epoch 19 Batch 1960 Training err. 99.66154 Training err. RA 116.06553 Valid. err. 98.08915
2018-02-04 00:20:13,541 training [INFO ] Epoch 20 Batch 1980 Training err. 111.59641 Training err. RA 116.02039 Valid. err. 143.06170
2018-02-04 00:20:14,083 training [INFO ] Epoch 20 Batch 2000 Training err. 109.04781 Training err. RA 115.95066 Valid. err. 131.80798
2018-02-04 00:20:14,613 training [INFO ] Epoch 20 Batch 2020 Training err. 105.22926 Training err. RA 115.84451 Valid. err. 131.16357
2018-02-04 00:20:15,151 training [INFO ] Epoch 20 Batch 2040 Training err. 119.97776 Training err. RA 115.88503 Valid. err. 122.10992
2018-02-04 00:20:15,689 training [INFO ] Epoch 20 Batch 2060 Training err. 124.94979 Training err. RA 115.97304 Valid. err. 117.26084
2018-02-04 00:20:16,226 training [INFO ] Epoch 20 Batch 2080 Training err. 103.29262 Training err. RA 115.85111 Valid. err. 100.20163
2018-02-04 00:20:17,130 training [INFO ] Epoch 21 Batch 2100 Training err. 107.26062 Training err. RA 115.76930 Valid. err. 118.00760
2018-02-04 00:20:17,670 training [INFO ] Epoch 21 Batch 2120 Training err. 106.36274 Training err. RA 115.68056 Valid. err. 114.34085
2018-02-04 00:20:18,218 training [INFO ] Epoch 21 Batch 2140 Training err. 114.85239 Training err. RA 115.67282 Valid. err. 143.49303
2018-02-04 00:20:18,754 training [INFO ] Epoch 21 Batch 2160 Training err. 96.28550 Training err. RA 115.49330 Valid. err. 82.78773
2018-02-04 00:20:19,298 training [INFO ] Epoch 21 Batch 2180 Training err. 87.71644 Training err. RA 115.23847 Valid. err. 69.99683
2018-02-04 00:20:20,221 training [INFO ] Epoch 22 Batch 2200 Training err. 81.75816 Training err. RA 114.93410 Valid. err. 96.97739
2018-02-04 00:20:20,755 training [INFO ] Epoch 22 Batch 2220 Training err. 106.16172 Training err. RA 114.85507 Valid. err. 154.55929
2018-02-04 00:20:21,370 training [INFO ] Epoch 22 Batch 2240 Training err. 104.55193 Training err. RA 114.76308 Valid. err. 112.99882
2018-02-04 00:20:22,059 training [INFO ] Epoch 22 Batch 2260 Training err. 107.10913 Training err. RA 114.69535 Valid. err. 95.57666
2018-02-04 00:20:22,750 training [INFO ] Epoch 22 Batch 2280 Training err. 105.92743 Training err. RA 114.61844 Valid. err. 83.50192
2018-02-04 00:20:23,942 training [INFO ] Epoch 23 Batch 2300 Training err. 79.01328 Training err. RA 114.30883 Valid. err. 102.42256
2018-02-04 00:20:24,656 training [INFO ] Epoch 23 Batch 2320 Training err. 105.40901 Training err. RA 114.23210 Valid. err. 101.68209
2018-02-04 00:20:25,293 training [INFO ] Epoch 23 Batch 2340 Training err. 109.58711 Training err. RA 114.19240 Valid. err. 61.08588
2018-02-04 00:20:25,886 training [INFO ] Epoch 23 Batch 2360 Training err. 96.60126 Training err. RA 114.04332 Valid. err. 97.48905
2018-02-04 00:20:26,458 training [INFO ] Epoch 23 Batch 2380 Training err. 105.33920 Training err. RA 113.97018 Valid. err. 135.48768
2018-02-04 00:20:27,417 training [INFO ] Epoch 24 Batch 2400 Training err. 93.87694 Training err. RA 113.80274 Valid. err. 81.57083
2018-02-04 00:20:27,989 training [INFO ] Epoch 24 Batch 2420 Training err. 96.76120 Training err. RA 113.66190 Valid. err. 81.07223
2018-02-04 00:20:28,556 training [INFO ] Epoch 24 Batch 2440 Training err. 96.04766 Training err. RA 113.51752 Valid. err. 86.33395
2018-02-04 00:20:29,123 training [INFO ] Epoch 24 Batch 2460 Training err. 105.78858 Training err. RA 113.45468 Valid. err. 138.63747
2018-02-04 00:20:29,660 training [INFO ] Epoch 24 Batch 2480 Training err. 116.41166 Training err. RA 113.47853 Valid. err. 99.66670
2018-02-04 00:20:30,583 training [INFO ] Epoch 25 Batch 2500 Training err. 97.19450 Training err. RA 113.34826 Valid. err. 110.06503
2018-02-04 00:20:31,122 training [INFO ] Epoch 25 Batch 2520 Training err. 105.31674 Training err. RA 113.28451 Valid. err. 113.23864
2018-02-04 00:20:31,661 training [INFO ] Epoch 25 Batch 2540 Training err. 103.10858 Training err. RA 113.20439 Valid. err. 102.02876
2018-02-04 00:20:32,188 training [INFO ] Epoch 25 Batch 2560 Training err. 123.73641 Training err. RA 113.28667 Valid. err. 106.22847
2018-02-04 00:20:32,729 training [INFO ] Epoch 25 Batch 2580 Training err. 105.34403 Training err. RA 113.22510 Valid. err. 83.94420
2018-02-04 00:20:33,270 training [INFO ] Epoch 25 Batch 2600 Training err. 94.42850 Training err. RA 113.08051 Valid. err. 63.45335
2018-02-04 00:20:34,166 training [INFO ] Epoch 26 Batch 2620 Training err. 105.72870 Training err. RA 113.02439 Valid. err. 103.52860
2018-02-04 00:20:34,706 training [INFO ] Epoch 26 Batch 2640 Training err. 107.58470 Training err. RA 112.98318 Valid. err. 93.70949
2018-02-04 00:20:35,244 training [INFO ] Epoch 26 Batch 2660 Training err. 105.10128 Training err. RA 112.92392 Valid. err. 107.25517
2018-02-04 00:20:35,783 training [INFO ] Epoch 26 Batch 2680 Training err. 114.17768 Training err. RA 112.93327 Valid. err. 101.04537
2018-02-04 00:20:36,326 training [INFO ] Epoch 26 Batch 2700 Training err. 112.13674 Training err. RA 112.92737 Valid. err. 83.65439
2018-02-04 00:20:37,233 training [INFO ] Epoch 27 Batch 2720 Training err. 86.15923 Training err. RA 112.73055 Valid. err. 114.58734
2018-02-04 00:20:37,774 training [INFO ] Epoch 27 Batch 2740 Training err. 100.40388 Training err. RA 112.64057 Valid. err. 107.10731
2018-02-04 00:20:38,319 training [INFO ] Epoch 27 Batch 2760 Training err. 93.75217 Training err. RA 112.50370 Valid. err. 133.21394
2018-02-04 00:20:38,860 training [INFO ] Epoch 27 Batch 2780 Training err. 95.01696 Training err. RA 112.37790 Valid. err. 79.44745
2018-02-04 00:20:39,404 training [INFO ] Epoch 27 Batch 2800 Training err. 103.03799 Training err. RA 112.31118 Valid. err. 88.25098
2018-02-04 00:20:40,299 training [INFO ] Epoch 28 Batch 2820 Training err. 112.85930 Training err. RA 112.31507 Valid. err. 100.67188
2018-02-04 00:20:40,840 training [INFO ] Epoch 28 Batch 2840 Training err. 96.23530 Training err. RA 112.20183 Valid. err. 80.46879
2018-02-04 00:20:41,423 training [INFO ] Epoch 28 Batch 2860 Training err. 97.66723 Training err. RA 112.10019 Valid. err. 89.24131
2018-02-04 00:20:42,081 training [INFO ] Epoch 28 Batch 2880 Training err. 108.17960 Training err. RA 112.07297 Valid. err. 91.19785
2018-02-04 00:20:42,769 training [INFO ] Epoch 28 Batch 2900 Training err. 98.45904 Training err. RA 111.97908 Valid. err. 95.16780
2018-02-04 00:20:43,952 training [INFO ] Epoch 29 Batch 2920 Training err. 106.62478 Training err. RA 111.94240 Valid. err. 92.32521
2018-02-04 00:20:44,644 training [INFO ] Epoch 29 Batch 2940 Training err. 88.73290 Training err. RA 111.78452 Valid. err. 125.95956
2018-02-04 00:20:45,276 training [INFO ] Epoch 29 Batch 2960 Training err. 102.18410 Training err. RA 111.71965 Valid. err. 80.69872
2018-02-04 00:20:45,851 training [INFO ] Epoch 29 Batch 2980 Training err. 107.25693 Training err. RA 111.68970 Valid. err. 106.53190
2018-02-04 00:20:46,425 training [INFO ] Epoch 29 Batch 3000 Training err. 111.74603 Training err. RA 111.69007 Valid. err. 58.93557
2018-02-04 00:20:47,407 training [INFO ] Epoch 30 Batch 3020 Training err. 90.68417 Training err. RA 111.55096 Valid. err. 81.93897
2018-02-04 00:20:47,975 training [INFO ] Epoch 30 Batch 3040 Training err. 109.36161 Training err. RA 111.53656 Valid. err. 81.70636
2018-02-04 00:20:48,547 training [INFO ] Epoch 30 Batch 3060 Training err. 105.49950 Training err. RA 111.49710 Valid. err. 121.06619
2018-02-04 00:20:49,115 training [INFO ] Epoch 30 Batch 3080 Training err. 106.50122 Training err. RA 111.46466 Valid. err. 126.69033
2018-02-04 00:20:49,655 training [INFO ] Epoch 30 Batch 3100 Training err. 114.30827 Training err. RA 111.48300 Valid. err. 91.83294
2018-02-04 00:20:50,199 training [INFO ] Epoch 30 Batch 3120 Training err. 91.20075 Training err. RA 111.35299 Valid. err. 64.21045
2018-02-04 00:20:51,124 training [INFO ] Epoch 31 Batch 3140 Training err. 89.43198 Training err. RA 111.21337 Valid. err. 76.94802
2018-02-04 00:20:51,659 training [INFO ] Epoch 31 Batch 3160 Training err. 83.10472 Training err. RA 111.03546 Valid. err. 69.62960
2018-02-04 00:20:52,201 training [INFO ] Epoch 31 Batch 3180 Training err. 92.10356 Training err. RA 110.91639 Valid. err. 109.13067
2018-02-04 00:20:52,744 training [INFO ] Epoch 31 Batch 3200 Training err. 99.11966 Training err. RA 110.84266 Valid. err. 75.00549
2018-02-04 00:20:53,283 training [INFO ] Epoch 31 Batch 3220 Training err. 93.99363 Training err. RA 110.73801 Valid. err. 88.78780
2018-02-04 00:20:54,187 training [INFO ] Epoch 32 Batch 3240 Training err. 105.66967 Training err. RA 110.70673 Valid. err. 89.39777
2018-02-04 00:20:54,722 training [INFO ] Epoch 32 Batch 3260 Training err. 91.94945 Training err. RA 110.59165 Valid. err. 96.57783
2018-02-04 00:20:55,256 training [INFO ] Epoch 32 Batch 3280 Training err. 106.39827 Training err. RA 110.56608 Valid. err. 87.49711
2018-02-04 00:20:55,802 training [INFO ] Epoch 32 Batch 3300 Training err. 114.68905 Training err. RA 110.59107 Valid. err. 97.06075
2018-02-04 00:20:56,342 training [INFO ] Epoch 32 Batch 3320 Training err. 95.07461 Training err. RA 110.49760 Valid. err. 94.29750
2018-02-04 00:20:57,252 training [INFO ] Epoch 33 Batch 3340 Training err. 100.87951 Training err. RA 110.44000 Valid. err. 86.45593
2018-02-04 00:20:57,791 training [INFO ] Epoch 33 Batch 3360 Training err. 93.53744 Training err. RA 110.33939 Valid. err. 123.16848
2018-02-04 00:20:58,334 training [INFO ] Epoch 33 Batch 3380 Training err. 105.18828 Training err. RA 110.30891 Valid. err. 68.51404
2018-02-04 00:20:58,877 training [INFO ] Epoch 33 Batch 3400 Training err. 89.65285 Training err. RA 110.18741 Valid. err. 137.91517
2018-02-04 00:20:59,419 training [INFO ] Epoch 33 Batch 3420 Training err. 109.54557 Training err. RA 110.18365 Valid. err. 95.70704
2018-02-04 00:21:00,331 training [INFO ] Epoch 34 Batch 3440 Training err. 98.20737 Training err. RA 110.11402 Valid. err. 109.43773
2018-02-04 00:21:00,863 training [INFO ] Epoch 34 Batch 3460 Training err. 100.56248 Training err. RA 110.05881 Valid. err. 124.84172
2018-02-04 00:21:01,401 training [INFO ] Epoch 34 Batch 3480 Training err. 89.67264 Training err. RA 109.94165 Valid. err. 66.71143
2018-02-04 00:21:01,941 training [INFO ] Epoch 34 Batch 3500 Training err. 98.98370 Training err. RA 109.87903 Valid. err. 106.51763
2018-02-04 00:21:02,481 training [INFO ] Epoch 34 Batch 3520 Training err. 118.39433 Training err. RA 109.92742 Valid. err. 88.08483
2018-02-04 00:21:03,383 training [INFO ] Epoch 35 Batch 3540 Training err. 113.05438 Training err. RA 109.94508 Valid. err. 122.70633
2018-02-04 00:21:03,923 training [INFO ] Epoch 35 Batch 3560 Training err. 103.66969 Training err. RA 109.90983 Valid. err. 95.73556
2018-02-04 00:21:04,463 training [INFO ] Epoch 35 Batch 3580 Training err. 91.75869 Training err. RA 109.80842 Valid. err. 82.58970
2018-02-04 00:21:05,004 training [INFO ] Epoch 35 Batch 3600 Training err. 82.94767 Training err. RA 109.65920 Valid. err. 60.73639
2018-02-04 00:21:05,541 training [INFO ] Epoch 35 Batch 3620 Training err. 84.44489 Training err. RA 109.51989 Valid. err. 74.27290
2018-02-04 00:21:06,088 training [INFO ] Epoch 35 Batch 3640 Training err. 97.39366 Training err. RA 109.45326 Valid. err. 92.77361
2018-02-04 00:21:07,010 training [INFO ] Epoch 36 Batch 3660 Training err. 97.18755 Training err. RA 109.38624 Valid. err. 88.64240
2018-02-04 00:21:07,541 training [INFO ] Epoch 36 Batch 3680 Training err. 101.01814 Training err. RA 109.34076 Valid. err. 79.54861
2018-02-04 00:21:08,083 training [INFO ] Epoch 36 Batch 3700 Training err. 86.68679 Training err. RA 109.21831 Valid. err. 115.74457
2018-02-04 00:21:08,616 training [INFO ] Epoch 36 Batch 3720 Training err. 89.62389 Training err. RA 109.11296 Valid. err. 104.24976
2018-02-04 00:21:09,156 training [INFO ] Epoch 36 Batch 3740 Training err. 100.85964 Training err. RA 109.06882 Valid. err. 98.63365
2018-02-04 00:21:10,069 training [INFO ] Epoch 37 Batch 3760 Training err. 98.71802 Training err. RA 109.01377 Valid. err. 136.43628
2018-02-04 00:21:10,597 training [INFO ] Epoch 37 Batch 3780 Training err. 107.49540 Training err. RA 109.00573 Valid. err. 77.51864
2018-02-04 00:21:11,136 training [INFO ] Epoch 37 Batch 3800 Training err. 108.00376 Training err. RA 109.00046 Valid. err. 98.84510
2018-02-04 00:21:11,670 training [INFO ] Epoch 37 Batch 3820 Training err. 102.01747 Training err. RA 108.96390 Valid. err. 85.93729
2018-02-04 00:21:12,215 training [INFO ] Epoch 37 Batch 3840 Training err. 97.59461 Training err. RA 108.90468 Valid. err. 116.21177
2018-02-04 00:21:13,118 training [INFO ] Epoch 38 Batch 3860 Training err. 85.74737 Training err. RA 108.78470 Valid. err. 105.65063
2018-02-04 00:21:13,657 training [INFO ] Epoch 38 Batch 3880 Training err. 96.85202 Training err. RA 108.72319 Valid. err. 126.08723
2018-02-04 00:21:14,199 training [INFO ] Epoch 38 Batch 3900 Training err. 101.85352 Training err. RA 108.68796 Valid. err. 74.87096
2018-02-04 00:21:14,741 training [INFO ] Epoch 38 Batch 3920 Training err. 85.24360 Training err. RA 108.56835 Valid. err. 61.51060
2018-02-04 00:21:15,283 training [INFO ] Epoch 38 Batch 3940 Training err. 100.08979 Training err. RA 108.52531 Valid. err. 98.60029
2018-02-04 00:21:16,202 training [INFO ] Epoch 39 Batch 3960 Training err. 108.50640 Training err. RA 108.52521 Valid. err. 98.85751
2018-02-04 00:21:16,745 training [INFO ] Epoch 39 Batch 3980 Training err. 93.61669 Training err. RA 108.45030 Valid. err. 88.74047
2018-02-04 00:21:17,363 training [INFO ] Epoch 39 Batch 4000 Training err. 86.70830 Training err. RA 108.34159 Valid. err. 71.53095
2018-02-04 00:21:18,047 training [INFO ] Epoch 39 Batch 4020 Training err. 93.07156 Training err. RA 108.26561 Valid. err. 89.12496
2018-02-04 00:21:18,729 training [INFO ] Epoch 39 Batch 4040 Training err. 92.80119 Training err. RA 108.18906 Valid. err. 126.21039
2018-02-04 00:21:19,906 training [INFO ] Epoch 40 Batch 4060 Training err. 89.27927 Training err. RA 108.09591 Valid. err. 98.96660
2018-02-04 00:21:20,593 training [INFO ] Epoch 40 Batch 4080 Training err. 104.18062 Training err. RA 108.07671 Valid. err. 79.00637
2018-02-04 00:21:21,244 training [INFO ] Epoch 40 Batch 4100 Training err. 85.90206 Training err. RA 107.96855 Valid. err. 112.73873
2018-02-04 00:21:21,826 training [INFO ] Epoch 40 Batch 4120 Training err. 95.61992 Training err. RA 107.90860 Valid. err. 108.14888
2018-02-04 00:21:22,411 training [INFO ] Epoch 40 Batch 4140 Training err. 103.02267 Training err. RA 107.88500 Valid. err. 92.27301
2018-02-04 00:21:23,006 training [INFO ] Epoch 40 Batch 4160 Training err. 87.73652 Training err. RA 107.78813 Valid. err. 73.47100
2018-02-04 00:21:23,987 training [INFO ] Epoch 41 Batch 4180 Training err. 85.14995 Training err. RA 107.67981 Valid. err. 96.08373
2018-02-04 00:21:24,559 training [INFO ] Epoch 41 Batch 4200 Training err. 84.47750 Training err. RA 107.56933 Valid. err. 74.99027
2018-02-04 00:21:25,121 training [INFO ] Epoch 41 Batch 4220 Training err. 94.35098 Training err. RA 107.50668 Valid. err. 94.97846
2018-02-04 00:21:25,657 training [INFO ] Epoch 41 Batch 4240 Training err. 79.22993 Training err. RA 107.37330 Valid. err. 90.84542
2018-02-04 00:21:26,195 training [INFO ] Epoch 41 Batch 4260 Training err. 103.06443 Training err. RA 107.35307 Valid. err. 89.48099
2018-02-04 00:21:27,130 training [INFO ] Epoch 42 Batch 4280 Training err. 89.47981 Training err. RA 107.26955 Valid. err. 103.22365
2018-02-04 00:21:27,667 training [INFO ] Epoch 42 Batch 4300 Training err. 102.82402 Training err. RA 107.24887 Valid. err. 77.34321
2018-02-04 00:21:28,213 training [INFO ] Epoch 42 Batch 4320 Training err. 90.53989 Training err. RA 107.17152 Valid. err. 102.30669
2018-02-04 00:21:28,756 training [INFO ] Epoch 42 Batch 4340 Training err. 85.31701 Training err. RA 107.07080 Valid. err. 79.62988
2018-02-04 00:21:29,292 training [INFO ] Epoch 42 Batch 4360 Training err. 84.33988 Training err. RA 106.96653 Valid. err. 111.37375
2018-02-04 00:21:30,190 training [INFO ] Epoch 43 Batch 4380 Training err. 87.01478 Training err. RA 106.87543 Valid. err. 57.28607
2018-02-04 00:21:30,722 training [INFO ] Epoch 43 Batch 4400 Training err. 81.21611 Training err. RA 106.75880 Valid. err. 101.53993
2018-02-04 00:21:31,260 training [INFO ] Epoch 43 Batch 4420 Training err. 102.50369 Training err. RA 106.73954 Valid. err. 106.78591
2018-02-04 00:21:31,799 training [INFO ] Epoch 43 Batch 4440 Training err. 95.94247 Training err. RA 106.69091 Valid. err. 86.81748
2018-02-04 00:21:32,329 training [INFO ] Epoch 43 Batch 4460 Training err. 98.21700 Training err. RA 106.65291 Valid. err. 90.26848
2018-02-04 00:21:33,233 training [INFO ] Epoch 44 Batch 4480 Training err. 92.30788 Training err. RA 106.58887 Valid. err. 105.78585
2018-02-04 00:21:33,768 training [INFO ] Epoch 44 Batch 4500 Training err. 97.95781 Training err. RA 106.55051 Valid. err. 75.51053
2018-02-04 00:21:34,308 training [INFO ] Epoch 44 Batch 4520 Training err. 89.06517 Training err. RA 106.47314 Valid. err. 114.33797
2018-02-04 00:21:34,856 training [INFO ] Epoch 44 Batch 4540 Training err. 110.88059 Training err. RA 106.49255 Valid. err. 86.85606
2018-02-04 00:21:35,397 training [INFO ] Epoch 44 Batch 4560 Training err. 104.39045 Training err. RA 106.48333 Valid. err. 148.69918
2018-02-04 00:21:36,305 training [INFO ] Epoch 45 Batch 4580 Training err. 100.87716 Training err. RA 106.45885 Valid. err. 77.59912
2018-02-04 00:21:36,841 training [INFO ] Epoch 45 Batch 4600 Training err. 96.93838 Training err. RA 106.41746 Valid. err. 129.41734
2018-02-04 00:21:37,379 training [INFO ] Epoch 45 Batch 4620 Training err. 99.19250 Training err. RA 106.38618 Valid. err. 110.57054
2018-02-04 00:21:37,924 training [INFO ] Epoch 45 Batch 4640 Training err. 97.78445 Training err. RA 106.34911 Valid. err. 98.43252
2018-02-04 00:21:38,463 training [INFO ] Epoch 45 Batch 4660 Training err. 102.38074 Training err. RA 106.33207 Valid. err. 105.06741
2018-02-04 00:21:38,999 training [INFO ] Epoch 45 Batch 4680 Training err. 76.51288 Training err. RA 106.20464 Valid. err. 53.95611
2018-02-04 00:21:39,899 training [INFO ] Epoch 46 Batch 4700 Training err. 89.18428 Training err. RA 106.13222 Valid. err. 94.60812
2018-02-04 00:21:40,434 training [INFO ] Epoch 46 Batch 4720 Training err. 97.66043 Training err. RA 106.09632 Valid. err. 94.55075
2018-02-04 00:21:40,979 training [INFO ] Epoch 46 Batch 4740 Training err. 101.33659 Training err. RA 106.07623 Valid. err. 127.55528
2018-02-04 00:21:41,519 training [INFO ] Epoch 46 Batch 4760 Training err. 90.83738 Training err. RA 106.01221 Valid. err. 105.15510
2018-02-04 00:21:42,061 training [INFO ] Epoch 46 Batch 4780 Training err. 92.59851 Training err. RA 105.95608 Valid. err. 101.08242
2018-02-04 00:21:42,965 training [INFO ] Epoch 47 Batch 4800 Training err. 77.46779 Training err. RA 105.83738 Valid. err. 61.22118
2018-02-04 00:21:43,504 training [INFO ] Epoch 47 Batch 4820 Training err. 93.16487 Training err. RA 105.78480 Valid. err. 73.65980
2018-02-04 00:21:44,050 training [INFO ] Epoch 47 Batch 4840 Training err. 87.71163 Training err. RA 105.71011 Valid. err. 86.77997
2018-02-04 00:21:44,588 training [INFO ] Epoch 47 Batch 4860 Training err. 101.06179 Training err. RA 105.69099 Valid. err. 123.32852
2018-02-04 00:21:45,127 training [INFO ] Epoch 47 Batch 4880 Training err. 87.84031 Training err. RA 105.61783 Valid. err. 98.83066
2018-02-04 00:21:46,060 training [INFO ] Epoch 48 Batch 4900 Training err. 74.69055 Training err. RA 105.49159 Valid. err. 59.19249
2018-02-04 00:21:46,597 training [INFO ] Epoch 48 Batch 4920 Training err. 91.97994 Training err. RA 105.43667 Valid. err. 133.36749
2018-02-04 00:21:47,138 training [INFO ] Epoch 48 Batch 4940 Training err. 105.13715 Training err. RA 105.43546 Valid. err. 105.11388
2018-02-04 00:21:47,669 training [INFO ] Epoch 48 Batch 4960 Training err. 109.88496 Training err. RA 105.45340 Valid. err. 133.79153
2018-02-04 00:21:48,206 training [INFO ] Epoch 48 Batch 4980 Training err. 104.20915 Training err. RA 105.44840 Valid. err. 121.51438
2018-02-04 00:21:49,134 training [INFO ] Epoch 49 Batch 5000 Training err. 93.36303 Training err. RA 105.40006 Valid. err. 102.52277
2018-02-04 00:21:49,671 training [INFO ] Epoch 49 Batch 5020 Training err. 94.75414 Training err. RA 105.35764 Valid. err. 101.11516
2018-02-04 00:21:50,196 training [INFO ] Epoch 49 Batch 5040 Training err. 91.68723 Training err. RA 105.30340 Valid. err. 72.87813
2018-02-04 00:21:50,730 training [INFO ] Epoch 49 Batch 5060 Training err. 90.62034 Training err. RA 105.24536 Valid. err. 71.65211
2018-02-04 00:21:51,274 training [INFO ] Epoch 49 Batch 5080 Training err. 83.98671 Training err. RA 105.16167 Valid. err. 115.51315
2018-02-04 00:21:52,179 training [INFO ] Epoch 50 Batch 5100 Training err. 97.20499 Training err. RA 105.13046 Valid. err. 93.28912
2018-02-04 00:21:52,721 training [INFO ] Epoch 50 Batch 5120 Training err. 93.58332 Training err. RA 105.08536 Valid. err. 119.35553
2018-02-04 00:21:53,259 training [INFO ] Epoch 50 Batch 5140 Training err. 89.63567 Training err. RA 105.02524 Valid. err. 110.73159
2018-02-04 00:21:53,797 training [INFO ] Epoch 50 Batch 5160 Training err. 81.27502 Training err. RA 104.93319 Valid. err. 93.86410
2018-02-04 00:21:54,340 training [INFO ] Epoch 50 Batch 5180 Training err. 82.12618 Training err. RA 104.84513 Valid. err. 96.87548
2018-02-04 00:21:54,883 training [INFO ] Epoch 50 Batch 5200 Training err. 102.82455 Training err. RA 104.83736 Valid. err. 123.11978
2018-02-04 00:21:55,780 training [INFO ] Epoch 51 Batch 5220 Training err. 106.14563 Training err. RA 104.84237 Valid. err. 127.99803
2018-02-04 00:21:56,317 training [INFO ] Epoch 51 Batch 5240 Training err. 97.98715 Training err. RA 104.81620 Valid. err. 67.13042
2018-02-04 00:21:56,853 training [INFO ] Epoch 51 Batch 5260 Training err. 78.31857 Training err. RA 104.71545 Valid. err. 78.42230
2018-02-04 00:21:57,401 training [INFO ] Epoch 51 Batch 5280 Training err. 84.97871 Training err. RA 104.64069 Valid. err. 68.82859
2018-02-04 00:21:57,946 training [INFO ] Epoch 51 Batch 5300 Training err. 99.86171 Training err. RA 104.62266 Valid. err. 116.51026
2018-02-04 00:21:58,871 training [INFO ] Epoch 52 Batch 5320 Training err. 88.98533 Training err. RA 104.56387 Valid. err. 77.58139
2018-02-04 00:21:59,416 training [INFO ] Epoch 52 Batch 5340 Training err. 98.38342 Training err. RA 104.54072 Valid. err. 65.35972
2018-02-04 00:21:59,968 training [INFO ] Epoch 52 Batch 5360 Training err. 95.13010 Training err. RA 104.50561 Valid. err. 125.11749
2018-02-04 00:22:00,522 training [INFO ] Epoch 52 Batch 5380 Training err. 102.32582 Training err. RA 104.49751 Valid. err. 88.00623
2018-02-04 00:22:01,060 training [INFO ] Epoch 52 Batch 5400 Training err. 95.79129 Training err. RA 104.46526 Valid. err. 74.08109
2018-02-04 00:22:01,961 training [INFO ] Epoch 53 Batch 5420 Training err. 86.23750 Training err. RA 104.39800 Valid. err. 78.52823
2018-02-04 00:22:02,493 training [INFO ] Epoch 53 Batch 5440 Training err. 97.16605 Training err. RA 104.37141 Valid. err. 108.95501
2018-02-04 00:22:03,029 training [INFO ] Epoch 53 Batch 5460 Training err. 94.49964 Training err. RA 104.33525 Valid. err. 105.52643
2018-02-04 00:22:03,573 training [INFO ] Epoch 53 Batch 5480 Training err. 88.90450 Training err. RA 104.27894 Valid. err. 104.16153
2018-02-04 00:22:04,109 training [INFO ] Epoch 53 Batch 5500 Training err. 90.01352 Training err. RA 104.22706 Valid. err. 75.10664
2018-02-04 00:22:05,021 training [INFO ] Epoch 54 Batch 5520 Training err. 88.81945 Training err. RA 104.17124 Valid. err. 95.11756
2018-02-04 00:22:05,553 training [INFO ] Epoch 54 Batch 5540 Training err. 101.56200 Training err. RA 104.16182 Valid. err. 112.16286
2018-02-04 00:22:06,093 training [INFO ] Epoch 54 Batch 5560 Training err. 94.55588 Training err. RA 104.12726 Valid. err. 113.09964
2018-02-04 00:22:06,637 training [INFO ] Epoch 54 Batch 5580 Training err. 102.37004 Training err. RA 104.12096 Valid. err. 76.82498
2018-02-04 00:22:07,199 training [INFO ] Epoch 54 Batch 5600 Training err. 86.47104 Training err. RA 104.05793 Valid. err. 91.77172
2018-02-04 00:22:08,162 training [INFO ] Epoch 55 Batch 5620 Training err. 84.13310 Training err. RA 103.98702 Valid. err. 120.06024
2018-02-04 00:22:08,717 training [INFO ] Epoch 55 Batch 5640 Training err. 89.07832 Training err. RA 103.93415 Valid. err. 132.45155
2018-02-04 00:22:09,295 training [INFO ] Epoch 55 Batch 5660 Training err. 91.24363 Training err. RA 103.88931 Valid. err. 99.76031
2018-02-04 00:22:09,965 training [INFO ] Epoch 55 Batch 5680 Training err. 83.24804 Training err. RA 103.81663 Valid. err. 95.52625
2018-02-04 00:22:10,661 training [INFO ] Epoch 55 Batch 5700 Training err. 98.15805 Training err. RA 103.79678 Valid. err. 94.69671
2018-02-04 00:22:11,359 training [INFO ] Epoch 55 Batch 5720 Training err. 98.47125 Training err. RA 103.77816 Valid. err. 90.37521
2018-02-04 00:22:12,577 training [INFO ] Epoch 56 Batch 5740 Training err. 85.04628 Training err. RA 103.71289 Valid. err. 82.25181
2018-02-04 00:22:13,242 training [INFO ] Epoch 56 Batch 5760 Training err. 79.14240 Training err. RA 103.62757 Valid. err. 76.68703
2018-02-04 00:22:13,827 training [INFO ] Epoch 56 Batch 5780 Training err. 86.62904 Training err. RA 103.56876 Valid. err. 102.30665
2018-02-04 00:22:14,399 training [INFO ] Epoch 56 Batch 5800 Training err. 99.47732 Training err. RA 103.55465 Valid. err. 113.58859
2018-02-04 00:22:14,961 training [INFO ] Epoch 56 Batch 5820 Training err. 85.91491 Training err. RA 103.49403 Valid. err. 78.86115
2018-02-04 00:22:15,943 training [INFO ] Epoch 57 Batch 5840 Training err. 86.32189 Training err. RA 103.43522 Valid. err. 61.08940
2018-02-04 00:22:16,519 training [INFO ] Epoch 57 Batch 5860 Training err. 91.87121 Training err. RA 103.39575 Valid. err. 98.06110
2018-02-04 00:22:17,094 training [INFO ] Epoch 57 Batch 5880 Training err. 90.20579 Training err. RA 103.35089 Valid. err. 98.52431
2018-02-04 00:22:17,641 training [INFO ] Epoch 57 Batch 5900 Training err. 95.07414 Training err. RA 103.32283 Valid. err. 85.62005
2018-02-04 00:22:18,204 training [INFO ] Epoch 57 Batch 5920 Training err. 90.49585 Training err. RA 103.27950 Valid. err. 81.05380
2018-02-04 00:22:19,140 training [INFO ] Epoch 58 Batch 5940 Training err. 74.55580 Training err. RA 103.18279 Valid. err. 91.52626
2018-02-04 00:22:19,708 training [INFO ] Epoch 58 Batch 5960 Training err. 86.67979 Training err. RA 103.12741 Valid. err. 118.15347
2018-02-04 00:22:20,266 training [INFO ] Epoch 58 Batch 5980 Training err. 104.32631 Training err. RA 103.13142 Valid. err. 90.42514
2018-02-04 00:22:20,859 training [INFO ] Epoch 58 Batch 6000 Training err. 89.28592 Training err. RA 103.08526 Valid. err. 63.78460
2018-02-04 00:22:21,421 training [INFO ] Epoch 58 Batch 6020 Training err. 78.92090 Training err. RA 103.00498 Valid. err. 112.03369
2018-02-04 00:22:22,342 training [INFO ] Epoch 59 Batch 6040 Training err. 95.24834 Training err. RA 102.97930 Valid. err. 92.83176
2018-02-04 00:22:22,884 training [INFO ] Epoch 59 Batch 6060 Training err. 105.01918 Training err. RA 102.98603 Valid. err. 83.70550
2018-02-04 00:22:23,420 training [INFO ] Epoch 59 Batch 6080 Training err. 86.60210 Training err. RA 102.93214 Valid. err. 105.80760
2018-02-04 00:22:23,958 training [INFO ] Epoch 59 Batch 6100 Training err. 79.92210 Training err. RA 102.85669 Valid. err. 85.46596
2018-02-04 00:22:24,501 training [INFO ] Epoch 59 Batch 6120 Training err. 91.56237 Training err. RA 102.81979 Valid. err. 72.51364
2018-02-04 00:22:25,405 training [INFO ] Epoch 60 Batch 6140 Training err. 91.99389 Training err. RA 102.78452 Valid. err. 88.10355
2018-02-04 00:22:25,947 training [INFO ] Epoch 60 Batch 6160 Training err. 101.49560 Training err. RA 102.78034 Valid. err. 96.70164
2018-02-04 00:22:26,489 training [INFO ] Epoch 60 Batch 6180 Training err. 111.05290 Training err. RA 102.80711 Valid. err. 84.94884
2018-02-04 00:22:27,066 training [INFO ] Epoch 60 Batch 6200 Training err. 96.91046 Training err. RA 102.78809 Valid. err. 93.40363
2018-02-04 00:22:27,615 training [INFO ] Epoch 60 Batch 6220 Training err. 94.56473 Training err. RA 102.76165 Valid. err. 91.85655
2018-02-04 00:22:28,152 training [INFO ] Epoch 60 Batch 6240 Training err. 93.95298 Training err. RA 102.73341 Valid. err. 70.29940
2018-02-04 00:22:28,404 __main__ [INFO ] End of training
2018-02-05 00:11:53,975 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-05 00:11:54,011 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-05 00:11:54,016 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-05 00:11:54,017 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-05 00:12:06,090 training [INFO ] Epoch  1 Batch   50 Training err. 4.04851 Training err. RA 4.04851 Valid. err. 3.52132
2018-02-05 00:12:06,340 training [INFO ] Epoch  1 Batch  100 Training err. 3.40429 Training err. RA 3.72640 Valid. err. 3.29804
2018-02-05 00:12:06,585 training [INFO ] Epoch  1 Batch  150 Training err. 3.27764 Training err. RA 3.57681 Valid. err. 3.28309
2018-02-05 00:12:06,838 training [INFO ] Epoch  1 Batch  200 Training err. 3.26552 Training err. RA 3.49899 Valid. err. 3.25416
2018-02-05 00:12:07,085 training [INFO ] Epoch  1 Batch  250 Training err. 3.22068 Training err. RA 3.44333 Valid. err. 3.25685
2018-02-05 00:12:07,334 training [INFO ] Epoch  1 Batch  300 Training err. 3.26950 Training err. RA 3.41436 Valid. err. 3.22033
2018-02-05 00:12:07,682 training [INFO ] Epoch  2 Batch  350 Training err. 3.22430 Training err. RA 3.38721 Valid. err. 3.23463
2018-02-05 00:12:07,931 training [INFO ] Epoch  2 Batch  400 Training err. 3.22584 Training err. RA 3.36704 Valid. err. 3.24001
2018-02-05 00:12:08,180 training [INFO ] Epoch  2 Batch  450 Training err. 3.21406 Training err. RA 3.35004 Valid. err. 3.20766
2018-02-05 00:12:08,431 training [INFO ] Epoch  2 Batch  500 Training err. 3.20514 Training err. RA 3.33555 Valid. err. 3.21554
2018-02-05 00:12:08,679 training [INFO ] Epoch  2 Batch  550 Training err. 3.18747 Training err. RA 3.32209 Valid. err. 3.21847
2018-02-05 00:12:08,944 training [INFO ] Epoch  2 Batch  600 Training err. 3.20800 Training err. RA 3.31258 Valid. err. 3.17259
2018-02-05 00:12:09,330 training [INFO ] Epoch  3 Batch  650 Training err. 3.18283 Training err. RA 3.30260 Valid. err. 3.18070
2018-02-05 00:12:09,595 training [INFO ] Epoch  3 Batch  700 Training err. 3.17474 Training err. RA 3.29347 Valid. err. 3.16621
2018-02-05 00:12:09,846 training [INFO ] Epoch  3 Batch  750 Training err. 3.13064 Training err. RA 3.28261 Valid. err. 3.13971
2018-02-05 00:12:10,092 training [INFO ] Epoch  3 Batch  800 Training err. 3.14100 Training err. RA 3.27376 Valid. err. 3.11609
2018-02-05 00:12:10,341 training [INFO ] Epoch  3 Batch  850 Training err. 3.08308 Training err. RA 3.26254 Valid. err. 3.15780
2018-02-05 00:12:10,589 training [INFO ] Epoch  3 Batch  900 Training err. 3.12691 Training err. RA 3.25501 Valid. err. 3.05476
2018-02-05 00:12:10,941 training [INFO ] Epoch  4 Batch  950 Training err. 3.09180 Training err. RA 3.24642 Valid. err. 3.08607
2018-02-05 00:12:11,187 training [INFO ] Epoch  4 Batch 1000 Training err. 3.02497 Training err. RA 3.23535 Valid. err. 2.99913
2018-02-05 00:12:11,440 training [INFO ] Epoch  4 Batch 1050 Training err. 2.96203 Training err. RA 3.22233 Valid. err. 2.97527
2018-02-05 00:12:11,688 training [INFO ] Epoch  4 Batch 1100 Training err. 2.94863 Training err. RA 3.20989 Valid. err. 2.90288
2018-02-05 00:12:11,936 training [INFO ] Epoch  4 Batch 1150 Training err. 2.89922 Training err. RA 3.19638 Valid. err. 2.95037
2018-02-05 00:12:12,184 training [INFO ] Epoch  4 Batch 1200 Training err. 2.90473 Training err. RA 3.18423 Valid. err. 2.84228
2018-02-05 00:12:12,541 training [INFO ] Epoch  5 Batch 1250 Training err. 2.93191 Training err. RA 3.17414 Valid. err. 2.92270
2018-02-05 00:12:12,790 training [INFO ] Epoch  5 Batch 1300 Training err. 2.87311 Training err. RA 3.16256 Valid. err. 2.83348
2018-02-05 00:12:13,038 training [INFO ] Epoch  5 Batch 1350 Training err. 2.77595 Training err. RA 3.14824 Valid. err. 2.79181
2018-02-05 00:12:13,284 training [INFO ] Epoch  5 Batch 1400 Training err. 2.79066 Training err. RA 3.13547 Valid. err. 2.77623
2018-02-05 00:12:13,522 training [INFO ] Epoch  5 Batch 1450 Training err. 2.79476 Training err. RA 3.12372 Valid. err. 2.75284
2018-02-05 00:12:13,776 training [INFO ] Epoch  5 Batch 1500 Training err. 2.75371 Training err. RA 3.11139 Valid. err. 2.71449
2018-02-05 00:12:14,129 training [INFO ] Epoch  6 Batch 1550 Training err. 2.83472 Training err. RA 3.10246 Valid. err. 2.71274
2018-02-05 00:12:14,381 training [INFO ] Epoch  6 Batch 1600 Training err. 2.77120 Training err. RA 3.09211 Valid. err. 2.75853
2018-02-05 00:12:14,631 training [INFO ] Epoch  6 Batch 1650 Training err. 2.69318 Training err. RA 3.08002 Valid. err. 2.67756
2018-02-05 00:12:14,885 training [INFO ] Epoch  6 Batch 1700 Training err. 2.66178 Training err. RA 3.06772 Valid. err. 2.68683
2018-02-05 00:12:15,128 training [INFO ] Epoch  6 Batch 1750 Training err. 2.73249 Training err. RA 3.05814 Valid. err. 2.66285
2018-02-05 00:12:15,387 training [INFO ] Epoch  6 Batch 1800 Training err. 2.63976 Training err. RA 3.04652 Valid. err. 2.63573
2018-02-05 00:12:15,736 training [INFO ] Epoch  7 Batch 1850 Training err. 2.73348 Training err. RA 3.03806 Valid. err. 2.66528
2018-02-05 00:12:15,985 training [INFO ] Epoch  7 Batch 1900 Training err. 2.71706 Training err. RA 3.02961 Valid. err. 2.61312
2018-02-05 00:12:16,239 training [INFO ] Epoch  7 Batch 1950 Training err. 2.60983 Training err. RA 3.01885 Valid. err. 2.59620
2018-02-05 00:12:16,476 training [INFO ] Epoch  7 Batch 2000 Training err. 2.57782 Training err. RA 3.00782 Valid. err. 2.57756
2018-02-05 00:12:16,718 training [INFO ] Epoch  7 Batch 2050 Training err. 2.67683 Training err. RA 2.99975 Valid. err. 2.56390
2018-02-05 00:12:16,968 training [INFO ] Epoch  7 Batch 2100 Training err. 2.55569 Training err. RA 2.98918 Valid. err. 2.55201
2018-02-05 00:12:17,320 training [INFO ] Epoch  8 Batch 2150 Training err. 2.62081 Training err. RA 2.98061 Valid. err. 2.53885
2018-02-05 00:12:17,571 training [INFO ] Epoch  8 Batch 2200 Training err. 2.69344 Training err. RA 2.97408 Valid. err. 2.52792
2018-02-05 00:12:17,821 training [INFO ] Epoch  8 Batch 2250 Training err. 2.56910 Training err. RA 2.96509 Valid. err. 2.54251
2018-02-05 00:12:18,072 training [INFO ] Epoch  8 Batch 2300 Training err. 2.53605 Training err. RA 2.95576 Valid. err. 2.52947
2018-02-05 00:12:18,322 training [INFO ] Epoch  8 Batch 2350 Training err. 2.59336 Training err. RA 2.94805 Valid. err. 2.53333
2018-02-05 00:12:18,573 training [INFO ] Epoch  8 Batch 2400 Training err. 2.48938 Training err. RA 2.93849 Valid. err. 2.49889
2018-02-05 00:12:18,825 training [INFO ] Epoch  8 Batch 2450 Training err. 2.56250 Training err. RA 2.93082 Valid. err. 2.51156
2018-02-05 00:12:19,176 training [INFO ] Epoch  9 Batch 2500 Training err. 2.61063 Training err. RA 2.92442 Valid. err. 2.53108
2018-02-05 00:12:19,427 training [INFO ] Epoch  9 Batch 2550 Training err. 2.57637 Training err. RA 2.91759 Valid. err. 2.48559
2018-02-05 00:12:19,680 training [INFO ] Epoch  9 Batch 2600 Training err. 2.49205 Training err. RA 2.90941 Valid. err. 2.46826
2018-02-05 00:12:19,928 training [INFO ] Epoch  9 Batch 2650 Training err. 2.55051 Training err. RA 2.90264 Valid. err. 2.50039
2018-02-05 00:12:20,177 training [INFO ] Epoch  9 Batch 2700 Training err. 2.44628 Training err. RA 2.89418 Valid. err. 2.49386
2018-02-05 00:12:20,430 training [INFO ] Epoch  9 Batch 2750 Training err. 2.49137 Training err. RA 2.88686 Valid. err. 2.44889
2018-02-05 00:12:20,805 training [INFO ] Epoch 10 Batch 2800 Training err. 2.54910 Training err. RA 2.88083 Valid. err. 2.48437
2018-02-05 00:12:21,071 training [INFO ] Epoch 10 Batch 2850 Training err. 2.55906 Training err. RA 2.87518 Valid. err. 2.46502
2018-02-05 00:12:21,346 training [INFO ] Epoch 10 Batch 2900 Training err. 2.45160 Training err. RA 2.86788 Valid. err. 2.42002
2018-02-05 00:12:21,597 training [INFO ] Epoch 10 Batch 2950 Training err. 2.50249 Training err. RA 2.86169 Valid. err. 2.45253
2018-02-05 00:12:21,847 training [INFO ] Epoch 10 Batch 3000 Training err. 2.43131 Training err. RA 2.85452 Valid. err. 2.40391
2018-02-05 00:12:22,333 training [INFO ] Epoch 10 Batch 3050 Training err. 2.44100 Training err. RA 2.84774 Valid. err. 2.42549
2018-02-05 00:12:22,497 __main__ [INFO ] End of training
2018-02-05 00:12:24,666 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-05 00:12:24,667 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-05 00:12:24,980 training [INFO ] Epoch  1 Batch   50 Training err. 4.04214 Training err. RA 4.04214 Valid. err. 3.54833
2018-02-05 00:12:25,304 training [INFO ] Epoch  1 Batch  100 Training err. 3.39814 Training err. RA 3.72014 Valid. err. 3.31442
2018-02-05 00:12:25,576 training [INFO ] Epoch  1 Batch  150 Training err. 3.27816 Training err. RA 3.57281 Valid. err. 3.25355
2018-02-05 00:12:25,883 training [INFO ] Epoch  1 Batch  200 Training err. 3.25863 Training err. RA 3.49427 Valid. err. 3.23396
2018-02-05 00:12:26,280 training [INFO ] Epoch  2 Batch  250 Training err. 3.25330 Training err. RA 3.44608 Valid. err. 3.25586
2018-02-05 00:12:26,571 training [INFO ] Epoch  2 Batch  300 Training err. 3.21729 Training err. RA 3.40794 Valid. err. 3.22208
2018-02-05 00:12:26,881 training [INFO ] Epoch  2 Batch  350 Training err. 3.21434 Training err. RA 3.38029 Valid. err. 3.22708
2018-02-05 00:12:27,182 training [INFO ] Epoch  2 Batch  400 Training err. 3.22115 Training err. RA 3.36039 Valid. err. 3.20212
2018-02-05 00:12:27,557 training [INFO ] Epoch  3 Batch  450 Training err. 3.23364 Training err. RA 3.34631 Valid. err. 3.21623
2018-02-05 00:12:27,855 training [INFO ] Epoch  3 Batch  500 Training err. 3.17546 Training err. RA 3.32923 Valid. err. 3.19916
2018-02-05 00:12:28,110 training [INFO ] Epoch  3 Batch  550 Training err. 3.19734 Training err. RA 3.31724 Valid. err. 3.20025
2018-02-05 00:12:28,367 training [INFO ] Epoch  3 Batch  600 Training err. 3.18341 Training err. RA 3.30608 Valid. err. 3.16973
2018-02-05 00:12:28,726 training [INFO ] Epoch  4 Batch  650 Training err. 3.19104 Training err. RA 3.29724 Valid. err. 3.16960
2018-02-05 00:12:28,974 training [INFO ] Epoch  4 Batch  700 Training err. 3.11587 Training err. RA 3.28428 Valid. err. 3.13092
2018-02-05 00:12:29,228 training [INFO ] Epoch  4 Batch  750 Training err. 3.11660 Training err. RA 3.27310 Valid. err. 3.10533
2018-02-05 00:12:29,512 training [INFO ] Epoch  4 Batch  800 Training err. 3.08383 Training err. RA 3.26127 Valid. err. 3.10539
2018-02-05 00:12:29,859 training [INFO ] Epoch  5 Batch  850 Training err. 3.09290 Training err. RA 3.25137 Valid. err. 3.05708
2018-02-05 00:12:30,130 training [INFO ] Epoch  5 Batch  900 Training err. 3.01284 Training err. RA 3.23812 Valid. err. 3.00853
2018-02-05 00:12:30,701 training [INFO ] Epoch  5 Batch  950 Training err. 2.97486 Training err. RA 3.22426 Valid. err. 2.94603
2018-02-05 00:12:31,132 training [INFO ] Epoch  5 Batch 1000 Training err. 2.91668 Training err. RA 3.20888 Valid. err. 2.89707
2018-02-05 00:12:31,562 training [INFO ] Epoch  6 Batch 1050 Training err. 2.95081 Training err. RA 3.19659 Valid. err. 2.87833
2018-02-05 00:12:32,055 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88961 Training err. RA 3.18264 Valid. err. 2.85112
2018-02-05 00:12:32,478 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83982 Training err. RA 3.16773 Valid. err. 2.80937
2018-02-05 00:12:32,788 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81488 Training err. RA 3.15303 Valid. err. 2.79451
2018-02-05 00:12:33,255 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87542 Training err. RA 3.14193 Valid. err. 2.84760
2018-02-05 00:12:33,591 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80802 Training err. RA 3.12908 Valid. err. 2.76413
2018-02-05 00:12:33,918 training [INFO ] Epoch  7 Batch 1350 Training err. 2.74761 Training err. RA 3.11496 Valid. err. 2.73305
2018-02-05 00:12:34,228 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74546 Training err. RA 3.10176 Valid. err. 2.72217
2018-02-05 00:12:34,602 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80934 Training err. RA 3.09168 Valid. err. 2.80859
2018-02-05 00:12:34,896 training [INFO ] Epoch  8 Batch 1500 Training err. 2.75365 Training err. RA 3.08041 Valid. err. 2.70634
2018-02-05 00:12:35,159 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69065 Training err. RA 3.06784 Valid. err. 2.68305
2018-02-05 00:12:35,421 training [INFO ] Epoch  8 Batch 1600 Training err. 2.68488 Training err. RA 3.05587 Valid. err. 2.69275
2018-02-05 00:12:35,789 training [INFO ] Epoch  9 Batch 1650 Training err. 2.75326 Training err. RA 3.04670 Valid. err. 2.64619
2018-02-05 00:12:36,068 training [INFO ] Epoch  9 Batch 1700 Training err. 2.70388 Training err. RA 3.03662 Valid. err. 2.64884
2018-02-05 00:12:36,395 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62870 Training err. RA 3.02496 Valid. err. 2.64648
2018-02-05 00:12:36,750 training [INFO ] Epoch  9 Batch 1800 Training err. 2.64168 Training err. RA 3.01431 Valid. err. 2.63541
2018-02-05 00:12:37,176 training [INFO ] Epoch 10 Batch 1850 Training err. 2.69184 Training err. RA 3.00560 Valid. err. 2.62022
2018-02-05 00:12:37,509 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66928 Training err. RA 2.99675 Valid. err. 2.66894
2018-02-05 00:12:37,848 training [INFO ] Epoch 10 Batch 1950 Training err. 2.57763 Training err. RA 2.98600 Valid. err. 2.57420
2018-02-05 00:12:38,171 training [INFO ] Epoch 10 Batch 2000 Training err. 2.61542 Training err. RA 2.97674 Valid. err. 2.56837
2018-02-05 00:12:38,497 training [INFO ] Epoch 10 Batch 2050 Training err. 2.59956 Training err. RA 2.96754 Valid. err. 2.56084
2018-02-05 00:12:38,597 __main__ [INFO ] End of training
2018-02-05 00:12:38,864 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-05 00:12:38,865 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-05 00:12:39,183 training [INFO ] Epoch  1 Batch   50 Training err. 4.25089 Training err. RA 4.25089 Valid. err. 4.07388
2018-02-05 00:12:39,455 training [INFO ] Epoch  1 Batch  100 Training err. 3.91735 Training err. RA 4.08412 Valid. err. 3.66513
2018-02-05 00:12:39,724 training [INFO ] Epoch  1 Batch  150 Training err. 3.58519 Training err. RA 3.91781 Valid. err. 3.43050
2018-02-05 00:12:39,982 training [INFO ] Epoch  1 Batch  200 Training err. 3.43288 Training err. RA 3.79658 Valid. err. 3.35624
2018-02-05 00:12:40,235 training [INFO ] Epoch  1 Batch  250 Training err. 3.35662 Training err. RA 3.70859 Valid. err. 3.32507
2018-02-05 00:12:40,521 training [INFO ] Epoch  1 Batch  300 Training err. 3.34314 Training err. RA 3.64768 Valid. err. 3.29843
2018-02-05 00:12:40,933 training [INFO ] Epoch  2 Batch  350 Training err. 3.30636 Training err. RA 3.59892 Valid. err. 3.27696
2018-02-05 00:12:41,215 training [INFO ] Epoch  2 Batch  400 Training err. 3.29690 Training err. RA 3.56117 Valid. err. 3.26078
2018-02-05 00:12:41,555 training [INFO ] Epoch  2 Batch  450 Training err. 3.24770 Training err. RA 3.52634 Valid. err. 3.26687
2018-02-05 00:12:41,843 training [INFO ] Epoch  2 Batch  500 Training err. 3.22835 Training err. RA 3.49654 Valid. err. 3.26708
2018-02-05 00:12:42,146 training [INFO ] Epoch  2 Batch  550 Training err. 3.27238 Training err. RA 3.47616 Valid. err. 3.24858
2018-02-05 00:12:42,407 training [INFO ] Epoch  2 Batch  600 Training err. 3.25082 Training err. RA 3.45738 Valid. err. 3.23533
2018-02-05 00:12:42,808 training [INFO ] Epoch  3 Batch  650 Training err. 3.26233 Training err. RA 3.44238 Valid. err. 3.24370
2018-02-05 00:12:43,096 training [INFO ] Epoch  3 Batch  700 Training err. 3.21580 Training err. RA 3.42619 Valid. err. 3.23970
2018-02-05 00:12:43,375 training [INFO ] Epoch  3 Batch  750 Training err. 3.23215 Training err. RA 3.41326 Valid. err. 3.24591
2018-02-05 00:12:43,661 training [INFO ] Epoch  3 Batch  800 Training err. 3.20004 Training err. RA 3.39993 Valid. err. 3.24128
2018-02-05 00:12:43,936 training [INFO ] Epoch  3 Batch  850 Training err. 3.24595 Training err. RA 3.39087 Valid. err. 3.22805
2018-02-05 00:12:44,225 training [INFO ] Epoch  3 Batch  900 Training err. 3.22280 Training err. RA 3.38154 Valid. err. 3.21908
2018-02-05 00:12:44,662 training [INFO ] Epoch  4 Batch  950 Training err. 3.22606 Training err. RA 3.37335 Valid. err. 3.22369
2018-02-05 00:12:45,041 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19468 Training err. RA 3.36442 Valid. err. 3.22399
2018-02-05 00:12:45,505 training [INFO ] Epoch  4 Batch 1050 Training err. 3.23040 Training err. RA 3.35804 Valid. err. 3.23087
2018-02-05 00:12:45,824 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18838 Training err. RA 3.35033 Valid. err. 3.22223
2018-02-05 00:12:46,132 training [INFO ] Epoch  4 Batch 1150 Training err. 3.22367 Training err. RA 3.34482 Valid. err. 3.21680
2018-02-05 00:12:46,434 training [INFO ] Epoch  4 Batch 1200 Training err. 3.19536 Training err. RA 3.33859 Valid. err. 3.20280
2018-02-05 00:12:46,839 training [INFO ] Epoch  5 Batch 1250 Training err. 3.21777 Training err. RA 3.33376 Valid. err. 3.20317
2018-02-05 00:12:47,091 training [INFO ] Epoch  5 Batch 1300 Training err. 3.18430 Training err. RA 3.32801 Valid. err. 3.19901
2018-02-05 00:12:47,388 training [INFO ] Epoch  5 Batch 1350 Training err. 3.21200 Training err. RA 3.32371 Valid. err. 3.20791
2018-02-05 00:12:47,798 training [INFO ] Epoch  5 Batch 1400 Training err. 3.14681 Training err. RA 3.31740 Valid. err. 3.19795
2018-02-05 00:12:48,257 training [INFO ] Epoch  5 Batch 1450 Training err. 3.20256 Training err. RA 3.31344 Valid. err. 3.18935
2018-02-05 00:12:48,683 training [INFO ] Epoch  5 Batch 1500 Training err. 3.16935 Training err. RA 3.30863 Valid. err. 3.18520
2018-02-05 00:12:49,291 training [INFO ] Epoch  6 Batch 1550 Training err. 3.19318 Training err. RA 3.30491 Valid. err. 3.17755
2018-02-05 00:12:49,695 training [INFO ] Epoch  6 Batch 1600 Training err. 3.17147 Training err. RA 3.30074 Valid. err. 3.16673
2018-02-05 00:12:50,157 training [INFO ] Epoch  6 Batch 1650 Training err. 3.18570 Training err. RA 3.29725 Valid. err. 3.16049
2018-02-05 00:12:50,554 training [INFO ] Epoch  6 Batch 1700 Training err. 3.08802 Training err. RA 3.29110 Valid. err. 3.16645
2018-02-05 00:12:50,974 training [INFO ] Epoch  6 Batch 1750 Training err. 3.17645 Training err. RA 3.28782 Valid. err. 3.14035
2018-02-05 00:12:51,394 training [INFO ] Epoch  6 Batch 1800 Training err. 3.12448 Training err. RA 3.28329 Valid. err. 3.12810
2018-02-05 00:12:51,908 training [INFO ] Epoch  7 Batch 1850 Training err. 3.12511 Training err. RA 3.27901 Valid. err. 3.11594
2018-02-05 00:12:52,199 training [INFO ] Epoch  7 Batch 1900 Training err. 3.14539 Training err. RA 3.27549 Valid. err. 3.13017
2018-02-05 00:12:52,470 training [INFO ] Epoch  7 Batch 1950 Training err. 3.12510 Training err. RA 3.27164 Valid. err. 3.09729
2018-02-05 00:12:52,748 training [INFO ] Epoch  7 Batch 2000 Training err. 3.02967 Training err. RA 3.26559 Valid. err. 3.07700
2018-02-05 00:12:53,008 training [INFO ] Epoch  7 Batch 2050 Training err. 3.10658 Training err. RA 3.26171 Valid. err. 3.06112
2018-02-05 00:12:53,273 training [INFO ] Epoch  7 Batch 2100 Training err. 3.03572 Training err. RA 3.25633 Valid. err. 3.03671
2018-02-05 00:12:53,646 training [INFO ] Epoch  8 Batch 2150 Training err. 3.04055 Training err. RA 3.25131 Valid. err. 3.01571
2018-02-05 00:12:53,898 training [INFO ] Epoch  8 Batch 2200 Training err. 3.07181 Training err. RA 3.24723 Valid. err. 2.99929
2018-02-05 00:12:54,172 training [INFO ] Epoch  8 Batch 2250 Training err. 3.04324 Training err. RA 3.24270 Valid. err. 2.97431
2018-02-05 00:12:54,433 training [INFO ] Epoch  8 Batch 2300 Training err. 2.94324 Training err. RA 3.23619 Valid. err. 2.99403
2018-02-05 00:12:54,705 training [INFO ] Epoch  8 Batch 2350 Training err. 2.96055 Training err. RA 3.23032 Valid. err. 2.94005
2018-02-05 00:12:54,999 training [INFO ] Epoch  8 Batch 2400 Training err. 2.95367 Training err. RA 3.22456 Valid. err. 2.93758
2018-02-05 00:12:55,249 training [INFO ] Epoch  8 Batch 2450 Training err. 2.93826 Training err. RA 3.21872 Valid. err. 2.91751
2018-02-05 00:12:55,654 training [INFO ] Epoch  9 Batch 2500 Training err. 2.97622 Training err. RA 3.21387 Valid. err. 2.93166
2018-02-05 00:12:55,904 training [INFO ] Epoch  9 Batch 2550 Training err. 2.96011 Training err. RA 3.20889 Valid. err. 2.87569
2018-02-05 00:12:56,159 training [INFO ] Epoch  9 Batch 2600 Training err. 2.87883 Training err. RA 3.20255 Valid. err. 2.88209
2018-02-05 00:12:56,440 training [INFO ] Epoch  9 Batch 2650 Training err. 2.82910 Training err. RA 3.19550 Valid. err. 2.86312
2018-02-05 00:12:56,722 training [INFO ] Epoch  9 Batch 2700 Training err. 2.87590 Training err. RA 3.18958 Valid. err. 2.86603
2018-02-05 00:12:56,983 training [INFO ] Epoch  9 Batch 2750 Training err. 2.89185 Training err. RA 3.18417 Valid. err. 2.83468
2018-02-05 00:12:57,338 training [INFO ] Epoch 10 Batch 2800 Training err. 2.91581 Training err. RA 3.17938 Valid. err. 2.84438
2018-02-05 00:12:57,611 training [INFO ] Epoch 10 Batch 2850 Training err. 2.84987 Training err. RA 3.17359 Valid. err. 2.84183
2018-02-05 00:12:57,930 training [INFO ] Epoch 10 Batch 2900 Training err. 2.86559 Training err. RA 3.16828 Valid. err. 2.85923
2018-02-05 00:12:58,190 training [INFO ] Epoch 10 Batch 2950 Training err. 2.77927 Training err. RA 3.16169 Valid. err. 2.81609
2018-02-05 00:12:58,444 training [INFO ] Epoch 10 Batch 3000 Training err. 2.81512 Training err. RA 3.15591 Valid. err. 2.78541
2018-02-05 00:12:58,718 training [INFO ] Epoch 10 Batch 3050 Training err. 2.83377 Training err. RA 3.15063 Valid. err. 2.78474
2018-02-05 00:12:58,939 __main__ [INFO ] End of training
2018-02-05 00:15:13,106 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:16:46,500 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:16:46,503 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:16:46,600 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:46,905 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:16:46,957 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:16:46,958 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:16:47,056 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:47,274 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:16:47,287 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:16:47,287 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:16:47,383 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:47,693 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:16:47,711 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:16:47,711 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:16:47,837 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:48,058 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:16:48,071 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:16:48,071 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:16:48,175 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:48,504 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:16:48,523 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:16:48,523 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:16:48,628 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:48,869 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:16:48,883 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:16:48,883 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:16:48,986 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:49,316 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:16:49,335 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:16:49,335 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:16:49,439 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:49,673 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:16:49,686 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:16:49,687 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:16:49,812 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:50,197 __main__ [INFO ] Evaluated on training set. Loss: 2.52835
2018-02-05 00:16:50,219 __main__ [INFO ] Evaluated on validation set. Loss: 2.68919
2018-02-05 00:16:50,219 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:16:50,347 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:50,615 __main__ [INFO ] Evaluated on training set. Loss: 2.50673
2018-02-05 00:16:50,630 __main__ [INFO ] Evaluated on validation set. Loss: 2.73057
2018-02-05 00:16:50,630 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:16:50,758 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:51,142 __main__ [INFO ] Evaluated on training set. Loss: 2.53413
2018-02-05 00:16:51,162 __main__ [INFO ] Evaluated on validation set. Loss: 2.65083
2018-02-05 00:16:51,162 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:16:51,290 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:51,560 __main__ [INFO ] Evaluated on training set. Loss: 2.51428
2018-02-05 00:16:51,574 __main__ [INFO ] Evaluated on validation set. Loss: 2.68495
2018-02-05 00:16:51,574 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:16:51,708 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:52,159 __main__ [INFO ] Evaluated on training set. Loss: 1.83746
2018-02-05 00:16:52,182 __main__ [INFO ] Evaluated on validation set. Loss: 2.42074
2018-02-05 00:16:52,183 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:16:52,338 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:52,667 __main__ [INFO ] Evaluated on training set. Loss: 1.78918
2018-02-05 00:16:52,682 __main__ [INFO ] Evaluated on validation set. Loss: 2.52118
2018-02-05 00:16:52,682 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:16:52,815 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:53,261 __main__ [INFO ] Evaluated on training set. Loss: 1.87039
2018-02-05 00:16:53,282 __main__ [INFO ] Evaluated on validation set. Loss: 2.30218
2018-02-05 00:16:53,283 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:16:53,416 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:53,747 __main__ [INFO ] Evaluated on training set. Loss: 1.82971
2018-02-05 00:16:53,763 __main__ [INFO ] Evaluated on validation set. Loss: 2.38176
2018-02-05 00:16:53,763 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:16:53,940 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:54,523 __main__ [INFO ] Evaluated on training set. Loss: 1.38630
2018-02-05 00:16:54,547 __main__ [INFO ] Evaluated on validation set. Loss: 2.67920
2018-02-05 00:16:54,548 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:16:54,702 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:55,152 __main__ [INFO ] Evaluated on training set. Loss: 1.31779
2018-02-05 00:16:55,168 __main__ [INFO ] Evaluated on validation set. Loss: 2.79794
2018-02-05 00:16:55,169 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:16:55,346 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:55,932 __main__ [INFO ] Evaluated on training set. Loss: 1.48051
2018-02-05 00:16:55,955 __main__ [INFO ] Evaluated on validation set. Loss: 2.46406
2018-02-05 00:16:55,956 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:16:56,117 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:16:56,612 __main__ [INFO ] Evaluated on training set. Loss: 1.42771
2018-02-05 00:16:56,629 __main__ [INFO ] Evaluated on validation set. Loss: 2.56396
2018-02-05 00:22:49,865 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:22:49,869 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:22:49,873 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:22:49,974 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:50,287 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:22:50,307 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:22:50,307 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:22:50,404 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:50,626 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:22:50,640 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:22:50,640 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:22:50,738 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:51,052 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:22:51,070 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:22:51,070 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:22:51,166 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:51,391 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:22:51,404 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:22:51,404 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:22:51,509 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:51,842 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:22:51,861 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:22:51,861 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:22:51,963 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:52,201 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:22:52,215 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:22:52,215 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:22:52,316 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:52,653 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:22:52,672 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:22:52,673 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:22:52,773 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:53,009 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:22:53,023 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:22:53,023 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:22:53,149 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:53,540 __main__ [INFO ] Evaluated on training set. Loss: 2.52835
2018-02-05 00:22:53,562 __main__ [INFO ] Evaluated on validation set. Loss: 2.68919
2018-02-05 00:22:53,563 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:22:53,689 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:53,963 __main__ [INFO ] Evaluated on training set. Loss: 2.50673
2018-02-05 00:22:53,978 __main__ [INFO ] Evaluated on validation set. Loss: 2.73057
2018-02-05 00:22:53,979 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:22:54,104 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:54,501 __main__ [INFO ] Evaluated on training set. Loss: 2.53413
2018-02-05 00:22:54,523 __main__ [INFO ] Evaluated on validation set. Loss: 2.65083
2018-02-05 00:22:54,524 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:22:54,648 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:54,923 __main__ [INFO ] Evaluated on training set. Loss: 2.51428
2018-02-05 00:22:54,939 __main__ [INFO ] Evaluated on validation set. Loss: 2.68495
2018-02-05 00:22:54,939 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:22:55,076 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:55,528 __main__ [INFO ] Evaluated on training set. Loss: 1.83746
2018-02-05 00:22:55,550 __main__ [INFO ] Evaluated on validation set. Loss: 2.42074
2018-02-05 00:22:55,550 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:22:55,707 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:56,039 __main__ [INFO ] Evaluated on training set. Loss: 1.78918
2018-02-05 00:22:56,055 __main__ [INFO ] Evaluated on validation set. Loss: 2.52118
2018-02-05 00:22:56,056 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:22:56,198 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:56,647 __main__ [INFO ] Evaluated on training set. Loss: 1.87039
2018-02-05 00:22:56,669 __main__ [INFO ] Evaluated on validation set. Loss: 2.30218
2018-02-05 00:22:56,669 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:22:56,804 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:57,170 __main__ [INFO ] Evaluated on training set. Loss: 1.82971
2018-02-05 00:22:57,187 __main__ [INFO ] Evaluated on validation set. Loss: 2.38176
2018-02-05 00:22:57,187 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:22:57,344 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:57,948 __main__ [INFO ] Evaluated on training set. Loss: 1.38630
2018-02-05 00:22:57,973 __main__ [INFO ] Evaluated on validation set. Loss: 2.67920
2018-02-05 00:22:57,973 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:22:58,136 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:58,608 __main__ [INFO ] Evaluated on training set. Loss: 1.31779
2018-02-05 00:22:58,626 __main__ [INFO ] Evaluated on validation set. Loss: 2.79794
2018-02-05 00:22:58,626 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:22:58,804 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:22:59,378 __main__ [INFO ] Evaluated on training set. Loss: 1.48051
2018-02-05 00:22:59,403 __main__ [INFO ] Evaluated on validation set. Loss: 2.46406
2018-02-05 00:22:59,403 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:22:59,556 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:23:00,042 __main__ [INFO ] Evaluated on training set. Loss: 1.42771
2018-02-05 00:23:00,059 __main__ [INFO ] Evaluated on validation set. Loss: 2.56396
2018-02-05 00:23:34,999 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:23:35,002 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:23:35,104 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:23:35,424 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:23:35,444 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:23:35,444 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:23:35,444 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,474 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:23:35,474 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,474 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:23:35,475 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,475 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:23:35,475 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,475 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:23:35,476 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,476 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:23:35,476 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,476 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:23:35,476 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,477 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:23:35,477 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,477 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:23:35,477 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,478 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:23:35,478 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,478 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:23:35,478 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,478 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:23:35,479 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,479 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:23:35,479 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,479 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:23:35,480 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,480 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:23:35,480 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,481 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:23:35,481 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,481 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:23:35,481 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,482 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:23:35,482 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:35,482 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:23:35,482 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 185, in <module>
    os.makedirs(experiment_out_dir)
  File "/home/yasen/anaconda3/lib/python3.6/os.py", line 220, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: './experiments/alice_test_n_gram/out'
2018-02-05 00:23:58,804 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:23:58,807 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:23:58,807 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:23:58,991 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:23:59,376 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:23:59,397 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:23:59,397 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:23:59,526 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:23:59,787 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:23:59,800 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:23:59,801 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:23:59,919 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:00,249 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:24:00,268 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:24:00,268 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:24:00,369 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:00,724 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:24:00,749 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:24:00,749 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:24:00,946 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:01,380 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:24:01,399 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:24:01,400 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:24:01,503 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:01,742 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:24:01,756 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:24:01,757 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:24:01,857 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:02,201 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:24:02,221 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:24:02,221 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:24:02,321 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:02,560 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:24:02,574 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:24:02,574 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:24:02,703 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:03,098 __main__ [INFO ] Evaluated on training set. Loss: 2.52835
2018-02-05 00:24:03,121 __main__ [INFO ] Evaluated on validation set. Loss: 2.68919
2018-02-05 00:24:03,121 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:24:03,249 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:03,522 __main__ [INFO ] Evaluated on training set. Loss: 2.50673
2018-02-05 00:24:03,538 __main__ [INFO ] Evaluated on validation set. Loss: 2.73057
2018-02-05 00:24:03,538 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:24:03,668 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:04,065 __main__ [INFO ] Evaluated on training set. Loss: 2.53413
2018-02-05 00:24:04,087 __main__ [INFO ] Evaluated on validation set. Loss: 2.65083
2018-02-05 00:24:04,087 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:24:04,219 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:04,522 __main__ [INFO ] Evaluated on training set. Loss: 2.51428
2018-02-05 00:24:04,537 __main__ [INFO ] Evaluated on validation set. Loss: 2.68495
2018-02-05 00:24:04,537 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:24:04,675 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:05,125 __main__ [INFO ] Evaluated on training set. Loss: 1.83746
2018-02-05 00:24:05,148 __main__ [INFO ] Evaluated on validation set. Loss: 2.42074
2018-02-05 00:24:05,148 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:24:05,305 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:05,637 __main__ [INFO ] Evaluated on training set. Loss: 1.78918
2018-02-05 00:24:05,653 __main__ [INFO ] Evaluated on validation set. Loss: 2.52118
2018-02-05 00:24:05,653 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:24:05,787 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:06,235 __main__ [INFO ] Evaluated on training set. Loss: 1.87039
2018-02-05 00:24:06,258 __main__ [INFO ] Evaluated on validation set. Loss: 2.30218
2018-02-05 00:24:06,258 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:24:06,395 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:06,722 __main__ [INFO ] Evaluated on training set. Loss: 1.82971
2018-02-05 00:24:06,738 __main__ [INFO ] Evaluated on validation set. Loss: 2.38176
2018-02-05 00:24:06,738 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:24:06,894 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:07,490 __main__ [INFO ] Evaluated on training set. Loss: 1.38630
2018-02-05 00:24:07,513 __main__ [INFO ] Evaluated on validation set. Loss: 2.67920
2018-02-05 00:24:07,514 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:24:07,669 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:08,123 __main__ [INFO ] Evaluated on training set. Loss: 1.31779
2018-02-05 00:24:08,140 __main__ [INFO ] Evaluated on validation set. Loss: 2.79794
2018-02-05 00:24:08,140 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:24:08,323 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:08,905 __main__ [INFO ] Evaluated on training set. Loss: 1.48051
2018-02-05 00:24:08,929 __main__ [INFO ] Evaluated on validation set. Loss: 2.46406
2018-02-05 00:24:08,930 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:24:09,084 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:24:09,568 __main__ [INFO ] Evaluated on training set. Loss: 1.42771
2018-02-05 00:24:09,585 __main__ [INFO ] Evaluated on validation set. Loss: 2.56396
2018-02-05 00:40:56,972 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:40:56,975 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:40:56,976 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:40:57,074 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:40:57,380 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:40:57,399 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:40:57,400 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:40:57,400 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:40:57,495 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:40:57,713 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:40:57,726 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:40:57,726 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:40:57,726 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:40:57,822 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:40:58,132 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:40:58,150 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:40:58,150 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:40:58,150 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:40:58,244 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:40:58,462 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:40:58,475 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:40:58,475 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:40:58,475 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:40:58,577 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:40:58,905 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:40:58,924 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:40:58,924 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:40:58,925 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:40:59,026 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:40:59,259 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:40:59,273 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:40:59,273 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:40:59,273 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:40:59,372 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:40:59,699 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:40:59,718 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:40:59,718 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:40:59,718 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:40:59,819 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:00,044 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:41:00,058 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:41:00,058 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:00,058 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:41:00,184 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:00,574 __main__ [INFO ] Evaluated on training set. Loss: 2.52835
2018-02-05 00:41:00,595 __main__ [INFO ] Evaluated on validation set. Loss: 2.68919
2018-02-05 00:41:00,596 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:00,596 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:41:00,720 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:00,991 __main__ [INFO ] Evaluated on training set. Loss: 2.50673
2018-02-05 00:41:01,007 __main__ [INFO ] Evaluated on validation set. Loss: 2.73057
2018-02-05 00:41:01,007 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:01,008 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:41:01,132 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:01,525 __main__ [INFO ] Evaluated on training set. Loss: 2.53413
2018-02-05 00:41:01,547 __main__ [INFO ] Evaluated on validation set. Loss: 2.65083
2018-02-05 00:41:01,547 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:01,548 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:41:01,675 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:01,945 __main__ [INFO ] Evaluated on training set. Loss: 2.51428
2018-02-05 00:41:01,960 __main__ [INFO ] Evaluated on validation set. Loss: 2.68495
2018-02-05 00:41:01,960 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:01,961 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:41:02,095 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:02,537 __main__ [INFO ] Evaluated on training set. Loss: 1.83746
2018-02-05 00:41:02,560 __main__ [INFO ] Evaluated on validation set. Loss: 2.42074
2018-02-05 00:41:02,560 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:02,560 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:41:02,718 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:03,053 __main__ [INFO ] Evaluated on training set. Loss: 1.78918
2018-02-05 00:41:03,070 __main__ [INFO ] Evaluated on validation set. Loss: 2.52118
2018-02-05 00:41:03,070 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:03,070 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:41:03,203 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:03,648 __main__ [INFO ] Evaluated on training set. Loss: 1.87039
2018-02-05 00:41:03,670 __main__ [INFO ] Evaluated on validation set. Loss: 2.30218
2018-02-05 00:41:03,670 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:03,671 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:41:03,807 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:04,134 __main__ [INFO ] Evaluated on training set. Loss: 1.82971
2018-02-05 00:41:04,151 __main__ [INFO ] Evaluated on validation set. Loss: 2.38176
2018-02-05 00:41:04,151 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:04,151 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:41:04,307 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:04,897 __main__ [INFO ] Evaluated on training set. Loss: 1.38630
2018-02-05 00:41:04,921 __main__ [INFO ] Evaluated on validation set. Loss: 2.67920
2018-02-05 00:41:04,921 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:04,922 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:41:05,079 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:05,526 __main__ [INFO ] Evaluated on training set. Loss: 1.31779
2018-02-05 00:41:05,543 __main__ [INFO ] Evaluated on validation set. Loss: 2.79794
2018-02-05 00:41:05,543 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:05,543 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 20 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:41:05,727 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:06,298 __main__ [INFO ] Evaluated on training set. Loss: 1.48051
2018-02-05 00:41:06,321 __main__ [INFO ] Evaluated on validation set. Loss: 2.46406
2018-02-05 00:41:06,321 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:41:06,321 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 20 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:41:06,473 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:41:06,952 __main__ [INFO ] Evaluated on training set. Loss: 1.42771
2018-02-05 00:41:06,969 __main__ [INFO ] Evaluated on validation set. Loss: 2.56396
2018-02-05 00:41:06,969 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 207, in <module>
    ngram_stats['deltas']['ns'].append(hyperparams.n)
KeyError: 'ns'
2018-02-05 00:49:32,628 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:49:32,631 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:49:32,632 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:49:32,730 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:33,067 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:49:33,088 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:49:33,088 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:49:33,186 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:33,437 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:49:33,451 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:49:33,452 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:49:33,548 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:33,887 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:49:33,906 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:49:33,906 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:49:34,001 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:34,246 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:49:34,260 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:49:34,260 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:49:34,365 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:34,718 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:49:34,738 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:49:34,738 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:49:34,841 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:35,093 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:49:35,108 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:49:35,108 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:49:35,215 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:35,572 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:49:35,596 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:49:35,596 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:49:35,701 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:35,954 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:49:35,969 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:49:54,809 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:49:54,813 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:49:54,814 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:49:54,941 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:55,580 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:49:55,618 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:49:55,618 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:49:55,747 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:56,263 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:49:56,293 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:49:56,293 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:49:56,421 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:57,063 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:49:57,100 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:49:57,101 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:49:57,227 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:57,737 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:49:57,767 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:49:57,767 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:49:57,902 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:58,572 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:49:58,610 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:49:58,611 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:49:58,745 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:49:59,286 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:49:59,317 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:49:59,318 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:49:59,460 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:00,139 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:50:00,177 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:50:00,177 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:50:00,315 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:00,864 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:50:00,895 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:50:36,843 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:50:36,847 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:50:36,848 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:50:36,976 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:37,596 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:50:37,632 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:50:37,633 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:50:37,763 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:38,247 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:50:38,276 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:50:38,276 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:50:38,403 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:39,032 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:50:39,069 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:50:39,070 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:50:39,200 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:39,684 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:50:39,713 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:50:39,713 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:50:39,852 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:40,509 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:50:40,546 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:50:40,547 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:50:40,690 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:41,201 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:50:41,232 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:50:41,232 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:50:41,370 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:42,014 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:50:42,053 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:50:42,053 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:50:42,188 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:50:42,702 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:50:42,732 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:51:25,442 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:51:25,445 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:51:25,447 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:25,578 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:26,234 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:51:26,270 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:51:26,271 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:26,399 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:29,370 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:51:29,373 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:51:29,374 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:29,475 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:29,829 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:51:29,850 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:51:29,851 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:29,948 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:30,204 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:51:30,218 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:51:30,219 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:30,315 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:30,666 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:51:30,685 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:51:30,686 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:30,784 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:31,044 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:51:31,059 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:51:31,059 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:51:31,165 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:31,533 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:51:31,553 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:51:31,554 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:51:31,661 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:31,926 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:51:31,941 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:51:31,941 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:51:32,042 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:32,407 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:51:32,428 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:51:32,428 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:51:32,529 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:32,794 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:51:32,810 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:51:53,781 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:51:53,785 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:51:53,786 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:53,918 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:54,541 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:51:54,577 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:51:54,578 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:54,711 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:55,204 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:51:55,233 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:51:55,234 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:55,365 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:55,983 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:51:56,019 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:51:56,020 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:51:56,147 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:56,631 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:51:56,659 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:51:56,660 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:51:56,797 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:57,444 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:51:57,480 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:51:57,480 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:51:57,616 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:58,123 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:51:58,153 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:51:58,153 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:51:58,288 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:58,940 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:51:58,977 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:51:58,977 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:51:59,113 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:51:59,624 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:51:59,652 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:53:52,316 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:53:52,319 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:53:52,320 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:53:52,419 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:53:52,759 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:53:52,780 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:53:52,780 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:53:52,879 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:53:53,132 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:53:53,147 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:53:53,147 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:53:53,245 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:53:53,591 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:53:53,611 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:53:53,611 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:53:53,708 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:53:53,959 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:53:53,974 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:53:53,974 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:53:54,078 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:53:54,437 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:53:54,457 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:53:54,458 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:53:54,563 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:53:54,827 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:53:54,842 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:53:54,842 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 8 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:53:54,947 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:53:55,307 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:53:55,328 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:53:55,329 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 8 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:53:55,430 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:53:55,689 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:53:55,704 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:55:08,291 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:55:08,294 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:55:08,295 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:08,397 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:08,794 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:55:08,817 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:55:08,817 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:08,913 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:09,199 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:55:09,215 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:55:09,216 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:09,315 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:09,688 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:55:09,710 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:55:09,710 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:09,808 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:10,086 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:55:10,102 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:55:10,102 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:10,199 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:10,570 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:55:10,592 __main__ [INFO ] Evaluated on validation set. Loss: 4.59312
2018-02-05 00:55:10,593 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:10,690 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:10,967 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:55:10,984 __main__ [INFO ] Evaluated on validation set. Loss: 4.59440
2018-02-05 00:55:10,984 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:11,082 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:11,461 __main__ [INFO ] Evaluated on training set. Loss: 4.50780
2018-02-05 00:55:11,484 __main__ [INFO ] Evaluated on validation set. Loss: 4.59304
2018-02-05 00:55:11,484 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:11,582 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:11,859 __main__ [INFO ] Evaluated on training set. Loss: 4.50756
2018-02-05 00:55:11,875 __main__ [INFO ] Evaluated on validation set. Loss: 4.59430
2018-02-05 00:55:11,875 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:11,981 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:12,367 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:55:12,390 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:55:12,390 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:12,496 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:12,780 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:55:12,797 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:55:12,797 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:12,905 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:13,295 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:55:13,318 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:55:13,318 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:13,426 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:13,709 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:55:13,726 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:55:13,726 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:13,831 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:14,220 __main__ [INFO ] Evaluated on training set. Loss: 3.50775
2018-02-05 00:55:14,242 __main__ [INFO ] Evaluated on validation set. Loss: 3.53111
2018-02-05 00:55:14,242 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:14,347 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:14,630 __main__ [INFO ] Evaluated on training set. Loss: 3.50443
2018-02-05 00:55:14,647 __main__ [INFO ] Evaluated on validation set. Loss: 3.53905
2018-02-05 00:55:14,647 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:14,754 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:15,142 __main__ [INFO ] Evaluated on training set. Loss: 3.52796
2018-02-05 00:55:15,166 __main__ [INFO ] Evaluated on validation set. Loss: 3.55867
2018-02-05 00:55:15,166 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:15,271 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:15,560 __main__ [INFO ] Evaluated on training set. Loss: 3.53310
2018-02-05 00:55:15,577 __main__ [INFO ] Evaluated on validation set. Loss: 3.56515
2018-02-05 00:55:15,577 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:15,704 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:16,147 __main__ [INFO ] Evaluated on training set. Loss: 2.52835
2018-02-05 00:55:16,172 __main__ [INFO ] Evaluated on validation set. Loss: 2.68919
2018-02-05 00:55:16,172 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:16,302 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:16,619 __main__ [INFO ] Evaluated on training set. Loss: 2.50673
2018-02-05 00:55:16,637 __main__ [INFO ] Evaluated on validation set. Loss: 2.73057
2018-02-05 00:55:16,638 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:16,765 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:17,208 __main__ [INFO ] Evaluated on training set. Loss: 2.53413
2018-02-05 00:55:17,234 __main__ [INFO ] Evaluated on validation set. Loss: 2.65083
2018-02-05 00:55:17,234 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:17,366 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:17,691 __main__ [INFO ] Evaluated on training set. Loss: 2.51428
2018-02-05 00:55:17,709 __main__ [INFO ] Evaluated on validation set. Loss: 2.68495
2018-02-05 00:55:17,709 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 21 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:17,837 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:18,288 __main__ [INFO ] Evaluated on training set. Loss: 2.57466
2018-02-05 00:55:18,313 __main__ [INFO ] Evaluated on validation set. Loss: 2.66467
2018-02-05 00:55:18,313 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 22 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:18,442 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:18,764 __main__ [INFO ] Evaluated on training set. Loss: 2.56789
2018-02-05 00:55:18,782 __main__ [INFO ] Evaluated on validation set. Loss: 2.69204
2018-02-05 00:55:18,782 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 23 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:18,911 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:19,360 __main__ [INFO ] Evaluated on training set. Loss: 2.78206
2018-02-05 00:55:19,386 __main__ [INFO ] Evaluated on validation set. Loss: 2.90272
2018-02-05 00:55:19,386 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 24 out of 120 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:19,513 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:19,834 __main__ [INFO ] Evaluated on training set. Loss: 2.83507
2018-02-05 00:55:19,851 __main__ [INFO ] Evaluated on validation set. Loss: 2.92732
2018-02-05 00:55:19,852 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 25 out of 120 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:55:28,404 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 00:55:28,407 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 00:55:28,408 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:28,510 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:28,847 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:55:28,868 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:55:28,868 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:28,967 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:29,215 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:55:29,229 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:55:29,230 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:29,329 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:29,669 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:55:29,689 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 00:55:29,689 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:29,788 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:30,038 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:55:30,053 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 00:55:30,053 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:30,150 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:30,492 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 00:55:30,512 __main__ [INFO ] Evaluated on validation set. Loss: 4.59312
2018-02-05 00:55:30,513 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:30,610 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:30,857 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 00:55:30,871 __main__ [INFO ] Evaluated on validation set. Loss: 4.59440
2018-02-05 00:55:30,871 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:30,972 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:31,318 __main__ [INFO ] Evaluated on training set. Loss: 4.50780
2018-02-05 00:55:31,338 __main__ [INFO ] Evaluated on validation set. Loss: 4.59304
2018-02-05 00:55:31,338 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 1
}
--------------------------------------------------
2018-02-05 00:55:31,438 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:31,691 __main__ [INFO ] Evaluated on training set. Loss: 4.50756
2018-02-05 00:55:31,705 __main__ [INFO ] Evaluated on validation set. Loss: 4.59430
2018-02-05 00:55:31,706 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:31,813 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:32,172 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 00:55:32,192 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 00:55:32,193 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:32,297 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:32,556 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 00:55:32,571 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 00:55:32,572 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:32,680 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:33,031 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 00:55:33,051 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 00:55:33,051 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:33,159 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:33,410 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 00:55:33,425 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 00:55:33,425 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:33,531 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:33,889 __main__ [INFO ] Evaluated on training set. Loss: 3.50775
2018-02-05 00:55:33,910 __main__ [INFO ] Evaluated on validation set. Loss: 3.53111
2018-02-05 00:55:33,910 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:34,012 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:34,269 __main__ [INFO ] Evaluated on training set. Loss: 3.50443
2018-02-05 00:55:34,284 __main__ [INFO ] Evaluated on validation set. Loss: 3.53905
2018-02-05 00:55:34,284 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:34,386 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:34,740 __main__ [INFO ] Evaluated on training set. Loss: 3.52796
2018-02-05 00:55:34,760 __main__ [INFO ] Evaluated on validation set. Loss: 3.55867
2018-02-05 00:55:34,761 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 2
}
--------------------------------------------------
2018-02-05 00:55:34,862 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:35,115 __main__ [INFO ] Evaluated on training set. Loss: 3.53310
2018-02-05 00:55:35,130 __main__ [INFO ] Evaluated on validation set. Loss: 3.56515
2018-02-05 00:55:35,130 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:35,258 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:35,670 __main__ [INFO ] Evaluated on training set. Loss: 2.52835
2018-02-05 00:55:35,693 __main__ [INFO ] Evaluated on validation set. Loss: 2.68919
2018-02-05 00:55:35,693 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:35,818 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:36,103 __main__ [INFO ] Evaluated on training set. Loss: 2.50673
2018-02-05 00:55:36,119 __main__ [INFO ] Evaluated on validation set. Loss: 2.73057
2018-02-05 00:55:36,119 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:36,247 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:36,652 __main__ [INFO ] Evaluated on training set. Loss: 2.53413
2018-02-05 00:55:36,675 __main__ [INFO ] Evaluated on validation set. Loss: 2.65083
2018-02-05 00:55:36,675 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:36,802 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:37,087 __main__ [INFO ] Evaluated on training set. Loss: 2.51428
2018-02-05 00:55:37,103 __main__ [INFO ] Evaluated on validation set. Loss: 2.68495
2018-02-05 00:55:37,103 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 21 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:37,227 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:37,631 __main__ [INFO ] Evaluated on training set. Loss: 2.57466
2018-02-05 00:55:37,654 __main__ [INFO ] Evaluated on validation set. Loss: 2.66467
2018-02-05 00:55:37,654 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 22 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:37,780 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:38,067 __main__ [INFO ] Evaluated on training set. Loss: 2.56789
2018-02-05 00:55:38,084 __main__ [INFO ] Evaluated on validation set. Loss: 2.69204
2018-02-05 00:55:38,084 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 23 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:38,210 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:38,617 __main__ [INFO ] Evaluated on training set. Loss: 2.78206
2018-02-05 00:55:38,640 __main__ [INFO ] Evaluated on validation set. Loss: 2.90272
2018-02-05 00:55:38,640 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 24 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 3
}
--------------------------------------------------
2018-02-05 00:55:38,766 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:39,051 __main__ [INFO ] Evaluated on training set. Loss: 2.83507
2018-02-05 00:55:39,067 __main__ [INFO ] Evaluated on validation set. Loss: 2.92732
2018-02-05 00:55:39,067 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 25 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:55:39,204 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:39,672 __main__ [INFO ] Evaluated on training set. Loss: 1.83746
2018-02-05 00:55:39,695 __main__ [INFO ] Evaluated on validation set. Loss: 2.42074
2018-02-05 00:55:39,695 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 26 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:55:39,859 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:40,210 __main__ [INFO ] Evaluated on training set. Loss: 1.78918
2018-02-05 00:55:40,227 __main__ [INFO ] Evaluated on validation set. Loss: 2.52118
2018-02-05 00:55:40,227 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 27 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:55:40,362 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:40,826 __main__ [INFO ] Evaluated on training set. Loss: 1.87039
2018-02-05 00:55:40,850 __main__ [INFO ] Evaluated on validation set. Loss: 2.30218
2018-02-05 00:55:40,850 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 28 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:55:40,984 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:41,332 __main__ [INFO ] Evaluated on training set. Loss: 1.82971
2018-02-05 00:55:41,349 __main__ [INFO ] Evaluated on validation set. Loss: 2.38176
2018-02-05 00:55:41,349 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 29 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:55:41,484 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:41,954 __main__ [INFO ] Evaluated on training set. Loss: 2.06434
2018-02-05 00:55:41,978 __main__ [INFO ] Evaluated on validation set. Loss: 2.38532
2018-02-05 00:55:41,978 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 30 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:55:42,113 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:42,491 __main__ [INFO ] Evaluated on training set. Loss: 2.07064
2018-02-05 00:55:42,508 __main__ [INFO ] Evaluated on validation set. Loss: 2.44743
2018-02-05 00:55:42,509 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 31 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:55:42,644 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:43,105 __main__ [INFO ] Evaluated on training set. Loss: 2.74820
2018-02-05 00:55:43,128 __main__ [INFO ] Evaluated on validation set. Loss: 3.05124
2018-02-05 00:55:43,129 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 32 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 4
}
--------------------------------------------------
2018-02-05 00:55:43,265 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:43,607 __main__ [INFO ] Evaluated on training set. Loss: 2.88516
2018-02-05 00:55:43,624 __main__ [INFO ] Evaluated on validation set. Loss: 3.10142
2018-02-05 00:55:43,624 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 33 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:55:43,782 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:44,406 __main__ [INFO ] Evaluated on training set. Loss: 1.38630
2018-02-05 00:55:44,431 __main__ [INFO ] Evaluated on validation set. Loss: 2.67920
2018-02-05 00:55:44,431 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 34 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:55:44,587 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:45,051 __main__ [INFO ] Evaluated on training set. Loss: 1.31779
2018-02-05 00:55:45,069 __main__ [INFO ] Evaluated on validation set. Loss: 2.79794
2018-02-05 00:55:45,070 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 35 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:55:45,260 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:45,842 __main__ [INFO ] Evaluated on training set. Loss: 1.48051
2018-02-05 00:55:45,867 __main__ [INFO ] Evaluated on validation set. Loss: 2.46406
2018-02-05 00:55:45,867 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 36 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:55:46,021 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:46,529 __main__ [INFO ] Evaluated on training set. Loss: 1.42771
2018-02-05 00:55:46,547 __main__ [INFO ] Evaluated on validation set. Loss: 2.56396
2018-02-05 00:55:46,547 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 37 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:55:46,700 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:47,283 __main__ [INFO ] Evaluated on training set. Loss: 1.95188
2018-02-05 00:55:47,308 __main__ [INFO ] Evaluated on validation set. Loss: 2.64696
2018-02-05 00:55:47,308 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 38 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:55:47,504 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:47,969 __main__ [INFO ] Evaluated on training set. Loss: 1.98117
2018-02-05 00:55:47,987 __main__ [INFO ] Evaluated on validation set. Loss: 2.72943
2018-02-05 00:55:47,987 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 39 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:55:48,142 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:48,720 __main__ [INFO ] Evaluated on training set. Loss: 3.15290
2018-02-05 00:55:48,745 __main__ [INFO ] Evaluated on validation set. Loss: 3.61724
2018-02-05 00:55:48,745 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 40 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 5
}
--------------------------------------------------
2018-02-05 00:55:48,934 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:49,390 __main__ [INFO ] Evaluated on training set. Loss: 3.33047
2018-02-05 00:55:49,408 __main__ [INFO ] Evaluated on validation set. Loss: 3.67874
2018-02-05 00:55:49,408 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 41 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 6
}
--------------------------------------------------
2018-02-05 00:55:49,630 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:50,388 __main__ [INFO ] Evaluated on training set. Loss: 1.05625
2018-02-05 00:55:50,414 __main__ [INFO ] Evaluated on validation set. Loss: 3.07878
2018-02-05 00:55:50,414 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 42 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 6
}
--------------------------------------------------
2018-02-05 00:55:50,640 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:51,272 __main__ [INFO ] Evaluated on training set. Loss: 0.98492
2018-02-05 00:55:51,292 __main__ [INFO ] Evaluated on validation set. Loss: 3.21457
2018-02-05 00:55:51,292 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 43 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 6
}
--------------------------------------------------
2018-02-05 00:55:51,518 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:52,314 __main__ [INFO ] Evaluated on training set. Loss: 1.23781
2018-02-05 00:55:52,341 __main__ [INFO ] Evaluated on validation set. Loss: 2.84237
2018-02-05 00:55:52,341 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 44 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 6
}
--------------------------------------------------
2018-02-05 00:55:52,521 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:53,205 __main__ [INFO ] Evaluated on training set. Loss: 1.18767
2018-02-05 00:55:53,224 __main__ [INFO ] Evaluated on validation set. Loss: 2.96093
2018-02-05 00:55:53,224 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 45 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 6
}
--------------------------------------------------
2018-02-05 00:55:53,454 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:54,207 __main__ [INFO ] Evaluated on training set. Loss: 2.03351
2018-02-05 00:55:54,233 __main__ [INFO ] Evaluated on validation set. Loss: 3.12482
2018-02-05 00:55:54,233 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 46 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 6
}
--------------------------------------------------
2018-02-05 00:55:54,460 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:55,097 __main__ [INFO ] Evaluated on training set. Loss: 2.08034
2018-02-05 00:55:55,118 __main__ [INFO ] Evaluated on validation set. Loss: 3.22148
2018-02-05 00:55:55,119 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 47 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 6
}
--------------------------------------------------
2018-02-05 00:55:55,346 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:56,143 __main__ [INFO ] Evaluated on training set. Loss: 3.62050
2018-02-05 00:55:56,169 __main__ [INFO ] Evaluated on validation set. Loss: 4.18999
2018-02-05 00:55:56,169 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 48 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 6
}
--------------------------------------------------
2018-02-05 00:55:56,351 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:57,032 __main__ [INFO ] Evaluated on training set. Loss: 3.79562
2018-02-05 00:55:57,052 __main__ [INFO ] Evaluated on validation set. Loss: 4.25463
2018-02-05 00:55:57,052 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 49 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 7
}
--------------------------------------------------
2018-02-05 00:55:57,307 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:58,274 __main__ [INFO ] Evaluated on training set. Loss: 0.80592
2018-02-05 00:55:58,301 __main__ [INFO ] Evaluated on validation set. Loss: 3.56593
2018-02-05 00:55:58,301 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 50 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 7
}
--------------------------------------------------
2018-02-05 00:55:58,576 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:55:59,369 __main__ [INFO ] Evaluated on training set. Loss: 0.73984
2018-02-05 00:55:59,390 __main__ [INFO ] Evaluated on validation set. Loss: 3.70812
2018-02-05 00:55:59,390 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 51 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 7
}
--------------------------------------------------
2018-02-05 00:55:59,713 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:00,619 __main__ [INFO ] Evaluated on training set. Loss: 1.07876
2018-02-05 00:56:00,647 __main__ [INFO ] Evaluated on validation set. Loss: 3.33480
2018-02-05 00:56:00,647 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 52 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 7
}
--------------------------------------------------
2018-02-05 00:56:00,910 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:01,760 __main__ [INFO ] Evaluated on training set. Loss: 1.03562
2018-02-05 00:56:01,781 __main__ [INFO ] Evaluated on validation set. Loss: 3.46293
2018-02-05 00:56:01,781 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 53 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 7
}
--------------------------------------------------
2018-02-05 00:56:02,054 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:03,028 __main__ [INFO ] Evaluated on training set. Loss: 2.17195
2018-02-05 00:56:03,055 __main__ [INFO ] Evaluated on validation set. Loss: 3.65690
2018-02-05 00:56:03,055 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 54 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 7
}
--------------------------------------------------
2018-02-05 00:56:03,325 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:04,127 __main__ [INFO ] Evaluated on training set. Loss: 2.22462
2018-02-05 00:56:04,200 __main__ [INFO ] Evaluated on validation set. Loss: 3.75871
2018-02-05 00:56:04,201 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 55 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 7
}
--------------------------------------------------
2018-02-05 00:56:04,476 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:05,380 __main__ [INFO ] Evaluated on training set. Loss: 4.01790
2018-02-05 00:56:05,408 __main__ [INFO ] Evaluated on validation set. Loss: 4.67147
2018-02-05 00:56:05,408 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 56 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 7
}
--------------------------------------------------
2018-02-05 00:56:05,663 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:06,513 __main__ [INFO ] Evaluated on training set. Loss: 4.17159
2018-02-05 00:56:06,534 __main__ [INFO ] Evaluated on validation set. Loss: 4.73337
2018-02-05 00:56:06,534 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 57 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 8
}
--------------------------------------------------
2018-02-05 00:56:06,879 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:07,932 __main__ [INFO ] Evaluated on training set. Loss: 0.60556
2018-02-05 00:56:07,961 __main__ [INFO ] Evaluated on validation set. Loss: 4.05365
2018-02-05 00:56:07,961 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 58 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 8
}
--------------------------------------------------
2018-02-05 00:56:08,308 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:09,335 __main__ [INFO ] Evaluated on training set. Loss: 0.54771
2018-02-05 00:56:09,358 __main__ [INFO ] Evaluated on validation set. Loss: 4.19924
2018-02-05 00:56:09,358 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 59 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 8
}
--------------------------------------------------
2018-02-05 00:56:09,655 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:10,788 __main__ [INFO ] Evaluated on training set. Loss: 0.96321
2018-02-05 00:56:10,817 __main__ [INFO ] Evaluated on validation set. Loss: 3.83837
2018-02-05 00:56:10,817 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 60 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 8
}
--------------------------------------------------
2018-02-05 00:56:11,114 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:12,130 __main__ [INFO ] Evaluated on training set. Loss: 0.92772
2018-02-05 00:56:12,152 __main__ [INFO ] Evaluated on validation set. Loss: 3.97177
2018-02-05 00:56:12,152 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 61 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 8
}
--------------------------------------------------
2018-02-05 00:56:12,447 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:13,567 __main__ [INFO ] Evaluated on training set. Loss: 2.31097
2018-02-05 00:56:13,597 __main__ [INFO ] Evaluated on validation set. Loss: 4.16290
2018-02-05 00:56:13,597 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 62 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 8
}
--------------------------------------------------
2018-02-05 00:56:13,891 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:14,898 __main__ [INFO ] Evaluated on training set. Loss: 2.36232
2018-02-05 00:56:14,920 __main__ [INFO ] Evaluated on validation set. Loss: 4.26567
2018-02-05 00:56:14,920 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 63 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 8
}
--------------------------------------------------
2018-02-05 00:56:15,275 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:16,326 __main__ [INFO ] Evaluated on training set. Loss: 4.33012
2018-02-05 00:56:16,355 __main__ [INFO ] Evaluated on validation set. Loss: 5.05962
2018-02-05 00:56:16,355 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 64 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 8
}
--------------------------------------------------
2018-02-05 00:56:16,707 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:17,729 __main__ [INFO ] Evaluated on training set. Loss: 4.45620
2018-02-05 00:56:17,751 __main__ [INFO ] Evaluated on validation set. Loss: 5.11659
2018-02-05 00:56:17,751 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 65 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 9
}
--------------------------------------------------
2018-02-05 00:56:18,058 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:19,306 __main__ [INFO ] Evaluated on training set. Loss: 0.45289
2018-02-05 00:56:19,337 __main__ [INFO ] Evaluated on validation set. Loss: 4.47368
2018-02-05 00:56:19,338 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 66 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 9
}
--------------------------------------------------
2018-02-05 00:56:19,715 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:20,884 __main__ [INFO ] Evaluated on training set. Loss: 0.40688
2018-02-05 00:56:20,910 __main__ [INFO ] Evaluated on validation set. Loss: 4.60861
2018-02-05 00:56:20,911 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 67 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 9
}
--------------------------------------------------
2018-02-05 00:56:21,241 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:22,522 __main__ [INFO ] Evaluated on training set. Loss: 0.88497
2018-02-05 00:56:22,556 __main__ [INFO ] Evaluated on validation set. Loss: 4.29723
2018-02-05 00:56:22,556 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 68 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 9
}
--------------------------------------------------
2018-02-05 00:56:22,878 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:24,038 __main__ [INFO ] Evaluated on training set. Loss: 0.85891
2018-02-05 00:56:24,064 __main__ [INFO ] Evaluated on validation set. Loss: 4.42520
2018-02-05 00:56:24,065 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 69 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 9
}
--------------------------------------------------
2018-02-05 00:56:24,376 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:25,631 __main__ [INFO ] Evaluated on training set. Loss: 2.43838
2018-02-05 00:56:25,663 __main__ [INFO ] Evaluated on validation set. Loss: 4.60520
2018-02-05 00:56:25,664 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 70 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 9
}
--------------------------------------------------
2018-02-05 00:56:26,033 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:27,186 __main__ [INFO ] Evaluated on training set. Loss: 2.48508
2018-02-05 00:56:27,212 __main__ [INFO ] Evaluated on validation set. Loss: 4.70296
2018-02-05 00:56:27,212 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 71 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 9
}
--------------------------------------------------
2018-02-05 00:56:27,528 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:28,791 __main__ [INFO ] Evaluated on training set. Loss: 4.56306
2018-02-05 00:56:28,821 __main__ [INFO ] Evaluated on validation set. Loss: 5.35872
2018-02-05 00:56:28,822 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 72 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 9
}
--------------------------------------------------
2018-02-05 00:56:29,212 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:30,374 __main__ [INFO ] Evaluated on training set. Loss: 4.66215
2018-02-05 00:56:30,399 __main__ [INFO ] Evaluated on validation set. Loss: 5.40956
2018-02-05 00:56:30,399 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 73 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 10
}
--------------------------------------------------
2018-02-05 00:56:30,730 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:32,103 __main__ [INFO ] Evaluated on training set. Loss: 0.34787
2018-02-05 00:56:32,134 __main__ [INFO ] Evaluated on validation set. Loss: 4.81782
2018-02-05 00:56:32,134 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 74 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 10
}
--------------------------------------------------
2018-02-05 00:56:32,543 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:33,719 __main__ [INFO ] Evaluated on training set. Loss: 0.31292
2018-02-05 00:56:33,743 __main__ [INFO ] Evaluated on validation set. Loss: 4.94839
2018-02-05 00:56:33,743 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 75 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 10
}
--------------------------------------------------
2018-02-05 00:56:34,133 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:35,503 __main__ [INFO ] Evaluated on training set. Loss: 0.83934
2018-02-05 00:56:35,533 __main__ [INFO ] Evaluated on validation set. Loss: 4.67890
2018-02-05 00:56:35,533 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 76 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 10
}
--------------------------------------------------
2018-02-05 00:56:35,932 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:37,193 __main__ [INFO ] Evaluated on training set. Loss: 0.82123
2018-02-05 00:56:37,216 __main__ [INFO ] Evaluated on validation set. Loss: 4.80228
2018-02-05 00:56:37,216 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 77 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 10
}
--------------------------------------------------
2018-02-05 00:56:37,554 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:38,917 __main__ [INFO ] Evaluated on training set. Loss: 2.54642
2018-02-05 00:56:38,948 __main__ [INFO ] Evaluated on validation set. Loss: 4.95612
2018-02-05 00:56:38,948 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 78 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 10
}
--------------------------------------------------
2018-02-05 00:56:39,341 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:40,610 __main__ [INFO ] Evaluated on training set. Loss: 2.58669
2018-02-05 00:56:40,634 __main__ [INFO ] Evaluated on validation set. Loss: 5.04794
2018-02-05 00:56:40,634 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 79 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 10
}
--------------------------------------------------
2018-02-05 00:56:40,969 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:42,333 __main__ [INFO ] Evaluated on training set. Loss: 4.73275
2018-02-05 00:56:42,362 __main__ [INFO ] Evaluated on validation set. Loss: 5.57141
2018-02-05 00:56:42,362 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 80 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 10
}
--------------------------------------------------
2018-02-05 00:56:42,767 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:44,025 __main__ [INFO ] Evaluated on training set. Loss: 4.80923
2018-02-05 00:56:44,049 __main__ [INFO ] Evaluated on validation set. Loss: 5.61599
2018-02-05 00:56:44,049 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 81 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 11
}
--------------------------------------------------
2018-02-05 00:56:44,389 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:45,837 __main__ [INFO ] Evaluated on training set. Loss: 0.27507
2018-02-05 00:56:45,868 __main__ [INFO ] Evaluated on validation set. Loss: 5.09298
2018-02-05 00:56:45,868 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 82 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 11
}
--------------------------------------------------
2018-02-05 00:56:46,284 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:47,623 __main__ [INFO ] Evaluated on training set. Loss: 0.24892
2018-02-05 00:56:47,646 __main__ [INFO ] Evaluated on validation set. Loss: 5.20260
2018-02-05 00:56:47,647 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 83 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 11
}
--------------------------------------------------
2018-02-05 00:56:48,069 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:49,543 __main__ [INFO ] Evaluated on training set. Loss: 0.81186
2018-02-05 00:56:49,575 __main__ [INFO ] Evaluated on validation set. Loss: 4.98894
2018-02-05 00:56:49,575 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 84 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 11
}
--------------------------------------------------
2018-02-05 00:56:49,924 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:51,259 __main__ [INFO ] Evaluated on training set. Loss: 0.79955
2018-02-05 00:56:51,283 __main__ [INFO ] Evaluated on validation set. Loss: 5.09697
2018-02-05 00:56:51,283 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 85 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 11
}
--------------------------------------------------
2018-02-05 00:56:51,709 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:53,177 __main__ [INFO ] Evaluated on training set. Loss: 2.63084
2018-02-05 00:56:53,208 __main__ [INFO ] Evaluated on validation set. Loss: 5.22756
2018-02-05 00:56:53,208 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 86 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 11
}
--------------------------------------------------
2018-02-05 00:56:53,560 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:54,903 __main__ [INFO ] Evaluated on training set. Loss: 2.66454
2018-02-05 00:56:54,928 __main__ [INFO ] Evaluated on validation set. Loss: 5.30825
2018-02-05 00:56:54,929 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 87 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 11
}
--------------------------------------------------
2018-02-05 00:56:55,349 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:56,812 __main__ [INFO ] Evaluated on training set. Loss: 4.85396
2018-02-05 00:56:56,843 __main__ [INFO ] Evaluated on validation set. Loss: 5.72132
2018-02-05 00:56:56,843 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 88 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 11
}
--------------------------------------------------
2018-02-05 00:56:57,196 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:56:58,531 __main__ [INFO ] Evaluated on training set. Loss: 4.91280
2018-02-05 00:56:58,556 __main__ [INFO ] Evaluated on validation set. Loss: 5.75951
2018-02-05 00:56:58,556 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 89 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 12
}
--------------------------------------------------
2018-02-05 00:56:58,982 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:00,511 __main__ [INFO ] Evaluated on training set. Loss: 0.22333
2018-02-05 00:57:00,543 __main__ [INFO ] Evaluated on validation set. Loss: 5.32007
2018-02-05 00:57:00,544 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 90 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 12
}
--------------------------------------------------
2018-02-05 00:57:00,907 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:02,303 __main__ [INFO ] Evaluated on training set. Loss: 0.20441
2018-02-05 00:57:02,328 __main__ [INFO ] Evaluated on validation set. Loss: 5.40929
2018-02-05 00:57:02,328 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 91 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 12
}
--------------------------------------------------
2018-02-05 00:57:02,756 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:04,286 __main__ [INFO ] Evaluated on training set. Loss: 0.79417
2018-02-05 00:57:04,318 __main__ [INFO ] Evaluated on validation set. Loss: 5.24229
2018-02-05 00:57:04,318 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 92 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 12
}
--------------------------------------------------
2018-02-05 00:57:04,756 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:06,061 __main__ [INFO ] Evaluated on training set. Loss: 0.78640
2018-02-05 00:57:06,086 __main__ [INFO ] Evaluated on validation set. Loss: 5.33233
2018-02-05 00:57:06,087 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 93 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 12
}
--------------------------------------------------
2018-02-05 00:57:06,589 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:08,006 __main__ [INFO ] Evaluated on training set. Loss: 2.69366
2018-02-05 00:57:08,037 __main__ [INFO ] Evaluated on validation set. Loss: 5.43934
2018-02-05 00:57:08,038 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 94 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 12
}
--------------------------------------------------
2018-02-05 00:57:08,541 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:09,838 __main__ [INFO ] Evaluated on training set. Loss: 2.72174
2018-02-05 00:57:09,863 __main__ [INFO ] Evaluated on validation set. Loss: 5.50668
2018-02-05 00:57:09,863 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 95 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 12
}
--------------------------------------------------
2018-02-05 00:57:10,363 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:11,786 __main__ [INFO ] Evaluated on training set. Loss: 4.93933
2018-02-05 00:57:11,816 __main__ [INFO ] Evaluated on validation set. Loss: 5.83146
2018-02-05 00:57:11,817 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 96 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 12
}
--------------------------------------------------
2018-02-05 00:57:12,326 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:13,620 __main__ [INFO ] Evaluated on training set. Loss: 4.98527
2018-02-05 00:57:13,644 __main__ [INFO ] Evaluated on validation set. Loss: 5.86305
2018-02-05 00:57:13,645 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 97 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 13
}
--------------------------------------------------
2018-02-05 00:57:14,150 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:15,613 __main__ [INFO ] Evaluated on training set. Loss: 0.18911
2018-02-05 00:57:15,725 __main__ [INFO ] Evaluated on validation set. Loss: 5.48719
2018-02-05 00:57:15,725 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 98 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 13
}
--------------------------------------------------
2018-02-05 00:57:16,174 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:17,516 __main__ [INFO ] Evaluated on training set. Loss: 0.17535
2018-02-05 00:57:17,541 __main__ [INFO ] Evaluated on validation set. Loss: 5.55922
2018-02-05 00:57:17,541 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 99 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 13
}
--------------------------------------------------
2018-02-05 00:57:18,050 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:19,504 __main__ [INFO ] Evaluated on training set. Loss: 0.78473
2018-02-05 00:57:19,536 __main__ [INFO ] Evaluated on validation set. Loss: 5.43405
2018-02-05 00:57:19,536 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 100 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 13
}
--------------------------------------------------
2018-02-05 00:57:20,043 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:21,383 __main__ [INFO ] Evaluated on training set. Loss: 0.77992
2018-02-05 00:57:21,408 __main__ [INFO ] Evaluated on validation set. Loss: 5.50794
2018-02-05 00:57:21,409 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 101 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 13
}
--------------------------------------------------
2018-02-05 00:57:21,923 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:23,384 __main__ [INFO ] Evaluated on training set. Loss: 2.74093
2018-02-05 00:57:23,415 __main__ [INFO ] Evaluated on validation set. Loss: 5.59828
2018-02-05 00:57:23,415 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 102 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 13
}
--------------------------------------------------
2018-02-05 00:57:23,937 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:25,283 __main__ [INFO ] Evaluated on training set. Loss: 2.76424
2018-02-05 00:57:25,308 __main__ [INFO ] Evaluated on validation set. Loss: 5.65373
2018-02-05 00:57:25,308 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 103 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 13
}
--------------------------------------------------
2018-02-05 00:57:25,823 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:27,263 __main__ [INFO ] Evaluated on training set. Loss: 5.00076
2018-02-05 00:57:27,293 __main__ [INFO ] Evaluated on validation set. Loss: 5.91301
2018-02-05 00:57:27,293 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 104 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 13
}
--------------------------------------------------
2018-02-05 00:57:27,801 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:29,136 __main__ [INFO ] Evaluated on training set. Loss: 5.03729
2018-02-05 00:57:29,160 __main__ [INFO ] Evaluated on validation set. Loss: 5.93918
2018-02-05 00:57:29,160 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 105 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 14
}
--------------------------------------------------
2018-02-05 00:57:29,675 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:31,158 __main__ [INFO ] Evaluated on training set. Loss: 0.16701
2018-02-05 00:57:31,271 __main__ [INFO ] Evaluated on validation set. Loss: 5.62142
2018-02-05 00:57:31,271 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 106 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 14
}
--------------------------------------------------
2018-02-05 00:57:31,727 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:33,099 __main__ [INFO ] Evaluated on training set. Loss: 0.15651
2018-02-05 00:57:33,124 __main__ [INFO ] Evaluated on validation set. Loss: 5.67731
2018-02-05 00:57:33,125 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 107 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 14
}
--------------------------------------------------
2018-02-05 00:57:33,640 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:35,118 __main__ [INFO ] Evaluated on training set. Loss: 0.78076
2018-02-05 00:57:35,149 __main__ [INFO ] Evaluated on validation set. Loss: 5.58305
2018-02-05 00:57:35,149 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 108 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 14
}
--------------------------------------------------
2018-02-05 00:57:35,678 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:37,045 __main__ [INFO ] Evaluated on training set. Loss: 0.77747
2018-02-05 00:57:37,070 __main__ [INFO ] Evaluated on validation set. Loss: 5.64139
2018-02-05 00:57:37,070 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 109 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 14
}
--------------------------------------------------
2018-02-05 00:57:37,592 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:39,083 __main__ [INFO ] Evaluated on training set. Loss: 2.77765
2018-02-05 00:57:39,199 __main__ [INFO ] Evaluated on validation set. Loss: 5.71934
2018-02-05 00:57:39,199 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 110 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 14
}
--------------------------------------------------
2018-02-05 00:57:39,568 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:41,030 __main__ [INFO ] Evaluated on training set. Loss: 2.79678
2018-02-05 00:57:41,055 __main__ [INFO ] Evaluated on validation set. Loss: 5.76354
2018-02-05 00:57:41,055 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 111 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 14
}
--------------------------------------------------
2018-02-05 00:57:41,580 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:43,067 __main__ [INFO ] Evaluated on training set. Loss: 5.04664
2018-02-05 00:57:43,098 __main__ [INFO ] Evaluated on validation set. Loss: 5.97312
2018-02-05 00:57:43,098 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 112 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 14
}
--------------------------------------------------
2018-02-05 00:57:43,617 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:44,988 __main__ [INFO ] Evaluated on training set. Loss: 5.07591
2018-02-05 00:57:45,097 __main__ [INFO ] Evaluated on validation set. Loss: 5.99408
2018-02-05 00:57:45,098 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 113 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 15
}
--------------------------------------------------
2018-02-05 00:57:45,560 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:47,073 __main__ [INFO ] Evaluated on training set. Loss: 0.15061
2018-02-05 00:57:47,105 __main__ [INFO ] Evaluated on validation set. Loss: 5.73959
2018-02-05 00:57:47,106 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 114 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 15
}
--------------------------------------------------
2018-02-05 00:57:47,624 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:49,143 __main__ [INFO ] Evaluated on training set. Loss: 0.14254
2018-02-05 00:57:49,168 __main__ [INFO ] Evaluated on validation set. Loss: 5.78290
2018-02-05 00:57:49,169 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 115 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 15
}
--------------------------------------------------
2018-02-05 00:57:49,550 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:51,162 __main__ [INFO ] Evaluated on training set. Loss: 0.77827
2018-02-05 00:57:51,193 __main__ [INFO ] Evaluated on validation set. Loss: 5.70785
2018-02-05 00:57:51,193 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 116 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 15
}
--------------------------------------------------
2018-02-05 00:57:51,647 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:53,159 __main__ [INFO ] Evaluated on training set. Loss: 0.77605
2018-02-05 00:57:53,184 __main__ [INFO ] Evaluated on validation set. Loss: 5.75369
2018-02-05 00:57:53,184 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 117 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 15
}
--------------------------------------------------
2018-02-05 00:57:53,559 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:55,184 __main__ [INFO ] Evaluated on training set. Loss: 2.80615
2018-02-05 00:57:55,217 __main__ [INFO ] Evaluated on validation set. Loss: 5.81772
2018-02-05 00:57:55,217 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 118 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 15
}
--------------------------------------------------
2018-02-05 00:57:55,674 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:57,064 __main__ [INFO ] Evaluated on training set. Loss: 2.82194
2018-02-05 00:57:57,174 __main__ [INFO ] Evaluated on validation set. Loss: 5.85282
2018-02-05 00:57:57,175 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 119 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 15
}
--------------------------------------------------
2018-02-05 00:57:57,544 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:57:59,147 __main__ [INFO ] Evaluated on training set. Loss: 5.08152
2018-02-05 00:57:59,178 __main__ [INFO ] Evaluated on validation set. Loss: 6.01954
2018-02-05 00:57:59,179 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 120 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 15
}
--------------------------------------------------
2018-02-05 00:57:59,605 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:01,097 __main__ [INFO ] Evaluated on training set. Loss: 5.10509
2018-02-05 00:58:01,122 __main__ [INFO ] Evaluated on validation set. Loss: 6.03627
2018-02-05 00:58:01,122 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 121 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 16
}
--------------------------------------------------
2018-02-05 00:58:01,567 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:03,197 __main__ [INFO ] Evaluated on training set. Loss: 0.13933
2018-02-05 00:58:03,231 __main__ [INFO ] Evaluated on validation set. Loss: 5.83557
2018-02-05 00:58:03,231 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 122 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 16
}
--------------------------------------------------
2018-02-05 00:58:03,675 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:05,196 __main__ [INFO ] Evaluated on training set. Loss: 0.13309
2018-02-05 00:58:05,223 __main__ [INFO ] Evaluated on validation set. Loss: 5.87111
2018-02-05 00:58:05,223 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 123 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 16
}
--------------------------------------------------
2018-02-05 00:58:05,663 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:07,293 __main__ [INFO ] Evaluated on training set. Loss: 0.77772
2018-02-05 00:58:07,325 __main__ [INFO ] Evaluated on validation set. Loss: 5.81055
2018-02-05 00:58:07,325 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 124 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 16
}
--------------------------------------------------
2018-02-05 00:58:07,770 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:09,286 __main__ [INFO ] Evaluated on training set. Loss: 0.77626
2018-02-05 00:58:09,312 __main__ [INFO ] Evaluated on validation set. Loss: 5.84761
2018-02-05 00:58:09,313 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 125 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 16
}
--------------------------------------------------
2018-02-05 00:58:09,756 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:11,388 __main__ [INFO ] Evaluated on training set. Loss: 2.82915
2018-02-05 00:58:11,420 __main__ [INFO ] Evaluated on validation set. Loss: 5.89824
2018-02-05 00:58:11,421 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 126 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 16
}
--------------------------------------------------
2018-02-05 00:58:11,865 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:13,390 __main__ [INFO ] Evaluated on training set. Loss: 2.84220
2018-02-05 00:58:13,415 __main__ [INFO ] Evaluated on validation set. Loss: 5.92651
2018-02-05 00:58:13,415 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 127 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 16
}
--------------------------------------------------
2018-02-05 00:58:13,865 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:15,500 __main__ [INFO ] Evaluated on training set. Loss: 5.10865
2018-02-05 00:58:15,531 __main__ [INFO ] Evaluated on validation set. Loss: 6.05736
2018-02-05 00:58:15,532 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 128 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 16
}
--------------------------------------------------
2018-02-05 00:58:15,980 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:17,503 __main__ [INFO ] Evaluated on training set. Loss: 5.12774
2018-02-05 00:58:17,528 __main__ [INFO ] Evaluated on validation set. Loss: 6.07066
2018-02-05 00:58:17,528 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 129 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 17
}
--------------------------------------------------
2018-02-05 00:58:17,993 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:19,661 __main__ [INFO ] Evaluated on training set. Loss: 0.13139
2018-02-05 00:58:19,694 __main__ [INFO ] Evaluated on validation set. Loss: 5.92252
2018-02-05 00:58:19,694 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 130 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 17
}
--------------------------------------------------
2018-02-05 00:58:20,071 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:21,600 __main__ [INFO ] Evaluated on training set. Loss: 0.12641
2018-02-05 00:58:21,626 __main__ [INFO ] Evaluated on validation set. Loss: 5.94885
2018-02-05 00:58:21,626 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 131 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 17
}
--------------------------------------------------
2018-02-05 00:58:22,076 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:23,717 __main__ [INFO ] Evaluated on training set. Loss: 0.77810
2018-02-05 00:58:23,750 __main__ [INFO ] Evaluated on validation set. Loss: 5.89988
2018-02-05 00:58:23,750 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 132 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 17
}
--------------------------------------------------
2018-02-05 00:58:24,200 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:25,730 __main__ [INFO ] Evaluated on training set. Loss: 0.77704
2018-02-05 00:58:25,756 __main__ [INFO ] Evaluated on validation set. Loss: 5.92817
2018-02-05 00:58:25,756 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 133 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 17
}
--------------------------------------------------
2018-02-05 00:58:26,214 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:27,866 __main__ [INFO ] Evaluated on training set. Loss: 2.84765
2018-02-05 00:58:27,899 __main__ [INFO ] Evaluated on validation set. Loss: 5.96703
2018-02-05 00:58:27,899 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 134 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 17
}
--------------------------------------------------
2018-02-05 00:58:28,369 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:29,895 __main__ [INFO ] Evaluated on training set. Loss: 2.85837
2018-02-05 00:58:29,920 __main__ [INFO ] Evaluated on validation set. Loss: 5.98894
2018-02-05 00:58:29,920 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 135 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 17
}
--------------------------------------------------
2018-02-05 00:58:30,378 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:32,014 __main__ [INFO ] Evaluated on training set. Loss: 5.13004
2018-02-05 00:58:32,045 __main__ [INFO ] Evaluated on validation set. Loss: 6.08982
2018-02-05 00:58:32,046 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 136 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 17
}
--------------------------------------------------
2018-02-05 00:58:32,490 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:34,007 __main__ [INFO ] Evaluated on training set. Loss: 5.14557
2018-02-05 00:58:34,032 __main__ [INFO ] Evaluated on validation set. Loss: 6.09993
2018-02-05 00:58:34,032 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 137 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 18
}
--------------------------------------------------
2018-02-05 00:58:34,481 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:36,132 __main__ [INFO ] Evaluated on training set. Loss: 0.12482
2018-02-05 00:58:36,165 __main__ [INFO ] Evaluated on validation set. Loss: 5.99431
2018-02-05 00:58:36,166 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 138 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 18
}
--------------------------------------------------
2018-02-05 00:58:36,608 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:38,145 __main__ [INFO ] Evaluated on training set. Loss: 0.12090
2018-02-05 00:58:38,171 __main__ [INFO ] Evaluated on validation set. Loss: 6.01236
2018-02-05 00:58:38,171 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 139 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 18
}
--------------------------------------------------
2018-02-05 00:58:38,616 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:40,273 __main__ [INFO ] Evaluated on training set. Loss: 0.77818
2018-02-05 00:58:40,306 __main__ [INFO ] Evaluated on validation set. Loss: 5.97343
2018-02-05 00:58:40,306 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 140 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 18
}
--------------------------------------------------
2018-02-05 00:58:40,849 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:42,304 __main__ [INFO ] Evaluated on training set. Loss: 0.77747
2018-02-05 00:58:42,329 __main__ [INFO ] Evaluated on validation set. Loss: 5.99383
2018-02-05 00:58:42,330 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 141 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 18
}
--------------------------------------------------
2018-02-05 00:58:42,855 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:44,544 __main__ [INFO ] Evaluated on training set. Loss: 2.86203
2018-02-05 00:58:44,577 __main__ [INFO ] Evaluated on validation set. Loss: 6.02355
2018-02-05 00:58:44,577 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 142 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 18
}
--------------------------------------------------
2018-02-05 00:58:44,954 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:46,499 __main__ [INFO ] Evaluated on training set. Loss: 2.87089
2018-02-05 00:58:46,524 __main__ [INFO ] Evaluated on validation set. Loss: 6.03974
2018-02-05 00:58:46,525 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 143 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 18
}
--------------------------------------------------
2018-02-05 00:58:46,979 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:48,648 __main__ [INFO ] Evaluated on training set. Loss: 5.14663
2018-02-05 00:58:48,680 __main__ [INFO ] Evaluated on validation set. Loss: 6.11576
2018-02-05 00:58:48,680 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 144 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 18
}
--------------------------------------------------
2018-02-05 00:58:49,144 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:50,585 __main__ [INFO ] Evaluated on training set. Loss: 5.15938
2018-02-05 00:58:50,696 __main__ [INFO ] Evaluated on validation set. Loss: 6.12308
2018-02-05 00:58:50,696 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 145 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 19
}
--------------------------------------------------
2018-02-05 00:58:51,164 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:52,743 __main__ [INFO ] Evaluated on training set. Loss: 0.11990
2018-02-05 00:58:52,775 __main__ [INFO ] Evaluated on validation set. Loss: 6.03294
2018-02-05 00:58:52,775 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 146 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 19
}
--------------------------------------------------
2018-02-05 00:58:53,315 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:54,768 __main__ [INFO ] Evaluated on training set. Loss: 0.11684
2018-02-05 00:58:54,794 __main__ [INFO ] Evaluated on validation set. Loss: 6.05011
2018-02-05 00:58:54,794 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 147 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 19
}
--------------------------------------------------
2018-02-05 00:58:55,325 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:57,024 __main__ [INFO ] Evaluated on training set. Loss: 0.77852
2018-02-05 00:58:57,057 __main__ [INFO ] Evaluated on validation set. Loss: 6.02016
2018-02-05 00:58:57,058 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 148 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 19
}
--------------------------------------------------
2018-02-05 00:58:57,443 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:58:58,998 __main__ [INFO ] Evaluated on training set. Loss: 0.77809
2018-02-05 00:58:59,024 __main__ [INFO ] Evaluated on validation set. Loss: 6.03777
2018-02-05 00:58:59,024 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 149 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 19
}
--------------------------------------------------
2018-02-05 00:58:59,472 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:01,149 __main__ [INFO ] Evaluated on training set. Loss: 2.87358
2018-02-05 00:59:01,181 __main__ [INFO ] Evaluated on validation set. Loss: 6.06175
2018-02-05 00:59:01,182 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 150 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 19
}
--------------------------------------------------
2018-02-05 00:59:01,644 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:03,211 __main__ [INFO ] Evaluated on training set. Loss: 2.88096
2018-02-05 00:59:03,237 __main__ [INFO ] Evaluated on validation set. Loss: 6.07490
2018-02-05 00:59:03,238 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 151 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 19
}
--------------------------------------------------
2018-02-05 00:59:03,700 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:05,398 __main__ [INFO ] Evaluated on training set. Loss: 5.15985
2018-02-05 00:59:05,431 __main__ [INFO ] Evaluated on validation set. Loss: 6.13335
2018-02-05 00:59:05,431 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 152 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 19
}
--------------------------------------------------
2018-02-05 00:59:05,818 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:07,359 __main__ [INFO ] Evaluated on training set. Loss: 5.17042
2018-02-05 00:59:07,385 __main__ [INFO ] Evaluated on validation set. Loss: 6.13881
2018-02-05 00:59:07,385 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 153 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 20
}
--------------------------------------------------
2018-02-05 00:59:07,838 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:09,516 __main__ [INFO ] Evaluated on training set. Loss: 0.11627
2018-02-05 00:59:09,550 __main__ [INFO ] Evaluated on validation set. Loss: 6.07232
2018-02-05 00:59:09,550 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 154 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 20
}
--------------------------------------------------
2018-02-05 00:59:10,003 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:11,572 __main__ [INFO ] Evaluated on training set. Loss: 0.11379
2018-02-05 00:59:11,598 __main__ [INFO ] Evaluated on validation set. Loss: 6.08613
2018-02-05 00:59:11,599 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 155 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 20
}
--------------------------------------------------
2018-02-05 00:59:12,068 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:13,759 __main__ [INFO ] Evaluated on training set. Loss: 0.77901
2018-02-05 00:59:13,791 __main__ [INFO ] Evaluated on validation set. Loss: 6.06101
2018-02-05 00:59:13,792 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 156 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 20
}
--------------------------------------------------
2018-02-05 00:59:14,175 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:15,725 __main__ [INFO ] Evaluated on training set. Loss: 0.77870
2018-02-05 00:59:15,751 __main__ [INFO ] Evaluated on validation set. Loss: 6.07541
2018-02-05 00:59:15,751 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 157 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 20
}
--------------------------------------------------
2018-02-05 00:59:16,204 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:17,872 __main__ [INFO ] Evaluated on training set. Loss: 2.88283
2018-02-05 00:59:17,906 __main__ [INFO ] Evaluated on validation set. Loss: 6.09226
2018-02-05 00:59:17,906 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 158 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 20
}
--------------------------------------------------
2018-02-05 00:59:18,365 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:19,938 __main__ [INFO ] Evaluated on training set. Loss: 2.88897
2018-02-05 00:59:19,965 __main__ [INFO ] Evaluated on validation set. Loss: 6.10281
2018-02-05 00:59:19,965 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 159 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 20
}
--------------------------------------------------
2018-02-05 00:59:20,424 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:22,123 __main__ [INFO ] Evaluated on training set. Loss: 5.17039
2018-02-05 00:59:22,156 __main__ [INFO ] Evaluated on validation set. Loss: 6.14630
2018-02-05 00:59:22,156 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 160 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 20
}
--------------------------------------------------
2018-02-05 00:59:22,540 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 00:59:24,101 __main__ [INFO ] Evaluated on training set. Loss: 5.17922
2018-02-05 00:59:24,126 __main__ [INFO ] Evaluated on validation set. Loss: 6.15048
2018-02-05 01:14:04,073 __main__ [INFO ] 
==============================
Starting experiment alice_n_gram_delta
==============================
2018-02-05 01:14:04,078 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:04,217 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:04,691 __main__ [INFO ] Evaluated on training set. Loss: 1.83746
2018-02-05 01:14:04,715 __main__ [INFO ] Evaluated on validation set. Loss: 2.42074
2018-02-05 01:14:04,715 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:04,855 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:05,207 __main__ [INFO ] Evaluated on training set. Loss: 1.78918
2018-02-05 01:14:05,226 __main__ [INFO ] Evaluated on validation set. Loss: 2.52118
2018-02-05 01:14:05,226 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.002,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:05,398 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:05,873 __main__ [INFO ] Evaluated on training set. Loss: 1.84152
2018-02-05 01:14:05,896 __main__ [INFO ] Evaluated on validation set. Loss: 2.37778
2018-02-05 01:14:05,896 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.002,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:06,033 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:06,385 __main__ [INFO ] Evaluated on training set. Loss: 1.79415
2018-02-05 01:14:06,401 __main__ [INFO ] Evaluated on validation set. Loss: 2.47183
2018-02-05 01:14:06,401 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.003,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:06,538 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:07,010 __main__ [INFO ] Evaluated on training set. Loss: 1.84546
2018-02-05 01:14:07,034 __main__ [INFO ] Evaluated on validation set. Loss: 2.35458
2018-02-05 01:14:07,034 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.003,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:07,168 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:07,514 __main__ [INFO ] Evaluated on training set. Loss: 1.79897
2018-02-05 01:14:07,530 __main__ [INFO ] Evaluated on validation set. Loss: 2.44492
2018-02-05 01:14:07,530 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.004,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:07,665 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:08,131 __main__ [INFO ] Evaluated on training set. Loss: 1.84929
2018-02-05 01:14:08,154 __main__ [INFO ] Evaluated on validation set. Loss: 2.33940
2018-02-05 01:14:08,154 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.004,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:08,319 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:08,665 __main__ [INFO ] Evaluated on training set. Loss: 1.80367
2018-02-05 01:14:08,682 __main__ [INFO ] Evaluated on validation set. Loss: 2.42713
2018-02-05 01:14:08,682 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.005,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:08,816 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:09,284 __main__ [INFO ] Evaluated on training set. Loss: 1.85302
2018-02-05 01:14:09,308 __main__ [INFO ] Evaluated on validation set. Loss: 2.32857
2018-02-05 01:14:09,308 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.005,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:09,442 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:09,793 __main__ [INFO ] Evaluated on training set. Loss: 1.80826
2018-02-05 01:14:09,810 __main__ [INFO ] Evaluated on validation set. Loss: 2.41429
2018-02-05 01:14:09,810 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.006,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:09,943 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:10,409 __main__ [INFO ] Evaluated on training set. Loss: 1.85665
2018-02-05 01:14:10,433 __main__ [INFO ] Evaluated on validation set. Loss: 2.32046
2018-02-05 01:14:10,433 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.006,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:10,599 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:10,947 __main__ [INFO ] Evaluated on training set. Loss: 1.81273
2018-02-05 01:14:10,963 __main__ [INFO ] Evaluated on validation set. Loss: 2.40454
2018-02-05 01:14:10,964 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.007,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:11,097 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:11,568 __main__ [INFO ] Evaluated on training set. Loss: 1.86020
2018-02-05 01:14:11,591 __main__ [INFO ] Evaluated on validation set. Loss: 2.31419
2018-02-05 01:14:11,591 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.007,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:11,726 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:12,076 __main__ [INFO ] Evaluated on training set. Loss: 1.81711
2018-02-05 01:14:12,093 __main__ [INFO ] Evaluated on validation set. Loss: 2.39690
2018-02-05 01:14:12,093 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.008,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:12,230 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:12,694 __main__ [INFO ] Evaluated on training set. Loss: 1.86367
2018-02-05 01:14:12,717 __main__ [INFO ] Evaluated on validation set. Loss: 2.30926
2018-02-05 01:14:12,717 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.008,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:12,851 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:13,195 __main__ [INFO ] Evaluated on training set. Loss: 1.82139
2018-02-05 01:14:13,211 __main__ [INFO ] Evaluated on validation set. Loss: 2.39079
2018-02-05 01:14:13,211 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.009,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:13,377 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:13,844 __main__ [INFO ] Evaluated on training set. Loss: 1.86706
2018-02-05 01:14:13,866 __main__ [INFO ] Evaluated on validation set. Loss: 2.30533
2018-02-05 01:14:13,867 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.009,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:14,000 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:14,347 __main__ [INFO ] Evaluated on training set. Loss: 1.82559
2018-02-05 01:14:14,364 __main__ [INFO ] Evaluated on validation set. Loss: 2.38583
2018-02-05 01:14:14,364 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:14,498 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:14,964 __main__ [INFO ] Evaluated on training set. Loss: 1.87039
2018-02-05 01:14:14,987 __main__ [INFO ] Evaluated on validation set. Loss: 2.30218
2018-02-05 01:14:14,988 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:15,123 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:15,468 __main__ [INFO ] Evaluated on training set. Loss: 1.82971
2018-02-05 01:14:15,485 __main__ [INFO ] Evaluated on validation set. Loss: 2.38176
2018-02-05 01:14:15,485 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 21 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.011,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:15,651 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:16,121 __main__ [INFO ] Evaluated on training set. Loss: 1.87365
2018-02-05 01:14:16,145 __main__ [INFO ] Evaluated on validation set. Loss: 2.29965
2018-02-05 01:14:16,145 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 22 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.011,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:16,280 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:16,627 __main__ [INFO ] Evaluated on training set. Loss: 1.83375
2018-02-05 01:14:16,644 __main__ [INFO ] Evaluated on validation set. Loss: 2.37841
2018-02-05 01:14:16,645 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 23 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.012,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:16,782 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:17,247 __main__ [INFO ] Evaluated on training set. Loss: 1.87686
2018-02-05 01:14:17,270 __main__ [INFO ] Evaluated on validation set. Loss: 2.29762
2018-02-05 01:14:17,271 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 24 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.012,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:17,404 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:17,755 __main__ [INFO ] Evaluated on training set. Loss: 1.83772
2018-02-05 01:14:17,772 __main__ [INFO ] Evaluated on validation set. Loss: 2.37563
2018-02-05 01:14:17,772 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 25 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.013,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:17,906 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:18,377 __main__ [INFO ] Evaluated on training set. Loss: 1.88000
2018-02-05 01:14:18,400 __main__ [INFO ] Evaluated on validation set. Loss: 2.29600
2018-02-05 01:14:18,400 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 26 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.013,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:18,564 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:18,917 __main__ [INFO ] Evaluated on training set. Loss: 1.84162
2018-02-05 01:14:18,933 __main__ [INFO ] Evaluated on validation set. Loss: 2.37333
2018-02-05 01:14:18,933 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 27 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.014,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:19,067 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:19,534 __main__ [INFO ] Evaluated on training set. Loss: 1.88310
2018-02-05 01:14:19,557 __main__ [INFO ] Evaluated on validation set. Loss: 2.29474
2018-02-05 01:14:19,557 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 28 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.014,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:19,692 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:20,036 __main__ [INFO ] Evaluated on training set. Loss: 1.84546
2018-02-05 01:14:20,053 __main__ [INFO ] Evaluated on validation set. Loss: 2.37143
2018-02-05 01:14:20,054 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 29 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.015,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:20,188 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:20,655 __main__ [INFO ] Evaluated on training set. Loss: 1.88614
2018-02-05 01:14:20,679 __main__ [INFO ] Evaluated on validation set. Loss: 2.29376
2018-02-05 01:14:20,679 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 30 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.015,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:20,847 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:21,193 __main__ [INFO ] Evaluated on training set. Loss: 1.84924
2018-02-05 01:14:21,210 __main__ [INFO ] Evaluated on validation set. Loss: 2.36988
2018-02-05 01:14:21,210 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 31 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.016,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:21,345 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:21,813 __main__ [INFO ] Evaluated on training set. Loss: 1.88914
2018-02-05 01:14:21,836 __main__ [INFO ] Evaluated on validation set. Loss: 2.29304
2018-02-05 01:14:21,837 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 32 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.016,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:21,972 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:22,317 __main__ [INFO ] Evaluated on training set. Loss: 1.85296
2018-02-05 01:14:22,334 __main__ [INFO ] Evaluated on validation set. Loss: 2.36861
2018-02-05 01:14:22,334 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 33 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.017,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:22,469 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:22,938 __main__ [INFO ] Evaluated on training set. Loss: 1.89209
2018-02-05 01:14:22,962 __main__ [INFO ] Evaluated on validation set. Loss: 2.29253
2018-02-05 01:14:22,962 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 34 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.017,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:23,096 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:23,441 __main__ [INFO ] Evaluated on training set. Loss: 1.85663
2018-02-05 01:14:23,458 __main__ [INFO ] Evaluated on validation set. Loss: 2.36760
2018-02-05 01:14:23,458 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 35 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.018,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:23,622 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:24,088 __main__ [INFO ] Evaluated on training set. Loss: 1.89500
2018-02-05 01:14:24,111 __main__ [INFO ] Evaluated on validation set. Loss: 2.29221
2018-02-05 01:14:24,111 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 36 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.018,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:24,246 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:24,592 __main__ [INFO ] Evaluated on training set. Loss: 1.86024
2018-02-05 01:14:24,609 __main__ [INFO ] Evaluated on validation set. Loss: 2.36681
2018-02-05 01:14:24,609 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 37 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.019,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:24,744 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:25,207 __main__ [INFO ] Evaluated on training set. Loss: 1.89787
2018-02-05 01:14:25,230 __main__ [INFO ] Evaluated on validation set. Loss: 2.29206
2018-02-05 01:14:25,230 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 38 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.019,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:25,364 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:25,714 __main__ [INFO ] Evaluated on training set. Loss: 1.86381
2018-02-05 01:14:25,732 __main__ [INFO ] Evaluated on validation set. Loss: 2.36621
2018-02-05 01:14:25,732 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 39 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.02,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:25,898 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:26,371 __main__ [INFO ] Evaluated on training set. Loss: 1.90070
2018-02-05 01:14:26,394 __main__ [INFO ] Evaluated on validation set. Loss: 2.29204
2018-02-05 01:14:26,395 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 40 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.02,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:26,529 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:26,876 __main__ [INFO ] Evaluated on training set. Loss: 1.86732
2018-02-05 01:14:26,892 __main__ [INFO ] Evaluated on validation set. Loss: 2.36578
2018-02-05 01:14:26,893 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 41 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.021,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:27,027 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:27,491 __main__ [INFO ] Evaluated on training set. Loss: 1.90349
2018-02-05 01:14:27,515 __main__ [INFO ] Evaluated on validation set. Loss: 2.29216
2018-02-05 01:14:27,515 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 42 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.021,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:27,649 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:27,991 __main__ [INFO ] Evaluated on training set. Loss: 1.87080
2018-02-05 01:14:28,008 __main__ [INFO ] Evaluated on validation set. Loss: 2.36550
2018-02-05 01:14:28,008 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 43 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.022,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:28,141 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:28,602 __main__ [INFO ] Evaluated on training set. Loss: 1.90624
2018-02-05 01:14:28,626 __main__ [INFO ] Evaluated on validation set. Loss: 2.29239
2018-02-05 01:14:28,626 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 44 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.022,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:28,791 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:29,135 __main__ [INFO ] Evaluated on training set. Loss: 1.87422
2018-02-05 01:14:29,152 __main__ [INFO ] Evaluated on validation set. Loss: 2.36535
2018-02-05 01:14:29,152 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 45 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.023,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:29,288 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:29,753 __main__ [INFO ] Evaluated on training set. Loss: 1.90897
2018-02-05 01:14:29,776 __main__ [INFO ] Evaluated on validation set. Loss: 2.29272
2018-02-05 01:14:29,776 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 46 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.023,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:29,912 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:30,263 __main__ [INFO ] Evaluated on training set. Loss: 1.87761
2018-02-05 01:14:30,280 __main__ [INFO ] Evaluated on validation set. Loss: 2.36532
2018-02-05 01:14:30,280 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 47 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.024,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:30,413 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:30,881 __main__ [INFO ] Evaluated on training set. Loss: 1.91165
2018-02-05 01:14:30,904 __main__ [INFO ] Evaluated on validation set. Loss: 2.29314
2018-02-05 01:14:30,904 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 48 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.024,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:31,069 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:31,423 __main__ [INFO ] Evaluated on training set. Loss: 1.88096
2018-02-05 01:14:31,440 __main__ [INFO ] Evaluated on validation set. Loss: 2.36540
2018-02-05 01:14:31,440 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 49 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.025,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:31,573 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:32,040 __main__ [INFO ] Evaluated on training set. Loss: 1.91431
2018-02-05 01:14:32,063 __main__ [INFO ] Evaluated on validation set. Loss: 2.29364
2018-02-05 01:14:32,063 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 50 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.025,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:32,196 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:32,545 __main__ [INFO ] Evaluated on training set. Loss: 1.88426
2018-02-05 01:14:32,562 __main__ [INFO ] Evaluated on validation set. Loss: 2.36558
2018-02-05 01:14:32,562 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 51 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.026,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:32,696 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:33,161 __main__ [INFO ] Evaluated on training set. Loss: 1.91694
2018-02-05 01:14:33,184 __main__ [INFO ] Evaluated on validation set. Loss: 2.29422
2018-02-05 01:14:33,185 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 52 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.026,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:33,318 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:33,669 __main__ [INFO ] Evaluated on training set. Loss: 1.88753
2018-02-05 01:14:33,685 __main__ [INFO ] Evaluated on validation set. Loss: 2.36584
2018-02-05 01:14:33,686 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 53 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.027,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:33,850 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:34,316 __main__ [INFO ] Evaluated on training set. Loss: 1.91953
2018-02-05 01:14:34,339 __main__ [INFO ] Evaluated on validation set. Loss: 2.29486
2018-02-05 01:14:34,339 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 54 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.027,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:34,474 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:34,820 __main__ [INFO ] Evaluated on training set. Loss: 1.89077
2018-02-05 01:14:34,837 __main__ [INFO ] Evaluated on validation set. Loss: 2.36618
2018-02-05 01:14:34,837 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 55 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.028,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:34,971 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:35,433 __main__ [INFO ] Evaluated on training set. Loss: 1.92210
2018-02-05 01:14:35,456 __main__ [INFO ] Evaluated on validation set. Loss: 2.29556
2018-02-05 01:14:35,457 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 56 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.028,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:35,591 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:35,949 __main__ [INFO ] Evaluated on training set. Loss: 1.89397
2018-02-05 01:14:35,966 __main__ [INFO ] Evaluated on validation set. Loss: 2.36660
2018-02-05 01:14:35,966 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 57 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.029,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:36,132 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:36,606 __main__ [INFO ] Evaluated on training set. Loss: 1.92464
2018-02-05 01:14:36,629 __main__ [INFO ] Evaluated on validation set. Loss: 2.29631
2018-02-05 01:14:36,630 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 58 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.029,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:36,766 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:37,119 __main__ [INFO ] Evaluated on training set. Loss: 1.89713
2018-02-05 01:14:37,135 __main__ [INFO ] Evaluated on validation set. Loss: 2.36708
2018-02-05 01:14:37,135 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 59 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.03,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:37,272 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:37,743 __main__ [INFO ] Evaluated on training set. Loss: 1.92716
2018-02-05 01:14:37,766 __main__ [INFO ] Evaluated on validation set. Loss: 2.29712
2018-02-05 01:14:37,766 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 60 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.03,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:37,901 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:38,254 __main__ [INFO ] Evaluated on training set. Loss: 1.90026
2018-02-05 01:14:38,271 __main__ [INFO ] Evaluated on validation set. Loss: 2.36762
2018-02-05 01:14:38,271 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 61 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.031,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:38,404 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:38,879 __main__ [INFO ] Evaluated on training set. Loss: 1.92964
2018-02-05 01:14:38,903 __main__ [INFO ] Evaluated on validation set. Loss: 2.29797
2018-02-05 01:14:38,903 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 62 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.031,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:39,067 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:39,422 __main__ [INFO ] Evaluated on training set. Loss: 1.90336
2018-02-05 01:14:39,439 __main__ [INFO ] Evaluated on validation set. Loss: 2.36822
2018-02-05 01:14:39,439 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 63 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.032,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:39,573 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:40,048 __main__ [INFO ] Evaluated on training set. Loss: 1.93211
2018-02-05 01:14:40,071 __main__ [INFO ] Evaluated on validation set. Loss: 2.29886
2018-02-05 01:14:40,071 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 64 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.032,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:40,206 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:40,563 __main__ [INFO ] Evaluated on training set. Loss: 1.90643
2018-02-05 01:14:40,580 __main__ [INFO ] Evaluated on validation set. Loss: 2.36886
2018-02-05 01:14:40,580 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 65 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.033,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:40,720 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:41,190 __main__ [INFO ] Evaluated on training set. Loss: 1.93455
2018-02-05 01:14:41,213 __main__ [INFO ] Evaluated on validation set. Loss: 2.29978
2018-02-05 01:14:41,213 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 66 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.033,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:41,380 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:41,735 __main__ [INFO ] Evaluated on training set. Loss: 1.90947
2018-02-05 01:14:41,752 __main__ [INFO ] Evaluated on validation set. Loss: 2.36955
2018-02-05 01:14:41,752 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 67 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.034,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:41,886 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:42,357 __main__ [INFO ] Evaluated on training set. Loss: 1.93697
2018-02-05 01:14:42,381 __main__ [INFO ] Evaluated on validation set. Loss: 2.30075
2018-02-05 01:14:42,381 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 68 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.034,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:42,516 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:42,874 __main__ [INFO ] Evaluated on training set. Loss: 1.91248
2018-02-05 01:14:42,891 __main__ [INFO ] Evaluated on validation set. Loss: 2.37029
2018-02-05 01:14:42,891 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 69 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.035,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:43,025 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:43,495 __main__ [INFO ] Evaluated on training set. Loss: 1.93936
2018-02-05 01:14:43,518 __main__ [INFO ] Evaluated on validation set. Loss: 2.30174
2018-02-05 01:14:43,518 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 70 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.035,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:43,651 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:44,005 __main__ [INFO ] Evaluated on training set. Loss: 1.91546
2018-02-05 01:14:44,022 __main__ [INFO ] Evaluated on validation set. Loss: 2.37106
2018-02-05 01:14:44,022 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 71 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.036,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:44,190 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:44,665 __main__ [INFO ] Evaluated on training set. Loss: 1.94173
2018-02-05 01:14:44,689 __main__ [INFO ] Evaluated on validation set. Loss: 2.30276
2018-02-05 01:14:44,689 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 72 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.036,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:44,824 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:45,176 __main__ [INFO ] Evaluated on training set. Loss: 1.91842
2018-02-05 01:14:45,193 __main__ [INFO ] Evaluated on validation set. Loss: 2.37187
2018-02-05 01:14:45,193 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 73 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.037,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:45,328 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:45,801 __main__ [INFO ] Evaluated on training set. Loss: 1.94408
2018-02-05 01:14:45,824 __main__ [INFO ] Evaluated on validation set. Loss: 2.30381
2018-02-05 01:14:45,824 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 74 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.037,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:45,959 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:46,316 __main__ [INFO ] Evaluated on training set. Loss: 1.92135
2018-02-05 01:14:46,332 __main__ [INFO ] Evaluated on validation set. Loss: 2.37272
2018-02-05 01:14:46,333 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 75 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.038,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:46,502 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:46,976 __main__ [INFO ] Evaluated on training set. Loss: 1.94641
2018-02-05 01:14:46,999 __main__ [INFO ] Evaluated on validation set. Loss: 2.30489
2018-02-05 01:14:46,999 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 76 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.038,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:47,135 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:47,485 __main__ [INFO ] Evaluated on training set. Loss: 1.92425
2018-02-05 01:14:47,502 __main__ [INFO ] Evaluated on validation set. Loss: 2.37359
2018-02-05 01:14:47,503 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 77 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.039,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:47,642 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:48,107 __main__ [INFO ] Evaluated on training set. Loss: 1.94872
2018-02-05 01:14:48,130 __main__ [INFO ] Evaluated on validation set. Loss: 2.30599
2018-02-05 01:14:48,130 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 78 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.039,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:48,265 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:48,612 __main__ [INFO ] Evaluated on training set. Loss: 1.92712
2018-02-05 01:14:48,629 __main__ [INFO ] Evaluated on validation set. Loss: 2.37450
2018-02-05 01:14:48,630 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 79 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.04,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:48,768 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:49,235 __main__ [INFO ] Evaluated on training set. Loss: 1.95101
2018-02-05 01:14:49,259 __main__ [INFO ] Evaluated on validation set. Loss: 2.30710
2018-02-05 01:14:49,259 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 80 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.04,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:49,424 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:49,775 __main__ [INFO ] Evaluated on training set. Loss: 1.92998
2018-02-05 01:14:49,793 __main__ [INFO ] Evaluated on validation set. Loss: 2.37543
2018-02-05 01:14:49,793 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 81 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.041,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:49,935 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:50,403 __main__ [INFO ] Evaluated on training set. Loss: 1.95328
2018-02-05 01:14:50,427 __main__ [INFO ] Evaluated on validation set. Loss: 2.30824
2018-02-05 01:14:50,427 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 82 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.041,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:50,562 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:50,914 __main__ [INFO ] Evaluated on training set. Loss: 1.93280
2018-02-05 01:14:50,931 __main__ [INFO ] Evaluated on validation set. Loss: 2.37638
2018-02-05 01:14:50,931 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 83 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.042,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:51,067 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:51,535 __main__ [INFO ] Evaluated on training set. Loss: 1.95554
2018-02-05 01:14:51,559 __main__ [INFO ] Evaluated on validation set. Loss: 2.30940
2018-02-05 01:14:51,559 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 84 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.042,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:51,727 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:52,072 __main__ [INFO ] Evaluated on training set. Loss: 1.93561
2018-02-05 01:14:52,089 __main__ [INFO ] Evaluated on validation set. Loss: 2.37736
2018-02-05 01:14:52,090 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 85 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.043,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:52,223 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:52,691 __main__ [INFO ] Evaluated on training set. Loss: 1.95777
2018-02-05 01:14:52,715 __main__ [INFO ] Evaluated on validation set. Loss: 2.31057
2018-02-05 01:14:52,715 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 86 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.043,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:52,852 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:53,198 __main__ [INFO ] Evaluated on training set. Loss: 1.93839
2018-02-05 01:14:53,214 __main__ [INFO ] Evaluated on validation set. Loss: 2.37836
2018-02-05 01:14:53,215 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 87 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.044,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:53,352 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:53,822 __main__ [INFO ] Evaluated on training set. Loss: 1.95999
2018-02-05 01:14:53,845 __main__ [INFO ] Evaluated on validation set. Loss: 2.31175
2018-02-05 01:14:53,846 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 88 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.044,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:53,980 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:54,327 __main__ [INFO ] Evaluated on training set. Loss: 1.94115
2018-02-05 01:14:54,343 __main__ [INFO ] Evaluated on validation set. Loss: 2.37937
2018-02-05 01:14:54,344 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 89 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.045,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:54,507 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:54,975 __main__ [INFO ] Evaluated on training set. Loss: 1.96219
2018-02-05 01:14:54,998 __main__ [INFO ] Evaluated on validation set. Loss: 2.31295
2018-02-05 01:14:54,998 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 90 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.045,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:55,132 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:55,479 __main__ [INFO ] Evaluated on training set. Loss: 1.94389
2018-02-05 01:14:55,496 __main__ [INFO ] Evaluated on validation set. Loss: 2.38041
2018-02-05 01:14:55,496 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 91 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.046,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:55,631 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:56,097 __main__ [INFO ] Evaluated on training set. Loss: 1.96437
2018-02-05 01:14:56,120 __main__ [INFO ] Evaluated on validation set. Loss: 2.31417
2018-02-05 01:14:56,120 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 92 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.046,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:56,254 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:56,607 __main__ [INFO ] Evaluated on training set. Loss: 1.94661
2018-02-05 01:14:56,623 __main__ [INFO ] Evaluated on validation set. Loss: 2.38147
2018-02-05 01:14:56,624 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 93 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.047,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:56,792 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:57,263 __main__ [INFO ] Evaluated on training set. Loss: 1.96653
2018-02-05 01:14:57,287 __main__ [INFO ] Evaluated on validation set. Loss: 2.31539
2018-02-05 01:14:57,287 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 94 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.047,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:57,421 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:57,772 __main__ [INFO ] Evaluated on training set. Loss: 1.94930
2018-02-05 01:14:57,788 __main__ [INFO ] Evaluated on validation set. Loss: 2.38253
2018-02-05 01:14:57,789 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 95 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.048,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:57,923 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:58,389 __main__ [INFO ] Evaluated on training set. Loss: 1.96868
2018-02-05 01:14:58,412 __main__ [INFO ] Evaluated on validation set. Loss: 2.31663
2018-02-05 01:14:58,412 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 96 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.048,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:58,548 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:58,900 __main__ [INFO ] Evaluated on training set. Loss: 1.95198
2018-02-05 01:14:58,917 __main__ [INFO ] Evaluated on validation set. Loss: 2.38362
2018-02-05 01:14:58,917 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 97 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.049,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:59,050 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:14:59,515 __main__ [INFO ] Evaluated on training set. Loss: 1.97082
2018-02-05 01:14:59,538 __main__ [INFO ] Evaluated on validation set. Loss: 2.31787
2018-02-05 01:14:59,538 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 98 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.049,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:14:59,702 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:00,050 __main__ [INFO ] Evaluated on training set. Loss: 1.95463
2018-02-05 01:15:00,067 __main__ [INFO ] Evaluated on validation set. Loss: 2.38472
2018-02-05 01:15:00,067 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 99 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.05,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:00,202 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:00,665 __main__ [INFO ] Evaluated on training set. Loss: 1.97294
2018-02-05 01:15:00,688 __main__ [INFO ] Evaluated on validation set. Loss: 2.31913
2018-02-05 01:15:00,688 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 100 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.05,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:00,824 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:01,177 __main__ [INFO ] Evaluated on training set. Loss: 1.95727
2018-02-05 01:15:01,194 __main__ [INFO ] Evaluated on validation set. Loss: 2.38583
2018-02-05 01:15:01,194 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 101 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.051,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:01,331 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:01,812 __main__ [INFO ] Evaluated on training set. Loss: 1.97504
2018-02-05 01:15:01,836 __main__ [INFO ] Evaluated on validation set. Loss: 2.32039
2018-02-05 01:15:01,836 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 102 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.051,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:02,001 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:02,365 __main__ [INFO ] Evaluated on training set. Loss: 1.95989
2018-02-05 01:15:02,382 __main__ [INFO ] Evaluated on validation set. Loss: 2.38695
2018-02-05 01:15:02,382 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 103 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.052,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:02,517 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:02,984 __main__ [INFO ] Evaluated on training set. Loss: 1.97713
2018-02-05 01:15:03,008 __main__ [INFO ] Evaluated on validation set. Loss: 2.32166
2018-02-05 01:15:03,008 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 104 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.052,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:03,144 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:03,487 __main__ [INFO ] Evaluated on training set. Loss: 1.96249
2018-02-05 01:15:03,504 __main__ [INFO ] Evaluated on validation set. Loss: 2.38809
2018-02-05 01:15:03,505 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 105 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.053,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:03,640 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:04,103 __main__ [INFO ] Evaluated on training set. Loss: 1.97920
2018-02-05 01:15:04,127 __main__ [INFO ] Evaluated on validation set. Loss: 2.32294
2018-02-05 01:15:04,127 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 106 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.053,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:04,261 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:04,611 __main__ [INFO ] Evaluated on training set. Loss: 1.96507
2018-02-05 01:15:04,628 __main__ [INFO ] Evaluated on validation set. Loss: 2.38923
2018-02-05 01:15:04,628 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 107 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.054,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:04,795 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:05,259 __main__ [INFO ] Evaluated on training set. Loss: 1.98126
2018-02-05 01:15:05,283 __main__ [INFO ] Evaluated on validation set. Loss: 2.32423
2018-02-05 01:15:05,283 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 108 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.054,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:05,418 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:05,769 __main__ [INFO ] Evaluated on training set. Loss: 1.96763
2018-02-05 01:15:05,786 __main__ [INFO ] Evaluated on validation set. Loss: 2.39039
2018-02-05 01:15:05,786 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 109 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.055,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:05,921 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:06,385 __main__ [INFO ] Evaluated on training set. Loss: 1.98331
2018-02-05 01:15:06,408 __main__ [INFO ] Evaluated on validation set. Loss: 2.32552
2018-02-05 01:15:06,408 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 110 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.055,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:06,541 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:06,887 __main__ [INFO ] Evaluated on training set. Loss: 1.97018
2018-02-05 01:15:06,904 __main__ [INFO ] Evaluated on validation set. Loss: 2.39155
2018-02-05 01:15:06,904 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 111 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.056,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:07,070 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:07,539 __main__ [INFO ] Evaluated on training set. Loss: 1.98534
2018-02-05 01:15:07,562 __main__ [INFO ] Evaluated on validation set. Loss: 2.32682
2018-02-05 01:15:07,562 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 112 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.056,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:07,696 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:08,044 __main__ [INFO ] Evaluated on training set. Loss: 1.97270
2018-02-05 01:15:08,061 __main__ [INFO ] Evaluated on validation set. Loss: 2.39272
2018-02-05 01:15:08,061 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 113 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.057,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:08,195 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:08,659 __main__ [INFO ] Evaluated on training set. Loss: 1.98736
2018-02-05 01:15:08,683 __main__ [INFO ] Evaluated on validation set. Loss: 2.32812
2018-02-05 01:15:08,683 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 114 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.057,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:08,821 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:09,168 __main__ [INFO ] Evaluated on training set. Loss: 1.97521
2018-02-05 01:15:09,185 __main__ [INFO ] Evaluated on validation set. Loss: 2.39390
2018-02-05 01:15:09,186 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 115 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.058,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:09,324 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:09,800 __main__ [INFO ] Evaluated on training set. Loss: 1.98937
2018-02-05 01:15:09,823 __main__ [INFO ] Evaluated on validation set. Loss: 2.32943
2018-02-05 01:15:09,823 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 116 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.058,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:09,987 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:10,336 __main__ [INFO ] Evaluated on training set. Loss: 1.97771
2018-02-05 01:15:10,353 __main__ [INFO ] Evaluated on validation set. Loss: 2.39509
2018-02-05 01:15:10,353 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 117 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.059,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:10,487 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:10,958 __main__ [INFO ] Evaluated on training set. Loss: 1.99136
2018-02-05 01:15:10,982 __main__ [INFO ] Evaluated on validation set. Loss: 2.33074
2018-02-05 01:15:10,982 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 118 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.059,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:11,120 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:11,467 __main__ [INFO ] Evaluated on training set. Loss: 1.98019
2018-02-05 01:15:11,484 __main__ [INFO ] Evaluated on validation set. Loss: 2.39628
2018-02-05 01:15:11,484 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 119 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.06,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:11,618 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:12,084 __main__ [INFO ] Evaluated on training set. Loss: 1.99334
2018-02-05 01:15:12,108 __main__ [INFO ] Evaluated on validation set. Loss: 2.33205
2018-02-05 01:15:12,108 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 120 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.06,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:12,274 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:12,625 __main__ [INFO ] Evaluated on training set. Loss: 1.98265
2018-02-05 01:15:12,642 __main__ [INFO ] Evaluated on validation set. Loss: 2.39748
2018-02-05 01:15:12,642 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 121 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.061,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:12,777 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:13,242 __main__ [INFO ] Evaluated on training set. Loss: 1.99531
2018-02-05 01:15:13,266 __main__ [INFO ] Evaluated on validation set. Loss: 2.33337
2018-02-05 01:15:13,266 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 122 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.061,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:13,401 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:13,753 __main__ [INFO ] Evaluated on training set. Loss: 1.98510
2018-02-05 01:15:13,770 __main__ [INFO ] Evaluated on validation set. Loss: 2.39869
2018-02-05 01:15:13,770 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 123 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.062,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:13,906 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:14,371 __main__ [INFO ] Evaluated on training set. Loss: 1.99727
2018-02-05 01:15:14,395 __main__ [INFO ] Evaluated on validation set. Loss: 2.33470
2018-02-05 01:15:14,395 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 124 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.062,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:14,530 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:14,881 __main__ [INFO ] Evaluated on training set. Loss: 1.98753
2018-02-05 01:15:14,898 __main__ [INFO ] Evaluated on validation set. Loss: 2.39990
2018-02-05 01:15:14,898 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 125 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.063,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:15,063 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:15,529 __main__ [INFO ] Evaluated on training set. Loss: 1.99921
2018-02-05 01:15:15,552 __main__ [INFO ] Evaluated on validation set. Loss: 2.33602
2018-02-05 01:15:15,552 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 126 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.063,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:15,686 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:16,037 __main__ [INFO ] Evaluated on training set. Loss: 1.98994
2018-02-05 01:15:16,054 __main__ [INFO ] Evaluated on validation set. Loss: 2.40112
2018-02-05 01:15:16,054 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 127 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.064,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:16,189 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:16,658 __main__ [INFO ] Evaluated on training set. Loss: 2.00115
2018-02-05 01:15:16,681 __main__ [INFO ] Evaluated on validation set. Loss: 2.33735
2018-02-05 01:15:16,681 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 128 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.064,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:16,819 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:17,166 __main__ [INFO ] Evaluated on training set. Loss: 1.99235
2018-02-05 01:15:17,183 __main__ [INFO ] Evaluated on validation set. Loss: 2.40234
2018-02-05 01:15:17,184 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 129 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.065,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:17,351 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:17,821 __main__ [INFO ] Evaluated on training set. Loss: 2.00307
2018-02-05 01:15:17,844 __main__ [INFO ] Evaluated on validation set. Loss: 2.33868
2018-02-05 01:15:17,845 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 130 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.065,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:17,978 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:18,330 __main__ [INFO ] Evaluated on training set. Loss: 1.99473
2018-02-05 01:15:18,347 __main__ [INFO ] Evaluated on validation set. Loss: 2.40356
2018-02-05 01:15:18,347 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 131 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.066,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:18,482 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:18,949 __main__ [INFO ] Evaluated on training set. Loss: 2.00498
2018-02-05 01:15:18,972 __main__ [INFO ] Evaluated on validation set. Loss: 2.34001
2018-02-05 01:15:18,973 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 132 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.066,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:19,107 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:19,457 __main__ [INFO ] Evaluated on training set. Loss: 1.99711
2018-02-05 01:15:19,474 __main__ [INFO ] Evaluated on validation set. Loss: 2.40479
2018-02-05 01:15:19,474 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 133 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.067,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:19,610 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:20,078 __main__ [INFO ] Evaluated on training set. Loss: 2.00688
2018-02-05 01:15:20,103 __main__ [INFO ] Evaluated on validation set. Loss: 2.34134
2018-02-05 01:15:20,103 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 134 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.067,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:20,268 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:20,615 __main__ [INFO ] Evaluated on training set. Loss: 1.99946
2018-02-05 01:15:20,632 __main__ [INFO ] Evaluated on validation set. Loss: 2.40603
2018-02-05 01:15:20,632 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 135 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.068,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:20,768 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:21,239 __main__ [INFO ] Evaluated on training set. Loss: 2.00877
2018-02-05 01:15:21,263 __main__ [INFO ] Evaluated on validation set. Loss: 2.34268
2018-02-05 01:15:21,264 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 136 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.068,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:21,400 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:21,747 __main__ [INFO ] Evaluated on training set. Loss: 2.00181
2018-02-05 01:15:21,764 __main__ [INFO ] Evaluated on validation set. Loss: 2.40726
2018-02-05 01:15:21,764 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 137 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.069,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:21,899 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:22,363 __main__ [INFO ] Evaluated on training set. Loss: 2.01064
2018-02-05 01:15:22,387 __main__ [INFO ] Evaluated on validation set. Loss: 2.34402
2018-02-05 01:15:22,388 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 138 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.069,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:22,554 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:22,904 __main__ [INFO ] Evaluated on training set. Loss: 2.00414
2018-02-05 01:15:22,921 __main__ [INFO ] Evaluated on validation set. Loss: 2.40850
2018-02-05 01:15:22,921 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 139 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.07,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:23,055 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:23,522 __main__ [INFO ] Evaluated on training set. Loss: 2.01251
2018-02-05 01:15:23,545 __main__ [INFO ] Evaluated on validation set. Loss: 2.34535
2018-02-05 01:15:23,546 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 140 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.07,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:23,682 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:24,034 __main__ [INFO ] Evaluated on training set. Loss: 2.00646
2018-02-05 01:15:24,052 __main__ [INFO ] Evaluated on validation set. Loss: 2.40974
2018-02-05 01:15:24,052 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 141 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.071,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:24,188 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:24,653 __main__ [INFO ] Evaluated on training set. Loss: 2.01437
2018-02-05 01:15:24,677 __main__ [INFO ] Evaluated on validation set. Loss: 2.34669
2018-02-05 01:15:24,677 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 142 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.071,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:24,815 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:25,166 __main__ [INFO ] Evaluated on training set. Loss: 2.00876
2018-02-05 01:15:25,183 __main__ [INFO ] Evaluated on validation set. Loss: 2.41099
2018-02-05 01:15:25,184 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 143 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.072,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:25,351 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:25,823 __main__ [INFO ] Evaluated on training set. Loss: 2.01621
2018-02-05 01:15:25,846 __main__ [INFO ] Evaluated on validation set. Loss: 2.34803
2018-02-05 01:15:25,847 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 144 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.072,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:25,982 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:26,330 __main__ [INFO ] Evaluated on training set. Loss: 2.01105
2018-02-05 01:15:26,347 __main__ [INFO ] Evaluated on validation set. Loss: 2.41223
2018-02-05 01:15:26,348 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 145 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.073,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:26,488 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:26,955 __main__ [INFO ] Evaluated on training set. Loss: 2.01805
2018-02-05 01:15:26,978 __main__ [INFO ] Evaluated on validation set. Loss: 2.34937
2018-02-05 01:15:26,979 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 146 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.073,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:27,112 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:27,466 __main__ [INFO ] Evaluated on training set. Loss: 2.01333
2018-02-05 01:15:27,483 __main__ [INFO ] Evaluated on validation set. Loss: 2.41348
2018-02-05 01:15:27,483 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 147 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.074,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:27,652 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:28,120 __main__ [INFO ] Evaluated on training set. Loss: 2.01988
2018-02-05 01:15:28,144 __main__ [INFO ] Evaluated on validation set. Loss: 2.35071
2018-02-05 01:15:28,144 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 148 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.074,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:28,279 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:28,647 __main__ [INFO ] Evaluated on training set. Loss: 2.01560
2018-02-05 01:15:28,664 __main__ [INFO ] Evaluated on validation set. Loss: 2.41473
2018-02-05 01:15:28,664 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 149 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.075,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:28,802 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:29,278 __main__ [INFO ] Evaluated on training set. Loss: 2.02169
2018-02-05 01:15:29,302 __main__ [INFO ] Evaluated on validation set. Loss: 2.35205
2018-02-05 01:15:29,302 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 150 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.075,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:29,437 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:29,783 __main__ [INFO ] Evaluated on training set. Loss: 2.01785
2018-02-05 01:15:29,800 __main__ [INFO ] Evaluated on validation set. Loss: 2.41599
2018-02-05 01:15:29,800 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 151 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.076,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:29,934 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:30,399 __main__ [INFO ] Evaluated on training set. Loss: 2.02350
2018-02-05 01:15:30,422 __main__ [INFO ] Evaluated on validation set. Loss: 2.35339
2018-02-05 01:15:30,422 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 152 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.076,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:30,587 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:30,936 __main__ [INFO ] Evaluated on training set. Loss: 2.02009
2018-02-05 01:15:30,953 __main__ [INFO ] Evaluated on validation set. Loss: 2.41724
2018-02-05 01:15:30,953 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 153 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.077,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:31,086 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:31,554 __main__ [INFO ] Evaluated on training set. Loss: 2.02530
2018-02-05 01:15:31,577 __main__ [INFO ] Evaluated on validation set. Loss: 2.35473
2018-02-05 01:15:31,578 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 154 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.077,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:31,713 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:32,061 __main__ [INFO ] Evaluated on training set. Loss: 2.02232
2018-02-05 01:15:32,078 __main__ [INFO ] Evaluated on validation set. Loss: 2.41850
2018-02-05 01:15:32,078 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 155 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.078,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:32,212 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:32,679 __main__ [INFO ] Evaluated on training set. Loss: 2.02709
2018-02-05 01:15:32,702 __main__ [INFO ] Evaluated on validation set. Loss: 2.35607
2018-02-05 01:15:32,703 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 156 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.078,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:32,871 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:33,219 __main__ [INFO ] Evaluated on training set. Loss: 2.02454
2018-02-05 01:15:33,236 __main__ [INFO ] Evaluated on validation set. Loss: 2.41975
2018-02-05 01:15:33,236 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 157 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.079,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:33,371 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:33,840 __main__ [INFO ] Evaluated on training set. Loss: 2.02887
2018-02-05 01:15:33,863 __main__ [INFO ] Evaluated on validation set. Loss: 2.35741
2018-02-05 01:15:33,864 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 158 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.079,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:33,998 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:34,345 __main__ [INFO ] Evaluated on training set. Loss: 2.02675
2018-02-05 01:15:34,362 __main__ [INFO ] Evaluated on validation set. Loss: 2.42101
2018-02-05 01:15:34,362 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 159 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.08,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:34,496 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:34,960 __main__ [INFO ] Evaluated on training set. Loss: 2.03064
2018-02-05 01:15:34,983 __main__ [INFO ] Evaluated on validation set. Loss: 2.35875
2018-02-05 01:15:34,983 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 160 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.08,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:35,117 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:35,464 __main__ [INFO ] Evaluated on training set. Loss: 2.02894
2018-02-05 01:15:35,480 __main__ [INFO ] Evaluated on validation set. Loss: 2.42227
2018-02-05 01:15:35,480 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 161 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.081,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:35,644 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:36,109 __main__ [INFO ] Evaluated on training set. Loss: 2.03240
2018-02-05 01:15:36,133 __main__ [INFO ] Evaluated on validation set. Loss: 2.36009
2018-02-05 01:15:36,133 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 162 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.081,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:36,267 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:36,617 __main__ [INFO ] Evaluated on training set. Loss: 2.03112
2018-02-05 01:15:36,634 __main__ [INFO ] Evaluated on validation set. Loss: 2.42353
2018-02-05 01:15:36,634 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 163 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.082,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:36,770 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:37,233 __main__ [INFO ] Evaluated on training set. Loss: 2.03415
2018-02-05 01:15:37,256 __main__ [INFO ] Evaluated on validation set. Loss: 2.36143
2018-02-05 01:15:37,257 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 164 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.082,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:37,392 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:37,743 __main__ [INFO ] Evaluated on training set. Loss: 2.03330
2018-02-05 01:15:37,760 __main__ [INFO ] Evaluated on validation set. Loss: 2.42479
2018-02-05 01:15:37,761 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 165 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.083,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:37,928 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:38,396 __main__ [INFO ] Evaluated on training set. Loss: 2.03590
2018-02-05 01:15:38,419 __main__ [INFO ] Evaluated on validation set. Loss: 2.36277
2018-02-05 01:15:38,420 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 166 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.083,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:38,553 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:38,903 __main__ [INFO ] Evaluated on training set. Loss: 2.03546
2018-02-05 01:15:38,919 __main__ [INFO ] Evaluated on validation set. Loss: 2.42605
2018-02-05 01:15:38,920 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 167 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.084,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:39,054 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:39,518 __main__ [INFO ] Evaluated on training set. Loss: 2.03763
2018-02-05 01:15:39,541 __main__ [INFO ] Evaluated on validation set. Loss: 2.36410
2018-02-05 01:15:39,541 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 168 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.084,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:39,675 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:40,019 __main__ [INFO ] Evaluated on training set. Loss: 2.03761
2018-02-05 01:15:40,036 __main__ [INFO ] Evaluated on validation set. Loss: 2.42731
2018-02-05 01:15:40,036 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 169 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.085,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:40,169 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:40,632 __main__ [INFO ] Evaluated on training set. Loss: 2.03936
2018-02-05 01:15:40,655 __main__ [INFO ] Evaluated on validation set. Loss: 2.36544
2018-02-05 01:15:40,655 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 170 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.085,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:40,820 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:41,169 __main__ [INFO ] Evaluated on training set. Loss: 2.03975
2018-02-05 01:15:41,186 __main__ [INFO ] Evaluated on validation set. Loss: 2.42857
2018-02-05 01:15:41,186 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 171 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.086,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:41,321 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:41,789 __main__ [INFO ] Evaluated on training set. Loss: 2.04108
2018-02-05 01:15:41,813 __main__ [INFO ] Evaluated on validation set. Loss: 2.36677
2018-02-05 01:15:41,814 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 172 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.086,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:41,948 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:42,293 __main__ [INFO ] Evaluated on training set. Loss: 2.04187
2018-02-05 01:15:42,310 __main__ [INFO ] Evaluated on validation set. Loss: 2.42983
2018-02-05 01:15:42,310 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 173 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.087,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:42,444 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:42,912 __main__ [INFO ] Evaluated on training set. Loss: 2.04279
2018-02-05 01:15:42,936 __main__ [INFO ] Evaluated on validation set. Loss: 2.36811
2018-02-05 01:15:42,936 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 174 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.087,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:43,102 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:43,450 __main__ [INFO ] Evaluated on training set. Loss: 2.04399
2018-02-05 01:15:43,467 __main__ [INFO ] Evaluated on validation set. Loss: 2.43109
2018-02-05 01:15:43,467 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 175 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.088,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:43,601 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:44,066 __main__ [INFO ] Evaluated on training set. Loss: 2.04449
2018-02-05 01:15:44,090 __main__ [INFO ] Evaluated on validation set. Loss: 2.36944
2018-02-05 01:15:44,090 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 176 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.088,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:44,225 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:44,576 __main__ [INFO ] Evaluated on training set. Loss: 2.04610
2018-02-05 01:15:44,592 __main__ [INFO ] Evaluated on validation set. Loss: 2.43235
2018-02-05 01:15:44,593 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 177 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.089,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:44,727 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:45,194 __main__ [INFO ] Evaluated on training set. Loss: 2.04619
2018-02-05 01:15:45,216 __main__ [INFO ] Evaluated on validation set. Loss: 2.37077
2018-02-05 01:15:45,217 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 178 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.089,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:45,352 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:45,698 __main__ [INFO ] Evaluated on training set. Loss: 2.04820
2018-02-05 01:15:45,715 __main__ [INFO ] Evaluated on validation set. Loss: 2.43361
2018-02-05 01:15:45,715 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 179 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.09,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:45,881 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:46,345 __main__ [INFO ] Evaluated on training set. Loss: 2.04788
2018-02-05 01:15:46,369 __main__ [INFO ] Evaluated on validation set. Loss: 2.37210
2018-02-05 01:15:46,369 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 180 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.09,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:46,503 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:46,852 __main__ [INFO ] Evaluated on training set. Loss: 2.05029
2018-02-05 01:15:46,869 __main__ [INFO ] Evaluated on validation set. Loss: 2.43487
2018-02-05 01:15:46,870 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 181 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.091,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:47,004 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:47,474 __main__ [INFO ] Evaluated on training set. Loss: 2.04955
2018-02-05 01:15:47,498 __main__ [INFO ] Evaluated on validation set. Loss: 2.37343
2018-02-05 01:15:47,498 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 182 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.091,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:47,633 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:47,982 __main__ [INFO ] Evaluated on training set. Loss: 2.05236
2018-02-05 01:15:47,999 __main__ [INFO ] Evaluated on validation set. Loss: 2.43613
2018-02-05 01:15:47,999 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 183 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.092,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:48,167 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:48,635 __main__ [INFO ] Evaluated on training set. Loss: 2.05123
2018-02-05 01:15:48,659 __main__ [INFO ] Evaluated on validation set. Loss: 2.37476
2018-02-05 01:15:48,659 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 184 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.092,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:48,795 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:49,142 __main__ [INFO ] Evaluated on training set. Loss: 2.05443
2018-02-05 01:15:49,159 __main__ [INFO ] Evaluated on validation set. Loss: 2.43739
2018-02-05 01:15:49,159 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 185 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.093,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:49,295 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:49,770 __main__ [INFO ] Evaluated on training set. Loss: 2.05289
2018-02-05 01:15:49,794 __main__ [INFO ] Evaluated on validation set. Loss: 2.37608
2018-02-05 01:15:49,795 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 186 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.093,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:49,934 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:50,283 __main__ [INFO ] Evaluated on training set. Loss: 2.05649
2018-02-05 01:15:50,300 __main__ [INFO ] Evaluated on validation set. Loss: 2.43864
2018-02-05 01:15:50,301 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 187 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.094,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:50,437 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:50,903 __main__ [INFO ] Evaluated on training set. Loss: 2.05455
2018-02-05 01:15:50,926 __main__ [INFO ] Evaluated on validation set. Loss: 2.37741
2018-02-05 01:15:50,927 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 188 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.094,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:51,093 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:51,444 __main__ [INFO ] Evaluated on training set. Loss: 2.05854
2018-02-05 01:15:51,461 __main__ [INFO ] Evaluated on validation set. Loss: 2.43990
2018-02-05 01:15:51,461 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 189 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.095,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:51,595 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:52,065 __main__ [INFO ] Evaluated on training set. Loss: 2.05620
2018-02-05 01:15:52,089 __main__ [INFO ] Evaluated on validation set. Loss: 2.37873
2018-02-05 01:15:52,089 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 190 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.095,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:52,224 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:52,576 __main__ [INFO ] Evaluated on training set. Loss: 2.06058
2018-02-05 01:15:52,592 __main__ [INFO ] Evaluated on validation set. Loss: 2.44116
2018-02-05 01:15:52,593 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 191 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.096,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:52,729 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:53,200 __main__ [INFO ] Evaluated on training set. Loss: 2.05784
2018-02-05 01:15:53,224 __main__ [INFO ] Evaluated on validation set. Loss: 2.38005
2018-02-05 01:15:53,224 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 192 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.096,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:53,396 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:53,744 __main__ [INFO ] Evaluated on training set. Loss: 2.06261
2018-02-05 01:15:53,762 __main__ [INFO ] Evaluated on validation set. Loss: 2.44242
2018-02-05 01:15:53,762 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 193 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.097,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:53,898 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:54,372 __main__ [INFO ] Evaluated on training set. Loss: 2.05947
2018-02-05 01:15:54,396 __main__ [INFO ] Evaluated on validation set. Loss: 2.38137
2018-02-05 01:15:54,396 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 194 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.097,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:54,531 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:54,879 __main__ [INFO ] Evaluated on training set. Loss: 2.06463
2018-02-05 01:15:54,896 __main__ [INFO ] Evaluated on validation set. Loss: 2.44367
2018-02-05 01:15:54,896 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 195 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.098,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:55,032 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:55,500 __main__ [INFO ] Evaluated on training set. Loss: 2.06110
2018-02-05 01:15:55,524 __main__ [INFO ] Evaluated on validation set. Loss: 2.38269
2018-02-05 01:15:55,524 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 196 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.098,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:55,658 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:56,007 __main__ [INFO ] Evaluated on training set. Loss: 2.06664
2018-02-05 01:15:56,024 __main__ [INFO ] Evaluated on validation set. Loss: 2.44492
2018-02-05 01:15:56,024 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 197 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.099,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:56,190 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:56,656 __main__ [INFO ] Evaluated on training set. Loss: 2.06272
2018-02-05 01:15:56,679 __main__ [INFO ] Evaluated on validation set. Loss: 2.38400
2018-02-05 01:15:56,679 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 198 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.099,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:56,815 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:57,163 __main__ [INFO ] Evaluated on training set. Loss: 2.06865
2018-02-05 01:15:57,179 __main__ [INFO ] Evaluated on validation set. Loss: 2.44618
2018-02-05 01:15:57,179 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 199 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:57,315 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:57,785 __main__ [INFO ] Evaluated on training set. Loss: 2.06434
2018-02-05 01:15:57,808 __main__ [INFO ] Evaluated on validation set. Loss: 2.38532
2018-02-05 01:15:57,808 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 200 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:15:57,943 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:58,291 __main__ [INFO ] Evaluated on training set. Loss: 2.07064
2018-02-05 01:15:58,307 __main__ [INFO ] Evaluated on validation set. Loss: 2.44743
2018-02-05 01:15:58,308 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 201 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:15:58,494 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:59,082 __main__ [INFO ] Evaluated on training set. Loss: 1.38630
2018-02-05 01:15:59,106 __main__ [INFO ] Evaluated on validation set. Loss: 2.67920
2018-02-05 01:15:59,106 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 202 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:15:59,258 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:15:59,767 __main__ [INFO ] Evaluated on training set. Loss: 1.31779
2018-02-05 01:15:59,784 __main__ [INFO ] Evaluated on validation set. Loss: 2.79794
2018-02-05 01:15:59,785 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 203 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.002,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:15:59,939 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:00,527 __main__ [INFO ] Evaluated on training set. Loss: 1.39828
2018-02-05 01:16:00,551 __main__ [INFO ] Evaluated on validation set. Loss: 2.59798
2018-02-05 01:16:00,551 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 204 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.002,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:00,744 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:01,214 __main__ [INFO ] Evaluated on training set. Loss: 1.33169
2018-02-05 01:16:01,231 __main__ [INFO ] Evaluated on validation set. Loss: 2.71097
2018-02-05 01:16:01,231 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 205 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.003,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:01,386 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:02,018 __main__ [INFO ] Evaluated on training set. Loss: 1.40979
2018-02-05 01:16:02,042 __main__ [INFO ] Evaluated on validation set. Loss: 2.55493
2018-02-05 01:16:02,042 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 206 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.003,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:02,195 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:02,668 __main__ [INFO ] Evaluated on training set. Loss: 1.34507
2018-02-05 01:16:02,687 __main__ [INFO ] Evaluated on validation set. Loss: 2.66458
2018-02-05 01:16:02,687 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 207 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.004,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:02,888 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:03,481 __main__ [INFO ] Evaluated on training set. Loss: 1.42088
2018-02-05 01:16:03,506 __main__ [INFO ] Evaluated on validation set. Loss: 2.52731
2018-02-05 01:16:03,506 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 208 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.004,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:03,662 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:04,133 __main__ [INFO ] Evaluated on training set. Loss: 1.35799
2018-02-05 01:16:04,152 __main__ [INFO ] Evaluated on validation set. Loss: 2.63460
2018-02-05 01:16:04,152 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 209 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.005,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:04,345 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:04,938 __main__ [INFO ] Evaluated on training set. Loss: 1.43159
2018-02-05 01:16:04,964 __main__ [INFO ] Evaluated on validation set. Loss: 2.50802
2018-02-05 01:16:04,964 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 210 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.005,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:05,119 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:05,635 __main__ [INFO ] Evaluated on training set. Loss: 1.37048
2018-02-05 01:16:05,654 __main__ [INFO ] Evaluated on validation set. Loss: 2.61348
2018-02-05 01:16:05,654 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 211 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.006,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:05,812 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:06,400 __main__ [INFO ] Evaluated on training set. Loss: 1.44196
2018-02-05 01:16:06,425 __main__ [INFO ] Evaluated on validation set. Loss: 2.49389
2018-02-05 01:16:06,426 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 212 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.006,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:06,621 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:07,090 __main__ [INFO ] Evaluated on training set. Loss: 1.38258
2018-02-05 01:16:07,108 __main__ [INFO ] Evaluated on validation set. Loss: 2.59787
2018-02-05 01:16:07,108 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 213 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.007,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:07,265 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:07,893 __main__ [INFO ] Evaluated on training set. Loss: 1.45201
2018-02-05 01:16:07,918 __main__ [INFO ] Evaluated on validation set. Loss: 2.48326
2018-02-05 01:16:07,918 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 214 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.007,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:08,073 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:08,545 __main__ [INFO ] Evaluated on training set. Loss: 1.39433
2018-02-05 01:16:08,563 __main__ [INFO ] Evaluated on validation set. Loss: 2.58600
2018-02-05 01:16:08,563 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 215 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.008,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:08,762 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:09,350 __main__ [INFO ] Evaluated on training set. Loss: 1.46177
2018-02-05 01:16:09,375 __main__ [INFO ] Evaluated on validation set. Loss: 2.47513
2018-02-05 01:16:09,375 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 216 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.008,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:09,531 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:10,003 __main__ [INFO ] Evaluated on training set. Loss: 1.40575
2018-02-05 01:16:10,021 __main__ [INFO ] Evaluated on validation set. Loss: 2.57680
2018-02-05 01:16:10,022 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 217 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.009,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:10,216 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:10,810 __main__ [INFO ] Evaluated on training set. Loss: 1.47126
2018-02-05 01:16:10,835 __main__ [INFO ] Evaluated on validation set. Loss: 2.46888
2018-02-05 01:16:10,835 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 218 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.009,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:10,991 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:11,502 __main__ [INFO ] Evaluated on training set. Loss: 1.41687
2018-02-05 01:16:11,521 __main__ [INFO ] Evaluated on validation set. Loss: 2.56961
2018-02-05 01:16:11,521 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 219 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:11,677 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:12,266 __main__ [INFO ] Evaluated on training set. Loss: 1.48051
2018-02-05 01:16:12,291 __main__ [INFO ] Evaluated on validation set. Loss: 2.46406
2018-02-05 01:16:12,291 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 220 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:12,489 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:12,966 __main__ [INFO ] Evaluated on training set. Loss: 1.42771
2018-02-05 01:16:12,984 __main__ [INFO ] Evaluated on validation set. Loss: 2.56396
2018-02-05 01:16:12,984 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 221 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.011,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:13,140 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:13,773 __main__ [INFO ] Evaluated on training set. Loss: 1.48952
2018-02-05 01:16:13,797 __main__ [INFO ] Evaluated on validation set. Loss: 2.46039
2018-02-05 01:16:13,798 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 222 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.011,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:13,955 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:14,429 __main__ [INFO ] Evaluated on training set. Loss: 1.43828
2018-02-05 01:16:14,447 __main__ [INFO ] Evaluated on validation set. Loss: 2.55952
2018-02-05 01:16:14,447 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 223 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.012,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:14,646 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:15,234 __main__ [INFO ] Evaluated on training set. Loss: 1.49831
2018-02-05 01:16:15,259 __main__ [INFO ] Evaluated on validation set. Loss: 2.45762
2018-02-05 01:16:15,259 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 224 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.012,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:15,417 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:15,892 __main__ [INFO ] Evaluated on training set. Loss: 1.44860
2018-02-05 01:16:15,911 __main__ [INFO ] Evaluated on validation set. Loss: 2.55608
2018-02-05 01:16:15,911 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 225 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.013,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:16,101 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:16,693 __main__ [INFO ] Evaluated on training set. Loss: 1.50691
2018-02-05 01:16:16,719 __main__ [INFO ] Evaluated on validation set. Loss: 2.45561
2018-02-05 01:16:16,719 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 226 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.013,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:16,919 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:17,395 __main__ [INFO ] Evaluated on training set. Loss: 1.45869
2018-02-05 01:16:17,414 __main__ [INFO ] Evaluated on validation set. Loss: 2.55344
2018-02-05 01:16:17,414 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 227 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.014,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:17,569 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:18,158 __main__ [INFO ] Evaluated on training set. Loss: 1.51531
2018-02-05 01:16:18,182 __main__ [INFO ] Evaluated on validation set. Loss: 2.45421
2018-02-05 01:16:18,183 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 228 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.014,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:18,379 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:18,858 __main__ [INFO ] Evaluated on training set. Loss: 1.46856
2018-02-05 01:16:18,877 __main__ [INFO ] Evaluated on validation set. Loss: 2.55146
2018-02-05 01:16:18,877 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 229 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.015,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:19,033 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:19,667 __main__ [INFO ] Evaluated on training set. Loss: 1.52353
2018-02-05 01:16:19,692 __main__ [INFO ] Evaluated on validation set. Loss: 2.45334
2018-02-05 01:16:19,692 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 230 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.015,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:19,850 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:20,324 __main__ [INFO ] Evaluated on training set. Loss: 1.47823
2018-02-05 01:16:20,342 __main__ [INFO ] Evaluated on validation set. Loss: 2.55005
2018-02-05 01:16:20,342 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 231 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.016,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:20,541 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:21,137 __main__ [INFO ] Evaluated on training set. Loss: 1.53159
2018-02-05 01:16:21,162 __main__ [INFO ] Evaluated on validation set. Loss: 2.45291
2018-02-05 01:16:21,162 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 232 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.016,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:21,319 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:21,835 __main__ [INFO ] Evaluated on training set. Loss: 1.48770
2018-02-05 01:16:21,854 __main__ [INFO ] Evaluated on validation set. Loss: 2.54912
2018-02-05 01:16:21,854 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 233 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.017,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:22,011 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:22,602 __main__ [INFO ] Evaluated on training set. Loss: 1.53948
2018-02-05 01:16:22,627 __main__ [INFO ] Evaluated on validation set. Loss: 2.45285
2018-02-05 01:16:22,627 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 234 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.017,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:22,828 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:23,307 __main__ [INFO ] Evaluated on training set. Loss: 1.49699
2018-02-05 01:16:23,325 __main__ [INFO ] Evaluated on validation set. Loss: 2.54859
2018-02-05 01:16:23,326 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 235 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.018,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:23,482 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:24,070 __main__ [INFO ] Evaluated on training set. Loss: 1.54722
2018-02-05 01:16:24,095 __main__ [INFO ] Evaluated on validation set. Loss: 2.45311
2018-02-05 01:16:24,095 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 236 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.018,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:24,291 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:24,772 __main__ [INFO ] Evaluated on training set. Loss: 1.50610
2018-02-05 01:16:24,791 __main__ [INFO ] Evaluated on validation set. Loss: 2.54841
2018-02-05 01:16:24,791 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 237 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.019,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:24,949 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:25,584 __main__ [INFO ] Evaluated on training set. Loss: 1.55482
2018-02-05 01:16:25,609 __main__ [INFO ] Evaluated on validation set. Loss: 2.45365
2018-02-05 01:16:25,609 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 238 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.019,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:25,766 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:26,241 __main__ [INFO ] Evaluated on training set. Loss: 1.51504
2018-02-05 01:16:26,260 __main__ [INFO ] Evaluated on validation set. Loss: 2.54854
2018-02-05 01:16:26,260 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 239 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.02,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:26,460 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:27,053 __main__ [INFO ] Evaluated on training set. Loss: 1.56228
2018-02-05 01:16:27,078 __main__ [INFO ] Evaluated on validation set. Loss: 2.45443
2018-02-05 01:16:27,078 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 240 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.02,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:27,234 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:27,754 __main__ [INFO ] Evaluated on training set. Loss: 1.52383
2018-02-05 01:16:27,773 __main__ [INFO ] Evaluated on validation set. Loss: 2.54893
2018-02-05 01:16:27,773 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 241 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.021,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:27,932 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:28,521 __main__ [INFO ] Evaluated on training set. Loss: 1.56962
2018-02-05 01:16:28,547 __main__ [INFO ] Evaluated on validation set. Loss: 2.45543
2018-02-05 01:16:28,547 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 242 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.021,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:28,746 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:29,226 __main__ [INFO ] Evaluated on training set. Loss: 1.53246
2018-02-05 01:16:29,246 __main__ [INFO ] Evaluated on validation set. Loss: 2.54955
2018-02-05 01:16:29,246 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 243 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.022,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:29,404 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:29,992 __main__ [INFO ] Evaluated on training set. Loss: 1.57682
2018-02-05 01:16:30,016 __main__ [INFO ] Evaluated on validation set. Loss: 2.45661
2018-02-05 01:16:30,017 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 244 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.022,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:30,213 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:30,683 __main__ [INFO ] Evaluated on training set. Loss: 1.54095
2018-02-05 01:16:30,701 __main__ [INFO ] Evaluated on validation set. Loss: 2.55038
2018-02-05 01:16:30,701 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 245 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.023,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:30,896 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:31,483 __main__ [INFO ] Evaluated on training set. Loss: 1.58391
2018-02-05 01:16:31,508 __main__ [INFO ] Evaluated on validation set. Loss: 2.45796
2018-02-05 01:16:31,508 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 246 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.023,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:31,662 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:32,124 __main__ [INFO ] Evaluated on training set. Loss: 1.54930
2018-02-05 01:16:32,142 __main__ [INFO ] Evaluated on validation set. Loss: 2.55139
2018-02-05 01:16:32,142 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 247 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.024,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:32,333 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:32,919 __main__ [INFO ] Evaluated on training set. Loss: 1.59089
2018-02-05 01:16:32,944 __main__ [INFO ] Evaluated on validation set. Loss: 2.45944
2018-02-05 01:16:32,944 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 248 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.024,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:33,097 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:33,610 __main__ [INFO ] Evaluated on training set. Loss: 1.55751
2018-02-05 01:16:33,628 __main__ [INFO ] Evaluated on validation set. Loss: 2.55255
2018-02-05 01:16:33,628 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 249 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.025,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:33,783 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:34,364 __main__ [INFO ] Evaluated on training set. Loss: 1.59775
2018-02-05 01:16:34,388 __main__ [INFO ] Evaluated on validation set. Loss: 2.46106
2018-02-05 01:16:34,388 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 250 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.025,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:34,579 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:35,050 __main__ [INFO ] Evaluated on training set. Loss: 1.56560
2018-02-05 01:16:35,068 __main__ [INFO ] Evaluated on validation set. Loss: 2.55386
2018-02-05 01:16:35,068 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 251 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.026,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:35,221 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:35,851 __main__ [INFO ] Evaluated on training set. Loss: 1.60451
2018-02-05 01:16:35,876 __main__ [INFO ] Evaluated on validation set. Loss: 2.46279
2018-02-05 01:16:35,876 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 252 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.026,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:36,031 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:36,497 __main__ [INFO ] Evaluated on training set. Loss: 1.57356
2018-02-05 01:16:36,515 __main__ [INFO ] Evaluated on validation set. Loss: 2.55530
2018-02-05 01:16:36,515 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 253 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.027,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:36,707 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:37,294 __main__ [INFO ] Evaluated on training set. Loss: 1.61117
2018-02-05 01:16:37,318 __main__ [INFO ] Evaluated on validation set. Loss: 2.46462
2018-02-05 01:16:37,319 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 254 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.027,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:37,473 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:37,942 __main__ [INFO ] Evaluated on training set. Loss: 1.58141
2018-02-05 01:16:37,960 __main__ [INFO ] Evaluated on validation set. Loss: 2.55685
2018-02-05 01:16:37,960 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 255 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.028,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:38,147 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:38,733 __main__ [INFO ] Evaluated on training set. Loss: 1.61774
2018-02-05 01:16:38,757 __main__ [INFO ] Evaluated on validation set. Loss: 2.46655
2018-02-05 01:16:38,758 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 256 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.028,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:38,912 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:39,427 __main__ [INFO ] Evaluated on training set. Loss: 1.58914
2018-02-05 01:16:39,445 __main__ [INFO ] Evaluated on validation set. Loss: 2.55850
2018-02-05 01:16:39,445 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 257 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.029,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:39,598 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:40,181 __main__ [INFO ] Evaluated on training set. Loss: 1.62421
2018-02-05 01:16:40,206 __main__ [INFO ] Evaluated on validation set. Loss: 2.46855
2018-02-05 01:16:40,206 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 258 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.029,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:40,397 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:40,877 __main__ [INFO ] Evaluated on training set. Loss: 1.59677
2018-02-05 01:16:40,896 __main__ [INFO ] Evaluated on validation set. Loss: 2.56024
2018-02-05 01:16:40,896 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 259 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.03,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:41,049 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:41,675 __main__ [INFO ] Evaluated on training set. Loss: 1.63059
2018-02-05 01:16:41,700 __main__ [INFO ] Evaluated on validation set. Loss: 2.47063
2018-02-05 01:16:41,701 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 260 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.03,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:41,854 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:42,319 __main__ [INFO ] Evaluated on training set. Loss: 1.60428
2018-02-05 01:16:42,337 __main__ [INFO ] Evaluated on validation set. Loss: 2.56206
2018-02-05 01:16:42,337 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 261 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.031,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:42,530 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:43,116 __main__ [INFO ] Evaluated on training set. Loss: 1.63688
2018-02-05 01:16:43,140 __main__ [INFO ] Evaluated on validation set. Loss: 2.47276
2018-02-05 01:16:43,141 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 262 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.031,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:43,299 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:43,772 __main__ [INFO ] Evaluated on training set. Loss: 1.61170
2018-02-05 01:16:43,790 __main__ [INFO ] Evaluated on validation set. Loss: 2.56395
2018-02-05 01:16:43,790 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 263 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.032,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:43,978 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:44,565 __main__ [INFO ] Evaluated on training set. Loss: 1.64309
2018-02-05 01:16:44,589 __main__ [INFO ] Evaluated on validation set. Loss: 2.47496
2018-02-05 01:16:44,590 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 264 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.032,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:44,785 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:45,261 __main__ [INFO ] Evaluated on training set. Loss: 1.61902
2018-02-05 01:16:45,279 __main__ [INFO ] Evaluated on validation set. Loss: 2.56591
2018-02-05 01:16:45,279 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 265 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.033,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:45,440 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:46,031 __main__ [INFO ] Evaluated on training set. Loss: 1.64922
2018-02-05 01:16:46,055 __main__ [INFO ] Evaluated on validation set. Loss: 2.47721
2018-02-05 01:16:46,056 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 266 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.033,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:46,252 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:46,725 __main__ [INFO ] Evaluated on training set. Loss: 1.62624
2018-02-05 01:16:46,743 __main__ [INFO ] Evaluated on validation set. Loss: 2.56793
2018-02-05 01:16:46,744 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 267 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.034,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:46,899 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:47,537 __main__ [INFO ] Evaluated on training set. Loss: 1.65528
2018-02-05 01:16:47,561 __main__ [INFO ] Evaluated on validation set. Loss: 2.47951
2018-02-05 01:16:47,561 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 268 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.034,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:47,717 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:48,194 __main__ [INFO ] Evaluated on training set. Loss: 1.63337
2018-02-05 01:16:48,212 __main__ [INFO ] Evaluated on validation set. Loss: 2.57000
2018-02-05 01:16:48,213 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 269 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.035,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:48,413 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:49,006 __main__ [INFO ] Evaluated on training set. Loss: 1.66125
2018-02-05 01:16:49,031 __main__ [INFO ] Evaluated on validation set. Loss: 2.48185
2018-02-05 01:16:49,031 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 270 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.035,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:49,185 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:49,694 __main__ [INFO ] Evaluated on training set. Loss: 1.64041
2018-02-05 01:16:49,712 __main__ [INFO ] Evaluated on validation set. Loss: 2.57213
2018-02-05 01:16:49,713 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 271 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.036,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:49,867 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:50,451 __main__ [INFO ] Evaluated on training set. Loss: 1.66716
2018-02-05 01:16:50,475 __main__ [INFO ] Evaluated on validation set. Loss: 2.48422
2018-02-05 01:16:50,475 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 272 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.036,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:50,669 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:51,147 __main__ [INFO ] Evaluated on training set. Loss: 1.64736
2018-02-05 01:16:51,165 __main__ [INFO ] Evaluated on validation set. Loss: 2.57429
2018-02-05 01:16:51,165 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 273 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.037,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:51,322 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:51,912 __main__ [INFO ] Evaluated on training set. Loss: 1.67299
2018-02-05 01:16:51,937 __main__ [INFO ] Evaluated on validation set. Loss: 2.48663
2018-02-05 01:16:51,937 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 274 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.037,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:52,125 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:52,605 __main__ [INFO ] Evaluated on training set. Loss: 1.65423
2018-02-05 01:16:52,624 __main__ [INFO ] Evaluated on validation set. Loss: 2.57650
2018-02-05 01:16:52,625 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 275 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.038,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:52,782 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:53,411 __main__ [INFO ] Evaluated on training set. Loss: 1.67876
2018-02-05 01:16:53,436 __main__ [INFO ] Evaluated on validation set. Loss: 2.48907
2018-02-05 01:16:53,436 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 276 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.038,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:53,589 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:54,058 __main__ [INFO ] Evaluated on training set. Loss: 1.66102
2018-02-05 01:16:54,076 __main__ [INFO ] Evaluated on validation set. Loss: 2.57874
2018-02-05 01:16:54,076 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 277 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.039,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:54,270 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:54,868 __main__ [INFO ] Evaluated on training set. Loss: 1.68446
2018-02-05 01:16:54,893 __main__ [INFO ] Evaluated on validation set. Loss: 2.49153
2018-02-05 01:16:54,893 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 278 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.039,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:55,047 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:55,563 __main__ [INFO ] Evaluated on training set. Loss: 1.66773
2018-02-05 01:16:55,581 __main__ [INFO ] Evaluated on validation set. Loss: 2.58101
2018-02-05 01:16:55,581 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 279 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.04,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:55,737 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:56,329 __main__ [INFO ] Evaluated on training set. Loss: 1.69009
2018-02-05 01:16:56,354 __main__ [INFO ] Evaluated on validation set. Loss: 2.49402
2018-02-05 01:16:56,354 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 280 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.04,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:56,549 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:57,026 __main__ [INFO ] Evaluated on training set. Loss: 1.67436
2018-02-05 01:16:57,044 __main__ [INFO ] Evaluated on validation set. Loss: 2.58331
2018-02-05 01:16:57,044 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 281 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.041,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:57,199 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:57,792 __main__ [INFO ] Evaluated on training set. Loss: 1.69566
2018-02-05 01:16:57,817 __main__ [INFO ] Evaluated on validation set. Loss: 2.49653
2018-02-05 01:16:57,817 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 282 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.041,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:58,016 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:58,504 __main__ [INFO ] Evaluated on training set. Loss: 1.68092
2018-02-05 01:16:58,522 __main__ [INFO ] Evaluated on validation set. Loss: 2.58564
2018-02-05 01:16:58,523 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 283 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.042,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:58,678 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:59,315 __main__ [INFO ] Evaluated on training set. Loss: 1.70117
2018-02-05 01:16:59,339 __main__ [INFO ] Evaluated on validation set. Loss: 2.49906
2018-02-05 01:16:59,340 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 284 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.042,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:16:59,496 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:16:59,969 __main__ [INFO ] Evaluated on training set. Loss: 1.68741
2018-02-05 01:16:59,988 __main__ [INFO ] Evaluated on validation set. Loss: 2.58799
2018-02-05 01:16:59,988 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 285 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.043,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:00,188 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:00,786 __main__ [INFO ] Evaluated on training set. Loss: 1.70662
2018-02-05 01:17:00,810 __main__ [INFO ] Evaluated on validation set. Loss: 2.50161
2018-02-05 01:17:00,811 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 286 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.043,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:00,965 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:01,487 __main__ [INFO ] Evaluated on training set. Loss: 1.69382
2018-02-05 01:17:01,505 __main__ [INFO ] Evaluated on validation set. Loss: 2.59036
2018-02-05 01:17:01,505 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 287 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.044,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:01,661 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:02,256 __main__ [INFO ] Evaluated on training set. Loss: 1.71201
2018-02-05 01:17:02,281 __main__ [INFO ] Evaluated on validation set. Loss: 2.50417
2018-02-05 01:17:02,282 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 288 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.044,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:02,481 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:02,965 __main__ [INFO ] Evaluated on training set. Loss: 1.70017
2018-02-05 01:17:02,984 __main__ [INFO ] Evaluated on validation set. Loss: 2.59275
2018-02-05 01:17:02,984 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 289 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.045,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:03,145 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:03,734 __main__ [INFO ] Evaluated on training set. Loss: 1.71735
2018-02-05 01:17:03,761 __main__ [INFO ] Evaluated on validation set. Loss: 2.50675
2018-02-05 01:17:03,761 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 290 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.045,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:03,957 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:04,441 __main__ [INFO ] Evaluated on training set. Loss: 1.70645
2018-02-05 01:17:04,460 __main__ [INFO ] Evaluated on validation set. Loss: 2.59516
2018-02-05 01:17:04,461 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 291 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.046,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:04,661 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:05,254 __main__ [INFO ] Evaluated on training set. Loss: 1.72263
2018-02-05 01:17:05,280 __main__ [INFO ] Evaluated on validation set. Loss: 2.50933
2018-02-05 01:17:05,280 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 292 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.046,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:05,436 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:05,913 __main__ [INFO ] Evaluated on training set. Loss: 1.71266
2018-02-05 01:17:05,932 __main__ [INFO ] Evaluated on validation set. Loss: 2.59758
2018-02-05 01:17:05,932 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 293 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.047,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:06,125 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:06,723 __main__ [INFO ] Evaluated on training set. Loss: 1.72786
2018-02-05 01:17:06,748 __main__ [INFO ] Evaluated on validation set. Loss: 2.51193
2018-02-05 01:17:06,749 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 294 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.047,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:06,905 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:07,431 __main__ [INFO ] Evaluated on training set. Loss: 1.71881
2018-02-05 01:17:07,449 __main__ [INFO ] Evaluated on validation set. Loss: 2.60002
2018-02-05 01:17:07,450 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 295 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.048,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:07,606 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:08,194 __main__ [INFO ] Evaluated on training set. Loss: 1.73304
2018-02-05 01:17:08,219 __main__ [INFO ] Evaluated on validation set. Loss: 2.51453
2018-02-05 01:17:08,220 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 296 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.048,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:08,419 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:08,900 __main__ [INFO ] Evaluated on training set. Loss: 1.72490
2018-02-05 01:17:08,919 __main__ [INFO ] Evaluated on validation set. Loss: 2.60247
2018-02-05 01:17:08,919 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 297 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.049,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:09,076 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:09,715 __main__ [INFO ] Evaluated on training set. Loss: 1.73817
2018-02-05 01:17:09,740 __main__ [INFO ] Evaluated on validation set. Loss: 2.51714
2018-02-05 01:17:09,740 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 298 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.049,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:09,897 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:10,374 __main__ [INFO ] Evaluated on training set. Loss: 1.73093
2018-02-05 01:17:10,393 __main__ [INFO ] Evaluated on validation set. Loss: 2.60493
2018-02-05 01:17:10,393 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 299 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.05,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:10,592 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:11,196 __main__ [INFO ] Evaluated on training set. Loss: 1.74324
2018-02-05 01:17:11,221 __main__ [INFO ] Evaluated on validation set. Loss: 2.51976
2018-02-05 01:17:11,221 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 300 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.05,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:11,378 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:11,854 __main__ [INFO ] Evaluated on training set. Loss: 1.73690
2018-02-05 01:17:11,872 __main__ [INFO ] Evaluated on validation set. Loss: 2.60740
2018-02-05 01:17:11,872 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 301 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.051,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:12,062 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:12,655 __main__ [INFO ] Evaluated on training set. Loss: 1.74827
2018-02-05 01:17:12,680 __main__ [INFO ] Evaluated on validation set. Loss: 2.52238
2018-02-05 01:17:12,680 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 302 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.051,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:12,838 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:13,356 __main__ [INFO ] Evaluated on training set. Loss: 1.74281
2018-02-05 01:17:13,374 __main__ [INFO ] Evaluated on validation set. Loss: 2.60987
2018-02-05 01:17:13,374 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 303 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.052,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:13,531 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:14,120 __main__ [INFO ] Evaluated on training set. Loss: 1.75325
2018-02-05 01:17:14,145 __main__ [INFO ] Evaluated on validation set. Loss: 2.52501
2018-02-05 01:17:14,145 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 304 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.052,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:14,344 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:14,858 __main__ [INFO ] Evaluated on training set. Loss: 1.74866
2018-02-05 01:17:14,877 __main__ [INFO ] Evaluated on validation set. Loss: 2.61235
2018-02-05 01:17:14,877 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 305 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.053,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:15,033 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:15,665 __main__ [INFO ] Evaluated on training set. Loss: 1.75819
2018-02-05 01:17:15,690 __main__ [INFO ] Evaluated on validation set. Loss: 2.52764
2018-02-05 01:17:15,690 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 306 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.053,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:15,848 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:16,315 __main__ [INFO ] Evaluated on training set. Loss: 1.75446
2018-02-05 01:17:16,333 __main__ [INFO ] Evaluated on validation set. Loss: 2.61484
2018-02-05 01:17:16,334 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 307 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.054,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:16,525 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:17,111 __main__ [INFO ] Evaluated on training set. Loss: 1.76308
2018-02-05 01:17:17,136 __main__ [INFO ] Evaluated on validation set. Loss: 2.53027
2018-02-05 01:17:17,137 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 308 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.054,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:17,293 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:17,761 __main__ [INFO ] Evaluated on training set. Loss: 1.76021
2018-02-05 01:17:17,779 __main__ [INFO ] Evaluated on validation set. Loss: 2.61734
2018-02-05 01:17:17,779 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 309 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.055,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:17,968 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:18,553 __main__ [INFO ] Evaluated on training set. Loss: 1.76792
2018-02-05 01:17:18,578 __main__ [INFO ] Evaluated on validation set. Loss: 2.53290
2018-02-05 01:17:18,578 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 310 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.055,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:18,775 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:19,255 __main__ [INFO ] Evaluated on training set. Loss: 1.76590
2018-02-05 01:17:19,274 __main__ [INFO ] Evaluated on validation set. Loss: 2.61983
2018-02-05 01:17:19,274 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 311 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.056,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:19,429 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:20,015 __main__ [INFO ] Evaluated on training set. Loss: 1.77273
2018-02-05 01:17:20,040 __main__ [INFO ] Evaluated on validation set. Loss: 2.53553
2018-02-05 01:17:20,040 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 312 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.056,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:20,235 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:20,707 __main__ [INFO ] Evaluated on training set. Loss: 1.77154
2018-02-05 01:17:20,726 __main__ [INFO ] Evaluated on validation set. Loss: 2.62233
2018-02-05 01:17:20,726 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 313 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.057,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:20,883 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:21,520 __main__ [INFO ] Evaluated on training set. Loss: 1.77749
2018-02-05 01:17:21,545 __main__ [INFO ] Evaluated on validation set. Loss: 2.53817
2018-02-05 01:17:21,545 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 314 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.057,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:21,700 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:22,171 __main__ [INFO ] Evaluated on training set. Loss: 1.77714
2018-02-05 01:17:22,189 __main__ [INFO ] Evaluated on validation set. Loss: 2.62484
2018-02-05 01:17:22,189 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 315 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.058,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:22,382 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:22,976 __main__ [INFO ] Evaluated on training set. Loss: 1.78221
2018-02-05 01:17:23,001 __main__ [INFO ] Evaluated on validation set. Loss: 2.54080
2018-02-05 01:17:23,001 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 316 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.058,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:23,156 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:23,673 __main__ [INFO ] Evaluated on training set. Loss: 1.78268
2018-02-05 01:17:23,690 __main__ [INFO ] Evaluated on validation set. Loss: 2.62734
2018-02-05 01:17:23,691 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 317 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.059,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:23,848 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:24,434 __main__ [INFO ] Evaluated on training set. Loss: 1.78689
2018-02-05 01:17:24,459 __main__ [INFO ] Evaluated on validation set. Loss: 2.54343
2018-02-05 01:17:24,459 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 318 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.059,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:24,654 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:25,132 __main__ [INFO ] Evaluated on training set. Loss: 1.78817
2018-02-05 01:17:25,149 __main__ [INFO ] Evaluated on validation set. Loss: 2.62985
2018-02-05 01:17:25,150 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 319 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.06,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:25,306 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:25,891 __main__ [INFO ] Evaluated on training set. Loss: 1.79153
2018-02-05 01:17:25,915 __main__ [INFO ] Evaluated on validation set. Loss: 2.54606
2018-02-05 01:17:25,916 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 320 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.06,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:26,106 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:26,586 __main__ [INFO ] Evaluated on training set. Loss: 1.79362
2018-02-05 01:17:26,604 __main__ [INFO ] Evaluated on validation set. Loss: 2.63235
2018-02-05 01:17:26,604 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 321 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.061,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:26,762 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:27,394 __main__ [INFO ] Evaluated on training set. Loss: 1.79613
2018-02-05 01:17:27,418 __main__ [INFO ] Evaluated on validation set. Loss: 2.54869
2018-02-05 01:17:27,419 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 322 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.061,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:27,576 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:28,042 __main__ [INFO ] Evaluated on training set. Loss: 1.79902
2018-02-05 01:17:28,061 __main__ [INFO ] Evaluated on validation set. Loss: 2.63486
2018-02-05 01:17:28,061 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 323 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.062,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:28,253 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:28,848 __main__ [INFO ] Evaluated on training set. Loss: 1.80070
2018-02-05 01:17:28,872 __main__ [INFO ] Evaluated on validation set. Loss: 2.55132
2018-02-05 01:17:28,873 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 324 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.062,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:29,026 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:29,539 __main__ [INFO ] Evaluated on training set. Loss: 1.80438
2018-02-05 01:17:29,558 __main__ [INFO ] Evaluated on validation set. Loss: 2.63736
2018-02-05 01:17:29,558 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 325 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.063,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:29,717 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:30,307 __main__ [INFO ] Evaluated on training set. Loss: 1.80522
2018-02-05 01:17:30,332 __main__ [INFO ] Evaluated on validation set. Loss: 2.55394
2018-02-05 01:17:30,332 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 326 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.063,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:30,533 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:31,004 __main__ [INFO ] Evaluated on training set. Loss: 1.80969
2018-02-05 01:17:31,023 __main__ [INFO ] Evaluated on validation set. Loss: 2.63987
2018-02-05 01:17:31,023 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 327 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.064,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:31,181 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:31,764 __main__ [INFO ] Evaluated on training set. Loss: 1.80971
2018-02-05 01:17:31,788 __main__ [INFO ] Evaluated on validation set. Loss: 2.55656
2018-02-05 01:17:31,789 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 328 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.064,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:31,984 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:32,457 __main__ [INFO ] Evaluated on training set. Loss: 1.81496
2018-02-05 01:17:32,475 __main__ [INFO ] Evaluated on validation set. Loss: 2.64237
2018-02-05 01:17:32,476 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 329 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.065,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:32,671 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:33,264 __main__ [INFO ] Evaluated on training set. Loss: 1.81417
2018-02-05 01:17:33,289 __main__ [INFO ] Evaluated on validation set. Loss: 2.55917
2018-02-05 01:17:33,290 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 330 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.065,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:33,453 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:33,924 __main__ [INFO ] Evaluated on training set. Loss: 1.82018
2018-02-05 01:17:33,942 __main__ [INFO ] Evaluated on validation set. Loss: 2.64487
2018-02-05 01:17:33,943 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 331 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.066,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:34,132 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:34,726 __main__ [INFO ] Evaluated on training set. Loss: 1.81859
2018-02-05 01:17:34,751 __main__ [INFO ] Evaluated on validation set. Loss: 2.56179
2018-02-05 01:17:34,751 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 332 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.066,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:34,911 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:35,445 __main__ [INFO ] Evaluated on training set. Loss: 1.82536
2018-02-05 01:17:35,464 __main__ [INFO ] Evaluated on validation set. Loss: 2.64737
2018-02-05 01:17:35,464 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 333 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.067,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:35,619 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:36,206 __main__ [INFO ] Evaluated on training set. Loss: 1.82298
2018-02-05 01:17:36,231 __main__ [INFO ] Evaluated on validation set. Loss: 2.56439
2018-02-05 01:17:36,232 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 334 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.067,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:36,427 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:36,898 __main__ [INFO ] Evaluated on training set. Loss: 1.83051
2018-02-05 01:17:36,916 __main__ [INFO ] Evaluated on validation set. Loss: 2.64987
2018-02-05 01:17:36,917 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 335 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.068,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:37,080 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:37,707 __main__ [INFO ] Evaluated on training set. Loss: 1.82733
2018-02-05 01:17:37,733 __main__ [INFO ] Evaluated on validation set. Loss: 2.56700
2018-02-05 01:17:37,733 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 336 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.068,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:37,887 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:38,354 __main__ [INFO ] Evaluated on training set. Loss: 1.83561
2018-02-05 01:17:38,373 __main__ [INFO ] Evaluated on validation set. Loss: 2.65236
2018-02-05 01:17:38,373 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 337 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.069,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:38,568 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:39,158 __main__ [INFO ] Evaluated on training set. Loss: 1.83165
2018-02-05 01:17:39,183 __main__ [INFO ] Evaluated on validation set. Loss: 2.56959
2018-02-05 01:17:39,183 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 338 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.069,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:39,340 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:39,809 __main__ [INFO ] Evaluated on training set. Loss: 1.84067
2018-02-05 01:17:39,827 __main__ [INFO ] Evaluated on validation set. Loss: 2.65485
2018-02-05 01:17:39,828 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 339 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.07,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:40,021 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:40,625 __main__ [INFO ] Evaluated on training set. Loss: 1.83593
2018-02-05 01:17:40,650 __main__ [INFO ] Evaluated on validation set. Loss: 2.57219
2018-02-05 01:17:40,651 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 340 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.07,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:40,807 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:41,336 __main__ [INFO ] Evaluated on training set. Loss: 1.84569
2018-02-05 01:17:41,356 __main__ [INFO ] Evaluated on validation set. Loss: 2.65733
2018-02-05 01:17:41,356 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 341 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.071,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:41,513 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:42,099 __main__ [INFO ] Evaluated on training set. Loss: 1.84019
2018-02-05 01:17:42,124 __main__ [INFO ] Evaluated on validation set. Loss: 2.57477
2018-02-05 01:17:42,124 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 342 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.071,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:42,324 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:42,802 __main__ [INFO ] Evaluated on training set. Loss: 1.85068
2018-02-05 01:17:42,820 __main__ [INFO ] Evaluated on validation set. Loss: 2.65982
2018-02-05 01:17:42,821 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 343 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.072,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:42,976 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:43,612 __main__ [INFO ] Evaluated on training set. Loss: 1.84441
2018-02-05 01:17:43,636 __main__ [INFO ] Evaluated on validation set. Loss: 2.57736
2018-02-05 01:17:43,637 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 344 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.072,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:43,794 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:44,271 __main__ [INFO ] Evaluated on training set. Loss: 1.85562
2018-02-05 01:17:44,289 __main__ [INFO ] Evaluated on validation set. Loss: 2.66229
2018-02-05 01:17:44,289 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 345 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.073,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:44,483 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:45,078 __main__ [INFO ] Evaluated on training set. Loss: 1.84861
2018-02-05 01:17:45,103 __main__ [INFO ] Evaluated on validation set. Loss: 2.57993
2018-02-05 01:17:45,104 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 346 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.073,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:45,261 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:45,726 __main__ [INFO ] Evaluated on training set. Loss: 1.86053
2018-02-05 01:17:45,744 __main__ [INFO ] Evaluated on validation set. Loss: 2.66477
2018-02-05 01:17:45,745 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 347 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.074,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:45,934 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:46,518 __main__ [INFO ] Evaluated on training set. Loss: 1.85277
2018-02-05 01:17:46,543 __main__ [INFO ] Evaluated on validation set. Loss: 2.58250
2018-02-05 01:17:46,543 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 348 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.074,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:46,701 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:47,219 __main__ [INFO ] Evaluated on training set. Loss: 1.86541
2018-02-05 01:17:47,237 __main__ [INFO ] Evaluated on validation set. Loss: 2.66724
2018-02-05 01:17:47,238 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 349 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.075,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:47,394 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:47,980 __main__ [INFO ] Evaluated on training set. Loss: 1.85690
2018-02-05 01:17:48,005 __main__ [INFO ] Evaluated on validation set. Loss: 2.58507
2018-02-05 01:17:48,005 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 350 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.075,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:48,197 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:48,669 __main__ [INFO ] Evaluated on training set. Loss: 1.87025
2018-02-05 01:17:48,688 __main__ [INFO ] Evaluated on validation set. Loss: 2.66970
2018-02-05 01:17:48,688 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 351 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.076,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:48,844 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:49,470 __main__ [INFO ] Evaluated on training set. Loss: 1.86101
2018-02-05 01:17:49,495 __main__ [INFO ] Evaluated on validation set. Loss: 2.58763
2018-02-05 01:17:49,495 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 352 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.076,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:49,650 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:50,124 __main__ [INFO ] Evaluated on training set. Loss: 1.87505
2018-02-05 01:17:50,143 __main__ [INFO ] Evaluated on validation set. Loss: 2.67216
2018-02-05 01:17:50,143 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 353 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.077,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:50,339 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:50,931 __main__ [INFO ] Evaluated on training set. Loss: 1.86508
2018-02-05 01:17:50,955 __main__ [INFO ] Evaluated on validation set. Loss: 2.59018
2018-02-05 01:17:50,955 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 354 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.077,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:51,113 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:51,576 __main__ [INFO ] Evaluated on training set. Loss: 1.87982
2018-02-05 01:17:51,595 __main__ [INFO ] Evaluated on validation set. Loss: 2.67462
2018-02-05 01:17:51,596 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 355 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.078,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:51,790 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:52,377 __main__ [INFO ] Evaluated on training set. Loss: 1.86913
2018-02-05 01:17:52,402 __main__ [INFO ] Evaluated on validation set. Loss: 2.59272
2018-02-05 01:17:52,403 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 356 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.078,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:52,599 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:53,076 __main__ [INFO ] Evaluated on training set. Loss: 1.88456
2018-02-05 01:17:53,095 __main__ [INFO ] Evaluated on validation set. Loss: 2.67706
2018-02-05 01:17:53,095 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 357 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.079,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:53,254 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:53,836 __main__ [INFO ] Evaluated on training set. Loss: 1.87315
2018-02-05 01:17:53,860 __main__ [INFO ] Evaluated on validation set. Loss: 2.59526
2018-02-05 01:17:53,861 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 358 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.079,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:54,051 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:54,527 __main__ [INFO ] Evaluated on training set. Loss: 1.88926
2018-02-05 01:17:54,545 __main__ [INFO ] Evaluated on validation set. Loss: 2.67951
2018-02-05 01:17:54,546 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 359 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.08,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:54,700 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:55,328 __main__ [INFO ] Evaluated on training set. Loss: 1.87714
2018-02-05 01:17:55,353 __main__ [INFO ] Evaluated on validation set. Loss: 2.59780
2018-02-05 01:17:55,353 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 360 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.08,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:55,509 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:55,986 __main__ [INFO ] Evaluated on training set. Loss: 1.89393
2018-02-05 01:17:56,004 __main__ [INFO ] Evaluated on validation set. Loss: 2.68195
2018-02-05 01:17:56,004 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 361 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.081,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:56,195 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:56,794 __main__ [INFO ] Evaluated on training set. Loss: 1.88111
2018-02-05 01:17:56,819 __main__ [INFO ] Evaluated on validation set. Loss: 2.60032
2018-02-05 01:17:56,819 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 362 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.081,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:56,975 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:57,493 __main__ [INFO ] Evaluated on training set. Loss: 1.89856
2018-02-05 01:17:57,511 __main__ [INFO ] Evaluated on validation set. Loss: 2.68438
2018-02-05 01:17:57,511 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 363 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.082,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:57,668 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:58,262 __main__ [INFO ] Evaluated on training set. Loss: 1.88505
2018-02-05 01:17:58,286 __main__ [INFO ] Evaluated on validation set. Loss: 2.60284
2018-02-05 01:17:58,287 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 364 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.082,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:58,481 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:58,958 __main__ [INFO ] Evaluated on training set. Loss: 1.90317
2018-02-05 01:17:58,976 __main__ [INFO ] Evaluated on validation set. Loss: 2.68681
2018-02-05 01:17:58,976 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 365 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.083,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:59,131 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:17:59,721 __main__ [INFO ] Evaluated on training set. Loss: 1.88896
2018-02-05 01:17:59,745 __main__ [INFO ] Evaluated on validation set. Loss: 2.60535
2018-02-05 01:17:59,746 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 366 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.083,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:17:59,937 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:00,416 __main__ [INFO ] Evaluated on training set. Loss: 1.90774
2018-02-05 01:18:00,434 __main__ [INFO ] Evaluated on validation set. Loss: 2.68923
2018-02-05 01:18:00,434 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 367 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.084,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:00,589 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:01,221 __main__ [INFO ] Evaluated on training set. Loss: 1.89285
2018-02-05 01:18:01,246 __main__ [INFO ] Evaluated on validation set. Loss: 2.60786
2018-02-05 01:18:01,246 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 368 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.084,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:01,402 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:01,874 __main__ [INFO ] Evaluated on training set. Loss: 1.91229
2018-02-05 01:18:01,893 __main__ [INFO ] Evaluated on validation set. Loss: 2.69164
2018-02-05 01:18:01,893 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 369 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.085,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:02,086 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:02,676 __main__ [INFO ] Evaluated on training set. Loss: 1.89671
2018-02-05 01:18:02,701 __main__ [INFO ] Evaluated on validation set. Loss: 2.61035
2018-02-05 01:18:02,701 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 370 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.085,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:02,857 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:03,372 __main__ [INFO ] Evaluated on training set. Loss: 1.91680
2018-02-05 01:18:03,390 __main__ [INFO ] Evaluated on validation set. Loss: 2.69405
2018-02-05 01:18:03,391 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 371 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.086,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:03,546 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:04,130 __main__ [INFO ] Evaluated on training set. Loss: 1.90055
2018-02-05 01:18:04,155 __main__ [INFO ] Evaluated on validation set. Loss: 2.61285
2018-02-05 01:18:04,155 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 372 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.086,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:04,351 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:04,827 __main__ [INFO ] Evaluated on training set. Loss: 1.92129
2018-02-05 01:18:04,846 __main__ [INFO ] Evaluated on validation set. Loss: 2.69646
2018-02-05 01:18:04,846 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 373 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.087,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:05,001 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:05,593 __main__ [INFO ] Evaluated on training set. Loss: 1.90436
2018-02-05 01:18:05,618 __main__ [INFO ] Evaluated on validation set. Loss: 2.61533
2018-02-05 01:18:05,618 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 374 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.087,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:05,810 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:06,282 __main__ [INFO ] Evaluated on training set. Loss: 1.92574
2018-02-05 01:18:06,300 __main__ [INFO ] Evaluated on validation set. Loss: 2.69885
2018-02-05 01:18:06,301 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 375 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.088,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:06,496 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:07,085 __main__ [INFO ] Evaluated on training set. Loss: 1.90815
2018-02-05 01:18:07,109 __main__ [INFO ] Evaluated on validation set. Loss: 2.61781
2018-02-05 01:18:07,110 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 376 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.088,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:07,268 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:07,737 __main__ [INFO ] Evaluated on training set. Loss: 1.93017
2018-02-05 01:18:07,755 __main__ [INFO ] Evaluated on validation set. Loss: 2.70124
2018-02-05 01:18:07,755 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 377 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.089,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:07,947 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:08,536 __main__ [INFO ] Evaluated on training set. Loss: 1.91192
2018-02-05 01:18:08,561 __main__ [INFO ] Evaluated on validation set. Loss: 2.62028
2018-02-05 01:18:08,561 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 378 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.089,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:08,716 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:09,222 __main__ [INFO ] Evaluated on training set. Loss: 1.93456
2018-02-05 01:18:09,240 __main__ [INFO ] Evaluated on validation set. Loss: 2.70363
2018-02-05 01:18:09,241 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 379 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.09,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:09,399 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:09,984 __main__ [INFO ] Evaluated on training set. Loss: 1.91566
2018-02-05 01:18:10,009 __main__ [INFO ] Evaluated on validation set. Loss: 2.62274
2018-02-05 01:18:10,009 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 380 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.09,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:10,203 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:10,676 __main__ [INFO ] Evaluated on training set. Loss: 1.93893
2018-02-05 01:18:10,694 __main__ [INFO ] Evaluated on validation set. Loss: 2.70601
2018-02-05 01:18:10,694 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 381 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.091,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:10,851 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:11,483 __main__ [INFO ] Evaluated on training set. Loss: 1.91938
2018-02-05 01:18:11,508 __main__ [INFO ] Evaluated on validation set. Loss: 2.62519
2018-02-05 01:18:11,508 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 382 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.091,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:11,663 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:12,133 __main__ [INFO ] Evaluated on training set. Loss: 1.94327
2018-02-05 01:18:12,150 __main__ [INFO ] Evaluated on validation set. Loss: 2.70838
2018-02-05 01:18:12,151 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 383 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.092,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:12,350 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:12,948 __main__ [INFO ] Evaluated on training set. Loss: 1.92308
2018-02-05 01:18:12,973 __main__ [INFO ] Evaluated on validation set. Loss: 2.62764
2018-02-05 01:18:12,973 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 384 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.092,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:13,130 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:13,600 __main__ [INFO ] Evaluated on training set. Loss: 1.94759
2018-02-05 01:18:13,618 __main__ [INFO ] Evaluated on validation set. Loss: 2.71074
2018-02-05 01:18:13,618 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 385 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.093,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:13,811 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:14,402 __main__ [INFO ] Evaluated on training set. Loss: 1.92675
2018-02-05 01:18:14,427 __main__ [INFO ] Evaluated on validation set. Loss: 2.63008
2018-02-05 01:18:14,427 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 386 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.093,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:14,581 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:15,094 __main__ [INFO ] Evaluated on training set. Loss: 1.95188
2018-02-05 01:18:15,112 __main__ [INFO ] Evaluated on validation set. Loss: 2.71310
2018-02-05 01:18:15,112 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 387 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.094,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:15,269 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:15,855 __main__ [INFO ] Evaluated on training set. Loss: 1.93041
2018-02-05 01:18:15,880 __main__ [INFO ] Evaluated on validation set. Loss: 2.63251
2018-02-05 01:18:15,881 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 388 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.094,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:16,074 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:16,545 __main__ [INFO ] Evaluated on training set. Loss: 1.95614
2018-02-05 01:18:16,564 __main__ [INFO ] Evaluated on validation set. Loss: 2.71546
2018-02-05 01:18:16,565 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 389 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.095,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:16,720 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:17,373 __main__ [INFO ] Evaluated on training set. Loss: 1.93404
2018-02-05 01:18:17,398 __main__ [INFO ] Evaluated on validation set. Loss: 2.63494
2018-02-05 01:18:17,398 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 390 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.095,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:17,552 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:18,037 __main__ [INFO ] Evaluated on training set. Loss: 1.96037
2018-02-05 01:18:18,055 __main__ [INFO ] Evaluated on validation set. Loss: 2.71780
2018-02-05 01:18:18,055 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 391 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.096,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:18,251 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:18,858 __main__ [INFO ] Evaluated on training set. Loss: 1.93765
2018-02-05 01:18:18,882 __main__ [INFO ] Evaluated on validation set. Loss: 2.63736
2018-02-05 01:18:18,882 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 392 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.096,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:19,039 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:19,510 __main__ [INFO ] Evaluated on training set. Loss: 1.96458
2018-02-05 01:18:19,529 __main__ [INFO ] Evaluated on validation set. Loss: 2.72014
2018-02-05 01:18:19,529 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 393 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.097,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:19,721 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:20,315 __main__ [INFO ] Evaluated on training set. Loss: 1.94124
2018-02-05 01:18:20,340 __main__ [INFO ] Evaluated on validation set. Loss: 2.63977
2018-02-05 01:18:20,340 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 394 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.097,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:20,538 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:21,014 __main__ [INFO ] Evaluated on training set. Loss: 1.96876
2018-02-05 01:18:21,032 __main__ [INFO ] Evaluated on validation set. Loss: 2.72247
2018-02-05 01:18:21,033 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 395 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.098,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:21,190 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:21,774 __main__ [INFO ] Evaluated on training set. Loss: 1.94480
2018-02-05 01:18:21,799 __main__ [INFO ] Evaluated on validation set. Loss: 2.64217
2018-02-05 01:18:21,799 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 396 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.098,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:21,995 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:22,469 __main__ [INFO ] Evaluated on training set. Loss: 1.97292
2018-02-05 01:18:22,487 __main__ [INFO ] Evaluated on validation set. Loss: 2.72480
2018-02-05 01:18:22,488 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 397 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.099,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:22,644 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:23,278 __main__ [INFO ] Evaluated on training set. Loss: 1.94835
2018-02-05 01:18:23,303 __main__ [INFO ] Evaluated on validation set. Loss: 2.64457
2018-02-05 01:18:23,303 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 398 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.099,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:23,459 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:23,932 __main__ [INFO ] Evaluated on training set. Loss: 1.97706
2018-02-05 01:18:23,950 __main__ [INFO ] Evaluated on validation set. Loss: 2.72712
2018-02-05 01:18:23,951 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 399 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:24,146 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:24,740 __main__ [INFO ] Evaluated on training set. Loss: 1.95188
2018-02-05 01:18:24,764 __main__ [INFO ] Evaluated on validation set. Loss: 2.64696
2018-02-05 01:18:24,765 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 400 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:18:24,921 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:18:25,439 __main__ [INFO ] Evaluated on training set. Loss: 1.98117
2018-02-05 01:18:25,457 __main__ [INFO ] Evaluated on validation set. Loss: 2.72943
2018-02-05 01:21:42,422 __main__ [INFO ] 
==============================
Starting experiment alice_n_gram_delta
==============================
2018-02-05 01:21:42,426 __main__ [INFO ] Removing old results directory ./experiments/alice_n_gram_delta/out
2018-02-05 01:21:42,427 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:42,566 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:43,046 __main__ [INFO ] Evaluated on training set. Loss: 1.83746
2018-02-05 01:21:43,071 __main__ [INFO ] Evaluated on validation set. Loss: 2.42074
2018-02-05 01:21:43,071 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:43,206 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:43,558 __main__ [INFO ] Evaluated on training set. Loss: 1.78918
2018-02-05 01:21:43,575 __main__ [INFO ] Evaluated on validation set. Loss: 2.52118
2018-02-05 01:21:43,576 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.002,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:43,742 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:44,215 __main__ [INFO ] Evaluated on training set. Loss: 1.84152
2018-02-05 01:21:44,240 __main__ [INFO ] Evaluated on validation set. Loss: 2.37778
2018-02-05 01:21:44,240 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.002,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:44,379 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:44,734 __main__ [INFO ] Evaluated on training set. Loss: 1.79415
2018-02-05 01:21:44,751 __main__ [INFO ] Evaluated on validation set. Loss: 2.47183
2018-02-05 01:21:44,751 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.003,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:44,890 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:45,388 __main__ [INFO ] Evaluated on training set. Loss: 1.84546
2018-02-05 01:21:45,413 __main__ [INFO ] Evaluated on validation set. Loss: 2.35458
2018-02-05 01:21:45,413 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.003,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:45,571 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:45,930 __main__ [INFO ] Evaluated on training set. Loss: 1.79897
2018-02-05 01:21:45,947 __main__ [INFO ] Evaluated on validation set. Loss: 2.44492
2018-02-05 01:21:45,947 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.004,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:46,081 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:46,557 __main__ [INFO ] Evaluated on training set. Loss: 1.84929
2018-02-05 01:21:46,581 __main__ [INFO ] Evaluated on validation set. Loss: 2.33940
2018-02-05 01:21:46,581 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.004,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:46,745 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:47,093 __main__ [INFO ] Evaluated on training set. Loss: 1.80367
2018-02-05 01:21:47,110 __main__ [INFO ] Evaluated on validation set. Loss: 2.42713
2018-02-05 01:21:47,110 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.005,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:47,243 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:47,715 __main__ [INFO ] Evaluated on training set. Loss: 1.85302
2018-02-05 01:21:47,738 __main__ [INFO ] Evaluated on validation set. Loss: 2.32857
2018-02-05 01:21:47,739 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.005,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:47,873 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:48,224 __main__ [INFO ] Evaluated on training set. Loss: 1.80826
2018-02-05 01:21:48,241 __main__ [INFO ] Evaluated on validation set. Loss: 2.41429
2018-02-05 01:21:48,241 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.006,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:48,374 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:48,844 __main__ [INFO ] Evaluated on training set. Loss: 1.85665
2018-02-05 01:21:48,868 __main__ [INFO ] Evaluated on validation set. Loss: 2.32046
2018-02-05 01:21:48,868 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.006,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:49,034 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:49,385 __main__ [INFO ] Evaluated on training set. Loss: 1.81273
2018-02-05 01:21:49,402 __main__ [INFO ] Evaluated on validation set. Loss: 2.40454
2018-02-05 01:21:49,402 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.007,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:49,534 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:50,005 __main__ [INFO ] Evaluated on training set. Loss: 1.86020
2018-02-05 01:21:50,029 __main__ [INFO ] Evaluated on validation set. Loss: 2.31419
2018-02-05 01:21:50,029 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.007,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:50,162 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:50,514 __main__ [INFO ] Evaluated on training set. Loss: 1.81711
2018-02-05 01:21:50,530 __main__ [INFO ] Evaluated on validation set. Loss: 2.39690
2018-02-05 01:21:50,531 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.008,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:50,663 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:51,140 __main__ [INFO ] Evaluated on training set. Loss: 1.86367
2018-02-05 01:21:51,164 __main__ [INFO ] Evaluated on validation set. Loss: 2.30926
2018-02-05 01:21:51,164 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.008,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:51,296 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:51,646 __main__ [INFO ] Evaluated on training set. Loss: 1.82139
2018-02-05 01:21:51,662 __main__ [INFO ] Evaluated on validation set. Loss: 2.39079
2018-02-05 01:21:51,663 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.009,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:51,827 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:52,305 __main__ [INFO ] Evaluated on training set. Loss: 1.86706
2018-02-05 01:21:52,328 __main__ [INFO ] Evaluated on validation set. Loss: 2.30533
2018-02-05 01:21:52,329 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.009,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:52,461 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:52,815 __main__ [INFO ] Evaluated on training set. Loss: 1.82559
2018-02-05 01:21:52,832 __main__ [INFO ] Evaluated on validation set. Loss: 2.38583
2018-02-05 01:21:52,832 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:52,965 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:53,441 __main__ [INFO ] Evaluated on training set. Loss: 1.87039
2018-02-05 01:21:53,465 __main__ [INFO ] Evaluated on validation set. Loss: 2.30218
2018-02-05 01:21:53,465 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:53,598 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:53,950 __main__ [INFO ] Evaluated on training set. Loss: 1.82971
2018-02-05 01:21:53,967 __main__ [INFO ] Evaluated on validation set. Loss: 2.38176
2018-02-05 01:21:53,967 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 21 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.011,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:54,132 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:54,607 __main__ [INFO ] Evaluated on training set. Loss: 1.87365
2018-02-05 01:21:54,631 __main__ [INFO ] Evaluated on validation set. Loss: 2.29965
2018-02-05 01:21:54,631 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 22 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.011,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:54,767 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:55,117 __main__ [INFO ] Evaluated on training set. Loss: 1.83375
2018-02-05 01:21:55,134 __main__ [INFO ] Evaluated on validation set. Loss: 2.37841
2018-02-05 01:21:55,134 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 23 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.012,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:55,268 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:55,741 __main__ [INFO ] Evaluated on training set. Loss: 1.87686
2018-02-05 01:21:55,764 __main__ [INFO ] Evaluated on validation set. Loss: 2.29762
2018-02-05 01:21:55,765 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 24 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.012,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:55,900 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:56,252 __main__ [INFO ] Evaluated on training set. Loss: 1.83772
2018-02-05 01:21:56,269 __main__ [INFO ] Evaluated on validation set. Loss: 2.37563
2018-02-05 01:21:56,269 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 25 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.013,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:56,403 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:56,872 __main__ [INFO ] Evaluated on training set. Loss: 1.88000
2018-02-05 01:21:56,896 __main__ [INFO ] Evaluated on validation set. Loss: 2.29600
2018-02-05 01:21:56,896 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 26 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.013,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:57,059 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:57,415 __main__ [INFO ] Evaluated on training set. Loss: 1.84162
2018-02-05 01:21:57,432 __main__ [INFO ] Evaluated on validation set. Loss: 2.37333
2018-02-05 01:21:57,433 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 27 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.014,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:57,567 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:58,046 __main__ [INFO ] Evaluated on training set. Loss: 1.88310
2018-02-05 01:21:58,069 __main__ [INFO ] Evaluated on validation set. Loss: 2.29474
2018-02-05 01:21:58,070 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 28 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.014,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:58,202 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:58,559 __main__ [INFO ] Evaluated on training set. Loss: 1.84546
2018-02-05 01:21:58,576 __main__ [INFO ] Evaluated on validation set. Loss: 2.37143
2018-02-05 01:21:58,576 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 29 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.015,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:58,709 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:59,182 __main__ [INFO ] Evaluated on training set. Loss: 1.88614
2018-02-05 01:21:59,206 __main__ [INFO ] Evaluated on validation set. Loss: 2.29376
2018-02-05 01:21:59,206 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 30 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.015,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:59,371 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:21:59,720 __main__ [INFO ] Evaluated on training set. Loss: 1.84924
2018-02-05 01:21:59,737 __main__ [INFO ] Evaluated on validation set. Loss: 2.36988
2018-02-05 01:21:59,737 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 31 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.016,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:21:59,869 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:00,343 __main__ [INFO ] Evaluated on training set. Loss: 1.88914
2018-02-05 01:22:00,367 __main__ [INFO ] Evaluated on validation set. Loss: 2.29304
2018-02-05 01:22:00,367 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 32 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.016,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:00,501 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:00,848 __main__ [INFO ] Evaluated on training set. Loss: 1.85296
2018-02-05 01:22:00,865 __main__ [INFO ] Evaluated on validation set. Loss: 2.36861
2018-02-05 01:22:00,865 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 33 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.017,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:01,001 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:01,471 __main__ [INFO ] Evaluated on training set. Loss: 1.89209
2018-02-05 01:22:01,495 __main__ [INFO ] Evaluated on validation set. Loss: 2.29253
2018-02-05 01:22:01,495 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 34 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.017,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:01,628 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:01,979 __main__ [INFO ] Evaluated on training set. Loss: 1.85663
2018-02-05 01:22:01,996 __main__ [INFO ] Evaluated on validation set. Loss: 2.36760
2018-02-05 01:22:01,997 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 35 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.018,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:02,159 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:02,630 __main__ [INFO ] Evaluated on training set. Loss: 1.89500
2018-02-05 01:22:02,654 __main__ [INFO ] Evaluated on validation set. Loss: 2.29221
2018-02-05 01:22:02,654 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 36 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.018,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:02,787 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:03,134 __main__ [INFO ] Evaluated on training set. Loss: 1.86024
2018-02-05 01:22:03,151 __main__ [INFO ] Evaluated on validation set. Loss: 2.36681
2018-02-05 01:22:03,151 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 37 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.019,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:03,285 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:03,760 __main__ [INFO ] Evaluated on training set. Loss: 1.89787
2018-02-05 01:22:03,783 __main__ [INFO ] Evaluated on validation set. Loss: 2.29206
2018-02-05 01:22:03,784 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 38 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.019,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:03,918 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:04,270 __main__ [INFO ] Evaluated on training set. Loss: 1.86381
2018-02-05 01:22:04,287 __main__ [INFO ] Evaluated on validation set. Loss: 2.36621
2018-02-05 01:22:04,287 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 39 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.02,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:04,454 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:04,921 __main__ [INFO ] Evaluated on training set. Loss: 1.90070
2018-02-05 01:22:04,945 __main__ [INFO ] Evaluated on validation set. Loss: 2.29204
2018-02-05 01:22:04,945 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 40 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.02,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:05,076 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:05,427 __main__ [INFO ] Evaluated on training set. Loss: 1.86732
2018-02-05 01:22:05,444 __main__ [INFO ] Evaluated on validation set. Loss: 2.36578
2018-02-05 01:22:05,444 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 41 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.021,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:05,577 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:06,046 __main__ [INFO ] Evaluated on training set. Loss: 1.90349
2018-02-05 01:22:06,069 __main__ [INFO ] Evaluated on validation set. Loss: 2.29216
2018-02-05 01:22:06,069 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 42 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.021,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:06,201 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:06,553 __main__ [INFO ] Evaluated on training set. Loss: 1.87080
2018-02-05 01:22:06,570 __main__ [INFO ] Evaluated on validation set. Loss: 2.36550
2018-02-05 01:22:06,570 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 43 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.022,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:06,702 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:07,170 __main__ [INFO ] Evaluated on training set. Loss: 1.90624
2018-02-05 01:22:07,195 __main__ [INFO ] Evaluated on validation set. Loss: 2.29239
2018-02-05 01:22:07,195 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 44 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.022,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:07,357 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:07,707 __main__ [INFO ] Evaluated on training set. Loss: 1.87422
2018-02-05 01:22:07,725 __main__ [INFO ] Evaluated on validation set. Loss: 2.36535
2018-02-05 01:22:07,725 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 45 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.023,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:07,859 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:08,325 __main__ [INFO ] Evaluated on training set. Loss: 1.90897
2018-02-05 01:22:08,349 __main__ [INFO ] Evaluated on validation set. Loss: 2.29272
2018-02-05 01:22:08,349 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 46 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.023,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:08,483 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:08,829 __main__ [INFO ] Evaluated on training set. Loss: 1.87761
2018-02-05 01:22:08,846 __main__ [INFO ] Evaluated on validation set. Loss: 2.36532
2018-02-05 01:22:08,846 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 47 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.024,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:08,980 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:09,455 __main__ [INFO ] Evaluated on training set. Loss: 1.91165
2018-02-05 01:22:09,478 __main__ [INFO ] Evaluated on validation set. Loss: 2.29314
2018-02-05 01:22:09,478 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 48 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.024,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:09,643 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:09,993 __main__ [INFO ] Evaluated on training set. Loss: 1.88096
2018-02-05 01:22:10,010 __main__ [INFO ] Evaluated on validation set. Loss: 2.36540
2018-02-05 01:22:10,010 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 49 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.025,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:10,142 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:10,616 __main__ [INFO ] Evaluated on training set. Loss: 1.91431
2018-02-05 01:22:10,640 __main__ [INFO ] Evaluated on validation set. Loss: 2.29364
2018-02-05 01:22:10,640 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 50 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.025,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:10,773 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:11,119 __main__ [INFO ] Evaluated on training set. Loss: 1.88426
2018-02-05 01:22:11,136 __main__ [INFO ] Evaluated on validation set. Loss: 2.36558
2018-02-05 01:22:11,136 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 51 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.026,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:11,270 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:11,737 __main__ [INFO ] Evaluated on training set. Loss: 1.91694
2018-02-05 01:22:11,761 __main__ [INFO ] Evaluated on validation set. Loss: 2.29422
2018-02-05 01:22:11,762 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 52 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.026,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:11,897 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:12,247 __main__ [INFO ] Evaluated on training set. Loss: 1.88753
2018-02-05 01:22:12,264 __main__ [INFO ] Evaluated on validation set. Loss: 2.36584
2018-02-05 01:22:12,264 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 53 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.027,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:12,426 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:12,895 __main__ [INFO ] Evaluated on training set. Loss: 1.91953
2018-02-05 01:22:12,919 __main__ [INFO ] Evaluated on validation set. Loss: 2.29486
2018-02-05 01:22:12,919 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 54 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.027,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:13,052 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:13,401 __main__ [INFO ] Evaluated on training set. Loss: 1.89077
2018-02-05 01:22:13,418 __main__ [INFO ] Evaluated on validation set. Loss: 2.36618
2018-02-05 01:22:13,418 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 55 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.028,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:13,551 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:14,024 __main__ [INFO ] Evaluated on training set. Loss: 1.92210
2018-02-05 01:22:14,047 __main__ [INFO ] Evaluated on validation set. Loss: 2.29556
2018-02-05 01:22:14,048 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 56 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.028,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:14,180 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:14,528 __main__ [INFO ] Evaluated on training set. Loss: 1.89397
2018-02-05 01:22:14,545 __main__ [INFO ] Evaluated on validation set. Loss: 2.36660
2018-02-05 01:22:14,545 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 57 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.029,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:14,710 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:15,184 __main__ [INFO ] Evaluated on training set. Loss: 1.92464
2018-02-05 01:22:15,207 __main__ [INFO ] Evaluated on validation set. Loss: 2.29631
2018-02-05 01:22:15,207 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 58 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.029,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:15,340 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:15,689 __main__ [INFO ] Evaluated on training set. Loss: 1.89713
2018-02-05 01:22:15,706 __main__ [INFO ] Evaluated on validation set. Loss: 2.36708
2018-02-05 01:22:15,706 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 59 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.03,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:15,839 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:16,305 __main__ [INFO ] Evaluated on training set. Loss: 1.92716
2018-02-05 01:22:16,328 __main__ [INFO ] Evaluated on validation set. Loss: 2.29712
2018-02-05 01:22:16,329 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 60 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.03,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:16,463 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:16,807 __main__ [INFO ] Evaluated on training set. Loss: 1.90026
2018-02-05 01:22:16,824 __main__ [INFO ] Evaluated on validation set. Loss: 2.36762
2018-02-05 01:22:16,824 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 61 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.031,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:16,960 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:17,427 __main__ [INFO ] Evaluated on training set. Loss: 1.92964
2018-02-05 01:22:17,451 __main__ [INFO ] Evaluated on validation set. Loss: 2.29797
2018-02-05 01:22:17,451 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 62 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.031,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:17,614 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:17,965 __main__ [INFO ] Evaluated on training set. Loss: 1.90336
2018-02-05 01:22:17,982 __main__ [INFO ] Evaluated on validation set. Loss: 2.36822
2018-02-05 01:22:17,982 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 63 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.032,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:18,114 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:18,587 __main__ [INFO ] Evaluated on training set. Loss: 1.93211
2018-02-05 01:22:18,611 __main__ [INFO ] Evaluated on validation set. Loss: 2.29886
2018-02-05 01:22:18,611 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 64 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.032,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:18,743 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:19,091 __main__ [INFO ] Evaluated on training set. Loss: 1.90643
2018-02-05 01:22:19,107 __main__ [INFO ] Evaluated on validation set. Loss: 2.36886
2018-02-05 01:22:19,108 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 65 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.033,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:19,239 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:19,710 __main__ [INFO ] Evaluated on training set. Loss: 1.93455
2018-02-05 01:22:19,733 __main__ [INFO ] Evaluated on validation set. Loss: 2.29978
2018-02-05 01:22:19,733 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 66 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.033,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:19,898 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:20,254 __main__ [INFO ] Evaluated on training set. Loss: 1.90947
2018-02-05 01:22:20,271 __main__ [INFO ] Evaluated on validation set. Loss: 2.36955
2018-02-05 01:22:20,272 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 67 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.034,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:20,408 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:20,878 __main__ [INFO ] Evaluated on training set. Loss: 1.93697
2018-02-05 01:22:20,902 __main__ [INFO ] Evaluated on validation set. Loss: 2.30075
2018-02-05 01:22:20,902 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 68 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.034,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:21,037 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:21,383 __main__ [INFO ] Evaluated on training set. Loss: 1.91248
2018-02-05 01:22:21,400 __main__ [INFO ] Evaluated on validation set. Loss: 2.37029
2018-02-05 01:22:21,401 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 69 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.035,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:21,534 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:22,005 __main__ [INFO ] Evaluated on training set. Loss: 1.93936
2018-02-05 01:22:22,029 __main__ [INFO ] Evaluated on validation set. Loss: 2.30174
2018-02-05 01:22:22,029 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 70 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.035,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:22,161 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:22,511 __main__ [INFO ] Evaluated on training set. Loss: 1.91546
2018-02-05 01:22:22,529 __main__ [INFO ] Evaluated on validation set. Loss: 2.37106
2018-02-05 01:22:22,529 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 71 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.036,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:22,692 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:23,170 __main__ [INFO ] Evaluated on training set. Loss: 1.94173
2018-02-05 01:22:23,194 __main__ [INFO ] Evaluated on validation set. Loss: 2.30276
2018-02-05 01:22:23,194 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 72 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.036,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:23,326 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:23,671 __main__ [INFO ] Evaluated on training set. Loss: 1.91842
2018-02-05 01:22:23,688 __main__ [INFO ] Evaluated on validation set. Loss: 2.37187
2018-02-05 01:22:23,688 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 73 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.037,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:23,828 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:24,302 __main__ [INFO ] Evaluated on training set. Loss: 1.94408
2018-02-05 01:22:24,326 __main__ [INFO ] Evaluated on validation set. Loss: 2.30381
2018-02-05 01:22:24,326 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 74 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.037,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:24,459 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:24,807 __main__ [INFO ] Evaluated on training set. Loss: 1.92135
2018-02-05 01:22:24,824 __main__ [INFO ] Evaluated on validation set. Loss: 2.37272
2018-02-05 01:22:24,824 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 75 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.038,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:24,989 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:25,457 __main__ [INFO ] Evaluated on training set. Loss: 1.94641
2018-02-05 01:22:25,482 __main__ [INFO ] Evaluated on validation set. Loss: 2.30489
2018-02-05 01:22:25,482 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 76 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.038,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:25,614 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:25,962 __main__ [INFO ] Evaluated on training set. Loss: 1.92425
2018-02-05 01:22:25,978 __main__ [INFO ] Evaluated on validation set. Loss: 2.37359
2018-02-05 01:22:25,978 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 77 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.039,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:26,111 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:26,585 __main__ [INFO ] Evaluated on training set. Loss: 1.94872
2018-02-05 01:22:26,608 __main__ [INFO ] Evaluated on validation set. Loss: 2.30599
2018-02-05 01:22:26,609 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 78 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.039,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:26,742 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:27,165 __main__ [INFO ] Evaluated on training set. Loss: 1.92712
2018-02-05 01:22:27,182 __main__ [INFO ] Evaluated on validation set. Loss: 2.37450
2018-02-05 01:22:27,182 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 79 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.04,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:27,315 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:27,787 __main__ [INFO ] Evaluated on training set. Loss: 1.95101
2018-02-05 01:22:27,819 __main__ [INFO ] Evaluated on validation set. Loss: 2.30710
2018-02-05 01:22:27,819 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 80 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.04,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:28,018 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:28,391 __main__ [INFO ] Evaluated on training set. Loss: 1.92998
2018-02-05 01:22:28,408 __main__ [INFO ] Evaluated on validation set. Loss: 2.37543
2018-02-05 01:22:28,408 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 81 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.041,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:28,542 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:29,024 __main__ [INFO ] Evaluated on training set. Loss: 1.95328
2018-02-05 01:22:29,048 __main__ [INFO ] Evaluated on validation set. Loss: 2.30824
2018-02-05 01:22:29,048 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 82 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.041,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:29,182 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:29,538 __main__ [INFO ] Evaluated on training set. Loss: 1.93280
2018-02-05 01:22:29,555 __main__ [INFO ] Evaluated on validation set. Loss: 2.37638
2018-02-05 01:22:29,555 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 83 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.042,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:29,687 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:30,161 __main__ [INFO ] Evaluated on training set. Loss: 1.95554
2018-02-05 01:22:30,184 __main__ [INFO ] Evaluated on validation set. Loss: 2.30940
2018-02-05 01:22:30,185 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 84 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.042,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:30,352 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:30,705 __main__ [INFO ] Evaluated on training set. Loss: 1.93561
2018-02-05 01:22:30,722 __main__ [INFO ] Evaluated on validation set. Loss: 2.37736
2018-02-05 01:22:30,723 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 85 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.043,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:30,856 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:31,329 __main__ [INFO ] Evaluated on training set. Loss: 1.95777
2018-02-05 01:22:31,353 __main__ [INFO ] Evaluated on validation set. Loss: 2.31057
2018-02-05 01:22:31,353 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 86 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.043,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:31,486 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:31,837 __main__ [INFO ] Evaluated on training set. Loss: 1.93839
2018-02-05 01:22:31,854 __main__ [INFO ] Evaluated on validation set. Loss: 2.37836
2018-02-05 01:22:31,854 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 87 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.044,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:31,988 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:32,457 __main__ [INFO ] Evaluated on training set. Loss: 1.95999
2018-02-05 01:22:32,481 __main__ [INFO ] Evaluated on validation set. Loss: 2.31175
2018-02-05 01:22:32,481 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 88 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.044,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:32,614 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:32,971 __main__ [INFO ] Evaluated on training set. Loss: 1.94115
2018-02-05 01:22:32,988 __main__ [INFO ] Evaluated on validation set. Loss: 2.37937
2018-02-05 01:22:32,988 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 89 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.045,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:33,152 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:33,623 __main__ [INFO ] Evaluated on training set. Loss: 1.96219
2018-02-05 01:22:33,647 __main__ [INFO ] Evaluated on validation set. Loss: 2.31295
2018-02-05 01:22:33,647 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 90 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.045,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:33,784 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:34,135 __main__ [INFO ] Evaluated on training set. Loss: 1.94389
2018-02-05 01:22:34,152 __main__ [INFO ] Evaluated on validation set. Loss: 2.38041
2018-02-05 01:22:34,152 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 91 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.046,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:34,285 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:34,763 __main__ [INFO ] Evaluated on training set. Loss: 1.96437
2018-02-05 01:22:34,788 __main__ [INFO ] Evaluated on validation set. Loss: 2.31417
2018-02-05 01:22:34,788 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 92 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.046,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:34,923 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:35,275 __main__ [INFO ] Evaluated on training set. Loss: 1.94661
2018-02-05 01:22:35,292 __main__ [INFO ] Evaluated on validation set. Loss: 2.38147
2018-02-05 01:22:35,292 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 93 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.047,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:35,456 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:35,932 __main__ [INFO ] Evaluated on training set. Loss: 1.96653
2018-02-05 01:22:35,955 __main__ [INFO ] Evaluated on validation set. Loss: 2.31539
2018-02-05 01:22:35,956 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 94 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.047,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:36,088 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:36,446 __main__ [INFO ] Evaluated on training set. Loss: 1.94930
2018-02-05 01:22:36,464 __main__ [INFO ] Evaluated on validation set. Loss: 2.38253
2018-02-05 01:22:36,464 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 95 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.048,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:36,596 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:37,064 __main__ [INFO ] Evaluated on training set. Loss: 1.96868
2018-02-05 01:22:37,088 __main__ [INFO ] Evaluated on validation set. Loss: 2.31663
2018-02-05 01:22:37,088 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 96 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.048,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:37,220 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:37,573 __main__ [INFO ] Evaluated on training set. Loss: 1.95198
2018-02-05 01:22:37,590 __main__ [INFO ] Evaluated on validation set. Loss: 2.38362
2018-02-05 01:22:37,590 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 97 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.049,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:37,729 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:38,208 __main__ [INFO ] Evaluated on training set. Loss: 1.97082
2018-02-05 01:22:38,231 __main__ [INFO ] Evaluated on validation set. Loss: 2.31787
2018-02-05 01:22:38,232 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 98 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.049,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:38,397 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:38,752 __main__ [INFO ] Evaluated on training set. Loss: 1.95463
2018-02-05 01:22:38,769 __main__ [INFO ] Evaluated on validation set. Loss: 2.38472
2018-02-05 01:22:38,769 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 99 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.05,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:38,904 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:39,378 __main__ [INFO ] Evaluated on training set. Loss: 1.97294
2018-02-05 01:22:39,403 __main__ [INFO ] Evaluated on validation set. Loss: 2.31913
2018-02-05 01:22:39,403 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 100 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.05,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:39,537 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:39,892 __main__ [INFO ] Evaluated on training set. Loss: 1.95727
2018-02-05 01:22:39,909 __main__ [INFO ] Evaluated on validation set. Loss: 2.38583
2018-02-05 01:22:39,909 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 101 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.051,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:40,040 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:40,518 __main__ [INFO ] Evaluated on training set. Loss: 1.97504
2018-02-05 01:22:40,542 __main__ [INFO ] Evaluated on validation set. Loss: 2.32039
2018-02-05 01:22:40,542 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 102 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.051,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:40,705 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:41,057 __main__ [INFO ] Evaluated on training set. Loss: 1.95989
2018-02-05 01:22:41,074 __main__ [INFO ] Evaluated on validation set. Loss: 2.38695
2018-02-05 01:22:41,074 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 103 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.052,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:41,210 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:41,681 __main__ [INFO ] Evaluated on training set. Loss: 1.97713
2018-02-05 01:22:41,705 __main__ [INFO ] Evaluated on validation set. Loss: 2.32166
2018-02-05 01:22:41,705 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 104 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.052,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:41,841 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:42,193 __main__ [INFO ] Evaluated on training set. Loss: 1.96249
2018-02-05 01:22:42,211 __main__ [INFO ] Evaluated on validation set. Loss: 2.38809
2018-02-05 01:22:42,211 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 105 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.053,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:42,347 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:42,822 __main__ [INFO ] Evaluated on training set. Loss: 1.97920
2018-02-05 01:22:42,846 __main__ [INFO ] Evaluated on validation set. Loss: 2.32294
2018-02-05 01:22:42,847 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 106 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.053,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:42,981 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:43,334 __main__ [INFO ] Evaluated on training set. Loss: 1.96507
2018-02-05 01:22:43,351 __main__ [INFO ] Evaluated on validation set. Loss: 2.38923
2018-02-05 01:22:43,351 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 107 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.054,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:43,517 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:43,991 __main__ [INFO ] Evaluated on training set. Loss: 1.98126
2018-02-05 01:22:44,014 __main__ [INFO ] Evaluated on validation set. Loss: 2.32423
2018-02-05 01:22:44,015 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 108 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.054,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:44,152 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:44,503 __main__ [INFO ] Evaluated on training set. Loss: 1.96763
2018-02-05 01:22:44,520 __main__ [INFO ] Evaluated on validation set. Loss: 2.39039
2018-02-05 01:22:44,521 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 109 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.055,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:44,655 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:45,130 __main__ [INFO ] Evaluated on training set. Loss: 1.98331
2018-02-05 01:22:45,154 __main__ [INFO ] Evaluated on validation set. Loss: 2.32552
2018-02-05 01:22:45,154 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 110 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.055,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:45,286 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:45,638 __main__ [INFO ] Evaluated on training set. Loss: 1.97018
2018-02-05 01:22:45,655 __main__ [INFO ] Evaluated on validation set. Loss: 2.39155
2018-02-05 01:22:45,656 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 111 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.056,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:45,819 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:46,293 __main__ [INFO ] Evaluated on training set. Loss: 1.98534
2018-02-05 01:22:46,317 __main__ [INFO ] Evaluated on validation set. Loss: 2.32682
2018-02-05 01:22:46,317 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 112 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.056,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:46,450 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:46,803 __main__ [INFO ] Evaluated on training set. Loss: 1.97270
2018-02-05 01:22:46,820 __main__ [INFO ] Evaluated on validation set. Loss: 2.39272
2018-02-05 01:22:46,821 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 113 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.057,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:46,954 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:47,426 __main__ [INFO ] Evaluated on training set. Loss: 1.98736
2018-02-05 01:22:47,449 __main__ [INFO ] Evaluated on validation set. Loss: 2.32812
2018-02-05 01:22:47,450 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 114 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.057,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:47,582 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:47,935 __main__ [INFO ] Evaluated on training set. Loss: 1.97521
2018-02-05 01:22:47,952 __main__ [INFO ] Evaluated on validation set. Loss: 2.39390
2018-02-05 01:22:47,953 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 115 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.058,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:48,085 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:48,560 __main__ [INFO ] Evaluated on training set. Loss: 1.98937
2018-02-05 01:22:48,583 __main__ [INFO ] Evaluated on validation set. Loss: 2.32943
2018-02-05 01:22:48,583 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 116 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.058,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:48,744 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:49,092 __main__ [INFO ] Evaluated on training set. Loss: 1.97771
2018-02-05 01:22:49,109 __main__ [INFO ] Evaluated on validation set. Loss: 2.39509
2018-02-05 01:22:49,109 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 117 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.059,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:49,241 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:49,713 __main__ [INFO ] Evaluated on training set. Loss: 1.99136
2018-02-05 01:22:49,736 __main__ [INFO ] Evaluated on validation set. Loss: 2.33074
2018-02-05 01:22:49,737 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 118 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.059,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:49,871 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:50,226 __main__ [INFO ] Evaluated on training set. Loss: 1.98019
2018-02-05 01:22:50,242 __main__ [INFO ] Evaluated on validation set. Loss: 2.39628
2018-02-05 01:22:50,243 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 119 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.06,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:50,376 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:50,849 __main__ [INFO ] Evaluated on training set. Loss: 1.99334
2018-02-05 01:22:50,873 __main__ [INFO ] Evaluated on validation set. Loss: 2.33205
2018-02-05 01:22:50,874 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 120 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.06,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:51,037 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:51,390 __main__ [INFO ] Evaluated on training set. Loss: 1.98265
2018-02-05 01:22:51,406 __main__ [INFO ] Evaluated on validation set. Loss: 2.39748
2018-02-05 01:22:51,407 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 121 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.061,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:51,539 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:52,012 __main__ [INFO ] Evaluated on training set. Loss: 1.99531
2018-02-05 01:22:52,035 __main__ [INFO ] Evaluated on validation set. Loss: 2.33337
2018-02-05 01:22:52,035 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 122 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.061,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:52,167 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:52,522 __main__ [INFO ] Evaluated on training set. Loss: 1.98510
2018-02-05 01:22:52,539 __main__ [INFO ] Evaluated on validation set. Loss: 2.39869
2018-02-05 01:22:52,539 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 123 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.062,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:52,672 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:53,145 __main__ [INFO ] Evaluated on training set. Loss: 1.99727
2018-02-05 01:22:53,168 __main__ [INFO ] Evaluated on validation set. Loss: 2.33470
2018-02-05 01:22:53,168 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 124 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.062,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:53,300 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:53,652 __main__ [INFO ] Evaluated on training set. Loss: 1.98753
2018-02-05 01:22:53,669 __main__ [INFO ] Evaluated on validation set. Loss: 2.39990
2018-02-05 01:22:53,669 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 125 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.063,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:53,830 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:54,302 __main__ [INFO ] Evaluated on training set. Loss: 1.99921
2018-02-05 01:22:54,325 __main__ [INFO ] Evaluated on validation set. Loss: 2.33602
2018-02-05 01:22:54,326 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 126 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.063,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:54,460 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:54,817 __main__ [INFO ] Evaluated on training set. Loss: 1.98994
2018-02-05 01:22:54,833 __main__ [INFO ] Evaluated on validation set. Loss: 2.40112
2018-02-05 01:22:54,834 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 127 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.064,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:54,969 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:55,449 __main__ [INFO ] Evaluated on training set. Loss: 2.00115
2018-02-05 01:22:55,472 __main__ [INFO ] Evaluated on validation set. Loss: 2.33735
2018-02-05 01:22:55,473 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 128 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.064,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:55,605 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:55,958 __main__ [INFO ] Evaluated on training set. Loss: 1.99235
2018-02-05 01:22:55,975 __main__ [INFO ] Evaluated on validation set. Loss: 2.40234
2018-02-05 01:22:55,975 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 129 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.065,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:56,139 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:56,615 __main__ [INFO ] Evaluated on training set. Loss: 2.00307
2018-02-05 01:22:56,639 __main__ [INFO ] Evaluated on validation set. Loss: 2.33868
2018-02-05 01:22:56,639 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 130 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.065,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:56,771 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:57,125 __main__ [INFO ] Evaluated on training set. Loss: 1.99473
2018-02-05 01:22:57,142 __main__ [INFO ] Evaluated on validation set. Loss: 2.40356
2018-02-05 01:22:57,142 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 131 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.066,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:57,280 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:57,755 __main__ [INFO ] Evaluated on training set. Loss: 2.00498
2018-02-05 01:22:57,779 __main__ [INFO ] Evaluated on validation set. Loss: 2.34001
2018-02-05 01:22:57,779 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 132 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.066,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:57,914 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:58,269 __main__ [INFO ] Evaluated on training set. Loss: 1.99711
2018-02-05 01:22:58,286 __main__ [INFO ] Evaluated on validation set. Loss: 2.40479
2018-02-05 01:22:58,287 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 133 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.067,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:58,423 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:58,900 __main__ [INFO ] Evaluated on training set. Loss: 2.00688
2018-02-05 01:22:58,923 __main__ [INFO ] Evaluated on validation set. Loss: 2.34134
2018-02-05 01:22:58,924 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 134 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.067,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:59,085 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:22:59,438 __main__ [INFO ] Evaluated on training set. Loss: 1.99946
2018-02-05 01:22:59,455 __main__ [INFO ] Evaluated on validation set. Loss: 2.40603
2018-02-05 01:22:59,455 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 135 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.068,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:22:59,588 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:00,068 __main__ [INFO ] Evaluated on training set. Loss: 2.00877
2018-02-05 01:23:00,092 __main__ [INFO ] Evaluated on validation set. Loss: 2.34268
2018-02-05 01:23:00,093 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 136 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.068,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:00,226 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:00,582 __main__ [INFO ] Evaluated on training set. Loss: 2.00181
2018-02-05 01:23:00,599 __main__ [INFO ] Evaluated on validation set. Loss: 2.40726
2018-02-05 01:23:00,599 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 137 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.069,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:00,731 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:01,205 __main__ [INFO ] Evaluated on training set. Loss: 2.01064
2018-02-05 01:23:01,228 __main__ [INFO ] Evaluated on validation set. Loss: 2.34402
2018-02-05 01:23:01,229 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 138 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.069,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:01,394 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:01,744 __main__ [INFO ] Evaluated on training set. Loss: 2.00414
2018-02-05 01:23:01,761 __main__ [INFO ] Evaluated on validation set. Loss: 2.40850
2018-02-05 01:23:01,761 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 139 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.07,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:01,896 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:02,409 __main__ [INFO ] Evaluated on training set. Loss: 2.01251
2018-02-05 01:23:02,433 __main__ [INFO ] Evaluated on validation set. Loss: 2.34535
2018-02-05 01:23:02,433 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 140 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.07,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:02,567 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:02,923 __main__ [INFO ] Evaluated on training set. Loss: 2.00646
2018-02-05 01:23:02,940 __main__ [INFO ] Evaluated on validation set. Loss: 2.40974
2018-02-05 01:23:02,940 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 141 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.071,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:03,073 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:03,546 __main__ [INFO ] Evaluated on training set. Loss: 2.01437
2018-02-05 01:23:03,571 __main__ [INFO ] Evaluated on validation set. Loss: 2.34669
2018-02-05 01:23:03,571 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 142 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.071,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:03,704 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:04,057 __main__ [INFO ] Evaluated on training set. Loss: 2.00876
2018-02-05 01:23:04,074 __main__ [INFO ] Evaluated on validation set. Loss: 2.41099
2018-02-05 01:23:04,074 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 143 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.072,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:04,234 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:04,713 __main__ [INFO ] Evaluated on training set. Loss: 2.01621
2018-02-05 01:23:04,737 __main__ [INFO ] Evaluated on validation set. Loss: 2.34803
2018-02-05 01:23:04,737 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 144 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.072,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:04,875 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:05,230 __main__ [INFO ] Evaluated on training set. Loss: 2.01105
2018-02-05 01:23:05,246 __main__ [INFO ] Evaluated on validation set. Loss: 2.41223
2018-02-05 01:23:05,247 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 145 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.073,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:05,380 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:05,858 __main__ [INFO ] Evaluated on training set. Loss: 2.01805
2018-02-05 01:23:05,882 __main__ [INFO ] Evaluated on validation set. Loss: 2.34937
2018-02-05 01:23:05,883 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 146 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.073,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:06,016 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:06,369 __main__ [INFO ] Evaluated on training set. Loss: 2.01333
2018-02-05 01:23:06,386 __main__ [INFO ] Evaluated on validation set. Loss: 2.41348
2018-02-05 01:23:06,387 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 147 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.074,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:06,551 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:07,029 __main__ [INFO ] Evaluated on training set. Loss: 2.01988
2018-02-05 01:23:07,053 __main__ [INFO ] Evaluated on validation set. Loss: 2.35071
2018-02-05 01:23:07,053 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 148 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.074,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:07,186 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:07,539 __main__ [INFO ] Evaluated on training set. Loss: 2.01560
2018-02-05 01:23:07,556 __main__ [INFO ] Evaluated on validation set. Loss: 2.41473
2018-02-05 01:23:07,556 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 149 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.075,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:07,689 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:08,162 __main__ [INFO ] Evaluated on training set. Loss: 2.02169
2018-02-05 01:23:08,186 __main__ [INFO ] Evaluated on validation set. Loss: 2.35205
2018-02-05 01:23:08,186 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 150 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.075,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:08,319 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:08,675 __main__ [INFO ] Evaluated on training set. Loss: 2.01785
2018-02-05 01:23:08,692 __main__ [INFO ] Evaluated on validation set. Loss: 2.41599
2018-02-05 01:23:08,692 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 151 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.076,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:08,826 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:09,302 __main__ [INFO ] Evaluated on training set. Loss: 2.02350
2018-02-05 01:23:09,326 __main__ [INFO ] Evaluated on validation set. Loss: 2.35339
2018-02-05 01:23:09,326 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 152 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.076,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:09,490 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:09,846 __main__ [INFO ] Evaluated on training set. Loss: 2.02009
2018-02-05 01:23:09,864 __main__ [INFO ] Evaluated on validation set. Loss: 2.41724
2018-02-05 01:23:09,864 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 153 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.077,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:09,999 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:10,480 __main__ [INFO ] Evaluated on training set. Loss: 2.02530
2018-02-05 01:23:10,504 __main__ [INFO ] Evaluated on validation set. Loss: 2.35473
2018-02-05 01:23:10,504 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 154 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.077,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:10,637 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:10,990 __main__ [INFO ] Evaluated on training set. Loss: 2.02232
2018-02-05 01:23:11,008 __main__ [INFO ] Evaluated on validation set. Loss: 2.41850
2018-02-05 01:23:11,008 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 155 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.078,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:11,140 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:11,615 __main__ [INFO ] Evaluated on training set. Loss: 2.02709
2018-02-05 01:23:11,639 __main__ [INFO ] Evaluated on validation set. Loss: 2.35607
2018-02-05 01:23:11,639 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 156 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.078,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:11,804 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:12,155 __main__ [INFO ] Evaluated on training set. Loss: 2.02454
2018-02-05 01:23:12,172 __main__ [INFO ] Evaluated on validation set. Loss: 2.41975
2018-02-05 01:23:12,172 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 157 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.079,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:12,307 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:12,783 __main__ [INFO ] Evaluated on training set. Loss: 2.02887
2018-02-05 01:23:12,807 __main__ [INFO ] Evaluated on validation set. Loss: 2.35741
2018-02-05 01:23:12,807 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 158 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.079,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:12,942 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:13,298 __main__ [INFO ] Evaluated on training set. Loss: 2.02675
2018-02-05 01:23:13,315 __main__ [INFO ] Evaluated on validation set. Loss: 2.42101
2018-02-05 01:23:13,315 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 159 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.08,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:13,450 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:13,926 __main__ [INFO ] Evaluated on training set. Loss: 2.03064
2018-02-05 01:23:13,950 __main__ [INFO ] Evaluated on validation set. Loss: 2.35875
2018-02-05 01:23:13,950 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 160 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.08,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:14,084 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:14,441 __main__ [INFO ] Evaluated on training set. Loss: 2.02894
2018-02-05 01:23:14,458 __main__ [INFO ] Evaluated on validation set. Loss: 2.42227
2018-02-05 01:23:14,459 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 161 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.081,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:14,620 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:15,099 __main__ [INFO ] Evaluated on training set. Loss: 2.03240
2018-02-05 01:23:15,123 __main__ [INFO ] Evaluated on validation set. Loss: 2.36009
2018-02-05 01:23:15,123 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 162 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.081,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:15,257 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:15,612 __main__ [INFO ] Evaluated on training set. Loss: 2.03112
2018-02-05 01:23:15,629 __main__ [INFO ] Evaluated on validation set. Loss: 2.42353
2018-02-05 01:23:15,629 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 163 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.082,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:15,765 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:16,244 __main__ [INFO ] Evaluated on training set. Loss: 2.03415
2018-02-05 01:23:16,268 __main__ [INFO ] Evaluated on validation set. Loss: 2.36143
2018-02-05 01:23:16,268 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 164 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.082,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:16,402 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:16,756 __main__ [INFO ] Evaluated on training set. Loss: 2.03330
2018-02-05 01:23:16,773 __main__ [INFO ] Evaluated on validation set. Loss: 2.42479
2018-02-05 01:23:16,773 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 165 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.083,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:16,938 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:17,413 __main__ [INFO ] Evaluated on training set. Loss: 2.03590
2018-02-05 01:23:17,437 __main__ [INFO ] Evaluated on validation set. Loss: 2.36277
2018-02-05 01:23:17,438 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 166 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.083,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:17,571 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:17,926 __main__ [INFO ] Evaluated on training set. Loss: 2.03546
2018-02-05 01:23:17,944 __main__ [INFO ] Evaluated on validation set. Loss: 2.42605
2018-02-05 01:23:17,944 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 167 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.084,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:18,077 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:18,553 __main__ [INFO ] Evaluated on training set. Loss: 2.03763
2018-02-05 01:23:18,576 __main__ [INFO ] Evaluated on validation set. Loss: 2.36410
2018-02-05 01:23:18,577 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 168 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.084,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:18,711 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:19,063 __main__ [INFO ] Evaluated on training set. Loss: 2.03761
2018-02-05 01:23:19,080 __main__ [INFO ] Evaluated on validation set. Loss: 2.42731
2018-02-05 01:23:19,080 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 169 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.085,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:19,212 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:19,683 __main__ [INFO ] Evaluated on training set. Loss: 2.03936
2018-02-05 01:23:19,707 __main__ [INFO ] Evaluated on validation set. Loss: 2.36544
2018-02-05 01:23:19,707 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 170 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.085,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:19,870 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:20,220 __main__ [INFO ] Evaluated on training set. Loss: 2.03975
2018-02-05 01:23:20,237 __main__ [INFO ] Evaluated on validation set. Loss: 2.42857
2018-02-05 01:23:20,237 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 171 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.086,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:20,370 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:20,841 __main__ [INFO ] Evaluated on training set. Loss: 2.04108
2018-02-05 01:23:20,866 __main__ [INFO ] Evaluated on validation set. Loss: 2.36677
2018-02-05 01:23:20,866 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 172 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.086,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:21,000 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:21,356 __main__ [INFO ] Evaluated on training set. Loss: 2.04187
2018-02-05 01:23:21,373 __main__ [INFO ] Evaluated on validation set. Loss: 2.42983
2018-02-05 01:23:21,373 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 173 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.087,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:21,506 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:21,999 __main__ [INFO ] Evaluated on training set. Loss: 2.04279
2018-02-05 01:23:22,023 __main__ [INFO ] Evaluated on validation set. Loss: 2.36811
2018-02-05 01:23:22,023 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 174 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.087,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:22,187 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:22,539 __main__ [INFO ] Evaluated on training set. Loss: 2.04399
2018-02-05 01:23:22,556 __main__ [INFO ] Evaluated on validation set. Loss: 2.43109
2018-02-05 01:23:22,557 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 175 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.088,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:22,689 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:23,161 __main__ [INFO ] Evaluated on training set. Loss: 2.04449
2018-02-05 01:23:23,184 __main__ [INFO ] Evaluated on validation set. Loss: 2.36944
2018-02-05 01:23:23,185 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 176 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.088,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:23,318 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:23,668 __main__ [INFO ] Evaluated on training set. Loss: 2.04610
2018-02-05 01:23:23,685 __main__ [INFO ] Evaluated on validation set. Loss: 2.43235
2018-02-05 01:23:23,685 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 177 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.089,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:23,819 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:24,293 __main__ [INFO ] Evaluated on training set. Loss: 2.04619
2018-02-05 01:23:24,317 __main__ [INFO ] Evaluated on validation set. Loss: 2.37077
2018-02-05 01:23:24,317 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 178 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.089,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:24,451 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:24,804 __main__ [INFO ] Evaluated on training set. Loss: 2.04820
2018-02-05 01:23:24,821 __main__ [INFO ] Evaluated on validation set. Loss: 2.43361
2018-02-05 01:23:24,821 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 179 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.09,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:24,987 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:25,461 __main__ [INFO ] Evaluated on training set. Loss: 2.04788
2018-02-05 01:23:25,485 __main__ [INFO ] Evaluated on validation set. Loss: 2.37210
2018-02-05 01:23:25,485 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 180 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.09,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:25,618 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:25,974 __main__ [INFO ] Evaluated on training set. Loss: 2.05029
2018-02-05 01:23:25,992 __main__ [INFO ] Evaluated on validation set. Loss: 2.43487
2018-02-05 01:23:25,992 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 181 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.091,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:26,125 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:26,602 __main__ [INFO ] Evaluated on training set. Loss: 2.04955
2018-02-05 01:23:26,626 __main__ [INFO ] Evaluated on validation set. Loss: 2.37343
2018-02-05 01:23:26,626 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 182 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.091,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:26,759 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:27,112 __main__ [INFO ] Evaluated on training set. Loss: 2.05236
2018-02-05 01:23:27,130 __main__ [INFO ] Evaluated on validation set. Loss: 2.43613
2018-02-05 01:23:27,130 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 183 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.092,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:27,294 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:27,770 __main__ [INFO ] Evaluated on training set. Loss: 2.05123
2018-02-05 01:23:27,793 __main__ [INFO ] Evaluated on validation set. Loss: 2.37476
2018-02-05 01:23:27,793 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 184 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.092,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:27,928 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:28,279 __main__ [INFO ] Evaluated on training set. Loss: 2.05443
2018-02-05 01:23:28,296 __main__ [INFO ] Evaluated on validation set. Loss: 2.43739
2018-02-05 01:23:28,296 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 185 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.093,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:28,430 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:28,902 __main__ [INFO ] Evaluated on training set. Loss: 2.05289
2018-02-05 01:23:28,926 __main__ [INFO ] Evaluated on validation set. Loss: 2.37608
2018-02-05 01:23:28,926 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 186 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.093,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:29,058 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:29,419 __main__ [INFO ] Evaluated on training set. Loss: 2.05649
2018-02-05 01:23:29,437 __main__ [INFO ] Evaluated on validation set. Loss: 2.43864
2018-02-05 01:23:29,437 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 187 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.094,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:29,571 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:30,075 __main__ [INFO ] Evaluated on training set. Loss: 2.05455
2018-02-05 01:23:30,099 __main__ [INFO ] Evaluated on validation set. Loss: 2.37741
2018-02-05 01:23:30,099 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 188 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.094,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:30,259 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:30,630 __main__ [INFO ] Evaluated on training set. Loss: 2.05854
2018-02-05 01:23:30,647 __main__ [INFO ] Evaluated on validation set. Loss: 2.43990
2018-02-05 01:23:30,647 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 189 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.095,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:30,779 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:31,255 __main__ [INFO ] Evaluated on training set. Loss: 2.05620
2018-02-05 01:23:31,279 __main__ [INFO ] Evaluated on validation set. Loss: 2.37873
2018-02-05 01:23:31,280 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 190 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.095,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:31,414 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:31,767 __main__ [INFO ] Evaluated on training set. Loss: 2.06058
2018-02-05 01:23:31,784 __main__ [INFO ] Evaluated on validation set. Loss: 2.44116
2018-02-05 01:23:31,784 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 191 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.096,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:31,920 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:32,393 __main__ [INFO ] Evaluated on training set. Loss: 2.05784
2018-02-05 01:23:32,416 __main__ [INFO ] Evaluated on validation set. Loss: 2.38005
2018-02-05 01:23:32,417 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 192 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.096,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:32,584 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:32,935 __main__ [INFO ] Evaluated on training set. Loss: 2.06261
2018-02-05 01:23:32,953 __main__ [INFO ] Evaluated on validation set. Loss: 2.44242
2018-02-05 01:23:32,953 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 193 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.097,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:33,091 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:33,565 __main__ [INFO ] Evaluated on training set. Loss: 2.05947
2018-02-05 01:23:33,589 __main__ [INFO ] Evaluated on validation set. Loss: 2.38137
2018-02-05 01:23:33,589 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 194 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.097,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:33,729 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:34,079 __main__ [INFO ] Evaluated on training set. Loss: 2.06463
2018-02-05 01:23:34,097 __main__ [INFO ] Evaluated on validation set. Loss: 2.44367
2018-02-05 01:23:34,097 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 195 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.098,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:34,237 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:34,709 __main__ [INFO ] Evaluated on training set. Loss: 2.06110
2018-02-05 01:23:34,732 __main__ [INFO ] Evaluated on validation set. Loss: 2.38269
2018-02-05 01:23:34,732 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 196 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.098,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:34,868 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:35,220 __main__ [INFO ] Evaluated on training set. Loss: 2.06664
2018-02-05 01:23:35,237 __main__ [INFO ] Evaluated on validation set. Loss: 2.44492
2018-02-05 01:23:35,237 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 197 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.099,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:35,399 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:35,878 __main__ [INFO ] Evaluated on training set. Loss: 2.06272
2018-02-05 01:23:35,902 __main__ [INFO ] Evaluated on validation set. Loss: 2.38400
2018-02-05 01:23:35,902 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 198 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.099,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:36,034 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:36,388 __main__ [INFO ] Evaluated on training set. Loss: 2.06865
2018-02-05 01:23:36,405 __main__ [INFO ] Evaluated on validation set. Loss: 2.44618
2018-02-05 01:23:36,405 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 199 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:36,538 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:37,012 __main__ [INFO ] Evaluated on training set. Loss: 2.06434
2018-02-05 01:23:37,035 __main__ [INFO ] Evaluated on validation set. Loss: 2.38532
2018-02-05 01:23:37,035 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 200 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:23:37,167 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:37,520 __main__ [INFO ] Evaluated on training set. Loss: 2.07064
2018-02-05 01:23:37,537 __main__ [INFO ] Evaluated on validation set. Loss: 2.44743
2018-02-05 01:23:37,537 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 201 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:37,718 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:38,305 __main__ [INFO ] Evaluated on training set. Loss: 1.38630
2018-02-05 01:23:38,331 __main__ [INFO ] Evaluated on validation set. Loss: 2.67920
2018-02-05 01:23:38,331 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 202 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:38,484 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:38,996 __main__ [INFO ] Evaluated on training set. Loss: 1.31779
2018-02-05 01:23:39,015 __main__ [INFO ] Evaluated on validation set. Loss: 2.79794
2018-02-05 01:23:39,015 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 203 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.002,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:39,166 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:39,755 __main__ [INFO ] Evaluated on training set. Loss: 1.39828
2018-02-05 01:23:39,779 __main__ [INFO ] Evaluated on validation set. Loss: 2.59798
2018-02-05 01:23:39,779 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 204 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.002,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:39,970 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:40,440 __main__ [INFO ] Evaluated on training set. Loss: 1.33169
2018-02-05 01:23:40,458 __main__ [INFO ] Evaluated on validation set. Loss: 2.71097
2018-02-05 01:23:40,458 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 205 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.003,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:40,608 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:41,236 __main__ [INFO ] Evaluated on training set. Loss: 1.40979
2018-02-05 01:23:41,260 __main__ [INFO ] Evaluated on validation set. Loss: 2.55493
2018-02-05 01:23:41,261 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 206 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.003,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:41,413 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:41,880 __main__ [INFO ] Evaluated on training set. Loss: 1.34507
2018-02-05 01:23:41,898 __main__ [INFO ] Evaluated on validation set. Loss: 2.66458
2018-02-05 01:23:41,898 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 207 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.004,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:42,085 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:42,671 __main__ [INFO ] Evaluated on training set. Loss: 1.42088
2018-02-05 01:23:42,696 __main__ [INFO ] Evaluated on validation set. Loss: 2.52731
2018-02-05 01:23:42,696 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 208 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.004,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:42,847 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:43,314 __main__ [INFO ] Evaluated on training set. Loss: 1.35799
2018-02-05 01:23:43,333 __main__ [INFO ] Evaluated on validation set. Loss: 2.63460
2018-02-05 01:23:43,333 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 209 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.005,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:43,522 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:44,113 __main__ [INFO ] Evaluated on training set. Loss: 1.43159
2018-02-05 01:23:44,139 __main__ [INFO ] Evaluated on validation set. Loss: 2.50802
2018-02-05 01:23:44,139 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 210 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.005,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:44,292 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:44,806 __main__ [INFO ] Evaluated on training set. Loss: 1.37048
2018-02-05 01:23:44,824 __main__ [INFO ] Evaluated on validation set. Loss: 2.61348
2018-02-05 01:23:44,825 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 211 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.006,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:44,977 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:45,566 __main__ [INFO ] Evaluated on training set. Loss: 1.44196
2018-02-05 01:23:45,590 __main__ [INFO ] Evaluated on validation set. Loss: 2.49389
2018-02-05 01:23:45,590 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 212 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.006,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:45,781 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:46,257 __main__ [INFO ] Evaluated on training set. Loss: 1.38258
2018-02-05 01:23:46,274 __main__ [INFO ] Evaluated on validation set. Loss: 2.59787
2018-02-05 01:23:46,275 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 213 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.007,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:46,429 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:47,063 __main__ [INFO ] Evaluated on training set. Loss: 1.45201
2018-02-05 01:23:47,088 __main__ [INFO ] Evaluated on validation set. Loss: 2.48326
2018-02-05 01:23:47,088 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 214 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.007,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:47,239 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:47,705 __main__ [INFO ] Evaluated on training set. Loss: 1.39433
2018-02-05 01:23:47,724 __main__ [INFO ] Evaluated on validation set. Loss: 2.58600
2018-02-05 01:23:47,724 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 215 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.008,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:47,915 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:48,509 __main__ [INFO ] Evaluated on training set. Loss: 1.46177
2018-02-05 01:23:48,533 __main__ [INFO ] Evaluated on validation set. Loss: 2.47513
2018-02-05 01:23:48,533 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 216 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.008,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:48,684 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:49,152 __main__ [INFO ] Evaluated on training set. Loss: 1.40575
2018-02-05 01:23:49,171 __main__ [INFO ] Evaluated on validation set. Loss: 2.57680
2018-02-05 01:23:49,171 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 217 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.009,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:49,359 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:49,955 __main__ [INFO ] Evaluated on training set. Loss: 1.47126
2018-02-05 01:23:49,979 __main__ [INFO ] Evaluated on validation set. Loss: 2.46888
2018-02-05 01:23:49,979 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 218 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.009,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:50,131 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:50,656 __main__ [INFO ] Evaluated on training set. Loss: 1.41687
2018-02-05 01:23:50,675 __main__ [INFO ] Evaluated on validation set. Loss: 2.56961
2018-02-05 01:23:50,675 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 219 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:50,984 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:51,588 __main__ [INFO ] Evaluated on training set. Loss: 1.48051
2018-02-05 01:23:51,615 __main__ [INFO ] Evaluated on validation set. Loss: 2.46406
2018-02-05 01:23:51,616 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 220 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:51,834 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:52,315 __main__ [INFO ] Evaluated on training set. Loss: 1.42771
2018-02-05 01:23:52,333 __main__ [INFO ] Evaluated on validation set. Loss: 2.56396
2018-02-05 01:23:52,333 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 221 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.011,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:52,493 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:53,184 __main__ [INFO ] Evaluated on training set. Loss: 1.48952
2018-02-05 01:23:53,210 __main__ [INFO ] Evaluated on validation set. Loss: 2.46039
2018-02-05 01:23:53,210 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 222 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.011,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:53,390 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:54,072 __main__ [INFO ] Evaluated on training set. Loss: 1.43828
2018-02-05 01:23:54,091 __main__ [INFO ] Evaluated on validation set. Loss: 2.55952
2018-02-05 01:23:54,091 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 223 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.012,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:54,305 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:55,053 __main__ [INFO ] Evaluated on training set. Loss: 1.49831
2018-02-05 01:23:55,102 __main__ [INFO ] Evaluated on validation set. Loss: 2.45762
2018-02-05 01:23:55,103 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 224 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.012,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:55,365 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:55,909 __main__ [INFO ] Evaluated on training set. Loss: 1.44860
2018-02-05 01:23:55,928 __main__ [INFO ] Evaluated on validation set. Loss: 2.55608
2018-02-05 01:23:55,929 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 225 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.013,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:56,130 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:56,788 __main__ [INFO ] Evaluated on training set. Loss: 1.50691
2018-02-05 01:23:56,823 __main__ [INFO ] Evaluated on validation set. Loss: 2.45561
2018-02-05 01:23:56,824 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 226 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.013,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:57,156 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:57,670 __main__ [INFO ] Evaluated on training set. Loss: 1.45869
2018-02-05 01:23:57,690 __main__ [INFO ] Evaluated on validation set. Loss: 2.55344
2018-02-05 01:23:57,690 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 227 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.014,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:57,853 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:58,458 __main__ [INFO ] Evaluated on training set. Loss: 1.51531
2018-02-05 01:23:58,483 __main__ [INFO ] Evaluated on validation set. Loss: 2.45421
2018-02-05 01:23:58,483 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 228 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.014,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:58,677 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:23:59,170 __main__ [INFO ] Evaluated on training set. Loss: 1.46856
2018-02-05 01:23:59,189 __main__ [INFO ] Evaluated on validation set. Loss: 2.55146
2018-02-05 01:23:59,189 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 229 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.015,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:23:59,353 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:00,033 __main__ [INFO ] Evaluated on training set. Loss: 1.52353
2018-02-05 01:24:00,059 __main__ [INFO ] Evaluated on validation set. Loss: 2.45334
2018-02-05 01:24:00,060 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 230 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.015,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:00,222 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:00,720 __main__ [INFO ] Evaluated on training set. Loss: 1.47823
2018-02-05 01:24:00,738 __main__ [INFO ] Evaluated on validation set. Loss: 2.55005
2018-02-05 01:24:00,738 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 231 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.016,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:00,942 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:01,582 __main__ [INFO ] Evaluated on training set. Loss: 1.53159
2018-02-05 01:24:01,609 __main__ [INFO ] Evaluated on validation set. Loss: 2.45291
2018-02-05 01:24:01,609 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 232 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.016,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:01,779 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:02,327 __main__ [INFO ] Evaluated on training set. Loss: 1.48770
2018-02-05 01:24:02,346 __main__ [INFO ] Evaluated on validation set. Loss: 2.54912
2018-02-05 01:24:02,347 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 233 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.017,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:02,503 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:03,141 __main__ [INFO ] Evaluated on training set. Loss: 1.53948
2018-02-05 01:24:03,166 __main__ [INFO ] Evaluated on validation set. Loss: 2.45285
2018-02-05 01:24:03,166 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 234 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.017,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:03,364 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:03,892 __main__ [INFO ] Evaluated on training set. Loss: 1.49699
2018-02-05 01:24:03,912 __main__ [INFO ] Evaluated on validation set. Loss: 2.54859
2018-02-05 01:24:03,912 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 235 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.018,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:04,081 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:04,698 __main__ [INFO ] Evaluated on training set. Loss: 1.54722
2018-02-05 01:24:04,725 __main__ [INFO ] Evaluated on validation set. Loss: 2.45311
2018-02-05 01:24:04,725 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 236 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.018,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:04,923 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:05,418 __main__ [INFO ] Evaluated on training set. Loss: 1.50610
2018-02-05 01:24:05,437 __main__ [INFO ] Evaluated on validation set. Loss: 2.54841
2018-02-05 01:24:05,437 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 237 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.019,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:05,596 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:06,300 __main__ [INFO ] Evaluated on training set. Loss: 1.55482
2018-02-05 01:24:06,327 __main__ [INFO ] Evaluated on validation set. Loss: 2.45365
2018-02-05 01:24:06,327 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 238 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.019,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:06,494 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:06,990 __main__ [INFO ] Evaluated on training set. Loss: 1.51504
2018-02-05 01:24:07,008 __main__ [INFO ] Evaluated on validation set. Loss: 2.54854
2018-02-05 01:24:07,009 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 239 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.02,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:07,208 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:07,818 __main__ [INFO ] Evaluated on training set. Loss: 1.56228
2018-02-05 01:24:07,844 __main__ [INFO ] Evaluated on validation set. Loss: 2.45443
2018-02-05 01:24:07,844 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 240 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.02,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:07,997 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:08,545 __main__ [INFO ] Evaluated on training set. Loss: 1.52383
2018-02-05 01:24:08,564 __main__ [INFO ] Evaluated on validation set. Loss: 2.54893
2018-02-05 01:24:08,565 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 241 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.021,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:08,725 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:09,339 __main__ [INFO ] Evaluated on training set. Loss: 1.56962
2018-02-05 01:24:09,365 __main__ [INFO ] Evaluated on validation set. Loss: 2.45543
2018-02-05 01:24:09,366 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 242 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.021,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:09,567 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:10,051 __main__ [INFO ] Evaluated on training set. Loss: 1.53246
2018-02-05 01:24:10,071 __main__ [INFO ] Evaluated on validation set. Loss: 2.54955
2018-02-05 01:24:10,071 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 243 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.022,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:10,228 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:10,847 __main__ [INFO ] Evaluated on training set. Loss: 1.57682
2018-02-05 01:24:10,873 __main__ [INFO ] Evaluated on validation set. Loss: 2.45661
2018-02-05 01:24:10,873 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 244 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.022,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:11,085 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:11,590 __main__ [INFO ] Evaluated on training set. Loss: 1.54095
2018-02-05 01:24:11,609 __main__ [INFO ] Evaluated on validation set. Loss: 2.55038
2018-02-05 01:24:11,610 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 245 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.023,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:11,816 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:12,436 __main__ [INFO ] Evaluated on training set. Loss: 1.58391
2018-02-05 01:24:12,462 __main__ [INFO ] Evaluated on validation set. Loss: 2.45796
2018-02-05 01:24:12,463 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 246 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.023,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:12,631 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:13,132 __main__ [INFO ] Evaluated on training set. Loss: 1.54930
2018-02-05 01:24:13,151 __main__ [INFO ] Evaluated on validation set. Loss: 2.55139
2018-02-05 01:24:13,151 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 247 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.024,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:13,355 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:13,982 __main__ [INFO ] Evaluated on training set. Loss: 1.59089
2018-02-05 01:24:14,009 __main__ [INFO ] Evaluated on validation set. Loss: 2.45944
2018-02-05 01:24:14,009 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 248 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.024,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:14,179 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:14,720 __main__ [INFO ] Evaluated on training set. Loss: 1.55751
2018-02-05 01:24:14,739 __main__ [INFO ] Evaluated on validation set. Loss: 2.55255
2018-02-05 01:24:14,739 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 249 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.025,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:14,927 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:15,632 __main__ [INFO ] Evaluated on training set. Loss: 1.59775
2018-02-05 01:24:15,660 __main__ [INFO ] Evaluated on validation set. Loss: 2.46106
2018-02-05 01:24:15,661 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 250 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.025,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:15,883 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:16,427 __main__ [INFO ] Evaluated on training set. Loss: 1.56560
2018-02-05 01:24:16,447 __main__ [INFO ] Evaluated on validation set. Loss: 2.55386
2018-02-05 01:24:16,448 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 251 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.026,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:16,638 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:17,442 __main__ [INFO ] Evaluated on training set. Loss: 1.60451
2018-02-05 01:24:17,469 __main__ [INFO ] Evaluated on validation set. Loss: 2.46279
2018-02-05 01:24:17,469 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 252 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.026,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:17,638 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:18,157 __main__ [INFO ] Evaluated on training set. Loss: 1.57356
2018-02-05 01:24:18,177 __main__ [INFO ] Evaluated on validation set. Loss: 2.55530
2018-02-05 01:24:18,177 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 253 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.027,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:18,389 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:19,090 __main__ [INFO ] Evaluated on training set. Loss: 1.61117
2018-02-05 01:24:19,116 __main__ [INFO ] Evaluated on validation set. Loss: 2.46462
2018-02-05 01:24:19,117 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 254 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.027,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:19,299 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:19,801 __main__ [INFO ] Evaluated on training set. Loss: 1.58141
2018-02-05 01:24:19,819 __main__ [INFO ] Evaluated on validation set. Loss: 2.55685
2018-02-05 01:24:19,820 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 255 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.028,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:20,024 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:20,732 __main__ [INFO ] Evaluated on training set. Loss: 1.61774
2018-02-05 01:24:20,758 __main__ [INFO ] Evaluated on validation set. Loss: 2.46655
2018-02-05 01:24:20,759 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 256 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.028,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:20,923 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:21,507 __main__ [INFO ] Evaluated on training set. Loss: 1.58914
2018-02-05 01:24:21,526 __main__ [INFO ] Evaluated on validation set. Loss: 2.55850
2018-02-05 01:24:21,526 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 257 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.029,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:21,687 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:22,306 __main__ [INFO ] Evaluated on training set. Loss: 1.62421
2018-02-05 01:24:22,332 __main__ [INFO ] Evaluated on validation set. Loss: 2.46855
2018-02-05 01:24:22,332 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 258 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.029,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:22,529 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:23,047 __main__ [INFO ] Evaluated on training set. Loss: 1.59677
2018-02-05 01:24:23,068 __main__ [INFO ] Evaluated on validation set. Loss: 2.56024
2018-02-05 01:24:23,069 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 259 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.03,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:23,285 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:24,172 __main__ [INFO ] Evaluated on training set. Loss: 1.63059
2018-02-05 01:24:24,200 __main__ [INFO ] Evaluated on validation set. Loss: 2.47063
2018-02-05 01:24:24,200 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 260 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.03,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:24,371 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:24,946 __main__ [INFO ] Evaluated on training set. Loss: 1.60428
2018-02-05 01:24:24,967 __main__ [INFO ] Evaluated on validation set. Loss: 2.56206
2018-02-05 01:24:24,968 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 261 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.031,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:25,283 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:26,012 __main__ [INFO ] Evaluated on training set. Loss: 1.63688
2018-02-05 01:24:26,049 __main__ [INFO ] Evaluated on validation set. Loss: 2.47276
2018-02-05 01:24:26,049 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 262 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.031,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:26,237 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:26,837 __main__ [INFO ] Evaluated on training set. Loss: 1.61170
2018-02-05 01:24:26,857 __main__ [INFO ] Evaluated on validation set. Loss: 2.56395
2018-02-05 01:24:26,857 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 263 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.032,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:27,065 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:27,753 __main__ [INFO ] Evaluated on training set. Loss: 1.64309
2018-02-05 01:24:27,780 __main__ [INFO ] Evaluated on validation set. Loss: 2.47496
2018-02-05 01:24:27,780 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 264 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.032,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:28,008 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:28,582 __main__ [INFO ] Evaluated on training set. Loss: 1.61902
2018-02-05 01:24:28,608 __main__ [INFO ] Evaluated on validation set. Loss: 2.56591
2018-02-05 01:24:28,608 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 265 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.033,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:28,796 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:29,483 __main__ [INFO ] Evaluated on training set. Loss: 1.64922
2018-02-05 01:24:29,527 __main__ [INFO ] Evaluated on validation set. Loss: 2.47721
2018-02-05 01:24:29,527 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 266 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.033,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:29,824 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:30,470 __main__ [INFO ] Evaluated on training set. Loss: 1.62624
2018-02-05 01:24:30,492 __main__ [INFO ] Evaluated on validation set. Loss: 2.56793
2018-02-05 01:24:30,493 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 267 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.034,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:30,657 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:31,324 __main__ [INFO ] Evaluated on training set. Loss: 1.65528
2018-02-05 01:24:31,349 __main__ [INFO ] Evaluated on validation set. Loss: 2.47951
2018-02-05 01:24:31,349 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 268 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.034,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:31,501 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:32,004 __main__ [INFO ] Evaluated on training set. Loss: 1.63337
2018-02-05 01:24:32,023 __main__ [INFO ] Evaluated on validation set. Loss: 2.57000
2018-02-05 01:24:32,023 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 269 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.035,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:32,227 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:32,877 __main__ [INFO ] Evaluated on training set. Loss: 1.66125
2018-02-05 01:24:32,904 __main__ [INFO ] Evaluated on validation set. Loss: 2.48185
2018-02-05 01:24:32,904 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 270 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.035,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:33,070 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:33,624 __main__ [INFO ] Evaluated on training set. Loss: 1.64041
2018-02-05 01:24:33,643 __main__ [INFO ] Evaluated on validation set. Loss: 2.57213
2018-02-05 01:24:33,643 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 271 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.036,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:33,811 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:34,470 __main__ [INFO ] Evaluated on training set. Loss: 1.66716
2018-02-05 01:24:34,497 __main__ [INFO ] Evaluated on validation set. Loss: 2.48422
2018-02-05 01:24:34,497 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 272 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.036,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:34,710 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:35,230 __main__ [INFO ] Evaluated on training set. Loss: 1.64736
2018-02-05 01:24:35,250 __main__ [INFO ] Evaluated on validation set. Loss: 2.57429
2018-02-05 01:24:35,250 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 273 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.037,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:35,418 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:36,070 __main__ [INFO ] Evaluated on training set. Loss: 1.67299
2018-02-05 01:24:36,095 __main__ [INFO ] Evaluated on validation set. Loss: 2.48663
2018-02-05 01:24:36,095 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 274 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.037,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:36,287 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:36,782 __main__ [INFO ] Evaluated on training set. Loss: 1.65423
2018-02-05 01:24:36,802 __main__ [INFO ] Evaluated on validation set. Loss: 2.57650
2018-02-05 01:24:36,802 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 275 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.038,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:36,961 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:37,714 __main__ [INFO ] Evaluated on training set. Loss: 1.67876
2018-02-05 01:24:37,739 __main__ [INFO ] Evaluated on validation set. Loss: 2.48907
2018-02-05 01:24:37,739 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 276 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.038,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:37,894 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:38,364 __main__ [INFO ] Evaluated on training set. Loss: 1.66102
2018-02-05 01:24:38,382 __main__ [INFO ] Evaluated on validation set. Loss: 2.57874
2018-02-05 01:24:38,382 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 277 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.039,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:38,571 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:39,166 __main__ [INFO ] Evaluated on training set. Loss: 1.68446
2018-02-05 01:24:39,191 __main__ [INFO ] Evaluated on validation set. Loss: 2.49153
2018-02-05 01:24:39,191 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 278 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.039,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:39,356 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:39,911 __main__ [INFO ] Evaluated on training set. Loss: 1.66773
2018-02-05 01:24:39,932 __main__ [INFO ] Evaluated on validation set. Loss: 2.58101
2018-02-05 01:24:39,932 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 279 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.04,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:40,113 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:40,713 __main__ [INFO ] Evaluated on training set. Loss: 1.69009
2018-02-05 01:24:40,738 __main__ [INFO ] Evaluated on validation set. Loss: 2.49402
2018-02-05 01:24:40,738 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 280 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.04,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:40,932 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:41,404 __main__ [INFO ] Evaluated on training set. Loss: 1.67436
2018-02-05 01:24:41,422 __main__ [INFO ] Evaluated on validation set. Loss: 2.58331
2018-02-05 01:24:41,422 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 281 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.041,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:41,574 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:42,166 __main__ [INFO ] Evaluated on training set. Loss: 1.69566
2018-02-05 01:24:42,191 __main__ [INFO ] Evaluated on validation set. Loss: 2.49653
2018-02-05 01:24:42,191 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 282 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.041,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:42,379 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:42,849 __main__ [INFO ] Evaluated on training set. Loss: 1.68092
2018-02-05 01:24:42,867 __main__ [INFO ] Evaluated on validation set. Loss: 2.58564
2018-02-05 01:24:42,868 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 283 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.042,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:43,020 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:43,652 __main__ [INFO ] Evaluated on training set. Loss: 1.70117
2018-02-05 01:24:43,676 __main__ [INFO ] Evaluated on validation set. Loss: 2.49906
2018-02-05 01:24:43,676 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 284 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.042,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:43,828 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:44,298 __main__ [INFO ] Evaluated on training set. Loss: 1.68741
2018-02-05 01:24:44,316 __main__ [INFO ] Evaluated on validation set. Loss: 2.58799
2018-02-05 01:24:44,316 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 285 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.043,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:44,503 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:45,100 __main__ [INFO ] Evaluated on training set. Loss: 1.70662
2018-02-05 01:24:45,124 __main__ [INFO ] Evaluated on validation set. Loss: 2.50161
2018-02-05 01:24:45,124 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 286 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.043,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:45,276 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:45,789 __main__ [INFO ] Evaluated on training set. Loss: 1.69382
2018-02-05 01:24:45,806 __main__ [INFO ] Evaluated on validation set. Loss: 2.59036
2018-02-05 01:24:45,806 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 287 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.044,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:45,962 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:46,558 __main__ [INFO ] Evaluated on training set. Loss: 1.71201
2018-02-05 01:24:46,582 __main__ [INFO ] Evaluated on validation set. Loss: 2.50417
2018-02-05 01:24:46,582 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 288 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.044,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:46,773 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:47,248 __main__ [INFO ] Evaluated on training set. Loss: 1.70017
2018-02-05 01:24:47,265 __main__ [INFO ] Evaluated on validation set. Loss: 2.59275
2018-02-05 01:24:47,265 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 289 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.045,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:47,417 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:48,010 __main__ [INFO ] Evaluated on training set. Loss: 1.71735
2018-02-05 01:24:48,035 __main__ [INFO ] Evaluated on validation set. Loss: 2.50675
2018-02-05 01:24:48,035 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 290 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.045,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:48,220 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:48,694 __main__ [INFO ] Evaluated on training set. Loss: 1.70645
2018-02-05 01:24:48,712 __main__ [INFO ] Evaluated on validation set. Loss: 2.59516
2018-02-05 01:24:48,712 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 291 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.046,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:48,905 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:49,500 __main__ [INFO ] Evaluated on training set. Loss: 1.72263
2018-02-05 01:24:49,525 __main__ [INFO ] Evaluated on validation set. Loss: 2.50933
2018-02-05 01:24:49,525 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 292 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.046,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:49,675 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:50,277 __main__ [INFO ] Evaluated on training set. Loss: 1.71266
2018-02-05 01:24:50,295 __main__ [INFO ] Evaluated on validation set. Loss: 2.59758
2018-02-05 01:24:50,295 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 293 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.047,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:50,484 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:51,079 __main__ [INFO ] Evaluated on training set. Loss: 1.72786
2018-02-05 01:24:51,104 __main__ [INFO ] Evaluated on validation set. Loss: 2.51193
2018-02-05 01:24:51,104 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 294 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.047,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:51,256 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:51,774 __main__ [INFO ] Evaluated on training set. Loss: 1.71881
2018-02-05 01:24:51,792 __main__ [INFO ] Evaluated on validation set. Loss: 2.60002
2018-02-05 01:24:51,792 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 295 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.048,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:51,945 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:52,542 __main__ [INFO ] Evaluated on training set. Loss: 1.73304
2018-02-05 01:24:52,566 __main__ [INFO ] Evaluated on validation set. Loss: 2.51453
2018-02-05 01:24:52,566 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 296 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.048,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:52,756 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:53,227 __main__ [INFO ] Evaluated on training set. Loss: 1.72490
2018-02-05 01:24:53,245 __main__ [INFO ] Evaluated on validation set. Loss: 2.60247
2018-02-05 01:24:53,246 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 297 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.049,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:53,398 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:54,036 __main__ [INFO ] Evaluated on training set. Loss: 1.73817
2018-02-05 01:24:54,060 __main__ [INFO ] Evaluated on validation set. Loss: 2.51714
2018-02-05 01:24:54,060 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 298 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.049,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:54,211 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:54,683 __main__ [INFO ] Evaluated on training set. Loss: 1.73093
2018-02-05 01:24:54,701 __main__ [INFO ] Evaluated on validation set. Loss: 2.60493
2018-02-05 01:24:54,701 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 299 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.05,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:54,894 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:55,492 __main__ [INFO ] Evaluated on training set. Loss: 1.74324
2018-02-05 01:24:55,516 __main__ [INFO ] Evaluated on validation set. Loss: 2.51976
2018-02-05 01:24:55,517 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 300 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.05,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:55,667 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:56,136 __main__ [INFO ] Evaluated on training set. Loss: 1.73690
2018-02-05 01:24:56,153 __main__ [INFO ] Evaluated on validation set. Loss: 2.60740
2018-02-05 01:24:56,153 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 301 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.051,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:56,338 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:56,937 __main__ [INFO ] Evaluated on training set. Loss: 1.74827
2018-02-05 01:24:56,961 __main__ [INFO ] Evaluated on validation set. Loss: 2.52238
2018-02-05 01:24:56,961 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 302 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.051,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:57,118 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:57,662 __main__ [INFO ] Evaluated on training set. Loss: 1.74281
2018-02-05 01:24:57,680 __main__ [INFO ] Evaluated on validation set. Loss: 2.60987
2018-02-05 01:24:57,680 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 303 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.052,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:57,851 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:58,528 __main__ [INFO ] Evaluated on training set. Loss: 1.75325
2018-02-05 01:24:58,554 __main__ [INFO ] Evaluated on validation set. Loss: 2.52501
2018-02-05 01:24:58,554 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 304 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.052,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:58,780 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:24:59,313 __main__ [INFO ] Evaluated on training set. Loss: 1.74866
2018-02-05 01:24:59,337 __main__ [INFO ] Evaluated on validation set. Loss: 2.61235
2018-02-05 01:24:59,337 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 305 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.053,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:24:59,549 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:00,206 __main__ [INFO ] Evaluated on training set. Loss: 1.75819
2018-02-05 01:25:00,232 __main__ [INFO ] Evaluated on validation set. Loss: 2.52764
2018-02-05 01:25:00,232 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 306 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.053,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:00,385 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:00,852 __main__ [INFO ] Evaluated on training set. Loss: 1.75446
2018-02-05 01:25:00,871 __main__ [INFO ] Evaluated on validation set. Loss: 2.61484
2018-02-05 01:25:00,871 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 307 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.054,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:01,060 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:01,712 __main__ [INFO ] Evaluated on training set. Loss: 1.76308
2018-02-05 01:25:01,745 __main__ [INFO ] Evaluated on validation set. Loss: 2.53027
2018-02-05 01:25:01,746 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 308 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.054,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:01,933 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:02,526 __main__ [INFO ] Evaluated on training set. Loss: 1.76021
2018-02-05 01:25:02,559 __main__ [INFO ] Evaluated on validation set. Loss: 2.61734
2018-02-05 01:25:02,560 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 309 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.055,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:02,816 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:03,525 __main__ [INFO ] Evaluated on training set. Loss: 1.76792
2018-02-05 01:25:03,566 __main__ [INFO ] Evaluated on validation set. Loss: 2.53290
2018-02-05 01:25:03,567 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 310 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.055,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:03,816 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:04,391 __main__ [INFO ] Evaluated on training set. Loss: 1.76590
2018-02-05 01:25:04,411 __main__ [INFO ] Evaluated on validation set. Loss: 2.61983
2018-02-05 01:25:04,411 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 311 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.056,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:04,595 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:05,309 __main__ [INFO ] Evaluated on training set. Loss: 1.77273
2018-02-05 01:25:05,337 __main__ [INFO ] Evaluated on validation set. Loss: 2.53553
2018-02-05 01:25:05,338 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 312 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.056,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:05,601 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:06,152 __main__ [INFO ] Evaluated on training set. Loss: 1.77154
2018-02-05 01:25:06,171 __main__ [INFO ] Evaluated on validation set. Loss: 2.62233
2018-02-05 01:25:06,171 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 313 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.057,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:06,397 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:07,127 __main__ [INFO ] Evaluated on training set. Loss: 1.77749
2018-02-05 01:25:07,154 __main__ [INFO ] Evaluated on validation set. Loss: 2.53817
2018-02-05 01:25:07,154 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 314 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.057,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:07,324 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:07,812 __main__ [INFO ] Evaluated on training set. Loss: 1.77714
2018-02-05 01:25:07,830 __main__ [INFO ] Evaluated on validation set. Loss: 2.62484
2018-02-05 01:25:07,831 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 315 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.058,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:08,023 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:08,684 __main__ [INFO ] Evaluated on training set. Loss: 1.78221
2018-02-05 01:25:08,709 __main__ [INFO ] Evaluated on validation set. Loss: 2.54080
2018-02-05 01:25:08,710 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 316 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.058,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:08,864 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:09,375 __main__ [INFO ] Evaluated on training set. Loss: 1.78268
2018-02-05 01:25:09,394 __main__ [INFO ] Evaluated on validation set. Loss: 2.62734
2018-02-05 01:25:09,394 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 317 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.059,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:09,549 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:10,144 __main__ [INFO ] Evaluated on training set. Loss: 1.78689
2018-02-05 01:25:10,169 __main__ [INFO ] Evaluated on validation set. Loss: 2.54343
2018-02-05 01:25:10,170 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 318 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.059,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:10,364 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:10,842 __main__ [INFO ] Evaluated on training set. Loss: 1.78817
2018-02-05 01:25:10,860 __main__ [INFO ] Evaluated on validation set. Loss: 2.62985
2018-02-05 01:25:10,861 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 319 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.06,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:11,014 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:11,614 __main__ [INFO ] Evaluated on training set. Loss: 1.79153
2018-02-05 01:25:11,641 __main__ [INFO ] Evaluated on validation set. Loss: 2.54606
2018-02-05 01:25:11,641 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 320 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.06,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:11,857 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:12,377 __main__ [INFO ] Evaluated on training set. Loss: 1.79362
2018-02-05 01:25:12,397 __main__ [INFO ] Evaluated on validation set. Loss: 2.63235
2018-02-05 01:25:12,397 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 321 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.061,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:12,574 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:13,269 __main__ [INFO ] Evaluated on training set. Loss: 1.79613
2018-02-05 01:25:13,296 __main__ [INFO ] Evaluated on validation set. Loss: 2.54869
2018-02-05 01:25:13,296 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 322 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.061,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:13,467 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:13,982 __main__ [INFO ] Evaluated on training set. Loss: 1.79902
2018-02-05 01:25:14,002 __main__ [INFO ] Evaluated on validation set. Loss: 2.63486
2018-02-05 01:25:14,002 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 323 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.062,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:14,211 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:14,864 __main__ [INFO ] Evaluated on training set. Loss: 1.80070
2018-02-05 01:25:14,892 __main__ [INFO ] Evaluated on validation set. Loss: 2.55132
2018-02-05 01:25:14,892 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 324 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.062,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:15,059 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:15,612 __main__ [INFO ] Evaluated on training set. Loss: 1.80438
2018-02-05 01:25:15,632 __main__ [INFO ] Evaluated on validation set. Loss: 2.63736
2018-02-05 01:25:15,632 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 325 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.063,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:15,791 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:16,387 __main__ [INFO ] Evaluated on training set. Loss: 1.80522
2018-02-05 01:25:16,412 __main__ [INFO ] Evaluated on validation set. Loss: 2.55394
2018-02-05 01:25:16,412 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 326 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.063,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:16,609 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:17,086 __main__ [INFO ] Evaluated on training set. Loss: 1.80969
2018-02-05 01:25:17,104 __main__ [INFO ] Evaluated on validation set. Loss: 2.63987
2018-02-05 01:25:17,105 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 327 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.064,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:17,258 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:17,846 __main__ [INFO ] Evaluated on training set. Loss: 1.80971
2018-02-05 01:25:17,872 __main__ [INFO ] Evaluated on validation set. Loss: 2.55656
2018-02-05 01:25:17,872 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 328 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.064,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:18,061 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:18,536 __main__ [INFO ] Evaluated on training set. Loss: 1.81496
2018-02-05 01:25:18,554 __main__ [INFO ] Evaluated on validation set. Loss: 2.64237
2018-02-05 01:25:18,555 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 329 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.065,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:18,748 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:19,348 __main__ [INFO ] Evaluated on training set. Loss: 1.81417
2018-02-05 01:25:19,373 __main__ [INFO ] Evaluated on validation set. Loss: 2.55917
2018-02-05 01:25:19,374 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 330 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.065,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:19,527 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:20,001 __main__ [INFO ] Evaluated on training set. Loss: 1.82018
2018-02-05 01:25:20,019 __main__ [INFO ] Evaluated on validation set. Loss: 2.64487
2018-02-05 01:25:20,019 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 331 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.066,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:20,212 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:20,809 __main__ [INFO ] Evaluated on training set. Loss: 1.81859
2018-02-05 01:25:20,834 __main__ [INFO ] Evaluated on validation set. Loss: 2.56179
2018-02-05 01:25:20,835 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 332 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.066,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:20,990 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:21,511 __main__ [INFO ] Evaluated on training set. Loss: 1.82536
2018-02-05 01:25:21,529 __main__ [INFO ] Evaluated on validation set. Loss: 2.64737
2018-02-05 01:25:21,529 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 333 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.067,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:21,683 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:22,281 __main__ [INFO ] Evaluated on training set. Loss: 1.82298
2018-02-05 01:25:22,305 __main__ [INFO ] Evaluated on validation set. Loss: 2.56439
2018-02-05 01:25:22,306 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 334 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.067,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:22,504 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:22,982 __main__ [INFO ] Evaluated on training set. Loss: 1.83051
2018-02-05 01:25:23,000 __main__ [INFO ] Evaluated on validation set. Loss: 2.64987
2018-02-05 01:25:23,000 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 335 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.068,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:23,153 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:23,784 __main__ [INFO ] Evaluated on training set. Loss: 1.82733
2018-02-05 01:25:23,809 __main__ [INFO ] Evaluated on validation set. Loss: 2.56700
2018-02-05 01:25:23,809 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 336 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.068,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:23,964 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:24,435 __main__ [INFO ] Evaluated on training set. Loss: 1.83561
2018-02-05 01:25:24,453 __main__ [INFO ] Evaluated on validation set. Loss: 2.65236
2018-02-05 01:25:24,454 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 337 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.069,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:24,645 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:25,244 __main__ [INFO ] Evaluated on training set. Loss: 1.83165
2018-02-05 01:25:25,268 __main__ [INFO ] Evaluated on validation set. Loss: 2.56959
2018-02-05 01:25:25,269 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 338 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.069,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:25,425 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:25,899 __main__ [INFO ] Evaluated on training set. Loss: 1.84067
2018-02-05 01:25:25,918 __main__ [INFO ] Evaluated on validation set. Loss: 2.65485
2018-02-05 01:25:25,918 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 339 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.07,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:26,105 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:26,698 __main__ [INFO ] Evaluated on training set. Loss: 1.83593
2018-02-05 01:25:26,724 __main__ [INFO ] Evaluated on validation set. Loss: 2.57219
2018-02-05 01:25:26,724 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 340 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.07,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:26,881 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:27,409 __main__ [INFO ] Evaluated on training set. Loss: 1.84569
2018-02-05 01:25:27,428 __main__ [INFO ] Evaluated on validation set. Loss: 2.65733
2018-02-05 01:25:27,428 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 341 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.071,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:27,585 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:28,188 __main__ [INFO ] Evaluated on training set. Loss: 1.84019
2018-02-05 01:25:28,213 __main__ [INFO ] Evaluated on validation set. Loss: 2.57477
2018-02-05 01:25:28,213 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 342 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.071,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:28,412 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:28,894 __main__ [INFO ] Evaluated on training set. Loss: 1.85068
2018-02-05 01:25:28,912 __main__ [INFO ] Evaluated on validation set. Loss: 2.65982
2018-02-05 01:25:28,912 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 343 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.072,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:29,070 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:29,723 __main__ [INFO ] Evaluated on training set. Loss: 1.84441
2018-02-05 01:25:29,748 __main__ [INFO ] Evaluated on validation set. Loss: 2.57736
2018-02-05 01:25:29,748 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 344 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.072,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:29,906 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:30,374 __main__ [INFO ] Evaluated on training set. Loss: 1.85562
2018-02-05 01:25:30,392 __main__ [INFO ] Evaluated on validation set. Loss: 2.66229
2018-02-05 01:25:30,392 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 345 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.073,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:30,587 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:31,189 __main__ [INFO ] Evaluated on training set. Loss: 1.84861
2018-02-05 01:25:31,214 __main__ [INFO ] Evaluated on validation set. Loss: 2.57993
2018-02-05 01:25:31,214 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 346 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.073,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:31,376 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:31,847 __main__ [INFO ] Evaluated on training set. Loss: 1.86053
2018-02-05 01:25:31,865 __main__ [INFO ] Evaluated on validation set. Loss: 2.66477
2018-02-05 01:25:31,866 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 347 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.074,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:32,074 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:32,672 __main__ [INFO ] Evaluated on training set. Loss: 1.85277
2018-02-05 01:25:32,697 __main__ [INFO ] Evaluated on validation set. Loss: 2.58250
2018-02-05 01:25:32,697 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 348 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.074,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:32,850 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:33,370 __main__ [INFO ] Evaluated on training set. Loss: 1.86541
2018-02-05 01:25:33,389 __main__ [INFO ] Evaluated on validation set. Loss: 2.66724
2018-02-05 01:25:33,389 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 349 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.075,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:33,554 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:34,162 __main__ [INFO ] Evaluated on training set. Loss: 1.85690
2018-02-05 01:25:34,187 __main__ [INFO ] Evaluated on validation set. Loss: 2.58507
2018-02-05 01:25:34,187 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 350 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.075,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:34,404 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:34,907 __main__ [INFO ] Evaluated on training set. Loss: 1.87025
2018-02-05 01:25:34,925 __main__ [INFO ] Evaluated on validation set. Loss: 2.66970
2018-02-05 01:25:34,925 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 351 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.076,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:35,106 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:35,775 __main__ [INFO ] Evaluated on training set. Loss: 1.86101
2018-02-05 01:25:35,802 __main__ [INFO ] Evaluated on validation set. Loss: 2.58763
2018-02-05 01:25:35,802 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 352 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.076,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:35,974 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:36,509 __main__ [INFO ] Evaluated on training set. Loss: 1.87505
2018-02-05 01:25:36,528 __main__ [INFO ] Evaluated on validation set. Loss: 2.67216
2018-02-05 01:25:36,528 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 353 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.077,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:36,749 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:37,428 __main__ [INFO ] Evaluated on training set. Loss: 1.86508
2018-02-05 01:25:37,456 __main__ [INFO ] Evaluated on validation set. Loss: 2.59018
2018-02-05 01:25:37,456 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 354 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.077,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:37,658 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:38,199 __main__ [INFO ] Evaluated on training set. Loss: 1.87982
2018-02-05 01:25:38,219 __main__ [INFO ] Evaluated on validation set. Loss: 2.67462
2018-02-05 01:25:38,219 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 355 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.078,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:38,432 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:39,125 __main__ [INFO ] Evaluated on training set. Loss: 1.86913
2018-02-05 01:25:39,155 __main__ [INFO ] Evaluated on validation set. Loss: 2.59272
2018-02-05 01:25:39,156 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 356 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.078,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:39,438 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:40,027 __main__ [INFO ] Evaluated on training set. Loss: 1.88456
2018-02-05 01:25:40,052 __main__ [INFO ] Evaluated on validation set. Loss: 2.67706
2018-02-05 01:25:40,052 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 357 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.079,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:40,261 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:40,992 __main__ [INFO ] Evaluated on training set. Loss: 1.87315
2018-02-05 01:25:41,018 __main__ [INFO ] Evaluated on validation set. Loss: 2.59526
2018-02-05 01:25:41,019 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 358 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.079,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:41,244 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:41,815 __main__ [INFO ] Evaluated on training set. Loss: 1.88926
2018-02-05 01:25:41,838 __main__ [INFO ] Evaluated on validation set. Loss: 2.67951
2018-02-05 01:25:41,839 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 359 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.08,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:42,073 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:42,817 __main__ [INFO ] Evaluated on training set. Loss: 1.87714
2018-02-05 01:25:42,845 __main__ [INFO ] Evaluated on validation set. Loss: 2.59780
2018-02-05 01:25:42,845 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 360 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.08,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:43,036 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:43,593 __main__ [INFO ] Evaluated on training set. Loss: 1.89393
2018-02-05 01:25:43,613 __main__ [INFO ] Evaluated on validation set. Loss: 2.68195
2018-02-05 01:25:43,613 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 361 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.081,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:43,856 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:44,563 __main__ [INFO ] Evaluated on training set. Loss: 1.88111
2018-02-05 01:25:44,590 __main__ [INFO ] Evaluated on validation set. Loss: 2.60032
2018-02-05 01:25:44,590 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 362 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.081,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:44,801 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:45,437 __main__ [INFO ] Evaluated on training set. Loss: 1.89856
2018-02-05 01:25:45,458 __main__ [INFO ] Evaluated on validation set. Loss: 2.68438
2018-02-05 01:25:45,458 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 363 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.082,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:45,666 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:46,391 __main__ [INFO ] Evaluated on training set. Loss: 1.88505
2018-02-05 01:25:46,422 __main__ [INFO ] Evaluated on validation set. Loss: 2.60284
2018-02-05 01:25:46,422 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 364 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.082,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:46,677 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:47,263 __main__ [INFO ] Evaluated on training set. Loss: 1.90317
2018-02-05 01:25:47,285 __main__ [INFO ] Evaluated on validation set. Loss: 2.68681
2018-02-05 01:25:47,286 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 365 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.083,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:47,532 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:48,197 __main__ [INFO ] Evaluated on training set. Loss: 1.88896
2018-02-05 01:25:48,223 __main__ [INFO ] Evaluated on validation set. Loss: 2.60535
2018-02-05 01:25:48,224 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 366 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.083,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:48,493 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:49,042 __main__ [INFO ] Evaluated on training set. Loss: 1.90774
2018-02-05 01:25:49,062 __main__ [INFO ] Evaluated on validation set. Loss: 2.68923
2018-02-05 01:25:49,062 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 367 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.084,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:49,257 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:49,992 __main__ [INFO ] Evaluated on training set. Loss: 1.89285
2018-02-05 01:25:50,020 __main__ [INFO ] Evaluated on validation set. Loss: 2.60786
2018-02-05 01:25:50,021 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 368 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.084,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:50,248 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:50,791 __main__ [INFO ] Evaluated on training set. Loss: 1.91229
2018-02-05 01:25:50,811 __main__ [INFO ] Evaluated on validation set. Loss: 2.69164
2018-02-05 01:25:50,812 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 369 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.085,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:51,068 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:51,752 __main__ [INFO ] Evaluated on training set. Loss: 1.89671
2018-02-05 01:25:51,780 __main__ [INFO ] Evaluated on validation set. Loss: 2.61035
2018-02-05 01:25:51,780 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 370 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.085,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:51,970 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:52,561 __main__ [INFO ] Evaluated on training set. Loss: 1.91680
2018-02-05 01:25:52,580 __main__ [INFO ] Evaluated on validation set. Loss: 2.69405
2018-02-05 01:25:52,581 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 371 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.086,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:52,777 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:53,423 __main__ [INFO ] Evaluated on training set. Loss: 1.90055
2018-02-05 01:25:53,450 __main__ [INFO ] Evaluated on validation set. Loss: 2.61285
2018-02-05 01:25:53,450 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 372 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.086,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:53,679 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:54,225 __main__ [INFO ] Evaluated on training set. Loss: 1.92129
2018-02-05 01:25:54,245 __main__ [INFO ] Evaluated on validation set. Loss: 2.69646
2018-02-05 01:25:54,245 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 373 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.087,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:54,421 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:55,073 __main__ [INFO ] Evaluated on training set. Loss: 1.90436
2018-02-05 01:25:55,100 __main__ [INFO ] Evaluated on validation set. Loss: 2.61533
2018-02-05 01:25:55,100 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 374 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.087,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:55,319 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:55,837 __main__ [INFO ] Evaluated on training set. Loss: 1.92574
2018-02-05 01:25:55,857 __main__ [INFO ] Evaluated on validation set. Loss: 2.69885
2018-02-05 01:25:55,857 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 375 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.088,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:56,083 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:56,737 __main__ [INFO ] Evaluated on training set. Loss: 1.90815
2018-02-05 01:25:56,764 __main__ [INFO ] Evaluated on validation set. Loss: 2.61781
2018-02-05 01:25:56,764 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 376 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.088,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:56,957 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:57,474 __main__ [INFO ] Evaluated on training set. Loss: 1.93017
2018-02-05 01:25:57,494 __main__ [INFO ] Evaluated on validation set. Loss: 2.70124
2018-02-05 01:25:57,494 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 377 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.089,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:57,716 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:58,361 __main__ [INFO ] Evaluated on training set. Loss: 1.91192
2018-02-05 01:25:58,386 __main__ [INFO ] Evaluated on validation set. Loss: 2.62028
2018-02-05 01:25:58,387 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 378 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.089,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:58,561 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:59,118 __main__ [INFO ] Evaluated on training set. Loss: 1.93456
2018-02-05 01:25:59,138 __main__ [INFO ] Evaluated on validation set. Loss: 2.70363
2018-02-05 01:25:59,138 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 379 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.09,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:25:59,306 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:25:59,940 __main__ [INFO ] Evaluated on training set. Loss: 1.91566
2018-02-05 01:25:59,967 __main__ [INFO ] Evaluated on validation set. Loss: 2.62274
2018-02-05 01:25:59,967 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 380 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.09,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:00,187 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:00,696 __main__ [INFO ] Evaluated on training set. Loss: 1.93893
2018-02-05 01:26:00,714 __main__ [INFO ] Evaluated on validation set. Loss: 2.70601
2018-02-05 01:26:00,715 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 381 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.091,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:00,877 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:01,558 __main__ [INFO ] Evaluated on training set. Loss: 1.91938
2018-02-05 01:26:01,584 __main__ [INFO ] Evaluated on validation set. Loss: 2.62519
2018-02-05 01:26:01,584 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 382 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.091,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:01,749 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:02,233 __main__ [INFO ] Evaluated on training set. Loss: 1.94327
2018-02-05 01:26:02,251 __main__ [INFO ] Evaluated on validation set. Loss: 2.70838
2018-02-05 01:26:02,251 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 383 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.092,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:02,459 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:03,142 __main__ [INFO ] Evaluated on training set. Loss: 1.92308
2018-02-05 01:26:03,171 __main__ [INFO ] Evaluated on validation set. Loss: 2.62764
2018-02-05 01:26:03,172 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 384 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.092,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:03,348 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:03,850 __main__ [INFO ] Evaluated on training set. Loss: 1.94759
2018-02-05 01:26:03,868 __main__ [INFO ] Evaluated on validation set. Loss: 2.71074
2018-02-05 01:26:03,869 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 385 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.093,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:04,065 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:04,684 __main__ [INFO ] Evaluated on training set. Loss: 1.92675
2018-02-05 01:26:04,710 __main__ [INFO ] Evaluated on validation set. Loss: 2.63008
2018-02-05 01:26:04,710 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 386 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.093,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:04,878 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:05,415 __main__ [INFO ] Evaluated on training set. Loss: 1.95188
2018-02-05 01:26:05,433 __main__ [INFO ] Evaluated on validation set. Loss: 2.71310
2018-02-05 01:26:05,434 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 387 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.094,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:05,595 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:06,203 __main__ [INFO ] Evaluated on training set. Loss: 1.93041
2018-02-05 01:26:06,229 __main__ [INFO ] Evaluated on validation set. Loss: 2.63251
2018-02-05 01:26:06,230 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 388 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.094,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:06,430 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:06,949 __main__ [INFO ] Evaluated on training set. Loss: 1.95614
2018-02-05 01:26:06,971 __main__ [INFO ] Evaluated on validation set. Loss: 2.71546
2018-02-05 01:26:06,971 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 389 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.095,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:07,179 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:07,899 __main__ [INFO ] Evaluated on training set. Loss: 1.93404
2018-02-05 01:26:07,929 __main__ [INFO ] Evaluated on validation set. Loss: 2.63494
2018-02-05 01:26:07,930 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 390 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.095,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:08,115 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:08,629 __main__ [INFO ] Evaluated on training set. Loss: 1.96037
2018-02-05 01:26:08,648 __main__ [INFO ] Evaluated on validation set. Loss: 2.71780
2018-02-05 01:26:08,648 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 391 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.096,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:08,865 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:09,502 __main__ [INFO ] Evaluated on training set. Loss: 1.93765
2018-02-05 01:26:09,529 __main__ [INFO ] Evaluated on validation set. Loss: 2.63736
2018-02-05 01:26:09,529 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 392 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.096,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:09,705 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:10,208 __main__ [INFO ] Evaluated on training set. Loss: 1.96458
2018-02-05 01:26:10,229 __main__ [INFO ] Evaluated on validation set. Loss: 2.72014
2018-02-05 01:26:10,230 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 393 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.097,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:10,459 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:11,111 __main__ [INFO ] Evaluated on training set. Loss: 1.94124
2018-02-05 01:26:11,136 __main__ [INFO ] Evaluated on validation set. Loss: 2.63977
2018-02-05 01:26:11,136 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 394 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.097,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:11,347 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:11,877 __main__ [INFO ] Evaluated on training set. Loss: 1.96876
2018-02-05 01:26:11,896 __main__ [INFO ] Evaluated on validation set. Loss: 2.72247
2018-02-05 01:26:11,897 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 395 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.098,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:12,071 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:12,710 __main__ [INFO ] Evaluated on training set. Loss: 1.94480
2018-02-05 01:26:12,736 __main__ [INFO ] Evaluated on validation set. Loss: 2.64217
2018-02-05 01:26:12,736 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 396 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.098,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:12,940 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:13,451 __main__ [INFO ] Evaluated on training set. Loss: 1.97292
2018-02-05 01:26:13,472 __main__ [INFO ] Evaluated on validation set. Loss: 2.72480
2018-02-05 01:26:13,472 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 397 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.099,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:13,664 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:14,371 __main__ [INFO ] Evaluated on training set. Loss: 1.94835
2018-02-05 01:26:14,399 __main__ [INFO ] Evaluated on validation set. Loss: 2.64457
2018-02-05 01:26:14,399 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 398 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.099,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:14,593 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:15,136 __main__ [INFO ] Evaluated on training set. Loss: 1.97706
2018-02-05 01:26:15,156 __main__ [INFO ] Evaluated on validation set. Loss: 2.72712
2018-02-05 01:26:15,156 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 399 out of 400 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:15,396 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:16,056 __main__ [INFO ] Evaluated on training set. Loss: 1.95188
2018-02-05 01:26:16,082 __main__ [INFO ] Evaluated on validation set. Loss: 2.64696
2018-02-05 01:26:16,083 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 400 out of 400 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:26:16,259 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:26:16,823 __main__ [INFO ] Evaluated on training set. Loss: 1.98117
2018-02-05 01:26:16,844 __main__ [INFO ] Evaluated on validation set. Loss: 2.72943
2018-02-05 01:28:04,553 __main__ [INFO ] 
==============================
Starting experiment alice_test_n_gram
==============================
2018-02-05 01:28:04,557 __main__ [INFO ] Removing old results directory ./experiments/alice_test_n_gram/out
2018-02-05 01:28:04,560 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 01:28:04,659 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:05,024 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 01:28:05,046 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 01:28:05,046 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 01:28:05,145 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:05,420 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 01:28:05,436 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 01:28:05,436 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 01:28:05,535 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:05,899 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 01:28:05,919 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 01:28:05,919 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 01:28:06,017 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:06,347 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 01:28:06,363 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 01:28:06,363 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 1
}
--------------------------------------------------
2018-02-05 01:28:06,464 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:06,827 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 01:28:06,848 __main__ [INFO ] Evaluated on validation set. Loss: 4.59312
2018-02-05 01:28:06,848 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 1
}
--------------------------------------------------
2018-02-05 01:28:06,947 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:07,231 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 01:28:07,246 __main__ [INFO ] Evaluated on validation set. Loss: 4.59440
2018-02-05 01:28:07,247 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 1
}
--------------------------------------------------
2018-02-05 01:28:07,345 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:07,713 __main__ [INFO ] Evaluated on training set. Loss: 4.50780
2018-02-05 01:28:07,733 __main__ [INFO ] Evaluated on validation set. Loss: 4.59304
2018-02-05 01:28:07,733 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 1
}
--------------------------------------------------
2018-02-05 01:28:07,832 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:08,103 __main__ [INFO ] Evaluated on training set. Loss: 4.50756
2018-02-05 01:28:08,118 __main__ [INFO ] Evaluated on validation set. Loss: 4.59430
2018-02-05 01:28:08,119 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 01:28:08,225 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:08,612 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 01:28:08,634 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 01:28:08,634 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 01:28:08,740 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:09,049 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 01:28:09,065 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 01:28:09,066 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 01:28:09,174 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:09,568 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 01:28:09,589 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 01:28:09,589 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 01:28:09,697 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:09,976 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 01:28:09,992 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 01:28:09,992 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 2
}
--------------------------------------------------
2018-02-05 01:28:10,096 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:10,482 __main__ [INFO ] Evaluated on training set. Loss: 3.50775
2018-02-05 01:28:10,504 __main__ [INFO ] Evaluated on validation set. Loss: 3.53111
2018-02-05 01:28:10,504 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 2
}
--------------------------------------------------
2018-02-05 01:28:10,608 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:10,890 __main__ [INFO ] Evaluated on training set. Loss: 3.50443
2018-02-05 01:28:10,906 __main__ [INFO ] Evaluated on validation set. Loss: 3.53905
2018-02-05 01:28:10,906 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 2
}
--------------------------------------------------
2018-02-05 01:28:11,011 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:11,394 __main__ [INFO ] Evaluated on training set. Loss: 3.52796
2018-02-05 01:28:11,416 __main__ [INFO ] Evaluated on validation set. Loss: 3.55867
2018-02-05 01:28:11,416 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 2
}
--------------------------------------------------
2018-02-05 01:28:11,520 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:11,798 __main__ [INFO ] Evaluated on training set. Loss: 3.53310
2018-02-05 01:28:11,813 __main__ [INFO ] Evaluated on validation set. Loss: 3.56515
2018-02-05 01:28:11,814 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 01:28:11,941 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:12,381 __main__ [INFO ] Evaluated on training set. Loss: 2.52835
2018-02-05 01:28:12,405 __main__ [INFO ] Evaluated on validation set. Loss: 2.68919
2018-02-05 01:28:12,405 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 01:28:12,535 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:12,849 __main__ [INFO ] Evaluated on training set. Loss: 2.50673
2018-02-05 01:28:12,866 __main__ [INFO ] Evaluated on validation set. Loss: 2.73057
2018-02-05 01:28:12,867 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 01:28:12,994 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:13,434 __main__ [INFO ] Evaluated on training set. Loss: 2.53413
2018-02-05 01:28:13,459 __main__ [INFO ] Evaluated on validation set. Loss: 2.65083
2018-02-05 01:28:13,459 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 01:28:13,591 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:13,914 __main__ [INFO ] Evaluated on training set. Loss: 2.51428
2018-02-05 01:28:13,931 __main__ [INFO ] Evaluated on validation set. Loss: 2.68495
2018-02-05 01:28:13,932 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 21 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 3
}
--------------------------------------------------
2018-02-05 01:28:14,245 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:14,720 __main__ [INFO ] Evaluated on training set. Loss: 2.57466
2018-02-05 01:28:14,747 __main__ [INFO ] Evaluated on validation set. Loss: 2.66467
2018-02-05 01:28:14,747 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 22 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 3
}
--------------------------------------------------
2018-02-05 01:28:14,914 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:15,242 __main__ [INFO ] Evaluated on training set. Loss: 2.56789
2018-02-05 01:28:15,260 __main__ [INFO ] Evaluated on validation set. Loss: 2.69204
2018-02-05 01:28:15,260 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 23 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 3
}
--------------------------------------------------
2018-02-05 01:28:15,393 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:15,857 __main__ [INFO ] Evaluated on training set. Loss: 2.78206
2018-02-05 01:28:15,881 __main__ [INFO ] Evaluated on validation set. Loss: 2.90272
2018-02-05 01:28:15,882 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 24 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 3
}
--------------------------------------------------
2018-02-05 01:28:16,015 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:16,336 __main__ [INFO ] Evaluated on training set. Loss: 2.83507
2018-02-05 01:28:16,353 __main__ [INFO ] Evaluated on validation set. Loss: 2.92732
2018-02-05 01:28:16,354 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 25 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:28:16,500 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:17,053 __main__ [INFO ] Evaluated on training set. Loss: 1.83746
2018-02-05 01:28:17,080 __main__ [INFO ] Evaluated on validation set. Loss: 2.42074
2018-02-05 01:28:17,081 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 26 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:28:17,281 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:17,687 __main__ [INFO ] Evaluated on training set. Loss: 1.78918
2018-02-05 01:28:17,706 __main__ [INFO ] Evaluated on validation set. Loss: 2.52118
2018-02-05 01:28:17,706 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 27 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:28:17,855 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:18,399 __main__ [INFO ] Evaluated on training set. Loss: 1.87039
2018-02-05 01:28:18,424 __main__ [INFO ] Evaluated on validation set. Loss: 2.30218
2018-02-05 01:28:18,425 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 28 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:28:18,569 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:19,010 __main__ [INFO ] Evaluated on training set. Loss: 1.82971
2018-02-05 01:28:19,029 __main__ [INFO ] Evaluated on validation set. Loss: 2.38176
2018-02-05 01:28:19,029 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 29 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:28:19,180 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:19,718 __main__ [INFO ] Evaluated on training set. Loss: 2.06434
2018-02-05 01:28:19,745 __main__ [INFO ] Evaluated on validation set. Loss: 2.38532
2018-02-05 01:28:19,745 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 30 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:28:19,892 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:20,384 __main__ [INFO ] Evaluated on training set. Loss: 2.07064
2018-02-05 01:28:20,403 __main__ [INFO ] Evaluated on validation set. Loss: 2.44743
2018-02-05 01:28:20,403 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 31 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:28:20,557 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:21,091 __main__ [INFO ] Evaluated on training set. Loss: 2.74820
2018-02-05 01:28:21,116 __main__ [INFO ] Evaluated on validation set. Loss: 3.05124
2018-02-05 01:28:21,117 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 32 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 4
}
--------------------------------------------------
2018-02-05 01:28:21,261 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:21,648 __main__ [INFO ] Evaluated on training set. Loss: 2.88516
2018-02-05 01:28:21,667 __main__ [INFO ] Evaluated on validation set. Loss: 3.10142
2018-02-05 01:28:21,667 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 33 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:28:21,832 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:22,522 __main__ [INFO ] Evaluated on training set. Loss: 1.38630
2018-02-05 01:28:22,548 __main__ [INFO ] Evaluated on validation set. Loss: 2.67920
2018-02-05 01:28:22,549 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 34 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:28:22,721 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:23,260 __main__ [INFO ] Evaluated on training set. Loss: 1.31779
2018-02-05 01:28:23,281 __main__ [INFO ] Evaluated on validation set. Loss: 2.79794
2018-02-05 01:28:23,281 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 35 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:28:23,508 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:24,175 __main__ [INFO ] Evaluated on training set. Loss: 1.48051
2018-02-05 01:28:24,203 __main__ [INFO ] Evaluated on validation set. Loss: 2.46406
2018-02-05 01:28:24,203 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 36 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:28:24,371 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:24,942 __main__ [INFO ] Evaluated on training set. Loss: 1.42771
2018-02-05 01:28:24,962 __main__ [INFO ] Evaluated on validation set. Loss: 2.56396
2018-02-05 01:28:24,962 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 37 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:28:25,134 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:25,794 __main__ [INFO ] Evaluated on training set. Loss: 1.95188
2018-02-05 01:28:25,822 __main__ [INFO ] Evaluated on validation set. Loss: 2.64696
2018-02-05 01:28:25,822 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 38 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:28:26,053 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:26,594 __main__ [INFO ] Evaluated on training set. Loss: 1.98117
2018-02-05 01:28:26,614 __main__ [INFO ] Evaluated on validation set. Loss: 2.72943
2018-02-05 01:28:26,614 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 39 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:28:26,790 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:27,466 __main__ [INFO ] Evaluated on training set. Loss: 3.15290
2018-02-05 01:28:27,494 __main__ [INFO ] Evaluated on validation set. Loss: 3.61724
2018-02-05 01:28:27,494 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 40 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 5
}
--------------------------------------------------
2018-02-05 01:28:27,714 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:28,258 __main__ [INFO ] Evaluated on training set. Loss: 3.33047
2018-02-05 01:28:28,279 __main__ [INFO ] Evaluated on validation set. Loss: 3.67874
2018-02-05 01:28:28,279 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 41 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 6
}
--------------------------------------------------
2018-02-05 01:28:28,545 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:29,391 __main__ [INFO ] Evaluated on training set. Loss: 1.05625
2018-02-05 01:28:29,419 __main__ [INFO ] Evaluated on validation set. Loss: 3.07878
2018-02-05 01:28:29,420 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 42 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 6
}
--------------------------------------------------
2018-02-05 01:28:29,671 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:30,403 __main__ [INFO ] Evaluated on training set. Loss: 0.98492
2018-02-05 01:28:30,425 __main__ [INFO ] Evaluated on validation set. Loss: 3.21457
2018-02-05 01:28:30,426 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 43 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 6
}
--------------------------------------------------
2018-02-05 01:28:30,670 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:31,585 __main__ [INFO ] Evaluated on training set. Loss: 1.23781
2018-02-05 01:28:31,614 __main__ [INFO ] Evaluated on validation set. Loss: 2.84237
2018-02-05 01:28:31,614 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 44 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 6
}
--------------------------------------------------
2018-02-05 01:28:31,825 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:32,586 __main__ [INFO ] Evaluated on training set. Loss: 1.18767
2018-02-05 01:28:32,608 __main__ [INFO ] Evaluated on validation set. Loss: 2.96093
2018-02-05 01:28:32,608 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 45 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 6
}
--------------------------------------------------
2018-02-05 01:28:32,877 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:33,709 __main__ [INFO ] Evaluated on training set. Loss: 2.03351
2018-02-05 01:28:33,738 __main__ [INFO ] Evaluated on validation set. Loss: 3.12482
2018-02-05 01:28:33,738 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 46 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 6
}
--------------------------------------------------
2018-02-05 01:28:33,997 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:34,711 __main__ [INFO ] Evaluated on training set. Loss: 2.08034
2018-02-05 01:28:34,733 __main__ [INFO ] Evaluated on validation set. Loss: 3.22148
2018-02-05 01:28:34,734 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 47 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 6
}
--------------------------------------------------
2018-02-05 01:28:34,985 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:35,863 __main__ [INFO ] Evaluated on training set. Loss: 3.62050
2018-02-05 01:28:35,890 __main__ [INFO ] Evaluated on validation set. Loss: 4.18999
2018-02-05 01:28:35,891 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 48 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 6
}
--------------------------------------------------
2018-02-05 01:28:36,094 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:36,859 __main__ [INFO ] Evaluated on training set. Loss: 3.79562
2018-02-05 01:28:36,881 __main__ [INFO ] Evaluated on validation set. Loss: 4.25463
2018-02-05 01:28:36,881 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 49 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 7
}
--------------------------------------------------
2018-02-05 01:28:37,162 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:38,229 __main__ [INFO ] Evaluated on training set. Loss: 0.80592
2018-02-05 01:28:38,265 __main__ [INFO ] Evaluated on validation set. Loss: 3.56593
2018-02-05 01:28:38,265 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 50 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 7
}
--------------------------------------------------
2018-02-05 01:28:38,592 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:39,540 __main__ [INFO ] Evaluated on training set. Loss: 0.73984
2018-02-05 01:28:39,563 __main__ [INFO ] Evaluated on validation set. Loss: 3.70812
2018-02-05 01:28:39,563 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 51 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 7
}
--------------------------------------------------
2018-02-05 01:28:39,922 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:40,965 __main__ [INFO ] Evaluated on training set. Loss: 1.07876
2018-02-05 01:28:40,995 __main__ [INFO ] Evaluated on validation set. Loss: 3.33480
2018-02-05 01:28:40,995 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 52 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 7
}
--------------------------------------------------
2018-02-05 01:28:41,276 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:42,219 __main__ [INFO ] Evaluated on training set. Loss: 1.03562
2018-02-05 01:28:42,242 __main__ [INFO ] Evaluated on validation set. Loss: 3.46293
2018-02-05 01:28:42,242 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 53 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 7
}
--------------------------------------------------
2018-02-05 01:28:42,522 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:43,582 __main__ [INFO ] Evaluated on training set. Loss: 2.17195
2018-02-05 01:28:43,613 __main__ [INFO ] Evaluated on validation set. Loss: 3.65690
2018-02-05 01:28:43,613 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 54 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 7
}
--------------------------------------------------
2018-02-05 01:28:43,910 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:44,794 __main__ [INFO ] Evaluated on training set. Loss: 2.22462
2018-02-05 01:28:44,873 __main__ [INFO ] Evaluated on validation set. Loss: 3.75871
2018-02-05 01:28:44,873 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 55 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 7
}
--------------------------------------------------
2018-02-05 01:28:45,175 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:46,184 __main__ [INFO ] Evaluated on training set. Loss: 4.01790
2018-02-05 01:28:46,215 __main__ [INFO ] Evaluated on validation set. Loss: 4.67147
2018-02-05 01:28:46,215 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 56 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 7
}
--------------------------------------------------
2018-02-05 01:28:46,516 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:47,447 __main__ [INFO ] Evaluated on training set. Loss: 4.17159
2018-02-05 01:28:47,470 __main__ [INFO ] Evaluated on validation set. Loss: 4.73337
2018-02-05 01:28:47,470 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 57 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 8
}
--------------------------------------------------
2018-02-05 01:28:47,848 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:49,040 __main__ [INFO ] Evaluated on training set. Loss: 0.60556
2018-02-05 01:28:49,072 __main__ [INFO ] Evaluated on validation set. Loss: 4.05365
2018-02-05 01:28:49,072 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 58 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 8
}
--------------------------------------------------
2018-02-05 01:28:49,464 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:50,591 __main__ [INFO ] Evaluated on training set. Loss: 0.54771
2018-02-05 01:28:50,615 __main__ [INFO ] Evaluated on validation set. Loss: 4.19924
2018-02-05 01:28:50,615 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 59 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 8
}
--------------------------------------------------
2018-02-05 01:28:50,956 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:52,198 __main__ [INFO ] Evaluated on training set. Loss: 0.96321
2018-02-05 01:28:52,230 __main__ [INFO ] Evaluated on validation set. Loss: 3.83837
2018-02-05 01:28:52,230 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 60 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 8
}
--------------------------------------------------
2018-02-05 01:28:52,566 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:53,707 __main__ [INFO ] Evaluated on training set. Loss: 0.92772
2018-02-05 01:28:53,732 __main__ [INFO ] Evaluated on validation set. Loss: 3.97177
2018-02-05 01:28:53,732 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 61 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 8
}
--------------------------------------------------
2018-02-05 01:28:54,052 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:55,277 __main__ [INFO ] Evaluated on training set. Loss: 2.31097
2018-02-05 01:28:55,308 __main__ [INFO ] Evaluated on validation set. Loss: 4.16290
2018-02-05 01:28:55,309 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 62 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 8
}
--------------------------------------------------
2018-02-05 01:28:55,622 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:56,725 __main__ [INFO ] Evaluated on training set. Loss: 2.36232
2018-02-05 01:28:56,749 __main__ [INFO ] Evaluated on validation set. Loss: 4.26567
2018-02-05 01:28:56,749 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 63 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 8
}
--------------------------------------------------
2018-02-05 01:28:57,123 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:58,246 __main__ [INFO ] Evaluated on training set. Loss: 4.33012
2018-02-05 01:28:58,276 __main__ [INFO ] Evaluated on validation set. Loss: 5.05962
2018-02-05 01:28:58,277 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 64 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 8
}
--------------------------------------------------
2018-02-05 01:28:58,664 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:28:59,763 __main__ [INFO ] Evaluated on training set. Loss: 4.45620
2018-02-05 01:28:59,787 __main__ [INFO ] Evaluated on validation set. Loss: 5.11659
2018-02-05 01:28:59,787 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 65 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 9
}
--------------------------------------------------
2018-02-05 01:29:00,128 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:01,488 __main__ [INFO ] Evaluated on training set. Loss: 0.45289
2018-02-05 01:29:01,522 __main__ [INFO ] Evaluated on validation set. Loss: 4.47368
2018-02-05 01:29:01,523 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 66 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 9
}
--------------------------------------------------
2018-02-05 01:29:01,928 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:03,261 __main__ [INFO ] Evaluated on training set. Loss: 0.40688
2018-02-05 01:29:03,288 __main__ [INFO ] Evaluated on validation set. Loss: 4.60861
2018-02-05 01:29:03,288 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 67 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 9
}
--------------------------------------------------
2018-02-05 01:29:03,659 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:05,046 __main__ [INFO ] Evaluated on training set. Loss: 0.88497
2018-02-05 01:29:05,081 __main__ [INFO ] Evaluated on validation set. Loss: 4.29723
2018-02-05 01:29:05,081 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 68 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 9
}
--------------------------------------------------
2018-02-05 01:29:05,429 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:06,681 __main__ [INFO ] Evaluated on training set. Loss: 0.85891
2018-02-05 01:29:06,708 __main__ [INFO ] Evaluated on validation set. Loss: 4.42520
2018-02-05 01:29:06,708 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 69 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 9
}
--------------------------------------------------
2018-02-05 01:29:07,032 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:08,418 __main__ [INFO ] Evaluated on training set. Loss: 2.43838
2018-02-05 01:29:08,452 __main__ [INFO ] Evaluated on validation set. Loss: 4.60520
2018-02-05 01:29:08,452 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 70 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 9
}
--------------------------------------------------
2018-02-05 01:29:08,852 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:10,368 __main__ [INFO ] Evaluated on training set. Loss: 2.48508
2018-02-05 01:29:10,408 __main__ [INFO ] Evaluated on validation set. Loss: 4.70296
2018-02-05 01:29:10,408 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 71 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 9
}
--------------------------------------------------
2018-02-05 01:29:10,886 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:12,535 __main__ [INFO ] Evaluated on training set. Loss: 4.56306
2018-02-05 01:29:12,568 __main__ [INFO ] Evaluated on validation set. Loss: 5.35872
2018-02-05 01:29:12,569 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 72 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 9
}
--------------------------------------------------
2018-02-05 01:29:12,988 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:14,502 __main__ [INFO ] Evaluated on training set. Loss: 4.66215
2018-02-05 01:29:14,541 __main__ [INFO ] Evaluated on validation set. Loss: 5.40956
2018-02-05 01:29:14,542 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 73 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 10
}
--------------------------------------------------
2018-02-05 01:29:15,035 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:16,871 __main__ [INFO ] Evaluated on training set. Loss: 0.34787
2018-02-05 01:29:16,921 __main__ [INFO ] Evaluated on validation set. Loss: 4.81782
2018-02-05 01:29:16,921 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 74 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 10
}
--------------------------------------------------
2018-02-05 01:29:17,514 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:19,228 __main__ [INFO ] Evaluated on training set. Loss: 0.31292
2018-02-05 01:29:19,255 __main__ [INFO ] Evaluated on validation set. Loss: 4.94839
2018-02-05 01:29:19,256 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 75 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 10
}
--------------------------------------------------
2018-02-05 01:29:19,678 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:21,346 __main__ [INFO ] Evaluated on training set. Loss: 0.83934
2018-02-05 01:29:21,380 __main__ [INFO ] Evaluated on validation set. Loss: 4.67890
2018-02-05 01:29:21,380 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 76 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 10
}
--------------------------------------------------
2018-02-05 01:29:21,813 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:23,197 __main__ [INFO ] Evaluated on training set. Loss: 0.82123
2018-02-05 01:29:23,224 __main__ [INFO ] Evaluated on validation set. Loss: 4.80228
2018-02-05 01:29:23,224 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 77 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 10
}
--------------------------------------------------
2018-02-05 01:29:23,586 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:25,077 __main__ [INFO ] Evaluated on training set. Loss: 2.54642
2018-02-05 01:29:25,110 __main__ [INFO ] Evaluated on validation set. Loss: 4.95612
2018-02-05 01:29:25,111 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 78 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 10
}
--------------------------------------------------
2018-02-05 01:29:25,545 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:26,921 __main__ [INFO ] Evaluated on training set. Loss: 2.58669
2018-02-05 01:29:26,948 __main__ [INFO ] Evaluated on validation set. Loss: 5.04794
2018-02-05 01:29:26,948 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 79 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 10
}
--------------------------------------------------
2018-02-05 01:29:27,341 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:28,819 __main__ [INFO ] Evaluated on training set. Loss: 4.73275
2018-02-05 01:29:28,850 __main__ [INFO ] Evaluated on validation set. Loss: 5.57141
2018-02-05 01:29:28,851 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 80 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 10
}
--------------------------------------------------
2018-02-05 01:29:29,275 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:30,651 __main__ [INFO ] Evaluated on training set. Loss: 4.80923
2018-02-05 01:29:30,676 __main__ [INFO ] Evaluated on validation set. Loss: 5.61599
2018-02-05 01:29:30,676 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 81 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 11
}
--------------------------------------------------
2018-02-05 01:29:31,045 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:32,603 __main__ [INFO ] Evaluated on training set. Loss: 0.27507
2018-02-05 01:29:32,637 __main__ [INFO ] Evaluated on validation set. Loss: 5.09298
2018-02-05 01:29:32,637 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 82 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 11
}
--------------------------------------------------
2018-02-05 01:29:33,093 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:34,536 __main__ [INFO ] Evaluated on training set. Loss: 0.24892
2018-02-05 01:29:34,562 __main__ [INFO ] Evaluated on validation set. Loss: 5.20260
2018-02-05 01:29:34,563 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 83 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 11
}
--------------------------------------------------
2018-02-05 01:29:35,002 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:36,627 __main__ [INFO ] Evaluated on training set. Loss: 0.81186
2018-02-05 01:29:36,660 __main__ [INFO ] Evaluated on validation set. Loss: 4.98894
2018-02-05 01:29:36,660 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 84 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 11
}
--------------------------------------------------
2018-02-05 01:29:37,052 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:38,506 __main__ [INFO ] Evaluated on training set. Loss: 0.79955
2018-02-05 01:29:38,532 __main__ [INFO ] Evaluated on validation set. Loss: 5.09697
2018-02-05 01:29:38,532 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 85 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 11
}
--------------------------------------------------
2018-02-05 01:29:38,986 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:40,646 __main__ [INFO ] Evaluated on training set. Loss: 2.63084
2018-02-05 01:29:40,682 __main__ [INFO ] Evaluated on validation set. Loss: 5.22756
2018-02-05 01:29:40,682 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 86 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 11
}
--------------------------------------------------
2018-02-05 01:29:41,080 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:42,636 __main__ [INFO ] Evaluated on training set. Loss: 2.66454
2018-02-05 01:29:42,664 __main__ [INFO ] Evaluated on validation set. Loss: 5.30825
2018-02-05 01:29:42,665 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 87 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 11
}
--------------------------------------------------
2018-02-05 01:29:43,120 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:44,742 __main__ [INFO ] Evaluated on training set. Loss: 4.85396
2018-02-05 01:29:44,775 __main__ [INFO ] Evaluated on validation set. Loss: 5.72132
2018-02-05 01:29:44,775 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 88 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 11
}
--------------------------------------------------
2018-02-05 01:29:45,220 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:46,675 __main__ [INFO ] Evaluated on training set. Loss: 4.91280
2018-02-05 01:29:46,702 __main__ [INFO ] Evaluated on validation set. Loss: 5.75951
2018-02-05 01:29:46,702 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 89 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 12
}
--------------------------------------------------
2018-02-05 01:29:47,172 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:48,852 __main__ [INFO ] Evaluated on training set. Loss: 0.22333
2018-02-05 01:29:48,888 __main__ [INFO ] Evaluated on validation set. Loss: 5.32007
2018-02-05 01:29:48,888 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 90 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 12
}
--------------------------------------------------
2018-02-05 01:29:49,297 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:50,914 __main__ [INFO ] Evaluated on training set. Loss: 0.20441
2018-02-05 01:29:50,944 __main__ [INFO ] Evaluated on validation set. Loss: 5.40929
2018-02-05 01:29:50,944 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 91 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 12
}
--------------------------------------------------
2018-02-05 01:29:51,427 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:53,132 __main__ [INFO ] Evaluated on training set. Loss: 0.79417
2018-02-05 01:29:53,166 __main__ [INFO ] Evaluated on validation set. Loss: 5.24229
2018-02-05 01:29:53,167 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 92 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 12
}
--------------------------------------------------
2018-02-05 01:29:53,673 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:55,119 __main__ [INFO ] Evaluated on training set. Loss: 0.78640
2018-02-05 01:29:55,146 __main__ [INFO ] Evaluated on validation set. Loss: 5.33233
2018-02-05 01:29:55,147 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 93 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 12
}
--------------------------------------------------
2018-02-05 01:29:55,703 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:57,259 __main__ [INFO ] Evaluated on training set. Loss: 2.69366
2018-02-05 01:29:57,293 __main__ [INFO ] Evaluated on validation set. Loss: 5.43934
2018-02-05 01:29:57,293 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 94 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 12
}
--------------------------------------------------
2018-02-05 01:29:57,835 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:29:59,234 __main__ [INFO ] Evaluated on training set. Loss: 2.72174
2018-02-05 01:29:59,262 __main__ [INFO ] Evaluated on validation set. Loss: 5.50668
2018-02-05 01:29:59,262 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 95 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 12
}
--------------------------------------------------
2018-02-05 01:29:59,797 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:01,411 __main__ [INFO ] Evaluated on training set. Loss: 4.93933
2018-02-05 01:30:01,444 __main__ [INFO ] Evaluated on validation set. Loss: 5.83146
2018-02-05 01:30:01,444 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 96 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 12
}
--------------------------------------------------
2018-02-05 01:30:01,978 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:03,385 __main__ [INFO ] Evaluated on training set. Loss: 4.98527
2018-02-05 01:30:03,411 __main__ [INFO ] Evaluated on validation set. Loss: 5.86305
2018-02-05 01:30:03,412 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 97 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 13
}
--------------------------------------------------
2018-02-05 01:30:03,967 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:05,525 __main__ [INFO ] Evaluated on training set. Loss: 0.18911
2018-02-05 01:30:05,646 __main__ [INFO ] Evaluated on validation set. Loss: 5.48719
2018-02-05 01:30:05,646 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 98 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 13
}
--------------------------------------------------
2018-02-05 01:30:06,125 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:07,575 __main__ [INFO ] Evaluated on training set. Loss: 0.17535
2018-02-05 01:30:07,603 __main__ [INFO ] Evaluated on validation set. Loss: 5.55922
2018-02-05 01:30:07,603 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 99 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 13
}
--------------------------------------------------
2018-02-05 01:30:08,149 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:09,764 __main__ [INFO ] Evaluated on training set. Loss: 0.78473
2018-02-05 01:30:09,800 __main__ [INFO ] Evaluated on validation set. Loss: 5.43405
2018-02-05 01:30:09,800 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 100 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 13
}
--------------------------------------------------
2018-02-05 01:30:10,357 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:12,221 __main__ [INFO ] Evaluated on training set. Loss: 0.77992
2018-02-05 01:30:12,247 __main__ [INFO ] Evaluated on validation set. Loss: 5.50794
2018-02-05 01:30:12,247 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 101 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 13
}
--------------------------------------------------
2018-02-05 01:30:12,788 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:14,549 __main__ [INFO ] Evaluated on training set. Loss: 2.74093
2018-02-05 01:30:14,583 __main__ [INFO ] Evaluated on validation set. Loss: 5.59828
2018-02-05 01:30:14,584 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 102 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 13
}
--------------------------------------------------
2018-02-05 01:30:15,128 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:16,615 __main__ [INFO ] Evaluated on training set. Loss: 2.76424
2018-02-05 01:30:16,644 __main__ [INFO ] Evaluated on validation set. Loss: 5.65373
2018-02-05 01:30:16,644 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 103 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 13
}
--------------------------------------------------
2018-02-05 01:30:17,309 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:19,133 __main__ [INFO ] Evaluated on training set. Loss: 5.00076
2018-02-05 01:30:19,168 __main__ [INFO ] Evaluated on validation set. Loss: 5.91301
2018-02-05 01:30:19,169 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 104 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 13
}
--------------------------------------------------
2018-02-05 01:30:19,741 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:21,223 __main__ [INFO ] Evaluated on training set. Loss: 5.03729
2018-02-05 01:30:21,249 __main__ [INFO ] Evaluated on validation set. Loss: 5.93918
2018-02-05 01:30:21,249 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 105 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 14
}
--------------------------------------------------
2018-02-05 01:30:21,795 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:23,391 __main__ [INFO ] Evaluated on training set. Loss: 0.16701
2018-02-05 01:30:23,511 __main__ [INFO ] Evaluated on validation set. Loss: 5.62142
2018-02-05 01:30:23,512 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 106 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 14
}
--------------------------------------------------
2018-02-05 01:30:23,995 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:25,465 __main__ [INFO ] Evaluated on training set. Loss: 0.15651
2018-02-05 01:30:25,492 __main__ [INFO ] Evaluated on validation set. Loss: 5.67731
2018-02-05 01:30:25,493 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 107 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 14
}
--------------------------------------------------
2018-02-05 01:30:26,060 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:27,679 __main__ [INFO ] Evaluated on training set. Loss: 0.78076
2018-02-05 01:30:27,713 __main__ [INFO ] Evaluated on validation set. Loss: 5.58305
2018-02-05 01:30:27,713 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 108 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 14
}
--------------------------------------------------
2018-02-05 01:30:28,266 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:29,752 __main__ [INFO ] Evaluated on training set. Loss: 0.77747
2018-02-05 01:30:29,779 __main__ [INFO ] Evaluated on validation set. Loss: 5.64139
2018-02-05 01:30:29,780 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 109 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 14
}
--------------------------------------------------
2018-02-05 01:30:30,332 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:31,948 __main__ [INFO ] Evaluated on training set. Loss: 2.77765
2018-02-05 01:30:32,067 __main__ [INFO ] Evaluated on validation set. Loss: 5.71934
2018-02-05 01:30:32,067 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 110 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 14
}
--------------------------------------------------
2018-02-05 01:30:32,460 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:34,028 __main__ [INFO ] Evaluated on training set. Loss: 2.79678
2018-02-05 01:30:34,057 __main__ [INFO ] Evaluated on validation set. Loss: 5.76354
2018-02-05 01:30:34,057 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 111 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 14
}
--------------------------------------------------
2018-02-05 01:30:34,623 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:36,278 __main__ [INFO ] Evaluated on training set. Loss: 5.04664
2018-02-05 01:30:36,312 __main__ [INFO ] Evaluated on validation set. Loss: 5.97312
2018-02-05 01:30:36,313 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 112 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 14
}
--------------------------------------------------
2018-02-05 01:30:36,870 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:38,382 __main__ [INFO ] Evaluated on training set. Loss: 5.07591
2018-02-05 01:30:38,497 __main__ [INFO ] Evaluated on validation set. Loss: 5.99408
2018-02-05 01:30:38,497 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 113 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 15
}
--------------------------------------------------
2018-02-05 01:30:38,982 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:40,623 __main__ [INFO ] Evaluated on training set. Loss: 0.15061
2018-02-05 01:30:40,661 __main__ [INFO ] Evaluated on validation set. Loss: 5.73959
2018-02-05 01:30:40,661 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 114 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 15
}
--------------------------------------------------
2018-02-05 01:30:41,225 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:42,906 __main__ [INFO ] Evaluated on training set. Loss: 0.14254
2018-02-05 01:30:42,934 __main__ [INFO ] Evaluated on validation set. Loss: 5.78290
2018-02-05 01:30:42,934 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 115 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 15
}
--------------------------------------------------
2018-02-05 01:30:43,361 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:45,151 __main__ [INFO ] Evaluated on training set. Loss: 0.77827
2018-02-05 01:30:45,187 __main__ [INFO ] Evaluated on validation set. Loss: 5.70785
2018-02-05 01:30:45,188 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 116 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 15
}
--------------------------------------------------
2018-02-05 01:30:45,690 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:47,360 __main__ [INFO ] Evaluated on training set. Loss: 0.77605
2018-02-05 01:30:47,388 __main__ [INFO ] Evaluated on validation set. Loss: 5.75369
2018-02-05 01:30:47,389 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 117 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 15
}
--------------------------------------------------
2018-02-05 01:30:47,809 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:49,580 __main__ [INFO ] Evaluated on training set. Loss: 2.80615
2018-02-05 01:30:49,615 __main__ [INFO ] Evaluated on validation set. Loss: 5.81772
2018-02-05 01:30:49,615 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 118 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 15
}
--------------------------------------------------
2018-02-05 01:30:50,104 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:51,624 __main__ [INFO ] Evaluated on training set. Loss: 2.82194
2018-02-05 01:30:51,743 __main__ [INFO ] Evaluated on validation set. Loss: 5.85282
2018-02-05 01:30:51,744 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 119 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 15
}
--------------------------------------------------
2018-02-05 01:30:52,138 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:53,889 __main__ [INFO ] Evaluated on training set. Loss: 5.08152
2018-02-05 01:30:53,923 __main__ [INFO ] Evaluated on validation set. Loss: 6.01954
2018-02-05 01:30:53,923 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 120 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 15
}
--------------------------------------------------
2018-02-05 01:30:54,387 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:56,010 __main__ [INFO ] Evaluated on training set. Loss: 5.10509
2018-02-05 01:30:56,037 __main__ [INFO ] Evaluated on validation set. Loss: 6.03627
2018-02-05 01:30:56,037 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 121 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 16
}
--------------------------------------------------
2018-02-05 01:30:56,502 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:30:58,257 __main__ [INFO ] Evaluated on training set. Loss: 0.13933
2018-02-05 01:30:58,292 __main__ [INFO ] Evaluated on validation set. Loss: 5.83557
2018-02-05 01:30:58,293 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 122 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 16
}
--------------------------------------------------
2018-02-05 01:30:58,761 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:00,438 __main__ [INFO ] Evaluated on training set. Loss: 0.13309
2018-02-05 01:31:00,466 __main__ [INFO ] Evaluated on validation set. Loss: 5.87111
2018-02-05 01:31:00,467 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 123 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 16
}
--------------------------------------------------
2018-02-05 01:31:00,936 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:02,699 __main__ [INFO ] Evaluated on training set. Loss: 0.77772
2018-02-05 01:31:02,734 __main__ [INFO ] Evaluated on validation set. Loss: 5.81055
2018-02-05 01:31:02,734 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 124 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 16
}
--------------------------------------------------
2018-02-05 01:31:03,200 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:04,901 __main__ [INFO ] Evaluated on training set. Loss: 0.77626
2018-02-05 01:31:04,930 __main__ [INFO ] Evaluated on validation set. Loss: 5.84761
2018-02-05 01:31:04,930 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 125 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 16
}
--------------------------------------------------
2018-02-05 01:31:05,398 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:07,174 __main__ [INFO ] Evaluated on training set. Loss: 2.82915
2018-02-05 01:31:07,209 __main__ [INFO ] Evaluated on validation set. Loss: 5.89824
2018-02-05 01:31:07,210 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 126 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 16
}
--------------------------------------------------
2018-02-05 01:31:07,674 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:09,329 __main__ [INFO ] Evaluated on training set. Loss: 2.84220
2018-02-05 01:31:09,358 __main__ [INFO ] Evaluated on validation set. Loss: 5.92651
2018-02-05 01:31:09,358 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 127 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 16
}
--------------------------------------------------
2018-02-05 01:31:09,829 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:11,587 __main__ [INFO ] Evaluated on training set. Loss: 5.10865
2018-02-05 01:31:11,624 __main__ [INFO ] Evaluated on validation set. Loss: 6.05736
2018-02-05 01:31:11,624 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 128 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 16
}
--------------------------------------------------
2018-02-05 01:31:12,101 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:13,820 __main__ [INFO ] Evaluated on training set. Loss: 5.12774
2018-02-05 01:31:13,848 __main__ [INFO ] Evaluated on validation set. Loss: 6.07066
2018-02-05 01:31:13,848 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 129 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 17
}
--------------------------------------------------
2018-02-05 01:31:14,317 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:16,106 __main__ [INFO ] Evaluated on training set. Loss: 0.13139
2018-02-05 01:31:16,141 __main__ [INFO ] Evaluated on validation set. Loss: 5.92252
2018-02-05 01:31:16,142 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 130 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 17
}
--------------------------------------------------
2018-02-05 01:31:16,572 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:18,282 __main__ [INFO ] Evaluated on training set. Loss: 0.12641
2018-02-05 01:31:18,311 __main__ [INFO ] Evaluated on validation set. Loss: 5.94885
2018-02-05 01:31:18,311 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 131 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 17
}
--------------------------------------------------
2018-02-05 01:31:18,782 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:20,571 __main__ [INFO ] Evaluated on training set. Loss: 0.77810
2018-02-05 01:31:20,607 __main__ [INFO ] Evaluated on validation set. Loss: 5.89988
2018-02-05 01:31:20,607 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 132 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 17
}
--------------------------------------------------
2018-02-05 01:31:21,109 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:22,775 __main__ [INFO ] Evaluated on training set. Loss: 0.77704
2018-02-05 01:31:22,803 __main__ [INFO ] Evaluated on validation set. Loss: 5.92817
2018-02-05 01:31:22,803 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 133 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 17
}
--------------------------------------------------
2018-02-05 01:31:23,273 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:25,039 __main__ [INFO ] Evaluated on training set. Loss: 2.84765
2018-02-05 01:31:25,075 __main__ [INFO ] Evaluated on validation set. Loss: 5.96703
2018-02-05 01:31:25,075 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 134 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 17
}
--------------------------------------------------
2018-02-05 01:31:25,544 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:27,193 __main__ [INFO ] Evaluated on training set. Loss: 2.85837
2018-02-05 01:31:27,222 __main__ [INFO ] Evaluated on validation set. Loss: 5.98894
2018-02-05 01:31:27,222 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 135 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 17
}
--------------------------------------------------
2018-02-05 01:31:27,710 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:29,485 __main__ [INFO ] Evaluated on training set. Loss: 5.13004
2018-02-05 01:31:29,520 __main__ [INFO ] Evaluated on validation set. Loss: 6.08982
2018-02-05 01:31:29,520 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 136 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 17
}
--------------------------------------------------
2018-02-05 01:31:30,006 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:31,646 __main__ [INFO ] Evaluated on training set. Loss: 5.14557
2018-02-05 01:31:31,674 __main__ [INFO ] Evaluated on validation set. Loss: 6.09993
2018-02-05 01:31:31,675 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 137 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 18
}
--------------------------------------------------
2018-02-05 01:31:32,163 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:33,977 __main__ [INFO ] Evaluated on training set. Loss: 0.12482
2018-02-05 01:31:34,013 __main__ [INFO ] Evaluated on validation set. Loss: 5.99431
2018-02-05 01:31:34,013 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 138 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 18
}
--------------------------------------------------
2018-02-05 01:31:34,489 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:36,203 __main__ [INFO ] Evaluated on training set. Loss: 0.12090
2018-02-05 01:31:36,231 __main__ [INFO ] Evaluated on validation set. Loss: 6.01236
2018-02-05 01:31:36,232 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 139 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 18
}
--------------------------------------------------
2018-02-05 01:31:36,709 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:38,514 __main__ [INFO ] Evaluated on training set. Loss: 0.77818
2018-02-05 01:31:38,550 __main__ [INFO ] Evaluated on validation set. Loss: 5.97343
2018-02-05 01:31:38,550 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 140 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 18
}
--------------------------------------------------
2018-02-05 01:31:39,129 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:40,729 __main__ [INFO ] Evaluated on training set. Loss: 0.77747
2018-02-05 01:31:40,762 __main__ [INFO ] Evaluated on validation set. Loss: 5.99383
2018-02-05 01:31:40,763 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 141 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 18
}
--------------------------------------------------
2018-02-05 01:31:41,362 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:43,295 __main__ [INFO ] Evaluated on training set. Loss: 2.86203
2018-02-05 01:31:43,333 __main__ [INFO ] Evaluated on validation set. Loss: 6.02355
2018-02-05 01:31:43,333 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 142 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 18
}
--------------------------------------------------
2018-02-05 01:31:43,760 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:45,454 __main__ [INFO ] Evaluated on training set. Loss: 2.87089
2018-02-05 01:31:45,484 __main__ [INFO ] Evaluated on validation set. Loss: 6.03974
2018-02-05 01:31:45,484 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 143 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 18
}
--------------------------------------------------
2018-02-05 01:31:45,976 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:47,782 __main__ [INFO ] Evaluated on training set. Loss: 5.14663
2018-02-05 01:31:47,820 __main__ [INFO ] Evaluated on validation set. Loss: 6.11576
2018-02-05 01:31:47,820 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 144 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 18
}
--------------------------------------------------
2018-02-05 01:31:48,351 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:50,049 __main__ [INFO ] Evaluated on training set. Loss: 5.15938
2018-02-05 01:31:50,174 __main__ [INFO ] Evaluated on validation set. Loss: 6.12308
2018-02-05 01:31:50,175 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 145 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 19
}
--------------------------------------------------
2018-02-05 01:31:50,697 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:52,474 __main__ [INFO ] Evaluated on training set. Loss: 0.11990
2018-02-05 01:31:52,510 __main__ [INFO ] Evaluated on validation set. Loss: 6.03294
2018-02-05 01:31:52,510 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 146 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 19
}
--------------------------------------------------
2018-02-05 01:31:53,081 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:54,640 __main__ [INFO ] Evaluated on training set. Loss: 0.11684
2018-02-05 01:31:54,669 __main__ [INFO ] Evaluated on validation set. Loss: 6.05011
2018-02-05 01:31:54,669 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 147 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 19
}
--------------------------------------------------
2018-02-05 01:31:55,231 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:57,155 __main__ [INFO ] Evaluated on training set. Loss: 0.77852
2018-02-05 01:31:57,195 __main__ [INFO ] Evaluated on validation set. Loss: 6.02016
2018-02-05 01:31:57,195 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 148 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 19
}
--------------------------------------------------
2018-02-05 01:31:57,620 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:31:59,423 __main__ [INFO ] Evaluated on training set. Loss: 0.77809
2018-02-05 01:31:59,454 __main__ [INFO ] Evaluated on validation set. Loss: 6.03777
2018-02-05 01:31:59,454 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 149 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 19
}
--------------------------------------------------
2018-02-05 01:31:59,959 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:01,775 __main__ [INFO ] Evaluated on training set. Loss: 2.87358
2018-02-05 01:32:01,810 __main__ [INFO ] Evaluated on validation set. Loss: 6.06175
2018-02-05 01:32:01,811 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 150 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 19
}
--------------------------------------------------
2018-02-05 01:32:02,305 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:04,002 __main__ [INFO ] Evaluated on training set. Loss: 2.88096
2018-02-05 01:32:04,032 __main__ [INFO ] Evaluated on validation set. Loss: 6.07490
2018-02-05 01:32:04,032 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 151 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 19
}
--------------------------------------------------
2018-02-05 01:32:04,548 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:06,384 __main__ [INFO ] Evaluated on training set. Loss: 5.15985
2018-02-05 01:32:06,419 __main__ [INFO ] Evaluated on validation set. Loss: 6.13335
2018-02-05 01:32:06,420 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 152 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 19
}
--------------------------------------------------
2018-02-05 01:32:06,848 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:08,629 __main__ [INFO ] Evaluated on training set. Loss: 5.17042
2018-02-05 01:32:08,660 __main__ [INFO ] Evaluated on validation set. Loss: 6.13881
2018-02-05 01:32:08,660 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 153 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 20
}
--------------------------------------------------
2018-02-05 01:32:09,153 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:11,082 __main__ [INFO ] Evaluated on training set. Loss: 0.11627
2018-02-05 01:32:11,121 __main__ [INFO ] Evaluated on validation set. Loss: 6.07232
2018-02-05 01:32:11,121 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 154 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 20
}
--------------------------------------------------
2018-02-05 01:32:11,626 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:13,340 __main__ [INFO ] Evaluated on training set. Loss: 0.11379
2018-02-05 01:32:13,370 __main__ [INFO ] Evaluated on validation set. Loss: 6.08613
2018-02-05 01:32:13,370 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 155 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 20
}
--------------------------------------------------
2018-02-05 01:32:13,884 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:15,769 __main__ [INFO ] Evaluated on training set. Loss: 0.77901
2018-02-05 01:32:15,805 __main__ [INFO ] Evaluated on validation set. Loss: 6.06101
2018-02-05 01:32:15,805 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 156 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 20
}
--------------------------------------------------
2018-02-05 01:32:16,217 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:17,918 __main__ [INFO ] Evaluated on training set. Loss: 0.77870
2018-02-05 01:32:17,948 __main__ [INFO ] Evaluated on validation set. Loss: 6.07541
2018-02-05 01:32:17,948 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 157 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 0.1,
  "n": 20
}
--------------------------------------------------
2018-02-05 01:32:18,425 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:20,236 __main__ [INFO ] Evaluated on training set. Loss: 2.88283
2018-02-05 01:32:20,275 __main__ [INFO ] Evaluated on validation set. Loss: 6.09226
2018-02-05 01:32:20,276 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 158 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 0.1,
  "n": 20
}
--------------------------------------------------
2018-02-05 01:32:20,770 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:22,520 __main__ [INFO ] Evaluated on training set. Loss: 2.88897
2018-02-05 01:32:22,549 __main__ [INFO ] Evaluated on validation set. Loss: 6.10281
2018-02-05 01:32:22,549 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 159 out of 160 with hyperparameters:
{
  "adapt": true,
  "delta": 1,
  "n": 20
}
--------------------------------------------------
2018-02-05 01:32:23,064 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:24,941 __main__ [INFO ] Evaluated on training set. Loss: 5.17039
2018-02-05 01:32:24,976 __main__ [INFO ] Evaluated on validation set. Loss: 6.14630
2018-02-05 01:32:24,976 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 160 out of 160 with hyperparameters:
{
  "adapt": false,
  "delta": 1,
  "n": 20
}
--------------------------------------------------
2018-02-05 01:32:25,384 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 01:32:27,079 __main__ [INFO ] Evaluated on training set. Loss: 5.17922
2018-02-05 01:32:27,108 __main__ [INFO ] Evaluated on validation set. Loss: 6.15048
2018-02-05 11:33:44,762 __main__ [INFO ] 
==============================
Starting experiment rn_dsh_gb
==============================
2018-02-05 11:33:59,037 __main__ [INFO ] 
==============================
Starting experiment rnn_dsh_gb
==============================
2018-02-05 11:33:59,042 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 4 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 60,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-05 11:33:59,043 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 87
2018-02-05 11:34:06,281 training [INFO ] Epoch  1 Batch   20 Training err. 4.37787 Training err. RA 4.37787 Valid. err. 4.29234
2018-02-05 11:34:07,155 training [INFO ] Epoch  1 Batch   40 Training err. 4.20667 Training err. RA 4.29227 Valid. err. 4.10297
2018-02-05 11:34:07,982 training [INFO ] Epoch  1 Batch   60 Training err. 3.98599 Training err. RA 4.19018 Valid. err. 3.84255
2018-02-05 11:34:08,804 training [INFO ] Epoch  1 Batch   80 Training err. 3.68816 Training err. RA 4.06467 Valid. err. 3.54099
2018-02-05 11:34:09,635 training [INFO ] Epoch  1 Batch  100 Training err. 3.44610 Training err. RA 3.94096 Valid. err. 3.34347
2018-02-05 11:34:10,459 training [INFO ] Epoch  1 Batch  120 Training err. 3.28061 Training err. RA 3.83090 Valid. err. 3.22712
2018-02-05 11:34:11,298 training [INFO ] Epoch  1 Batch  140 Training err. 3.20010 Training err. RA 3.74079 Valid. err. 3.16998
2018-02-05 11:34:12,167 training [INFO ] Epoch  1 Batch  160 Training err. 3.12961 Training err. RA 3.66439 Valid. err. 3.13832
2018-02-05 11:34:12,994 training [INFO ] Epoch  1 Batch  180 Training err. 3.15454 Training err. RA 3.60774 Valid. err. 3.11740
2018-02-05 11:34:13,823 training [INFO ] Epoch  1 Batch  200 Training err. 3.11021 Training err. RA 3.55799 Valid. err. 3.10316
2018-02-05 11:34:14,650 training [INFO ] Epoch  1 Batch  220 Training err. 3.10812 Training err. RA 3.51709 Valid. err. 3.09471
2018-02-05 11:34:15,489 training [INFO ] Epoch  1 Batch  240 Training err. 3.10169 Training err. RA 3.48247 Valid. err. 3.08798
2018-02-05 11:34:16,319 training [INFO ] Epoch  1 Batch  260 Training err. 3.09897 Training err. RA 3.45297 Valid. err. 3.08343
2018-02-05 11:34:17,145 training [INFO ] Epoch  1 Batch  280 Training err. 3.07608 Training err. RA 3.42605 Valid. err. 3.08002
2018-02-05 11:34:18,011 training [INFO ] Epoch  1 Batch  300 Training err. 3.07636 Training err. RA 3.40274 Valid. err. 3.07776
2018-02-05 11:34:18,896 training [INFO ] Epoch  1 Batch  320 Training err. 3.07254 Training err. RA 3.38210 Valid. err. 3.07541
2018-02-05 11:34:19,763 training [INFO ] Epoch  1 Batch  340 Training err. 3.08811 Training err. RA 3.36481 Valid. err. 3.07459
2018-02-05 11:34:20,612 training [INFO ] Epoch  1 Batch  360 Training err. 3.06310 Training err. RA 3.34805 Valid. err. 3.07373
2018-02-05 11:34:21,440 training [INFO ] Epoch  1 Batch  380 Training err. 3.06671 Training err. RA 3.33324 Valid. err. 3.07350
2018-02-05 11:34:22,267 training [INFO ] Epoch  1 Batch  400 Training err. 3.06840 Training err. RA 3.32000 Valid. err. 3.07128
2018-02-05 11:34:23,098 training [INFO ] Epoch  1 Batch  420 Training err. 3.06867 Training err. RA 3.30803 Valid. err. 3.07043
2018-02-05 11:34:23,925 training [INFO ] Epoch  1 Batch  440 Training err. 3.09049 Training err. RA 3.29814 Valid. err. 3.07025
2018-02-05 11:34:26,008 training [INFO ] Epoch  2 Batch  460 Training err. 3.08668 Training err. RA 3.28895 Valid. err. 3.06955
2018-02-05 11:34:26,837 training [INFO ] Epoch  2 Batch  480 Training err. 3.06991 Training err. RA 3.27982 Valid. err. 3.06926
2018-02-05 11:34:27,681 training [INFO ] Epoch  2 Batch  500 Training err. 3.09551 Training err. RA 3.27245 Valid. err. 3.06701
2018-02-05 11:34:28,523 training [INFO ] Epoch  2 Batch  520 Training err. 3.07156 Training err. RA 3.26472 Valid. err. 3.06649
2018-02-05 11:34:29,355 training [INFO ] Epoch  2 Batch  540 Training err. 3.07237 Training err. RA 3.25760 Valid. err. 3.06525
2018-02-05 11:34:30,203 training [INFO ] Epoch  2 Batch  560 Training err. 3.07654 Training err. RA 3.25113 Valid. err. 3.06514
2018-02-05 11:34:31,145 training [INFO ] Epoch  2 Batch  580 Training err. 3.06329 Training err. RA 3.24465 Valid. err. 3.06404
2018-02-05 11:34:32,001 training [INFO ] Epoch  2 Batch  600 Training err. 3.04157 Training err. RA 3.23788 Valid. err. 3.06448
2018-02-05 11:34:32,844 training [INFO ] Epoch  2 Batch  620 Training err. 3.07354 Training err. RA 3.23258 Valid. err. 3.06387
2018-02-05 11:34:33,703 training [INFO ] Epoch  2 Batch  640 Training err. 3.07531 Training err. RA 3.22767 Valid. err. 3.06222
2018-02-05 11:34:34,552 training [INFO ] Epoch  2 Batch  660 Training err. 3.05844 Training err. RA 3.22254 Valid. err. 3.06169
2018-02-05 11:34:35,383 training [INFO ] Epoch  2 Batch  680 Training err. 3.06018 Training err. RA 3.21776 Valid. err. 3.06070
2018-02-05 11:34:36,255 training [INFO ] Epoch  2 Batch  700 Training err. 3.08791 Training err. RA 3.21405 Valid. err. 3.05946
2018-02-05 11:34:37,120 training [INFO ] Epoch  2 Batch  720 Training err. 3.04424 Training err. RA 3.20934 Valid. err. 3.05977
2018-02-05 11:34:37,947 training [INFO ] Epoch  2 Batch  740 Training err. 3.05409 Training err. RA 3.20514 Valid. err. 3.05963
2018-02-05 11:34:38,774 training [INFO ] Epoch  2 Batch  760 Training err. 3.05543 Training err. RA 3.20120 Valid. err. 3.05725
2018-02-05 11:34:39,602 training [INFO ] Epoch  2 Batch  780 Training err. 3.05516 Training err. RA 3.19746 Valid. err. 3.05717
2018-02-05 11:34:40,429 training [INFO ] Epoch  2 Batch  800 Training err. 3.06240 Training err. RA 3.19408 Valid. err. 3.05752
2018-02-05 11:34:41,253 training [INFO ] Epoch  2 Batch  820 Training err. 3.04611 Training err. RA 3.19047 Valid. err. 3.05597
2018-02-05 11:34:42,084 training [INFO ] Epoch  2 Batch  840 Training err. 3.04316 Training err. RA 3.18696 Valid. err. 3.05572
2018-02-05 11:34:42,918 training [INFO ] Epoch  2 Batch  860 Training err. 3.04714 Training err. RA 3.18371 Valid. err. 3.05472
2018-02-05 11:34:43,754 training [INFO ] Epoch  2 Batch  880 Training err. 3.07796 Training err. RA 3.18131 Valid. err. 3.05309
2018-02-05 11:34:45,525 training [INFO ] Epoch  3 Batch  900 Training err. 3.05998 Training err. RA 3.17861 Valid. err. 3.05212
2018-02-05 11:34:46,350 training [INFO ] Epoch  3 Batch  920 Training err. 3.06609 Training err. RA 3.17617 Valid. err. 3.05243
2018-02-05 11:35:52,409 __main__ [INFO ] 
==============================
Starting experiment rnn_dsh_gb
==============================
2018-02-05 11:35:52,415 __main__ [INFO ] Removing old results directory ./experiments/rnn_dsh_gb/out
2018-02-05 11:35:52,416 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 2 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 30,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-05 11:35:55,497 training [INFO ] Epoch  1 Batch   20 Training err. 4.37956 Training err. RA 4.37956 Valid. err. 4.29838
2018-02-05 11:35:56,309 training [INFO ] Epoch  1 Batch   40 Training err. 4.22262 Training err. RA 4.30109 Valid. err. 4.13134
2018-02-05 11:35:57,106 training [INFO ] Epoch  1 Batch   60 Training err. 4.03339 Training err. RA 4.21186 Valid. err. 3.91486
2018-02-05 11:35:57,892 training [INFO ] Epoch  1 Batch   80 Training err. 3.77262 Training err. RA 4.10205 Valid. err. 3.62715
2018-02-05 11:35:58,686 training [INFO ] Epoch  1 Batch  100 Training err. 3.51360 Training err. RA 3.98436 Valid. err. 3.39393
2018-02-05 11:35:59,506 training [INFO ] Epoch  1 Batch  120 Training err. 3.31727 Training err. RA 3.87318 Valid. err. 3.25305
2018-02-05 11:36:00,310 training [INFO ] Epoch  1 Batch  140 Training err. 3.21800 Training err. RA 3.77958 Valid. err. 3.18407
2018-02-05 11:36:01,151 training [INFO ] Epoch  1 Batch  160 Training err. 3.13865 Training err. RA 3.69946 Valid. err. 3.14551
2018-02-05 11:36:01,998 training [INFO ] Epoch  1 Batch  180 Training err. 3.15829 Training err. RA 3.63933 Valid. err. 3.11969
2018-02-05 11:36:02,869 training [INFO ] Epoch  1 Batch  200 Training err. 3.11120 Training err. RA 3.58652 Valid. err. 3.10303
2018-02-05 11:36:03,708 training [INFO ] Epoch  1 Batch  220 Training err. 3.10674 Training err. RA 3.54290 Valid. err. 3.09321
2018-02-05 11:36:04,497 training [INFO ] Epoch  1 Batch  240 Training err. 3.09924 Training err. RA 3.50593 Valid. err. 3.08582
2018-02-05 11:36:05,279 training [INFO ] Epoch  1 Batch  260 Training err. 3.09704 Training err. RA 3.47448 Valid. err. 3.08090
2018-02-05 11:36:06,076 training [INFO ] Epoch  1 Batch  280 Training err. 3.07311 Training err. RA 3.44581 Valid. err. 3.07747
2018-02-05 11:36:06,866 training [INFO ] Epoch  1 Batch  300 Training err. 3.07377 Training err. RA 3.42101 Valid. err. 3.07524
2018-02-05 11:36:07,670 training [INFO ] Epoch  1 Batch  320 Training err. 3.06967 Training err. RA 3.39905 Valid. err. 3.07292
2018-02-05 11:36:08,467 training [INFO ] Epoch  1 Batch  340 Training err. 3.08592 Training err. RA 3.38063 Valid. err. 3.07208
2018-02-05 11:36:09,264 training [INFO ] Epoch  1 Batch  360 Training err. 3.06018 Training err. RA 3.36283 Valid. err. 3.07126
2018-02-05 11:36:10,050 training [INFO ] Epoch  1 Batch  380 Training err. 3.06420 Training err. RA 3.34711 Valid. err. 3.07116
2018-02-05 11:36:10,910 training [INFO ] Epoch  1 Batch  400 Training err. 3.06596 Training err. RA 3.33305 Valid. err. 3.06870
2018-02-05 11:36:11,723 training [INFO ] Epoch  1 Batch  420 Training err. 3.06579 Training err. RA 3.32032 Valid. err. 3.06783
2018-02-05 11:36:12,515 training [INFO ] Epoch  1 Batch  440 Training err. 3.08817 Training err. RA 3.30977 Valid. err. 3.06747
2018-02-05 11:36:14,154 training [INFO ] Epoch  2 Batch  460 Training err. 3.08389 Training err. RA 3.29995 Valid. err. 3.06668
2018-02-05 11:36:14,974 training [INFO ] Epoch  2 Batch  480 Training err. 3.06766 Training err. RA 3.29027 Valid. err. 3.06625
2018-02-05 11:36:15,770 training [INFO ] Epoch  2 Batch  500 Training err. 3.09244 Training err. RA 3.28236 Valid. err. 3.06385
2018-02-05 11:36:16,576 training [INFO ] Epoch  2 Batch  520 Training err. 3.06803 Training err. RA 3.27412 Valid. err. 3.06315
2018-02-05 11:36:17,379 training [INFO ] Epoch  2 Batch  540 Training err. 3.06920 Training err. RA 3.26653 Valid. err. 3.06172
2018-02-05 11:36:18,180 training [INFO ] Epoch  2 Batch  560 Training err. 3.07311 Training err. RA 3.25962 Valid. err. 3.06149
2018-02-05 11:36:18,989 training [INFO ] Epoch  2 Batch  580 Training err. 3.05969 Training err. RA 3.25272 Valid. err. 3.06013
2018-02-05 11:36:19,783 training [INFO ] Epoch  2 Batch  600 Training err. 3.03755 Training err. RA 3.24555 Valid. err. 3.06045
2018-02-05 11:36:20,573 training [INFO ] Epoch  2 Batch  620 Training err. 3.06920 Training err. RA 3.23986 Valid. err. 3.05952
2018-02-05 11:36:21,467 training [INFO ] Epoch  2 Batch  640 Training err. 3.07091 Training err. RA 3.23458 Valid. err. 3.05761
2018-02-05 11:36:22,381 training [INFO ] Epoch  2 Batch  660 Training err. 3.05367 Training err. RA 3.22910 Valid. err. 3.05686
2018-02-05 11:36:23,257 training [INFO ] Epoch  2 Batch  680 Training err. 3.05473 Training err. RA 3.22397 Valid. err. 3.05558
2018-02-05 11:36:24,064 training [INFO ] Epoch  2 Batch  700 Training err. 3.08261 Training err. RA 3.21993 Valid. err. 3.05385
2018-02-05 11:36:24,935 training [INFO ] Epoch  2 Batch  720 Training err. 3.03824 Training err. RA 3.21489 Valid. err. 3.05402
2018-02-05 11:36:25,759 training [INFO ] Epoch  2 Batch  740 Training err. 3.04819 Training err. RA 3.21038 Valid. err. 3.05356
2018-02-05 11:36:26,610 training [INFO ] Epoch  2 Batch  760 Training err. 3.04894 Training err. RA 3.20613 Valid. err. 3.05060
2018-02-05 11:36:27,444 training [INFO ] Epoch  2 Batch  780 Training err. 3.04817 Training err. RA 3.20208 Valid. err. 3.05000
2018-02-05 11:36:28,278 training [INFO ] Epoch  2 Batch  800 Training err. 3.05481 Training err. RA 3.19840 Valid. err. 3.05000
2018-02-05 11:36:29,099 training [INFO ] Epoch  2 Batch  820 Training err. 3.03798 Training err. RA 3.19449 Valid. err. 3.04775
2018-02-05 11:36:29,907 training [INFO ] Epoch  2 Batch  840 Training err. 3.03442 Training err. RA 3.19068 Valid. err. 3.04694
2018-02-05 11:36:30,702 training [INFO ] Epoch  2 Batch  860 Training err. 3.03829 Training err. RA 3.18713 Valid. err. 3.04529
2018-02-05 11:36:31,493 training [INFO ] Epoch  2 Batch  880 Training err. 3.06824 Training err. RA 3.18443 Valid. err. 3.04268
2018-02-05 11:36:33,130 training [INFO ] Epoch  3 Batch  900 Training err. 3.04916 Training err. RA 3.18142 Valid. err. 3.04100
2018-02-05 11:36:33,935 training [INFO ] Epoch  3 Batch  920 Training err. 3.05430 Training err. RA 3.17866 Valid. err. 3.04039
2018-02-05 11:36:34,727 training [INFO ] Epoch  3 Batch  940 Training err. 3.04766 Training err. RA 3.17587 Valid. err. 3.03746
2018-02-05 11:36:35,520 training [INFO ] Epoch  3 Batch  960 Training err. 3.03631 Training err. RA 3.17297 Valid. err. 3.03498
2018-02-05 11:36:36,303 training [INFO ] Epoch  3 Batch  980 Training err. 3.02867 Training err. RA 3.17002 Valid. err. 3.03346
2018-02-05 11:36:37,119 training [INFO ] Epoch  3 Batch 1000 Training err. 3.05263 Training err. RA 3.16767 Valid. err. 3.02981
2018-02-05 11:36:38,031 training [INFO ] Epoch  3 Batch 1020 Training err. 3.03210 Training err. RA 3.16501 Valid. err. 3.02651
2018-02-05 11:36:38,820 training [INFO ] Epoch  3 Batch 1040 Training err. 3.01016 Training err. RA 3.16204 Valid. err. 3.02464
2018-02-05 11:36:39,639 training [INFO ] Epoch  3 Batch 1060 Training err. 2.99664 Training err. RA 3.15892 Valid. err. 3.02057
2018-02-05 11:36:40,441 training [INFO ] Epoch  3 Batch 1080 Training err. 3.03486 Training err. RA 3.15662 Valid. err. 3.01620
2018-02-05 11:36:41,267 training [INFO ] Epoch  3 Batch 1100 Training err. 3.01446 Training err. RA 3.15403 Valid. err. 3.01046
2018-02-05 11:36:42,065 training [INFO ] Epoch  3 Batch 1120 Training err. 3.00590 Training err. RA 3.15139 Valid. err. 3.00625
2018-02-05 11:36:43,067 training [INFO ] Epoch  3 Batch 1140 Training err. 3.01582 Training err. RA 3.14901 Valid. err. 3.00216
2018-02-05 11:36:43,919 training [INFO ] Epoch  3 Batch 1160 Training err. 3.00806 Training err. RA 3.14658 Valid. err. 2.99708
2018-02-05 11:36:44,716 training [INFO ] Epoch  3 Batch 1180 Training err. 2.98932 Training err. RA 3.14391 Valid. err. 2.99318
2018-02-05 11:36:45,504 training [INFO ] Epoch  3 Batch 1200 Training err. 2.98896 Training err. RA 3.14133 Valid. err. 2.99268
2018-02-05 11:36:46,296 training [INFO ] Epoch  3 Batch 1220 Training err. 2.98192 Training err. RA 3.13872 Valid. err. 2.98553
2018-02-05 11:36:47,110 training [INFO ] Epoch  3 Batch 1240 Training err. 2.99910 Training err. RA 3.13647 Valid. err. 2.98403
2018-02-05 11:36:47,903 training [INFO ] Epoch  3 Batch 1260 Training err. 2.96686 Training err. RA 3.13377 Valid. err. 2.98641
2018-02-05 11:36:48,716 training [INFO ] Epoch  3 Batch 1280 Training err. 2.97616 Training err. RA 3.13131 Valid. err. 2.97490
2018-02-05 11:36:49,522 training [INFO ] Epoch  3 Batch 1300 Training err. 2.95357 Training err. RA 3.12858 Valid. err. 2.96557
2018-02-05 11:36:50,533 training [INFO ] Epoch  3 Batch 1320 Training err. 2.97581 Training err. RA 3.12626 Valid. err. 2.98445
2018-02-05 11:36:51,355 training [INFO ] Epoch  3 Batch 1340 Training err. 2.98399 Training err. RA 3.12414 Valid. err. 2.95450
2018-02-05 11:36:53,002 training [INFO ] Epoch  4 Batch 1360 Training err. 2.96488 Training err. RA 3.12180 Valid. err. 2.96354
2018-02-05 11:36:53,807 training [INFO ] Epoch  4 Batch 1380 Training err. 2.97600 Training err. RA 3.11968 Valid. err. 2.95448
2018-02-05 11:36:54,602 training [INFO ] Epoch  4 Batch 1400 Training err. 2.95273 Training err. RA 3.11730 Valid. err. 2.97354
2018-02-05 11:36:55,394 training [INFO ] Epoch  4 Batch 1420 Training err. 2.95581 Training err. RA 3.11502 Valid. err. 2.93422
2018-02-05 11:36:56,200 training [INFO ] Epoch  4 Batch 1440 Training err. 2.94158 Training err. RA 3.11262 Valid. err. 2.92765
2018-02-05 11:36:56,996 training [INFO ] Epoch  4 Batch 1460 Training err. 2.94622 Training err. RA 3.11034 Valid. err. 2.92298
2018-02-05 11:36:57,783 training [INFO ] Epoch  4 Batch 1480 Training err. 2.90829 Training err. RA 3.10761 Valid. err. 2.93173
2018-02-05 11:36:58,582 training [INFO ] Epoch  4 Batch 1500 Training err. 2.90641 Training err. RA 3.10492 Valid. err. 2.91155
2018-02-05 11:36:59,378 training [INFO ] Epoch  4 Batch 1520 Training err. 2.92591 Training err. RA 3.10257 Valid. err. 2.92732
2018-02-05 11:37:00,172 training [INFO ] Epoch  4 Batch 1540 Training err. 2.89740 Training err. RA 3.09990 Valid. err. 2.90223
2018-02-05 11:37:00,960 training [INFO ] Epoch  4 Batch 1560 Training err. 2.91771 Training err. RA 3.09757 Valid. err. 2.89450
2018-02-05 11:37:01,742 training [INFO ] Epoch  4 Batch 1580 Training err. 2.89619 Training err. RA 3.09502 Valid. err. 2.88617
2018-02-05 11:37:02,525 training [INFO ] Epoch  4 Batch 1600 Training err. 2.89851 Training err. RA 3.09256 Valid. err. 2.87904
2018-02-05 11:37:03,308 training [INFO ] Epoch  4 Batch 1620 Training err. 2.87864 Training err. RA 3.08992 Valid. err. 2.88580
2018-02-05 11:37:04,096 training [INFO ] Epoch  4 Batch 1640 Training err. 2.87853 Training err. RA 3.08734 Valid. err. 2.87765
2018-02-05 11:37:04,880 training [INFO ] Epoch  4 Batch 1660 Training err. 2.85697 Training err. RA 3.08457 Valid. err. 2.87209
2018-02-05 11:37:05,669 training [INFO ] Epoch  4 Batch 1680 Training err. 2.87196 Training err. RA 3.08204 Valid. err. 2.87031
2018-02-05 11:37:06,456 training [INFO ] Epoch  4 Batch 1700 Training err. 2.83582 Training err. RA 3.07914 Valid. err. 2.86023
2018-02-05 11:37:07,260 training [INFO ] Epoch  4 Batch 1720 Training err. 2.85108 Training err. RA 3.07649 Valid. err. 2.86072
2018-02-05 11:37:08,055 training [INFO ] Epoch  4 Batch 1740 Training err. 2.83119 Training err. RA 3.07367 Valid. err. 2.83877
2018-02-05 11:37:08,841 training [INFO ] Epoch  4 Batch 1760 Training err. 2.82937 Training err. RA 3.07089 Valid. err. 2.86726
2018-02-05 11:37:09,630 training [INFO ] Epoch  4 Batch 1780 Training err. 2.84767 Training err. RA 3.06838 Valid. err. 2.82531
2018-02-05 11:37:11,306 training [INFO ] Epoch  5 Batch 1800 Training err. 2.84864 Training err. RA 3.06594 Valid. err. 2.84058
2018-02-05 11:37:12,109 training [INFO ] Epoch  5 Batch 1820 Training err. 2.81807 Training err. RA 3.06322 Valid. err. 2.81599
2018-02-05 11:37:12,904 training [INFO ] Epoch  5 Batch 1840 Training err. 2.83764 Training err. RA 3.06077 Valid. err. 2.80725
2018-02-05 11:37:13,909 training [INFO ] Epoch  5 Batch 1860 Training err. 2.81055 Training err. RA 3.05808 Valid. err. 2.80028
2018-02-05 11:37:14,706 training [INFO ] Epoch  5 Batch 1880 Training err. 2.80446 Training err. RA 3.05538 Valid. err. 2.79363
2018-02-05 11:37:15,511 training [INFO ] Epoch  5 Batch 1900 Training err. 2.81203 Training err. RA 3.05282 Valid. err. 2.81945
2018-02-05 11:37:16,300 training [INFO ] Epoch  5 Batch 1920 Training err. 2.79421 Training err. RA 3.05012 Valid. err. 2.78692
2018-02-05 11:37:17,087 training [INFO ] Epoch  5 Batch 1940 Training err. 2.74477 Training err. RA 3.04698 Valid. err. 2.81150
2018-02-05 11:37:17,875 training [INFO ] Epoch  5 Batch 1960 Training err. 2.77212 Training err. RA 3.04417 Valid. err. 2.77040
2018-02-05 11:37:18,679 training [INFO ] Epoch  5 Batch 1980 Training err. 2.80027 Training err. RA 3.04171 Valid. err. 2.79703
2018-02-05 11:37:19,488 training [INFO ] Epoch  5 Batch 2000 Training err. 2.76078 Training err. RA 3.03890 Valid. err. 2.78414
2018-02-05 11:37:20,279 training [INFO ] Epoch  5 Batch 2020 Training err. 2.76530 Training err. RA 3.03619 Valid. err. 2.77243
2018-02-05 11:37:21,069 training [INFO ] Epoch  5 Batch 2040 Training err. 2.76603 Training err. RA 3.03354 Valid. err. 2.74919
2018-02-05 11:37:21,858 training [INFO ] Epoch  5 Batch 2060 Training err. 2.74151 Training err. RA 3.03070 Valid. err. 2.76772
2018-02-05 11:37:22,647 training [INFO ] Epoch  5 Batch 2080 Training err. 2.75080 Training err. RA 3.02801 Valid. err. 2.76014
2018-02-05 11:37:23,432 training [INFO ] Epoch  5 Batch 2100 Training err. 2.73661 Training err. RA 3.02524 Valid. err. 2.73342
2018-02-05 11:37:24,216 training [INFO ] Epoch  5 Batch 2120 Training err. 2.73328 Training err. RA 3.02248 Valid. err. 2.73471
2018-02-05 11:37:25,001 training [INFO ] Epoch  5 Batch 2140 Training err. 2.72306 Training err. RA 3.01969 Valid. err. 2.74081
2018-02-05 11:37:25,785 training [INFO ] Epoch  5 Batch 2160 Training err. 2.70945 Training err. RA 3.01681 Valid. err. 2.72000
2018-02-05 11:37:26,599 training [INFO ] Epoch  5 Batch 2180 Training err. 2.72285 Training err. RA 3.01412 Valid. err. 2.71911
2018-02-05 11:37:27,390 training [INFO ] Epoch  5 Batch 2200 Training err. 2.71072 Training err. RA 3.01136 Valid. err. 2.73243
2018-02-05 11:37:28,178 training [INFO ] Epoch  5 Batch 2220 Training err. 2.73973 Training err. RA 3.00891 Valid. err. 2.73135
2018-02-05 11:37:28,965 training [INFO ] Epoch  5 Batch 2240 Training err. 2.71188 Training err. RA 3.00626 Valid. err. 2.70692
2018-02-05 11:37:30,615 training [INFO ] Epoch  6 Batch 2260 Training err. 2.69503 Training err. RA 3.00350 Valid. err. 2.70484
2018-02-05 11:37:31,403 training [INFO ] Epoch  6 Batch 2280 Training err. 2.72987 Training err. RA 3.00110 Valid. err. 2.69732
2018-02-05 11:37:32,186 training [INFO ] Epoch  6 Batch 2300 Training err. 2.72044 Training err. RA 2.99866 Valid. err. 2.73358
2018-02-05 11:37:32,971 training [INFO ] Epoch  6 Batch 2320 Training err. 2.69607 Training err. RA 2.99605 Valid. err. 2.70960
2018-02-05 11:37:33,757 training [INFO ] Epoch  6 Batch 2340 Training err. 2.70704 Training err. RA 2.99358 Valid. err. 2.68779
2018-02-05 11:37:34,541 training [INFO ] Epoch  6 Batch 2360 Training err. 2.69162 Training err. RA 2.99103 Valid. err. 2.68864
2018-02-05 11:37:35,323 training [INFO ] Epoch  6 Batch 2380 Training err. 2.67598 Training err. RA 2.98838 Valid. err. 2.69951
2018-02-05 11:37:36,113 training [INFO ] Epoch  6 Batch 2400 Training err. 2.64637 Training err. RA 2.98553 Valid. err. 2.67872
2018-02-05 11:37:36,899 training [INFO ] Epoch  6 Batch 2420 Training err. 2.69712 Training err. RA 2.98314 Valid. err. 2.68106
2018-02-05 11:37:37,682 training [INFO ] Epoch  6 Batch 2440 Training err. 2.66815 Training err. RA 2.98056 Valid. err. 2.68467
2018-02-05 11:37:38,466 training [INFO ] Epoch  6 Batch 2460 Training err. 2.68310 Training err. RA 2.97814 Valid. err. 2.72900
2018-02-05 11:37:39,253 training [INFO ] Epoch  6 Batch 2480 Training err. 2.67014 Training err. RA 2.97566 Valid. err. 2.66774
2018-02-05 11:37:40,041 training [INFO ] Epoch  6 Batch 2500 Training err. 2.67835 Training err. RA 2.97328 Valid. err. 2.67476
2018-02-05 11:37:40,823 training [INFO ] Epoch  6 Batch 2520 Training err. 2.64430 Training err. RA 2.97067 Valid. err. 2.66387
2018-02-05 11:37:41,612 training [INFO ] Epoch  6 Batch 2540 Training err. 2.64913 Training err. RA 2.96814 Valid. err. 2.66738
2018-02-05 11:37:42,402 training [INFO ] Epoch  6 Batch 2560 Training err. 2.65242 Training err. RA 2.96567 Valid. err. 2.66132
2018-02-05 11:37:43,203 training [INFO ] Epoch  6 Batch 2580 Training err. 2.64964 Training err. RA 2.96322 Valid. err. 2.65873
2018-02-05 11:37:43,987 training [INFO ] Epoch  6 Batch 2600 Training err. 2.63372 Training err. RA 2.96069 Valid. err. 2.65442
2018-02-05 11:37:44,774 training [INFO ] Epoch  6 Batch 2620 Training err. 2.64576 Training err. RA 2.95828 Valid. err. 2.65150
2018-02-05 11:37:45,561 training [INFO ] Epoch  6 Batch 2640 Training err. 2.63412 Training err. RA 2.95583 Valid. err. 2.65094
2018-02-05 11:37:46,344 training [INFO ] Epoch  6 Batch 2660 Training err. 2.64305 Training err. RA 2.95348 Valid. err. 2.66472
2018-02-05 11:37:47,129 training [INFO ] Epoch  6 Batch 2680 Training err. 2.67049 Training err. RA 2.95136 Valid. err. 2.65663
2018-02-05 11:37:48,763 training [INFO ] Epoch  7 Batch 2700 Training err. 2.62804 Training err. RA 2.94897 Valid. err. 2.63965
2018-02-05 11:37:49,552 training [INFO ] Epoch  7 Batch 2720 Training err. 2.63011 Training err. RA 2.94662 Valid. err. 2.66769
2018-02-05 11:37:50,338 training [INFO ] Epoch  7 Batch 2740 Training err. 2.67254 Training err. RA 2.94462 Valid. err. 2.63347
2018-02-05 11:37:51,127 training [INFO ] Epoch  7 Batch 2760 Training err. 2.64713 Training err. RA 2.94247 Valid. err. 2.63488
2018-02-05 11:37:51,912 training [INFO ] Epoch  7 Batch 2780 Training err. 2.63801 Training err. RA 2.94028 Valid. err. 2.64242
2018-02-05 11:37:52,700 training [INFO ] Epoch  7 Batch 2800 Training err. 2.63222 Training err. RA 2.93808 Valid. err. 2.63472
2018-02-05 11:37:53,484 training [INFO ] Epoch  7 Batch 2820 Training err. 2.61111 Training err. RA 2.93576 Valid. err. 2.62676
2018-02-05 11:37:54,271 training [INFO ] Epoch  7 Batch 2840 Training err. 2.59541 Training err. RA 2.93336 Valid. err. 2.70073
2018-02-05 11:37:55,058 training [INFO ] Epoch  7 Batch 2860 Training err. 2.61672 Training err. RA 2.93115 Valid. err. 2.61849
2018-02-05 11:37:55,845 training [INFO ] Epoch  7 Batch 2880 Training err. 2.61490 Training err. RA 2.92895 Valid. err. 2.65977
2018-02-05 11:37:56,645 training [INFO ] Epoch  7 Batch 2900 Training err. 2.62081 Training err. RA 2.92683 Valid. err. 2.62233
2018-02-05 11:37:57,436 training [INFO ] Epoch  7 Batch 2920 Training err. 2.60087 Training err. RA 2.92459 Valid. err. 2.63142
2018-02-05 11:37:58,221 training [INFO ] Epoch  7 Batch 2940 Training err. 2.62965 Training err. RA 2.92259 Valid. err. 2.61117
2018-02-05 11:37:59,019 training [INFO ] Epoch  7 Batch 2960 Training err. 2.59529 Training err. RA 2.92038 Valid. err. 2.61581
2018-02-05 11:37:59,824 training [INFO ] Epoch  7 Batch 2980 Training err. 2.59917 Training err. RA 2.91822 Valid. err. 2.63287
2018-02-05 11:38:00,620 training [INFO ] Epoch  7 Batch 3000 Training err. 2.59314 Training err. RA 2.91605 Valid. err. 2.61357
2018-02-05 11:38:01,408 training [INFO ] Epoch  7 Batch 3020 Training err. 2.59341 Training err. RA 2.91392 Valid. err. 2.61181
2018-02-05 11:38:02,197 training [INFO ] Epoch  7 Batch 3040 Training err. 2.58961 Training err. RA 2.91178 Valid. err. 2.63154
2018-02-05 11:38:02,982 training [INFO ] Epoch  7 Batch 3060 Training err. 2.58159 Training err. RA 2.90962 Valid. err. 2.63171
2018-02-05 11:38:03,770 training [INFO ] Epoch  7 Batch 3080 Training err. 2.59530 Training err. RA 2.90758 Valid. err. 2.61295
2018-02-05 11:38:04,555 training [INFO ] Epoch  7 Batch 3100 Training err. 2.58103 Training err. RA 2.90548 Valid. err. 2.62647
2018-02-05 11:38:05,340 training [INFO ] Epoch  7 Batch 3120 Training err. 2.63010 Training err. RA 2.90371 Valid. err. 2.60970
2018-02-05 11:38:06,949 training [INFO ] Epoch  8 Batch 3140 Training err. 2.58519 Training err. RA 2.90168 Valid. err. 2.59988
2018-02-05 11:38:07,738 training [INFO ] Epoch  8 Batch 3160 Training err. 2.58350 Training err. RA 2.89967 Valid. err. 2.59760
2018-02-05 11:38:08,528 training [INFO ] Epoch  8 Batch 3180 Training err. 2.60306 Training err. RA 2.89780 Valid. err. 2.59759
2018-02-05 11:38:09,311 training [INFO ] Epoch  8 Batch 3200 Training err. 2.60041 Training err. RA 2.89594 Valid. err. 2.59303
2018-02-05 11:38:10,098 training [INFO ] Epoch  8 Batch 3220 Training err. 2.58559 Training err. RA 2.89402 Valid. err. 2.58900
2018-02-05 11:38:10,886 training [INFO ] Epoch  8 Batch 3240 Training err. 2.59525 Training err. RA 2.89217 Valid. err. 2.58470
2018-02-05 11:38:11,669 training [INFO ] Epoch  8 Batch 3260 Training err. 2.58507 Training err. RA 2.89029 Valid. err. 2.58276
2018-02-05 11:38:12,460 training [INFO ] Epoch  8 Batch 3280 Training err. 2.55198 Training err. RA 2.88823 Valid. err. 2.63780
2018-02-05 11:38:13,245 training [INFO ] Epoch  8 Batch 3300 Training err. 2.55443 Training err. RA 2.88620 Valid. err. 2.58829
2018-02-05 11:38:14,035 training [INFO ] Epoch  8 Batch 3320 Training err. 2.58245 Training err. RA 2.88437 Valid. err. 2.58305
2018-02-05 11:38:14,821 training [INFO ] Epoch  8 Batch 3340 Training err. 2.56556 Training err. RA 2.88246 Valid. err. 2.59105
2018-02-05 11:38:15,615 training [INFO ] Epoch  8 Batch 3360 Training err. 2.57293 Training err. RA 2.88062 Valid. err. 2.59310
2018-02-05 11:38:16,401 training [INFO ] Epoch  8 Batch 3380 Training err. 2.56844 Training err. RA 2.87877 Valid. err. 2.58309
2018-02-05 11:38:17,189 training [INFO ] Epoch  8 Batch 3400 Training err. 2.58170 Training err. RA 2.87703 Valid. err. 2.57776
2018-02-05 11:38:18,002 training [INFO ] Epoch  8 Batch 3420 Training err. 2.55238 Training err. RA 2.87513 Valid. err. 2.57255
2018-02-05 11:38:18,846 training [INFO ] Epoch  8 Batch 3440 Training err. 2.54533 Training err. RA 2.87321 Valid. err. 2.58065
2018-02-05 11:38:19,645 training [INFO ] Epoch  8 Batch 3460 Training err. 2.54835 Training err. RA 2.87133 Valid. err. 2.57057
2018-02-05 11:38:20,451 training [INFO ] Epoch  8 Batch 3480 Training err. 2.56478 Training err. RA 2.86957 Valid. err. 2.56528
2018-02-05 11:38:21,255 training [INFO ] Epoch  8 Batch 3500 Training err. 2.53180 Training err. RA 2.86764 Valid. err. 2.57331
2018-02-05 11:38:22,061 training [INFO ] Epoch  8 Batch 3520 Training err. 2.55122 Training err. RA 2.86584 Valid. err. 2.57826
2018-02-05 11:38:22,863 training [INFO ] Epoch  8 Batch 3540 Training err. 2.53761 Training err. RA 2.86399 Valid. err. 2.56122
2018-02-05 11:38:23,684 training [INFO ] Epoch  8 Batch 3560 Training err. 2.57076 Training err. RA 2.86234 Valid. err. 2.59022
2018-02-05 11:38:24,566 training [INFO ] Epoch  8 Batch 3580 Training err. 2.56266 Training err. RA 2.86067 Valid. err. 2.56463
2018-02-05 11:38:26,239 training [INFO ] Epoch  9 Batch 3600 Training err. 2.54829 Training err. RA 2.85893 Valid. err. 2.56058
2018-02-05 11:38:27,042 training [INFO ] Epoch  9 Batch 3620 Training err. 2.55863 Training err. RA 2.85727 Valid. err. 2.58858
2018-02-05 11:38:27,870 training [INFO ] Epoch  9 Batch 3640 Training err. 2.56009 Training err. RA 2.85564 Valid. err. 2.57932
2018-02-05 11:38:28,764 training [INFO ] Epoch  9 Batch 3660 Training err. 2.57281 Training err. RA 2.85409 Valid. err. 2.55196
2018-02-05 11:38:29,635 training [INFO ] Epoch  9 Batch 3680 Training err. 2.54666 Training err. RA 2.85242 Valid. err. 2.55086
2018-02-05 11:38:30,428 training [INFO ] Epoch  9 Batch 3700 Training err. 2.55268 Training err. RA 2.85080 Valid. err. 2.55407
2018-02-05 11:38:31,228 training [INFO ] Epoch  9 Batch 3720 Training err. 2.51384 Training err. RA 2.84899 Valid. err. 2.54936
2018-02-05 11:38:32,028 training [INFO ] Epoch  9 Batch 3740 Training err. 2.51780 Training err. RA 2.84722 Valid. err. 2.56116
2018-02-05 11:38:32,826 training [INFO ] Epoch  9 Batch 3760 Training err. 2.54695 Training err. RA 2.84562 Valid. err. 2.54993
2018-02-05 11:38:33,630 training [INFO ] Epoch  9 Batch 3780 Training err. 2.51124 Training err. RA 2.84385 Valid. err. 2.54858
2018-02-05 11:38:34,430 training [INFO ] Epoch  9 Batch 3800 Training err. 2.54915 Training err. RA 2.84230 Valid. err. 2.54785
2018-02-05 11:38:35,249 training [INFO ] Epoch  9 Batch 3820 Training err. 2.52142 Training err. RA 2.84062 Valid. err. 2.54310
2018-02-05 11:38:36,039 training [INFO ] Epoch  9 Batch 3840 Training err. 2.54840 Training err. RA 2.83910 Valid. err. 2.56742
2018-02-05 11:38:36,825 training [INFO ] Epoch  9 Batch 3860 Training err. 2.51550 Training err. RA 2.83742 Valid. err. 2.54097
2018-02-05 11:38:37,609 training [INFO ] Epoch  9 Batch 3880 Training err. 2.52545 Training err. RA 2.83582 Valid. err. 2.53815
2018-02-05 11:38:38,392 training [INFO ] Epoch  9 Batch 3900 Training err. 2.50768 Training err. RA 2.83413 Valid. err. 2.53837
2018-02-05 11:38:39,217 training [INFO ] Epoch  9 Batch 3920 Training err. 2.52860 Training err. RA 2.83257 Valid. err. 2.54646
2018-02-05 11:38:40,081 training [INFO ] Epoch  9 Batch 3940 Training err. 2.50101 Training err. RA 2.83089 Valid. err. 2.54737
2018-02-05 11:38:40,902 training [INFO ] Epoch  9 Batch 3960 Training err. 2.51836 Training err. RA 2.82931 Valid. err. 2.56313
2018-02-05 11:38:41,773 training [INFO ] Epoch  9 Batch 3980 Training err. 2.50702 Training err. RA 2.82769 Valid. err. 2.53277
2018-02-05 11:38:42,747 training [INFO ] Epoch  9 Batch 4000 Training err. 2.50813 Training err. RA 2.82610 Valid. err. 2.52781
2018-02-05 11:38:43,699 training [INFO ] Epoch  9 Batch 4020 Training err. 2.53929 Training err. RA 2.82467 Valid. err. 2.54036
2018-02-05 11:38:45,589 training [INFO ] Epoch 10 Batch 4040 Training err. 2.52025 Training err. RA 2.82316 Valid. err. 2.52903
2018-02-05 11:38:46,528 training [INFO ] Epoch 10 Batch 4060 Training err. 2.51157 Training err. RA 2.82163 Valid. err. 2.53019
2018-02-05 11:38:47,486 training [INFO ] Epoch 10 Batch 4080 Training err. 2.53986 Training err. RA 2.82025 Valid. err. 2.52990
2018-02-05 11:38:48,431 training [INFO ] Epoch 10 Batch 4100 Training err. 2.52425 Training err. RA 2.81880 Valid. err. 2.52654
2018-02-05 11:38:49,383 training [INFO ] Epoch 10 Batch 4120 Training err. 2.51973 Training err. RA 2.81735 Valid. err. 2.52374
2018-02-05 11:38:50,338 training [INFO ] Epoch 10 Batch 4140 Training err. 2.51753 Training err. RA 2.81590 Valid. err. 2.52739
2018-02-05 11:38:51,286 training [INFO ] Epoch 10 Batch 4160 Training err. 2.51074 Training err. RA 2.81443 Valid. err. 2.52187
2018-02-05 11:38:52,239 training [INFO ] Epoch 10 Batch 4180 Training err. 2.47688 Training err. RA 2.81282 Valid. err. 2.53560
2018-02-05 11:38:53,182 training [INFO ] Epoch 10 Batch 4200 Training err. 2.47868 Training err. RA 2.81123 Valid. err. 2.53660
2018-02-05 11:38:54,132 training [INFO ] Epoch 10 Batch 4220 Training err. 2.51590 Training err. RA 2.80983 Valid. err. 2.53003
2018-02-05 11:38:55,080 training [INFO ] Epoch 10 Batch 4240 Training err. 2.50306 Training err. RA 2.80838 Valid. err. 2.52293
2018-02-05 11:38:56,046 training [INFO ] Epoch 10 Batch 4260 Training err. 2.49630 Training err. RA 2.80692 Valid. err. 2.52431
2018-02-05 11:38:56,988 training [INFO ] Epoch 10 Batch 4280 Training err. 2.50840 Training err. RA 2.80552 Valid. err. 2.51579
2018-02-05 11:38:57,944 training [INFO ] Epoch 10 Batch 4300 Training err. 2.49357 Training err. RA 2.80407 Valid. err. 2.51594
2018-02-05 11:38:58,907 training [INFO ] Epoch 10 Batch 4320 Training err. 2.50071 Training err. RA 2.80267 Valid. err. 2.54819
2018-02-05 11:38:59,843 training [INFO ] Epoch 10 Batch 4340 Training err. 2.48108 Training err. RA 2.80118 Valid. err. 2.50659
2018-02-05 11:39:00,791 training [INFO ] Epoch 10 Batch 4360 Training err. 2.48975 Training err. RA 2.79976 Valid. err. 2.51345
2018-02-05 11:39:01,744 training [INFO ] Epoch 10 Batch 4380 Training err. 2.48129 Training err. RA 2.79830 Valid. err. 2.51825
2018-02-05 11:39:02,690 training [INFO ] Epoch 10 Batch 4400 Training err. 2.46457 Training err. RA 2.79678 Valid. err. 2.50383
2018-02-05 11:39:03,641 training [INFO ] Epoch 10 Batch 4420 Training err. 2.48681 Training err. RA 2.79538 Valid. err. 2.50626
2018-02-05 11:39:04,592 training [INFO ] Epoch 10 Batch 4440 Training err. 2.48404 Training err. RA 2.79398 Valid. err. 2.52581
2018-02-05 11:39:05,571 training [INFO ] Epoch 10 Batch 4460 Training err. 2.50965 Training err. RA 2.79270 Valid. err. 2.51849
2018-02-05 11:39:06,528 training [INFO ] Epoch 10 Batch 4480 Training err. 2.47907 Training err. RA 2.79130 Valid. err. 2.50128
2018-02-05 11:39:08,401 training [INFO ] Epoch 11 Batch 4500 Training err. 2.47502 Training err. RA 2.78990 Valid. err. 2.50854
2018-02-05 11:39:09,361 training [INFO ] Epoch 11 Batch 4520 Training err. 2.50268 Training err. RA 2.78863 Valid. err. 2.49502
2018-02-05 11:39:10,304 training [INFO ] Epoch 11 Batch 4540 Training err. 2.51419 Training err. RA 2.78742 Valid. err. 2.51168
2018-02-05 11:39:11,245 training [INFO ] Epoch 11 Batch 4560 Training err. 2.49004 Training err. RA 2.78611 Valid. err. 2.50979
2018-02-05 11:39:12,190 training [INFO ] Epoch 11 Batch 4580 Training err. 2.48978 Training err. RA 2.78482 Valid. err. 2.49322
2018-02-05 11:39:13,137 training [INFO ] Epoch 11 Batch 4600 Training err. 2.47549 Training err. RA 2.78348 Valid. err. 2.49959
2018-02-05 11:39:14,034 training [INFO ] Epoch 11 Batch 4620 Training err. 2.46847 Training err. RA 2.78211 Valid. err. 2.53158
2018-02-05 11:39:14,915 training [INFO ] Epoch 11 Batch 4640 Training err. 2.42713 Training err. RA 2.78058 Valid. err. 2.49280
2018-02-05 11:39:15,782 training [INFO ] Epoch 11 Batch 4660 Training err. 2.50055 Training err. RA 2.77938 Valid. err. 2.49072
2018-02-05 11:39:16,695 training [INFO ] Epoch 11 Batch 4680 Training err. 2.44875 Training err. RA 2.77797 Valid. err. 2.51806
2018-02-05 11:39:17,529 training [INFO ] Epoch 11 Batch 4700 Training err. 2.48999 Training err. RA 2.77674 Valid. err. 2.54013
2018-02-05 11:39:18,333 training [INFO ] Epoch 11 Batch 4720 Training err. 2.46823 Training err. RA 2.77543 Valid. err. 2.48551
2018-02-05 11:39:19,129 training [INFO ] Epoch 11 Batch 4740 Training err. 2.49328 Training err. RA 2.77424 Valid. err. 2.49024
2018-02-05 11:39:19,929 training [INFO ] Epoch 11 Batch 4760 Training err. 2.44606 Training err. RA 2.77286 Valid. err. 2.48344
2018-02-05 11:39:20,718 training [INFO ] Epoch 11 Batch 4780 Training err. 2.45343 Training err. RA 2.77153 Valid. err. 2.49231
2018-02-05 11:39:21,500 training [INFO ] Epoch 11 Batch 4800 Training err. 2.46152 Training err. RA 2.77024 Valid. err. 2.48513
2018-02-05 11:39:22,296 training [INFO ] Epoch 11 Batch 4820 Training err. 2.46963 Training err. RA 2.76899 Valid. err. 2.48331
2018-02-05 11:39:23,080 training [INFO ] Epoch 11 Batch 4840 Training err. 2.43276 Training err. RA 2.76760 Valid. err. 2.47796
2018-02-05 11:39:23,875 training [INFO ] Epoch 11 Batch 4860 Training err. 2.45593 Training err. RA 2.76632 Valid. err. 2.48426
2018-02-05 11:39:24,663 training [INFO ] Epoch 11 Batch 4880 Training err. 2.44988 Training err. RA 2.76502 Valid. err. 2.47961
2018-02-05 11:39:25,450 training [INFO ] Epoch 11 Batch 4900 Training err. 2.46304 Training err. RA 2.76379 Valid. err. 2.47784
2018-02-05 11:39:26,245 training [INFO ] Epoch 11 Batch 4920 Training err. 2.47993 Training err. RA 2.76263 Valid. err. 2.48690
2018-02-05 11:39:27,849 training [INFO ] Epoch 12 Batch 4940 Training err. 2.44725 Training err. RA 2.76136 Valid. err. 2.47727
2018-02-05 11:39:28,642 training [INFO ] Epoch 12 Batch 4960 Training err. 2.45667 Training err. RA 2.76013 Valid. err. 2.47623
2018-02-05 11:39:29,438 training [INFO ] Epoch 12 Batch 4980 Training err. 2.49132 Training err. RA 2.75905 Valid. err. 2.48176
2018-02-05 11:39:30,226 training [INFO ] Epoch 12 Batch 5000 Training err. 2.47916 Training err. RA 2.75793 Valid. err. 2.47074
2018-02-05 11:39:31,013 training [INFO ] Epoch 12 Batch 5020 Training err. 2.46285 Training err. RA 2.75675 Valid. err. 2.48019
2018-02-05 11:39:31,802 training [INFO ] Epoch 12 Batch 5040 Training err. 2.44956 Training err. RA 2.75553 Valid. err. 2.46824
2018-02-05 11:39:32,594 training [INFO ] Epoch 12 Batch 5060 Training err. 2.43802 Training err. RA 2.75428 Valid. err. 2.47073
2018-02-05 11:39:33,393 training [INFO ] Epoch 12 Batch 5080 Training err. 2.41742 Training err. RA 2.75295 Valid. err. 2.49161
2018-02-05 11:39:34,195 training [INFO ] Epoch 12 Batch 5100 Training err. 2.44150 Training err. RA 2.75173 Valid. err. 2.46479
2018-02-05 11:39:34,986 training [INFO ] Epoch 12 Batch 5120 Training err. 2.44394 Training err. RA 2.75053 Valid. err. 2.47001
2018-02-05 11:39:35,773 training [INFO ] Epoch 12 Batch 5140 Training err. 2.45491 Training err. RA 2.74938 Valid. err. 2.46954
2018-02-05 11:39:36,558 training [INFO ] Epoch 12 Batch 5160 Training err. 2.43298 Training err. RA 2.74815 Valid. err. 2.48293
2018-02-05 11:39:37,350 training [INFO ] Epoch 12 Batch 5180 Training err. 2.46468 Training err. RA 2.74706 Valid. err. 2.45854
2018-02-05 11:39:38,129 training [INFO ] Epoch 12 Batch 5200 Training err. 2.43416 Training err. RA 2.74586 Valid. err. 2.46725
2018-02-05 11:39:38,917 training [INFO ] Epoch 12 Batch 5220 Training err. 2.43574 Training err. RA 2.74467 Valid. err. 2.47545
2018-02-05 11:39:39,706 training [INFO ] Epoch 12 Batch 5240 Training err. 2.42914 Training err. RA 2.74346 Valid. err. 2.46071
2018-02-05 11:39:40,494 training [INFO ] Epoch 12 Batch 5260 Training err. 2.43128 Training err. RA 2.74228 Valid. err. 2.45535
2018-02-05 11:39:41,279 training [INFO ] Epoch 12 Batch 5280 Training err. 2.43016 Training err. RA 2.74109 Valid. err. 2.47701
2018-02-05 11:39:42,064 training [INFO ] Epoch 12 Batch 5300 Training err. 2.42174 Training err. RA 2.73989 Valid. err. 2.47295
2018-02-05 11:39:42,848 training [INFO ] Epoch 12 Batch 5320 Training err. 2.42946 Training err. RA 2.73872 Valid. err. 2.46598
2018-02-05 11:39:43,640 training [INFO ] Epoch 12 Batch 5340 Training err. 2.42797 Training err. RA 2.73756 Valid. err. 2.46185
2018-02-05 11:39:44,432 training [INFO ] Epoch 12 Batch 5360 Training err. 2.46578 Training err. RA 2.73654 Valid. err. 2.45306
2018-02-05 11:39:46,022 training [INFO ] Epoch 13 Batch 5380 Training err. 2.42708 Training err. RA 2.73539 Valid. err. 2.45887
2018-02-05 11:39:46,808 training [INFO ] Epoch 13 Batch 5400 Training err. 2.42988 Training err. RA 2.73426 Valid. err. 2.44755
2018-02-05 11:39:47,601 training [INFO ] Epoch 13 Batch 5420 Training err. 2.44387 Training err. RA 2.73319 Valid. err. 2.44891
2018-02-05 11:39:48,390 training [INFO ] Epoch 13 Batch 5440 Training err. 2.44958 Training err. RA 2.73215 Valid. err. 2.45160
2018-02-05 11:39:49,181 training [INFO ] Epoch 13 Batch 5460 Training err. 2.43785 Training err. RA 2.73107 Valid. err. 2.44497
2018-02-05 11:39:49,968 training [INFO ] Epoch 13 Batch 5480 Training err. 2.43832 Training err. RA 2.73000 Valid. err. 2.44535
2018-02-05 11:39:50,754 training [INFO ] Epoch 13 Batch 5500 Training err. 2.43025 Training err. RA 2.72891 Valid. err. 2.44920
2018-02-05 11:39:51,538 training [INFO ] Epoch 13 Batch 5520 Training err. 2.40116 Training err. RA 2.72772 Valid. err. 2.46857
2018-02-05 11:39:52,328 training [INFO ] Epoch 13 Batch 5540 Training err. 2.38668 Training err. RA 2.72649 Valid. err. 2.44231
2018-02-05 11:39:53,111 training [INFO ] Epoch 13 Batch 5560 Training err. 2.43593 Training err. RA 2.72545 Valid. err. 2.44248
2018-02-05 11:39:53,895 training [INFO ] Epoch 13 Batch 5580 Training err. 2.41316 Training err. RA 2.72433 Valid. err. 2.43808
2018-02-05 11:39:54,690 training [INFO ] Epoch 13 Batch 5600 Training err. 2.42819 Training err. RA 2.72327 Valid. err. 2.44819
2018-02-05 11:39:55,642 training [INFO ] Epoch 13 Batch 5620 Training err. 2.42409 Training err. RA 2.72221 Valid. err. 2.44462
2018-02-05 11:39:56,569 training [INFO ] Epoch 13 Batch 5640 Training err. 2.44094 Training err. RA 2.72121 Valid. err. 2.43564
2018-02-05 11:39:57,501 training [INFO ] Epoch 13 Batch 5660 Training err. 2.40884 Training err. RA 2.72010 Valid. err. 2.43839
2018-02-05 11:39:58,396 training [INFO ] Epoch 13 Batch 5680 Training err. 2.39226 Training err. RA 2.71895 Valid. err. 2.45087
2018-02-05 11:39:59,189 training [INFO ] Epoch 13 Batch 5700 Training err. 2.40513 Training err. RA 2.71785 Valid. err. 2.44124
2018-02-05 11:40:00,074 training [INFO ] Epoch 13 Batch 5720 Training err. 2.42562 Training err. RA 2.71683 Valid. err. 2.43534
2018-02-05 11:40:00,993 training [INFO ] Epoch 13 Batch 5740 Training err. 2.38605 Training err. RA 2.71567 Valid. err. 2.44041
2018-02-05 11:40:01,956 training [INFO ] Epoch 13 Batch 5760 Training err. 2.40681 Training err. RA 2.71460 Valid. err. 2.44175
2018-02-05 11:40:02,820 training [INFO ] Epoch 13 Batch 5780 Training err. 2.40172 Training err. RA 2.71352 Valid. err. 2.42875
2018-02-05 11:40:03,604 training [INFO ] Epoch 13 Batch 5800 Training err. 2.42532 Training err. RA 2.71253 Valid. err. 2.43752
2018-02-05 11:40:04,393 training [INFO ] Epoch 13 Batch 5820 Training err. 2.41867 Training err. RA 2.71152 Valid. err. 2.43302
2018-02-05 11:40:05,997 training [INFO ] Epoch 14 Batch 5840 Training err. 2.41134 Training err. RA 2.71049 Valid. err. 2.42754
2018-02-05 11:40:06,786 training [INFO ] Epoch 14 Batch 5860 Training err. 2.41671 Training err. RA 2.70948 Valid. err. 2.43001
2018-02-05 11:40:07,588 training [INFO ] Epoch 14 Batch 5880 Training err. 2.41764 Training err. RA 2.70849 Valid. err. 2.44076
2018-02-05 11:40:08,426 training [INFO ] Epoch 14 Batch 5900 Training err. 2.44226 Training err. RA 2.70759 Valid. err. 2.42180
2018-02-05 11:40:09,285 training [INFO ] Epoch 14 Batch 5920 Training err. 2.40616 Training err. RA 2.70657 Valid. err. 2.42188
2018-02-05 11:40:10,146 training [INFO ] Epoch 14 Batch 5940 Training err. 2.41096 Training err. RA 2.70558 Valid. err. 2.42438
2018-02-05 11:40:11,012 training [INFO ] Epoch 14 Batch 5960 Training err. 2.38148 Training err. RA 2.70449 Valid. err. 2.42086
2018-02-05 11:40:11,883 training [INFO ] Epoch 14 Batch 5980 Training err. 2.36729 Training err. RA 2.70336 Valid. err. 2.42848
2018-02-05 11:40:12,735 training [INFO ] Epoch 14 Batch 6000 Training err. 2.40970 Training err. RA 2.70238 Valid. err. 2.42931
2018-02-05 11:40:13,525 training [INFO ] Epoch 14 Batch 6020 Training err. 2.37912 Training err. RA 2.70131 Valid. err. 2.45187
2018-02-05 11:40:14,311 training [INFO ] Epoch 14 Batch 6040 Training err. 2.41648 Training err. RA 2.70036 Valid. err. 2.42474
2018-02-05 11:40:15,090 training [INFO ] Epoch 14 Batch 6060 Training err. 2.38969 Training err. RA 2.69934 Valid. err. 2.41903
2018-02-05 11:40:15,882 training [INFO ] Epoch 14 Batch 6080 Training err. 2.42321 Training err. RA 2.69843 Valid. err. 2.44044
2018-02-05 11:40:16,669 training [INFO ] Epoch 14 Batch 6100 Training err. 2.38073 Training err. RA 2.69739 Valid. err. 2.41618
2018-02-05 11:40:17,455 training [INFO ] Epoch 14 Batch 6120 Training err. 2.39348 Training err. RA 2.69640 Valid. err. 2.41277
2018-02-05 11:40:18,239 training [INFO ] Epoch 14 Batch 6140 Training err. 2.37537 Training err. RA 2.69535 Valid. err. 2.41535
2018-02-05 11:40:19,018 training [INFO ] Epoch 14 Batch 6160 Training err. 2.40130 Training err. RA 2.69440 Valid. err. 2.42509
2018-02-05 11:40:19,801 training [INFO ] Epoch 14 Batch 6180 Training err. 2.37071 Training err. RA 2.69335 Valid. err. 2.41274
2018-02-05 11:40:20,589 training [INFO ] Epoch 14 Batch 6200 Training err. 2.38998 Training err. RA 2.69237 Valid. err. 2.43184
2018-02-05 11:40:21,386 training [INFO ] Epoch 14 Batch 6220 Training err. 2.38019 Training err. RA 2.69137 Valid. err. 2.41313
2018-02-05 11:40:22,167 training [INFO ] Epoch 14 Batch 6240 Training err. 2.38150 Training err. RA 2.69037 Valid. err. 2.40837
2018-02-05 11:40:22,953 training [INFO ] Epoch 14 Batch 6260 Training err. 2.40650 Training err. RA 2.68947 Valid. err. 2.41553
2018-02-05 11:40:24,514 training [INFO ] Epoch 15 Batch 6280 Training err. 2.39367 Training err. RA 2.68852 Valid. err. 2.41021
2018-02-05 11:40:25,303 training [INFO ] Epoch 15 Batch 6300 Training err. 2.38675 Training err. RA 2.68757 Valid. err. 2.41010
2018-02-05 11:40:26,093 training [INFO ] Epoch 15 Batch 6320 Training err. 2.40480 Training err. RA 2.68667 Valid. err. 2.40519
2018-02-05 11:40:26,882 training [INFO ] Epoch 15 Batch 6340 Training err. 2.39933 Training err. RA 2.68576 Valid. err. 2.40630
2018-02-05 11:40:27,670 training [INFO ] Epoch 15 Batch 6360 Training err. 2.39539 Training err. RA 2.68485 Valid. err. 2.40490
2018-02-05 11:40:28,456 training [INFO ] Epoch 15 Batch 6380 Training err. 2.39237 Training err. RA 2.68393 Valid. err. 2.40014
2018-02-05 11:40:29,262 training [INFO ] Epoch 15 Batch 6400 Training err. 2.38611 Training err. RA 2.68300 Valid. err. 2.40983
2018-02-05 11:40:30,096 training [INFO ] Epoch 15 Batch 6420 Training err. 2.35167 Training err. RA 2.68197 Valid. err. 2.40248
2018-02-05 11:40:30,919 training [INFO ] Epoch 15 Batch 6440 Training err. 2.34578 Training err. RA 2.68093 Valid. err. 2.42144
2018-02-05 11:40:31,730 training [INFO ] Epoch 15 Batch 6460 Training err. 2.39447 Training err. RA 2.68004 Valid. err. 2.40862
2018-02-05 11:40:32,534 training [INFO ] Epoch 15 Batch 6480 Training err. 2.37926 Training err. RA 2.67911 Valid. err. 2.40820
2018-02-05 11:40:33,383 training [INFO ] Epoch 15 Batch 6500 Training err. 2.37810 Training err. RA 2.67819 Valid. err. 2.41450
2018-02-05 11:40:34,187 training [INFO ] Epoch 15 Batch 6520 Training err. 2.38924 Training err. RA 2.67730 Valid. err. 2.40178
2018-02-05 11:40:35,042 training [INFO ] Epoch 15 Batch 6540 Training err. 2.37654 Training err. RA 2.67638 Valid. err. 2.39564
2018-02-05 11:40:35,899 training [INFO ] Epoch 15 Batch 6560 Training err. 2.38260 Training err. RA 2.67548 Valid. err. 2.43433
2018-02-05 11:40:36,735 training [INFO ] Epoch 15 Batch 6580 Training err. 2.35646 Training err. RA 2.67451 Valid. err. 2.39299
2018-02-05 11:40:37,529 training [INFO ] Epoch 15 Batch 6600 Training err. 2.36748 Training err. RA 2.67358 Valid. err. 2.40028
2018-02-05 11:40:38,353 training [INFO ] Epoch 15 Batch 6620 Training err. 2.36526 Training err. RA 2.67265 Valid. err. 2.41127
2018-02-05 11:40:39,169 training [INFO ] Epoch 15 Batch 6640 Training err. 2.35095 Training err. RA 2.67168 Valid. err. 2.39192
2018-02-05 11:40:39,964 training [INFO ] Epoch 15 Batch 6660 Training err. 2.36566 Training err. RA 2.67076 Valid. err. 2.39295
2018-02-05 11:40:40,763 training [INFO ] Epoch 15 Batch 6680 Training err. 2.37281 Training err. RA 2.66987 Valid. err. 2.39912
2018-02-05 11:40:41,612 training [INFO ] Epoch 15 Batch 6700 Training err. 2.38750 Training err. RA 2.66903 Valid. err. 2.40628
2018-02-05 11:40:42,603 training [INFO ] Epoch 15 Batch 6720 Training err. 2.36323 Training err. RA 2.66812 Valid. err. 2.39208
2018-02-05 11:40:44,282 training [INFO ] Epoch 16 Batch 6740 Training err. 2.35863 Training err. RA 2.66720 Valid. err. 2.39833
2018-02-05 11:40:45,087 training [INFO ] Epoch 16 Batch 6760 Training err. 2.37965 Training err. RA 2.66635 Valid. err. 2.38893
2018-02-05 11:40:45,882 training [INFO ] Epoch 16 Batch 6780 Training err. 2.39681 Training err. RA 2.66556 Valid. err. 2.40549
2018-02-05 11:40:46,685 training [INFO ] Epoch 16 Batch 6800 Training err. 2.37908 Training err. RA 2.66471 Valid. err. 2.40253
2018-02-05 11:40:47,479 training [INFO ] Epoch 16 Batch 6820 Training err. 2.37327 Training err. RA 2.66386 Valid. err. 2.38393
2018-02-05 11:40:48,264 training [INFO ] Epoch 16 Batch 6840 Training err. 2.36288 Training err. RA 2.66298 Valid. err. 2.38593
2018-02-05 11:40:49,045 training [INFO ] Epoch 16 Batch 6860 Training err. 2.35475 Training err. RA 2.66208 Valid. err. 2.41490
2018-02-05 11:40:49,832 training [INFO ] Epoch 16 Batch 6880 Training err. 2.30713 Training err. RA 2.66105 Valid. err. 2.38257
2018-02-05 11:40:50,631 training [INFO ] Epoch 16 Batch 6900 Training err. 2.38459 Training err. RA 2.66025 Valid. err. 2.38524
2018-02-05 11:40:51,414 training [INFO ] Epoch 16 Batch 6920 Training err. 2.34081 Training err. RA 2.65932 Valid. err. 2.40129
2018-02-05 11:40:52,205 training [INFO ] Epoch 16 Batch 6940 Training err. 2.37453 Training err. RA 2.65850 Valid. err. 2.41777
2018-02-05 11:40:52,991 training [INFO ] Epoch 16 Batch 6960 Training err. 2.35830 Training err. RA 2.65764 Valid. err. 2.37798
2018-02-05 11:40:53,774 training [INFO ] Epoch 16 Batch 6980 Training err. 2.38793 Training err. RA 2.65687 Valid. err. 2.38657
2018-02-05 11:40:54,563 training [INFO ] Epoch 16 Batch 7000 Training err. 2.33511 Training err. RA 2.65595 Valid. err. 2.37720
2018-02-05 11:40:55,350 training [INFO ] Epoch 16 Batch 7020 Training err. 2.34039 Training err. RA 2.65505 Valid. err. 2.38537
2018-02-05 11:40:56,139 training [INFO ] Epoch 16 Batch 7040 Training err. 2.35189 Training err. RA 2.65419 Valid. err. 2.38062
2018-02-05 11:40:56,925 training [INFO ] Epoch 16 Batch 7060 Training err. 2.36056 Training err. RA 2.65336 Valid. err. 2.37448
2018-02-05 11:40:57,723 training [INFO ] Epoch 16 Batch 7080 Training err. 2.32689 Training err. RA 2.65243 Valid. err. 2.37445
2018-02-05 11:40:58,515 training [INFO ] Epoch 16 Batch 7100 Training err. 2.34779 Training err. RA 2.65158 Valid. err. 2.37898
2018-02-05 11:40:59,312 training [INFO ] Epoch 16 Batch 7120 Training err. 2.34403 Training err. RA 2.65071 Valid. err. 2.37762
2018-02-05 11:41:00,098 training [INFO ] Epoch 16 Batch 7140 Training err. 2.35446 Training err. RA 2.64988 Valid. err. 2.37615
2018-02-05 11:41:00,886 training [INFO ] Epoch 16 Batch 7160 Training err. 2.37437 Training err. RA 2.64911 Valid. err. 2.38391
2018-02-05 11:41:02,481 training [INFO ] Epoch 17 Batch 7180 Training err. 2.33794 Training err. RA 2.64825 Valid. err. 2.37248
2018-02-05 11:41:03,280 training [INFO ] Epoch 17 Batch 7200 Training err. 2.34926 Training err. RA 2.64741 Valid. err. 2.36938
2018-02-05 11:41:04,071 training [INFO ] Epoch 17 Batch 7220 Training err. 2.37933 Training err. RA 2.64667 Valid. err. 2.37323
2018-02-05 11:41:04,858 training [INFO ] Epoch 17 Batch 7240 Training err. 2.37220 Training err. RA 2.64591 Valid. err. 2.36940
2018-02-05 11:41:05,647 training [INFO ] Epoch 17 Batch 7260 Training err. 2.35697 Training err. RA 2.64512 Valid. err. 2.37632
2018-02-05 11:41:06,441 training [INFO ] Epoch 17 Batch 7280 Training err. 2.34397 Training err. RA 2.64429 Valid. err. 2.36708
2018-02-05 11:41:07,228 training [INFO ] Epoch 17 Batch 7300 Training err. 2.33456 Training err. RA 2.64344 Valid. err. 2.36594
2018-02-05 11:41:08,019 training [INFO ] Epoch 17 Batch 7320 Training err. 2.31176 Training err. RA 2.64254 Valid. err. 2.37545
2018-02-05 11:41:08,816 training [INFO ] Epoch 17 Batch 7340 Training err. 2.33341 Training err. RA 2.64169 Valid. err. 2.36398
2018-02-05 11:41:09,607 training [INFO ] Epoch 17 Batch 7360 Training err. 2.33997 Training err. RA 2.64087 Valid. err. 2.36339
2018-02-05 11:41:10,393 training [INFO ] Epoch 17 Batch 7380 Training err. 2.35495 Training err. RA 2.64010 Valid. err. 2.37190
2018-02-05 11:41:11,177 training [INFO ] Epoch 17 Batch 7400 Training err. 2.32848 Training err. RA 2.63926 Valid. err. 2.37433
2018-02-05 11:41:11,968 training [INFO ] Epoch 17 Batch 7420 Training err. 2.36519 Training err. RA 2.63852 Valid. err. 2.36344
2018-02-05 11:41:12,754 training [INFO ] Epoch 17 Batch 7440 Training err. 2.33283 Training err. RA 2.63770 Valid. err. 2.36977
2018-02-05 11:41:13,545 training [INFO ] Epoch 17 Batch 7460 Training err. 2.33472 Training err. RA 2.63688 Valid. err. 2.36929
2018-02-05 11:41:14,334 training [INFO ] Epoch 17 Batch 7480 Training err. 2.32775 Training err. RA 2.63606 Valid. err. 2.36838
2018-02-05 11:41:15,115 training [INFO ] Epoch 17 Batch 7500 Training err. 2.32692 Training err. RA 2.63523 Valid. err. 2.36001
2018-02-05 11:41:15,900 training [INFO ] Epoch 17 Batch 7520 Training err. 2.33407 Training err. RA 2.63443 Valid. err. 2.36948
2018-02-05 11:41:16,693 training [INFO ] Epoch 17 Batch 7540 Training err. 2.32743 Training err. RA 2.63362 Valid. err. 2.37545
2018-02-05 11:41:17,488 training [INFO ] Epoch 17 Batch 7560 Training err. 2.32638 Training err. RA 2.63280 Valid. err. 2.37188
2018-02-05 11:41:18,279 training [INFO ] Epoch 17 Batch 7580 Training err. 2.33137 Training err. RA 2.63201 Valid. err. 2.37346
2018-02-05 11:41:19,080 training [INFO ] Epoch 17 Batch 7600 Training err. 2.36514 Training err. RA 2.63131 Valid. err. 2.35923
2018-02-05 11:41:20,705 training [INFO ] Epoch 18 Batch 7620 Training err. 2.32684 Training err. RA 2.63051 Valid. err. 2.36004
2018-02-05 11:41:21,484 training [INFO ] Epoch 18 Batch 7640 Training err. 2.33027 Training err. RA 2.62972 Valid. err. 2.35256
2018-02-05 11:41:22,309 training [INFO ] Epoch 18 Batch 7660 Training err. 2.34057 Training err. RA 2.62897 Valid. err. 2.35556
2018-02-05 11:41:23,109 training [INFO ] Epoch 18 Batch 7680 Training err. 2.34909 Training err. RA 2.62824 Valid. err. 2.35849
2018-02-05 11:41:23,892 training [INFO ] Epoch 18 Batch 7700 Training err. 2.34086 Training err. RA 2.62749 Valid. err. 2.35178
2018-02-05 11:41:24,703 training [INFO ] Epoch 18 Batch 7720 Training err. 2.34234 Training err. RA 2.62675 Valid. err. 2.35483
2018-02-05 11:41:25,516 training [INFO ] Epoch 18 Batch 7740 Training err. 2.33506 Training err. RA 2.62600 Valid. err. 2.36010
2018-02-05 11:41:26,297 training [INFO ] Epoch 18 Batch 7760 Training err. 2.30342 Training err. RA 2.62517 Valid. err. 2.35858
2018-02-05 11:41:27,094 training [INFO ] Epoch 18 Batch 7780 Training err. 2.28925 Training err. RA 2.62430 Valid. err. 2.35032
2018-02-05 11:41:27,878 training [INFO ] Epoch 18 Batch 7800 Training err. 2.33874 Training err. RA 2.62357 Valid. err. 2.35024
2018-02-05 11:41:28,669 training [INFO ] Epoch 18 Batch 7820 Training err. 2.31959 Training err. RA 2.62279 Valid. err. 2.34612
2018-02-05 11:41:29,614 training [INFO ] Epoch 18 Batch 7840 Training err. 2.33135 Training err. RA 2.62205 Valid. err. 2.35346
2018-02-05 11:41:30,528 training [INFO ] Epoch 18 Batch 7860 Training err. 2.33224 Training err. RA 2.62131 Valid. err. 2.34950
2018-02-05 11:41:31,400 training [INFO ] Epoch 18 Batch 7880 Training err. 2.34823 Training err. RA 2.62062 Valid. err. 2.34628
2018-02-05 11:41:32,260 training [INFO ] Epoch 18 Batch 7900 Training err. 2.31615 Training err. RA 2.61985 Valid. err. 2.35184
2018-02-05 11:41:33,275 training [INFO ] Epoch 18 Batch 7920 Training err. 2.29351 Training err. RA 2.61903 Valid. err. 2.36138
2018-02-05 11:41:34,253 training [INFO ] Epoch 18 Batch 7940 Training err. 2.31278 Training err. RA 2.61825 Valid. err. 2.34944
2018-02-05 11:41:35,206 training [INFO ] Epoch 18 Batch 7960 Training err. 2.33478 Training err. RA 2.61754 Valid. err. 2.34305
2018-02-05 11:41:36,162 training [INFO ] Epoch 18 Batch 7980 Training err. 2.29414 Training err. RA 2.61673 Valid. err. 2.35184
2018-02-05 11:41:37,110 training [INFO ] Epoch 18 Batch 8000 Training err. 2.31499 Training err. RA 2.61598 Valid. err. 2.35141
2018-02-05 11:41:38,065 training [INFO ] Epoch 18 Batch 8020 Training err. 2.31420 Training err. RA 2.61522 Valid. err. 2.34040
2018-02-05 11:41:39,029 training [INFO ] Epoch 18 Batch 8040 Training err. 2.32993 Training err. RA 2.61451 Valid. err. 2.34692
2018-02-05 11:41:39,977 training [INFO ] Epoch 18 Batch 8060 Training err. 2.33008 Training err. RA 2.61381 Valid. err. 2.35007
2018-02-05 11:41:41,823 training [INFO ] Epoch 19 Batch 8080 Training err. 2.31860 Training err. RA 2.61308 Valid. err. 2.33827
2018-02-05 11:41:42,778 training [INFO ] Epoch 19 Batch 8100 Training err. 2.32305 Training err. RA 2.61236 Valid. err. 2.33877
2018-02-05 11:41:43,739 training [INFO ] Epoch 19 Batch 8120 Training err. 2.32528 Training err. RA 2.61166 Valid. err. 2.35222
2018-02-05 11:41:44,692 training [INFO ] Epoch 19 Batch 8140 Training err. 2.35072 Training err. RA 2.61101 Valid. err. 2.33652
2018-02-05 11:41:45,637 training [INFO ] Epoch 19 Batch 8160 Training err. 2.31624 Training err. RA 2.61029 Valid. err. 2.33666
2018-02-05 11:41:46,585 training [INFO ] Epoch 19 Batch 8180 Training err. 2.32108 Training err. RA 2.60958 Valid. err. 2.33855
2018-02-05 11:41:47,561 training [INFO ] Epoch 19 Batch 8200 Training err. 2.29338 Training err. RA 2.60881 Valid. err. 2.33540
2018-02-05 11:41:48,509 training [INFO ] Epoch 19 Batch 8220 Training err. 2.27725 Training err. RA 2.60801 Valid. err. 2.34283
2018-02-05 11:41:49,456 training [INFO ] Epoch 19 Batch 8240 Training err. 2.31872 Training err. RA 2.60730 Valid. err. 2.34718
2018-02-05 11:41:50,404 training [INFO ] Epoch 19 Batch 8260 Training err. 2.29536 Training err. RA 2.60655 Valid. err. 2.36987
2018-02-05 11:41:51,353 training [INFO ] Epoch 19 Batch 8280 Training err. 2.32857 Training err. RA 2.60588 Valid. err. 2.33585
2018-02-05 11:41:52,301 training [INFO ] Epoch 19 Batch 8300 Training err. 2.29916 Training err. RA 2.60514 Valid. err. 2.33696
2018-02-05 11:41:53,239 training [INFO ] Epoch 19 Batch 8320 Training err. 2.34093 Training err. RA 2.60450 Valid. err. 2.34527
2018-02-05 11:41:54,187 training [INFO ] Epoch 19 Batch 8340 Training err. 2.29093 Training err. RA 2.60375 Valid. err. 2.33332
2018-02-05 11:41:55,136 training [INFO ] Epoch 19 Batch 8360 Training err. 2.30356 Training err. RA 2.60303 Valid. err. 2.32979
2018-02-05 11:41:56,087 training [INFO ] Epoch 19 Batch 8380 Training err. 2.29142 Training err. RA 2.60229 Valid. err. 2.33535
2018-02-05 11:41:57,037 training [INFO ] Epoch 19 Batch 8400 Training err. 2.31545 Training err. RA 2.60161 Valid. err. 2.33953
2018-02-05 11:41:57,996 training [INFO ] Epoch 19 Batch 8420 Training err. 2.28509 Training err. RA 2.60085 Valid. err. 2.32963
2018-02-05 11:41:58,946 training [INFO ] Epoch 19 Batch 8440 Training err. 2.30874 Training err. RA 2.60016 Valid. err. 2.34253
2018-02-05 11:41:59,903 training [INFO ] Epoch 19 Batch 8460 Training err. 2.29281 Training err. RA 2.59944 Valid. err. 2.33271
2018-02-05 11:42:00,864 training [INFO ] Epoch 19 Batch 8480 Training err. 2.29787 Training err. RA 2.59872 Valid. err. 2.32718
2018-02-05 11:42:01,808 training [INFO ] Epoch 19 Batch 8500 Training err. 2.32183 Training err. RA 2.59807 Valid. err. 2.33190
2018-02-05 11:42:03,706 training [INFO ] Epoch 20 Batch 8520 Training err. 2.30821 Training err. RA 2.59739 Valid. err. 2.33180
2018-02-05 11:42:04,661 training [INFO ] Epoch 20 Batch 8540 Training err. 2.30133 Training err. RA 2.59670 Valid. err. 2.33475
2018-02-05 11:42:05,483 training [INFO ] Epoch 20 Batch 8560 Training err. 2.31897 Training err. RA 2.59605 Valid. err. 2.32493
2018-02-05 11:42:06,252 training [INFO ] Epoch 20 Batch 8580 Training err. 2.31268 Training err. RA 2.59539 Valid. err. 2.32705
2018-02-05 11:42:07,022 training [INFO ] Epoch 20 Batch 8600 Training err. 2.31051 Training err. RA 2.59473 Valid. err. 2.32577
2018-02-05 11:42:07,813 training [INFO ] Epoch 20 Batch 8620 Training err. 2.31147 Training err. RA 2.59407 Valid. err. 2.32318
2018-02-05 11:42:08,622 training [INFO ] Epoch 20 Batch 8640 Training err. 2.30434 Training err. RA 2.59340 Valid. err. 2.33521
2018-02-05 11:42:09,418 training [INFO ] Epoch 20 Batch 8660 Training err. 2.26983 Training err. RA 2.59265 Valid. err. 2.32414
2018-02-05 11:42:10,218 training [INFO ] Epoch 20 Batch 8680 Training err. 2.26237 Training err. RA 2.59189 Valid. err. 2.33660
2018-02-05 11:42:11,099 training [INFO ] Epoch 20 Batch 8700 Training err. 2.31216 Training err. RA 2.59125 Valid. err. 2.32653
2018-02-05 11:42:12,063 training [INFO ] Epoch 20 Batch 8720 Training err. 2.30023 Training err. RA 2.59058 Valid. err. 2.32894
2018-02-05 11:42:12,892 training [INFO ] Epoch 20 Batch 8740 Training err. 2.29616 Training err. RA 2.58991 Valid. err. 2.33688
2018-02-05 11:42:13,746 training [INFO ] Epoch 20 Batch 8760 Training err. 2.30975 Training err. RA 2.58927 Valid. err. 2.32572
2018-02-05 11:42:14,583 training [INFO ] Epoch 20 Batch 8780 Training err. 2.29582 Training err. RA 2.58860 Valid. err. 2.31697
2018-02-05 11:42:15,369 training [INFO ] Epoch 20 Batch 8800 Training err. 2.30096 Training err. RA 2.58795 Valid. err. 2.35056
2018-02-05 11:42:16,139 training [INFO ] Epoch 20 Batch 8820 Training err. 2.27681 Training err. RA 2.58724 Valid. err. 2.31648
2018-02-05 11:42:16,920 training [INFO ] Epoch 20 Batch 8840 Training err. 2.28461 Training err. RA 2.58655 Valid. err. 2.32471
2018-02-05 11:42:17,708 training [INFO ] Epoch 20 Batch 8860 Training err. 2.28876 Training err. RA 2.58588 Valid. err. 2.33379
2018-02-05 11:42:18,496 training [INFO ] Epoch 20 Batch 8880 Training err. 2.27196 Training err. RA 2.58518 Valid. err. 2.31551
2018-02-05 11:42:19,268 training [INFO ] Epoch 20 Batch 8900 Training err. 2.28549 Training err. RA 2.58450 Valid. err. 2.31875
2018-02-05 11:42:20,047 training [INFO ] Epoch 20 Batch 8920 Training err. 2.29605 Training err. RA 2.58386 Valid. err. 2.31895
2018-02-05 11:42:20,850 training [INFO ] Epoch 20 Batch 8940 Training err. 2.30591 Training err. RA 2.58323 Valid. err. 2.33285
2018-02-05 11:42:21,642 training [INFO ] Epoch 20 Batch 8960 Training err. 2.28784 Training err. RA 2.58257 Valid. err. 2.31555
2018-02-05 11:42:23,239 training [INFO ] Epoch 21 Batch 8980 Training err. 2.28011 Training err. RA 2.58190 Valid. err. 2.32274
2018-02-05 11:42:24,018 training [INFO ] Epoch 21 Batch 9000 Training err. 2.29738 Training err. RA 2.58127 Valid. err. 2.31674
2018-02-05 11:42:24,798 training [INFO ] Epoch 21 Batch 9020 Training err. 2.31641 Training err. RA 2.58068 Valid. err. 2.32545
2018-02-05 11:42:25,577 training [INFO ] Epoch 21 Batch 9040 Training err. 2.30428 Training err. RA 2.58007 Valid. err. 2.32788
2018-02-05 11:42:26,435 training [INFO ] Epoch 21 Batch 9060 Training err. 2.29436 Training err. RA 2.57944 Valid. err. 2.31095
2018-02-05 11:42:27,203 training [INFO ] Epoch 21 Batch 9080 Training err. 2.28769 Training err. RA 2.57880 Valid. err. 2.31099
2018-02-05 11:42:27,972 training [INFO ] Epoch 21 Batch 9100 Training err. 2.27917 Training err. RA 2.57814 Valid. err. 2.33739
2018-02-05 11:42:28,749 training [INFO ] Epoch 21 Batch 9120 Training err. 2.23011 Training err. RA 2.57737 Valid. err. 2.30853
2018-02-05 11:42:29,528 training [INFO ] Epoch 21 Batch 9140 Training err. 2.30747 Training err. RA 2.57678 Valid. err. 2.31114
2018-02-05 11:42:30,299 training [INFO ] Epoch 21 Batch 9160 Training err. 2.26985 Training err. RA 2.57611 Valid. err. 2.32552
2018-02-05 11:42:31,066 training [INFO ] Epoch 21 Batch 9180 Training err. 2.29756 Training err. RA 2.57551 Valid. err. 2.33445
2018-02-05 11:42:31,839 training [INFO ] Epoch 21 Batch 9200 Training err. 2.28203 Training err. RA 2.57487 Valid. err. 2.30709
2018-02-05 11:42:32,617 training [INFO ] Epoch 21 Batch 9220 Training err. 2.31362 Training err. RA 2.57430 Valid. err. 2.31561
2018-02-05 11:42:33,391 training [INFO ] Epoch 21 Batch 9240 Training err. 2.25889 Training err. RA 2.57362 Valid. err. 2.30595
2018-02-05 11:42:34,162 training [INFO ] Epoch 21 Batch 9260 Training err. 2.26460 Training err. RA 2.57295 Valid. err. 2.31633
2018-02-05 11:42:34,938 training [INFO ] Epoch 21 Batch 9280 Training err. 2.27828 Training err. RA 2.57232 Valid. err. 2.30589
2018-02-05 11:42:35,712 training [INFO ] Epoch 21 Batch 9300 Training err. 2.28809 Training err. RA 2.57171 Valid. err. 2.30401
2018-02-05 11:42:36,480 training [INFO ] Epoch 21 Batch 9320 Training err. 2.25204 Training err. RA 2.57102 Valid. err. 2.30363
2018-02-05 11:42:37,258 training [INFO ] Epoch 21 Batch 9340 Training err. 2.27265 Training err. RA 2.57038 Valid. err. 2.30977
2018-02-05 11:42:38,031 training [INFO ] Epoch 21 Batch 9360 Training err. 2.27090 Training err. RA 2.56974 Valid. err. 2.31163
2018-02-05 11:42:38,809 training [INFO ] Epoch 21 Batch 9380 Training err. 2.28130 Training err. RA 2.56913 Valid. err. 2.30634
2018-02-05 11:42:39,578 training [INFO ] Epoch 21 Batch 9400 Training err. 2.30349 Training err. RA 2.56856 Valid. err. 2.31387
2018-02-05 11:42:41,166 training [INFO ] Epoch 22 Batch 9420 Training err. 2.26438 Training err. RA 2.56792 Valid. err. 2.30550
2018-02-05 11:42:41,939 training [INFO ] Epoch 22 Batch 9440 Training err. 2.27257 Training err. RA 2.56729 Valid. err. 2.29968
2018-02-05 11:42:42,710 training [INFO ] Epoch 22 Batch 9460 Training err. 2.30689 Training err. RA 2.56674 Valid. err. 2.30245
2018-02-05 11:42:43,702 training [INFO ] Epoch 22 Batch 9480 Training err. 2.29906 Training err. RA 2.56617 Valid. err. 2.29797
2018-02-05 11:42:44,536 training [INFO ] Epoch 22 Batch 9500 Training err. 2.28540 Training err. RA 2.56558 Valid. err. 2.30233
2018-02-05 11:42:45,377 training [INFO ] Epoch 22 Batch 9520 Training err. 2.27215 Training err. RA 2.56497 Valid. err. 2.29946
2018-02-05 11:42:46,176 training [INFO ] Epoch 22 Batch 9540 Training err. 2.26286 Training err. RA 2.56433 Valid. err. 2.29898
2018-02-05 11:42:47,118 training [INFO ] Epoch 22 Batch 9560 Training err. 2.24090 Training err. RA 2.56366 Valid. err. 2.30447
2018-02-05 11:42:47,966 training [INFO ] Epoch 22 Batch 9580 Training err. 2.26278 Training err. RA 2.56303 Valid. err. 2.29629
2018-02-05 11:42:48,757 training [INFO ] Epoch 22 Batch 9600 Training err. 2.27020 Training err. RA 2.56242 Valid. err. 2.29513
2018-02-05 11:42:49,663 training [INFO ] Epoch 22 Batch 9620 Training err. 2.28643 Training err. RA 2.56184 Valid. err. 2.30480
2018-02-05 11:42:50,470 training [INFO ] Epoch 22 Batch 9640 Training err. 2.25557 Training err. RA 2.56121 Valid. err. 2.30558
2018-02-05 11:42:51,294 training [INFO ] Epoch 22 Batch 9660 Training err. 2.29812 Training err. RA 2.56066 Valid. err. 2.29729
2018-02-05 11:42:52,081 training [INFO ] Epoch 22 Batch 9680 Training err. 2.25986 Training err. RA 2.56004 Valid. err. 2.30156
2018-02-05 11:42:52,930 training [INFO ] Epoch 22 Batch 9700 Training err. 2.26477 Training err. RA 2.55943 Valid. err. 2.29851
2018-02-05 11:42:53,719 training [INFO ] Epoch 22 Batch 9720 Training err. 2.25884 Training err. RA 2.55882 Valid. err. 2.30342
2018-02-05 11:42:54,507 training [INFO ] Epoch 22 Batch 9740 Training err. 2.25589 Training err. RA 2.55819 Valid. err. 2.29480
2018-02-05 11:42:55,302 training [INFO ] Epoch 22 Batch 9760 Training err. 2.26664 Training err. RA 2.55760 Valid. err. 2.30126
2018-02-05 11:42:56,078 training [INFO ] Epoch 22 Batch 9780 Training err. 2.25942 Training err. RA 2.55699 Valid. err. 2.30662
2018-02-05 11:42:56,867 training [INFO ] Epoch 22 Batch 9800 Training err. 2.25436 Training err. RA 2.55637 Valid. err. 2.31100
2018-02-05 11:42:57,659 training [INFO ] Epoch 22 Batch 9820 Training err. 2.26428 Training err. RA 2.55577 Valid. err. 2.31002
2018-02-05 11:42:58,434 training [INFO ] Epoch 22 Batch 9840 Training err. 2.29633 Training err. RA 2.55525 Valid. err. 2.29890
2018-02-05 11:43:00,019 training [INFO ] Epoch 23 Batch 9860 Training err. 2.25705 Training err. RA 2.55464 Valid. err. 2.29266
2018-02-05 11:43:00,804 training [INFO ] Epoch 23 Batch 9880 Training err. 2.26112 Training err. RA 2.55405 Valid. err. 2.28846
2018-02-05 11:43:01,596 training [INFO ] Epoch 23 Batch 9900 Training err. 2.26963 Training err. RA 2.55347 Valid. err. 2.28941
2018-02-05 11:43:02,393 training [INFO ] Epoch 23 Batch 9920 Training err. 2.27895 Training err. RA 2.55292 Valid. err. 2.29697
2018-02-05 11:43:03,174 training [INFO ] Epoch 23 Batch 9940 Training err. 2.27566 Training err. RA 2.55236 Valid. err. 2.28710
2018-02-05 11:43:03,946 training [INFO ] Epoch 23 Batch 9960 Training err. 2.27582 Training err. RA 2.55181 Valid. err. 2.28887
2018-02-05 11:43:04,727 training [INFO ] Epoch 23 Batch 9980 Training err. 2.26723 Training err. RA 2.55124 Valid. err. 2.29609
2018-02-05 11:43:05,509 training [INFO ] Epoch 23 Batch10000 Training err. 2.23737 Training err. RA 2.55061 Valid. err. 2.29013
2018-02-05 11:43:06,280 training [INFO ] Epoch 23 Batch10020 Training err. 2.22236 Training err. RA 2.54995 Valid. err. 2.28653
2018-02-05 11:43:07,049 training [INFO ] Epoch 23 Batch10040 Training err. 2.27221 Training err. RA 2.54940 Valid. err. 2.28932
2018-02-05 11:43:07,825 training [INFO ] Epoch 23 Batch10060 Training err. 2.25550 Training err. RA 2.54882 Valid. err. 2.28592
2018-02-05 11:43:08,610 training [INFO ] Epoch 23 Batch10080 Training err. 2.26496 Training err. RA 2.54825 Valid. err. 2.28745
2018-02-05 11:43:09,382 training [INFO ] Epoch 23 Batch10100 Training err. 2.26706 Training err. RA 2.54770 Valid. err. 2.28317
2018-02-05 11:43:10,167 training [INFO ] Epoch 23 Batch10120 Training err. 2.28069 Training err. RA 2.54717 Valid. err. 2.28306
2018-02-05 11:43:10,950 training [INFO ] Epoch 23 Batch10140 Training err. 2.25141 Training err. RA 2.54658 Valid. err. 2.29134
2018-02-05 11:43:11,725 training [INFO ] Epoch 23 Batch10160 Training err. 2.22675 Training err. RA 2.54595 Valid. err. 2.29546
2018-02-05 11:43:12,498 training [INFO ] Epoch 23 Batch10180 Training err. 2.24697 Training err. RA 2.54537 Valid. err. 2.28504
2018-02-05 11:43:13,269 training [INFO ] Epoch 23 Batch10200 Training err. 2.27266 Training err. RA 2.54483 Valid. err. 2.27929
2018-02-05 11:43:14,054 training [INFO ] Epoch 23 Batch10220 Training err. 2.22525 Training err. RA 2.54421 Valid. err. 2.28769
2018-02-05 11:43:14,841 training [INFO ] Epoch 23 Batch10240 Training err. 2.24790 Training err. RA 2.54363 Valid. err. 2.29254
2018-02-05 11:43:15,625 training [INFO ] Epoch 23 Batch10260 Training err. 2.25107 Training err. RA 2.54306 Valid. err. 2.28113
2018-02-05 11:43:16,417 training [INFO ] Epoch 23 Batch10280 Training err. 2.26314 Training err. RA 2.54251 Valid. err. 2.28408
2018-02-05 11:43:17,203 training [INFO ] Epoch 23 Batch10300 Training err. 2.26689 Training err. RA 2.54198 Valid. err. 2.28622
2018-02-05 11:43:18,815 training [INFO ] Epoch 24 Batch10320 Training err. 2.25290 Training err. RA 2.54142 Valid. err. 2.27805
2018-02-05 11:43:19,594 training [INFO ] Epoch 24 Batch10340 Training err. 2.25538 Training err. RA 2.54087 Valid. err. 2.27639
2018-02-05 11:43:20,376 training [INFO ] Epoch 24 Batch10360 Training err. 2.26045 Training err. RA 2.54032 Valid. err. 2.28621
2018-02-05 11:43:21,153 training [INFO ] Epoch 24 Batch10380 Training err. 2.28691 Training err. RA 2.53984 Valid. err. 2.27532
2018-02-05 11:43:21,950 training [INFO ] Epoch 24 Batch10400 Training err. 2.25363 Training err. RA 2.53929 Valid. err. 2.27712
2018-02-05 11:43:22,889 training [INFO ] Epoch 24 Batch10420 Training err. 2.25635 Training err. RA 2.53874 Valid. err. 2.27994
2018-02-05 11:43:23,809 training [INFO ] Epoch 24 Batch10440 Training err. 2.23059 Training err. RA 2.53815 Valid. err. 2.27653
2018-02-05 11:43:24,608 training [INFO ] Epoch 24 Batch10460 Training err. 2.21302 Training err. RA 2.53753 Valid. err. 2.28528
2018-02-05 11:43:25,406 training [INFO ] Epoch 24 Batch10480 Training err. 2.25547 Training err. RA 2.53699 Valid. err. 2.28640
2018-02-05 11:43:26,177 training [INFO ] Epoch 24 Batch10500 Training err. 2.23626 Training err. RA 2.53642 Valid. err. 2.30912
2018-02-05 11:43:26,969 training [INFO ] Epoch 24 Batch10520 Training err. 2.26599 Training err. RA 2.53590 Valid. err. 2.27600
2018-02-05 11:43:27,759 training [INFO ] Epoch 24 Batch10540 Training err. 2.23661 Training err. RA 2.53534 Valid. err. 2.27578
2018-02-05 11:43:28,593 training [INFO ] Epoch 24 Batch10560 Training err. 2.27938 Training err. RA 2.53485 Valid. err. 2.28195
2018-02-05 11:43:29,390 training [INFO ] Epoch 24 Batch10580 Training err. 2.22556 Training err. RA 2.53427 Valid. err. 2.27285
2018-02-05 11:43:30,165 training [INFO ] Epoch 24 Batch10600 Training err. 2.23998 Training err. RA 2.53371 Valid. err. 2.27073
2018-02-05 11:43:30,939 training [INFO ] Epoch 24 Batch10620 Training err. 2.23066 Training err. RA 2.53314 Valid. err. 2.27572
2018-02-05 11:43:31,832 training [INFO ] Epoch 24 Batch10640 Training err. 2.25507 Training err. RA 2.53262 Valid. err. 2.28749
2018-02-05 11:43:32,754 training [INFO ] Epoch 24 Batch10660 Training err. 2.22093 Training err. RA 2.53203 Valid. err. 2.27065
2018-02-05 11:43:33,544 training [INFO ] Epoch 24 Batch10680 Training err. 2.24486 Training err. RA 2.53150 Valid. err. 2.27986
2018-02-05 11:43:34,399 training [INFO ] Epoch 24 Batch10700 Training err. 2.23034 Training err. RA 2.53093 Valid. err. 2.27357
2018-02-05 11:43:35,270 training [INFO ] Epoch 24 Batch10720 Training err. 2.23686 Training err. RA 2.53038 Valid. err. 2.26790
2018-02-05 11:43:36,118 training [INFO ] Epoch 24 Batch10740 Training err. 2.26062 Training err. RA 2.52988 Valid. err. 2.27515
2018-02-05 11:43:37,846 training [INFO ] Epoch 25 Batch10760 Training err. 2.24417 Training err. RA 2.52935 Valid. err. 2.27215
2018-02-05 11:43:38,629 training [INFO ] Epoch 25 Batch10780 Training err. 2.23745 Training err. RA 2.52881 Valid. err. 2.27980
2018-02-05 11:43:39,413 training [INFO ] Epoch 25 Batch10800 Training err. 2.25667 Training err. RA 2.52831 Valid. err. 2.26660
2018-02-05 11:43:40,236 training [INFO ] Epoch 25 Batch10820 Training err. 2.25004 Training err. RA 2.52779 Valid. err. 2.26803
2018-02-05 11:43:41,022 training [INFO ] Epoch 25 Batch10840 Training err. 2.24985 Training err. RA 2.52728 Valid. err. 2.26592
2018-02-05 11:43:41,792 training [INFO ] Epoch 25 Batch10860 Training err. 2.25145 Training err. RA 2.52677 Valid. err. 2.26826
2018-02-05 11:43:42,560 training [INFO ] Epoch 25 Batch10880 Training err. 2.24224 Training err. RA 2.52625 Valid. err. 2.27749
2018-02-05 11:43:43,379 training [INFO ] Epoch 25 Batch10900 Training err. 2.20984 Training err. RA 2.52567 Valid. err. 2.26785
2018-02-05 11:43:44,250 training [INFO ] Epoch 25 Batch10920 Training err. 2.20263 Training err. RA 2.52508 Valid. err. 2.26960
2018-02-05 11:43:45,088 training [INFO ] Epoch 25 Batch10940 Training err. 2.25252 Training err. RA 2.52458 Valid. err. 2.27055
2018-02-05 11:43:45,911 training [INFO ] Epoch 25 Batch10960 Training err. 2.24121 Training err. RA 2.52406 Valid. err. 2.27328
2018-02-05 11:43:46,793 training [INFO ] Epoch 25 Batch10980 Training err. 2.23769 Training err. RA 2.52354 Valid. err. 2.27380
2018-02-05 11:43:47,844 training [INFO ] Epoch 25 Batch11000 Training err. 2.24953 Training err. RA 2.52304 Valid. err. 2.26769
2018-02-05 11:43:48,855 training [INFO ] Epoch 25 Batch11020 Training err. 2.23518 Training err. RA 2.52252 Valid. err. 2.26107
2018-02-05 11:43:49,827 training [INFO ] Epoch 25 Batch11040 Training err. 2.24138 Training err. RA 2.52201 Valid. err. 2.29320
2018-02-05 11:43:50,622 training [INFO ] Epoch 25 Batch11060 Training err. 2.21862 Training err. RA 2.52146 Valid. err. 2.25921
2018-02-05 11:43:51,460 training [INFO ] Epoch 25 Batch11080 Training err. 2.22253 Training err. RA 2.52092 Valid. err. 2.26964
2018-02-05 11:43:52,298 training [INFO ] Epoch 25 Batch11100 Training err. 2.23158 Training err. RA 2.52040 Valid. err. 2.27379
2018-02-05 11:43:53,193 training [INFO ] Epoch 25 Batch11120 Training err. 2.21008 Training err. RA 2.51984 Valid. err. 2.26011
2018-02-05 11:43:53,995 training [INFO ] Epoch 25 Batch11140 Training err. 2.22377 Training err. RA 2.51931 Valid. err. 2.26242
2018-02-05 11:43:54,805 training [INFO ] Epoch 25 Batch11160 Training err. 2.23668 Training err. RA 2.51880 Valid. err. 2.26534
2018-02-05 11:43:55,610 training [INFO ] Epoch 25 Batch11180 Training err. 2.24473 Training err. RA 2.51831 Valid. err. 2.27924
2018-02-05 11:43:56,430 training [INFO ] Epoch 25 Batch11200 Training err. 2.22828 Training err. RA 2.51779 Valid. err. 2.25868
2018-02-05 11:43:58,109 training [INFO ] Epoch 26 Batch11220 Training err. 2.21992 Training err. RA 2.51726 Valid. err. 2.26644
2018-02-05 11:43:58,934 training [INFO ] Epoch 26 Batch11240 Training err. 2.23539 Training err. RA 2.51676 Valid. err. 2.26441
2018-02-05 11:43:59,742 training [INFO ] Epoch 26 Batch11260 Training err. 2.25525 Training err. RA 2.51630 Valid. err. 2.26540
2018-02-05 11:44:00,526 training [INFO ] Epoch 26 Batch11280 Training err. 2.24785 Training err. RA 2.51582 Valid. err. 2.27330
2018-02-05 11:44:01,321 training [INFO ] Epoch 26 Batch11300 Training err. 2.23506 Training err. RA 2.51532 Valid. err. 2.25593
2018-02-05 11:44:02,107 training [INFO ] Epoch 26 Batch11320 Training err. 2.22907 Training err. RA 2.51482 Valid. err. 2.25596
2018-02-05 11:44:02,909 training [INFO ] Epoch 26 Batch11340 Training err. 2.22140 Training err. RA 2.51430 Valid. err. 2.27949
2018-02-05 11:44:03,698 training [INFO ] Epoch 26 Batch11360 Training err. 2.17134 Training err. RA 2.51370 Valid. err. 2.25347
2018-02-05 11:44:04,502 training [INFO ] Epoch 26 Batch11380 Training err. 2.24976 Training err. RA 2.51323 Valid. err. 2.25489
2018-02-05 11:44:05,310 training [INFO ] Epoch 26 Batch11400 Training err. 2.21452 Training err. RA 2.51271 Valid. err. 2.26488
2018-02-05 11:44:06,090 training [INFO ] Epoch 26 Batch11420 Training err. 2.23996 Training err. RA 2.51223 Valid. err. 2.27657
2018-02-05 11:44:06,870 training [INFO ] Epoch 26 Batch11440 Training err. 2.22434 Training err. RA 2.51173 Valid. err. 2.25150
2018-02-05 11:44:07,650 training [INFO ] Epoch 26 Batch11460 Training err. 2.25537 Training err. RA 2.51128 Valid. err. 2.25809
2018-02-05 11:44:08,434 training [INFO ] Epoch 26 Batch11480 Training err. 2.20061 Training err. RA 2.51074 Valid. err. 2.25127
2018-02-05 11:44:09,211 training [INFO ] Epoch 26 Batch11500 Training err. 2.20651 Training err. RA 2.51021 Valid. err. 2.26391
2018-02-05 11:44:10,010 training [INFO ] Epoch 26 Batch11520 Training err. 2.22182 Training err. RA 2.50971 Valid. err. 2.25117
2018-02-05 11:44:10,791 training [INFO ] Epoch 26 Batch11540 Training err. 2.23256 Training err. RA 2.50923 Valid. err. 2.25179
2018-02-05 11:44:11,582 training [INFO ] Epoch 26 Batch11560 Training err. 2.19168 Training err. RA 2.50868 Valid. err. 2.24852
2018-02-05 11:44:12,356 training [INFO ] Epoch 26 Batch11580 Training err. 2.21188 Training err. RA 2.50817 Valid. err. 2.25615
2018-02-05 11:44:13,131 training [INFO ] Epoch 26 Batch11600 Training err. 2.21204 Training err. RA 2.50766 Valid. err. 2.25544
2018-02-05 11:44:13,911 training [INFO ] Epoch 26 Batch11620 Training err. 2.22363 Training err. RA 2.50717 Valid. err. 2.25232
2018-02-05 11:44:14,697 training [INFO ] Epoch 26 Batch11640 Training err. 2.24674 Training err. RA 2.50672 Valid. err. 2.25785
2018-02-05 11:44:16,270 training [INFO ] Epoch 27 Batch11660 Training err. 2.20469 Training err. RA 2.50620 Valid. err. 2.25497
2018-02-05 11:44:17,047 training [INFO ] Epoch 27 Batch11680 Training err. 2.21186 Training err. RA 2.50570 Valid. err. 2.24596
2018-02-05 11:44:17,824 training [INFO ] Epoch 27 Batch11700 Training err. 2.24976 Training err. RA 2.50526 Valid. err. 2.24786
2018-02-05 11:44:18,601 training [INFO ] Epoch 27 Batch11720 Training err. 2.24214 Training err. RA 2.50481 Valid. err. 2.24389
2018-02-05 11:44:19,387 training [INFO ] Epoch 27 Batch11740 Training err. 2.22939 Training err. RA 2.50434 Valid. err. 2.24800
2018-02-05 11:44:20,166 training [INFO ] Epoch 27 Batch11760 Training err. 2.21444 Training err. RA 2.50385 Valid. err. 2.24598
2018-02-05 11:44:20,945 training [INFO ] Epoch 27 Batch11780 Training err. 2.20496 Training err. RA 2.50334 Valid. err. 2.24837
2018-02-05 11:44:21,753 training [INFO ] Epoch 27 Batch11800 Training err. 2.18486 Training err. RA 2.50280 Valid. err. 2.25064
2018-02-05 11:44:22,557 training [INFO ] Epoch 27 Batch11820 Training err. 2.20695 Training err. RA 2.50230 Valid. err. 2.24427
2018-02-05 11:44:23,369 training [INFO ] Epoch 27 Batch11840 Training err. 2.21519 Training err. RA 2.50182 Valid. err. 2.24144
2018-02-05 11:44:24,158 training [INFO ] Epoch 27 Batch11860 Training err. 2.23070 Training err. RA 2.50136 Valid. err. 2.25238
2018-02-05 11:44:24,950 training [INFO ] Epoch 27 Batch11880 Training err. 2.20064 Training err. RA 2.50085 Valid. err. 2.25358
2018-02-05 11:44:25,724 training [INFO ] Epoch 27 Batch11900 Training err. 2.24152 Training err. RA 2.50042 Valid. err. 2.24659
2018-02-05 11:44:26,496 training [INFO ] Epoch 27 Batch11920 Training err. 2.20245 Training err. RA 2.49992 Valid. err. 2.24900
2018-02-05 11:44:27,289 training [INFO ] Epoch 27 Batch11940 Training err. 2.20885 Training err. RA 2.49943 Valid. err. 2.24330
2018-02-05 11:44:28,090 training [INFO ] Epoch 27 Batch11960 Training err. 2.20414 Training err. RA 2.49894 Valid. err. 2.25286
2018-02-05 11:44:28,875 training [INFO ] Epoch 27 Batch11980 Training err. 2.20009 Training err. RA 2.49844 Valid. err. 2.24499
2018-02-05 11:44:29,671 training [INFO ] Epoch 27 Batch12000 Training err. 2.21067 Training err. RA 2.49796 Valid. err. 2.24717
2018-02-05 11:44:30,450 training [INFO ] Epoch 27 Batch12020 Training err. 2.20199 Training err. RA 2.49747 Valid. err. 2.24862
2018-02-05 11:44:31,227 training [INFO ] Epoch 27 Batch12040 Training err. 2.19521 Training err. RA 2.49696 Valid. err. 2.25701
2018-02-05 11:44:32,000 training [INFO ] Epoch 27 Batch12060 Training err. 2.20833 Training err. RA 2.49648 Valid. err. 2.25728
2018-02-05 11:44:32,795 training [INFO ] Epoch 27 Batch12080 Training err. 2.24028 Training err. RA 2.49606 Valid. err. 2.24791
2018-02-05 11:44:34,474 training [INFO ] Epoch 28 Batch12100 Training err. 2.19853 Training err. RA 2.49557 Valid. err. 2.24164
2018-02-05 11:44:35,284 training [INFO ] Epoch 28 Batch12120 Training err. 2.20380 Training err. RA 2.49509 Valid. err. 2.23640
2018-02-05 11:44:36,065 training [INFO ] Epoch 28 Batch12140 Training err. 2.21303 Training err. RA 2.49462 Valid. err. 2.23748
2018-02-05 11:44:36,845 training [INFO ] Epoch 28 Batch12160 Training err. 2.22210 Training err. RA 2.49417 Valid. err. 2.24472
2018-02-05 11:44:37,624 training [INFO ] Epoch 28 Batch12180 Training err. 2.22191 Training err. RA 2.49373 Valid. err. 2.23560
2018-02-05 11:44:38,410 training [INFO ] Epoch 28 Batch12200 Training err. 2.22039 Training err. RA 2.49328 Valid. err. 2.23503
2018-02-05 11:44:39,186 training [INFO ] Epoch 28 Batch12220 Training err. 2.21045 Training err. RA 2.49282 Valid. err. 2.24542
2018-02-05 11:44:39,975 training [INFO ] Epoch 28 Batch12240 Training err. 2.18369 Training err. RA 2.49231 Valid. err. 2.23654
2018-02-05 11:44:40,766 training [INFO ] Epoch 28 Batch12260 Training err. 2.16662 Training err. RA 2.49178 Valid. err. 2.23566
2018-02-05 11:44:41,602 training [INFO ] Epoch 28 Batch12280 Training err. 2.21778 Training err. RA 2.49133 Valid. err. 2.24102
2018-02-05 11:44:42,428 training [INFO ] Epoch 28 Batch12300 Training err. 2.20187 Training err. RA 2.49086 Valid. err. 2.23698
2018-02-05 11:44:43,232 training [INFO ] Epoch 28 Batch12320 Training err. 2.21123 Training err. RA 2.49041 Valid. err. 2.23733
2018-02-05 11:44:44,035 training [INFO ] Epoch 28 Batch12340 Training err. 2.21258 Training err. RA 2.48996 Valid. err. 2.23009
2018-02-05 11:44:44,810 training [INFO ] Epoch 28 Batch12360 Training err. 2.22561 Training err. RA 2.48953 Valid. err. 2.23168
2018-02-05 11:44:45,579 training [INFO ] Epoch 28 Batch12380 Training err. 2.19832 Training err. RA 2.48906 Valid. err. 2.24010
2018-02-05 11:44:46,354 training [INFO ] Epoch 28 Batch12400 Training err. 2.17121 Training err. RA 2.48855 Valid. err. 2.24236
2018-02-05 11:44:47,124 training [INFO ] Epoch 28 Batch12420 Training err. 2.19315 Training err. RA 2.48807 Valid. err. 2.23379
2018-02-05 11:44:47,900 training [INFO ] Epoch 28 Batch12440 Training err. 2.22115 Training err. RA 2.48764 Valid. err. 2.22875
2018-02-05 11:44:48,669 training [INFO ] Epoch 28 Batch12460 Training err. 2.16649 Training err. RA 2.48713 Valid. err. 2.23465
2018-02-05 11:44:49,445 training [INFO ] Epoch 28 Batch12480 Training err. 2.19051 Training err. RA 2.48665 Valid. err. 2.24235
2018-02-05 11:44:50,218 training [INFO ] Epoch 28 Batch12500 Training err. 2.19552 Training err. RA 2.48619 Valid. err. 2.23161
2018-02-05 11:44:50,991 training [INFO ] Epoch 28 Batch12520 Training err. 2.20756 Training err. RA 2.48574 Valid. err. 2.23369
2018-02-05 11:44:51,771 training [INFO ] Epoch 28 Batch12540 Training err. 2.21272 Training err. RA 2.48531 Valid. err. 2.23232
2018-02-05 11:44:53,388 training [INFO ] Epoch 29 Batch12560 Training err. 2.19718 Training err. RA 2.48485 Valid. err. 2.22915
2018-02-05 11:44:54,163 training [INFO ] Epoch 29 Batch12580 Training err. 2.19933 Training err. RA 2.48439 Valid. err. 2.22625
2018-02-05 11:44:54,947 training [INFO ] Epoch 29 Batch12600 Training err. 2.20699 Training err. RA 2.48395 Valid. err. 2.23234
2018-02-05 11:44:55,727 training [INFO ] Epoch 29 Batch12620 Training err. 2.23348 Training err. RA 2.48356 Valid. err. 2.22503
2018-02-05 11:44:56,508 training [INFO ] Epoch 29 Batch12640 Training err. 2.19995 Training err. RA 2.48311 Valid. err. 2.22778
2018-02-05 11:44:57,283 training [INFO ] Epoch 29 Batch12660 Training err. 2.20135 Training err. RA 2.48266 Valid. err. 2.23268
2018-02-05 11:44:58,058 training [INFO ] Epoch 29 Batch12680 Training err. 2.17742 Training err. RA 2.48218 Valid. err. 2.22672
2018-02-05 11:44:58,842 training [INFO ] Epoch 29 Batch12700 Training err. 2.15922 Training err. RA 2.48167 Valid. err. 2.23616
2018-02-05 11:44:59,622 training [INFO ] Epoch 29 Batch12720 Training err. 2.20122 Training err. RA 2.48123 Valid. err. 2.23316
2018-02-05 11:45:00,413 training [INFO ] Epoch 29 Batch12740 Training err. 2.18525 Training err. RA 2.48077 Valid. err. 2.26177
2018-02-05 11:45:01,190 training [INFO ] Epoch 29 Batch12760 Training err. 2.21288 Training err. RA 2.48035 Valid. err. 2.22665
2018-02-05 11:45:01,987 training [INFO ] Epoch 29 Batch12780 Training err. 2.18545 Training err. RA 2.47989 Valid. err. 2.22532
2018-02-05 11:45:02,763 training [INFO ] Epoch 29 Batch12800 Training err. 2.22522 Training err. RA 2.47949 Valid. err. 2.23218
2018-02-05 11:45:03,551 training [INFO ] Epoch 29 Batch12820 Training err. 2.17235 Training err. RA 2.47901 Valid. err. 2.22340
2018-02-05 11:45:04,330 training [INFO ] Epoch 29 Batch12840 Training err. 2.18618 Training err. RA 2.47855 Valid. err. 2.22168
2018-02-05 11:45:05,109 training [INFO ] Epoch 29 Batch12860 Training err. 2.17952 Training err. RA 2.47809 Valid. err. 2.22552
2018-02-05 11:45:05,889 training [INFO ] Epoch 29 Batch12880 Training err. 2.20423 Training err. RA 2.47766 Valid. err. 2.24224
2018-02-05 11:45:06,680 training [INFO ] Epoch 29 Batch12900 Training err. 2.16546 Training err. RA 2.47718 Valid. err. 2.22194
2018-02-05 11:45:07,459 training [INFO ] Epoch 29 Batch12920 Training err. 2.18901 Training err. RA 2.47673 Valid. err. 2.23087
2018-02-05 11:45:08,238 training [INFO ] Epoch 29 Batch12940 Training err. 2.17615 Training err. RA 2.47627 Valid. err. 2.22515
2018-02-05 11:45:09,016 training [INFO ] Epoch 29 Batch12960 Training err. 2.18357 Training err. RA 2.47582 Valid. err. 2.21793
2018-02-05 11:45:09,797 training [INFO ] Epoch 29 Batch12980 Training err. 2.20759 Training err. RA 2.47540 Valid. err. 2.22800
2018-02-05 11:45:11,480 training [INFO ] Epoch 30 Batch13000 Training err. 2.19014 Training err. RA 2.47496 Valid. err. 2.22148
2018-02-05 11:45:12,391 training [INFO ] Epoch 30 Batch13020 Training err. 2.18398 Training err. RA 2.47452 Valid. err. 2.23107
2018-02-05 11:45:13,306 training [INFO ] Epoch 30 Batch13040 Training err. 2.20395 Training err. RA 2.47410 Valid. err. 2.21773
2018-02-05 11:45:14,181 training [INFO ] Epoch 30 Batch13060 Training err. 2.19754 Training err. RA 2.47368 Valid. err. 2.21933
2018-02-05 11:45:15,034 training [INFO ] Epoch 30 Batch13080 Training err. 2.19704 Training err. RA 2.47325 Valid. err. 2.21502
2018-02-05 11:45:15,874 training [INFO ] Epoch 30 Batch13100 Training err. 2.19984 Training err. RA 2.47284 Valid. err. 2.22049
2018-02-05 11:45:16,843 training [INFO ] Epoch 30 Batch13120 Training err. 2.18884 Training err. RA 2.47240 Valid. err. 2.22450
2018-02-05 11:45:17,684 training [INFO ] Epoch 30 Batch13140 Training err. 2.15874 Training err. RA 2.47193 Valid. err. 2.21771
2018-02-05 11:45:18,516 training [INFO ] Epoch 30 Batch13160 Training err. 2.15220 Training err. RA 2.47144 Valid. err. 2.21692
2018-02-05 11:45:19,364 training [INFO ] Epoch 30 Batch13180 Training err. 2.19974 Training err. RA 2.47103 Valid. err. 2.22806
2018-02-05 11:45:20,712 training [INFO ] Epoch 30 Batch13200 Training err. 2.19035 Training err. RA 2.47060 Valid. err. 2.22893
2018-02-05 11:45:21,515 training [INFO ] Epoch 30 Batch13220 Training err. 2.18795 Training err. RA 2.47018 Valid. err. 2.22231
2018-02-05 11:45:22,326 training [INFO ] Epoch 30 Batch13240 Training err. 2.19682 Training err. RA 2.46976 Valid. err. 2.21765
2018-02-05 11:45:23,157 training [INFO ] Epoch 30 Batch13260 Training err. 2.18448 Training err. RA 2.46933 Valid. err. 2.21430
2018-02-05 11:45:23,968 training [INFO ] Epoch 30 Batch13280 Training err. 2.18992 Training err. RA 2.46891 Valid. err. 2.24697
2018-02-05 11:45:24,764 training [INFO ] Epoch 30 Batch13300 Training err. 2.16840 Training err. RA 2.46846 Valid. err. 2.21114
2018-02-05 11:45:25,559 training [INFO ] Epoch 30 Batch13320 Training err. 2.17218 Training err. RA 2.46802 Valid. err. 2.22365
2018-02-05 11:45:26,350 training [INFO ] Epoch 30 Batch13340 Training err. 2.18147 Training err. RA 2.46759 Valid. err. 2.22293
2018-02-05 11:45:27,140 training [INFO ] Epoch 30 Batch13360 Training err. 2.15666 Training err. RA 2.46712 Valid. err. 2.21340
2018-02-05 11:45:27,923 training [INFO ] Epoch 30 Batch13380 Training err. 2.16992 Training err. RA 2.46668 Valid. err. 2.21516
2018-02-05 11:45:28,725 training [INFO ] Epoch 30 Batch13400 Training err. 2.18435 Training err. RA 2.46625 Valid. err. 2.22041
2018-02-05 11:45:29,527 training [INFO ] Epoch 30 Batch13420 Training err. 2.19182 Training err. RA 2.46585 Valid. err. 2.23012
2018-02-05 11:45:30,313 training [INFO ] Epoch 30 Batch13440 Training err. 2.17699 Training err. RA 2.46542 Valid. err. 2.21155
2018-02-05 11:45:30,882 __main__ [INFO ] End of training
2018-02-05 11:45:32,418 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 2 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 30,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.1,
      "weight_decay": 0
    }
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 5,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-05 11:45:33,499 training [INFO ] Epoch  1 Batch   20 Training err. 3.66512 Training err. RA 3.66512 Valid. err. 3.14371
2018-02-05 11:45:34,288 training [INFO ] Epoch  1 Batch   40 Training err. 3.15970 Training err. RA 3.41241 Valid. err. 3.16116
2018-02-05 11:45:35,078 training [INFO ] Epoch  1 Batch   60 Training err. 3.12972 Training err. RA 3.31818 Valid. err. 3.11316
2018-02-05 11:45:35,878 training [INFO ] Epoch  1 Batch   80 Training err. 3.08203 Training err. RA 3.25914 Valid. err. 3.10288
2018-02-05 11:45:36,691 training [INFO ] Epoch  1 Batch  100 Training err. 3.08838 Training err. RA 3.22499 Valid. err. 3.07203
2018-02-05 11:45:37,497 training [INFO ] Epoch  1 Batch  120 Training err. 3.05042 Training err. RA 3.19589 Valid. err. 3.05361
2018-02-05 11:45:38,320 training [INFO ] Epoch  1 Batch  140 Training err. 3.06362 Training err. RA 3.17700 Valid. err. 3.07192
2018-02-05 11:45:39,128 training [INFO ] Epoch  1 Batch  160 Training err. 3.00549 Training err. RA 3.15556 Valid. err. 3.03097
2018-02-05 11:45:39,920 training [INFO ] Epoch  1 Batch  180 Training err. 3.03978 Training err. RA 3.14269 Valid. err. 3.01169
2018-02-05 11:45:40,720 training [INFO ] Epoch  1 Batch  200 Training err. 2.98696 Training err. RA 3.12712 Valid. err. 2.98439
2018-02-05 11:45:41,527 training [INFO ] Epoch  1 Batch  220 Training err. 2.96370 Training err. RA 3.11226 Valid. err. 2.94925
2018-02-05 11:45:42,380 training [INFO ] Epoch  1 Batch  240 Training err. 2.89040 Training err. RA 3.09378 Valid. err. 2.85725
2018-02-05 11:45:43,285 training [INFO ] Epoch  1 Batch  260 Training err. 2.87556 Training err. RA 3.07699 Valid. err. 2.82317
2018-02-05 11:45:44,129 training [INFO ] Epoch  1 Batch  280 Training err. 2.78267 Training err. RA 3.05597 Valid. err. 2.82319
2018-02-05 11:45:44,992 training [INFO ] Epoch  1 Batch  300 Training err. 2.77008 Training err. RA 3.03691 Valid. err. 2.76627
2018-02-05 11:45:45,810 training [INFO ] Epoch  1 Batch  320 Training err. 2.73282 Training err. RA 3.01790 Valid. err. 2.74796
2018-02-05 11:45:46,621 training [INFO ] Epoch  1 Batch  340 Training err. 2.71823 Training err. RA 3.00027 Valid. err. 2.68665
2018-02-05 11:45:47,421 training [INFO ] Epoch  1 Batch  360 Training err. 2.66684 Training err. RA 2.98175 Valid. err. 2.70365
2018-02-05 11:45:48,220 training [INFO ] Epoch  1 Batch  380 Training err. 2.65778 Training err. RA 2.96470 Valid. err. 2.66463
2018-02-05 11:45:49,041 training [INFO ] Epoch  1 Batch  400 Training err. 2.63717 Training err. RA 2.94832 Valid. err. 2.63836
2018-02-05 11:45:49,848 training [INFO ] Epoch  1 Batch  420 Training err. 2.63308 Training err. RA 2.93331 Valid. err. 2.64963
2018-02-05 11:45:50,650 training [INFO ] Epoch  1 Batch  440 Training err. 2.62955 Training err. RA 2.91950 Valid. err. 2.63647
2018-02-05 11:45:52,312 training [INFO ] Epoch  2 Batch  460 Training err. 2.58677 Training err. RA 2.90504 Valid. err. 2.59217
2018-02-05 11:45:53,113 training [INFO ] Epoch  2 Batch  480 Training err. 2.58098 Training err. RA 2.89153 Valid. err. 2.61302
2018-02-05 11:45:53,911 training [INFO ] Epoch  2 Batch  500 Training err. 2.60982 Training err. RA 2.88027 Valid. err. 2.58436
2018-02-05 11:45:54,703 training [INFO ] Epoch  2 Batch  520 Training err. 2.57799 Training err. RA 2.86864 Valid. err. 2.57392
2018-02-05 11:45:55,507 training [INFO ] Epoch  2 Batch  540 Training err. 2.56316 Training err. RA 2.85733 Valid. err. 2.56594
2018-02-05 11:45:56,309 training [INFO ] Epoch  2 Batch  560 Training err. 2.54763 Training err. RA 2.84627 Valid. err. 2.54329
2018-02-05 11:45:57,117 training [INFO ] Epoch  2 Batch  580 Training err. 2.52087 Training err. RA 2.83504 Valid. err. 2.56514
2018-02-05 11:45:57,923 training [INFO ] Epoch  2 Batch  600 Training err. 2.48984 Training err. RA 2.82354 Valid. err. 2.52582
2018-02-05 11:45:58,729 training [INFO ] Epoch  2 Batch  620 Training err. 2.49683 Training err. RA 2.81300 Valid. err. 2.50907
2018-02-05 11:45:59,519 training [INFO ] Epoch  2 Batch  640 Training err. 2.48887 Training err. RA 2.80287 Valid. err. 2.49884
2018-02-05 11:46:00,309 training [INFO ] Epoch  2 Batch  660 Training err. 2.49725 Training err. RA 2.79361 Valid. err. 2.51380
2018-02-05 11:46:01,095 training [INFO ] Epoch  2 Batch  680 Training err. 2.45958 Training err. RA 2.78378 Valid. err. 2.50560
2018-02-05 11:46:01,884 training [INFO ] Epoch  2 Batch  700 Training err. 2.48300 Training err. RA 2.77519 Valid. err. 2.48691
2018-02-05 11:46:02,676 training [INFO ] Epoch  2 Batch  720 Training err. 2.43855 Training err. RA 2.76584 Valid. err. 2.46551
2018-02-05 11:46:03,468 training [INFO ] Epoch  2 Batch  740 Training err. 2.44359 Training err. RA 2.75713 Valid. err. 2.47948
2018-02-05 11:46:04,251 training [INFO ] Epoch  2 Batch  760 Training err. 2.41831 Training err. RA 2.74821 Valid. err. 2.46336
2018-02-05 11:46:05,071 training [INFO ] Epoch  2 Batch  780 Training err. 2.41420 Training err. RA 2.73965 Valid. err. 2.44504
2018-02-05 11:46:05,872 training [INFO ] Epoch  2 Batch  800 Training err. 2.40410 Training err. RA 2.73126 Valid. err. 2.47083
2018-02-05 11:46:06,685 training [INFO ] Epoch  2 Batch  820 Training err. 2.39703 Training err. RA 2.72311 Valid. err. 2.45800
2018-02-05 11:46:07,601 training [INFO ] Epoch  2 Batch  840 Training err. 2.39982 Training err. RA 2.71541 Valid. err. 2.43469
2018-02-05 11:46:08,417 training [INFO ] Epoch  2 Batch  860 Training err. 2.38349 Training err. RA 2.70769 Valid. err. 2.44630
2018-02-05 11:46:09,219 training [INFO ] Epoch  2 Batch  880 Training err. 2.41828 Training err. RA 2.70111 Valid. err. 2.41062
2018-02-05 11:46:10,838 training [INFO ] Epoch  3 Batch  900 Training err. 2.36335 Training err. RA 2.69361 Valid. err. 2.39863
2018-02-05 11:46:11,625 training [INFO ] Epoch  3 Batch  920 Training err. 2.36399 Training err. RA 2.68644 Valid. err. 2.39479
2018-02-05 11:46:12,411 training [INFO ] Epoch  3 Batch  940 Training err. 2.37370 Training err. RA 2.67979 Valid. err. 2.37813
2018-02-05 11:46:13,195 training [INFO ] Epoch  3 Batch  960 Training err. 2.37595 Training err. RA 2.67346 Valid. err. 2.38295
2018-02-05 11:46:13,992 training [INFO ] Epoch  3 Batch  980 Training err. 2.35894 Training err. RA 2.66704 Valid. err. 2.36266
2018-02-05 11:46:14,791 training [INFO ] Epoch  3 Batch 1000 Training err. 2.34817 Training err. RA 2.66066 Valid. err. 2.36020
2018-02-05 11:46:15,586 training [INFO ] Epoch  3 Batch 1020 Training err. 2.33920 Training err. RA 2.65436 Valid. err. 2.35488
2018-02-05 11:46:16,384 training [INFO ] Epoch  3 Batch 1040 Training err. 2.31188 Training err. RA 2.64777 Valid. err. 2.35083
2018-02-05 11:46:17,177 training [INFO ] Epoch  3 Batch 1060 Training err. 2.27935 Training err. RA 2.64082 Valid. err. 2.33879
2018-02-05 11:46:17,975 training [INFO ] Epoch  3 Batch 1080 Training err. 2.32799 Training err. RA 2.63503 Valid. err. 2.32790
2018-02-05 11:46:18,759 training [INFO ] Epoch  3 Batch 1100 Training err. 2.29813 Training err. RA 2.62890 Valid. err. 2.33243
2018-02-05 11:46:19,549 training [INFO ] Epoch  3 Batch 1120 Training err. 2.31195 Training err. RA 2.62324 Valid. err. 2.32360
2018-02-05 11:46:20,340 training [INFO ] Epoch  3 Batch 1140 Training err. 2.29336 Training err. RA 2.61746 Valid. err. 2.32867
2018-02-05 11:46:21,125 training [INFO ] Epoch  3 Batch 1160 Training err. 2.31758 Training err. RA 2.61229 Valid. err. 2.31505
2018-02-05 11:46:21,907 training [INFO ] Epoch  3 Batch 1180 Training err. 2.27366 Training err. RA 2.60655 Valid. err. 2.31450
2018-02-05 11:46:22,695 training [INFO ] Epoch  3 Batch 1200 Training err. 2.25298 Training err. RA 2.60065 Valid. err. 2.30627
2018-02-05 11:46:23,488 training [INFO ] Epoch  3 Batch 1220 Training err. 2.26063 Training err. RA 2.59508 Valid. err. 2.30341
2018-02-05 11:46:24,282 training [INFO ] Epoch  3 Batch 1240 Training err. 2.28341 Training err. RA 2.59005 Valid. err. 2.29622
2018-02-05 11:46:25,089 training [INFO ] Epoch  3 Batch 1260 Training err. 2.22726 Training err. RA 2.58429 Valid. err. 2.29047
2018-02-05 11:46:25,898 training [INFO ] Epoch  3 Batch 1280 Training err. 2.24980 Training err. RA 2.57907 Valid. err. 2.29163
2018-02-05 11:46:26,691 training [INFO ] Epoch  3 Batch 1300 Training err. 2.24012 Training err. RA 2.57385 Valid. err. 2.29364
2018-02-05 11:46:27,473 training [INFO ] Epoch  3 Batch 1320 Training err. 2.26102 Training err. RA 2.56911 Valid. err. 2.29266
2018-02-05 11:46:28,258 training [INFO ] Epoch  3 Batch 1340 Training err. 2.25300 Training err. RA 2.56439 Valid. err. 2.28037
2018-02-05 11:46:29,882 training [INFO ] Epoch  4 Batch 1360 Training err. 2.22877 Training err. RA 2.55946 Valid. err. 2.27419
2018-02-05 11:46:30,665 training [INFO ] Epoch  4 Batch 1380 Training err. 2.23283 Training err. RA 2.55473 Valid. err. 2.25368
2018-02-05 11:46:31,454 training [INFO ] Epoch  4 Batch 1400 Training err. 2.24203 Training err. RA 2.55026 Valid. err. 2.28169
2018-02-05 11:46:32,237 training [INFO ] Epoch  4 Batch 1420 Training err. 2.26357 Training err. RA 2.54622 Valid. err. 2.24341
2018-02-05 11:46:33,034 training [INFO ] Epoch  4 Batch 1440 Training err. 2.21265 Training err. RA 2.54159 Valid. err. 2.24017
2018-02-05 11:46:33,825 training [INFO ] Epoch  4 Batch 1460 Training err. 2.22227 Training err. RA 2.53721 Valid. err. 2.26502
2018-02-05 11:46:34,620 training [INFO ] Epoch  4 Batch 1480 Training err. 2.19412 Training err. RA 2.53258 Valid. err. 2.23214
2018-02-05 11:46:35,416 training [INFO ] Epoch  4 Batch 1500 Training err. 2.16867 Training err. RA 2.52772 Valid. err. 2.24443
2018-02-05 11:46:36,209 training [INFO ] Epoch  4 Batch 1520 Training err. 2.20596 Training err. RA 2.52349 Valid. err. 2.23145
2018-02-05 11:46:36,994 training [INFO ] Epoch  4 Batch 1540 Training err. 2.18299 Training err. RA 2.51907 Valid. err. 2.27191
2018-02-05 11:46:37,784 training [INFO ] Epoch  4 Batch 1560 Training err. 2.21573 Training err. RA 2.51518 Valid. err. 2.22032
2018-02-05 11:46:38,572 training [INFO ] Epoch  4 Batch 1580 Training err. 2.17249 Training err. RA 2.51084 Valid. err. 2.23135
2018-02-05 11:46:39,508 training [INFO ] Epoch  4 Batch 1600 Training err. 2.21098 Training err. RA 2.50709 Valid. err. 2.22907
2018-02-05 11:46:40,414 training [INFO ] Epoch  4 Batch 1620 Training err. 2.15274 Training err. RA 2.50272 Valid. err. 2.22004
2018-02-05 11:46:41,197 training [INFO ] Epoch  4 Batch 1640 Training err. 2.17212 Training err. RA 2.49869 Valid. err. 2.20809
2018-02-05 11:46:41,979 training [INFO ] Epoch  4 Batch 1660 Training err. 2.16260 Training err. RA 2.49464 Valid. err. 2.21459
2018-02-05 11:46:42,760 training [INFO ] Epoch  4 Batch 1680 Training err. 2.18318 Training err. RA 2.49093 Valid. err. 2.23150
2018-02-05 11:46:43,541 training [INFO ] Epoch  4 Batch 1700 Training err. 2.14136 Training err. RA 2.48682 Valid. err. 2.19577
2018-02-05 11:46:44,329 training [INFO ] Epoch  4 Batch 1720 Training err. 2.16421 Training err. RA 2.48307 Valid. err. 2.19233
2018-02-05 11:46:45,114 training [INFO ] Epoch  4 Batch 1740 Training err. 2.12877 Training err. RA 2.47899 Valid. err. 2.24975
2018-02-05 11:46:45,902 training [INFO ] Epoch  4 Batch 1760 Training err. 2.14942 Training err. RA 2.47525 Valid. err. 2.18795
2018-02-05 11:46:46,696 training [INFO ] Epoch  4 Batch 1780 Training err. 2.16995 Training err. RA 2.47182 Valid. err. 2.18883
2018-02-05 11:46:48,330 training [INFO ] Epoch  5 Batch 1800 Training err. 2.14948 Training err. RA 2.46824 Valid. err. 2.19518
2018-02-05 11:46:49,109 training [INFO ] Epoch  5 Batch 1820 Training err. 2.13793 Training err. RA 2.46461 Valid. err. 2.18602
2018-02-05 11:46:49,889 training [INFO ] Epoch  5 Batch 1840 Training err. 2.16091 Training err. RA 2.46131 Valid. err. 2.17334
2018-02-05 11:46:50,676 training [INFO ] Epoch  5 Batch 1860 Training err. 2.15460 Training err. RA 2.45801 Valid. err. 2.17218
2018-02-05 11:46:51,452 training [INFO ] Epoch  5 Batch 1880 Training err. 2.14026 Training err. RA 2.45463 Valid. err. 2.16835
2018-02-05 11:46:52,264 training [INFO ] Epoch  5 Batch 1900 Training err. 2.14195 Training err. RA 2.45134 Valid. err. 2.16835
2018-02-05 11:46:53,250 training [INFO ] Epoch  5 Batch 1920 Training err. 2.14142 Training err. RA 2.44811 Valid. err. 2.16186
2018-02-05 11:46:54,239 training [INFO ] Epoch  5 Batch 1940 Training err. 2.10637 Training err. RA 2.44459 Valid. err. 2.15756
2018-02-05 11:46:55,087 training [INFO ] Epoch  5 Batch 1960 Training err. 2.09433 Training err. RA 2.44101 Valid. err. 2.17769
2018-02-05 11:46:55,968 training [INFO ] Epoch  5 Batch 1980 Training err. 2.12390 Training err. RA 2.43781 Valid. err. 2.16530
2018-02-05 11:46:56,834 training [INFO ] Epoch  5 Batch 2000 Training err. 2.12381 Training err. RA 2.43467 Valid. err. 2.16844
2018-02-05 11:46:57,815 training [INFO ] Epoch  5 Batch 2020 Training err. 2.11781 Training err. RA 2.43153 Valid. err. 2.17076
2018-02-05 11:46:58,660 training [INFO ] Epoch  5 Batch 2040 Training err. 2.11509 Training err. RA 2.42843 Valid. err. 2.15549
2018-02-05 11:46:59,469 training [INFO ] Epoch  5 Batch 2060 Training err. 2.10752 Training err. RA 2.42531 Valid. err. 2.14339
2018-02-05 11:47:00,413 training [INFO ] Epoch  5 Batch 2080 Training err. 2.10381 Training err. RA 2.42222 Valid. err. 2.16618
2018-02-05 11:47:01,426 training [INFO ] Epoch  5 Batch 2100 Training err. 2.09125 Training err. RA 2.41907 Valid. err. 2.13611
2018-02-05 11:47:02,379 training [INFO ] Epoch  5 Batch 2120 Training err. 2.08887 Training err. RA 2.41595 Valid. err. 2.14520
2018-02-05 11:47:03,213 training [INFO ] Epoch  5 Batch 2140 Training err. 2.10321 Training err. RA 2.41303 Valid. err. 2.14430
2018-02-05 11:47:04,000 training [INFO ] Epoch  5 Batch 2160 Training err. 2.07132 Training err. RA 2.40987 Valid. err. 2.13023
2018-02-05 11:47:04,781 training [INFO ] Epoch  5 Batch 2180 Training err. 2.07300 Training err. RA 2.40678 Valid. err. 2.13319
2018-02-05 11:47:05,580 training [INFO ] Epoch  5 Batch 2200 Training err. 2.08333 Training err. RA 2.40384 Valid. err. 2.14068
2018-02-05 11:47:06,385 training [INFO ] Epoch  5 Batch 2220 Training err. 2.09557 Training err. RA 2.40106 Valid. err. 2.16924
2018-02-05 11:47:07,188 training [INFO ] Epoch  5 Batch 2240 Training err. 2.08566 Training err. RA 2.39824 Valid. err. 2.12693
2018-02-05 11:47:08,936 training [INFO ] Epoch  6 Batch 2260 Training err. 2.07544 Training err. RA 2.39539 Valid. err. 2.13108
2018-02-05 11:47:09,729 training [INFO ] Epoch  6 Batch 2280 Training err. 2.09017 Training err. RA 2.39271 Valid. err. 2.13866
2018-02-05 11:47:10,531 training [INFO ] Epoch  6 Batch 2300 Training err. 2.11098 Training err. RA 2.39026 Valid. err. 2.13936
2018-02-05 11:47:11,320 training [INFO ] Epoch  6 Batch 2320 Training err. 2.09642 Training err. RA 2.38773 Valid. err. 2.13534
2018-02-05 11:47:12,192 training [INFO ] Epoch  6 Batch 2340 Training err. 2.07217 Training err. RA 2.38503 Valid. err. 2.11533
2018-02-05 11:47:13,118 training [INFO ] Epoch  6 Batch 2360 Training err. 2.08293 Training err. RA 2.38247 Valid. err. 2.11318
2018-02-05 11:47:14,082 training [INFO ] Epoch  6 Batch 2380 Training err. 2.06363 Training err. RA 2.37979 Valid. err. 2.13915
2018-02-05 11:47:14,976 training [INFO ] Epoch  6 Batch 2400 Training err. 2.01831 Training err. RA 2.37678 Valid. err. 2.10196
2018-02-05 11:47:16,001 training [INFO ] Epoch  6 Batch 2420 Training err. 2.07848 Training err. RA 2.37431 Valid. err. 2.10149
2018-02-05 11:47:16,897 training [INFO ] Epoch  6 Batch 2440 Training err. 2.04499 Training err. RA 2.37161 Valid. err. 2.12268
2018-02-05 11:47:17,678 training [INFO ] Epoch  6 Batch 2460 Training err. 2.07803 Training err. RA 2.36923 Valid. err. 2.10609
2018-02-05 11:47:18,459 training [INFO ] Epoch  6 Batch 2480 Training err. 2.04922 Training err. RA 2.36665 Valid. err. 2.09880
2018-02-05 11:47:19,308 training [INFO ] Epoch  6 Batch 2500 Training err. 2.08433 Training err. RA 2.36439 Valid. err. 2.09500
2018-02-05 11:47:20,197 training [INFO ] Epoch  6 Batch 2520 Training err. 2.01654 Training err. RA 2.36163 Valid. err. 2.11035
2018-02-05 11:47:21,054 training [INFO ] Epoch  6 Batch 2540 Training err. 2.03473 Training err. RA 2.35905 Valid. err. 2.11454
2018-02-05 11:47:21,892 training [INFO ] Epoch  6 Batch 2560 Training err. 2.04829 Training err. RA 2.35662 Valid. err. 2.09322
2018-02-05 11:47:22,725 training [INFO ] Epoch  6 Batch 2580 Training err. 2.05854 Training err. RA 2.35431 Valid. err. 2.08953
2018-02-05 11:47:23,723 training [INFO ] Epoch  6 Batch 2600 Training err. 2.01922 Training err. RA 2.35174 Valid. err. 2.08847
2018-02-05 11:47:24,510 training [INFO ] Epoch  6 Batch 2620 Training err. 2.02475 Training err. RA 2.34924 Valid. err. 2.09471
2018-02-05 11:47:25,304 training [INFO ] Epoch  6 Batch 2640 Training err. 2.00768 Training err. RA 2.34665 Valid. err. 2.08340
2018-02-05 11:47:26,084 training [INFO ] Epoch  6 Batch 2660 Training err. 2.04648 Training err. RA 2.34440 Valid. err. 2.08253
2018-02-05 11:47:26,890 training [INFO ] Epoch  6 Batch 2680 Training err. 2.05990 Training err. RA 2.34227 Valid. err. 2.09216
2018-02-05 11:47:28,509 training [INFO ] Epoch  7 Batch 2700 Training err. 2.02386 Training err. RA 2.33991 Valid. err. 2.07706
2018-02-05 11:47:29,328 training [INFO ] Epoch  7 Batch 2720 Training err. 2.02152 Training err. RA 2.33757 Valid. err. 2.08421
2018-02-05 11:47:30,122 training [INFO ] Epoch  7 Batch 2740 Training err. 2.07232 Training err. RA 2.33564 Valid. err. 2.06994
2018-02-05 11:47:30,918 training [INFO ] Epoch  7 Batch 2760 Training err. 2.04935 Training err. RA 2.33356 Valid. err. 2.07035
2018-02-05 11:47:31,698 training [INFO ] Epoch  7 Batch 2780 Training err. 2.03512 Training err. RA 2.33141 Valid. err. 2.07935
2018-02-05 11:47:32,477 training [INFO ] Epoch  7 Batch 2800 Training err. 2.02267 Training err. RA 2.32921 Valid. err. 2.08391
2018-02-05 11:47:33,252 training [INFO ] Epoch  7 Batch 2820 Training err. 2.01295 Training err. RA 2.32697 Valid. err. 2.07950
2018-02-05 11:47:34,046 training [INFO ] Epoch  7 Batch 2840 Training err. 1.99415 Training err. RA 2.32462 Valid. err. 2.09637
2018-02-05 11:47:34,838 training [INFO ] Epoch  7 Batch 2860 Training err. 2.01145 Training err. RA 2.32243 Valid. err. 2.06098
2018-02-05 11:47:35,640 training [INFO ] Epoch  7 Batch 2880 Training err. 1.99252 Training err. RA 2.32014 Valid. err. 2.07309
2018-02-05 11:47:36,435 training [INFO ] Epoch  7 Batch 2900 Training err. 2.03906 Training err. RA 2.31820 Valid. err. 2.06706
2018-02-05 11:47:37,220 training [INFO ] Epoch  7 Batch 2920 Training err. 1.99814 Training err. RA 2.31601 Valid. err. 2.06953
2018-02-05 11:47:38,011 training [INFO ] Epoch  7 Batch 2940 Training err. 2.02922 Training err. RA 2.31406 Valid. err. 2.05738
2018-02-05 11:47:38,807 training [INFO ] Epoch  7 Batch 2960 Training err. 1.99052 Training err. RA 2.31187 Valid. err. 2.06488
2018-02-05 11:47:39,606 training [INFO ] Epoch  7 Batch 2980 Training err. 1.99678 Training err. RA 2.30976 Valid. err. 2.06222
2018-02-05 11:47:40,399 training [INFO ] Epoch  7 Batch 3000 Training err. 1.99768 Training err. RA 2.30768 Valid. err. 2.06455
2018-02-05 11:47:41,180 training [INFO ] Epoch  7 Batch 3020 Training err. 1.98631 Training err. RA 2.30555 Valid. err. 2.05518
2018-02-05 11:47:41,967 training [INFO ] Epoch  7 Batch 3040 Training err. 2.00163 Training err. RA 2.30355 Valid. err. 2.05900
2018-02-05 11:47:42,748 training [INFO ] Epoch  7 Batch 3060 Training err. 2.00456 Training err. RA 2.30160 Valid. err. 2.05410
2018-02-05 11:47:43,546 training [INFO ] Epoch  7 Batch 3080 Training err. 1.95780 Training err. RA 2.29936 Valid. err. 2.05021
2018-02-05 11:47:44,324 training [INFO ] Epoch  7 Batch 3100 Training err. 1.98887 Training err. RA 2.29736 Valid. err. 2.05975
2018-02-05 11:47:45,095 training [INFO ] Epoch  7 Batch 3120 Training err. 2.02085 Training err. RA 2.29559 Valid. err. 2.07802
2018-02-05 11:47:46,746 training [INFO ] Epoch  8 Batch 3140 Training err. 1.98276 Training err. RA 2.29360 Valid. err. 2.04847
2018-02-05 11:47:47,541 training [INFO ] Epoch  8 Batch 3160 Training err. 1.98393 Training err. RA 2.29164 Valid. err. 2.04421
2018-02-05 11:47:48,332 training [INFO ] Epoch  8 Batch 3180 Training err. 2.00613 Training err. RA 2.28984 Valid. err. 2.03928
2018-02-05 11:47:49,120 training [INFO ] Epoch  8 Batch 3200 Training err. 1.99851 Training err. RA 2.28802 Valid. err. 2.04605
2018-02-05 11:47:49,933 training [INFO ] Epoch  8 Batch 3220 Training err. 1.99903 Training err. RA 2.28622 Valid. err. 2.04156
2018-02-05 11:47:50,734 training [INFO ] Epoch  8 Batch 3240 Training err. 1.99581 Training err. RA 2.28443 Valid. err. 2.03413
2018-02-05 11:47:51,544 training [INFO ] Epoch  8 Batch 3260 Training err. 1.98752 Training err. RA 2.28261 Valid. err. 2.03362
2018-02-05 11:47:52,334 training [INFO ] Epoch  8 Batch 3280 Training err. 1.95653 Training err. RA 2.28062 Valid. err. 2.04419
2018-02-05 11:47:53,120 training [INFO ] Epoch  8 Batch 3300 Training err. 1.94891 Training err. RA 2.27861 Valid. err. 2.03671
2018-02-05 11:47:53,908 training [INFO ] Epoch  8 Batch 3320 Training err. 1.97598 Training err. RA 2.27679 Valid. err. 2.02587
2018-02-05 11:47:54,686 training [INFO ] Epoch  8 Batch 3340 Training err. 1.96416 Training err. RA 2.27492 Valid. err. 2.02333
2018-02-05 11:47:55,470 training [INFO ] Epoch  8 Batch 3360 Training err. 1.98150 Training err. RA 2.27317 Valid. err. 2.02201
2018-02-05 11:47:56,263 training [INFO ] Epoch  8 Batch 3380 Training err. 1.96908 Training err. RA 2.27137 Valid. err. 2.02944
2018-02-05 11:47:57,053 training [INFO ] Epoch  8 Batch 3400 Training err. 1.99681 Training err. RA 2.26976 Valid. err. 2.02101
2018-02-05 11:47:57,863 training [INFO ] Epoch  8 Batch 3420 Training err. 1.95187 Training err. RA 2.26790 Valid. err. 2.02043
2018-02-05 11:47:58,660 training [INFO ] Epoch  8 Batch 3440 Training err. 1.93459 Training err. RA 2.26596 Valid. err. 2.02852
2018-02-05 11:47:59,448 training [INFO ] Epoch  8 Batch 3460 Training err. 1.94936 Training err. RA 2.26413 Valid. err. 2.02580
2018-02-05 11:48:00,268 training [INFO ] Epoch  8 Batch 3480 Training err. 1.99331 Training err. RA 2.26257 Valid. err. 2.01902
2018-02-05 11:48:01,064 training [INFO ] Epoch  8 Batch 3500 Training err. 1.92771 Training err. RA 2.26066 Valid. err. 2.02317
2018-02-05 11:48:01,846 training [INFO ] Epoch  8 Batch 3520 Training err. 1.94436 Training err. RA 2.25886 Valid. err. 2.02174
2018-02-05 11:48:02,630 training [INFO ] Epoch  8 Batch 3540 Training err. 1.93524 Training err. RA 2.25703 Valid. err. 2.01380
2018-02-05 11:48:03,437 training [INFO ] Epoch  8 Batch 3560 Training err. 1.95610 Training err. RA 2.25534 Valid. err. 2.02590
2018-02-05 11:48:04,220 training [INFO ] Epoch  8 Batch 3580 Training err. 1.96891 Training err. RA 2.25374 Valid. err. 2.02049
2018-02-05 11:48:05,854 training [INFO ] Epoch  9 Batch 3600 Training err. 1.96337 Training err. RA 2.25213 Valid. err. 2.01021
2018-02-05 11:48:06,646 training [INFO ] Epoch  9 Batch 3620 Training err. 1.95510 Training err. RA 2.25049 Valid. err. 2.00684
2018-02-05 11:48:07,439 training [INFO ] Epoch  9 Batch 3640 Training err. 1.95962 Training err. RA 2.24889 Valid. err. 2.00551
2018-02-05 11:48:08,231 training [INFO ] Epoch  9 Batch 3660 Training err. 1.98849 Training err. RA 2.24747 Valid. err. 2.00464
2018-02-05 11:48:09,021 training [INFO ] Epoch  9 Batch 3680 Training err. 1.94867 Training err. RA 2.24584 Valid. err. 2.00683
2018-02-05 11:48:09,810 training [INFO ] Epoch  9 Batch 3700 Training err. 1.95337 Training err. RA 2.24426 Valid. err. 2.01374
2018-02-05 11:48:10,601 training [INFO ] Epoch  9 Batch 3720 Training err. 1.91751 Training err. RA 2.24251 Valid. err. 1.99756
2018-02-05 11:48:11,426 training [INFO ] Epoch  9 Batch 3740 Training err. 1.91511 Training err. RA 2.24075 Valid. err. 2.02507
2018-02-05 11:48:12,214 training [INFO ] Epoch  9 Batch 3760 Training err. 1.94082 Training err. RA 2.23916 Valid. err. 1.99641
2018-02-05 11:48:12,990 training [INFO ] Epoch  9 Batch 3780 Training err. 1.91129 Training err. RA 2.23742 Valid. err. 2.01607
2018-02-05 11:48:13,771 training [INFO ] Epoch  9 Batch 3800 Training err. 1.96303 Training err. RA 2.23598 Valid. err. 1.99332
2018-02-05 11:48:14,547 training [INFO ] Epoch  9 Batch 3820 Training err. 1.92260 Training err. RA 2.23434 Valid. err. 2.01355
2018-02-05 11:48:15,325 training [INFO ] Epoch  9 Batch 3840 Training err. 1.96405 Training err. RA 2.23293 Valid. err. 1.99699
2018-02-05 11:48:16,099 training [INFO ] Epoch  9 Batch 3860 Training err. 1.90576 Training err. RA 2.23124 Valid. err. 1.99753
2018-02-05 11:48:16,881 training [INFO ] Epoch  9 Batch 3880 Training err. 1.92204 Training err. RA 2.22964 Valid. err. 1.99842
2018-02-05 11:48:17,689 training [INFO ] Epoch  9 Batch 3900 Training err. 1.91958 Training err. RA 2.22805 Valid. err. 2.00250
2018-02-05 11:48:18,470 training [INFO ] Epoch  9 Batch 3920 Training err. 1.94475 Training err. RA 2.22661 Valid. err. 2.00950
2018-02-05 11:48:19,250 training [INFO ] Epoch  9 Batch 3940 Training err. 1.90669 Training err. RA 2.22498 Valid. err. 1.99384
2018-02-05 11:48:20,065 training [INFO ] Epoch  9 Batch 3960 Training err. 1.93479 Training err. RA 2.22352 Valid. err. 1.98378
2018-02-05 11:48:20,851 training [INFO ] Epoch  9 Batch 3980 Training err. 1.88330 Training err. RA 2.22181 Valid. err. 1.99410
2018-02-05 11:48:21,652 training [INFO ] Epoch  9 Batch 4000 Training err. 1.91116 Training err. RA 2.22026 Valid. err. 1.99032
2018-02-05 11:48:22,450 training [INFO ] Epoch  9 Batch 4020 Training err. 1.93779 Training err. RA 2.21885 Valid. err. 1.98351
2018-02-05 11:48:24,027 training [INFO ] Epoch 10 Batch 4040 Training err. 1.93129 Training err. RA 2.21743 Valid. err. 1.99916
2018-02-05 11:48:24,799 training [INFO ] Epoch 10 Batch 4060 Training err. 1.90941 Training err. RA 2.21591 Valid. err. 1.98492
2018-02-05 11:48:25,573 training [INFO ] Epoch 10 Batch 4080 Training err. 1.94658 Training err. RA 2.21459 Valid. err. 1.97865
2018-02-05 11:48:26,370 training [INFO ] Epoch 10 Batch 4100 Training err. 1.91594 Training err. RA 2.21313 Valid. err. 1.98224
2018-02-05 11:48:27,165 training [INFO ] Epoch 10 Batch 4120 Training err. 1.92409 Training err. RA 2.21173 Valid. err. 1.97740
2018-02-05 11:48:27,939 training [INFO ] Epoch 10 Batch 4140 Training err. 1.92405 Training err. RA 2.21034 Valid. err. 1.98212
2018-02-05 11:48:28,718 training [INFO ] Epoch 10 Batch 4160 Training err. 1.92054 Training err. RA 2.20895 Valid. err. 1.97753
2018-02-05 11:48:29,494 training [INFO ] Epoch 10 Batch 4180 Training err. 1.88097 Training err. RA 2.20738 Valid. err. 1.97709
2018-02-05 11:48:30,284 training [INFO ] Epoch 10 Batch 4200 Training err. 1.89022 Training err. RA 2.20587 Valid. err. 1.97540
2018-02-05 11:48:31,060 training [INFO ] Epoch 10 Batch 4220 Training err. 1.89132 Training err. RA 2.20438 Valid. err. 1.99024
2018-02-05 11:48:31,849 training [INFO ] Epoch 10 Batch 4240 Training err. 1.91029 Training err. RA 2.20299 Valid. err. 2.00141
2018-02-05 11:48:32,636 training [INFO ] Epoch 10 Batch 4260 Training err. 1.91438 Training err. RA 2.20163 Valid. err. 1.96581
2018-02-05 11:48:33,452 training [INFO ] Epoch 10 Batch 4280 Training err. 1.89750 Training err. RA 2.20021 Valid. err. 1.98580
2018-02-05 11:48:34,233 training [INFO ] Epoch 10 Batch 4300 Training err. 1.91386 Training err. RA 2.19888 Valid. err. 1.97706
2018-02-05 11:48:35,033 training [INFO ] Epoch 10 Batch 4320 Training err. 1.89418 Training err. RA 2.19747 Valid. err. 1.97889
2018-02-05 11:48:35,814 training [INFO ] Epoch 10 Batch 4340 Training err. 1.88786 Training err. RA 2.19604 Valid. err. 1.96468
2018-02-05 11:48:36,598 training [INFO ] Epoch 10 Batch 4360 Training err. 1.88661 Training err. RA 2.19462 Valid. err. 1.97512
2018-02-05 11:48:37,374 training [INFO ] Epoch 10 Batch 4380 Training err. 1.90662 Training err. RA 2.19331 Valid. err. 1.97126
2018-02-05 11:48:38,152 training [INFO ] Epoch 10 Batch 4400 Training err. 1.87359 Training err. RA 2.19186 Valid. err. 1.95762
2018-02-05 11:48:38,934 training [INFO ] Epoch 10 Batch 4420 Training err. 1.87603 Training err. RA 2.19043 Valid. err. 1.97659
2018-02-05 11:48:39,723 training [INFO ] Epoch 10 Batch 4440 Training err. 1.88129 Training err. RA 2.18903 Valid. err. 1.96969
2018-02-05 11:48:40,503 training [INFO ] Epoch 10 Batch 4460 Training err. 1.88771 Training err. RA 2.18768 Valid. err. 1.99833
2018-02-05 11:48:41,284 training [INFO ] Epoch 10 Batch 4480 Training err. 1.89119 Training err. RA 2.18636 Valid. err. 1.96907
2018-02-05 11:48:42,883 training [INFO ] Epoch 11 Batch 4500 Training err. 1.89120 Training err. RA 2.18505 Valid. err. 1.96280
2018-02-05 11:48:43,669 training [INFO ] Epoch 11 Batch 4520 Training err. 1.90062 Training err. RA 2.18379 Valid. err. 1.96328
2018-02-05 11:48:44,456 training [INFO ] Epoch 11 Batch 4540 Training err. 1.90870 Training err. RA 2.18258 Valid. err. 1.96457
2018-02-05 11:48:45,239 training [INFO ] Epoch 11 Batch 4560 Training err. 1.90777 Training err. RA 2.18137 Valid. err. 1.97250
2018-02-05 11:48:46,025 training [INFO ] Epoch 11 Batch 4580 Training err. 1.88577 Training err. RA 2.18008 Valid. err. 1.96330
2018-02-05 11:48:46,817 training [INFO ] Epoch 11 Batch 4600 Training err. 1.89186 Training err. RA 2.17883 Valid. err. 1.95192
2018-02-05 11:48:47,609 training [INFO ] Epoch 11 Batch 4620 Training err. 1.86999 Training err. RA 2.17749 Valid. err. 1.96439
2018-02-05 11:48:48,386 training [INFO ] Epoch 11 Batch 4640 Training err. 1.83406 Training err. RA 2.17601 Valid. err. 1.95177
2018-02-05 11:48:49,194 training [INFO ] Epoch 11 Batch 4660 Training err. 1.88675 Training err. RA 2.17477 Valid. err. 1.95255
2018-02-05 11:48:49,978 training [INFO ] Epoch 11 Batch 4680 Training err. 1.85395 Training err. RA 2.17340 Valid. err. 1.96469
2018-02-05 11:48:50,753 training [INFO ] Epoch 11 Batch 4700 Training err. 1.89379 Training err. RA 2.17221 Valid. err. 1.94709
2018-02-05 11:48:51,534 training [INFO ] Epoch 11 Batch 4720 Training err. 1.86408 Training err. RA 2.17090 Valid. err. 1.94430
2018-02-05 11:48:52,310 training [INFO ] Epoch 11 Batch 4740 Training err. 1.90745 Training err. RA 2.16979 Valid. err. 1.94700
2018-02-05 11:48:53,089 training [INFO ] Epoch 11 Batch 4760 Training err. 1.83814 Training err. RA 2.16840 Valid. err. 1.95991
2018-02-05 11:48:53,872 training [INFO ] Epoch 11 Batch 4780 Training err. 1.86214 Training err. RA 2.16712 Valid. err. 1.95662
2018-02-05 11:48:54,689 training [INFO ] Epoch 11 Batch 4800 Training err. 1.87124 Training err. RA 2.16588 Valid. err. 1.94927
2018-02-05 11:48:55,469 training [INFO ] Epoch 11 Batch 4820 Training err. 1.88339 Training err. RA 2.16471 Valid. err. 1.95179
2018-02-05 11:48:56,267 training [INFO ] Epoch 11 Batch 4840 Training err. 1.84889 Training err. RA 2.16341 Valid. err. 1.94408
2018-02-05 11:48:57,051 training [INFO ] Epoch 11 Batch 4860 Training err. 1.85224 Training err. RA 2.16212 Valid. err. 1.95065
2018-02-05 11:48:57,826 training [INFO ] Epoch 11 Batch 4880 Training err. 1.82742 Training err. RA 2.16075 Valid. err. 1.94739
2018-02-05 11:48:58,605 training [INFO ] Epoch 11 Batch 4900 Training err. 1.86287 Training err. RA 2.15954 Valid. err. 1.94540
2018-02-05 11:48:59,380 training [INFO ] Epoch 11 Batch 4920 Training err. 1.88364 Training err. RA 2.15842 Valid. err. 1.94408
2018-02-05 11:49:00,951 training [INFO ] Epoch 12 Batch 4940 Training err. 1.86346 Training err. RA 2.15722 Valid. err. 1.93980
2018-02-05 11:49:01,728 training [INFO ] Epoch 12 Batch 4960 Training err. 1.84335 Training err. RA 2.15596 Valid. err. 1.94976
2018-02-05 11:49:02,536 training [INFO ] Epoch 12 Batch 4980 Training err. 1.90930 Training err. RA 2.15497 Valid. err. 1.94100
2018-02-05 11:49:03,322 training [INFO ] Epoch 12 Batch 5000 Training err. 1.87213 Training err. RA 2.15383 Valid. err. 1.93944
2018-02-05 11:49:04,159 training [INFO ] Epoch 12 Batch 5020 Training err. 1.87104 Training err. RA 2.15271 Valid. err. 1.94345
2018-02-05 11:49:04,963 training [INFO ] Epoch 12 Batch 5040 Training err. 1.85641 Training err. RA 2.15153 Valid. err. 1.94895
2018-02-05 11:49:05,752 training [INFO ] Epoch 12 Batch 5060 Training err. 1.84174 Training err. RA 2.15031 Valid. err. 1.93385
2018-02-05 11:49:06,540 training [INFO ] Epoch 12 Batch 5080 Training err. 1.82476 Training err. RA 2.14903 Valid. err. 1.95216
2018-02-05 11:49:07,336 training [INFO ] Epoch 12 Batch 5100 Training err. 1.84143 Training err. RA 2.14782 Valid. err. 1.93633
2018-02-05 11:49:08,110 training [INFO ] Epoch 12 Batch 5120 Training err. 1.82057 Training err. RA 2.14654 Valid. err. 1.93914
2018-02-05 11:49:08,896 training [INFO ] Epoch 12 Batch 5140 Training err. 1.87337 Training err. RA 2.14548 Valid. err. 1.94577
2018-02-05 11:49:09,678 training [INFO ] Epoch 12 Batch 5160 Training err. 1.83951 Training err. RA 2.14429 Valid. err. 1.93404
2018-02-05 11:49:10,467 training [INFO ] Epoch 12 Batch 5180 Training err. 1.85873 Training err. RA 2.14319 Valid. err. 1.93308
2018-02-05 11:49:11,251 training [INFO ] Epoch 12 Batch 5200 Training err. 1.83600 Training err. RA 2.14201 Valid. err. 1.94593
2018-02-05 11:49:12,051 training [INFO ] Epoch 12 Batch 5220 Training err. 1.83668 Training err. RA 2.14084 Valid. err. 1.93738
2018-02-05 11:49:12,864 training [INFO ] Epoch 12 Batch 5240 Training err. 1.84463 Training err. RA 2.13971 Valid. err. 1.93428
2018-02-05 11:49:13,631 training [INFO ] Epoch 12 Batch 5260 Training err. 1.83087 Training err. RA 2.13853 Valid. err. 1.92957
2018-02-05 11:49:14,439 training [INFO ] Epoch 12 Batch 5280 Training err. 1.84695 Training err. RA 2.13743 Valid. err. 1.93577
2018-02-05 11:49:15,231 training [INFO ] Epoch 12 Batch 5300 Training err. 1.85046 Training err. RA 2.13635 Valid. err. 1.92367
2018-02-05 11:49:16,019 training [INFO ] Epoch 12 Batch 5320 Training err. 1.79918 Training err. RA 2.13508 Valid. err. 1.92218
2018-02-05 11:49:16,807 training [INFO ] Epoch 12 Batch 5340 Training err. 1.82268 Training err. RA 2.13391 Valid. err. 1.94273
2018-02-05 11:49:17,586 training [INFO ] Epoch 12 Batch 5360 Training err. 1.86205 Training err. RA 2.13289 Valid. err. 1.93086
2018-02-05 11:49:19,212 training [INFO ] Epoch 13 Batch 5380 Training err. 1.82687 Training err. RA 2.13176 Valid. err. 1.92510
2018-02-05 11:49:19,989 training [INFO ] Epoch 13 Batch 5400 Training err. 1.83965 Training err. RA 2.13067 Valid. err. 1.92388
2018-02-05 11:49:20,766 training [INFO ] Epoch 13 Batch 5420 Training err. 1.85735 Training err. RA 2.12967 Valid. err. 1.91520
2018-02-05 11:49:21,542 training [INFO ] Epoch 13 Batch 5440 Training err. 1.83630 Training err. RA 2.12859 Valid. err. 1.92577
2018-02-05 11:49:22,325 training [INFO ] Epoch 13 Batch 5460 Training err. 1.84412 Training err. RA 2.12755 Valid. err. 1.92374
2018-02-05 11:49:23,112 training [INFO ] Epoch 13 Batch 5480 Training err. 1.85026 Training err. RA 2.12653 Valid. err. 1.92021
2018-02-05 11:49:23,891 training [INFO ] Epoch 13 Batch 5500 Training err. 1.83472 Training err. RA 2.12547 Valid. err. 1.91784
2018-02-05 11:49:24,669 training [INFO ] Epoch 13 Batch 5520 Training err. 1.80495 Training err. RA 2.12431 Valid. err. 1.92459
2018-02-05 11:49:25,444 training [INFO ] Epoch 13 Batch 5540 Training err. 1.79834 Training err. RA 2.12313 Valid. err. 1.91880
2018-02-05 11:49:26,223 training [INFO ] Epoch 13 Batch 5560 Training err. 1.82143 Training err. RA 2.12205 Valid. err. 1.91264
2018-02-05 11:49:27,000 training [INFO ] Epoch 13 Batch 5580 Training err. 1.81173 Training err. RA 2.12094 Valid. err. 1.91322
2018-02-05 11:49:27,775 training [INFO ] Epoch 13 Batch 5600 Training err. 1.83480 Training err. RA 2.11991 Valid. err. 1.91443
2018-02-05 11:49:28,552 training [INFO ] Epoch 13 Batch 5620 Training err. 1.82055 Training err. RA 2.11885 Valid. err. 1.90923
2018-02-05 11:49:29,334 training [INFO ] Epoch 13 Batch 5640 Training err. 1.84796 Training err. RA 2.11789 Valid. err. 1.90868
2018-02-05 11:49:30,106 training [INFO ] Epoch 13 Batch 5660 Training err. 1.80524 Training err. RA 2.11678 Valid. err. 1.90958
2018-02-05 11:49:30,886 training [INFO ] Epoch 13 Batch 5680 Training err. 1.79359 Training err. RA 2.11565 Valid. err. 1.91936
2018-02-05 11:49:31,660 training [INFO ] Epoch 13 Batch 5700 Training err. 1.81032 Training err. RA 2.11457 Valid. err. 1.91800
2018-02-05 11:49:32,442 training [INFO ] Epoch 13 Batch 5720 Training err. 1.85474 Training err. RA 2.11367 Valid. err. 1.90509
2018-02-05 11:49:33,218 training [INFO ] Epoch 13 Batch 5740 Training err. 1.78187 Training err. RA 2.11251 Valid. err. 1.90644
2018-02-05 11:49:33,998 training [INFO ] Epoch 13 Batch 5760 Training err. 1.80769 Training err. RA 2.11145 Valid. err. 1.91991
2018-02-05 11:49:34,772 training [INFO ] Epoch 13 Batch 5780 Training err. 1.78179 Training err. RA 2.11031 Valid. err. 1.91083
2018-02-05 11:49:35,553 training [INFO ] Epoch 13 Batch 5800 Training err. 1.80985 Training err. RA 2.10927 Valid. err. 1.91096
2018-02-05 11:49:36,328 training [INFO ] Epoch 13 Batch 5820 Training err. 1.82871 Training err. RA 2.10831 Valid. err. 1.91052
2018-02-05 11:49:37,884 training [INFO ] Epoch 14 Batch 5840 Training err. 1.83289 Training err. RA 2.10737 Valid. err. 1.90621
2018-02-05 11:49:38,659 training [INFO ] Epoch 14 Batch 5860 Training err. 1.81705 Training err. RA 2.10638 Valid. err. 1.90204
2018-02-05 11:49:39,437 training [INFO ] Epoch 14 Batch 5880 Training err. 1.81478 Training err. RA 2.10538 Valid. err. 1.89573
2018-02-05 11:49:40,213 training [INFO ] Epoch 14 Batch 5900 Training err. 1.84828 Training err. RA 2.10451 Valid. err. 1.90023
2018-02-05 11:49:40,993 training [INFO ] Epoch 14 Batch 5920 Training err. 1.81444 Training err. RA 2.10353 Valid. err. 1.91110
2018-02-05 11:49:41,767 training [INFO ] Epoch 14 Batch 5940 Training err. 1.81459 Training err. RA 2.10256 Valid. err. 1.90643
2018-02-05 11:49:42,548 training [INFO ] Epoch 14 Batch 5960 Training err. 1.77835 Training err. RA 2.10147 Valid. err. 1.89902
2018-02-05 11:49:43,324 training [INFO ] Epoch 14 Batch 5980 Training err. 1.78133 Training err. RA 2.10040 Valid. err. 1.91108
2018-02-05 11:49:44,104 training [INFO ] Epoch 14 Batch 6000 Training err. 1.79849 Training err. RA 2.09940 Valid. err. 1.89939
2018-02-05 11:49:44,879 training [INFO ] Epoch 14 Batch 6020 Training err. 1.77313 Training err. RA 2.09831 Valid. err. 1.92131
2018-02-05 11:49:45,658 training [INFO ] Epoch 14 Batch 6040 Training err. 1.82192 Training err. RA 2.09740 Valid. err. 1.89383
2018-02-05 11:49:46,430 training [INFO ] Epoch 14 Batch 6060 Training err. 1.79095 Training err. RA 2.09638 Valid. err. 1.90747
2018-02-05 11:49:47,210 training [INFO ] Epoch 14 Batch 6080 Training err. 1.82503 Training err. RA 2.09549 Valid. err. 1.90159
2018-02-05 11:49:47,981 training [INFO ] Epoch 14 Batch 6100 Training err. 1.77438 Training err. RA 2.09444 Valid. err. 1.89694
2018-02-05 11:49:48,767 training [INFO ] Epoch 14 Batch 6120 Training err. 1.78929 Training err. RA 2.09344 Valid. err. 1.89684
2018-02-05 11:49:49,571 training [INFO ] Epoch 14 Batch 6140 Training err. 1.79351 Training err. RA 2.09247 Valid. err. 1.90189
2018-02-05 11:49:50,351 training [INFO ] Epoch 14 Batch 6160 Training err. 1.81728 Training err. RA 2.09157 Valid. err. 1.90192
2018-02-05 11:49:51,152 training [INFO ] Epoch 14 Batch 6180 Training err. 1.77224 Training err. RA 2.09054 Valid. err. 1.89582
2018-02-05 11:49:52,021 training [INFO ] Epoch 14 Batch 6200 Training err. 1.80513 Training err. RA 2.08962 Valid. err. 1.88937
2018-02-05 11:49:52,792 training [INFO ] Epoch 14 Batch 6220 Training err. 1.75151 Training err. RA 2.08853 Valid. err. 1.89693
2018-02-05 11:49:53,569 training [INFO ] Epoch 14 Batch 6240 Training err. 1.77298 Training err. RA 2.08752 Valid. err. 1.89491
2018-02-05 11:49:54,342 training [INFO ] Epoch 14 Batch 6260 Training err. 1.80924 Training err. RA 2.08663 Valid. err. 1.88812
2018-02-05 11:49:55,937 training [INFO ] Epoch 15 Batch 6280 Training err. 1.80993 Training err. RA 2.08575 Valid. err. 1.90540
2018-02-05 11:49:56,717 training [INFO ] Epoch 15 Batch 6300 Training err. 1.78011 Training err. RA 2.08478 Valid. err. 1.89884
2018-02-05 11:49:57,493 training [INFO ] Epoch 15 Batch 6320 Training err. 1.82242 Training err. RA 2.08395 Valid. err. 1.88819
2018-02-05 11:49:58,269 training [INFO ] Epoch 15 Batch 6340 Training err. 1.78016 Training err. RA 2.08299 Valid. err. 1.88724
2018-02-05 11:49:59,044 training [INFO ] Epoch 15 Batch 6360 Training err. 1.79883 Training err. RA 2.08210 Valid. err. 1.88825
2018-02-05 11:49:59,817 training [INFO ] Epoch 15 Batch 6380 Training err. 1.79767 Training err. RA 2.08120 Valid. err. 1.88615
2018-02-05 11:50:00,602 training [INFO ] Epoch 15 Batch 6400 Training err. 1.79320 Training err. RA 2.08030 Valid. err. 1.88660
2018-02-05 11:50:01,406 training [INFO ] Epoch 15 Batch 6420 Training err. 1.75332 Training err. RA 2.07929 Valid. err. 1.89150
2018-02-05 11:50:02,225 training [INFO ] Epoch 15 Batch 6440 Training err. 1.76924 Training err. RA 2.07832 Valid. err. 1.88485
2018-02-05 11:50:03,007 training [INFO ] Epoch 15 Batch 6460 Training err. 1.75993 Training err. RA 2.07734 Valid. err. 1.89189
2018-02-05 11:50:03,788 training [INFO ] Epoch 15 Batch 6480 Training err. 1.78492 Training err. RA 2.07644 Valid. err. 1.89414
2018-02-05 11:50:04,562 training [INFO ] Epoch 15 Batch 6500 Training err. 1.78869 Training err. RA 2.07555 Valid. err. 1.88059
2018-02-05 11:50:05,353 training [INFO ] Epoch 15 Batch 6520 Training err. 1.77200 Training err. RA 2.07462 Valid. err. 1.89201
2018-02-05 11:50:06,151 training [INFO ] Epoch 15 Batch 6540 Training err. 1.78868 Training err. RA 2.07374 Valid. err. 1.89093
2018-02-05 11:50:06,945 training [INFO ] Epoch 15 Batch 6560 Training err. 1.76602 Training err. RA 2.07281 Valid. err. 1.89312
2018-02-05 11:50:07,738 training [INFO ] Epoch 15 Batch 6580 Training err. 1.77013 Training err. RA 2.07189 Valid. err. 1.87705
2018-02-05 11:50:08,528 training [INFO ] Epoch 15 Batch 6600 Training err. 1.77039 Training err. RA 2.07097 Valid. err. 1.88672
2018-02-05 11:50:09,321 training [INFO ] Epoch 15 Batch 6620 Training err. 1.78402 Training err. RA 2.07011 Valid. err. 1.89087
2018-02-05 11:50:10,126 training [INFO ] Epoch 15 Batch 6640 Training err. 1.75027 Training err. RA 2.06914 Valid. err. 1.87066
2018-02-05 11:50:10,935 training [INFO ] Epoch 15 Batch 6660 Training err. 1.76044 Training err. RA 2.06821 Valid. err. 1.88586
2018-02-05 11:50:11,741 training [INFO ] Epoch 15 Batch 6680 Training err. 1.75245 Training err. RA 2.06727 Valid. err. 1.88191
2018-02-05 11:50:12,530 training [INFO ] Epoch 15 Batch 6700 Training err. 1.76692 Training err. RA 2.06637 Valid. err. 1.89693
2018-02-05 11:50:13,342 training [INFO ] Epoch 15 Batch 6720 Training err. 1.77631 Training err. RA 2.06551 Valid. err. 1.88362
2018-02-05 11:50:14,917 training [INFO ] Epoch 16 Batch 6740 Training err. 1.78405 Training err. RA 2.06467 Valid. err. 1.87879
2018-02-05 11:50:15,806 training [INFO ] Epoch 16 Batch 6760 Training err. 1.77759 Training err. RA 2.06383 Valid. err. 1.87890
2018-02-05 11:50:16,605 training [INFO ] Epoch 16 Batch 6780 Training err. 1.78359 Training err. RA 2.06300 Valid. err. 1.87467
2018-02-05 11:50:17,401 training [INFO ] Epoch 16 Batch 6800 Training err. 1.78915 Training err. RA 2.06219 Valid. err. 1.89229
2018-02-05 11:50:18,180 training [INFO ] Epoch 16 Batch 6820 Training err. 1.77046 Training err. RA 2.06134 Valid. err. 1.87814
2018-02-05 11:50:18,955 training [INFO ] Epoch 16 Batch 6840 Training err. 1.77343 Training err. RA 2.06050 Valid. err. 1.86809
2018-02-05 11:50:19,735 training [INFO ] Epoch 16 Batch 6860 Training err. 1.75244 Training err. RA 2.05960 Valid. err. 1.87639
2018-02-05 11:50:20,512 training [INFO ] Epoch 16 Batch 6880 Training err. 1.72091 Training err. RA 2.05861 Valid. err. 1.87409
2018-02-05 11:50:21,287 training [INFO ] Epoch 16 Batch 6900 Training err. 1.76923 Training err. RA 2.05777 Valid. err. 1.87220
2018-02-05 11:50:22,069 training [INFO ] Epoch 16 Batch 6920 Training err. 1.74142 Training err. RA 2.05686 Valid. err. 1.87927
2018-02-05 11:50:22,860 training [INFO ] Epoch 16 Batch 6940 Training err. 1.77036 Training err. RA 2.05603 Valid. err. 1.87142
2018-02-05 11:50:23,649 training [INFO ] Epoch 16 Batch 6960 Training err. 1.74963 Training err. RA 2.05515 Valid. err. 1.86874
2018-02-05 11:50:24,434 training [INFO ] Epoch 16 Batch 6980 Training err. 1.79290 Training err. RA 2.05440 Valid. err. 1.86766
2018-02-05 11:50:25,209 training [INFO ] Epoch 16 Batch 7000 Training err. 1.71652 Training err. RA 2.05344 Valid. err. 1.87797
2018-02-05 11:50:26,001 training [INFO ] Epoch 16 Batch 7020 Training err. 1.75301 Training err. RA 2.05258 Valid. err. 1.87620
2018-02-05 11:50:26,814 training [INFO ] Epoch 16 Batch 7040 Training err. 1.76538 Training err. RA 2.05177 Valid. err. 1.87329
2018-02-05 11:50:27,601 training [INFO ] Epoch 16 Batch 7060 Training err. 1.76896 Training err. RA 2.05096 Valid. err. 1.87521
2018-02-05 11:50:28,383 training [INFO ] Epoch 16 Batch 7080 Training err. 1.73406 Training err. RA 2.05007 Valid. err. 1.86185
2018-02-05 11:50:29,157 training [INFO ] Epoch 16 Batch 7100 Training err. 1.74056 Training err. RA 2.04920 Valid. err. 1.87763
2018-02-05 11:50:29,936 training [INFO ] Epoch 16 Batch 7120 Training err. 1.71468 Training err. RA 2.04826 Valid. err. 1.86461
2018-02-05 11:50:30,709 training [INFO ] Epoch 16 Batch 7140 Training err. 1.74868 Training err. RA 2.04742 Valid. err. 1.86784
2018-02-05 11:50:31,497 training [INFO ] Epoch 16 Batch 7160 Training err. 1.77336 Training err. RA 2.04665 Valid. err. 1.86375
2018-02-05 11:50:33,098 training [INFO ] Epoch 17 Batch 7180 Training err. 1.76330 Training err. RA 2.04586 Valid. err. 1.86542
2018-02-05 11:50:33,871 training [INFO ] Epoch 17 Batch 7200 Training err. 1.73120 Training err. RA 2.04499 Valid. err. 1.87263
2018-02-05 11:50:34,647 training [INFO ] Epoch 17 Batch 7220 Training err. 1.79795 Training err. RA 2.04430 Valid. err. 1.86486
2018-02-05 11:50:35,420 training [INFO ] Epoch 17 Batch 7240 Training err. 1.75585 Training err. RA 2.04351 Valid. err. 1.86577
2018-02-05 11:50:36,193 training [INFO ] Epoch 17 Batch 7260 Training err. 1.76512 Training err. RA 2.04274 Valid. err. 1.86843
2018-02-05 11:50:36,974 training [INFO ] Epoch 17 Batch 7280 Training err. 1.74597 Training err. RA 2.04193 Valid. err. 1.86789
2018-02-05 11:50:37,750 training [INFO ] Epoch 17 Batch 7300 Training err. 1.73038 Training err. RA 2.04107 Valid. err. 1.85876
2018-02-05 11:50:38,536 training [INFO ] Epoch 17 Batch 7320 Training err. 1.71814 Training err. RA 2.04019 Valid. err. 1.86664
2018-02-05 11:50:39,336 training [INFO ] Epoch 17 Batch 7340 Training err. 1.73300 Training err. RA 2.03935 Valid. err. 1.87204
2018-02-05 11:50:40,122 training [INFO ] Epoch 17 Batch 7360 Training err. 1.71476 Training err. RA 2.03847 Valid. err. 1.87115
2018-02-05 11:50:40,925 training [INFO ] Epoch 17 Batch 7380 Training err. 1.76219 Training err. RA 2.03772 Valid. err. 1.86612
2018-02-05 11:50:41,712 training [INFO ] Epoch 17 Batch 7400 Training err. 1.73324 Training err. RA 2.03690 Valid. err. 1.86423
2018-02-05 11:50:42,508 training [INFO ] Epoch 17 Batch 7420 Training err. 1.75413 Training err. RA 2.03614 Valid. err. 1.86412
2018-02-05 11:50:43,312 training [INFO ] Epoch 17 Batch 7440 Training err. 1.72405 Training err. RA 2.03530 Valid. err. 1.87302
2018-02-05 11:50:44,102 training [INFO ] Epoch 17 Batch 7460 Training err. 1.72642 Training err. RA 2.03447 Valid. err. 1.86744
2018-02-05 11:50:44,877 training [INFO ] Epoch 17 Batch 7480 Training err. 1.74421 Training err. RA 2.03369 Valid. err. 1.86554
2018-02-05 11:50:45,656 training [INFO ] Epoch 17 Batch 7500 Training err. 1.72968 Training err. RA 2.03288 Valid. err. 1.86092
2018-02-05 11:50:46,431 training [INFO ] Epoch 17 Batch 7520 Training err. 1.73702 Training err. RA 2.03210 Valid. err. 1.86114
2018-02-05 11:50:47,213 training [INFO ] Epoch 17 Batch 7540 Training err. 1.74812 Training err. RA 2.03134 Valid. err. 1.85399
2018-02-05 11:50:47,990 training [INFO ] Epoch 17 Batch 7560 Training err. 1.69172 Training err. RA 2.03044 Valid. err. 1.85890
2018-02-05 11:50:48,768 training [INFO ] Epoch 17 Batch 7580 Training err. 1.71620 Training err. RA 2.02962 Valid. err. 1.86425
2018-02-05 11:50:49,544 training [INFO ] Epoch 17 Batch 7600 Training err. 1.76087 Training err. RA 2.02891 Valid. err. 1.85289
2018-02-05 11:50:51,109 training [INFO ] Epoch 18 Batch 7620 Training err. 1.72762 Training err. RA 2.02812 Valid. err. 1.85566
2018-02-05 11:50:51,884 training [INFO ] Epoch 18 Batch 7640 Training err. 1.74332 Training err. RA 2.02737 Valid. err. 1.85012
2018-02-05 11:50:52,659 training [INFO ] Epoch 18 Batch 7660 Training err. 1.74997 Training err. RA 2.02665 Valid. err. 1.85182
2018-02-05 11:50:53,434 training [INFO ] Epoch 18 Batch 7680 Training err. 1.72827 Training err. RA 2.02587 Valid. err. 1.85231
2018-02-05 11:50:54,213 training [INFO ] Epoch 18 Batch 7700 Training err. 1.74003 Training err. RA 2.02513 Valid. err. 1.85709
2018-02-05 11:50:54,987 training [INFO ] Epoch 18 Batch 7720 Training err. 1.74867 Training err. RA 2.02441 Valid. err. 1.85751
2018-02-05 11:50:55,770 training [INFO ] Epoch 18 Batch 7740 Training err. 1.73089 Training err. RA 2.02365 Valid. err. 1.84663
2018-02-05 11:50:56,545 training [INFO ] Epoch 18 Batch 7760 Training err. 1.70102 Training err. RA 2.02282 Valid. err. 1.85761
2018-02-05 11:50:57,327 training [INFO ] Epoch 18 Batch 7780 Training err. 1.70162 Training err. RA 2.02200 Valid. err. 1.84639
2018-02-05 11:50:58,112 training [INFO ] Epoch 18 Batch 7800 Training err. 1.72419 Training err. RA 2.02123 Valid. err. 1.84751
2018-02-05 11:50:58,901 training [INFO ] Epoch 18 Batch 7820 Training err. 1.71162 Training err. RA 2.02044 Valid. err. 1.84990
2018-02-05 11:50:59,685 training [INFO ] Epoch 18 Batch 7840 Training err. 1.73027 Training err. RA 2.01970 Valid. err. 1.84827
2018-02-05 11:51:00,484 training [INFO ] Epoch 18 Batch 7860 Training err. 1.72379 Training err. RA 2.01895 Valid. err. 1.84683
2018-02-05 11:51:01,263 training [INFO ] Epoch 18 Batch 7880 Training err. 1.74541 Training err. RA 2.01825 Valid. err. 1.84422
2018-02-05 11:51:02,041 training [INFO ] Epoch 18 Batch 7900 Training err. 1.69545 Training err. RA 2.01744 Valid. err. 1.84796
2018-02-05 11:51:02,813 training [INFO ] Epoch 18 Batch 7920 Training err. 1.70099 Training err. RA 2.01664 Valid. err. 1.85470
2018-02-05 11:51:03,593 training [INFO ] Epoch 18 Batch 7940 Training err. 1.71517 Training err. RA 2.01588 Valid. err. 1.85546
2018-02-05 11:51:04,365 training [INFO ] Epoch 18 Batch 7960 Training err. 1.75402 Training err. RA 2.01522 Valid. err. 1.84358
2018-02-05 11:51:05,177 training [INFO ] Epoch 18 Batch 7980 Training err. 1.68209 Training err. RA 2.01438 Valid. err. 1.84937
2018-02-05 11:51:05,976 training [INFO ] Epoch 18 Batch 8000 Training err. 1.71199 Training err. RA 2.01363 Valid. err. 1.85896
2018-02-05 11:51:06,762 training [INFO ] Epoch 18 Batch 8020 Training err. 1.68053 Training err. RA 2.01280 Valid. err. 1.84885
2018-02-05 11:51:07,536 training [INFO ] Epoch 18 Batch 8040 Training err. 1.71270 Training err. RA 2.01205 Valid. err. 1.84605
2018-02-05 11:51:08,322 training [INFO ] Epoch 18 Batch 8060 Training err. 1.73652 Training err. RA 2.01137 Valid. err. 1.84682
2018-02-05 11:51:10,141 training [INFO ] Epoch 19 Batch 8080 Training err. 1.74222 Training err. RA 2.01070 Valid. err. 1.84632
2018-02-05 11:51:10,927 training [INFO ] Epoch 19 Batch 8100 Training err. 1.71817 Training err. RA 2.00998 Valid. err. 1.83966
2018-02-05 11:51:11,718 training [INFO ] Epoch 19 Batch 8120 Training err. 1.71284 Training err. RA 2.00925 Valid. err. 1.83383
2018-02-05 11:51:12,499 training [INFO ] Epoch 19 Batch 8140 Training err. 1.75115 Training err. RA 2.00861 Valid. err. 1.84014
2018-02-05 11:51:13,271 training [INFO ] Epoch 19 Batch 8160 Training err. 1.72013 Training err. RA 2.00791 Valid. err. 1.84739
2018-02-05 11:51:14,042 training [INFO ] Epoch 19 Batch 8180 Training err. 1.71506 Training err. RA 2.00719 Valid. err. 1.84768
2018-02-05 11:51:14,812 training [INFO ] Epoch 19 Batch 8200 Training err. 1.67902 Training err. RA 2.00639 Valid. err. 1.84126
2018-02-05 11:51:15,588 training [INFO ] Epoch 19 Batch 8220 Training err. 1.69303 Training err. RA 2.00563 Valid. err. 1.84536
2018-02-05 11:51:16,359 training [INFO ] Epoch 19 Batch 8240 Training err. 1.70594 Training err. RA 2.00490 Valid. err. 1.84439
2018-02-05 11:51:17,135 training [INFO ] Epoch 19 Batch 8260 Training err. 1.68067 Training err. RA 2.00411 Valid. err. 1.85704
2018-02-05 11:51:17,918 training [INFO ] Epoch 19 Batch 8280 Training err. 1.72254 Training err. RA 2.00343 Valid. err. 1.83732
2018-02-05 11:51:18,702 training [INFO ] Epoch 19 Batch 8300 Training err. 1.70160 Training err. RA 2.00271 Valid. err. 1.85124
2018-02-05 11:51:19,491 training [INFO ] Epoch 19 Batch 8320 Training err. 1.73191 Training err. RA 2.00206 Valid. err. 1.85311
2018-02-05 11:51:20,275 training [INFO ] Epoch 19 Batch 8340 Training err. 1.67564 Training err. RA 2.00127 Valid. err. 1.83537
2018-02-05 11:51:21,051 training [INFO ] Epoch 19 Batch 8360 Training err. 1.69469 Training err. RA 2.00054 Valid. err. 1.83871
2018-02-05 11:51:21,822 training [INFO ] Epoch 19 Batch 8380 Training err. 1.70548 Training err. RA 1.99984 Valid. err. 1.84431
2018-02-05 11:51:22,593 training [INFO ] Epoch 19 Batch 8400 Training err. 1.72213 Training err. RA 1.99917 Valid. err. 1.84371
2018-02-05 11:51:23,363 training [INFO ] Epoch 19 Batch 8420 Training err. 1.67892 Training err. RA 1.99841 Valid. err. 1.83540
2018-02-05 11:51:24,134 training [INFO ] Epoch 19 Batch 8440 Training err. 1.71420 Training err. RA 1.99774 Valid. err. 1.83263
2018-02-05 11:51:24,903 training [INFO ] Epoch 19 Batch 8460 Training err. 1.65916 Training err. RA 1.99694 Valid. err. 1.84138
2018-02-05 11:51:25,672 training [INFO ] Epoch 19 Batch 8480 Training err. 1.68165 Training err. RA 1.99620 Valid. err. 1.84548
2018-02-05 11:51:26,455 training [INFO ] Epoch 19 Batch 8500 Training err. 1.71959 Training err. RA 1.99555 Valid. err. 1.83243
2018-02-05 11:51:28,251 training [INFO ] Epoch 20 Batch 8520 Training err. 1.72436 Training err. RA 1.99491 Valid. err. 1.83876
2018-02-05 11:51:29,021 training [INFO ] Epoch 20 Batch 8540 Training err. 1.68726 Training err. RA 1.99419 Valid. err. 1.84711
2018-02-05 11:51:29,812 training [INFO ] Epoch 20 Batch 8560 Training err. 1.73335 Training err. RA 1.99358 Valid. err. 1.83462
2018-02-05 11:51:30,608 training [INFO ] Epoch 20 Batch 8580 Training err. 1.68147 Training err. RA 1.99285 Valid. err. 1.83345
2018-02-05 11:51:31,398 training [INFO ] Epoch 20 Batch 8600 Training err. 1.71061 Training err. RA 1.99220 Valid. err. 1.83793
2018-02-05 11:51:32,195 training [INFO ] Epoch 20 Batch 8620 Training err. 1.70678 Training err. RA 1.99153 Valid. err. 1.83395
2018-02-05 11:51:32,986 training [INFO ] Epoch 20 Batch 8640 Training err. 1.69878 Training err. RA 1.99086 Valid. err. 1.83237
2018-02-05 11:51:33,780 training [INFO ] Epoch 20 Batch 8660 Training err. 1.66311 Training err. RA 1.99010 Valid. err. 1.84455
2018-02-05 11:51:34,575 training [INFO ] Epoch 20 Batch 8680 Training err. 1.68701 Training err. RA 1.98940 Valid. err. 1.83486
2018-02-05 11:51:35,359 training [INFO ] Epoch 20 Batch 8700 Training err. 1.67212 Training err. RA 1.98867 Valid. err. 1.83985
2018-02-05 11:51:36,145 training [INFO ] Epoch 20 Batch 8720 Training err. 1.69753 Training err. RA 1.98800 Valid. err. 1.84102
2018-02-05 11:51:36,926 training [INFO ] Epoch 20 Batch 8740 Training err. 1.70059 Training err. RA 1.98735 Valid. err. 1.83154
2018-02-05 11:51:37,702 training [INFO ] Epoch 20 Batch 8760 Training err. 1.68889 Training err. RA 1.98666 Valid. err. 1.83179
2018-02-05 11:51:38,484 training [INFO ] Epoch 20 Batch 8780 Training err. 1.70045 Training err. RA 1.98601 Valid. err. 1.83931
2018-02-05 11:51:39,289 training [INFO ] Epoch 20 Batch 8800 Training err. 1.66782 Training err. RA 1.98529 Valid. err. 1.84432
2018-02-05 11:51:40,064 training [INFO ] Epoch 20 Batch 8820 Training err. 1.68428 Training err. RA 1.98461 Valid. err. 1.83459
2018-02-05 11:51:40,851 training [INFO ] Epoch 20 Batch 8840 Training err. 1.68518 Training err. RA 1.98393 Valid. err. 1.83588
2018-02-05 11:51:41,643 training [INFO ] Epoch 20 Batch 8860 Training err. 1.69418 Training err. RA 1.98327 Valid. err. 1.83651
2018-02-05 11:51:42,435 training [INFO ] Epoch 20 Batch 8880 Training err. 1.66655 Training err. RA 1.98256 Valid. err. 1.82068
2018-02-05 11:51:43,257 training [INFO ] Epoch 20 Batch 8900 Training err. 1.67276 Training err. RA 1.98187 Valid. err. 1.83956
2018-02-05 11:51:44,158 training [INFO ] Epoch 20 Batch 8920 Training err. 1.66509 Training err. RA 1.98116 Valid. err. 1.83415
2018-02-05 11:51:44,932 training [INFO ] Epoch 20 Batch 8940 Training err. 1.68306 Training err. RA 1.98049 Valid. err. 1.84049
2018-02-05 11:51:45,700 training [INFO ] Epoch 20 Batch 8960 Training err. 1.69491 Training err. RA 1.97985 Valid. err. 1.83235
2018-02-05 11:51:47,305 training [INFO ] Epoch 21 Batch 8980 Training err. 1.69992 Training err. RA 1.97923 Valid. err. 1.82991
2018-02-05 11:51:48,087 training [INFO ] Epoch 21 Batch 9000 Training err. 1.68901 Training err. RA 1.97858 Valid. err. 1.82967
2018-02-05 11:51:49,051 training [INFO ] Epoch 21 Batch 9020 Training err. 1.69515 Training err. RA 1.97795 Valid. err. 1.82192
2018-02-05 11:51:49,888 training [INFO ] Epoch 21 Batch 9040 Training err. 1.70379 Training err. RA 1.97735 Valid. err. 1.84362
2018-02-05 11:51:50,672 training [INFO ] Epoch 21 Batch 9060 Training err. 1.68718 Training err. RA 1.97671 Valid. err. 1.82969
2018-02-05 11:51:51,482 training [INFO ] Epoch 21 Batch 9080 Training err. 1.68486 Training err. RA 1.97606 Valid. err. 1.82274
2018-02-05 11:51:52,258 training [INFO ] Epoch 21 Batch 9100 Training err. 1.66719 Training err. RA 1.97539 Valid. err. 1.82522
2018-02-05 11:51:53,044 training [INFO ] Epoch 21 Batch 9120 Training err. 1.64143 Training err. RA 1.97465 Valid. err. 1.82782
2018-02-05 11:51:53,825 training [INFO ] Epoch 21 Batch 9140 Training err. 1.68976 Training err. RA 1.97403 Valid. err. 1.82703
2018-02-05 11:51:54,626 training [INFO ] Epoch 21 Batch 9160 Training err. 1.65856 Training err. RA 1.97334 Valid. err. 1.82932
2018-02-05 11:51:55,506 training [INFO ] Epoch 21 Batch 9180 Training err. 1.68701 Training err. RA 1.97272 Valid. err. 1.82612
2018-02-05 11:51:56,307 training [INFO ] Epoch 21 Batch 9200 Training err. 1.67051 Training err. RA 1.97206 Valid. err. 1.82128
2018-02-05 11:51:57,103 training [INFO ] Epoch 21 Batch 9220 Training err. 1.71014 Training err. RA 1.97149 Valid. err. 1.82117
2018-02-05 11:51:57,905 training [INFO ] Epoch 21 Batch 9240 Training err. 1.62811 Training err. RA 1.97075 Valid. err. 1.83662
2018-02-05 11:51:58,692 training [INFO ] Epoch 21 Batch 9260 Training err. 1.67117 Training err. RA 1.97010 Valid. err. 1.83224
2018-02-05 11:51:59,598 training [INFO ] Epoch 21 Batch 9280 Training err. 1.68515 Training err. RA 1.96949 Valid. err. 1.82997
2018-02-05 11:52:00,493 training [INFO ] Epoch 21 Batch 9300 Training err. 1.68190 Training err. RA 1.96887 Valid. err. 1.83093
2018-02-05 11:52:01,406 training [INFO ] Epoch 21 Batch 9320 Training err. 1.65315 Training err. RA 1.96819 Valid. err. 1.81175
2018-02-05 11:52:02,187 training [INFO ] Epoch 21 Batch 9340 Training err. 1.65847 Training err. RA 1.96753 Valid. err. 1.83298
2018-02-05 11:52:02,968 training [INFO ] Epoch 21 Batch 9360 Training err. 1.63661 Training err. RA 1.96682 Valid. err. 1.81971
2018-02-05 11:52:03,894 training [INFO ] Epoch 21 Batch 9380 Training err. 1.66435 Training err. RA 1.96618 Valid. err. 1.82350
2018-02-05 11:52:04,847 training [INFO ] Epoch 21 Batch 9400 Training err. 1.69510 Training err. RA 1.96560 Valid. err. 1.81952
2018-02-05 11:52:06,630 training [INFO ] Epoch 22 Batch 9420 Training err. 1.68555 Training err. RA 1.96500 Valid. err. 1.82193
2018-02-05 11:52:07,434 training [INFO ] Epoch 22 Batch 9440 Training err. 1.64819 Training err. RA 1.96433 Valid. err. 1.82553
2018-02-05 11:52:08,239 training [INFO ] Epoch 22 Batch 9460 Training err. 1.71900 Training err. RA 1.96381 Valid. err. 1.81911
2018-02-05 11:52:09,032 training [INFO ] Epoch 22 Batch 9480 Training err. 1.67268 Training err. RA 1.96320 Valid. err. 1.82501
2018-02-05 11:52:09,816 training [INFO ] Epoch 22 Batch 9500 Training err. 1.68799 Training err. RA 1.96262 Valid. err. 1.82925
2018-02-05 11:52:10,604 training [INFO ] Epoch 22 Batch 9520 Training err. 1.66411 Training err. RA 1.96199 Valid. err. 1.82169
2018-02-05 11:52:11,532 training [INFO ] Epoch 22 Batch 9540 Training err. 1.64721 Training err. RA 1.96133 Valid. err. 1.81766
2018-02-05 11:52:12,411 training [INFO ] Epoch 22 Batch 9560 Training err. 1.64104 Training err. RA 1.96066 Valid. err. 1.81589
2018-02-05 11:52:13,270 training [INFO ] Epoch 22 Batch 9580 Training err. 1.65824 Training err. RA 1.96003 Valid. err. 1.83024
2018-02-05 11:52:14,075 training [INFO ] Epoch 22 Batch 9600 Training err. 1.63743 Training err. RA 1.95936 Valid. err. 1.83174
2018-02-05 11:52:14,864 training [INFO ] Epoch 22 Batch 9620 Training err. 1.68402 Training err. RA 1.95879 Valid. err. 1.82270
2018-02-05 11:52:15,657 training [INFO ] Epoch 22 Batch 9640 Training err. 1.65844 Training err. RA 1.95817 Valid. err. 1.82440
2018-02-05 11:52:16,444 training [INFO ] Epoch 22 Batch 9660 Training err. 1.67848 Training err. RA 1.95759 Valid. err. 1.82258
2018-02-05 11:52:17,234 training [INFO ] Epoch 22 Batch 9680 Training err. 1.64563 Training err. RA 1.95694 Valid. err. 1.83069
2018-02-05 11:52:18,022 training [INFO ] Epoch 22 Batch 9700 Training err. 1.64217 Training err. RA 1.95629 Valid. err. 1.82365
2018-02-05 11:52:18,808 training [INFO ] Epoch 22 Batch 9720 Training err. 1.66728 Training err. RA 1.95570 Valid. err. 1.82632
2018-02-05 11:52:19,591 training [INFO ] Epoch 22 Batch 9740 Training err. 1.65031 Training err. RA 1.95507 Valid. err. 1.82278
2018-02-05 11:52:20,397 training [INFO ] Epoch 22 Batch 9760 Training err. 1.65787 Training err. RA 1.95446 Valid. err. 1.82378
2018-02-05 11:52:21,203 training [INFO ] Epoch 22 Batch 9780 Training err. 1.67400 Training err. RA 1.95389 Valid. err. 1.81579
2018-02-05 11:52:21,993 training [INFO ] Epoch 22 Batch 9800 Training err. 1.61317 Training err. RA 1.95319 Valid. err. 1.82002
2018-02-05 11:52:22,774 training [INFO ] Epoch 22 Batch 9820 Training err. 1.64098 Training err. RA 1.95256 Valid. err. 1.82164
2018-02-05 11:52:23,558 training [INFO ] Epoch 22 Batch 9840 Training err. 1.68218 Training err. RA 1.95201 Valid. err. 1.81126
2018-02-05 11:52:25,169 training [INFO ] Epoch 23 Batch 9860 Training err. 1.65559 Training err. RA 1.95141 Valid. err. 1.81341
2018-02-05 11:52:25,971 training [INFO ] Epoch 23 Batch 9880 Training err. 1.66633 Training err. RA 1.95083 Valid. err. 1.80829
2018-02-05 11:52:26,771 training [INFO ] Epoch 23 Batch 9900 Training err. 1.67422 Training err. RA 1.95027 Valid. err. 1.81354
2018-02-05 11:52:27,580 training [INFO ] Epoch 23 Batch 9920 Training err. 1.65194 Training err. RA 1.94967 Valid. err. 1.80953
2018-02-05 11:52:28,389 training [INFO ] Epoch 23 Batch 9940 Training err. 1.66407 Training err. RA 1.94909 Valid. err. 1.82424
2018-02-05 11:52:29,188 training [INFO ] Epoch 23 Batch 9960 Training err. 1.67660 Training err. RA 1.94855 Valid. err. 1.81849
2018-02-05 11:52:29,996 training [INFO ] Epoch 23 Batch 9980 Training err. 1.64997 Training err. RA 1.94795 Valid. err. 1.80716
2018-02-05 11:52:30,801 training [INFO ] Epoch 23 Batch10000 Training err. 1.62557 Training err. RA 1.94730 Valid. err. 1.82208
2018-02-05 11:52:31,594 training [INFO ] Epoch 23 Batch10020 Training err. 1.63258 Training err. RA 1.94668 Valid. err. 1.81169
2018-02-05 11:52:32,401 training [INFO ] Epoch 23 Batch10040 Training err. 1.65197 Training err. RA 1.94609 Valid. err. 1.81660
2018-02-05 11:52:33,193 training [INFO ] Epoch 23 Batch10060 Training err. 1.63821 Training err. RA 1.94548 Valid. err. 1.81508
2018-02-05 11:52:33,988 training [INFO ] Epoch 23 Batch10080 Training err. 1.65845 Training err. RA 1.94491 Valid. err. 1.80633
2018-02-05 11:52:34,793 training [INFO ] Epoch 23 Batch10100 Training err. 1.65420 Training err. RA 1.94433 Valid. err. 1.80737
2018-02-05 11:52:35,588 training [INFO ] Epoch 23 Batch10120 Training err. 1.67123 Training err. RA 1.94379 Valid. err. 1.80774
2018-02-05 11:52:36,389 training [INFO ] Epoch 23 Batch10140 Training err. 1.61443 Training err. RA 1.94314 Valid. err. 1.81151
2018-02-05 11:52:37,186 training [INFO ] Epoch 23 Batch10160 Training err. 1.62930 Training err. RA 1.94252 Valid. err. 1.82051
2018-02-05 11:52:37,991 training [INFO ] Epoch 23 Batch10180 Training err. 1.64029 Training err. RA 1.94193 Valid. err. 1.81693
2018-02-05 11:52:38,801 training [INFO ] Epoch 23 Batch10200 Training err. 1.67709 Training err. RA 1.94141 Valid. err. 1.81128
2018-02-05 11:52:39,621 training [INFO ] Epoch 23 Batch10220 Training err. 1.61113 Training err. RA 1.94076 Valid. err. 1.81473
2018-02-05 11:52:40,418 training [INFO ] Epoch 23 Batch10240 Training err. 1.63696 Training err. RA 1.94017 Valid. err. 1.82271
2018-02-05 11:52:41,229 training [INFO ] Epoch 23 Batch10260 Training err. 1.61072 Training err. RA 1.93953 Valid. err. 1.81483
2018-02-05 11:52:42,035 training [INFO ] Epoch 23 Batch10280 Training err. 1.63854 Training err. RA 1.93894 Valid. err. 1.80893
2018-02-05 11:52:42,864 training [INFO ] Epoch 23 Batch10300 Training err. 1.66513 Training err. RA 1.93841 Valid. err. 1.81139
2018-02-05 11:52:44,520 training [INFO ] Epoch 24 Batch10320 Training err. 1.67291 Training err. RA 1.93790 Valid. err. 1.80751
2018-02-05 11:52:45,324 training [INFO ] Epoch 24 Batch10340 Training err. 1.64503 Training err. RA 1.93733 Valid. err. 1.80049
2018-02-05 11:52:46,182 training [INFO ] Epoch 24 Batch10360 Training err. 1.64115 Training err. RA 1.93676 Valid. err. 1.79812
2018-02-05 11:52:47,025 training [INFO ] Epoch 24 Batch10380 Training err. 1.68035 Training err. RA 1.93627 Valid. err. 1.80548
2018-02-05 11:52:47,872 training [INFO ] Epoch 24 Batch10400 Training err. 1.65388 Training err. RA 1.93572 Valid. err. 1.80936
2018-02-05 11:52:48,712 training [INFO ] Epoch 24 Batch10420 Training err. 1.63843 Training err. RA 1.93515 Valid. err. 1.81078
2018-02-05 11:52:49,548 training [INFO ] Epoch 24 Batch10440 Training err. 1.60667 Training err. RA 1.93452 Valid. err. 1.80929
2018-02-05 11:52:50,370 training [INFO ] Epoch 24 Batch10460 Training err. 1.62599 Training err. RA 1.93393 Valid. err. 1.81000
2018-02-05 11:52:51,156 training [INFO ] Epoch 24 Batch10480 Training err. 1.63820 Training err. RA 1.93337 Valid. err. 1.81360
2018-02-05 11:52:51,955 training [INFO ] Epoch 24 Batch10500 Training err. 1.61137 Training err. RA 1.93275 Valid. err. 1.82490
2018-02-05 11:52:52,805 training [INFO ] Epoch 24 Batch10520 Training err. 1.65334 Training err. RA 1.93222 Valid. err. 1.80279
2018-02-05 11:52:53,612 training [INFO ] Epoch 24 Batch10540 Training err. 1.63517 Training err. RA 1.93166 Valid. err. 1.81626
2018-02-05 11:52:54,423 training [INFO ] Epoch 24 Batch10560 Training err. 1.66425 Training err. RA 1.93115 Valid. err. 1.81841
2018-02-05 11:52:55,253 training [INFO ] Epoch 24 Batch10580 Training err. 1.60193 Training err. RA 1.93053 Valid. err. 1.80239
2018-02-05 11:52:56,096 training [INFO ] Epoch 24 Batch10600 Training err. 1.62472 Training err. RA 1.92995 Valid. err. 1.80237
2018-02-05 11:52:56,911 training [INFO ] Epoch 24 Batch10620 Training err. 1.63508 Training err. RA 1.92940 Valid. err. 1.81253
2018-02-05 11:52:57,702 training [INFO ] Epoch 24 Batch10640 Training err. 1.64747 Training err. RA 1.92887 Valid. err. 1.81303
2018-02-05 11:52:58,597 training [INFO ] Epoch 24 Batch10660 Training err. 1.61113 Training err. RA 1.92827 Valid. err. 1.80314
2018-02-05 11:52:59,399 training [INFO ] Epoch 24 Batch10680 Training err. 1.64477 Training err. RA 1.92774 Valid. err. 1.79721
2018-02-05 11:53:00,212 training [INFO ] Epoch 24 Batch10700 Training err. 1.59176 Training err. RA 1.92711 Valid. err. 1.81057
2018-02-05 11:53:01,098 training [INFO ] Epoch 24 Batch10720 Training err. 1.61423 Training err. RA 1.92653 Valid. err. 1.81107
2018-02-05 11:53:01,939 training [INFO ] Epoch 24 Batch10740 Training err. 1.64614 Training err. RA 1.92601 Valid. err. 1.80262
2018-02-05 11:53:03,717 training [INFO ] Epoch 25 Batch10760 Training err. 1.65808 Training err. RA 1.92551 Valid. err. 1.80056
2018-02-05 11:53:04,600 training [INFO ] Epoch 25 Batch10780 Training err. 1.61974 Training err. RA 1.92494 Valid. err. 1.81887
2018-02-05 11:53:05,426 training [INFO ] Epoch 25 Batch10800 Training err. 1.66791 Training err. RA 1.92447 Valid. err. 1.80004
2018-02-05 11:53:06,236 training [INFO ] Epoch 25 Batch10820 Training err. 1.61232 Training err. RA 1.92389 Valid. err. 1.80150
2018-02-05 11:53:07,021 training [INFO ] Epoch 25 Batch10840 Training err. 1.64547 Training err. RA 1.92338 Valid. err. 1.81092
2018-02-05 11:53:07,808 training [INFO ] Epoch 25 Batch10860 Training err. 1.64048 Training err. RA 1.92285 Valid. err. 1.80441
2018-02-05 11:53:08,598 training [INFO ] Epoch 25 Batch10880 Training err. 1.62849 Training err. RA 1.92231 Valid. err. 1.80287
2018-02-05 11:53:09,397 training [INFO ] Epoch 25 Batch10900 Training err. 1.59541 Training err. RA 1.92171 Valid. err. 1.81789
2018-02-05 11:53:10,223 training [INFO ] Epoch 25 Batch10920 Training err. 1.62655 Training err. RA 1.92117 Valid. err. 1.80429
2018-02-05 11:53:11,023 training [INFO ] Epoch 25 Batch10940 Training err. 1.60627 Training err. RA 1.92060 Valid. err. 1.81142
2018-02-05 11:53:11,857 training [INFO ] Epoch 25 Batch10960 Training err. 1.63196 Training err. RA 1.92007 Valid. err. 1.81046
2018-02-05 11:53:12,670 training [INFO ] Epoch 25 Batch10980 Training err. 1.63499 Training err. RA 1.91955 Valid. err. 1.79927
2018-02-05 11:53:13,524 training [INFO ] Epoch 25 Batch11000 Training err. 1.62562 Training err. RA 1.91902 Valid. err. 1.80196
2018-02-05 11:53:14,315 training [INFO ] Epoch 25 Batch11020 Training err. 1.63683 Training err. RA 1.91850 Valid. err. 1.81094
2018-02-05 11:53:15,102 training [INFO ] Epoch 25 Batch11040 Training err. 1.59489 Training err. RA 1.91792 Valid. err. 1.81149
2018-02-05 11:53:15,891 training [INFO ] Epoch 25 Batch11060 Training err. 1.61951 Training err. RA 1.91738 Valid. err. 1.80555
2018-02-05 11:53:16,772 training [INFO ] Epoch 25 Batch11080 Training err. 1.61632 Training err. RA 1.91684 Valid. err. 1.80483
2018-02-05 11:53:17,606 training [INFO ] Epoch 25 Batch11100 Training err. 1.62530 Training err. RA 1.91631 Valid. err. 1.80497
2018-02-05 11:53:18,427 training [INFO ] Epoch 25 Batch11120 Training err. 1.60338 Training err. RA 1.91575 Valid. err. 1.79178
2018-02-05 11:53:19,251 training [INFO ] Epoch 25 Batch11140 Training err. 1.60534 Training err. RA 1.91519 Valid. err. 1.81126
2018-02-05 11:53:20,040 training [INFO ] Epoch 25 Batch11160 Training err. 1.60335 Training err. RA 1.91463 Valid. err. 1.80367
2018-02-05 11:53:20,879 training [INFO ] Epoch 25 Batch11180 Training err. 1.61507 Training err. RA 1.91410 Valid. err. 1.81632
2018-02-05 11:53:21,700 training [INFO ] Epoch 25 Batch11200 Training err. 1.63142 Training err. RA 1.91359 Valid. err. 1.79611
2018-02-05 11:53:23,318 training [INFO ] Epoch 26 Batch11220 Training err. 1.63597 Training err. RA 1.91310 Valid. err. 1.79881
2018-02-05 11:53:24,120 training [INFO ] Epoch 26 Batch11240 Training err. 1.62388 Training err. RA 1.91258 Valid. err. 1.79789
2018-02-05 11:53:24,923 training [INFO ] Epoch 26 Batch11260 Training err. 1.63150 Training err. RA 1.91208 Valid. err. 1.79459
2018-02-05 11:53:25,727 training [INFO ] Epoch 26 Batch11280 Training err. 1.63974 Training err. RA 1.91160 Valid. err. 1.81284
2018-02-05 11:53:26,531 training [INFO ] Epoch 26 Batch11300 Training err. 1.62827 Training err. RA 1.91110 Valid. err. 1.79279
2018-02-05 11:53:27,340 training [INFO ] Epoch 26 Batch11320 Training err. 1.61505 Training err. RA 1.91057 Valid. err. 1.79566
2018-02-05 11:53:28,153 training [INFO ] Epoch 26 Batch11340 Training err. 1.60546 Training err. RA 1.91004 Valid. err. 1.79385
2018-02-05 11:53:28,950 training [INFO ] Epoch 26 Batch11360 Training err. 1.58204 Training err. RA 1.90946 Valid. err. 1.79592
2018-02-05 11:53:29,744 training [INFO ] Epoch 26 Batch11380 Training err. 1.62797 Training err. RA 1.90896 Valid. err. 1.80100
2018-02-05 11:53:30,547 training [INFO ] Epoch 26 Batch11400 Training err. 1.59717 Training err. RA 1.90842 Valid. err. 1.79814
2018-02-05 11:53:31,435 training [INFO ] Epoch 26 Batch11420 Training err. 1.62444 Training err. RA 1.90792 Valid. err. 1.79527
2018-02-05 11:53:32,309 training [INFO ] Epoch 26 Batch11440 Training err. 1.60915 Training err. RA 1.90740 Valid. err. 1.79184
2018-02-05 11:53:33,110 training [INFO ] Epoch 26 Batch11460 Training err. 1.64786 Training err. RA 1.90694 Valid. err. 1.79826
2018-02-05 11:53:33,908 training [INFO ] Epoch 26 Batch11480 Training err. 1.56584 Training err. RA 1.90635 Valid. err. 1.80703
2018-02-05 11:53:34,775 training [INFO ] Epoch 26 Batch11500 Training err. 1.60981 Training err. RA 1.90583 Valid. err. 1.79991
2018-02-05 11:53:35,595 training [INFO ] Epoch 26 Batch11520 Training err. 1.62053 Training err. RA 1.90534 Valid. err. 1.80492
2018-02-05 11:53:36,407 training [INFO ] Epoch 26 Batch11540 Training err. 1.61391 Training err. RA 1.90483 Valid. err. 1.80586
2018-02-05 11:53:37,201 training [INFO ] Epoch 26 Batch11560 Training err. 1.59247 Training err. RA 1.90429 Valid. err. 1.78309
2018-02-05 11:53:37,985 training [INFO ] Epoch 26 Batch11580 Training err. 1.59469 Training err. RA 1.90376 Valid. err. 1.79928
2018-02-05 11:53:38,772 training [INFO ] Epoch 26 Batch11600 Training err. 1.57650 Training err. RA 1.90319 Valid. err. 1.79316
2018-02-05 11:53:39,568 training [INFO ] Epoch 26 Batch11620 Training err. 1.60214 Training err. RA 1.90268 Valid. err. 1.79824
2018-02-05 11:53:40,357 training [INFO ] Epoch 26 Batch11640 Training err. 1.63098 Training err. RA 1.90221 Valid. err. 1.79434
2018-02-05 11:53:41,984 training [INFO ] Epoch 27 Batch11660 Training err. 1.62584 Training err. RA 1.90174 Valid. err. 1.79563
2018-02-05 11:53:42,767 training [INFO ] Epoch 27 Batch11680 Training err. 1.58557 Training err. RA 1.90119 Valid. err. 1.80024
2018-02-05 11:53:43,557 training [INFO ] Epoch 27 Batch11700 Training err. 1.66011 Training err. RA 1.90078 Valid. err. 1.79653
2018-02-05 11:53:44,343 training [INFO ] Epoch 27 Batch11720 Training err. 1.61158 Training err. RA 1.90029 Valid. err. 1.80470
2018-02-05 11:53:45,133 training [INFO ] Epoch 27 Batch11740 Training err. 1.63172 Training err. RA 1.89983 Valid. err. 1.79755
2018-02-05 11:53:45,916 training [INFO ] Epoch 27 Batch11760 Training err. 1.60031 Training err. RA 1.89932 Valid. err. 1.79306
2018-02-05 11:53:46,702 training [INFO ] Epoch 27 Batch11780 Training err. 1.58727 Training err. RA 1.89879 Valid. err. 1.79456
2018-02-05 11:53:47,490 training [INFO ] Epoch 27 Batch11800 Training err. 1.58104 Training err. RA 1.89825 Valid. err. 1.78719
2018-02-05 11:53:48,276 training [INFO ] Epoch 27 Batch11820 Training err. 1.60287 Training err. RA 1.89775 Valid. err. 1.80233
2018-02-05 11:53:49,087 training [INFO ] Epoch 27 Batch11840 Training err. 1.57810 Training err. RA 1.89721 Valid. err. 1.80267
2018-02-05 11:53:49,895 training [INFO ] Epoch 27 Batch11860 Training err. 1.62258 Training err. RA 1.89675 Valid. err. 1.79806
2018-02-05 11:53:50,912 training [INFO ] Epoch 27 Batch11880 Training err. 1.60116 Training err. RA 1.89625 Valid. err. 1.79869
2018-02-05 11:53:51,858 training [INFO ] Epoch 27 Batch11900 Training err. 1.62086 Training err. RA 1.89579 Valid. err. 1.79709
2018-02-05 11:53:52,847 training [INFO ] Epoch 27 Batch11920 Training err. 1.58801 Training err. RA 1.89527 Valid. err. 1.80662
2018-02-05 11:53:53,798 training [INFO ] Epoch 27 Batch11940 Training err. 1.58193 Training err. RA 1.89475 Valid. err. 1.79693
2018-02-05 11:53:54,839 training [INFO ] Epoch 27 Batch11960 Training err. 1.60789 Training err. RA 1.89427 Valid. err. 1.80138
2018-02-05 11:53:55,737 training [INFO ] Epoch 27 Batch11980 Training err. 1.58533 Training err. RA 1.89375 Valid. err. 1.80211
2018-02-05 11:53:56,666 training [INFO ] Epoch 27 Batch12000 Training err. 1.59996 Training err. RA 1.89326 Valid. err. 1.79678
2018-02-05 11:53:57,684 training [INFO ] Epoch 27 Batch12020 Training err. 1.61507 Training err. RA 1.89280 Valid. err. 1.79669
2018-02-05 11:53:58,659 training [INFO ] Epoch 27 Batch12040 Training err. 1.55450 Training err. RA 1.89224 Valid. err. 1.79618
2018-02-05 11:53:59,532 training [INFO ] Epoch 27 Batch12060 Training err. 1.58474 Training err. RA 1.89173 Valid. err. 1.79631
2018-02-05 11:54:00,326 training [INFO ] Epoch 27 Batch12080 Training err. 1.62069 Training err. RA 1.89128 Valid. err. 1.78784
2018-02-05 11:54:01,980 training [INFO ] Epoch 28 Batch12100 Training err. 1.59859 Training err. RA 1.89080 Valid. err. 1.78939
2018-02-05 11:54:02,763 training [INFO ] Epoch 28 Batch12120 Training err. 1.60730 Training err. RA 1.89033 Valid. err. 1.78013
2018-02-05 11:54:03,563 training [INFO ] Epoch 28 Batch12140 Training err. 1.61695 Training err. RA 1.88988 Valid. err. 1.79054
2018-02-05 11:54:04,347 training [INFO ] Epoch 28 Batch12160 Training err. 1.59501 Training err. RA 1.88939 Valid. err. 1.78579
2018-02-05 11:54:05,128 training [INFO ] Epoch 28 Batch12180 Training err. 1.60589 Training err. RA 1.88893 Valid. err. 1.80696
2018-02-05 11:54:05,912 training [INFO ] Epoch 28 Batch12200 Training err. 1.62203 Training err. RA 1.88849 Valid. err. 1.79112
2018-02-05 11:54:06,699 training [INFO ] Epoch 28 Batch12220 Training err. 1.58753 Training err. RA 1.88800 Valid. err. 1.78557
2018-02-05 11:54:07,481 training [INFO ] Epoch 28 Batch12240 Training err. 1.57061 Training err. RA 1.88748 Valid. err. 1.79780
2018-02-05 11:54:08,261 training [INFO ] Epoch 28 Batch12260 Training err. 1.57872 Training err. RA 1.88698 Valid. err. 1.78747
2018-02-05 11:54:09,041 training [INFO ] Epoch 28 Batch12280 Training err. 1.59657 Training err. RA 1.88650 Valid. err. 1.79883
2018-02-05 11:54:09,827 training [INFO ] Epoch 28 Batch12300 Training err. 1.58276 Training err. RA 1.88601 Valid. err. 1.79300
2018-02-05 11:54:10,605 training [INFO ] Epoch 28 Batch12320 Training err. 1.60108 Training err. RA 1.88555 Valid. err. 1.78131
2018-02-05 11:54:11,392 training [INFO ] Epoch 28 Batch12340 Training err. 1.59884 Training err. RA 1.88508 Valid. err. 1.78602
2018-02-05 11:54:12,175 training [INFO ] Epoch 28 Batch12360 Training err. 1.61503 Training err. RA 1.88464 Valid. err. 1.78611
2018-02-05 11:54:12,958 training [INFO ] Epoch 28 Batch12380 Training err. 1.55711 Training err. RA 1.88412 Valid. err. 1.79173
2018-02-05 11:54:13,743 training [INFO ] Epoch 28 Batch12400 Training err. 1.57706 Training err. RA 1.88362 Valid. err. 1.79603
2018-02-05 11:54:14,532 training [INFO ] Epoch 28 Batch12420 Training err. 1.58250 Training err. RA 1.88314 Valid. err. 1.79672
2018-02-05 11:54:15,317 training [INFO ] Epoch 28 Batch12440 Training err. 1.61805 Training err. RA 1.88271 Valid. err. 1.79050
2018-02-05 11:54:16,102 training [INFO ] Epoch 28 Batch12460 Training err. 1.55811 Training err. RA 1.88219 Valid. err. 1.78958
2018-02-05 11:54:16,894 training [INFO ] Epoch 28 Batch12480 Training err. 1.57847 Training err. RA 1.88170 Valid. err. 1.79920
2018-02-05 11:54:17,710 training [INFO ] Epoch 28 Batch12500 Training err. 1.55838 Training err. RA 1.88118 Valid. err. 1.79673
2018-02-05 11:54:18,527 training [INFO ] Epoch 28 Batch12520 Training err. 1.58091 Training err. RA 1.88070 Valid. err. 1.78767
2018-02-05 11:54:19,342 training [INFO ] Epoch 28 Batch12540 Training err. 1.60891 Training err. RA 1.88027 Valid. err. 1.79308
2018-02-05 11:54:21,017 training [INFO ] Epoch 29 Batch12560 Training err. 1.61715 Training err. RA 1.87985 Valid. err. 1.78450
2018-02-05 11:54:21,844 training [INFO ] Epoch 29 Batch12580 Training err. 1.58981 Training err. RA 1.87939 Valid. err. 1.78026
2018-02-05 11:54:22,639 training [INFO ] Epoch 29 Batch12600 Training err. 1.58677 Training err. RA 1.87893 Valid. err. 1.78017
2018-02-05 11:54:23,421 training [INFO ] Epoch 29 Batch12620 Training err. 1.62553 Training err. RA 1.87852 Valid. err. 1.78656
2018-02-05 11:54:24,212 training [INFO ] Epoch 29 Batch12640 Training err. 1.60295 Training err. RA 1.87809 Valid. err. 1.78686
2018-02-05 11:54:25,001 training [INFO ] Epoch 29 Batch12660 Training err. 1.57867 Training err. RA 1.87762 Valid. err. 1.78737
2018-02-05 11:54:25,812 training [INFO ] Epoch 29 Batch12680 Training err. 1.55233 Training err. RA 1.87710 Valid. err. 1.79513
2018-02-05 11:54:26,607 training [INFO ] Epoch 29 Batch12700 Training err. 1.57377 Training err. RA 1.87662 Valid. err. 1.79135
2018-02-05 11:54:27,427 training [INFO ] Epoch 29 Batch12720 Training err. 1.58690 Training err. RA 1.87617 Valid. err. 1.80146
2018-02-05 11:54:28,234 training [INFO ] Epoch 29 Batch12740 Training err. 1.55750 Training err. RA 1.87567 Valid. err. 1.80760
2018-02-05 11:54:29,027 training [INFO ] Epoch 29 Batch12760 Training err. 1.59944 Training err. RA 1.87524 Valid. err. 1.78316
2018-02-05 11:54:29,814 training [INFO ] Epoch 29 Batch12780 Training err. 1.58140 Training err. RA 1.87478 Valid. err. 1.79800
2018-02-05 11:54:30,614 training [INFO ] Epoch 29 Batch12800 Training err. 1.61277 Training err. RA 1.87437 Valid. err. 1.79808
2018-02-05 11:54:31,401 training [INFO ] Epoch 29 Batch12820 Training err. 1.54786 Training err. RA 1.87386 Valid. err. 1.78572
2018-02-05 11:54:32,233 training [INFO ] Epoch 29 Batch12840 Training err. 1.57380 Training err. RA 1.87339 Valid. err. 1.78564
2018-02-05 11:54:33,140 training [INFO ] Epoch 29 Batch12860 Training err. 1.58243 Training err. RA 1.87294 Valid. err. 1.79510
2018-02-05 11:54:34,122 training [INFO ] Epoch 29 Batch12880 Training err. 1.58920 Training err. RA 1.87250 Valid. err. 1.79544
2018-02-05 11:54:35,066 training [INFO ] Epoch 29 Batch12900 Training err. 1.56083 Training err. RA 1.87201 Valid. err. 1.78421
2018-02-05 11:54:35,891 training [INFO ] Epoch 29 Batch12920 Training err. 1.59194 Training err. RA 1.87158 Valid. err. 1.77893
2018-02-05 11:54:36,690 training [INFO ] Epoch 29 Batch12940 Training err. 1.54089 Training err. RA 1.87107 Valid. err. 1.79236
2018-02-05 11:54:37,485 training [INFO ] Epoch 29 Batch12960 Training err. 1.56206 Training err. RA 1.87059 Valid. err. 1.79118
2018-02-05 11:54:38,283 training [INFO ] Epoch 29 Batch12980 Training err. 1.59109 Training err. RA 1.87016 Valid. err. 1.78806
2018-02-05 11:54:39,895 training [INFO ] Epoch 30 Batch13000 Training err. 1.60445 Training err. RA 1.86975 Valid. err. 1.78599
2018-02-05 11:54:40,690 training [INFO ] Epoch 30 Batch13020 Training err. 1.56803 Training err. RA 1.86929 Valid. err. 1.80012
2018-02-05 11:54:41,520 training [INFO ] Epoch 30 Batch13040 Training err. 1.61561 Training err. RA 1.86890 Valid. err. 1.78390
2018-02-05 11:54:42,374 training [INFO ] Epoch 30 Batch13060 Training err. 1.55920 Training err. RA 1.86843 Valid. err. 1.78585
2018-02-05 11:54:43,209 training [INFO ] Epoch 30 Batch13080 Training err. 1.59521 Training err. RA 1.86801 Valid. err. 1.79198
2018-02-05 11:54:44,065 training [INFO ] Epoch 30 Batch13100 Training err. 1.58865 Training err. RA 1.86758 Valid. err. 1.78736
2018-02-05 11:54:44,915 training [INFO ] Epoch 30 Batch13120 Training err. 1.57367 Training err. RA 1.86713 Valid. err. 1.79216
2018-02-05 11:54:45,738 training [INFO ] Epoch 30 Batch13140 Training err. 1.54476 Training err. RA 1.86664 Valid. err. 1.79991
2018-02-05 11:54:46,580 training [INFO ] Epoch 30 Batch13160 Training err. 1.57736 Training err. RA 1.86620 Valid. err. 1.78991
2018-02-05 11:54:47,379 training [INFO ] Epoch 30 Batch13180 Training err. 1.55742 Training err. RA 1.86573 Valid. err. 1.79643
2018-02-05 11:54:48,190 training [INFO ] Epoch 30 Batch13200 Training err. 1.57953 Training err. RA 1.86530 Valid. err. 1.79570
2018-02-05 11:54:48,988 training [INFO ] Epoch 30 Batch13220 Training err. 1.58386 Training err. RA 1.86488 Valid. err. 1.78048
2018-02-05 11:54:49,778 training [INFO ] Epoch 30 Batch13240 Training err. 1.57359 Training err. RA 1.86444 Valid. err. 1.78831
2018-02-05 11:54:50,576 training [INFO ] Epoch 30 Batch13260 Training err. 1.58785 Training err. RA 1.86402 Valid. err. 1.79680
2018-02-05 11:54:51,373 training [INFO ] Epoch 30 Batch13280 Training err. 1.54267 Training err. RA 1.86353 Valid. err. 1.79199
2018-02-05 11:54:52,172 training [INFO ] Epoch 30 Batch13300 Training err. 1.57197 Training err. RA 1.86310 Valid. err. 1.78726
2018-02-05 11:54:52,969 training [INFO ] Epoch 30 Batch13320 Training err. 1.56484 Training err. RA 1.86265 Valid. err. 1.78801
2018-02-05 11:54:53,760 training [INFO ] Epoch 30 Batch13340 Training err. 1.57421 Training err. RA 1.86222 Valid. err. 1.79147
2018-02-05 11:54:54,555 training [INFO ] Epoch 30 Batch13360 Training err. 1.55443 Training err. RA 1.86175 Valid. err. 1.78022
2018-02-05 11:54:55,343 training [INFO ] Epoch 30 Batch13380 Training err. 1.55492 Training err. RA 1.86130 Valid. err. 1.79626
2018-02-05 11:54:56,152 training [INFO ] Epoch 30 Batch13400 Training err. 1.55540 Training err. RA 1.86084 Valid. err. 1.78540
2018-02-05 11:54:56,971 training [INFO ] Epoch 30 Batch13420 Training err. 1.56432 Training err. RA 1.86040 Valid. err. 1.80215
2018-02-05 11:54:57,825 training [INFO ] Epoch 30 Batch13440 Training err. 1.58133 Training err. RA 1.85998 Valid. err. 1.78088
2018-02-05 11:54:58,423 __main__ [INFO ] End of training
2018-02-05 11:56:56,061 __main__ [INFO ] 
==============================
Starting experiment ng_dsh_gb
==============================
2018-02-05 11:56:56,080 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 11:56:56,179 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:56:56,517 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 11:56:56,570 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 11:56:56,571 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 1
}
--------------------------------------------------
2018-02-05 11:56:56,666 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:56:56,915 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 11:56:56,929 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 11:56:56,929 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 11:56:57,025 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:56:57,360 __main__ [INFO ] Evaluated on training set. Loss: 4.50778
2018-02-05 11:56:57,380 __main__ [INFO ] Evaluated on validation set. Loss: 4.59313
2018-02-05 11:56:57,380 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 4 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 1
}
--------------------------------------------------
2018-02-05 11:56:57,476 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:56:57,721 __main__ [INFO ] Evaluated on training set. Loss: 4.50752
2018-02-05 11:56:57,736 __main__ [INFO ] Evaluated on validation set. Loss: 4.59441
2018-02-05 11:56:57,736 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 5 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 11:56:57,840 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:56:58,195 __main__ [INFO ] Evaluated on training set. Loss: 3.50508
2018-02-05 11:56:58,215 __main__ [INFO ] Evaluated on validation set. Loss: 3.53561
2018-02-05 11:56:58,216 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 6 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 2
}
--------------------------------------------------
2018-02-05 11:56:58,320 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:56:58,577 __main__ [INFO ] Evaluated on training set. Loss: 3.50053
2018-02-05 11:56:58,592 __main__ [INFO ] Evaluated on validation set. Loss: 3.54952
2018-02-05 11:56:58,592 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 7 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 11:56:58,698 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:56:59,058 __main__ [INFO ] Evaluated on training set. Loss: 3.50535
2018-02-05 11:56:59,078 __main__ [INFO ] Evaluated on validation set. Loss: 3.53157
2018-02-05 11:56:59,079 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 8 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 2
}
--------------------------------------------------
2018-02-05 11:56:59,187 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:56:59,446 __main__ [INFO ] Evaluated on training set. Loss: 3.50092
2018-02-05 11:56:59,461 __main__ [INFO ] Evaluated on validation set. Loss: 3.54237
2018-02-05 11:56:59,461 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 9 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 11:56:59,586 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:56:59,992 __main__ [INFO ] Evaluated on training set. Loss: 2.52835
2018-02-05 11:57:00,014 __main__ [INFO ] Evaluated on validation set. Loss: 2.68919
2018-02-05 11:57:00,015 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 10 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 3
}
--------------------------------------------------
2018-02-05 11:57:00,143 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:00,430 __main__ [INFO ] Evaluated on training set. Loss: 2.50673
2018-02-05 11:57:00,446 __main__ [INFO ] Evaluated on validation set. Loss: 2.73057
2018-02-05 11:57:00,446 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 11 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 11:57:00,573 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:00,979 __main__ [INFO ] Evaluated on training set. Loss: 2.53413
2018-02-05 11:57:01,001 __main__ [INFO ] Evaluated on validation set. Loss: 2.65083
2018-02-05 11:57:01,002 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 12 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 3
}
--------------------------------------------------
2018-02-05 11:57:01,128 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:01,419 __main__ [INFO ] Evaluated on training set. Loss: 2.51428
2018-02-05 11:57:01,435 __main__ [INFO ] Evaluated on validation set. Loss: 2.68495
2018-02-05 11:57:01,435 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 13 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 11:57:01,568 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:02,042 __main__ [INFO ] Evaluated on training set. Loss: 1.83746
2018-02-05 11:57:02,065 __main__ [INFO ] Evaluated on validation set. Loss: 2.42074
2018-02-05 11:57:02,065 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 14 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 4
}
--------------------------------------------------
2018-02-05 11:57:02,202 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:02,585 __main__ [INFO ] Evaluated on training set. Loss: 1.78918
2018-02-05 11:57:02,602 __main__ [INFO ] Evaluated on validation set. Loss: 2.52118
2018-02-05 11:57:02,602 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 15 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 11:57:02,736 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:03,205 __main__ [INFO ] Evaluated on training set. Loss: 1.87039
2018-02-05 11:57:03,228 __main__ [INFO ] Evaluated on validation set. Loss: 2.30218
2018-02-05 11:57:03,228 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 16 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 4
}
--------------------------------------------------
2018-02-05 11:57:03,363 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:03,710 __main__ [INFO ] Evaluated on training set. Loss: 1.82971
2018-02-05 11:57:03,727 __main__ [INFO ] Evaluated on validation set. Loss: 2.38176
2018-02-05 11:57:03,727 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 17 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 11:57:03,879 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:04,498 __main__ [INFO ] Evaluated on training set. Loss: 1.38630
2018-02-05 11:57:04,522 __main__ [INFO ] Evaluated on validation set. Loss: 2.67920
2018-02-05 11:57:04,522 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 18 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 5
}
--------------------------------------------------
2018-02-05 11:57:04,676 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:05,145 __main__ [INFO ] Evaluated on training set. Loss: 1.31779
2018-02-05 11:57:05,163 __main__ [INFO ] Evaluated on validation set. Loss: 2.79794
2018-02-05 11:57:05,163 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 19 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 11:57:05,354 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:05,938 __main__ [INFO ] Evaluated on training set. Loss: 1.48051
2018-02-05 11:57:05,962 __main__ [INFO ] Evaluated on validation set. Loss: 2.46406
2018-02-05 11:57:05,963 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 20 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 5
}
--------------------------------------------------
2018-02-05 11:57:06,118 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:06,585 __main__ [INFO ] Evaluated on training set. Loss: 1.42771
2018-02-05 11:57:06,603 __main__ [INFO ] Evaluated on validation set. Loss: 2.56396
2018-02-05 11:57:06,603 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 21 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 6
}
--------------------------------------------------
2018-02-05 11:57:06,814 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:07,673 __main__ [INFO ] Evaluated on training set. Loss: 1.05625
2018-02-05 11:57:07,699 __main__ [INFO ] Evaluated on validation set. Loss: 3.07878
2018-02-05 11:57:07,699 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 22 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 6
}
--------------------------------------------------
2018-02-05 11:57:07,885 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:08,578 __main__ [INFO ] Evaluated on training set. Loss: 0.98492
2018-02-05 11:57:08,597 __main__ [INFO ] Evaluated on validation set. Loss: 3.21457
2018-02-05 11:57:08,598 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 23 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 6
}
--------------------------------------------------
2018-02-05 11:57:08,831 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:09,584 __main__ [INFO ] Evaluated on training set. Loss: 1.23781
2018-02-05 11:57:09,609 __main__ [INFO ] Evaluated on validation set. Loss: 2.84237
2018-02-05 11:57:09,609 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 24 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 6
}
--------------------------------------------------
2018-02-05 11:57:09,838 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:10,475 __main__ [INFO ] Evaluated on training set. Loss: 1.18767
2018-02-05 11:57:10,494 __main__ [INFO ] Evaluated on validation set. Loss: 2.96093
2018-02-05 11:57:10,495 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 25 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 7
}
--------------------------------------------------
2018-02-05 11:57:10,740 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:11,701 __main__ [INFO ] Evaluated on training set. Loss: 0.80592
2018-02-05 11:57:11,729 __main__ [INFO ] Evaluated on validation set. Loss: 3.56593
2018-02-05 11:57:11,729 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 26 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 7
}
--------------------------------------------------
2018-02-05 11:57:11,989 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:12,872 __main__ [INFO ] Evaluated on training set. Loss: 0.73984
2018-02-05 11:57:12,893 __main__ [INFO ] Evaluated on validation set. Loss: 3.70812
2018-02-05 11:57:12,894 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 27 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 7
}
--------------------------------------------------
2018-02-05 11:57:13,157 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:14,133 __main__ [INFO ] Evaluated on training set. Loss: 1.07876
2018-02-05 11:57:14,160 __main__ [INFO ] Evaluated on validation set. Loss: 3.33480
2018-02-05 11:57:14,161 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 28 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 7
}
--------------------------------------------------
2018-02-05 11:57:14,437 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:15,322 __main__ [INFO ] Evaluated on training set. Loss: 1.03562
2018-02-05 11:57:15,344 __main__ [INFO ] Evaluated on validation set. Loss: 3.46293
2018-02-05 11:57:15,345 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 29 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.001,
  "n": 8
}
--------------------------------------------------
2018-02-05 11:57:15,636 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:16,778 __main__ [INFO ] Evaluated on training set. Loss: 0.60556
2018-02-05 11:57:16,807 __main__ [INFO ] Evaluated on validation set. Loss: 4.05365
2018-02-05 11:57:16,807 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 30 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.001,
  "n": 8
}
--------------------------------------------------
2018-02-05 11:57:17,108 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:18,160 __main__ [INFO ] Evaluated on training set. Loss: 0.54771
2018-02-05 11:57:18,183 __main__ [INFO ] Evaluated on validation set. Loss: 4.19924
2018-02-05 11:57:18,183 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 31 out of 32 with hyperparameters:
{
  "adapt": true,
  "delta": 0.01,
  "n": 8
}
--------------------------------------------------
2018-02-05 11:57:18,489 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:19,632 __main__ [INFO ] Evaluated on training set. Loss: 0.96321
2018-02-05 11:57:19,661 __main__ [INFO ] Evaluated on validation set. Loss: 3.83837
2018-02-05 11:57:19,661 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 32 out of 32 with hyperparameters:
{
  "adapt": false,
  "delta": 0.01,
  "n": 8
}
--------------------------------------------------
2018-02-05 11:57:20,025 __main__ [INFO ] Training complete. Now evaluating on training set
2018-02-05 11:57:20,987 __main__ [INFO ] Evaluated on training set. Loss: 0.92772
2018-02-05 11:57:21,010 __main__ [INFO ] Evaluated on validation set. Loss: 3.97177
2018-02-05 12:12:32,633 __main__ [INFO ] 
==============================
Starting experiment rnn_dsh_gb_2
==============================
2018-02-05 12:12:32,718 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 1 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 10,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-05 12:12:47,382 training [INFO ] Epoch  1 Batch  100 Training err. 99.77533 Training err. RA 99.77533 Valid. err. 110.55489
2018-02-05 12:12:49,369 training [INFO ] Epoch  1 Batch  200 Training err. 86.61934 Training err. RA 93.19733 Valid. err. 80.23442
2018-02-05 12:12:52,695 training [INFO ] Epoch  2 Batch  300 Training err. 80.36085 Training err. RA 88.91851 Valid. err. 71.85677
2018-02-05 12:12:55,049 training [INFO ] Epoch  2 Batch  400 Training err. 77.75888 Training err. RA 86.12860 Valid. err. 81.72584
2018-02-05 12:12:57,970 training [INFO ] Epoch  3 Batch  500 Training err. 74.69677 Training err. RA 83.84223 Valid. err. 73.84774
2018-02-05 12:13:00,049 training [INFO ] Epoch  3 Batch  600 Training err. 71.53816 Training err. RA 81.79155 Valid. err. 73.43849
2018-02-05 12:13:02,921 training [INFO ] Epoch  4 Batch  700 Training err. 69.27723 Training err. RA 80.00379 Valid. err. 107.01968
2018-02-05 12:13:05,059 training [INFO ] Epoch  4 Batch  800 Training err. 84.48124 Training err. RA 80.56347 Valid. err. 78.11911
2018-02-05 12:13:22,976 __main__ [INFO ] 
==============================
Starting experiment rnn_dsh_gb_2
==============================
2018-02-05 12:13:22,981 __main__ [INFO ] Removing old results directory ./experiments/rnn_dsh_gb_2/out
2018-02-05 12:13:22,983 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 1 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 1024,
  "num_timesteps": 128,
  "batch_size": 10,
  "num_layers": 1,
  "hidden_size": 128,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-05 12:13:27,056 training [INFO ] Epoch  1 Batch  100 Training err. 3.21432 Training err. RA 3.21432 Valid. err. 3.07113
2018-02-05 12:13:28,968 training [INFO ] Epoch  1 Batch  200 Training err. 3.04312 Training err. RA 3.12872 Valid. err. 3.03085
2018-02-05 12:13:31,613 training [INFO ] Epoch  2 Batch  300 Training err. 2.92325 Training err. RA 3.06023 Valid. err. 2.82689
2018-02-05 12:13:33,542 training [INFO ] Epoch  2 Batch  400 Training err. 2.72295 Training err. RA 2.97591 Valid. err. 2.68159
2018-02-05 12:13:36,194 training [INFO ] Epoch  3 Batch  500 Training err. 2.62079 Training err. RA 2.90489 Valid. err. 2.60631
2018-02-05 12:13:38,113 training [INFO ] Epoch  3 Batch  600 Training err. 2.54567 Training err. RA 2.84502 Valid. err. 2.55538
2018-02-05 12:13:40,750 training [INFO ] Epoch  4 Batch  700 Training err. 2.49008 Training err. RA 2.79431 Valid. err. 2.48779
2018-02-05 12:13:42,676 training [INFO ] Epoch  4 Batch  800 Training err. 2.44381 Training err. RA 2.75050 Valid. err. 2.51633
2018-02-05 12:13:45,370 training [INFO ] Epoch  5 Batch  900 Training err. 2.39090 Training err. RA 2.71054 Valid. err. 2.40598
2018-02-05 12:13:47,345 training [INFO ] Epoch  5 Batch 1000 Training err. 2.36101 Training err. RA 2.67559 Valid. err. 2.36360
2018-02-05 12:13:49,306 training [INFO ] Epoch  5 Batch 1100 Training err. 2.31959 Training err. RA 2.64323 Valid. err. 2.34014
2018-02-05 12:13:51,987 training [INFO ] Epoch  6 Batch 1200 Training err. 2.29781 Training err. RA 2.61444 Valid. err. 2.33797
2018-02-05 12:13:54,000 training [INFO ] Epoch  6 Batch 1300 Training err. 2.25611 Training err. RA 2.58688 Valid. err. 2.34293
2018-02-05 12:13:56,687 training [INFO ] Epoch  7 Batch 1400 Training err. 2.24175 Training err. RA 2.56223 Valid. err. 2.25144
2018-02-05 12:13:58,622 training [INFO ] Epoch  7 Batch 1500 Training err. 2.21114 Training err. RA 2.53882 Valid. err. 2.23873
2018-02-05 12:14:01,280 training [INFO ] Epoch  8 Batch 1600 Training err. 2.19226 Training err. RA 2.51716 Valid. err. 2.22265
2018-02-05 12:14:03,221 training [INFO ] Epoch  8 Batch 1700 Training err. 2.17320 Training err. RA 2.49693 Valid. err. 2.20405
2018-02-05 12:14:05,884 training [INFO ] Epoch  9 Batch 1800 Training err. 2.14605 Training err. RA 2.47743 Valid. err. 2.17658
2018-02-05 12:14:07,814 training [INFO ] Epoch  9 Batch 1900 Training err. 2.13851 Training err. RA 2.45960 Valid. err. 2.18633
2018-02-05 12:14:09,749 training [INFO ] Epoch  9 Batch 2000 Training err. 2.11208 Training err. RA 2.44222 Valid. err. 2.17132
2018-02-05 12:14:12,399 training [INFO ] Epoch 10 Batch 2100 Training err. 2.10511 Training err. RA 2.42617 Valid. err. 2.12475
2018-02-05 12:14:14,335 training [INFO ] Epoch 10 Batch 2200 Training err. 2.07965 Training err. RA 2.41042 Valid. err. 2.12720
2018-02-05 12:14:15,450 __main__ [INFO ] End of training
2018-02-08 10:38:14,808 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 10:38:14,826 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 10:38:14,842 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 10:38:14,843 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 10:38:29,438 training [INFO ] Epoch  1 Batch   50 Training err. 4.03708 Training err. RA 4.03708 Valid. err. 3.53623
2018-02-08 10:38:29,753 training [INFO ] Epoch  1 Batch  100 Training err. 3.40098 Training err. RA 3.71903 Valid. err. 3.30233
2018-02-08 10:38:30,056 training [INFO ] Epoch  1 Batch  150 Training err. 3.27742 Training err. RA 3.57183 Valid. err. 3.28578
2018-02-08 10:38:30,328 training [INFO ] Epoch  1 Batch  200 Training err. 3.26646 Training err. RA 3.49548 Valid. err. 3.25643
2018-02-08 10:38:30,566 training [INFO ] Epoch  1 Batch  250 Training err. 3.22034 Training err. RA 3.44046 Valid. err. 3.25935
2018-02-08 10:38:30,840 training [INFO ] Epoch  1 Batch  300 Training err. 3.26876 Training err. RA 3.41184 Valid. err. 3.22181
2018-02-08 10:38:31,280 training [INFO ] Epoch  2 Batch  350 Training err. 3.22602 Training err. RA 3.38529 Valid. err. 3.23468
2018-02-08 10:38:31,622 training [INFO ] Epoch  2 Batch  400 Training err. 3.22607 Training err. RA 3.36539 Valid. err. 3.24047
2018-02-08 10:38:31,905 training [INFO ] Epoch  2 Batch  450 Training err. 3.21541 Training err. RA 3.34873 Valid. err. 3.21034
2018-02-08 10:38:32,134 training [INFO ] Epoch  2 Batch  500 Training err. 3.20734 Training err. RA 3.33459 Valid. err. 3.21774
2018-02-08 10:38:32,367 training [INFO ] Epoch  2 Batch  550 Training err. 3.18942 Training err. RA 3.32139 Valid. err. 3.22152
2018-02-08 10:38:32,678 training [INFO ] Epoch  2 Batch  600 Training err. 3.20961 Training err. RA 3.31208 Valid. err. 3.17403
2018-02-08 10:38:33,186 training [INFO ] Epoch  3 Batch  650 Training err. 3.18507 Training err. RA 3.30231 Valid. err. 3.18041
2018-02-08 10:38:33,451 training [INFO ] Epoch  3 Batch  700 Training err. 3.17428 Training err. RA 3.29316 Valid. err. 3.15894
2018-02-08 10:38:33,709 training [INFO ] Epoch  3 Batch  750 Training err. 3.12560 Training err. RA 3.28199 Valid. err. 3.13578
2018-02-08 10:38:33,992 training [INFO ] Epoch  3 Batch  800 Training err. 3.13328 Training err. RA 3.27270 Valid. err. 3.11378
2018-02-08 10:38:34,313 training [INFO ] Epoch  3 Batch  850 Training err. 3.07063 Training err. RA 3.26081 Valid. err. 3.15170
2018-02-08 10:38:34,635 training [INFO ] Epoch  3 Batch  900 Training err. 3.11474 Training err. RA 3.25270 Valid. err. 3.03334
2018-02-08 10:38:35,002 training [INFO ] Epoch  4 Batch  950 Training err. 3.08232 Training err. RA 3.24373 Valid. err. 3.07042
2018-02-08 10:38:35,234 training [INFO ] Epoch  4 Batch 1000 Training err. 3.01300 Training err. RA 3.23219 Valid. err. 2.99423
2018-02-08 10:38:35,506 training [INFO ] Epoch  4 Batch 1050 Training err. 2.94754 Training err. RA 3.21864 Valid. err. 2.97451
2018-02-08 10:38:35,826 training [INFO ] Epoch  4 Batch 1100 Training err. 2.94612 Training err. RA 3.20625 Valid. err. 2.90155
2018-02-08 10:38:36,146 training [INFO ] Epoch  4 Batch 1150 Training err. 2.90196 Training err. RA 3.19302 Valid. err. 2.92513
2018-02-08 10:38:36,414 training [INFO ] Epoch  4 Batch 1200 Training err. 2.90345 Training err. RA 3.18095 Valid. err. 2.84290
2018-02-08 10:38:36,761 training [INFO ] Epoch  5 Batch 1250 Training err. 2.93743 Training err. RA 3.17121 Valid. err. 2.89204
2018-02-08 10:38:37,039 training [INFO ] Epoch  5 Batch 1300 Training err. 2.87671 Training err. RA 3.15989 Valid. err. 2.82577
2018-02-08 10:38:37,355 training [INFO ] Epoch  5 Batch 1350 Training err. 2.77467 Training err. RA 3.14562 Valid. err. 2.79540
2018-02-08 10:38:37,674 training [INFO ] Epoch  5 Batch 1400 Training err. 2.79866 Training err. RA 3.13323 Valid. err. 2.77574
2018-02-08 10:38:37,941 training [INFO ] Epoch  5 Batch 1450 Training err. 2.80561 Training err. RA 3.12193 Valid. err. 2.76364
2018-02-08 10:38:38,204 training [INFO ] Epoch  5 Batch 1500 Training err. 2.76366 Training err. RA 3.10999 Valid. err. 2.72715
2018-02-08 10:38:38,608 training [INFO ] Epoch  6 Batch 1550 Training err. 2.84650 Training err. RA 3.10149 Valid. err. 2.73472
2018-02-08 10:38:38,934 training [INFO ] Epoch  6 Batch 1600 Training err. 2.78506 Training err. RA 3.09160 Valid. err. 2.77997
2018-02-08 10:38:39,249 training [INFO ] Epoch  6 Batch 1650 Training err. 2.71111 Training err. RA 3.08007 Valid. err. 2.70419
2018-02-08 10:38:39,486 training [INFO ] Epoch  6 Batch 1700 Training err. 2.68194 Training err. RA 3.06836 Valid. err. 2.69732
2018-02-08 10:38:39,709 training [INFO ] Epoch  6 Batch 1750 Training err. 2.75396 Training err. RA 3.05938 Valid. err. 2.68738
2018-02-08 10:38:39,944 training [INFO ] Epoch  6 Batch 1800 Training err. 2.66366 Training err. RA 3.04838 Valid. err. 2.65984
2018-02-08 10:38:40,377 training [INFO ] Epoch  7 Batch 1850 Training err. 2.75940 Training err. RA 3.04057 Valid. err. 2.77332
2018-02-08 10:38:40,685 training [INFO ] Epoch  7 Batch 1900 Training err. 2.73680 Training err. RA 3.03258 Valid. err. 2.64157
2018-02-08 10:38:40,952 training [INFO ] Epoch  7 Batch 1950 Training err. 2.63304 Training err. RA 3.02234 Valid. err. 2.62025
2018-02-08 10:38:41,194 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59782 Training err. RA 3.01172 Valid. err. 2.60434
2018-02-08 10:38:41,440 training [INFO ] Epoch  7 Batch 2050 Training err. 2.69755 Training err. RA 3.00406 Valid. err. 2.59151
2018-02-08 10:38:41,758 training [INFO ] Epoch  7 Batch 2100 Training err. 2.58017 Training err. RA 2.99397 Valid. err. 2.57106
2018-02-08 10:38:42,225 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64768 Training err. RA 2.98591 Valid. err. 2.56027
2018-02-08 10:38:42,479 training [INFO ] Epoch  8 Batch 2200 Training err. 2.71620 Training err. RA 2.97978 Valid. err. 2.56267
2018-02-08 10:38:42,720 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58827 Training err. RA 2.97108 Valid. err. 2.57122
2018-02-08 10:38:42,970 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55337 Training err. RA 2.96200 Valid. err. 2.55579
2018-02-08 10:38:43,284 training [INFO ] Epoch  8 Batch 2350 Training err. 2.61258 Training err. RA 2.95457 Valid. err. 2.57150
2018-02-08 10:38:43,596 training [INFO ] Epoch  8 Batch 2400 Training err. 2.51520 Training err. RA 2.94541 Valid. err. 2.52428
2018-02-08 10:38:43,914 training [INFO ] Epoch  8 Batch 2450 Training err. 2.59469 Training err. RA 2.93826 Valid. err. 2.53006
2018-02-08 10:38:44,280 training [INFO ] Epoch  9 Batch 2500 Training err. 2.63460 Training err. RA 2.93218 Valid. err. 2.53122
2018-02-08 10:38:44,512 training [INFO ] Epoch  9 Batch 2550 Training err. 2.59544 Training err. RA 2.92558 Valid. err. 2.51033
2018-02-08 10:38:44,746 training [INFO ] Epoch  9 Batch 2600 Training err. 2.50622 Training err. RA 2.91752 Valid. err. 2.48563
2018-02-08 10:38:44,981 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56657 Training err. RA 2.91089 Valid. err. 2.52043
2018-02-08 10:38:45,224 training [INFO ] Epoch  9 Batch 2700 Training err. 2.47245 Training err. RA 2.90278 Valid. err. 2.51137
2018-02-08 10:38:45,468 training [INFO ] Epoch  9 Batch 2750 Training err. 2.52176 Training err. RA 2.89585 Valid. err. 2.46877
2018-02-08 10:38:45,805 training [INFO ] Epoch 10 Batch 2800 Training err. 2.56925 Training err. RA 2.89002 Valid. err. 2.49972
2018-02-08 10:38:46,037 training [INFO ] Epoch 10 Batch 2850 Training err. 2.58412 Training err. RA 2.88465 Valid. err. 2.47388
2018-02-08 10:38:46,302 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46289 Training err. RA 2.87738 Valid. err. 2.44115
2018-02-08 10:38:46,554 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51434 Training err. RA 2.87122 Valid. err. 2.50364
2018-02-08 10:38:46,793 training [INFO ] Epoch 10 Batch 3000 Training err. 2.44873 Training err. RA 2.86418 Valid. err. 2.43053
2018-02-08 10:38:47,046 training [INFO ] Epoch 10 Batch 3050 Training err. 2.46738 Training err. RA 2.85768 Valid. err. 2.43282
2018-02-08 10:38:47,191 __main__ [INFO ] End of training
2018-02-08 10:38:48,461 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 10:38:48,461 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 10:38:48,811 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004
2018-02-08 10:38:49,087 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220
2018-02-08 10:38:49,351 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708
2018-02-08 10:38:49,593 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226
2018-02-08 10:38:49,922 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791
2018-02-08 10:38:50,165 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095
2018-02-08 10:38:50,401 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617
2018-02-08 10:38:50,641 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091
2018-02-08 10:38:50,968 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571
2018-02-08 10:38:51,217 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752
2018-02-08 10:38:51,498 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115
2018-02-08 10:38:51,771 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850
2018-02-08 10:38:52,149 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007
2018-02-08 10:38:52,431 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578
2018-02-08 10:38:52,729 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063
2018-02-08 10:38:53,031 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541
2018-02-08 10:38:53,578 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331
2018-02-08 10:38:53,836 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885
2018-02-08 10:38:54,122 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402
2018-02-08 10:38:54,397 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876
2018-02-08 10:38:55,062 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261
2018-02-08 10:38:55,448 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771
2018-02-08 10:38:55,839 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434
2018-02-08 10:38:56,222 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230
2018-02-08 10:38:56,865 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620
2018-02-08 10:38:57,337 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672
2018-02-08 10:38:57,813 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298
2018-02-08 10:38:58,243 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529
2018-02-08 10:38:58,770 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410
2018-02-08 10:38:59,025 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609
2018-02-08 10:38:59,274 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099
2018-02-08 10:38:59,525 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653
2018-02-08 10:38:59,860 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570
2018-02-08 10:39:00,156 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963
2018-02-08 10:39:00,417 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815
2018-02-08 10:39:00,676 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999
2018-02-08 10:39:01,031 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695
2018-02-08 10:39:01,277 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245
2018-02-08 10:39:01,529 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415
2018-02-08 10:39:01,778 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328
2018-02-08 10:39:02,032 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049
2018-02-08 10:39:02,110 __main__ [INFO ] End of training
2018-02-08 10:39:02,273 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 10:39:02,273 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 10:39:02,569 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945
2018-02-08 10:39:02,861 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585
2018-02-08 10:39:03,147 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036
2018-02-08 10:39:03,404 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844
2018-02-08 10:39:03,667 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920
2018-02-08 10:39:03,939 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863
2018-02-08 10:39:04,305 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650
2018-02-08 10:39:04,572 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923
2018-02-08 10:39:04,839 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288
2018-02-08 10:39:05,108 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297
2018-02-08 10:39:05,378 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633
2018-02-08 10:39:05,645 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329
2018-02-08 10:39:06,007 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222
2018-02-08 10:39:06,282 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798
2018-02-08 10:39:06,546 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300
2018-02-08 10:39:06,810 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864
2018-02-08 10:39:07,071 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590
2018-02-08 10:39:07,330 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607
2018-02-08 10:39:07,677 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056
2018-02-08 10:39:07,928 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954
2018-02-08 10:39:08,179 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403
2018-02-08 10:39:08,431 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444
2018-02-08 10:39:08,696 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682
2018-02-08 10:39:08,964 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167
2018-02-08 10:39:09,320 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971
2018-02-08 10:39:09,587 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051
2018-02-08 10:39:09,847 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551
2018-02-08 10:39:10,105 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389
2018-02-08 10:39:10,361 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053
2018-02-08 10:39:10,619 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556
2018-02-08 10:39:10,976 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131
2018-02-08 10:39:11,242 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897
2018-02-08 10:39:11,508 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355
2018-02-08 10:39:11,776 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367
2018-02-08 10:39:12,043 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858
2018-02-08 10:39:12,308 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398
2018-02-08 10:39:12,668 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153
2018-02-08 10:39:12,934 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232
2018-02-08 10:39:13,201 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708
2018-02-08 10:39:13,462 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540
2018-02-08 10:39:13,737 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636
2018-02-08 10:39:14,000 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333
2018-02-08 10:39:14,356 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953
2018-02-08 10:39:14,622 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544
2018-02-08 10:39:14,887 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447
2018-02-08 10:39:15,170 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667
2018-02-08 10:39:15,451 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969
2018-02-08 10:39:15,717 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715
2018-02-08 10:39:15,987 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796
2018-02-08 10:39:16,342 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617
2018-02-08 10:39:16,602 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010
2018-02-08 10:39:16,861 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204
2018-02-08 10:39:17,119 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228
2018-02-08 10:39:17,384 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751
2018-02-08 10:39:17,647 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178
2018-02-08 10:39:18,006 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059
2018-02-08 10:39:18,270 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651
2018-02-08 10:39:18,539 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126
2018-02-08 10:39:18,808 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984
2018-02-08 10:39:19,077 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388
2018-02-08 10:39:19,347 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202
2018-02-08 10:39:19,507 __main__ [INFO ] End of training
2018-02-08 10:45:30,177 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 10:45:30,179 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 10:45:30,185 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 10:45:30,186 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 10:45:33,326 training [INFO ] Epoch  1 Batch   50 Training err. 4.06668 Training err. RA 4.06668 Valid. err. 3.55792
2018-02-08 10:45:33,671 training [INFO ] Epoch  1 Batch  100 Training err. 3.41115 Training err. RA 3.73892 Valid. err. 3.30138
2018-02-08 10:45:34,012 training [INFO ] Epoch  1 Batch  150 Training err. 3.27883 Training err. RA 3.58555 Valid. err. 3.28216
2018-02-08 10:45:34,351 training [INFO ] Epoch  1 Batch  200 Training err. 3.26455 Training err. RA 3.50530 Valid. err. 3.25345
2018-02-08 10:45:34,696 training [INFO ] Epoch  1 Batch  250 Training err. 3.21888 Training err. RA 3.44802 Valid. err. 3.25736
2018-02-08 10:45:35,066 training [INFO ] Epoch  1 Batch  300 Training err. 3.26888 Training err. RA 3.41816 Valid. err. 3.22067
2018-02-08 10:45:35,525 training [INFO ] Epoch  2 Batch  350 Training err. 3.22470 Training err. RA 3.39052 Valid. err. 3.23481
2018-02-08 10:45:35,857 training [INFO ] Epoch  2 Batch  400 Training err. 3.22565 Training err. RA 3.36991 Valid. err. 3.24099
2018-02-08 10:45:36,202 training [INFO ] Epoch  2 Batch  450 Training err. 3.21484 Training err. RA 3.35268 Valid. err. 3.20923
2018-02-08 10:45:36,538 training [INFO ] Epoch  2 Batch  500 Training err. 3.20565 Training err. RA 3.33798 Valid. err. 3.21675
2018-02-08 10:45:36,867 training [INFO ] Epoch  2 Batch  550 Training err. 3.18810 Training err. RA 3.32436 Valid. err. 3.21965
2018-02-08 10:45:37,228 training [INFO ] Epoch  2 Batch  600 Training err. 3.20945 Training err. RA 3.31478 Valid. err. 3.17253
2018-02-08 10:45:37,698 training [INFO ] Epoch  3 Batch  650 Training err. 3.18389 Training err. RA 3.30471 Valid. err. 3.17964
2018-02-08 10:45:38,037 training [INFO ] Epoch  3 Batch  700 Training err. 3.17436 Training err. RA 3.29540 Valid. err. 3.16575
2018-02-08 10:45:38,378 training [INFO ] Epoch  3 Batch  750 Training err. 3.12921 Training err. RA 3.28432 Valid. err. 3.14229
2018-02-08 10:45:38,729 training [INFO ] Epoch  3 Batch  800 Training err. 3.14096 Training err. RA 3.27536 Valid. err. 3.11644
2018-02-08 10:45:39,088 training [INFO ] Epoch  3 Batch  850 Training err. 3.08331 Training err. RA 3.26406 Valid. err. 3.15954
2018-02-08 10:45:39,433 training [INFO ] Epoch  3 Batch  900 Training err. 3.13017 Training err. RA 3.25663 Valid. err. 3.05807
2018-02-08 10:45:39,897 training [INFO ] Epoch  4 Batch  950 Training err. 3.10015 Training err. RA 3.24839 Valid. err. 3.11039
2018-02-08 10:45:40,217 training [INFO ] Epoch  4 Batch 1000 Training err. 3.03819 Training err. RA 3.23788 Valid. err. 3.02773
2018-02-08 10:45:40,541 training [INFO ] Epoch  4 Batch 1050 Training err. 2.98703 Training err. RA 3.22593 Valid. err. 3.01230
2018-02-08 10:45:40,880 training [INFO ] Epoch  4 Batch 1100 Training err. 2.98476 Training err. RA 3.21497 Valid. err. 2.94176
2018-02-08 10:45:41,201 training [INFO ] Epoch  4 Batch 1150 Training err. 2.94016 Training err. RA 3.20302 Valid. err. 2.97638
2018-02-08 10:45:41,526 training [INFO ] Epoch  4 Batch 1200 Training err. 2.93710 Training err. RA 3.19194 Valid. err. 2.87868
2018-02-08 10:45:41,996 training [INFO ] Epoch  5 Batch 1250 Training err. 2.96480 Training err. RA 3.18286 Valid. err. 2.93109
2018-02-08 10:45:42,332 training [INFO ] Epoch  5 Batch 1300 Training err. 2.89718 Training err. RA 3.17187 Valid. err. 2.84727
2018-02-08 10:45:42,670 training [INFO ] Epoch  5 Batch 1350 Training err. 2.79645 Training err. RA 3.15797 Valid. err. 2.82242
2018-02-08 10:45:42,989 training [INFO ] Epoch  5 Batch 1400 Training err. 2.81351 Training err. RA 3.14566 Valid. err. 2.80099
2018-02-08 10:45:43,325 training [INFO ] Epoch  5 Batch 1450 Training err. 2.81726 Training err. RA 3.13434 Valid. err. 2.77449
2018-02-08 10:45:43,657 training [INFO ] Epoch  5 Batch 1500 Training err. 2.77498 Training err. RA 3.12236 Valid. err. 2.74255
2018-02-08 10:45:44,104 training [INFO ] Epoch  6 Batch 1550 Training err. 2.86219 Training err. RA 3.11397 Valid. err. 2.74529
2018-02-08 10:45:44,434 training [INFO ] Epoch  6 Batch 1600 Training err. 2.79366 Training err. RA 3.10396 Valid. err. 2.78517
2018-02-08 10:45:44,767 training [INFO ] Epoch  6 Batch 1650 Training err. 2.71686 Training err. RA 3.09223 Valid. err. 2.71670
2018-02-08 10:45:45,112 training [INFO ] Epoch  6 Batch 1700 Training err. 2.68714 Training err. RA 3.08031 Valid. err. 2.71365
2018-02-08 10:45:45,451 training [INFO ] Epoch  6 Batch 1750 Training err. 2.76050 Training err. RA 3.07118 Valid. err. 2.69884
2018-02-08 10:45:45,780 training [INFO ] Epoch  6 Batch 1800 Training err. 2.66380 Training err. RA 3.05986 Valid. err. 2.67043
2018-02-08 10:45:46,234 training [INFO ] Epoch  7 Batch 1850 Training err. 2.76817 Training err. RA 3.05198 Valid. err. 2.68826
2018-02-08 10:45:46,556 training [INFO ] Epoch  7 Batch 1900 Training err. 2.74214 Training err. RA 3.04382 Valid. err. 2.64343
2018-02-08 10:45:46,884 training [INFO ] Epoch  7 Batch 1950 Training err. 2.63050 Training err. RA 3.03323 Valid. err. 2.62250
2018-02-08 10:45:47,223 training [INFO ] Epoch  7 Batch 2000 Training err. 2.60499 Training err. RA 3.02252 Valid. err. 2.61119
2018-02-08 10:45:47,548 training [INFO ] Epoch  7 Batch 2050 Training err. 2.70030 Training err. RA 3.01466 Valid. err. 2.59709
2018-02-08 10:45:47,877 training [INFO ] Epoch  7 Batch 2100 Training err. 2.57671 Training err. RA 3.00423 Valid. err. 2.57994
2018-02-08 10:45:48,333 training [INFO ] Epoch  8 Batch 2150 Training err. 2.65211 Training err. RA 2.99604 Valid. err. 2.55940
2018-02-08 10:45:48,682 training [INFO ] Epoch  8 Batch 2200 Training err. 2.71679 Training err. RA 2.98970 Valid. err. 2.56957
2018-02-08 10:45:49,032 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58311 Training err. RA 2.98066 Valid. err. 2.57319
2018-02-08 10:45:49,379 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55830 Training err. RA 2.97148 Valid. err. 2.55415
2018-02-08 10:45:49,735 training [INFO ] Epoch  8 Batch 2350 Training err. 2.61525 Training err. RA 2.96390 Valid. err. 2.55715
2018-02-08 10:45:50,073 training [INFO ] Epoch  8 Batch 2400 Training err. 2.50499 Training err. RA 2.95434 Valid. err. 2.52224
2018-02-08 10:45:50,424 training [INFO ] Epoch  8 Batch 2450 Training err. 2.59370 Training err. RA 2.94698 Valid. err. 2.53462
2018-02-08 10:45:50,897 training [INFO ] Epoch  9 Batch 2500 Training err. 2.62917 Training err. RA 2.94062 Valid. err. 2.53805
2018-02-08 10:45:51,243 training [INFO ] Epoch  9 Batch 2550 Training err. 2.58593 Training err. RA 2.93367 Valid. err. 2.51789
2018-02-08 10:45:51,581 training [INFO ] Epoch  9 Batch 2600 Training err. 2.51075 Training err. RA 2.92554 Valid. err. 2.48486
2018-02-08 10:45:51,925 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56972 Training err. RA 2.91882 Valid. err. 2.52787
2018-02-08 10:45:52,294 training [INFO ] Epoch  9 Batch 2700 Training err. 2.45539 Training err. RA 2.91024 Valid. err. 2.50995
2018-02-08 10:45:52,626 training [INFO ] Epoch  9 Batch 2750 Training err. 2.51576 Training err. RA 2.90307 Valid. err. 2.46231
2018-02-08 10:45:53,115 training [INFO ] Epoch 10 Batch 2800 Training err. 2.56235 Training err. RA 2.89698 Valid. err. 2.48668
2018-02-08 10:45:53,436 training [INFO ] Epoch 10 Batch 2850 Training err. 2.57065 Training err. RA 2.89126 Valid. err. 2.47053
2018-02-08 10:45:53,831 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46044 Training err. RA 2.88383 Valid. err. 2.44095
2018-02-08 10:45:54,178 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51979 Training err. RA 2.87766 Valid. err. 2.47407
2018-02-08 10:45:54,515 training [INFO ] Epoch 10 Batch 3000 Training err. 2.43446 Training err. RA 2.87027 Valid. err. 2.42247
2018-02-08 10:45:54,852 training [INFO ] Epoch 10 Batch 3050 Training err. 2.46029 Training err. RA 2.86355 Valid. err. 2.42836
2018-02-08 10:45:55,056 __main__ [INFO ] End of training
2018-02-08 10:45:55,463 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 10:45:55,464 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 10:45:55,845 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004
2018-02-08 10:45:56,190 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220
2018-02-08 10:45:56,612 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708
2018-02-08 10:45:57,029 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226
2018-02-08 10:45:57,496 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791
2018-02-08 10:45:57,824 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095
2018-02-08 10:45:58,179 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617
2018-02-08 10:45:58,519 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091
2018-02-08 10:45:58,962 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571
2018-02-08 10:45:59,335 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752
2018-02-08 10:45:59,644 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115
2018-02-08 10:45:59,918 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850
2018-02-08 10:46:00,299 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007
2018-02-08 10:46:00,584 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578
2018-02-08 10:46:00,868 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063
2018-02-08 10:46:01,163 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541
2018-02-08 10:46:01,515 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331
2018-02-08 10:46:01,774 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885
2018-02-08 10:46:02,026 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402
2018-02-08 10:46:02,291 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876
2018-02-08 10:46:02,638 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261
2018-02-08 10:46:02,896 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771
2018-02-08 10:46:03,163 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434
2018-02-08 10:46:03,417 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230
2018-02-08 10:46:03,763 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620
2018-02-08 10:46:04,040 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672
2018-02-08 10:46:04,380 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298
2018-02-08 10:46:04,676 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529
2018-02-08 10:46:05,070 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410
2018-02-08 10:46:05,361 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609
2018-02-08 10:46:05,645 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099
2018-02-08 10:46:06,581 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653
2018-02-08 10:46:07,008 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570
2018-02-08 10:46:07,387 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963
2018-02-08 10:46:07,751 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815
2018-02-08 10:46:08,095 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999
2018-02-08 10:46:08,566 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695
2018-02-08 10:46:08,903 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245
2018-02-08 10:46:09,237 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415
2018-02-08 10:46:09,574 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328
2018-02-08 10:46:09,931 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049
2018-02-08 10:46:10,036 __main__ [INFO ] End of training
2018-02-08 10:46:10,204 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 10:46:10,205 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 10:46:10,580 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945
2018-02-08 10:46:10,938 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585
2018-02-08 10:46:11,325 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036
2018-02-08 10:46:11,684 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844
2018-02-08 10:46:12,050 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920
2018-02-08 10:46:12,407 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863
2018-02-08 10:46:12,869 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650
2018-02-08 10:46:13,220 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923
2018-02-08 10:46:13,581 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288
2018-02-08 10:46:13,924 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297
2018-02-08 10:46:14,268 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633
2018-02-08 10:46:14,610 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329
2018-02-08 10:46:15,094 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222
2018-02-08 10:46:15,463 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798
2018-02-08 10:46:15,858 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300
2018-02-08 10:46:16,211 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864
2018-02-08 10:46:16,559 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590
2018-02-08 10:46:16,919 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607
2018-02-08 10:46:17,400 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056
2018-02-08 10:46:17,738 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954
2018-02-08 10:46:18,077 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403
2018-02-08 10:46:18,416 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444
2018-02-08 10:46:18,754 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682
2018-02-08 10:46:19,106 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167
2018-02-08 10:46:19,578 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971
2018-02-08 10:46:19,933 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051
2018-02-08 10:46:20,295 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551
2018-02-08 10:46:20,653 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389
2018-02-08 10:46:21,019 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053
2018-02-08 10:46:21,377 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556
2018-02-08 10:46:21,833 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131
2018-02-08 10:46:22,200 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897
2018-02-08 10:46:22,560 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355
2018-02-08 10:46:22,926 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367
2018-02-08 10:46:23,279 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858
2018-02-08 10:46:23,644 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398
2018-02-08 10:46:24,126 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153
2018-02-08 10:46:24,466 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232
2018-02-08 10:46:24,801 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708
2018-02-08 10:46:25,159 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540
2018-02-08 10:46:25,523 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636
2018-02-08 10:46:25,862 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333
2018-02-08 10:46:26,337 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953
2018-02-08 10:46:26,697 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544
2018-02-08 10:46:27,050 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447
2018-02-08 10:46:27,415 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667
2018-02-08 10:46:27,760 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969
2018-02-08 10:46:28,108 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715
2018-02-08 10:46:28,481 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796
2018-02-08 10:46:28,945 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617
2018-02-08 10:46:29,276 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010
2018-02-08 10:46:29,612 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204
2018-02-08 10:46:29,950 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228
2018-02-08 10:46:30,282 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751
2018-02-08 10:46:30,609 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178
2018-02-08 10:46:31,056 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059
2018-02-08 10:46:31,417 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651
2018-02-08 10:46:31,711 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126
2018-02-08 10:46:31,998 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984
2018-02-08 10:46:32,284 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388
2018-02-08 10:46:32,617 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202
2018-02-08 10:46:32,834 __main__ [INFO ] End of training
2018-02-08 11:15:00,751 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 11:15:00,753 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 11:15:00,755 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 11:15:00,756 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 11:15:03,730 training [INFO ] Epoch  1 Batch   50 Training err. 4.03237 Training err. RA 4.03237 Valid. err. 3.51677
2018-02-08 11:15:04,063 training [INFO ] Epoch  1 Batch  100 Training err. 3.40004 Training err. RA 3.71620 Valid. err. 3.30437
2018-02-08 11:15:04,309 training [INFO ] Epoch  1 Batch  150 Training err. 3.28054 Training err. RA 3.57098 Valid. err. 3.28370
2018-02-08 11:15:04,558 training [INFO ] Epoch  1 Batch  200 Training err. 3.26420 Training err. RA 3.49429 Valid. err. 3.25501
2018-02-08 11:15:04,821 training [INFO ] Epoch  1 Batch  250 Training err. 3.21952 Training err. RA 3.43933 Valid. err. 3.25689
2018-02-08 11:15:05,065 training [INFO ] Epoch  1 Batch  300 Training err. 3.26854 Training err. RA 3.41087 Valid. err. 3.22031
2018-02-08 11:15:05,450 training [INFO ] Epoch  2 Batch  350 Training err. 3.22539 Training err. RA 3.38437 Valid. err. 3.23363
2018-02-08 11:15:05,721 training [INFO ] Epoch  2 Batch  400 Training err. 3.22582 Training err. RA 3.36455 Valid. err. 3.23898
2018-02-08 11:15:05,998 training [INFO ] Epoch  2 Batch  450 Training err. 3.21269 Training err. RA 3.34768 Valid. err. 3.20638
2018-02-08 11:15:06,266 training [INFO ] Epoch  2 Batch  500 Training err. 3.20186 Training err. RA 3.33310 Valid. err. 3.21054
2018-02-08 11:15:06,549 training [INFO ] Epoch  2 Batch  550 Training err. 3.18126 Training err. RA 3.31929 Valid. err. 3.21783
2018-02-08 11:15:06,826 training [INFO ] Epoch  2 Batch  600 Training err. 3.19983 Training err. RA 3.30934 Valid. err. 3.16273
2018-02-08 11:15:07,217 training [INFO ] Epoch  3 Batch  650 Training err. 3.17166 Training err. RA 3.29875 Valid. err. 3.15526
2018-02-08 11:15:07,523 training [INFO ] Epoch  3 Batch  700 Training err. 3.15844 Training err. RA 3.28873 Valid. err. 3.14166
2018-02-08 11:15:07,815 training [INFO ] Epoch  3 Batch  750 Training err. 3.09741 Training err. RA 3.27597 Valid. err. 3.10503
2018-02-08 11:15:08,068 training [INFO ] Epoch  3 Batch  800 Training err. 3.10318 Training err. RA 3.26517 Valid. err. 3.07654
2018-02-08 11:15:08,344 training [INFO ] Epoch  3 Batch  850 Training err. 3.03298 Training err. RA 3.25151 Valid. err. 3.09208
2018-02-08 11:15:08,623 training [INFO ] Epoch  3 Batch  900 Training err. 3.07835 Training err. RA 3.24189 Valid. err. 2.99325
2018-02-08 11:15:09,000 training [INFO ] Epoch  4 Batch  950 Training err. 3.04885 Training err. RA 3.23173 Valid. err. 3.04284
2018-02-08 11:15:09,283 training [INFO ] Epoch  4 Batch 1000 Training err. 2.97611 Training err. RA 3.21895 Valid. err. 2.95719
2018-02-08 11:15:09,565 training [INFO ] Epoch  4 Batch 1050 Training err. 2.90753 Training err. RA 3.20412 Valid. err. 2.93240
2018-02-08 11:15:09,816 training [INFO ] Epoch  4 Batch 1100 Training err. 2.91332 Training err. RA 3.19090 Valid. err. 2.86848
2018-02-08 11:15:10,074 training [INFO ] Epoch  4 Batch 1150 Training err. 2.86908 Training err. RA 3.17691 Valid. err. 2.90832
2018-02-08 11:15:10,318 training [INFO ] Epoch  4 Batch 1200 Training err. 2.87524 Training err. RA 3.16434 Valid. err. 2.81803
2018-02-08 11:15:10,650 training [INFO ] Epoch  5 Batch 1250 Training err. 2.91568 Training err. RA 3.15440 Valid. err. 2.86454
2018-02-08 11:15:10,897 training [INFO ] Epoch  5 Batch 1300 Training err. 2.85693 Training err. RA 3.14295 Valid. err. 2.80994
2018-02-08 11:15:11,137 training [INFO ] Epoch  5 Batch 1350 Training err. 2.76030 Training err. RA 3.12878 Valid. err. 2.78384
2018-02-08 11:15:11,407 training [INFO ] Epoch  5 Batch 1400 Training err. 2.78142 Training err. RA 3.11638 Valid. err. 2.76415
2018-02-08 11:15:11,670 training [INFO ] Epoch  5 Batch 1450 Training err. 2.78501 Training err. RA 3.10495 Valid. err. 2.74528
2018-02-08 11:15:11,905 training [INFO ] Epoch  5 Batch 1500 Training err. 2.74703 Training err. RA 3.09302 Valid. err. 2.71568
2018-02-08 11:15:12,249 training [INFO ] Epoch  6 Batch 1550 Training err. 2.83131 Training err. RA 3.08458 Valid. err. 2.71033
2018-02-08 11:15:12,499 training [INFO ] Epoch  6 Batch 1600 Training err. 2.77162 Training err. RA 3.07480 Valid. err. 2.75705
2018-02-08 11:15:12,733 training [INFO ] Epoch  6 Batch 1650 Training err. 2.69830 Training err. RA 3.06339 Valid. err. 2.69783
2018-02-08 11:15:12,982 training [INFO ] Epoch  6 Batch 1700 Training err. 2.66642 Training err. RA 3.05171 Valid. err. 2.70588
2018-02-08 11:15:13,221 training [INFO ] Epoch  6 Batch 1750 Training err. 2.73749 Training err. RA 3.04273 Valid. err. 2.67247
2018-02-08 11:15:13,464 training [INFO ] Epoch  6 Batch 1800 Training err. 2.64458 Training err. RA 3.03167 Valid. err. 2.65228
2018-02-08 11:15:13,784 training [INFO ] Epoch  7 Batch 1850 Training err. 2.74989 Training err. RA 3.02406 Valid. err. 2.68983
2018-02-08 11:15:14,019 training [INFO ] Epoch  7 Batch 1900 Training err. 2.72616 Training err. RA 3.01622 Valid. err. 2.63557
2018-02-08 11:15:14,249 training [INFO ] Epoch  7 Batch 1950 Training err. 2.62184 Training err. RA 3.00611 Valid. err. 2.61030
2018-02-08 11:15:14,479 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59195 Training err. RA 2.99575 Valid. err. 2.59851
2018-02-08 11:15:14,709 training [INFO ] Epoch  7 Batch 2050 Training err. 2.68717 Training err. RA 2.98823 Valid. err. 2.58847
2018-02-08 11:15:14,936 training [INFO ] Epoch  7 Batch 2100 Training err. 2.56836 Training err. RA 2.97823 Valid. err. 2.56537
2018-02-08 11:15:15,255 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64567 Training err. RA 2.97050 Valid. err. 2.55346
2018-02-08 11:15:15,489 training [INFO ] Epoch  8 Batch 2200 Training err. 2.70899 Training err. RA 2.96455 Valid. err. 2.55934
2018-02-08 11:15:15,730 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58136 Training err. RA 2.95604 Valid. err. 2.55751
2018-02-08 11:15:15,971 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55100 Training err. RA 2.94723 Valid. err. 2.54699
2018-02-08 11:15:16,210 training [INFO ] Epoch  8 Batch 2350 Training err. 2.60534 Training err. RA 2.93996 Valid. err. 2.54728
2018-02-08 11:15:16,442 training [INFO ] Epoch  8 Batch 2400 Training err. 2.50453 Training err. RA 2.93089 Valid. err. 2.51330
2018-02-08 11:15:16,672 training [INFO ] Epoch  8 Batch 2450 Training err. 2.59387 Training err. RA 2.92401 Valid. err. 2.52606
2018-02-08 11:15:17,006 training [INFO ] Epoch  9 Batch 2500 Training err. 2.62815 Training err. RA 2.91809 Valid. err. 2.52547
2018-02-08 11:15:17,264 training [INFO ] Epoch  9 Batch 2550 Training err. 2.58600 Training err. RA 2.91158 Valid. err. 2.50834
2018-02-08 11:15:17,534 training [INFO ] Epoch  9 Batch 2600 Training err. 2.50795 Training err. RA 2.90382 Valid. err. 2.48491
2018-02-08 11:15:17,804 training [INFO ] Epoch  9 Batch 2650 Training err. 2.55943 Training err. RA 2.89732 Valid. err. 2.52907
2018-02-08 11:15:18,041 training [INFO ] Epoch  9 Batch 2700 Training err. 2.46296 Training err. RA 2.88928 Valid. err. 2.50968
2018-02-08 11:15:18,270 training [INFO ] Epoch  9 Batch 2750 Training err. 2.51818 Training err. RA 2.88253 Valid. err. 2.46447
2018-02-08 11:15:18,618 training [INFO ] Epoch 10 Batch 2800 Training err. 2.56850 Training err. RA 2.87692 Valid. err. 2.49907
2018-02-08 11:15:18,859 training [INFO ] Epoch 10 Batch 2850 Training err. 2.57130 Training err. RA 2.87156 Valid. err. 2.46256
2018-02-08 11:15:19,119 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46290 Training err. RA 2.86451 Valid. err. 2.44389
2018-02-08 11:15:19,351 training [INFO ] Epoch 10 Batch 2950 Training err. 2.50764 Training err. RA 2.85846 Valid. err. 2.46924
2018-02-08 11:15:19,582 training [INFO ] Epoch 10 Batch 3000 Training err. 2.44397 Training err. RA 2.85156 Valid. err. 2.42292
2018-02-08 11:15:19,813 training [INFO ] Epoch 10 Batch 3050 Training err. 2.46471 Training err. RA 2.84521 Valid. err. 2.42606
2018-02-08 11:15:19,953 __main__ [INFO ] End of training
2018-02-08 11:15:20,332 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 11:15:20,333 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 11:15:20,597 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004
2018-02-08 11:15:20,853 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220
2018-02-08 11:15:21,105 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708
2018-02-08 11:15:21,362 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226
2018-02-08 11:15:21,695 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791
2018-02-08 11:15:21,941 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095
2018-02-08 11:15:22,187 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617
2018-02-08 11:15:22,430 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091
2018-02-08 11:15:22,777 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571
2018-02-08 11:15:23,020 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752
2018-02-08 11:15:23,260 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115
2018-02-08 11:15:23,503 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850
2018-02-08 11:15:23,836 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007
2018-02-08 11:15:24,075 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578
2018-02-08 11:15:24,320 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063
2018-02-08 11:15:24,565 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541
2018-02-08 11:15:24,888 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331
2018-02-08 11:15:25,132 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885
2018-02-08 11:15:25,375 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402
2018-02-08 11:15:25,621 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876
2018-02-08 11:15:25,951 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261
2018-02-08 11:15:26,196 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771
2018-02-08 11:15:26,445 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434
2018-02-08 11:15:26,688 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230
2018-02-08 11:15:27,019 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620
2018-02-08 11:15:27,262 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672
2018-02-08 11:15:27,508 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298
2018-02-08 11:15:27,760 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529
2018-02-08 11:15:28,097 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410
2018-02-08 11:15:28,348 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609
2018-02-08 11:15:28,605 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099
2018-02-08 11:15:28,859 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653
2018-02-08 11:15:29,182 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570
2018-02-08 11:15:29,432 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963
2018-02-08 11:15:29,674 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815
2018-02-08 11:15:29,922 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999
2018-02-08 11:15:30,245 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695
2018-02-08 11:15:30,494 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245
2018-02-08 11:15:30,737 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415
2018-02-08 11:15:30,986 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328
2018-02-08 11:15:31,233 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049
2018-02-08 11:15:31,310 __main__ [INFO ] End of training
2018-02-08 11:15:31,462 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 11:15:31,463 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 11:15:31,770 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945
2018-02-08 11:15:32,028 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585
2018-02-08 11:15:32,281 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036
2018-02-08 11:15:32,534 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844
2018-02-08 11:15:32,795 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920
2018-02-08 11:15:33,056 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863
2018-02-08 11:15:33,406 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650
2018-02-08 11:15:33,674 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923
2018-02-08 11:15:33,929 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288
2018-02-08 11:15:34,184 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297
2018-02-08 11:15:34,437 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633
2018-02-08 11:15:34,693 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329
2018-02-08 11:15:35,063 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222
2018-02-08 11:15:35,322 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798
2018-02-08 11:15:35,579 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300
2018-02-08 11:15:35,831 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864
2018-02-08 11:15:36,083 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590
2018-02-08 11:15:36,337 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607
2018-02-08 11:15:36,679 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056
2018-02-08 11:15:36,941 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954
2018-02-08 11:15:37,222 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403
2018-02-08 11:15:37,481 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444
2018-02-08 11:15:37,740 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682
2018-02-08 11:15:37,998 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167
2018-02-08 11:15:38,345 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971
2018-02-08 11:15:38,609 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051
2018-02-08 11:15:38,871 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551
2018-02-08 11:15:39,134 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389
2018-02-08 11:15:39,392 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053
2018-02-08 11:15:39,647 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556
2018-02-08 11:15:39,989 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131
2018-02-08 11:15:40,253 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897
2018-02-08 11:15:40,520 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355
2018-02-08 11:15:40,785 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367
2018-02-08 11:15:41,044 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858
2018-02-08 11:15:41,303 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398
2018-02-08 11:15:41,654 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153
2018-02-08 11:15:41,916 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232
2018-02-08 11:15:42,176 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708
2018-02-08 11:15:42,441 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540
2018-02-08 11:15:42,707 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636
2018-02-08 11:15:42,973 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333
2018-02-08 11:15:43,332 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953
2018-02-08 11:15:43,596 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544
2018-02-08 11:15:43,861 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447
2018-02-08 11:15:44,124 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667
2018-02-08 11:15:44,393 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969
2018-02-08 11:15:44,656 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715
2018-02-08 11:15:44,922 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796
2018-02-08 11:15:45,283 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617
2018-02-08 11:15:45,555 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010
2018-02-08 11:15:45,830 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204
2018-02-08 11:15:46,093 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228
2018-02-08 11:15:46,356 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751
2018-02-08 11:15:46,622 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178
2018-02-08 11:15:46,985 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059
2018-02-08 11:15:47,255 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651
2018-02-08 11:15:47,530 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126
2018-02-08 11:15:47,795 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984
2018-02-08 11:15:48,055 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388
2018-02-08 11:15:48,325 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202
2018-02-08 11:15:48,482 __main__ [INFO ] End of training
2018-02-08 11:55:08,078 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 11:56:38,047 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 11:56:38,049 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 11:56:38,052 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 11:56:38,053 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 11:56:48,826 training [INFO ] Epoch  1 Batch   50 Training err. 4.06975 Training err. RA 4.06975 Valid. err. 3.61351
2018-02-08 11:56:49,173 training [INFO ] Epoch  1 Batch  100 Training err. 3.44720 Training err. RA 3.75847 Valid. err. 3.31789
2018-02-08 11:56:49,559 training [INFO ] Epoch  1 Batch  150 Training err. 3.28555 Training err. RA 3.60083 Valid. err. 3.28707
2018-02-08 11:56:50,049 training [INFO ] Epoch  1 Batch  200 Training err. 3.26490 Training err. RA 3.51685 Valid. err. 3.25771
2018-02-08 11:56:50,526 training [INFO ] Epoch  1 Batch  250 Training err. 3.21976 Training err. RA 3.45743 Valid. err. 3.25942
2018-02-08 11:56:50,880 training [INFO ] Epoch  1 Batch  300 Training err. 3.26849 Training err. RA 3.42594 Valid. err. 3.21999
2018-02-08 11:56:51,630 training [INFO ] Epoch  2 Batch  350 Training err. 3.22183 Training err. RA 3.39678 Valid. err. 3.23359
2018-02-08 11:56:52,059 training [INFO ] Epoch  2 Batch  400 Training err. 3.22251 Training err. RA 3.37500 Valid. err. 3.23774
2018-02-08 11:56:52,478 training [INFO ] Epoch  2 Batch  450 Training err. 3.20928 Training err. RA 3.35659 Valid. err. 3.20166
2018-02-08 11:56:53,489 training [INFO ] Epoch  2 Batch  500 Training err. 3.19644 Training err. RA 3.34057 Valid. err. 3.20470
2018-02-08 11:56:53,842 training [INFO ] Epoch  2 Batch  550 Training err. 3.17417 Training err. RA 3.32544 Valid. err. 3.20447
2018-02-08 11:56:54,197 training [INFO ] Epoch  2 Batch  600 Training err. 3.18909 Training err. RA 3.31408 Valid. err. 3.14804
2018-02-08 11:56:54,639 training [INFO ] Epoch  3 Batch  650 Training err. 3.15493 Training err. RA 3.30184 Valid. err. 3.13474
2018-02-08 11:56:54,922 training [INFO ] Epoch  3 Batch  700 Training err. 3.13406 Training err. RA 3.28985 Valid. err. 3.11714
2018-02-08 11:56:55,199 training [INFO ] Epoch  3 Batch  750 Training err. 3.05691 Training err. RA 3.27432 Valid. err. 3.05197
2018-02-08 11:56:55,472 training [INFO ] Epoch  3 Batch  800 Training err. 3.05268 Training err. RA 3.26047 Valid. err. 3.01781
2018-02-08 11:56:55,771 training [INFO ] Epoch  3 Batch  850 Training err. 2.96290 Training err. RA 3.24297 Valid. err. 3.04625
2018-02-08 11:56:56,061 training [INFO ] Epoch  3 Batch  900 Training err. 3.00858 Training err. RA 3.22995 Valid. err. 2.90843
2018-02-08 11:56:56,466 training [INFO ] Epoch  4 Batch  950 Training err. 2.98000 Training err. RA 3.21679 Valid. err. 2.99358
2018-02-08 11:56:56,752 training [INFO ] Epoch  4 Batch 1000 Training err. 2.90528 Training err. RA 3.20122 Valid. err. 2.89533
2018-02-08 11:56:57,057 training [INFO ] Epoch  4 Batch 1050 Training err. 2.83600 Training err. RA 3.18382 Valid. err. 2.86084
2018-02-08 11:56:57,361 training [INFO ] Epoch  4 Batch 1100 Training err. 2.86031 Training err. RA 3.16912 Valid. err. 2.81071
2018-02-08 11:56:57,631 training [INFO ] Epoch  4 Batch 1150 Training err. 2.82356 Training err. RA 3.15409 Valid. err. 2.86033
2018-02-08 11:56:57,915 training [INFO ] Epoch  4 Batch 1200 Training err. 2.82875 Training err. RA 3.14054 Valid. err. 2.77138
2018-02-08 11:56:58,384 training [INFO ] Epoch  5 Batch 1250 Training err. 2.87708 Training err. RA 3.13000 Valid. err. 2.83313
2018-02-08 11:56:58,662 training [INFO ] Epoch  5 Batch 1300 Training err. 2.82179 Training err. RA 3.11815 Valid. err. 2.76310
2018-02-08 11:56:58,947 training [INFO ] Epoch  5 Batch 1350 Training err. 2.72096 Training err. RA 3.10344 Valid. err. 2.74273
2018-02-08 11:56:59,240 training [INFO ] Epoch  5 Batch 1400 Training err. 2.74647 Training err. RA 3.09069 Valid. err. 2.73551
2018-02-08 11:56:59,565 training [INFO ] Epoch  5 Batch 1450 Training err. 2.75755 Training err. RA 3.07920 Valid. err. 2.70681
2018-02-08 11:56:59,912 training [INFO ] Epoch  5 Batch 1500 Training err. 2.70670 Training err. RA 3.06678 Valid. err. 2.66762
2018-02-08 11:57:00,343 training [INFO ] Epoch  6 Batch 1550 Training err. 2.79467 Training err. RA 3.05801 Valid. err. 2.66929
2018-02-08 11:57:00,622 training [INFO ] Epoch  6 Batch 1600 Training err. 2.74212 Training err. RA 3.04813 Valid. err. 2.73124
2018-02-08 11:57:00,914 training [INFO ] Epoch  6 Batch 1650 Training err. 2.65964 Training err. RA 3.03636 Valid. err. 2.65072
2018-02-08 11:57:01,205 training [INFO ] Epoch  6 Batch 1700 Training err. 2.63619 Training err. RA 3.02459 Valid. err. 2.65913
2018-02-08 11:57:01,498 training [INFO ] Epoch  6 Batch 1750 Training err. 2.71206 Training err. RA 3.01566 Valid. err. 2.63450
2018-02-08 11:57:01,787 training [INFO ] Epoch  6 Batch 1800 Training err. 2.60901 Training err. RA 3.00437 Valid. err. 2.60869
2018-02-08 11:57:02,186 training [INFO ] Epoch  7 Batch 1850 Training err. 2.71831 Training err. RA 2.99663 Valid. err. 2.67051
2018-02-08 11:57:02,478 training [INFO ] Epoch  7 Batch 1900 Training err. 2.69801 Training err. RA 2.98878 Valid. err. 2.59319
2018-02-08 11:57:02,768 training [INFO ] Epoch  7 Batch 1950 Training err. 2.59078 Training err. RA 2.97857 Valid. err. 2.57823
2018-02-08 11:57:03,047 training [INFO ] Epoch  7 Batch 2000 Training err. 2.55808 Training err. RA 2.96806 Valid. err. 2.56213
2018-02-08 11:57:03,332 training [INFO ] Epoch  7 Batch 2050 Training err. 2.66433 Training err. RA 2.96065 Valid. err. 2.54342
2018-02-08 11:57:03,671 training [INFO ] Epoch  7 Batch 2100 Training err. 2.53309 Training err. RA 2.95047 Valid. err. 2.53406
2018-02-08 11:57:04,168 training [INFO ] Epoch  8 Batch 2150 Training err. 2.61193 Training err. RA 2.94260 Valid. err. 2.51790
2018-02-08 11:57:04,492 training [INFO ] Epoch  8 Batch 2200 Training err. 2.68058 Training err. RA 2.93664 Valid. err. 2.51482
2018-02-08 11:57:04,813 training [INFO ] Epoch  8 Batch 2250 Training err. 2.55224 Training err. RA 2.92810 Valid. err. 2.52341
2018-02-08 11:57:05,114 training [INFO ] Epoch  8 Batch 2300 Training err. 2.51755 Training err. RA 2.91918 Valid. err. 2.51981
2018-02-08 11:57:05,400 training [INFO ] Epoch  8 Batch 2350 Training err. 2.58488 Training err. RA 2.91206 Valid. err. 2.52651
2018-02-08 11:57:05,678 training [INFO ] Epoch  8 Batch 2400 Training err. 2.47348 Training err. RA 2.90293 Valid. err. 2.48759
2018-02-08 11:57:05,945 training [INFO ] Epoch  8 Batch 2450 Training err. 2.55825 Training err. RA 2.89589 Valid. err. 2.48784
2018-02-08 11:57:06,320 training [INFO ] Epoch  9 Batch 2500 Training err. 2.59995 Training err. RA 2.88997 Valid. err. 2.51260
2018-02-08 11:57:06,610 training [INFO ] Epoch  9 Batch 2550 Training err. 2.56281 Training err. RA 2.88356 Valid. err. 2.48050
2018-02-08 11:57:06,902 training [INFO ] Epoch  9 Batch 2600 Training err. 2.47299 Training err. RA 2.87566 Valid. err. 2.46275
2018-02-08 11:57:07,184 training [INFO ] Epoch  9 Batch 2650 Training err. 2.54598 Training err. RA 2.86944 Valid. err. 2.49199
2018-02-08 11:57:07,489 training [INFO ] Epoch  9 Batch 2700 Training err. 2.43325 Training err. RA 2.86136 Valid. err. 2.48536
2018-02-08 11:57:07,816 training [INFO ] Epoch  9 Batch 2750 Training err. 2.48855 Training err. RA 2.85459 Valid. err. 2.43896
2018-02-08 11:57:08,366 training [INFO ] Epoch 10 Batch 2800 Training err. 2.54281 Training err. RA 2.84902 Valid. err. 2.46938
2018-02-08 11:57:08,661 training [INFO ] Epoch 10 Batch 2850 Training err. 2.55226 Training err. RA 2.84381 Valid. err. 2.45567
2018-02-08 11:57:08,948 training [INFO ] Epoch 10 Batch 2900 Training err. 2.43248 Training err. RA 2.83672 Valid. err. 2.42943
2018-02-08 11:57:09,274 training [INFO ] Epoch 10 Batch 2950 Training err. 2.49758 Training err. RA 2.83097 Valid. err. 2.46843
2018-02-08 11:57:09,585 training [INFO ] Epoch 10 Batch 3000 Training err. 2.42302 Training err. RA 2.82417 Valid. err. 2.40551
2018-02-08 11:57:09,971 training [INFO ] Epoch 10 Batch 3050 Training err. 2.44285 Training err. RA 2.81792 Valid. err. 2.41645
2018-02-08 11:57:10,182 __main__ [INFO ] End of training
2018-02-08 11:57:14,621 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 11:57:14,621 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 11:57:15,087 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004
2018-02-08 11:57:15,380 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220
2018-02-08 11:57:15,679 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708
2018-02-08 11:57:15,978 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226
2018-02-08 11:57:16,365 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791
2018-02-08 11:57:16,650 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095
2018-02-08 11:57:17,303 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617
2018-02-08 11:57:17,606 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091
2018-02-08 11:57:17,998 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571
2018-02-08 11:57:18,297 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752
2018-02-08 11:57:18,601 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115
2018-02-08 11:57:18,936 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850
2018-02-08 11:57:19,555 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007
2018-02-08 11:57:19,938 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578
2018-02-08 11:57:20,281 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063
2018-02-08 11:57:20,654 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541
2018-02-08 11:57:21,061 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331
2018-02-08 11:57:21,362 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885
2018-02-08 11:57:21,692 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402
2018-02-08 11:57:22,025 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876
2018-02-08 11:57:22,415 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261
2018-02-08 11:57:22,716 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771
2018-02-08 11:57:23,013 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434
2018-02-08 11:57:23,309 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230
2018-02-08 11:57:23,737 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620
2018-02-08 11:57:24,044 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672
2018-02-08 11:57:24,388 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298
2018-02-08 11:57:24,701 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529
2018-02-08 11:57:25,164 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410
2018-02-08 11:57:25,471 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609
2018-02-08 11:57:25,775 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099
2018-02-08 11:57:26,071 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653
2018-02-08 11:57:26,470 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570
2018-02-08 11:57:26,787 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963
2018-02-08 11:57:27,089 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815
2018-02-08 11:57:27,388 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999
2018-02-08 11:57:27,805 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695
2018-02-08 11:57:28,128 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245
2018-02-08 11:57:28,485 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415
2018-02-08 11:57:28,814 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328
2018-02-08 11:57:29,114 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049
2018-02-08 11:57:29,811 __main__ [INFO ] End of training
2018-02-08 11:57:29,968 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 11:57:30,007 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 11:57:30,333 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945
2018-02-08 11:57:30,631 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585
2018-02-08 11:57:30,942 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036
2018-02-08 11:57:31,241 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844
2018-02-08 11:57:31,541 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920
2018-02-08 11:57:31,832 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863
2018-02-08 11:57:32,247 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650
2018-02-08 11:57:32,544 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923
2018-02-08 11:57:32,859 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288
2018-02-08 11:57:33,171 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297
2018-02-08 11:57:33,474 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633
2018-02-08 11:57:33,786 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329
2018-02-08 11:57:34,198 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222
2018-02-08 11:57:34,506 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798
2018-02-08 11:57:34,810 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300
2018-02-08 11:57:35,117 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864
2018-02-08 11:57:35,424 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590
2018-02-08 11:57:35,725 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607
2018-02-08 11:57:36,137 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056
2018-02-08 11:57:36,449 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954
2018-02-08 11:57:36,751 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403
2018-02-08 11:57:37,061 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444
2018-02-08 11:57:37,358 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682
2018-02-08 11:57:37,657 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167
2018-02-08 11:57:38,061 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971
2018-02-08 11:57:38,363 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051
2018-02-08 11:57:38,668 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551
2018-02-08 11:57:38,977 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389
2018-02-08 11:57:39,323 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053
2018-02-08 11:57:39,634 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556
2018-02-08 11:57:40,084 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131
2018-02-08 11:57:40,405 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897
2018-02-08 11:57:40,701 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355
2018-02-08 11:57:41,012 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367
2018-02-08 11:57:41,314 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858
2018-02-08 11:57:41,621 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398
2018-02-08 11:57:42,045 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153
2018-02-08 11:57:42,347 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232
2018-02-08 11:57:42,645 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708
2018-02-08 11:57:42,959 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540
2018-02-08 11:57:43,267 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636
2018-02-08 11:57:43,568 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333
2018-02-08 11:57:44,005 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953
2018-02-08 11:57:44,306 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544
2018-02-08 11:57:44,603 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447
2018-02-08 11:57:44,906 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667
2018-02-08 11:57:45,215 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969
2018-02-08 11:57:45,516 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715
2018-02-08 11:57:45,824 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796
2018-02-08 11:57:46,234 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617
2018-02-08 11:57:46,530 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010
2018-02-08 11:57:46,838 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204
2018-02-08 11:57:47,151 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228
2018-02-08 11:57:47,460 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751
2018-02-08 11:57:47,761 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178
2018-02-08 11:57:48,167 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059
2018-02-08 11:57:48,464 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651
2018-02-08 11:57:48,765 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126
2018-02-08 11:57:49,069 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984
2018-02-08 11:57:49,369 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388
2018-02-08 11:57:49,666 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202
2018-02-08 11:57:49,846 __main__ [INFO ] End of training
2018-02-08 11:59:40,529 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 11:59:40,532 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 11:59:40,535 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 11:59:40,535 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 11:59:55,217 training [INFO ] Epoch  1 Batch   50 Training err. 4.03550 Training err. RA 4.03550 Valid. err. 3.52520
2018-02-08 11:59:55,556 training [INFO ] Epoch  1 Batch  100 Training err. 3.40336 Training err. RA 3.71943 Valid. err. 3.29721
2018-02-08 11:59:55,873 training [INFO ] Epoch  1 Batch  150 Training err. 3.27746 Training err. RA 3.57211 Valid. err. 3.28284
2018-02-08 11:59:56,187 training [INFO ] Epoch  1 Batch  200 Training err. 3.26289 Training err. RA 3.49480 Valid. err. 3.25168
2018-02-08 11:59:56,489 training [INFO ] Epoch  1 Batch  250 Training err. 3.21705 Training err. RA 3.43925 Valid. err. 3.25452
2018-02-08 11:59:56,797 training [INFO ] Epoch  1 Batch  300 Training err. 3.26619 Training err. RA 3.41041 Valid. err. 3.21593
2018-02-08 11:59:57,295 training [INFO ] Epoch  2 Batch  350 Training err. 3.22181 Training err. RA 3.38346 Valid. err. 3.22865
2018-02-08 11:59:57,590 training [INFO ] Epoch  2 Batch  400 Training err. 3.21903 Training err. RA 3.36291 Valid. err. 3.23372
2018-02-08 11:59:57,898 training [INFO ] Epoch  2 Batch  450 Training err. 3.20238 Training err. RA 3.34507 Valid. err. 3.19036
2018-02-08 11:59:58,199 training [INFO ] Epoch  2 Batch  500 Training err. 3.18770 Training err. RA 3.32934 Valid. err. 3.19004
2018-02-08 11:59:58,508 training [INFO ] Epoch  2 Batch  550 Training err. 3.15817 Training err. RA 3.31378 Valid. err. 3.21749
2018-02-08 11:59:58,885 training [INFO ] Epoch  2 Batch  600 Training err. 3.17375 Training err. RA 3.30211 Valid. err. 3.12878
2018-02-08 11:59:59,408 training [INFO ] Epoch  3 Batch  650 Training err. 3.14188 Training err. RA 3.28978 Valid. err. 3.10658
2018-02-08 11:59:59,739 training [INFO ] Epoch  3 Batch  700 Training err. 3.11743 Training err. RA 3.27747 Valid. err. 3.10029
2018-02-08 12:00:00,042 training [INFO ] Epoch  3 Batch  750 Training err. 3.04440 Training err. RA 3.26193 Valid. err. 3.05524
2018-02-08 12:00:00,368 training [INFO ] Epoch  3 Batch  800 Training err. 3.06351 Training err. RA 3.24953 Valid. err. 3.03555
2018-02-08 12:00:00,805 training [INFO ] Epoch  3 Batch  850 Training err. 2.99505 Training err. RA 3.23456 Valid. err. 3.05128
2018-02-08 12:00:01,107 training [INFO ] Epoch  3 Batch  900 Training err. 3.04269 Training err. RA 3.22390 Valid. err. 2.95658
2018-02-08 12:00:01,539 training [INFO ] Epoch  4 Batch  950 Training err. 3.01975 Training err. RA 3.21316 Valid. err. 3.03602
2018-02-08 12:00:01,851 training [INFO ] Epoch  4 Batch 1000 Training err. 2.94948 Training err. RA 3.19997 Valid. err. 2.92854
2018-02-08 12:00:02,132 training [INFO ] Epoch  4 Batch 1050 Training err. 2.87775 Training err. RA 3.18463 Valid. err. 2.90878
2018-02-08 12:00:02,420 training [INFO ] Epoch  4 Batch 1100 Training err. 2.89010 Training err. RA 3.17124 Valid. err. 2.84363
2018-02-08 12:00:02,700 training [INFO ] Epoch  4 Batch 1150 Training err. 2.85166 Training err. RA 3.15735 Valid. err. 2.86954
2018-02-08 12:00:02,969 training [INFO ] Epoch  4 Batch 1200 Training err. 2.84987 Training err. RA 3.14454 Valid. err. 2.79682
2018-02-08 12:00:03,346 training [INFO ] Epoch  5 Batch 1250 Training err. 2.89453 Training err. RA 3.13454 Valid. err. 2.84942
2018-02-08 12:00:03,628 training [INFO ] Epoch  5 Batch 1300 Training err. 2.83943 Training err. RA 3.12319 Valid. err. 2.78326
2018-02-08 12:00:03,904 training [INFO ] Epoch  5 Batch 1350 Training err. 2.74118 Training err. RA 3.10904 Valid. err. 2.76639
2018-02-08 12:00:04,205 training [INFO ] Epoch  5 Batch 1400 Training err. 2.76430 Training err. RA 3.09673 Valid. err. 2.74862
2018-02-08 12:00:04,531 training [INFO ] Epoch  5 Batch 1450 Training err. 2.77429 Training err. RA 3.08561 Valid. err. 2.73191
2018-02-08 12:00:04,819 training [INFO ] Epoch  5 Batch 1500 Training err. 2.72666 Training err. RA 3.07364 Valid. err. 2.69255
2018-02-08 12:00:05,252 training [INFO ] Epoch  6 Batch 1550 Training err. 2.81373 Training err. RA 3.06526 Valid. err. 2.68811
2018-02-08 12:00:05,551 training [INFO ] Epoch  6 Batch 1600 Training err. 2.76059 Training err. RA 3.05574 Valid. err. 2.74238
2018-02-08 12:00:05,866 training [INFO ] Epoch  6 Batch 1650 Training err. 2.68162 Training err. RA 3.04440 Valid. err. 2.68698
2018-02-08 12:00:06,203 training [INFO ] Epoch  6 Batch 1700 Training err. 2.65900 Training err. RA 3.03307 Valid. err. 2.66621
2018-02-08 12:00:06,508 training [INFO ] Epoch  6 Batch 1750 Training err. 2.73007 Training err. RA 3.02441 Valid. err. 2.65674
2018-02-08 12:00:06,785 training [INFO ] Epoch  6 Batch 1800 Training err. 2.63697 Training err. RA 3.01365 Valid. err. 2.63737
2018-02-08 12:00:07,194 training [INFO ] Epoch  7 Batch 1850 Training err. 2.74434 Training err. RA 3.00637 Valid. err. 2.65093
2018-02-08 12:00:07,475 training [INFO ] Epoch  7 Batch 1900 Training err. 2.72232 Training err. RA 2.99889 Valid. err. 2.62772
2018-02-08 12:00:07,753 training [INFO ] Epoch  7 Batch 1950 Training err. 2.61778 Training err. RA 2.98912 Valid. err. 2.60618
2018-02-08 12:00:08,033 training [INFO ] Epoch  7 Batch 2000 Training err. 2.58939 Training err. RA 2.97913 Valid. err. 2.59892
2018-02-08 12:00:08,406 training [INFO ] Epoch  7 Batch 2050 Training err. 2.68740 Training err. RA 2.97201 Valid. err. 2.58839
2018-02-08 12:00:08,693 training [INFO ] Epoch  7 Batch 2100 Training err. 2.57428 Training err. RA 2.96254 Valid. err. 2.56559
2018-02-08 12:00:09,087 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64440 Training err. RA 2.95514 Valid. err. 2.55549
2018-02-08 12:00:09,369 training [INFO ] Epoch  8 Batch 2200 Training err. 2.71141 Training err. RA 2.94960 Valid. err. 2.56986
2018-02-08 12:00:09,640 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58400 Training err. RA 2.94148 Valid. err. 2.56352
2018-02-08 12:00:09,917 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55077 Training err. RA 2.93299 Valid. err. 2.54610
2018-02-08 12:00:10,195 training [INFO ] Epoch  8 Batch 2350 Training err. 2.61223 Training err. RA 2.92616 Valid. err. 2.55609
2018-02-08 12:00:10,468 training [INFO ] Epoch  8 Batch 2400 Training err. 2.51765 Training err. RA 2.91765 Valid. err. 2.52052
2018-02-08 12:00:10,781 training [INFO ] Epoch  8 Batch 2450 Training err. 2.59264 Training err. RA 2.91102 Valid. err. 2.53084
2018-02-08 12:00:11,220 training [INFO ] Epoch  9 Batch 2500 Training err. 2.63394 Training err. RA 2.90548 Valid. err. 2.54123
2018-02-08 12:00:11,540 training [INFO ] Epoch  9 Batch 2550 Training err. 2.59505 Training err. RA 2.89939 Valid. err. 2.51235
2018-02-08 12:00:11,855 training [INFO ] Epoch  9 Batch 2600 Training err. 2.50727 Training err. RA 2.89185 Valid. err. 2.49189
2018-02-08 12:00:12,156 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56845 Training err. RA 2.88575 Valid. err. 2.54443
2018-02-08 12:00:12,436 training [INFO ] Epoch  9 Batch 2700 Training err. 2.47693 Training err. RA 2.87818 Valid. err. 2.51705
2018-02-08 12:00:12,722 training [INFO ] Epoch  9 Batch 2750 Training err. 2.52226 Training err. RA 2.87170 Valid. err. 2.47706
2018-02-08 12:00:13,116 training [INFO ] Epoch 10 Batch 2800 Training err. 2.57282 Training err. RA 2.86637 Valid. err. 2.51401
2018-02-08 12:00:13,399 training [INFO ] Epoch 10 Batch 2850 Training err. 2.58164 Training err. RA 2.86137 Valid. err. 2.47445
2018-02-08 12:00:13,671 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46524 Training err. RA 2.85454 Valid. err. 2.45122
2018-02-08 12:00:13,961 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51665 Training err. RA 2.84882 Valid. err. 2.49750
2018-02-08 12:00:14,239 training [INFO ] Epoch 10 Batch 3000 Training err. 2.45418 Training err. RA 2.84224 Valid. err. 2.43532
2018-02-08 12:00:14,518 training [INFO ] Epoch 10 Batch 3050 Training err. 2.47080 Training err. RA 2.83615 Valid. err. 2.43788
2018-02-08 12:00:14,687 __main__ [INFO ] End of training
2018-02-08 12:00:15,679 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:00:15,707 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:00:16,047 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004
2018-02-08 12:00:16,351 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220
2018-02-08 12:00:16,638 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708
2018-02-08 12:00:16,944 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226
2018-02-08 12:00:17,399 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791
2018-02-08 12:00:17,707 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095
2018-02-08 12:00:18,005 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617
2018-02-08 12:00:18,298 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091
2018-02-08 12:00:18,692 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571
2018-02-08 12:00:18,982 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752
2018-02-08 12:00:19,278 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115
2018-02-08 12:00:19,596 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850
2018-02-08 12:00:19,999 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007
2018-02-08 12:00:20,341 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578
2018-02-08 12:00:20,640 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063
2018-02-08 12:00:20,978 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541
2018-02-08 12:00:21,458 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331
2018-02-08 12:00:21,791 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885
2018-02-08 12:00:22,116 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402
2018-02-08 12:00:22,422 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876
2018-02-08 12:00:22,823 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261
2018-02-08 12:00:23,122 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771
2018-02-08 12:00:23,424 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434
2018-02-08 12:00:23,730 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230
2018-02-08 12:00:24,153 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620
2018-02-08 12:00:24,439 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672
2018-02-08 12:00:24,724 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298
2018-02-08 12:00:25,026 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529
2018-02-08 12:00:25,407 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410
2018-02-08 12:00:25,719 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609
2018-02-08 12:00:26,036 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099
2018-02-08 12:00:26,338 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653
2018-02-08 12:00:26,727 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570
2018-02-08 12:00:27,027 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963
2018-02-08 12:00:27,340 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815
2018-02-08 12:00:27,622 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999
2018-02-08 12:00:28,095 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695
2018-02-08 12:00:28,488 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245
2018-02-08 12:00:28,844 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415
2018-02-08 12:00:29,275 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328
2018-02-08 12:00:29,626 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049
2018-02-08 12:00:29,755 __main__ [INFO ] End of training
2018-02-08 12:00:29,917 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:00:30,341 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:00:30,785 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945
2018-02-08 12:00:31,154 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585
2018-02-08 12:00:31,554 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036
2018-02-08 12:00:31,950 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844
2018-02-08 12:00:32,306 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920
2018-02-08 12:00:32,636 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863
2018-02-08 12:00:33,059 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650
2018-02-08 12:00:33,362 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923
2018-02-08 12:00:33,658 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288
2018-02-08 12:00:33,960 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297
2018-02-08 12:00:34,272 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633
2018-02-08 12:00:34,591 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329
2018-02-08 12:00:35,012 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222
2018-02-08 12:00:35,333 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798
2018-02-08 12:00:35,676 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300
2018-02-08 12:00:36,063 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864
2018-02-08 12:00:36,428 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590
2018-02-08 12:00:36,762 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607
2018-02-08 12:00:37,203 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056
2018-02-08 12:00:37,521 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954
2018-02-08 12:00:37,877 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403
2018-02-08 12:00:38,199 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444
2018-02-08 12:00:38,506 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682
2018-02-08 12:00:38,803 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167
2018-02-08 12:00:39,310 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971
2018-02-08 12:00:39,641 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051
2018-02-08 12:00:39,975 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551
2018-02-08 12:00:40,304 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389
2018-02-08 12:00:40,625 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053
2018-02-08 12:00:41,041 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556
2018-02-08 12:00:41,478 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131
2018-02-08 12:00:41,778 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897
2018-02-08 12:00:42,097 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355
2018-02-08 12:00:42,400 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367
2018-02-08 12:00:42,700 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858
2018-02-08 12:00:43,005 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398
2018-02-08 12:00:43,448 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153
2018-02-08 12:00:43,805 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232
2018-02-08 12:00:44,178 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708
2018-02-08 12:00:44,519 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540
2018-02-08 12:00:44,845 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636
2018-02-08 12:00:45,157 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333
2018-02-08 12:00:45,882 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953
2018-02-08 12:00:46,203 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544
2018-02-08 12:00:46,511 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447
2018-02-08 12:00:46,823 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667
2018-02-08 12:00:47,140 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969
2018-02-08 12:00:47,449 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715
2018-02-08 12:00:47,767 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796
2018-02-08 12:00:48,186 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617
2018-02-08 12:00:48,502 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010
2018-02-08 12:00:48,818 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204
2018-02-08 12:00:49,132 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228
2018-02-08 12:00:49,451 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751
2018-02-08 12:00:49,773 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178
2018-02-08 12:00:50,192 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059
2018-02-08 12:00:50,492 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651
2018-02-08 12:00:50,799 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126
2018-02-08 12:00:51,103 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984
2018-02-08 12:00:51,416 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388
2018-02-08 12:00:51,752 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202
2018-02-08 12:00:51,943 __main__ [INFO ] End of training
2018-02-08 12:04:05,098 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 12:04:05,100 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 12:04:05,103 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:04:05,122 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:04:05,122 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 138, in <module>
    model = get_rnn_for_hyperparams(hyperparams, alphabet.get_size(), args.use_gpu)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 84, in get_rnn_for_hyperparams
    model = RNN_LM(hyperparams.hidden_size, alphabet_size(), hyperparams.batch_size,
TypeError: 'int' object is not callable
2018-02-08 12:04:05,122 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:04:05,123 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:04:05,123 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 138, in <module>
    model = get_rnn_for_hyperparams(hyperparams, alphabet.get_size(), args.use_gpu)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 84, in get_rnn_for_hyperparams
    model = RNN_LM(hyperparams.hidden_size, alphabet_size(), hyperparams.batch_size,
TypeError: 'int' object is not callable
2018-02-08 12:04:05,123 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:04:05,124 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:04:05,124 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 138, in <module>
    model = get_rnn_for_hyperparams(hyperparams, alphabet.get_size(), args.use_gpu)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/models/rnn.py", line 84, in get_rnn_for_hyperparams
    model = RNN_LM(hyperparams.hidden_size, alphabet_size(), hyperparams.batch_size,
TypeError: 'int' object is not callable
2018-02-08 12:04:17,295 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 12:04:17,297 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 12:04:17,298 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:04:17,299 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:04:20,134 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 147, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model.parameters(), **optimizer_spec['kwargs'])
AttributeError: 'NoneType' object has no attribute 'parameters'
2018-02-08 12:04:20,135 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:04:20,136 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:04:20,136 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 147, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model.parameters(), **optimizer_spec['kwargs'])
AttributeError: 'NoneType' object has no attribute 'parameters'
2018-02-08 12:04:20,137 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:04:20,137 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:04:20,138 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 147, in <module>
    optimizer = get_optimizer(optimizer_spec, model)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/torchutils.py", line 19, in get_optimizer
    return optim.SGD(model.parameters(), **optimizer_spec['kwargs'])
AttributeError: 'NoneType' object has no attribute 'parameters'
2018-02-08 12:04:53,042 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 12:04:53,044 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 12:04:53,045 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:04:53,062 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:04:57,358 training [INFO ] Epoch  1 Batch   50 Training err. 4.05579 Training err. RA 4.05579 Valid. err. 3.57039
2018-02-08 12:04:57,613 training [INFO ] Epoch  1 Batch  100 Training err. 3.42016 Training err. RA 3.73798 Valid. err. 3.31473
2018-02-08 12:04:57,879 training [INFO ] Epoch  1 Batch  150 Training err. 3.28365 Training err. RA 3.58653 Valid. err. 3.28640
2018-02-08 12:04:58,131 training [INFO ] Epoch  1 Batch  200 Training err. 3.26513 Training err. RA 3.50618 Valid. err. 3.25506
2018-02-08 12:04:58,377 training [INFO ] Epoch  1 Batch  250 Training err. 3.21895 Training err. RA 3.44874 Valid. err. 3.25720
2018-02-08 12:04:58,619 training [INFO ] Epoch  1 Batch  300 Training err. 3.26694 Training err. RA 3.41844 Valid. err. 3.21984
2018-02-08 12:04:58,993 training [INFO ] Epoch  2 Batch  350 Training err. 3.22258 Training err. RA 3.39046 Valid. err. 3.23348
2018-02-08 12:04:59,244 training [INFO ] Epoch  2 Batch  400 Training err. 3.22301 Training err. RA 3.36953 Valid. err. 3.23662
2018-02-08 12:04:59,491 training [INFO ] Epoch  2 Batch  450 Training err. 3.21027 Training err. RA 3.35183 Valid. err. 3.20394
2018-02-08 12:04:59,738 training [INFO ] Epoch  2 Batch  500 Training err. 3.19947 Training err. RA 3.33660 Valid. err. 3.20758
2018-02-08 12:04:59,989 training [INFO ] Epoch  2 Batch  550 Training err. 3.18029 Training err. RA 3.32239 Valid. err. 3.21608
2018-02-08 12:05:00,249 training [INFO ] Epoch  2 Batch  600 Training err. 3.19823 Training err. RA 3.31204 Valid. err. 3.16119
2018-02-08 12:05:00,601 training [INFO ] Epoch  3 Batch  650 Training err. 3.17177 Training err. RA 3.30125 Valid. err. 3.15793
2018-02-08 12:05:00,860 training [INFO ] Epoch  3 Batch  700 Training err. 3.16096 Training err. RA 3.29123 Valid. err. 3.14949
2018-02-08 12:05:01,113 training [INFO ] Epoch  3 Batch  750 Training err. 3.10604 Training err. RA 3.27888 Valid. err. 3.11262
2018-02-08 12:05:01,369 training [INFO ] Epoch  3 Batch  800 Training err. 3.11530 Training err. RA 3.26866 Valid. err. 3.09083
2018-02-08 12:05:01,621 training [INFO ] Epoch  3 Batch  850 Training err. 3.04756 Training err. RA 3.25565 Valid. err. 3.14004
2018-02-08 12:05:01,880 training [INFO ] Epoch  3 Batch  900 Training err. 3.08932 Training err. RA 3.24641 Valid. err. 3.00399
2018-02-08 12:05:02,237 training [INFO ] Epoch  4 Batch  950 Training err. 3.05606 Training err. RA 3.23639 Valid. err. 3.06320
2018-02-08 12:05:02,491 training [INFO ] Epoch  4 Batch 1000 Training err. 2.98239 Training err. RA 3.22369 Valid. err. 2.95747
2018-02-08 12:05:02,738 training [INFO ] Epoch  4 Batch 1050 Training err. 2.91272 Training err. RA 3.20889 Valid. err. 2.92934
2018-02-08 12:05:02,995 training [INFO ] Epoch  4 Batch 1100 Training err. 2.91318 Training err. RA 3.19545 Valid. err. 2.86264
2018-02-08 12:05:03,252 training [INFO ] Epoch  4 Batch 1150 Training err. 2.86791 Training err. RA 3.18120 Valid. err. 2.90110
2018-02-08 12:05:03,497 training [INFO ] Epoch  4 Batch 1200 Training err. 2.87168 Training err. RA 3.16831 Valid. err. 2.80797
2018-02-08 12:05:03,845 training [INFO ] Epoch  5 Batch 1250 Training err. 2.90834 Training err. RA 3.15791 Valid. err. 2.87654
2018-02-08 12:05:04,105 training [INFO ] Epoch  5 Batch 1300 Training err. 2.84751 Training err. RA 3.14597 Valid. err. 2.80237
2018-02-08 12:05:04,368 training [INFO ] Epoch  5 Batch 1350 Training err. 2.75013 Training err. RA 3.13131 Valid. err. 2.76429
2018-02-08 12:05:04,644 training [INFO ] Epoch  5 Batch 1400 Training err. 2.77110 Training err. RA 3.11845 Valid. err. 2.74408
2018-02-08 12:05:04,914 training [INFO ] Epoch  5 Batch 1450 Training err. 2.77446 Training err. RA 3.10658 Valid. err. 2.73483
2018-02-08 12:05:05,184 training [INFO ] Epoch  5 Batch 1500 Training err. 2.73353 Training err. RA 3.09415 Valid. err. 2.69037
2018-02-08 12:05:05,551 training [INFO ] Epoch  6 Batch 1550 Training err. 2.81458 Training err. RA 3.08513 Valid. err. 2.68894
2018-02-08 12:05:05,830 training [INFO ] Epoch  6 Batch 1600 Training err. 2.75513 Training err. RA 3.07482 Valid. err. 2.72374
2018-02-08 12:05:06,076 training [INFO ] Epoch  6 Batch 1650 Training err. 2.67809 Training err. RA 3.06280 Valid. err. 2.67367
2018-02-08 12:05:06,327 training [INFO ] Epoch  6 Batch 1700 Training err. 2.65251 Training err. RA 3.05073 Valid. err. 2.65889
2018-02-08 12:05:06,579 training [INFO ] Epoch  6 Batch 1750 Training err. 2.72580 Training err. RA 3.04145 Valid. err. 2.64886
2018-02-08 12:05:06,854 training [INFO ] Epoch  6 Batch 1800 Training err. 2.63195 Training err. RA 3.03007 Valid. err. 2.62955
2018-02-08 12:05:07,228 training [INFO ] Epoch  7 Batch 1850 Training err. 2.73451 Training err. RA 3.02208 Valid. err. 2.64251
2018-02-08 12:05:07,485 training [INFO ] Epoch  7 Batch 1900 Training err. 2.71638 Training err. RA 3.01404 Valid. err. 2.60795
2018-02-08 12:05:07,748 training [INFO ] Epoch  7 Batch 1950 Training err. 2.60683 Training err. RA 3.00360 Valid. err. 2.59260
2018-02-08 12:05:08,011 training [INFO ] Epoch  7 Batch 2000 Training err. 2.57543 Training err. RA 2.99289 Valid. err. 2.57595
2018-02-08 12:05:08,280 training [INFO ] Epoch  7 Batch 2050 Training err. 2.67728 Training err. RA 2.98519 Valid. err. 2.56581
2018-02-08 12:05:08,549 training [INFO ] Epoch  7 Batch 2100 Training err. 2.55512 Training err. RA 2.97495 Valid. err. 2.54480
2018-02-08 12:05:08,949 training [INFO ] Epoch  8 Batch 2150 Training err. 2.63273 Training err. RA 2.96700 Valid. err. 2.53470
2018-02-08 12:05:09,253 training [INFO ] Epoch  8 Batch 2200 Training err. 2.70184 Training err. RA 2.96097 Valid. err. 2.53993
2018-02-08 12:05:09,522 training [INFO ] Epoch  8 Batch 2250 Training err. 2.57070 Training err. RA 2.95230 Valid. err. 2.53927
2018-02-08 12:05:09,781 training [INFO ] Epoch  8 Batch 2300 Training err. 2.53151 Training err. RA 2.94315 Valid. err. 2.52667
2018-02-08 12:05:10,054 training [INFO ] Epoch  8 Batch 2350 Training err. 2.59312 Training err. RA 2.93570 Valid. err. 2.53091
2018-02-08 12:05:10,324 training [INFO ] Epoch  8 Batch 2400 Training err. 2.48873 Training err. RA 2.92639 Valid. err. 2.49764
2018-02-08 12:05:10,613 training [INFO ] Epoch  8 Batch 2450 Training err. 2.57635 Training err. RA 2.91925 Valid. err. 2.51727
2018-02-08 12:05:11,008 training [INFO ] Epoch  9 Batch 2500 Training err. 2.62088 Training err. RA 2.91328 Valid. err. 2.53672
2018-02-08 12:05:11,303 training [INFO ] Epoch  9 Batch 2550 Training err. 2.57892 Training err. RA 2.90672 Valid. err. 2.48840
2018-02-08 12:05:11,647 training [INFO ] Epoch  9 Batch 2600 Training err. 2.48249 Training err. RA 2.89856 Valid. err. 2.46612
2018-02-08 12:05:11,945 training [INFO ] Epoch  9 Batch 2650 Training err. 2.54813 Training err. RA 2.89195 Valid. err. 2.50468
2018-02-08 12:05:12,213 training [INFO ] Epoch  9 Batch 2700 Training err. 2.44165 Training err. RA 2.88361 Valid. err. 2.49081
2018-02-08 12:05:12,476 training [INFO ] Epoch  9 Batch 2750 Training err. 2.50178 Training err. RA 2.87667 Valid. err. 2.44671
2018-02-08 12:05:12,834 training [INFO ] Epoch 10 Batch 2800 Training err. 2.55546 Training err. RA 2.87094 Valid. err. 2.47559
2018-02-08 12:05:13,102 training [INFO ] Epoch 10 Batch 2850 Training err. 2.56555 Training err. RA 2.86558 Valid. err. 2.45778
2018-02-08 12:05:13,365 training [INFO ] Epoch 10 Batch 2900 Training err. 2.43827 Training err. RA 2.85821 Valid. err. 2.42215
2018-02-08 12:05:13,650 training [INFO ] Epoch 10 Batch 2950 Training err. 2.49490 Training err. RA 2.85205 Valid. err. 2.45017
2018-02-08 12:05:13,941 training [INFO ] Epoch 10 Batch 3000 Training err. 2.42298 Training err. RA 2.84490 Valid. err. 2.40440
2018-02-08 12:05:14,224 training [INFO ] Epoch 10 Batch 3050 Training err. 2.44676 Training err. RA 2.83837 Valid. err. 2.40615
2018-02-08 12:05:14,390 __main__ [INFO ] End of training
2018-02-08 12:05:14,797 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:05:14,797 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:05:15,124 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004
2018-02-08 12:05:15,399 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220
2018-02-08 12:05:15,691 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708
2018-02-08 12:05:15,988 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226
2018-02-08 12:05:16,359 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791
2018-02-08 12:05:16,644 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095
2018-02-08 12:05:16,960 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617
2018-02-08 12:05:17,235 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091
2018-02-08 12:05:17,604 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571
2018-02-08 12:05:17,887 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752
2018-02-08 12:05:18,173 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115
2018-02-08 12:05:18,463 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850
2018-02-08 12:05:18,869 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007
2018-02-08 12:05:19,157 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578
2018-02-08 12:05:19,446 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063
2018-02-08 12:05:19,724 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541
2018-02-08 12:05:20,096 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331
2018-02-08 12:05:20,361 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885
2018-02-08 12:05:20,646 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402
2018-02-08 12:05:20,931 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876
2018-02-08 12:05:21,297 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261
2018-02-08 12:05:21,557 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771
2018-02-08 12:05:21,836 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434
2018-02-08 12:05:22,129 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230
2018-02-08 12:05:22,498 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620
2018-02-08 12:05:22,763 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672
2018-02-08 12:05:23,034 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298
2018-02-08 12:05:23,298 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529
2018-02-08 12:05:23,655 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410
2018-02-08 12:05:23,934 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609
2018-02-08 12:05:24,206 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099
2018-02-08 12:05:24,471 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653
2018-02-08 12:05:24,879 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570
2018-02-08 12:05:25,155 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963
2018-02-08 12:05:25,430 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815
2018-02-08 12:05:25,712 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999
2018-02-08 12:05:26,094 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695
2018-02-08 12:05:26,430 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245
2018-02-08 12:05:26,708 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415
2018-02-08 12:05:27,012 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328
2018-02-08 12:05:27,283 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049
2018-02-08 12:05:27,360 __main__ [INFO ] End of training
2018-02-08 12:05:27,517 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:05:27,518 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:05:27,825 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945
2018-02-08 12:05:28,109 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585
2018-02-08 12:05:28,391 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036
2018-02-08 12:05:28,676 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844
2018-02-08 12:05:28,966 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920
2018-02-08 12:05:29,252 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863
2018-02-08 12:05:29,622 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650
2018-02-08 12:05:29,925 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923
2018-02-08 12:05:30,204 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288
2018-02-08 12:05:30,477 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297
2018-02-08 12:05:30,765 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633
2018-02-08 12:05:31,043 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329
2018-02-08 12:05:31,416 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222
2018-02-08 12:05:31,689 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798
2018-02-08 12:05:31,971 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300
2018-02-08 12:05:32,239 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864
2018-02-08 12:05:32,505 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590
2018-02-08 12:05:32,810 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607
2018-02-08 12:05:33,197 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056
2018-02-08 12:05:33,477 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954
2018-02-08 12:05:33,796 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403
2018-02-08 12:05:34,092 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444
2018-02-08 12:05:34,375 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682
2018-02-08 12:05:34,646 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167
2018-02-08 12:05:35,027 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971
2018-02-08 12:05:35,302 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051
2018-02-08 12:05:35,587 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551
2018-02-08 12:05:35,875 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389
2018-02-08 12:05:36,181 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053
2018-02-08 12:05:36,461 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556
2018-02-08 12:05:36,840 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131
2018-02-08 12:05:37,127 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897
2018-02-08 12:05:37,401 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355
2018-02-08 12:05:37,688 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367
2018-02-08 12:05:37,976 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858
2018-02-08 12:05:38,259 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398
2018-02-08 12:05:38,633 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153
2018-02-08 12:05:38,913 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232
2018-02-08 12:05:39,181 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708
2018-02-08 12:05:39,459 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540
2018-02-08 12:05:39,742 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636
2018-02-08 12:05:40,035 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333
2018-02-08 12:05:40,414 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953
2018-02-08 12:05:40,686 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544
2018-02-08 12:05:40,998 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447
2018-02-08 12:05:41,280 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667
2018-02-08 12:05:41,579 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969
2018-02-08 12:05:41,861 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715
2018-02-08 12:05:42,138 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796
2018-02-08 12:05:42,511 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617
2018-02-08 12:05:42,794 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010
2018-02-08 12:05:43,090 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204
2018-02-08 12:05:43,377 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228
2018-02-08 12:05:43,697 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751
2018-02-08 12:05:43,994 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178
2018-02-08 12:05:44,378 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059
2018-02-08 12:05:44,655 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651
2018-02-08 12:05:44,944 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126
2018-02-08 12:05:45,254 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984
2018-02-08 12:05:45,536 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388
2018-02-08 12:05:45,839 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202
2018-02-08 12:05:46,054 __main__ [INFO ] End of training
2018-02-08 12:16:17,779 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 12:16:17,807 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 12:16:17,811 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:16:17,811 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:16:20,562 training [INFO ] Epoch  1 Batch   50 Training err. 4.01913 Training err. RA 4.01913 Valid. err. 3.51845
2018-02-08 12:16:20,807 training [INFO ] Epoch  1 Batch  100 Training err. 3.40303 Training err. RA 3.71108 Valid. err. 3.29889
2018-02-08 12:16:21,059 training [INFO ] Epoch  1 Batch  150 Training err. 3.27819 Training err. RA 3.56678 Valid. err. 3.28080
2018-02-08 12:16:21,316 training [INFO ] Epoch  1 Batch  200 Training err. 3.26430 Training err. RA 3.49116 Valid. err. 3.25401
2018-02-08 12:16:21,557 training [INFO ] Epoch  1 Batch  250 Training err. 3.21978 Training err. RA 3.43689 Valid. err. 3.25781
2018-02-08 12:16:21,805 training [INFO ] Epoch  1 Batch  300 Training err. 3.27002 Training err. RA 3.40908 Valid. err. 3.22101
2018-02-08 12:16:22,200 training [INFO ] Epoch  2 Batch  350 Training err. 3.22488 Training err. RA 3.38276 Valid. err. 3.23445
2018-02-08 12:16:22,447 training [INFO ] Epoch  2 Batch  400 Training err. 3.22616 Training err. RA 3.36319 Valid. err. 3.24056
2018-02-08 12:16:22,695 training [INFO ] Epoch  2 Batch  450 Training err. 3.21545 Training err. RA 3.34677 Valid. err. 3.21023
2018-02-08 12:16:22,955 training [INFO ] Epoch  2 Batch  500 Training err. 3.20664 Training err. RA 3.33276 Valid. err. 3.21754
2018-02-08 12:16:23,224 training [INFO ] Epoch  2 Batch  550 Training err. 3.18958 Training err. RA 3.31974 Valid. err. 3.22022
2018-02-08 12:16:23,475 training [INFO ] Epoch  2 Batch  600 Training err. 3.21133 Training err. RA 3.31071 Valid. err. 3.17554
2018-02-08 12:16:23,830 training [INFO ] Epoch  3 Batch  650 Training err. 3.18577 Training err. RA 3.30110 Valid. err. 3.18230
2018-02-08 12:16:24,078 training [INFO ] Epoch  3 Batch  700 Training err. 3.17727 Training err. RA 3.29225 Valid. err. 3.16487
2018-02-08 12:16:24,332 training [INFO ] Epoch  3 Batch  750 Training err. 3.13239 Training err. RA 3.28159 Valid. err. 3.14597
2018-02-08 12:16:24,592 training [INFO ] Epoch  3 Batch  800 Training err. 3.14390 Training err. RA 3.27299 Valid. err. 3.11838
2018-02-08 12:16:24,848 training [INFO ] Epoch  3 Batch  850 Training err. 3.08814 Training err. RA 3.26211 Valid. err. 3.15301
2018-02-08 12:16:25,115 training [INFO ] Epoch  3 Batch  900 Training err. 3.13595 Training err. RA 3.25511 Valid. err. 3.06391
2018-02-08 12:16:25,469 training [INFO ] Epoch  4 Batch  950 Training err. 3.10339 Training err. RA 3.24712 Valid. err. 3.11048
2018-02-08 12:16:25,712 training [INFO ] Epoch  4 Batch 1000 Training err. 3.04433 Training err. RA 3.23698 Valid. err. 3.03571
2018-02-08 12:16:25,979 training [INFO ] Epoch  4 Batch 1050 Training err. 2.99873 Training err. RA 3.22564 Valid. err. 3.02416
2018-02-08 12:16:26,253 training [INFO ] Epoch  4 Batch 1100 Training err. 2.99734 Training err. RA 3.21526 Valid. err. 2.95850
2018-02-08 12:16:26,502 training [INFO ] Epoch  4 Batch 1150 Training err. 2.95449 Training err. RA 3.20392 Valid. err. 3.00028
2018-02-08 12:16:26,752 training [INFO ] Epoch  4 Batch 1200 Training err. 2.95379 Training err. RA 3.19350 Valid. err. 2.89311
2018-02-08 12:16:27,110 training [INFO ] Epoch  5 Batch 1250 Training err. 2.97401 Training err. RA 3.18472 Valid. err. 2.95232
2018-02-08 12:16:27,364 training [INFO ] Epoch  5 Batch 1300 Training err. 2.90930 Training err. RA 3.17413 Valid. err. 2.86900
2018-02-08 12:16:27,620 training [INFO ] Epoch  5 Batch 1350 Training err. 2.80730 Training err. RA 3.16054 Valid. err. 2.82633
2018-02-08 12:16:27,882 training [INFO ] Epoch  5 Batch 1400 Training err. 2.82138 Training err. RA 3.14843 Valid. err. 2.80780
2018-02-08 12:16:28,147 training [INFO ] Epoch  5 Batch 1450 Training err. 2.82400 Training err. RA 3.13724 Valid. err. 2.79134
2018-02-08 12:16:28,402 training [INFO ] Epoch  5 Batch 1500 Training err. 2.78390 Training err. RA 3.12546 Valid. err. 2.74457
2018-02-08 12:16:28,761 training [INFO ] Epoch  6 Batch 1550 Training err. 2.86191 Training err. RA 3.11696 Valid. err. 2.74972
2018-02-08 12:16:29,012 training [INFO ] Epoch  6 Batch 1600 Training err. 2.79123 Training err. RA 3.10678 Valid. err. 2.77902
2018-02-08 12:16:29,258 training [INFO ] Epoch  6 Batch 1650 Training err. 2.71673 Training err. RA 3.09496 Valid. err. 2.71117
2018-02-08 12:16:29,508 training [INFO ] Epoch  6 Batch 1700 Training err. 2.68728 Training err. RA 3.08297 Valid. err. 2.70577
2018-02-08 12:16:29,752 training [INFO ] Epoch  6 Batch 1750 Training err. 2.75820 Training err. RA 3.07369 Valid. err. 2.69150
2018-02-08 12:16:30,021 training [INFO ] Epoch  6 Batch 1800 Training err. 2.66182 Training err. RA 3.06225 Valid. err. 2.66534
2018-02-08 12:16:30,362 training [INFO ] Epoch  7 Batch 1850 Training err. 2.75912 Training err. RA 3.05406 Valid. err. 2.68700
2018-02-08 12:16:30,626 training [INFO ] Epoch  7 Batch 1900 Training err. 2.73508 Training err. RA 3.04566 Valid. err. 2.64306
2018-02-08 12:16:30,877 training [INFO ] Epoch  7 Batch 1950 Training err. 2.62864 Training err. RA 3.03497 Valid. err. 2.61486
2018-02-08 12:16:31,136 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59968 Training err. RA 3.02409 Valid. err. 2.61122
2018-02-08 12:16:31,388 training [INFO ] Epoch  7 Batch 2050 Training err. 2.69366 Training err. RA 3.01603 Valid. err. 2.58978
2018-02-08 12:16:31,645 training [INFO ] Epoch  7 Batch 2100 Training err. 2.57132 Training err. RA 3.00544 Valid. err. 2.56567
2018-02-08 12:16:32,008 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64190 Training err. RA 2.99699 Valid. err. 2.56151
2018-02-08 12:16:32,260 training [INFO ] Epoch  8 Batch 2200 Training err. 2.70607 Training err. RA 2.99037 Valid. err. 2.55234
2018-02-08 12:16:32,511 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58192 Training err. RA 2.98130 Valid. err. 2.55834
2018-02-08 12:16:32,779 training [INFO ] Epoch  8 Batch 2300 Training err. 2.54833 Training err. RA 2.97189 Valid. err. 2.54467
2018-02-08 12:16:33,046 training [INFO ] Epoch  8 Batch 2350 Training err. 2.60529 Training err. RA 2.96409 Valid. err. 2.54686
2018-02-08 12:16:33,299 training [INFO ] Epoch  8 Batch 2400 Training err. 2.49782 Training err. RA 2.95437 Valid. err. 2.50613
2018-02-08 12:16:33,554 training [INFO ] Epoch  8 Batch 2450 Training err. 2.57952 Training err. RA 2.94672 Valid. err. 2.52034
2018-02-08 12:16:33,922 training [INFO ] Epoch  9 Batch 2500 Training err. 2.61677 Training err. RA 2.94012 Valid. err. 2.53424
2018-02-08 12:16:34,178 training [INFO ] Epoch  9 Batch 2550 Training err. 2.58045 Training err. RA 2.93307 Valid. err. 2.49565
2018-02-08 12:16:34,428 training [INFO ] Epoch  9 Batch 2600 Training err. 2.49879 Training err. RA 2.92472 Valid. err. 2.47321
2018-02-08 12:16:34,687 training [INFO ] Epoch  9 Batch 2650 Training err. 2.55510 Training err. RA 2.91775 Valid. err. 2.50765
2018-02-08 12:16:34,958 training [INFO ] Epoch  9 Batch 2700 Training err. 2.44826 Training err. RA 2.90905 Valid. err. 2.48740
2018-02-08 12:16:35,225 training [INFO ] Epoch  9 Batch 2750 Training err. 2.49983 Training err. RA 2.90161 Valid. err. 2.44625
2018-02-08 12:16:35,577 training [INFO ] Epoch 10 Batch 2800 Training err. 2.54755 Training err. RA 2.89529 Valid. err. 2.47995
2018-02-08 12:16:35,834 training [INFO ] Epoch 10 Batch 2850 Training err. 2.56029 Training err. RA 2.88941 Valid. err. 2.46500
2018-02-08 12:16:36,094 training [INFO ] Epoch 10 Batch 2900 Training err. 2.45001 Training err. RA 2.88184 Valid. err. 2.42586
2018-02-08 12:16:36,340 training [INFO ] Epoch 10 Batch 2950 Training err. 2.50308 Training err. RA 2.87542 Valid. err. 2.46219
2018-02-08 12:16:36,588 training [INFO ] Epoch 10 Batch 3000 Training err. 2.42663 Training err. RA 2.86794 Valid. err. 2.40859
2018-02-08 12:16:36,836 training [INFO ] Epoch 10 Batch 3050 Training err. 2.44431 Training err. RA 2.86099 Valid. err. 2.41658
2018-02-08 12:16:36,986 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 170, in <module>
    if best_model_valid_loss < best_valid_loss_overall or best_valid_loss_overall is None:
TypeError: '<' not supported between instances of 'float' and 'NoneType'
2018-02-08 12:16:36,987 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:16:36,987 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:16:37,290 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004
2018-02-08 12:16:37,554 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220
2018-02-08 12:16:37,817 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708
2018-02-08 12:16:38,088 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226
2018-02-08 12:16:38,447 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791
2018-02-08 12:16:38,705 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095
2018-02-08 12:16:38,991 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617
2018-02-08 12:16:39,275 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091
2018-02-08 12:16:39,632 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571
2018-02-08 12:16:39,900 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752
2018-02-08 12:16:40,165 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115
2018-02-08 12:16:40,449 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850
2018-02-08 12:16:40,794 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007
2018-02-08 12:16:41,069 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578
2018-02-08 12:16:41,339 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063
2018-02-08 12:16:41,586 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541
2018-02-08 12:16:41,948 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331
2018-02-08 12:16:42,211 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885
2018-02-08 12:16:42,491 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402
2018-02-08 12:16:42,762 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876
2018-02-08 12:16:43,129 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261
2018-02-08 12:16:43,393 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771
2018-02-08 12:16:43,669 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434
2018-02-08 12:16:43,932 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230
2018-02-08 12:16:44,319 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620
2018-02-08 12:16:44,590 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672
2018-02-08 12:16:44,855 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298
2018-02-08 12:16:45,129 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529
2018-02-08 12:16:45,541 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410
2018-02-08 12:16:45,827 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609
2018-02-08 12:16:46,112 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099
2018-02-08 12:16:46,381 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653
2018-02-08 12:16:46,742 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570
2018-02-08 12:16:47,014 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963
2018-02-08 12:16:47,291 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815
2018-02-08 12:16:47,551 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999
2018-02-08 12:16:47,945 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695
2018-02-08 12:16:48,206 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245
2018-02-08 12:16:48,486 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415
2018-02-08 12:16:48,754 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328
2018-02-08 12:16:49,040 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049
2018-02-08 12:16:49,117 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 170, in <module>
    if best_model_valid_loss < best_valid_loss_overall or best_valid_loss_overall is None:
TypeError: '<' not supported between instances of 'float' and 'NoneType'
2018-02-08 12:16:49,117 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:16:49,118 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:16:49,421 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945
2018-02-08 12:16:49,697 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585
2018-02-08 12:16:49,981 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036
2018-02-08 12:16:50,257 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844
2018-02-08 12:16:50,528 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920
2018-02-08 12:16:50,784 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863
2018-02-08 12:16:51,150 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650
2018-02-08 12:16:51,410 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923
2018-02-08 12:16:51,674 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288
2018-02-08 12:16:51,952 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297
2018-02-08 12:16:52,215 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633
2018-02-08 12:16:52,496 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329
2018-02-08 12:16:52,864 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222
2018-02-08 12:16:53,138 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798
2018-02-08 12:16:53,413 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300
2018-02-08 12:16:53,685 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864
2018-02-08 12:16:53,946 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590
2018-02-08 12:16:54,222 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607
2018-02-08 12:16:54,593 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056
2018-02-08 12:16:54,865 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954
2018-02-08 12:16:55,141 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403
2018-02-08 12:16:55,409 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444
2018-02-08 12:16:55,689 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682
2018-02-08 12:16:55,962 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167
2018-02-08 12:16:56,333 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971
2018-02-08 12:16:56,592 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051
2018-02-08 12:16:56,865 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551
2018-02-08 12:16:57,132 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389
2018-02-08 12:16:57,407 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053
2018-02-08 12:16:57,674 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556
2018-02-08 12:16:58,051 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131
2018-02-08 12:16:58,323 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897
2018-02-08 12:16:58,593 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355
2018-02-08 12:16:58,870 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367
2018-02-08 12:16:59,142 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858
2018-02-08 12:16:59,404 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398
2018-02-08 12:16:59,790 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153
2018-02-08 12:17:00,066 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232
2018-02-08 12:17:00,347 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708
2018-02-08 12:17:00,614 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540
2018-02-08 12:17:00,887 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636
2018-02-08 12:17:01,161 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333
2018-02-08 12:17:01,524 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953
2018-02-08 12:17:01,808 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544
2018-02-08 12:17:02,079 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447
2018-02-08 12:17:02,361 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667
2018-02-08 12:17:02,625 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969
2018-02-08 12:17:02,891 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715
2018-02-08 12:17:03,163 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796
2018-02-08 12:17:03,531 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617
2018-02-08 12:17:03,801 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010
2018-02-08 12:17:04,072 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204
2018-02-08 12:17:04,347 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228
2018-02-08 12:17:04,608 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751
2018-02-08 12:17:04,877 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178
2018-02-08 12:17:05,240 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059
2018-02-08 12:17:05,509 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651
2018-02-08 12:17:05,776 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126
2018-02-08 12:17:06,046 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984
2018-02-08 12:17:06,317 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388
2018-02-08 12:17:06,579 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202
2018-02-08 12:17:06,743 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 170, in <module>
    if best_model_valid_loss < best_valid_loss_overall or best_valid_loss_overall is None:
TypeError: '<' not supported between instances of 'float' and 'NoneType'
2018-02-08 12:25:55,006 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 12:25:55,009 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 12:25:55,011 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:25:55,012 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:26:11,347 training [INFO ] Epoch  1 Batch   50 Training err. 4.04377 Training err. RA 4.04377 Valid. err. 3.55707
2018-02-08 12:26:11,738 training [INFO ] Epoch  1 Batch  100 Training err. 3.42322 Training err. RA 3.73349 Valid. err. 3.30793
2018-02-08 12:26:12,004 training [INFO ] Epoch  1 Batch  150 Training err. 3.28340 Training err. RA 3.58346 Valid. err. 3.28300
2018-02-08 12:26:12,270 training [INFO ] Epoch  1 Batch  200 Training err. 3.26490 Training err. RA 3.50382 Valid. err. 3.25405
2018-02-08 12:26:12,562 training [INFO ] Epoch  1 Batch  250 Training err. 3.21908 Training err. RA 3.44687 Valid. err. 3.25577
2018-02-08 12:26:12,821 training [INFO ] Epoch  1 Batch  300 Training err. 3.26680 Training err. RA 3.41686 Valid. err. 3.21897
2018-02-08 12:26:13,434 training [INFO ] Epoch  2 Batch  350 Training err. 3.22284 Training err. RA 3.38914 Valid. err. 3.23162
2018-02-08 12:26:13,690 training [INFO ] Epoch  2 Batch  400 Training err. 3.22217 Training err. RA 3.36827 Valid. err. 3.23501
2018-02-08 12:26:13,940 training [INFO ] Epoch  2 Batch  450 Training err. 3.20902 Training err. RA 3.35058 Valid. err. 3.20017
2018-02-08 12:26:14,187 training [INFO ] Epoch  2 Batch  500 Training err. 3.19655 Training err. RA 3.33517 Valid. err. 3.20353
2018-02-08 12:26:14,432 training [INFO ] Epoch  2 Batch  550 Training err. 3.17253 Training err. RA 3.32039 Valid. err. 3.21399
2018-02-08 12:26:14,733 training [INFO ] Epoch  2 Batch  600 Training err. 3.18933 Training err. RA 3.30947 Valid. err. 3.14644
2018-02-08 12:26:15,269 training [INFO ] Epoch  3 Batch  650 Training err. 3.15896 Training err. RA 3.29789 Valid. err. 3.13698
2018-02-08 12:26:15,520 training [INFO ] Epoch  3 Batch  700 Training err. 3.14020 Training err. RA 3.28663 Valid. err. 3.12602
2018-02-08 12:26:15,804 training [INFO ] Epoch  3 Batch  750 Training err. 3.07062 Training err. RA 3.27222 Valid. err. 3.07208
2018-02-08 12:26:16,080 training [INFO ] Epoch  3 Batch  800 Training err. 3.07408 Training err. RA 3.25984 Valid. err. 3.04392
2018-02-08 12:26:16,402 training [INFO ] Epoch  3 Batch  850 Training err. 2.99218 Training err. RA 3.24410 Valid. err. 3.06433
2018-02-08 12:26:16,854 training [INFO ] Epoch  3 Batch  900 Training err. 3.03553 Training err. RA 3.23251 Valid. err. 2.94118
2018-02-08 12:26:17,678 training [INFO ] Epoch  4 Batch  950 Training err. 3.00412 Training err. RA 3.22049 Valid. err. 2.99315
2018-02-08 12:26:18,002 training [INFO ] Epoch  4 Batch 1000 Training err. 2.92670 Training err. RA 3.20580 Valid. err. 2.91232
2018-02-08 12:26:18,370 training [INFO ] Epoch  4 Batch 1050 Training err. 2.85290 Training err. RA 3.18899 Valid. err. 2.88046
2018-02-08 12:26:18,698 training [INFO ] Epoch  4 Batch 1100 Training err. 2.87451 Training err. RA 3.17470 Valid. err. 2.82319
2018-02-08 12:26:19,021 training [INFO ] Epoch  4 Batch 1150 Training err. 2.83183 Training err. RA 3.15979 Valid. err. 2.85957
2018-02-08 12:26:19,355 training [INFO ] Epoch  4 Batch 1200 Training err. 2.83881 Training err. RA 3.14642 Valid. err. 2.78416
2018-02-08 12:26:19,833 training [INFO ] Epoch  5 Batch 1250 Training err. 2.88468 Training err. RA 3.13595 Valid. err. 2.83008
2018-02-08 12:26:20,076 training [INFO ] Epoch  5 Batch 1300 Training err. 2.82797 Training err. RA 3.12410 Valid. err. 2.78413
2018-02-08 12:26:20,416 training [INFO ] Epoch  5 Batch 1350 Training err. 2.72712 Training err. RA 3.10940 Valid. err. 2.75119
2018-02-08 12:26:20,704 training [INFO ] Epoch  5 Batch 1400 Training err. 2.75900 Training err. RA 3.09689 Valid. err. 2.73818
2018-02-08 12:26:20,995 training [INFO ] Epoch  5 Batch 1450 Training err. 2.75892 Training err. RA 3.08523 Valid. err. 2.72924
2018-02-08 12:26:21,323 training [INFO ] Epoch  5 Batch 1500 Training err. 2.71796 Training err. RA 3.07299 Valid. err. 2.68316
2018-02-08 12:26:21,720 training [INFO ] Epoch  6 Batch 1550 Training err. 2.80132 Training err. RA 3.06423 Valid. err. 2.68523
2018-02-08 12:26:22,014 training [INFO ] Epoch  6 Batch 1600 Training err. 2.74692 Training err. RA 3.05431 Valid. err. 2.73371
2018-02-08 12:26:22,267 training [INFO ] Epoch  6 Batch 1650 Training err. 2.65924 Training err. RA 3.04234 Valid. err. 2.65708
2018-02-08 12:26:22,591 training [INFO ] Epoch  6 Batch 1700 Training err. 2.64589 Training err. RA 3.03068 Valid. err. 2.65429
2018-02-08 12:26:22,929 training [INFO ] Epoch  6 Batch 1750 Training err. 2.70988 Training err. RA 3.02151 Valid. err. 2.64024
2018-02-08 12:26:23,286 training [INFO ] Epoch  6 Batch 1800 Training err. 2.61491 Training err. RA 3.01022 Valid. err. 2.62607
2018-02-08 12:26:23,988 training [INFO ] Epoch  7 Batch 1850 Training err. 2.72124 Training err. RA 3.00241 Valid. err. 2.63050
2018-02-08 12:26:24,250 training [INFO ] Epoch  7 Batch 1900 Training err. 2.70619 Training err. RA 2.99461 Valid. err. 2.59781
2018-02-08 12:26:24,504 training [INFO ] Epoch  7 Batch 1950 Training err. 2.59308 Training err. RA 2.98432 Valid. err. 2.58908
2018-02-08 12:26:24,757 training [INFO ] Epoch  7 Batch 2000 Training err. 2.56966 Training err. RA 2.97395 Valid. err. 2.57413
2018-02-08 12:26:25,007 training [INFO ] Epoch  7 Batch 2050 Training err. 2.66319 Training err. RA 2.96637 Valid. err. 2.56246
2018-02-08 12:26:25,270 training [INFO ] Epoch  7 Batch 2100 Training err. 2.54012 Training err. RA 2.95622 Valid. err. 2.53885
2018-02-08 12:26:25,629 training [INFO ] Epoch  8 Batch 2150 Training err. 2.62064 Training err. RA 2.94842 Valid. err. 2.52537
2018-02-08 12:26:25,882 training [INFO ] Epoch  8 Batch 2200 Training err. 2.69426 Training err. RA 2.94264 Valid. err. 2.54071
2018-02-08 12:26:26,237 training [INFO ] Epoch  8 Batch 2250 Training err. 2.56382 Training err. RA 2.93422 Valid. err. 2.53142
2018-02-08 12:26:26,495 training [INFO ] Epoch  8 Batch 2300 Training err. 2.52840 Training err. RA 2.92540 Valid. err. 2.52334
2018-02-08 12:26:26,752 training [INFO ] Epoch  8 Batch 2350 Training err. 2.58397 Training err. RA 2.91814 Valid. err. 2.54171
2018-02-08 12:26:26,999 training [INFO ] Epoch  8 Batch 2400 Training err. 2.48269 Training err. RA 2.90906 Valid. err. 2.49464
2018-02-08 12:26:27,256 training [INFO ] Epoch  8 Batch 2450 Training err. 2.56897 Training err. RA 2.90212 Valid. err. 2.51396
2018-02-08 12:26:27,648 training [INFO ] Epoch  9 Batch 2500 Training err. 2.61813 Training err. RA 2.89644 Valid. err. 2.52475
2018-02-08 12:26:27,887 training [INFO ] Epoch  9 Batch 2550 Training err. 2.57264 Training err. RA 2.89009 Valid. err. 2.48133
2018-02-08 12:26:28,140 training [INFO ] Epoch  9 Batch 2600 Training err. 2.48634 Training err. RA 2.88233 Valid. err. 2.46903
2018-02-08 12:26:28,391 training [INFO ] Epoch  9 Batch 2650 Training err. 2.54272 Training err. RA 2.87592 Valid. err. 2.50534
2018-02-08 12:26:28,632 training [INFO ] Epoch  9 Batch 2700 Training err. 2.44009 Training err. RA 2.86785 Valid. err. 2.48289
2018-02-08 12:26:28,858 training [INFO ] Epoch  9 Batch 2750 Training err. 2.49687 Training err. RA 2.86111 Valid. err. 2.44597
2018-02-08 12:26:29,196 training [INFO ] Epoch 10 Batch 2800 Training err. 2.55555 Training err. RA 2.85565 Valid. err. 2.45768
2018-02-08 12:26:29,440 training [INFO ] Epoch 10 Batch 2850 Training err. 2.56173 Training err. RA 2.85049 Valid. err. 2.44732
2018-02-08 12:26:29,688 training [INFO ] Epoch 10 Batch 2900 Training err. 2.44253 Training err. RA 2.84346 Valid. err. 2.43034
2018-02-08 12:26:29,935 training [INFO ] Epoch 10 Batch 2950 Training err. 2.49650 Training err. RA 2.83758 Valid. err. 2.45090
2018-02-08 12:26:30,185 training [INFO ] Epoch 10 Batch 3000 Training err. 2.42008 Training err. RA 2.83062 Valid. err. 2.40275
2018-02-08 12:26:30,436 training [INFO ] Epoch 10 Batch 3050 Training err. 2.44946 Training err. RA 2.82437 Valid. err. 2.41363
2018-02-08 12:26:30,588 __main__ [INFO ] End of training
2018-02-08 12:26:33,950 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:26:33,976 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:26:34,348 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004
2018-02-08 12:26:34,611 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220
2018-02-08 12:26:34,883 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708
2018-02-08 12:26:35,151 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226
2018-02-08 12:26:35,537 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791
2018-02-08 12:26:35,810 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095
2018-02-08 12:26:36,425 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617
2018-02-08 12:26:36,686 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091
2018-02-08 12:26:37,048 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571
2018-02-08 12:26:37,317 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752
2018-02-08 12:26:37,588 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115
2018-02-08 12:26:37,853 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850
2018-02-08 12:26:38,233 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007
2018-02-08 12:26:38,484 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578
2018-02-08 12:26:38,751 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063
2018-02-08 12:26:39,018 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541
2018-02-08 12:26:39,360 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331
2018-02-08 12:26:39,620 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885
2018-02-08 12:26:39,867 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402
2018-02-08 12:26:40,132 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876
2018-02-08 12:26:40,475 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261
2018-02-08 12:26:40,733 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771
2018-02-08 12:26:41,013 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434
2018-02-08 12:26:41,274 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230
2018-02-08 12:26:41,655 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620
2018-02-08 12:26:41,919 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672
2018-02-08 12:26:42,181 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298
2018-02-08 12:26:42,446 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529
2018-02-08 12:26:42,787 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410
2018-02-08 12:26:43,060 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609
2018-02-08 12:26:43,330 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099
2018-02-08 12:26:43,592 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653
2018-02-08 12:26:43,952 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570
2018-02-08 12:26:44,220 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963
2018-02-08 12:26:44,486 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815
2018-02-08 12:26:44,754 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999
2018-02-08 12:26:45,110 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695
2018-02-08 12:26:45,378 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245
2018-02-08 12:26:45,652 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415
2018-02-08 12:26:45,921 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328
2018-02-08 12:26:46,179 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049
2018-02-08 12:26:46,264 __main__ [INFO ] End of training
2018-02-08 12:26:46,418 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 12:26:46,419 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 12:26:46,692 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945
2018-02-08 12:26:46,962 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585
2018-02-08 12:26:47,224 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036
2018-02-08 12:26:47,488 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844
2018-02-08 12:26:47,759 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920
2018-02-08 12:26:48,034 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863
2018-02-08 12:26:48,405 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650
2018-02-08 12:26:48,678 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923
2018-02-08 12:26:48,948 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288
2018-02-08 12:26:49,348 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297
2018-02-08 12:26:49,628 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633
2018-02-08 12:26:50,026 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329
2018-02-08 12:26:50,385 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222
2018-02-08 12:26:50,660 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798
2018-02-08 12:26:51,049 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300
2018-02-08 12:26:51,321 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864
2018-02-08 12:26:51,593 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590
2018-02-08 12:26:51,863 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607
2018-02-08 12:26:52,244 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056
2018-02-08 12:26:52,491 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954
2018-02-08 12:26:52,751 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403
2018-02-08 12:26:53,013 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444
2018-02-08 12:26:53,283 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682
2018-02-08 12:26:53,557 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167
2018-02-08 12:26:53,921 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971
2018-02-08 12:26:54,182 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051
2018-02-08 12:26:54,449 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551
2018-02-08 12:26:54,716 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389
2018-02-08 12:26:55,015 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053
2018-02-08 12:26:55,289 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556
2018-02-08 12:26:55,714 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131
2018-02-08 12:26:56,269 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897
2018-02-08 12:26:56,537 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355
2018-02-08 12:26:56,798 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367
2018-02-08 12:26:57,054 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858
2018-02-08 12:26:57,323 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398
2018-02-08 12:26:57,678 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153
2018-02-08 12:26:57,943 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232
2018-02-08 12:26:58,204 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708
2018-02-08 12:26:58,466 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540
2018-02-08 12:26:58,733 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636
2018-02-08 12:26:59,002 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333
2018-02-08 12:26:59,362 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953
2018-02-08 12:26:59,641 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544
2018-02-08 12:26:59,899 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447
2018-02-08 12:27:00,189 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667
2018-02-08 12:27:00,454 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969
2018-02-08 12:27:00,726 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715
2018-02-08 12:27:00,987 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796
2018-02-08 12:27:01,462 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617
2018-02-08 12:27:01,723 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010
2018-02-08 12:27:01,991 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204
2018-02-08 12:27:02,258 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228
2018-02-08 12:27:02,518 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751
2018-02-08 12:27:02,798 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178
2018-02-08 12:27:03,158 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059
2018-02-08 12:27:03,419 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651
2018-02-08 12:27:03,688 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126
2018-02-08 12:27:03,950 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984
2018-02-08 12:27:04,210 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388
2018-02-08 12:27:04,473 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202
2018-02-08 12:27:04,625 __main__ [INFO ] End of training
2018-02-08 13:28:47,811 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:28:47,831 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:28:47,834 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:28:47,835 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:29:00,160 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 170, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 131, in train_rnn
    train_log.log_record(record, logger)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 50, in log_record
    record_logger.info(record.to_string())
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 25, in to_string
    ve=self.valid_err + ' Time elapsed: {h:02d}:{m:02d}:{s:02d}'.format(h=h, m=m, s=s))
TypeError: unsupported operand type(s) for +: 'float' and 'str'
2018-02-08 13:29:00,280 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:29:00,312 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:29:00,688 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 170, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 131, in train_rnn
    train_log.log_record(record, logger)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 50, in log_record
    record_logger.info(record.to_string())
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 25, in to_string
    ve=self.valid_err + ' Time elapsed: {h:02d}:{m:02d}:{s:02d}'.format(h=h, m=m, s=s))
TypeError: unsupported operand type(s) for +: 'float' and 'str'
2018-02-08 13:29:00,689 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:29:00,709 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:29:01,046 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 170, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 131, in train_rnn
    train_log.log_record(record, logger)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 50, in log_record
    record_logger.info(record.to_string())
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 25, in to_string
    ve=self.valid_err + ' Time elapsed: {h:02d}:{m:02d}:{s:02d}'.format(h=h, m=m, s=s))
TypeError: unsupported operand type(s) for +: 'float' and 'str'
2018-02-08 13:29:30,280 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:29:30,284 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:29:30,286 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:29:30,286 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:29:45,542 training [INFO ] Epoch  1 Batch   50 Training err. 4.07211 Training err. RA 4.07211 Valid. err. 3.59743 Time elapsed: 00:00:00
2018-02-08 13:29:45,965 training [INFO ] Epoch  1 Batch  100 Training err. 3.43152 Training err. RA 3.75182 Valid. err. 3.30891 Time elapsed: 00:00:00
2018-02-08 13:29:46,212 training [INFO ] Epoch  1 Batch  150 Training err. 3.28023 Training err. RA 3.59462 Valid. err. 3.28419 Time elapsed: 00:00:00
2018-02-08 13:29:46,475 training [INFO ] Epoch  1 Batch  200 Training err. 3.26266 Training err. RA 3.51163 Valid. err. 3.25417 Time elapsed: 00:00:00
2018-02-08 13:29:46,725 training [INFO ] Epoch  1 Batch  250 Training err. 3.21828 Training err. RA 3.45296 Valid. err. 3.25725 Time elapsed: 00:00:00
2018-02-08 13:29:46,977 training [INFO ] Epoch  1 Batch  300 Training err. 3.26781 Training err. RA 3.42210 Valid. err. 3.21985 Time elapsed: 00:00:00
2018-02-08 13:29:47,393 training [INFO ] Epoch  2 Batch  350 Training err. 3.22272 Training err. RA 3.39362 Valid. err. 3.23265 Time elapsed: 00:00:00
2018-02-08 13:29:47,645 training [INFO ] Epoch  2 Batch  400 Training err. 3.22291 Training err. RA 3.37228 Valid. err. 3.23706 Time elapsed: 00:00:00
2018-02-08 13:29:47,897 training [INFO ] Epoch  2 Batch  450 Training err. 3.21112 Training err. RA 3.35437 Valid. err. 3.20516 Time elapsed: 00:00:00
2018-02-08 13:29:48,146 training [INFO ] Epoch  2 Batch  500 Training err. 3.19967 Training err. RA 3.33890 Valid. err. 3.20966 Time elapsed: 00:00:00
2018-02-08 13:29:48,393 training [INFO ] Epoch  2 Batch  550 Training err. 3.17968 Training err. RA 3.32443 Valid. err. 3.21381 Time elapsed: 00:00:00
2018-02-08 13:29:48,646 training [INFO ] Epoch  2 Batch  600 Training err. 3.19932 Training err. RA 3.31400 Valid. err. 3.16149 Time elapsed: 00:00:00
2018-02-08 13:29:49,061 training [INFO ] Epoch  3 Batch  650 Training err. 3.16943 Training err. RA 3.30288 Valid. err. 3.15691 Time elapsed: 00:00:00
2018-02-08 13:29:49,310 training [INFO ] Epoch  3 Batch  700 Training err. 3.15618 Training err. RA 3.29240 Valid. err. 3.13870 Time elapsed: 00:00:00
2018-02-08 13:29:49,564 training [INFO ] Epoch  3 Batch  750 Training err. 3.09828 Training err. RA 3.27946 Valid. err. 3.10589 Time elapsed: 00:00:00
2018-02-08 13:29:49,825 training [INFO ] Epoch  3 Batch  800 Training err. 3.10613 Training err. RA 3.26863 Valid. err. 3.07899 Time elapsed: 00:00:00
2018-02-08 13:29:50,088 training [INFO ] Epoch  3 Batch  850 Training err. 3.03921 Training err. RA 3.25513 Valid. err. 3.08734 Time elapsed: 00:00:00
2018-02-08 13:29:50,336 training [INFO ] Epoch  3 Batch  900 Training err. 3.08448 Training err. RA 3.24565 Valid. err. 3.00474 Time elapsed: 00:00:00
2018-02-08 13:29:50,695 training [INFO ] Epoch  4 Batch  950 Training err. 3.05482 Training err. RA 3.23561 Valid. err. 3.05536 Time elapsed: 00:00:00
2018-02-08 13:29:50,943 training [INFO ] Epoch  4 Batch 1000 Training err. 2.98228 Training err. RA 3.22294 Valid. err. 2.97160 Time elapsed: 00:00:00
2018-02-08 13:29:51,214 training [INFO ] Epoch  4 Batch 1050 Training err. 2.91569 Training err. RA 3.20831 Valid. err. 2.94551 Time elapsed: 00:00:00
2018-02-08 13:29:51,467 training [INFO ] Epoch  4 Batch 1100 Training err. 2.92327 Training err. RA 3.19536 Valid. err. 2.87853 Time elapsed: 00:00:00
2018-02-08 13:29:51,727 training [INFO ] Epoch  4 Batch 1150 Training err. 2.87837 Training err. RA 3.18157 Valid. err. 2.90257 Time elapsed: 00:00:00
2018-02-08 13:29:51,976 training [INFO ] Epoch  4 Batch 1200 Training err. 2.88149 Training err. RA 3.16907 Valid. err. 2.82523 Time elapsed: 00:00:00
2018-02-08 13:29:52,326 training [INFO ] Epoch  5 Batch 1250 Training err. 2.92048 Training err. RA 3.15913 Valid. err. 2.87355 Time elapsed: 00:00:00
2018-02-08 13:29:52,577 training [INFO ] Epoch  5 Batch 1300 Training err. 2.85994 Training err. RA 3.14762 Valid. err. 2.81754 Time elapsed: 00:00:00
2018-02-08 13:29:52,831 training [INFO ] Epoch  5 Batch 1350 Training err. 2.76237 Training err. RA 3.13335 Valid. err. 2.79060 Time elapsed: 00:00:00
2018-02-08 13:29:53,091 training [INFO ] Epoch  5 Batch 1400 Training err. 2.79015 Training err. RA 3.12109 Valid. err. 2.77384 Time elapsed: 00:00:00
2018-02-08 13:29:53,340 training [INFO ] Epoch  5 Batch 1450 Training err. 2.79286 Training err. RA 3.10978 Valid. err. 2.75369 Time elapsed: 00:00:00
2018-02-08 13:29:53,601 training [INFO ] Epoch  5 Batch 1500 Training err. 2.75366 Training err. RA 3.09790 Valid. err. 2.72101 Time elapsed: 00:00:00
2018-02-08 13:29:53,949 training [INFO ] Epoch  6 Batch 1550 Training err. 2.83687 Training err. RA 3.08948 Valid. err. 2.72306 Time elapsed: 00:00:00
2018-02-08 13:29:54,198 training [INFO ] Epoch  6 Batch 1600 Training err. 2.77251 Training err. RA 3.07958 Valid. err. 2.77012 Time elapsed: 00:00:00
2018-02-08 13:29:54,446 training [INFO ] Epoch  6 Batch 1650 Training err. 2.69928 Training err. RA 3.06805 Valid. err. 2.69809 Time elapsed: 00:00:00
2018-02-08 13:29:54,711 training [INFO ] Epoch  6 Batch 1700 Training err. 2.67058 Training err. RA 3.05636 Valid. err. 2.68463 Time elapsed: 00:00:00
2018-02-08 13:29:54,964 training [INFO ] Epoch  6 Batch 1750 Training err. 2.74384 Training err. RA 3.04743 Valid. err. 2.67715 Time elapsed: 00:00:00
2018-02-08 13:29:55,215 training [INFO ] Epoch  6 Batch 1800 Training err. 2.65041 Training err. RA 3.03641 Valid. err. 2.64793 Time elapsed: 00:00:00
2018-02-08 13:29:55,588 training [INFO ] Epoch  7 Batch 1850 Training err. 2.74981 Training err. RA 3.02866 Valid. err. 2.67716 Time elapsed: 00:00:00
2018-02-08 13:29:55,837 training [INFO ] Epoch  7 Batch 1900 Training err. 2.72638 Training err. RA 3.02071 Valid. err. 2.63127 Time elapsed: 00:00:00
2018-02-08 13:29:56,091 training [INFO ] Epoch  7 Batch 1950 Training err. 2.61871 Training err. RA 3.01040 Valid. err. 2.61056 Time elapsed: 00:00:00
2018-02-08 13:29:56,349 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59235 Training err. RA 2.99995 Valid. err. 2.59402 Time elapsed: 00:00:00
2018-02-08 13:29:56,613 training [INFO ] Epoch  7 Batch 2050 Training err. 2.69329 Training err. RA 2.99247 Valid. err. 2.58683 Time elapsed: 00:00:00
2018-02-08 13:29:56,883 training [INFO ] Epoch  7 Batch 2100 Training err. 2.57082 Training err. RA 2.98243 Valid. err. 2.56092 Time elapsed: 00:00:00
2018-02-08 13:29:57,255 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64004 Training err. RA 2.97447 Valid. err. 2.55111 Time elapsed: 00:00:00
2018-02-08 13:29:57,517 training [INFO ] Epoch  8 Batch 2200 Training err. 2.70758 Training err. RA 2.96840 Valid. err. 2.56573 Time elapsed: 00:00:00
2018-02-08 13:29:57,777 training [INFO ] Epoch  8 Batch 2250 Training err. 2.57517 Training err. RA 2.95966 Valid. err. 2.55721 Time elapsed: 00:00:00
2018-02-08 13:29:58,023 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55086 Training err. RA 2.95077 Valid. err. 2.54167 Time elapsed: 00:00:00
2018-02-08 13:29:58,282 training [INFO ] Epoch  8 Batch 2350 Training err. 2.60764 Training err. RA 2.94347 Valid. err. 2.55423 Time elapsed: 00:00:00
2018-02-08 13:29:58,534 training [INFO ] Epoch  8 Batch 2400 Training err. 2.50140 Training err. RA 2.93426 Valid. err. 2.51026 Time elapsed: 00:00:00
2018-02-08 13:29:58,785 training [INFO ] Epoch  8 Batch 2450 Training err. 2.58254 Training err. RA 2.92709 Valid. err. 2.52876 Time elapsed: 00:00:00
2018-02-08 13:29:59,158 training [INFO ] Epoch  9 Batch 2500 Training err. 2.62483 Training err. RA 2.92104 Valid. err. 2.53637 Time elapsed: 00:00:00
2018-02-08 13:29:59,435 training [INFO ] Epoch  9 Batch 2550 Training err. 2.57496 Training err. RA 2.91426 Valid. err. 2.49445 Time elapsed: 00:00:00
2018-02-08 13:29:59,685 training [INFO ] Epoch  9 Batch 2600 Training err. 2.50099 Training err. RA 2.90631 Valid. err. 2.47722 Time elapsed: 00:00:00
2018-02-08 13:29:59,928 training [INFO ] Epoch  9 Batch 2650 Training err. 2.55869 Training err. RA 2.89975 Valid. err. 2.50612 Time elapsed: 00:00:00
2018-02-08 13:30:00,182 training [INFO ] Epoch  9 Batch 2700 Training err. 2.45183 Training err. RA 2.89145 Valid. err. 2.49232 Time elapsed: 00:00:00
2018-02-08 13:30:00,423 training [INFO ] Epoch  9 Batch 2750 Training err. 2.50347 Training err. RA 2.88440 Valid. err. 2.45091 Time elapsed: 00:00:00
2018-02-08 13:30:00,770 training [INFO ] Epoch 10 Batch 2800 Training err. 2.55677 Training err. RA 2.87855 Valid. err. 2.48525 Time elapsed: 00:00:00
2018-02-08 13:30:01,072 training [INFO ] Epoch 10 Batch 2850 Training err. 2.55662 Training err. RA 2.87290 Valid. err. 2.46494 Time elapsed: 00:00:00
2018-02-08 13:30:01,339 training [INFO ] Epoch 10 Batch 2900 Training err. 2.45169 Training err. RA 2.86564 Valid. err. 2.43989 Time elapsed: 00:00:00
2018-02-08 13:30:01,591 training [INFO ] Epoch 10 Batch 2950 Training err. 2.50624 Training err. RA 2.85955 Valid. err. 2.45465 Time elapsed: 00:00:00
2018-02-08 13:30:01,841 training [INFO ] Epoch 10 Batch 3000 Training err. 2.42849 Training err. RA 2.85236 Valid. err. 2.40726 Time elapsed: 00:00:00
2018-02-08 13:30:02,096 training [INFO ] Epoch 10 Batch 3050 Training err. 2.44527 Training err. RA 2.84569 Valid. err. 2.41881 Time elapsed: 00:00:00
2018-02-08 13:30:02,242 __main__ [INFO ] End of training
2018-02-08 13:30:05,554 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:30:05,562 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:30:28,215 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:30:28,218 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:30:28,220 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:30:28,221 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:30:38,725 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 170, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 132, in train_rnn
    train_log.log_record(record, logger)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 50, in log_record
    record_logger.info(record.to_string())
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 25, in to_string
    ve=self.valid_err) + ' Time elapsed: {h:02d}:{m:02d}:{s:02d}'.format(h=h, m=m, s=s)
ValueError: Unknown format code 'd' for object of type 'float'
2018-02-08 13:30:38,817 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:30:38,834 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:30:39,164 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 170, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 132, in train_rnn
    train_log.log_record(record, logger)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 50, in log_record
    record_logger.info(record.to_string())
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 25, in to_string
    ve=self.valid_err) + ' Time elapsed: {h:02d}:{m:02d}:{s:02d}'.format(h=h, m=m, s=s)
ValueError: Unknown format code 'd' for object of type 'float'
2018-02-08 13:30:39,165 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:30:39,165 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:30:40,274 __main__ [ERROR] Something went wrong. Will try to train with the rest of the hyperparameter profiles
Traceback (most recent call last):
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/experiment.py", line 170, in <module>
    train_log_file=os.path.join(out_dir, 'train_log.json')
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/training.py", line 132, in train_rnn
    train_log.log_record(record, logger)
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 50, in log_record
    record_logger.info(record.to_string())
  File "/media/yasen/storage/studies/uoe/fyp/project/lstm-for-dasher/lmexperiments/trainutils/trainutils.py", line 25, in to_string
    ve=self.valid_err) + ' Time elapsed: {h:02d}:{m:02d}:{s:02d}'.format(h=h, m=m, s=s)
ValueError: Unknown format code 'd' for object of type 'float'
2018-02-08 13:31:33,528 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:31:33,531 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:31:33,533 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:31:33,533 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:31:37,346 training [INFO ] Epoch  1 Batch   50 Training err. 4.06936 Training err. RA 4.06936 Valid. err. 3.59566 Time elapsed: 00:00:00
2018-02-08 13:31:37,632 training [INFO ] Epoch  1 Batch  100 Training err. 3.42672 Training err. RA 3.74804 Valid. err. 3.30594 Time elapsed: 00:00:00
2018-02-08 13:31:37,896 training [INFO ] Epoch  1 Batch  150 Training err. 3.28125 Training err. RA 3.59244 Valid. err. 3.28267 Time elapsed: 00:00:01
2018-02-08 13:31:38,174 training [INFO ] Epoch  1 Batch  200 Training err. 3.26454 Training err. RA 3.51047 Valid. err. 3.25599 Time elapsed: 00:00:01
2018-02-08 13:31:38,486 training [INFO ] Epoch  1 Batch  250 Training err. 3.21882 Training err. RA 3.45214 Valid. err. 3.25797 Time elapsed: 00:00:01
2018-02-08 13:31:38,765 training [INFO ] Epoch  1 Batch  300 Training err. 3.26796 Training err. RA 3.42144 Valid. err. 3.22003 Time elapsed: 00:00:01
2018-02-08 13:31:39,187 training [INFO ] Epoch  2 Batch  350 Training err. 3.22177 Training err. RA 3.39292 Valid. err. 3.23335 Time elapsed: 00:00:02
2018-02-08 13:31:39,454 training [INFO ] Epoch  2 Batch  400 Training err. 3.22280 Training err. RA 3.37165 Valid. err. 3.23741 Time elapsed: 00:00:02
2018-02-08 13:31:39,708 training [INFO ] Epoch  2 Batch  450 Training err. 3.20973 Training err. RA 3.35366 Valid. err. 3.20356 Time elapsed: 00:00:02
2018-02-08 13:31:39,974 training [INFO ] Epoch  2 Batch  500 Training err. 3.19790 Training err. RA 3.33809 Valid. err. 3.20644 Time elapsed: 00:00:03
2018-02-08 13:31:40,232 training [INFO ] Epoch  2 Batch  550 Training err. 3.17510 Training err. RA 3.32327 Valid. err. 3.22209 Time elapsed: 00:00:03
2018-02-08 13:31:40,482 training [INFO ] Epoch  2 Batch  600 Training err. 3.19368 Training err. RA 3.31247 Valid. err. 3.15429 Time elapsed: 00:00:03
2018-02-08 13:31:40,853 training [INFO ] Epoch  3 Batch  650 Training err. 3.16248 Training err. RA 3.30093 Valid. err. 3.14364 Time elapsed: 00:00:03
2018-02-08 13:31:41,103 training [INFO ] Epoch  3 Batch  700 Training err. 3.14856 Training err. RA 3.29005 Valid. err. 3.14171 Time elapsed: 00:00:04
2018-02-08 13:31:41,361 training [INFO ] Epoch  3 Batch  750 Training err. 3.08736 Training err. RA 3.27654 Valid. err. 3.09719 Time elapsed: 00:00:04
2018-02-08 13:31:41,657 training [INFO ] Epoch  3 Batch  800 Training err. 3.09866 Training err. RA 3.26542 Valid. err. 3.08317 Time elapsed: 00:00:04
2018-02-08 13:31:41,931 training [INFO ] Epoch  3 Batch  850 Training err. 3.03190 Training err. RA 3.25168 Valid. err. 3.12325 Time elapsed: 00:00:05
2018-02-08 13:31:42,186 training [INFO ] Epoch  3 Batch  900 Training err. 3.08144 Training err. RA 3.24222 Valid. err. 2.99767 Time elapsed: 00:00:05
2018-02-08 13:31:42,537 training [INFO ] Epoch  4 Batch  950 Training err. 3.05003 Training err. RA 3.23211 Valid. err. 3.07722 Time elapsed: 00:00:05
2018-02-08 13:31:42,783 training [INFO ] Epoch  4 Batch 1000 Training err. 2.98037 Training err. RA 3.21952 Valid. err. 2.97363 Time elapsed: 00:00:05
2018-02-08 13:31:43,039 training [INFO ] Epoch  4 Batch 1050 Training err. 2.90885 Training err. RA 3.20473 Valid. err. 2.93517 Time elapsed: 00:00:06
2018-02-08 13:31:43,298 training [INFO ] Epoch  4 Batch 1100 Training err. 2.91445 Training err. RA 3.19153 Valid. err. 2.86888 Time elapsed: 00:00:06
2018-02-08 13:31:43,587 training [INFO ] Epoch  4 Batch 1150 Training err. 2.87200 Training err. RA 3.17764 Valid. err. 2.89381 Time elapsed: 00:00:06
2018-02-08 13:31:43,854 training [INFO ] Epoch  4 Batch 1200 Training err. 2.87796 Training err. RA 3.16515 Valid. err. 2.81625 Time elapsed: 00:00:06
2018-02-08 13:31:44,203 training [INFO ] Epoch  5 Batch 1250 Training err. 2.91083 Training err. RA 3.15498 Valid. err. 2.86520 Time elapsed: 00:00:07
2018-02-08 13:31:44,478 training [INFO ] Epoch  5 Batch 1300 Training err. 2.85645 Training err. RA 3.14350 Valid. err. 2.80892 Time elapsed: 00:00:07
2018-02-08 13:31:44,745 training [INFO ] Epoch  5 Batch 1350 Training err. 2.75647 Training err. RA 3.12916 Valid. err. 2.78214 Time elapsed: 00:00:07
2018-02-08 13:31:45,019 training [INFO ] Epoch  5 Batch 1400 Training err. 2.78092 Training err. RA 3.11673 Valid. err. 2.78303 Time elapsed: 00:00:08
2018-02-08 13:31:45,315 training [INFO ] Epoch  5 Batch 1450 Training err. 2.79189 Training err. RA 3.10553 Valid. err. 2.75401 Time elapsed: 00:00:08
2018-02-08 13:31:45,597 training [INFO ] Epoch  5 Batch 1500 Training err. 2.75142 Training err. RA 3.09372 Valid. err. 2.71800 Time elapsed: 00:00:08
2018-02-08 13:31:46,046 training [INFO ] Epoch  6 Batch 1550 Training err. 2.83198 Training err. RA 3.08528 Valid. err. 2.72194 Time elapsed: 00:00:09
2018-02-08 13:31:46,325 training [INFO ] Epoch  6 Batch 1600 Training err. 2.77434 Training err. RA 3.07556 Valid. err. 2.76035 Time elapsed: 00:00:09
2018-02-08 13:31:46,597 training [INFO ] Epoch  6 Batch 1650 Training err. 2.69756 Training err. RA 3.06411 Valid. err. 2.69401 Time elapsed: 00:00:09
2018-02-08 13:31:46,847 training [INFO ] Epoch  6 Batch 1700 Training err. 2.67105 Training err. RA 3.05255 Valid. err. 2.69149 Time elapsed: 00:00:09
2018-02-08 13:31:47,133 training [INFO ] Epoch  6 Batch 1750 Training err. 2.74415 Training err. RA 3.04374 Valid. err. 2.68131 Time elapsed: 00:00:10
2018-02-08 13:31:47,445 training [INFO ] Epoch  6 Batch 1800 Training err. 2.65471 Training err. RA 3.03293 Valid. err. 2.65152 Time elapsed: 00:00:10
2018-02-08 13:31:47,873 training [INFO ] Epoch  7 Batch 1850 Training err. 2.75313 Training err. RA 3.02537 Valid. err. 2.68082 Time elapsed: 00:00:10
2018-02-08 13:31:48,172 training [INFO ] Epoch  7 Batch 1900 Training err. 2.72903 Training err. RA 3.01757 Valid. err. 2.63775 Time elapsed: 00:00:11
2018-02-08 13:31:48,460 training [INFO ] Epoch  7 Batch 1950 Training err. 2.62683 Training err. RA 3.00755 Valid. err. 2.61598 Time elapsed: 00:00:11
2018-02-08 13:31:48,724 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59312 Training err. RA 2.99719 Valid. err. 2.60187 Time elapsed: 00:00:11
2018-02-08 13:31:48,981 training [INFO ] Epoch  7 Batch 2050 Training err. 2.69335 Training err. RA 2.98978 Valid. err. 2.57777 Time elapsed: 00:00:12
2018-02-08 13:31:49,236 training [INFO ] Epoch  7 Batch 2100 Training err. 2.58107 Training err. RA 2.98005 Valid. err. 2.57622 Time elapsed: 00:00:12
2018-02-08 13:31:50,360 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64191 Training err. RA 2.97218 Valid. err. 2.55779 Time elapsed: 00:00:13
2018-02-08 13:31:50,638 training [INFO ] Epoch  8 Batch 2200 Training err. 2.71479 Training err. RA 2.96633 Valid. err. 2.55770 Time elapsed: 00:00:13
2018-02-08 13:31:50,881 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58709 Training err. RA 2.95791 Valid. err. 2.55670 Time elapsed: 00:00:13
2018-02-08 13:31:51,135 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55351 Training err. RA 2.94912 Valid. err. 2.55770 Time elapsed: 00:00:14
2018-02-08 13:31:51,383 training [INFO ] Epoch  8 Batch 2350 Training err. 2.61050 Training err. RA 2.94191 Valid. err. 2.55786 Time elapsed: 00:00:14
2018-02-08 13:31:51,639 training [INFO ] Epoch  8 Batch 2400 Training err. 2.51732 Training err. RA 2.93307 Valid. err. 2.52217 Time elapsed: 00:00:14
2018-02-08 13:31:51,890 training [INFO ] Epoch  8 Batch 2450 Training err. 2.59022 Training err. RA 2.92607 Valid. err. 2.53761 Time elapsed: 00:00:15
2018-02-08 13:31:52,249 training [INFO ] Epoch  9 Batch 2500 Training err. 2.63171 Training err. RA 2.92018 Valid. err. 2.53770 Time elapsed: 00:00:15
2018-02-08 13:31:52,505 training [INFO ] Epoch  9 Batch 2550 Training err. 2.59794 Training err. RA 2.91386 Valid. err. 2.50358 Time elapsed: 00:00:15
2018-02-08 13:31:52,749 training [INFO ] Epoch  9 Batch 2600 Training err. 2.50727 Training err. RA 2.90604 Valid. err. 2.49223 Time elapsed: 00:00:15
2018-02-08 13:31:52,998 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56576 Training err. RA 2.89962 Valid. err. 2.50950 Time elapsed: 00:00:16
2018-02-08 13:31:53,281 training [INFO ] Epoch  9 Batch 2700 Training err. 2.47413 Training err. RA 2.89174 Valid. err. 2.50401 Time elapsed: 00:00:16
2018-02-08 13:31:53,551 training [INFO ] Epoch  9 Batch 2750 Training err. 2.51502 Training err. RA 2.88489 Valid. err. 2.46141 Time elapsed: 00:00:16
2018-02-08 13:31:53,907 training [INFO ] Epoch 10 Batch 2800 Training err. 2.57009 Training err. RA 2.87927 Valid. err. 2.48357 Time elapsed: 00:00:17
2018-02-08 13:31:54,159 training [INFO ] Epoch 10 Batch 2850 Training err. 2.58153 Training err. RA 2.87405 Valid. err. 2.47531 Time elapsed: 00:00:17
2018-02-08 13:31:54,413 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46401 Training err. RA 2.86698 Valid. err. 2.44507 Time elapsed: 00:00:17
2018-02-08 13:31:54,695 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51277 Training err. RA 2.86098 Valid. err. 2.46914 Time elapsed: 00:00:17
2018-02-08 13:31:55,060 training [INFO ] Epoch 10 Batch 3000 Training err. 2.44762 Training err. RA 2.85409 Valid. err. 2.42510 Time elapsed: 00:00:18
2018-02-08 13:31:55,359 training [INFO ] Epoch 10 Batch 3050 Training err. 2.46226 Training err. RA 2.84766 Valid. err. 2.42687 Time elapsed: 00:00:18
2018-02-08 13:31:55,549 __main__ [INFO ] End of training
2018-02-08 13:31:57,003 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:31:57,026 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:31:57,349 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004 Time elapsed: 00:00:00
2018-02-08 13:31:57,645 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220 Time elapsed: 00:00:00
2018-02-08 13:31:57,944 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708 Time elapsed: 00:00:00
2018-02-08 13:31:58,261 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226 Time elapsed: 00:00:01
2018-02-08 13:31:58,690 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791 Time elapsed: 00:00:01
2018-02-08 13:31:59,019 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095 Time elapsed: 00:00:01
2018-02-08 13:31:59,326 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617 Time elapsed: 00:00:02
2018-02-08 13:31:59,602 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091 Time elapsed: 00:00:02
2018-02-08 13:31:59,949 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571 Time elapsed: 00:00:02
2018-02-08 13:32:00,211 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752 Time elapsed: 00:00:03
2018-02-08 13:32:00,483 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115 Time elapsed: 00:00:03
2018-02-08 13:32:00,751 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850 Time elapsed: 00:00:03
2018-02-08 13:32:01,107 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007 Time elapsed: 00:00:04
2018-02-08 13:32:01,369 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578 Time elapsed: 00:00:04
2018-02-08 13:32:01,650 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063 Time elapsed: 00:00:04
2018-02-08 13:32:01,924 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541 Time elapsed: 00:00:04
2018-02-08 13:32:02,270 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331 Time elapsed: 00:00:05
2018-02-08 13:32:02,541 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885 Time elapsed: 00:00:05
2018-02-08 13:32:02,806 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402 Time elapsed: 00:00:05
2018-02-08 13:32:03,063 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876 Time elapsed: 00:00:06
2018-02-08 13:32:03,408 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261 Time elapsed: 00:00:06
2018-02-08 13:32:03,670 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771 Time elapsed: 00:00:06
2018-02-08 13:32:03,943 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434 Time elapsed: 00:00:06
2018-02-08 13:32:04,207 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230 Time elapsed: 00:00:07
2018-02-08 13:32:04,559 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620 Time elapsed: 00:00:07
2018-02-08 13:32:04,822 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672 Time elapsed: 00:00:07
2018-02-08 13:32:05,095 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298 Time elapsed: 00:00:08
2018-02-08 13:32:05,362 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529 Time elapsed: 00:00:08
2018-02-08 13:32:05,717 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410 Time elapsed: 00:00:08
2018-02-08 13:32:05,968 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609 Time elapsed: 00:00:08
2018-02-08 13:32:06,217 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099 Time elapsed: 00:00:09
2018-02-08 13:32:06,473 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653 Time elapsed: 00:00:09
2018-02-08 13:32:06,819 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570 Time elapsed: 00:00:09
2018-02-08 13:32:07,083 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963 Time elapsed: 00:00:10
2018-02-08 13:32:07,362 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815 Time elapsed: 00:00:10
2018-02-08 13:32:07,638 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999 Time elapsed: 00:00:10
2018-02-08 13:32:08,117 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695 Time elapsed: 00:00:11
2018-02-08 13:32:08,380 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245 Time elapsed: 00:00:11
2018-02-08 13:32:08,652 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415 Time elapsed: 00:00:11
2018-02-08 13:32:08,911 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328 Time elapsed: 00:00:11
2018-02-08 13:32:09,169 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049 Time elapsed: 00:00:12
2018-02-08 13:32:09,279 __main__ [INFO ] End of training
2018-02-08 13:32:09,435 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:32:09,436 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:32:09,788 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945 Time elapsed: 00:00:00
2018-02-08 13:32:10,067 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585 Time elapsed: 00:00:00
2018-02-08 13:32:10,336 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036 Time elapsed: 00:00:00
2018-02-08 13:32:10,612 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844 Time elapsed: 00:00:01
2018-02-08 13:32:10,893 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920 Time elapsed: 00:00:01
2018-02-08 13:32:11,181 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863 Time elapsed: 00:00:01
2018-02-08 13:32:11,571 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650 Time elapsed: 00:00:02
2018-02-08 13:32:11,838 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923 Time elapsed: 00:00:02
2018-02-08 13:32:12,104 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288 Time elapsed: 00:00:02
2018-02-08 13:32:12,376 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297 Time elapsed: 00:00:02
2018-02-08 13:32:12,657 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633 Time elapsed: 00:00:03
2018-02-08 13:32:12,943 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329 Time elapsed: 00:00:03
2018-02-08 13:32:13,313 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222 Time elapsed: 00:00:03
2018-02-08 13:32:13,599 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798 Time elapsed: 00:00:04
2018-02-08 13:32:13,883 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300 Time elapsed: 00:00:04
2018-02-08 13:32:14,189 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864 Time elapsed: 00:00:04
2018-02-08 13:32:14,478 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590 Time elapsed: 00:00:05
2018-02-08 13:32:14,764 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607 Time elapsed: 00:00:05
2018-02-08 13:32:15,144 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056 Time elapsed: 00:00:05
2018-02-08 13:32:15,426 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954 Time elapsed: 00:00:05
2018-02-08 13:32:15,701 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403 Time elapsed: 00:00:06
2018-02-08 13:32:15,980 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444 Time elapsed: 00:00:06
2018-02-08 13:32:16,249 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682 Time elapsed: 00:00:06
2018-02-08 13:32:16,555 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167 Time elapsed: 00:00:07
2018-02-08 13:32:16,977 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971 Time elapsed: 00:00:07
2018-02-08 13:32:17,284 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051 Time elapsed: 00:00:07
2018-02-08 13:32:17,592 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551 Time elapsed: 00:00:08
2018-02-08 13:32:17,901 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389 Time elapsed: 00:00:08
2018-02-08 13:33:25,210 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:33:25,212 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:33:25,215 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:33:25,243 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:33:28,234 training [INFO ] Epoch  1 Batch   50 Training err. 4.05807 Training err. RA 4.05807 Valid. err. 3.57848 Time elapsed: 00:00:00
2018-02-08 13:33:28,504 training [INFO ] Epoch  1 Batch  100 Training err. 3.43030 Training err. RA 3.74418 Valid. err. 3.31350 Time elapsed: 00:00:00
2018-02-08 13:33:28,816 training [INFO ] Epoch  1 Batch  150 Training err. 3.28626 Training err. RA 3.59154 Valid. err. 3.28566 Time elapsed: 00:00:01
2018-02-08 13:33:29,088 training [INFO ] Epoch  1 Batch  200 Training err. 3.26703 Training err. RA 3.51041 Valid. err. 3.25575 Time elapsed: 00:00:01
2018-02-08 13:33:29,356 training [INFO ] Epoch  1 Batch  250 Training err. 3.22007 Training err. RA 3.45235 Valid. err. 3.25780 Time elapsed: 00:00:01
2018-02-08 13:33:29,626 training [INFO ] Epoch  1 Batch  300 Training err. 3.26925 Training err. RA 3.42183 Valid. err. 3.22068 Time elapsed: 00:00:01
2018-02-08 13:33:29,994 training [INFO ] Epoch  2 Batch  350 Training err. 3.22531 Training err. RA 3.39376 Valid. err. 3.23398 Time elapsed: 00:00:02
2018-02-08 13:33:30,250 training [INFO ] Epoch  2 Batch  400 Training err. 3.22549 Training err. RA 3.37272 Valid. err. 3.23946 Time elapsed: 00:00:02
2018-02-08 13:33:30,506 training [INFO ] Epoch  2 Batch  450 Training err. 3.21452 Training err. RA 3.35514 Valid. err. 3.20788 Time elapsed: 00:00:02
2018-02-08 13:33:30,782 training [INFO ] Epoch  2 Batch  500 Training err. 3.20471 Training err. RA 3.34010 Valid. err. 3.21384 Time elapsed: 00:00:03
2018-02-08 13:33:31,045 training [INFO ] Epoch  2 Batch  550 Training err. 3.18577 Training err. RA 3.32607 Valid. err. 3.21446 Time elapsed: 00:00:03
2018-02-08 13:33:31,306 training [INFO ] Epoch  2 Batch  600 Training err. 3.20402 Training err. RA 3.31590 Valid. err. 3.16614 Time elapsed: 00:00:03
2018-02-08 13:33:31,683 training [INFO ] Epoch  3 Batch  650 Training err. 3.17650 Training err. RA 3.30518 Valid. err. 3.16966 Time elapsed: 00:00:03
2018-02-08 13:33:31,939 training [INFO ] Epoch  3 Batch  700 Training err. 3.16576 Training err. RA 3.29522 Valid. err. 3.15070 Time elapsed: 00:00:04
2018-02-08 13:33:32,186 training [INFO ] Epoch  3 Batch  750 Training err. 3.10956 Training err. RA 3.28284 Valid. err. 3.11751 Time elapsed: 00:00:04
2018-02-08 13:33:32,441 training [INFO ] Epoch  3 Batch  800 Training err. 3.11363 Training err. RA 3.27227 Valid. err. 3.08629 Time elapsed: 00:00:04
2018-02-08 13:33:32,702 training [INFO ] Epoch  3 Batch  850 Training err. 3.04784 Training err. RA 3.25906 Valid. err. 3.11334 Time elapsed: 00:00:04
2018-02-08 13:33:32,949 training [INFO ] Epoch  3 Batch  900 Training err. 3.09056 Training err. RA 3.24970 Valid. err. 3.00971 Time elapsed: 00:00:05
2018-02-08 13:33:33,296 training [INFO ] Epoch  4 Batch  950 Training err. 3.05940 Training err. RA 3.23969 Valid. err. 3.04728 Time elapsed: 00:00:05
2018-02-08 13:33:33,548 training [INFO ] Epoch  4 Batch 1000 Training err. 2.99230 Training err. RA 3.22732 Valid. err. 2.97988 Time elapsed: 00:00:05
2018-02-08 13:33:33,805 training [INFO ] Epoch  4 Batch 1050 Training err. 2.92639 Training err. RA 3.21299 Valid. err. 2.94255 Time elapsed: 00:00:06
2018-02-08 13:33:34,060 training [INFO ] Epoch  4 Batch 1100 Training err. 2.92822 Training err. RA 3.20004 Valid. err. 2.88519 Time elapsed: 00:00:06
2018-02-08 13:33:34,316 training [INFO ] Epoch  4 Batch 1150 Training err. 2.88705 Training err. RA 3.18643 Valid. err. 2.90627 Time elapsed: 00:00:06
2018-02-08 13:33:34,578 training [INFO ] Epoch  4 Batch 1200 Training err. 2.89276 Training err. RA 3.17420 Valid. err. 2.83435 Time elapsed: 00:00:06
2018-02-08 13:33:34,980 training [INFO ] Epoch  5 Batch 1250 Training err. 2.92708 Training err. RA 3.16431 Valid. err. 2.86800 Time elapsed: 00:00:07
2018-02-08 13:33:35,263 training [INFO ] Epoch  5 Batch 1300 Training err. 2.86907 Training err. RA 3.15296 Valid. err. 2.82901 Time elapsed: 00:00:07
2018-02-08 13:33:35,563 training [INFO ] Epoch  5 Batch 1350 Training err. 2.77177 Training err. RA 3.13884 Valid. err. 2.78805 Time elapsed: 00:00:07
2018-02-08 13:33:35,841 training [INFO ] Epoch  5 Batch 1400 Training err. 2.79678 Training err. RA 3.12662 Valid. err. 2.78553 Time elapsed: 00:00:08
2018-02-08 13:33:36,150 training [INFO ] Epoch  5 Batch 1450 Training err. 2.79966 Training err. RA 3.11535 Valid. err. 2.77329 Time elapsed: 00:00:08
2018-02-08 13:33:36,427 training [INFO ] Epoch  5 Batch 1500 Training err. 2.75966 Training err. RA 3.10349 Valid. err. 2.72660 Time elapsed: 00:00:08
2018-02-08 13:33:36,846 training [INFO ] Epoch  6 Batch 1550 Training err. 2.84180 Training err. RA 3.09505 Valid. err. 2.72729 Time elapsed: 00:00:09
2018-02-08 13:33:37,118 training [INFO ] Epoch  6 Batch 1600 Training err. 2.77438 Training err. RA 3.08503 Valid. err. 2.75910 Time elapsed: 00:00:09
2018-02-08 13:33:37,369 training [INFO ] Epoch  6 Batch 1650 Training err. 2.69856 Training err. RA 3.07332 Valid. err. 2.69699 Time elapsed: 00:00:09
2018-02-08 13:33:37,656 training [INFO ] Epoch  6 Batch 1700 Training err. 2.67399 Training err. RA 3.06157 Valid. err. 2.69168 Time elapsed: 00:00:09
2018-02-08 13:33:37,950 training [INFO ] Epoch  6 Batch 1750 Training err. 2.74588 Training err. RA 3.05255 Valid. err. 2.66632 Time elapsed: 00:00:10
2018-02-08 13:33:38,264 training [INFO ] Epoch  6 Batch 1800 Training err. 2.64450 Training err. RA 3.04122 Valid. err. 2.65125 Time elapsed: 00:00:10
2018-02-08 13:33:38,616 training [INFO ] Epoch  7 Batch 1850 Training err. 2.74804 Training err. RA 3.03330 Valid. err. 2.65179 Time elapsed: 00:00:10
2018-02-08 13:33:38,862 training [INFO ] Epoch  7 Batch 1900 Training err. 2.72124 Training err. RA 3.02508 Valid. err. 2.63025 Time elapsed: 00:00:11
2018-02-08 13:33:39,108 training [INFO ] Epoch  7 Batch 1950 Training err. 2.61423 Training err. RA 3.01455 Valid. err. 2.60777 Time elapsed: 00:00:11
2018-02-08 13:33:39,365 training [INFO ] Epoch  7 Batch 2000 Training err. 2.58997 Training err. RA 3.00393 Valid. err. 2.58967 Time elapsed: 00:00:11
2018-02-08 13:33:39,626 training [INFO ] Epoch  7 Batch 2050 Training err. 2.68944 Training err. RA 2.99626 Valid. err. 2.56827 Time elapsed: 00:00:11
2018-02-08 13:33:39,913 training [INFO ] Epoch  7 Batch 2100 Training err. 2.56222 Training err. RA 2.98593 Valid. err. 2.54901 Time elapsed: 00:00:12
2018-02-08 13:33:40,261 training [INFO ] Epoch  8 Batch 2150 Training err. 2.63274 Training err. RA 2.97772 Valid. err. 2.53995 Time elapsed: 00:00:12
2018-02-08 13:33:40,501 training [INFO ] Epoch  8 Batch 2200 Training err. 2.69994 Training err. RA 2.97140 Valid. err. 2.54609 Time elapsed: 00:00:12
2018-02-08 13:33:40,755 training [INFO ] Epoch  8 Batch 2250 Training err. 2.57271 Training err. RA 2.96254 Valid. err. 2.54192 Time elapsed: 00:00:13
2018-02-08 13:33:41,006 training [INFO ] Epoch  8 Batch 2300 Training err. 2.54518 Training err. RA 2.95347 Valid. err. 2.53396 Time elapsed: 00:00:13
2018-02-08 13:33:41,259 training [INFO ] Epoch  8 Batch 2350 Training err. 2.60369 Training err. RA 2.94603 Valid. err. 2.54902 Time elapsed: 00:00:13
2018-02-08 13:33:41,503 training [INFO ] Epoch  8 Batch 2400 Training err. 2.50038 Training err. RA 2.93674 Valid. err. 2.50913 Time elapsed: 00:00:13
2018-02-08 13:33:41,761 training [INFO ] Epoch  8 Batch 2450 Training err. 2.57312 Training err. RA 2.92932 Valid. err. 2.52078 Time elapsed: 00:00:14
2018-02-08 13:33:42,117 training [INFO ] Epoch  9 Batch 2500 Training err. 2.62562 Training err. RA 2.92325 Valid. err. 2.52491 Time elapsed: 00:00:14
2018-02-08 13:33:42,373 training [INFO ] Epoch  9 Batch 2550 Training err. 2.57498 Training err. RA 2.91642 Valid. err. 2.49840 Time elapsed: 00:00:14
2018-02-08 13:33:42,634 training [INFO ] Epoch  9 Batch 2600 Training err. 2.49756 Training err. RA 2.90836 Valid. err. 2.47249 Time elapsed: 00:00:14
2018-02-08 13:33:42,871 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56223 Training err. RA 2.90183 Valid. err. 2.50890 Time elapsed: 00:00:15
2018-02-08 13:33:43,175 training [INFO ] Epoch  9 Batch 2700 Training err. 2.45654 Training err. RA 2.89359 Valid. err. 2.49412 Time elapsed: 00:00:15
2018-02-08 13:33:43,477 training [INFO ] Epoch  9 Batch 2750 Training err. 2.50329 Training err. RA 2.88649 Valid. err. 2.45901 Time elapsed: 00:00:15
2018-02-08 13:33:43,847 training [INFO ] Epoch 10 Batch 2800 Training err. 2.56329 Training err. RA 2.88072 Valid. err. 2.47334 Time elapsed: 00:00:16
2018-02-08 13:33:44,085 training [INFO ] Epoch 10 Batch 2850 Training err. 2.55833 Training err. RA 2.87506 Valid. err. 2.47697 Time elapsed: 00:00:16
2018-02-08 13:33:44,329 training [INFO ] Epoch 10 Batch 2900 Training err. 2.45040 Training err. RA 2.86774 Valid. err. 2.43835 Time elapsed: 00:00:16
2018-02-08 13:33:44,578 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51381 Training err. RA 2.86174 Valid. err. 2.46109 Time elapsed: 00:00:16
2018-02-08 13:33:44,820 training [INFO ] Epoch 10 Batch 3000 Training err. 2.43863 Training err. RA 2.85469 Valid. err. 2.42193 Time elapsed: 00:00:17
2018-02-08 13:33:45,057 training [INFO ] Epoch 10 Batch 3050 Training err. 2.45225 Training err. RA 2.84809 Valid. err. 2.41684 Time elapsed: 00:00:17
2018-02-08 13:33:45,209 __main__ [INFO ] End of training
2018-02-08 13:33:45,612 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:33:45,613 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:33:45,922 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004 Time elapsed: 00:00:00
2018-02-08 13:33:46,192 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220 Time elapsed: 00:00:00
2018-02-08 13:33:46,451 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708 Time elapsed: 00:00:00
2018-02-08 13:33:46,721 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226 Time elapsed: 00:00:01
2018-02-08 13:33:47,073 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791 Time elapsed: 00:00:01
2018-02-08 13:33:47,331 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095 Time elapsed: 00:00:01
2018-02-08 13:33:47,591 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617 Time elapsed: 00:00:01
2018-02-08 13:33:47,856 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091 Time elapsed: 00:00:02
2018-02-08 13:33:48,209 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571 Time elapsed: 00:00:02
2018-02-08 13:33:48,465 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752 Time elapsed: 00:00:02
2018-02-08 13:33:48,738 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115 Time elapsed: 00:00:03
2018-02-08 13:33:49,016 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850 Time elapsed: 00:00:03
2018-02-08 13:33:49,370 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007 Time elapsed: 00:00:03
2018-02-08 13:33:49,635 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578 Time elapsed: 00:00:04
2018-02-08 13:33:49,894 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063 Time elapsed: 00:00:04
2018-02-08 13:33:50,160 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541 Time elapsed: 00:00:04
2018-02-08 13:33:50,506 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331 Time elapsed: 00:00:04
2018-02-08 13:33:50,773 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885 Time elapsed: 00:00:05
2018-02-08 13:33:51,040 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402 Time elapsed: 00:00:05
2018-02-08 13:33:51,305 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876 Time elapsed: 00:00:05
2018-02-08 13:33:51,661 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261 Time elapsed: 00:00:06
2018-02-08 13:33:51,942 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771 Time elapsed: 00:00:06
2018-02-08 13:33:52,208 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434 Time elapsed: 00:00:06
2018-02-08 13:33:52,472 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230 Time elapsed: 00:00:06
2018-02-08 13:33:52,826 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620 Time elapsed: 00:00:07
2018-02-08 13:33:53,083 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672 Time elapsed: 00:00:07
2018-02-08 13:33:53,344 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298 Time elapsed: 00:00:07
2018-02-08 13:33:53,611 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529 Time elapsed: 00:00:07
2018-02-08 13:33:54,021 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410 Time elapsed: 00:00:08
2018-02-08 13:33:54,298 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609 Time elapsed: 00:00:08
2018-02-08 13:33:54,569 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099 Time elapsed: 00:00:08
2018-02-08 13:33:54,845 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653 Time elapsed: 00:00:09
2018-02-08 13:33:55,202 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570 Time elapsed: 00:00:09
2018-02-08 13:33:55,456 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963 Time elapsed: 00:00:09
2018-02-08 13:33:55,725 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815 Time elapsed: 00:00:10
2018-02-08 13:33:56,003 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999 Time elapsed: 00:00:10
2018-02-08 13:33:56,357 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695 Time elapsed: 00:00:10
2018-02-08 13:33:56,629 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245 Time elapsed: 00:00:11
2018-02-08 13:33:56,899 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415 Time elapsed: 00:00:11
2018-02-08 13:33:57,164 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328 Time elapsed: 00:00:11
2018-02-08 13:33:57,433 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049 Time elapsed: 00:00:11
2018-02-08 13:33:57,532 __main__ [INFO ] End of training
2018-02-08 13:33:57,688 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:33:57,689 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:33:58,009 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945 Time elapsed: 00:00:00
2018-02-08 13:33:58,293 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585 Time elapsed: 00:00:00
2018-02-08 13:33:58,589 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036 Time elapsed: 00:00:00
2018-02-08 13:33:58,860 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844 Time elapsed: 00:00:01
2018-02-08 13:33:59,142 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920 Time elapsed: 00:00:01
2018-02-08 13:33:59,414 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863 Time elapsed: 00:00:01
2018-02-08 13:33:59,795 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650 Time elapsed: 00:00:02
2018-02-08 13:34:00,068 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923 Time elapsed: 00:00:02
2018-02-08 13:34:00,349 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288 Time elapsed: 00:00:02
2018-02-08 13:34:00,618 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297 Time elapsed: 00:00:02
2018-02-08 13:34:00,890 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633 Time elapsed: 00:00:03
2018-02-08 13:34:01,159 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329 Time elapsed: 00:00:03
2018-02-08 13:34:01,519 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222 Time elapsed: 00:00:03
2018-02-08 13:34:01,794 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798 Time elapsed: 00:00:04
2018-02-08 13:34:02,062 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300 Time elapsed: 00:00:04
2018-02-08 13:34:02,328 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864 Time elapsed: 00:00:04
2018-02-08 13:34:02,597 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590 Time elapsed: 00:00:04
2018-02-08 13:34:02,862 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607 Time elapsed: 00:00:05
2018-02-08 13:34:03,243 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056 Time elapsed: 00:00:05
2018-02-08 13:34:03,531 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954 Time elapsed: 00:00:05
2018-02-08 13:34:03,843 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403 Time elapsed: 00:00:06
2018-02-08 13:34:04,237 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444 Time elapsed: 00:00:06
2018-02-08 13:34:04,528 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682 Time elapsed: 00:00:06
2018-02-08 13:34:04,873 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167 Time elapsed: 00:00:07
2018-02-08 13:34:05,254 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971 Time elapsed: 00:00:07
2018-02-08 13:34:05,558 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051 Time elapsed: 00:00:07
2018-02-08 13:34:05,843 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551 Time elapsed: 00:00:08
2018-02-08 13:34:06,113 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389 Time elapsed: 00:00:08
2018-02-08 13:34:06,383 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053 Time elapsed: 00:00:08
2018-02-08 13:34:06,660 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556 Time elapsed: 00:00:08
2018-02-08 13:34:07,024 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131 Time elapsed: 00:00:09
2018-02-08 13:34:07,308 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897 Time elapsed: 00:00:09
2018-02-08 13:34:07,611 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355 Time elapsed: 00:00:09
2018-02-08 13:34:07,925 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367 Time elapsed: 00:00:10
2018-02-08 13:34:08,260 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858 Time elapsed: 00:00:10
2018-02-08 13:34:08,582 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398 Time elapsed: 00:00:10
2018-02-08 13:34:09,014 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153 Time elapsed: 00:00:11
2018-02-08 13:34:09,328 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232 Time elapsed: 00:00:11
2018-02-08 13:34:09,616 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708 Time elapsed: 00:00:11
2018-02-08 13:34:09,901 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540 Time elapsed: 00:00:12
2018-02-08 13:34:10,182 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636 Time elapsed: 00:00:12
2018-02-08 13:34:10,482 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333 Time elapsed: 00:00:12
2018-02-08 13:34:10,965 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953 Time elapsed: 00:00:13
2018-02-08 13:34:11,253 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544 Time elapsed: 00:00:13
2018-02-08 13:34:11,562 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447 Time elapsed: 00:00:13
2018-02-08 13:34:11,875 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667 Time elapsed: 00:00:14
2018-02-08 13:34:12,151 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969 Time elapsed: 00:00:14
2018-02-08 13:34:12,416 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715 Time elapsed: 00:00:14
2018-02-08 13:34:12,683 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796 Time elapsed: 00:00:14
2018-02-08 13:34:13,074 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617 Time elapsed: 00:00:15
2018-02-08 13:34:13,375 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010 Time elapsed: 00:00:15
2018-02-08 13:34:13,670 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204 Time elapsed: 00:00:15
2018-02-08 13:34:13,956 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228 Time elapsed: 00:00:16
2018-02-08 13:34:14,246 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751 Time elapsed: 00:00:16
2018-02-08 13:34:14,581 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178 Time elapsed: 00:00:16
2018-02-08 13:34:14,972 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059 Time elapsed: 00:00:17
2018-02-08 13:34:15,252 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651 Time elapsed: 00:00:17
2018-02-08 13:34:15,549 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126 Time elapsed: 00:00:17
2018-02-08 13:34:15,839 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984 Time elapsed: 00:00:18
2018-02-08 13:34:16,156 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388 Time elapsed: 00:00:18
2018-02-08 13:34:16,440 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202 Time elapsed: 00:00:18
2018-02-08 13:34:16,604 __main__ [INFO ] End of training
2018-02-08 13:37:47,210 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:37:47,212 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:37:47,215 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:37:47,216 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:37:50,062 training [INFO ] Epoch  1 Batch   50 Training err. 4.02924 Training err. RA 4.02924 Valid. err. 3.50107 Time elapsed: 00:00:00
2018-02-08 13:37:50,308 training [INFO ] Epoch  1 Batch  100 Training err. 3.38998 Training err. RA 3.70961 Valid. err. 3.29622 Time elapsed: 00:00:00
2018-02-08 13:37:50,564 training [INFO ] Epoch  1 Batch  150 Training err. 3.27811 Training err. RA 3.56578 Valid. err. 3.28161 Time elapsed: 00:00:00
2018-02-08 13:37:50,814 training [INFO ] Epoch  1 Batch  200 Training err. 3.26574 Training err. RA 3.49077 Valid. err. 3.25301 Time elapsed: 00:00:01
2018-02-08 13:37:51,084 training [INFO ] Epoch  1 Batch  250 Training err. 3.22035 Training err. RA 3.43668 Valid. err. 3.25603 Time elapsed: 00:00:01
2018-02-08 13:37:51,336 training [INFO ] Epoch  1 Batch  300 Training err. 3.26906 Training err. RA 3.40875 Valid. err. 3.21983 Time elapsed: 00:00:01
2018-02-08 13:37:51,729 training [INFO ] Epoch  2 Batch  350 Training err. 3.22545 Training err. RA 3.38256 Valid. err. 3.23166 Time elapsed: 00:00:02
2018-02-08 13:37:51,984 training [INFO ] Epoch  2 Batch  400 Training err. 3.22524 Training err. RA 3.36290 Valid. err. 3.23806 Time elapsed: 00:00:02
2018-02-08 13:37:52,235 training [INFO ] Epoch  2 Batch  450 Training err. 3.21281 Training err. RA 3.34622 Valid. err. 3.20397 Time elapsed: 00:00:02
2018-02-08 13:37:52,477 training [INFO ] Epoch  2 Batch  500 Training err. 3.20212 Training err. RA 3.33181 Valid. err. 3.20822 Time elapsed: 00:00:02
2018-02-08 13:37:52,731 training [INFO ] Epoch  2 Batch  550 Training err. 3.17980 Training err. RA 3.31799 Valid. err. 3.21297 Time elapsed: 00:00:03
2018-02-08 13:37:52,976 training [INFO ] Epoch  2 Batch  600 Training err. 3.19674 Training err. RA 3.30789 Valid. err. 3.15445 Time elapsed: 00:00:03
2018-02-08 13:37:53,349 training [INFO ] Epoch  3 Batch  650 Training err. 3.16628 Training err. RA 3.29699 Valid. err. 3.14860 Time elapsed: 00:00:03
2018-02-08 13:37:53,623 training [INFO ] Epoch  3 Batch  700 Training err. 3.15257 Training err. RA 3.28668 Valid. err. 3.13866 Time elapsed: 00:00:03
2018-02-08 13:37:53,877 training [INFO ] Epoch  3 Batch  750 Training err. 3.09185 Training err. RA 3.27369 Valid. err. 3.10190 Time elapsed: 00:00:04
2018-02-08 13:37:54,139 training [INFO ] Epoch  3 Batch  800 Training err. 3.10672 Training err. RA 3.26325 Valid. err. 3.09152 Time elapsed: 00:00:04
2018-02-08 13:37:54,396 training [INFO ] Epoch  3 Batch  850 Training err. 3.04509 Training err. RA 3.25042 Valid. err. 3.13093 Time elapsed: 00:00:04
2018-02-08 13:37:54,665 training [INFO ] Epoch  3 Batch  900 Training err. 3.09644 Training err. RA 3.24187 Valid. err. 3.02134 Time elapsed: 00:00:05
2018-02-08 13:37:55,018 training [INFO ] Epoch  4 Batch  950 Training err. 3.07371 Training err. RA 3.23302 Valid. err. 3.10700 Time elapsed: 00:00:05
2018-02-08 13:37:55,276 training [INFO ] Epoch  4 Batch 1000 Training err. 3.01480 Training err. RA 3.22211 Valid. err. 3.01108 Time elapsed: 00:00:05
2018-02-08 13:37:55,518 training [INFO ] Epoch  4 Batch 1050 Training err. 2.95937 Training err. RA 3.20959 Valid. err. 2.98590 Time elapsed: 00:00:05
2018-02-08 13:37:55,774 training [INFO ] Epoch  4 Batch 1100 Training err. 2.97275 Training err. RA 3.19883 Valid. err. 2.93336 Time elapsed: 00:00:06
2018-02-08 13:37:56,026 training [INFO ] Epoch  4 Batch 1150 Training err. 2.93714 Training err. RA 3.18745 Valid. err. 2.96206 Time elapsed: 00:00:06
2018-02-08 13:37:56,277 training [INFO ] Epoch  4 Batch 1200 Training err. 2.93710 Training err. RA 3.17702 Valid. err. 2.88082 Time elapsed: 00:00:06
2018-02-08 13:37:56,659 training [INFO ] Epoch  5 Batch 1250 Training err. 2.96627 Training err. RA 3.16859 Valid. err. 2.90873 Time elapsed: 00:00:07
2018-02-08 13:37:56,915 training [INFO ] Epoch  5 Batch 1300 Training err. 2.90832 Training err. RA 3.15858 Valid. err. 2.86239 Time elapsed: 00:00:07
2018-02-08 13:37:57,169 training [INFO ] Epoch  5 Batch 1350 Training err. 2.80906 Training err. RA 3.14563 Valid. err. 2.83121 Time elapsed: 00:00:07
2018-02-08 13:37:57,439 training [INFO ] Epoch  5 Batch 1400 Training err. 2.82390 Training err. RA 3.13414 Valid. err. 2.82085 Time elapsed: 00:00:07
2018-02-08 13:37:57,715 training [INFO ] Epoch  5 Batch 1450 Training err. 2.82684 Training err. RA 3.12355 Valid. err. 2.79272 Time elapsed: 00:00:08
2018-02-08 13:37:57,989 training [INFO ] Epoch  5 Batch 1500 Training err. 2.78616 Training err. RA 3.11230 Valid. err. 2.75141 Time elapsed: 00:00:08
2018-02-08 13:37:58,358 training [INFO ] Epoch  6 Batch 1550 Training err. 2.86394 Training err. RA 3.10429 Valid. err. 2.74880 Time elapsed: 00:00:08
2018-02-08 13:37:58,605 training [INFO ] Epoch  6 Batch 1600 Training err. 2.79999 Training err. RA 3.09478 Valid. err. 2.78731 Time elapsed: 00:00:08
2018-02-08 13:37:58,861 training [INFO ] Epoch  6 Batch 1650 Training err. 2.72479 Training err. RA 3.08357 Valid. err. 2.73017 Time elapsed: 00:00:09
2018-02-08 13:37:59,122 training [INFO ] Epoch  6 Batch 1700 Training err. 2.69996 Training err. RA 3.07229 Valid. err. 2.72373 Time elapsed: 00:00:09
2018-02-08 13:37:59,369 training [INFO ] Epoch  6 Batch 1750 Training err. 2.76850 Training err. RA 3.06361 Valid. err. 2.70823 Time elapsed: 00:00:09
2018-02-08 13:37:59,624 training [INFO ] Epoch  6 Batch 1800 Training err. 2.67913 Training err. RA 3.05293 Valid. err. 2.68483 Time elapsed: 00:00:09
2018-02-08 13:37:59,968 training [INFO ] Epoch  7 Batch 1850 Training err. 2.77647 Training err. RA 3.04545 Valid. err. 2.67897 Time elapsed: 00:00:10
2018-02-08 13:38:00,223 training [INFO ] Epoch  7 Batch 1900 Training err. 2.75048 Training err. RA 3.03769 Valid. err. 2.65744 Time elapsed: 00:00:10
2018-02-08 13:38:00,475 training [INFO ] Epoch  7 Batch 1950 Training err. 2.63949 Training err. RA 3.02748 Valid. err. 2.64302 Time elapsed: 00:00:10
2018-02-08 13:38:00,728 training [INFO ] Epoch  7 Batch 2000 Training err. 2.61810 Training err. RA 3.01725 Valid. err. 2.62606 Time elapsed: 00:00:11
2018-02-08 13:38:00,984 training [INFO ] Epoch  7 Batch 2050 Training err. 2.71832 Training err. RA 3.00996 Valid. err. 2.61228 Time elapsed: 00:00:11
2018-02-08 13:38:01,236 training [INFO ] Epoch  7 Batch 2100 Training err. 2.59571 Training err. RA 3.00009 Valid. err. 2.58975 Time elapsed: 00:00:11
2018-02-08 13:38:01,575 training [INFO ] Epoch  8 Batch 2150 Training err. 2.66367 Training err. RA 2.99227 Valid. err. 2.58746 Time elapsed: 00:00:11
2018-02-08 13:38:01,842 training [INFO ] Epoch  8 Batch 2200 Training err. 2.72985 Training err. RA 2.98630 Valid. err. 2.58865 Time elapsed: 00:00:12
2018-02-08 13:38:02,103 training [INFO ] Epoch  8 Batch 2250 Training err. 2.59773 Training err. RA 2.97767 Valid. err. 2.58223 Time elapsed: 00:00:12
2018-02-08 13:38:02,349 training [INFO ] Epoch  8 Batch 2300 Training err. 2.57422 Training err. RA 2.96890 Valid. err. 2.56809 Time elapsed: 00:00:12
2018-02-08 13:38:02,605 training [INFO ] Epoch  8 Batch 2350 Training err. 2.63299 Training err. RA 2.96175 Valid. err. 2.57190 Time elapsed: 00:00:12
2018-02-08 13:38:02,853 training [INFO ] Epoch  8 Batch 2400 Training err. 2.52540 Training err. RA 2.95266 Valid. err. 2.53370 Time elapsed: 00:00:13
2018-02-08 13:38:03,110 training [INFO ] Epoch  8 Batch 2450 Training err. 2.60708 Training err. RA 2.94561 Valid. err. 2.54697 Time elapsed: 00:00:13
2018-02-08 13:38:03,451 training [INFO ] Epoch  9 Batch 2500 Training err. 2.64330 Training err. RA 2.93956 Valid. err. 2.55896 Time elapsed: 00:00:13
2018-02-08 13:38:03,706 training [INFO ] Epoch  9 Batch 2550 Training err. 2.60500 Training err. RA 2.93300 Valid. err. 2.52046 Time elapsed: 00:00:14
2018-02-08 13:38:03,958 training [INFO ] Epoch  9 Batch 2600 Training err. 2.52330 Training err. RA 2.92512 Valid. err. 2.50329 Time elapsed: 00:00:14
2018-02-08 13:38:04,212 training [INFO ] Epoch  9 Batch 2650 Training err. 2.58428 Training err. RA 2.91869 Valid. err. 2.53347 Time elapsed: 00:00:14
2018-02-08 13:38:04,472 training [INFO ] Epoch  9 Batch 2700 Training err. 2.47289 Training err. RA 2.91044 Valid. err. 2.51146 Time elapsed: 00:00:14
2018-02-08 13:38:04,718 training [INFO ] Epoch  9 Batch 2750 Training err. 2.53371 Training err. RA 2.90359 Valid. err. 2.47382 Time elapsed: 00:00:15
2018-02-08 13:38:05,059 training [INFO ] Epoch 10 Batch 2800 Training err. 2.57744 Training err. RA 2.89776 Valid. err. 2.51909 Time elapsed: 00:00:15
2018-02-08 13:38:05,306 training [INFO ] Epoch 10 Batch 2850 Training err. 2.58317 Training err. RA 2.89224 Valid. err. 2.48869 Time elapsed: 00:00:15
2018-02-08 13:38:05,555 training [INFO ] Epoch 10 Batch 2900 Training err. 2.47399 Training err. RA 2.88503 Valid. err. 2.46066 Time elapsed: 00:00:15
2018-02-08 13:38:05,810 training [INFO ] Epoch 10 Batch 2950 Training err. 2.52777 Training err. RA 2.87898 Valid. err. 2.48288 Time elapsed: 00:00:16
2018-02-08 13:38:06,057 training [INFO ] Epoch 10 Batch 3000 Training err. 2.44897 Training err. RA 2.87181 Valid. err. 2.43163 Time elapsed: 00:00:16
2018-02-08 13:38:06,297 training [INFO ] Epoch 10 Batch 3050 Training err. 2.47688 Training err. RA 2.86534 Valid. err. 2.42658 Time elapsed: 00:00:16
2018-02-08 13:38:06,449 __main__ [INFO ] End of training
2018-02-08 13:38:06,854 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:38:06,855 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:38:07,141 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004 Time elapsed: 00:00:00
2018-02-08 13:38:07,416 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220 Time elapsed: 00:00:00
2018-02-08 13:38:07,680 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708 Time elapsed: 00:00:00
2018-02-08 13:38:07,949 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226 Time elapsed: 00:00:01
2018-02-08 13:38:08,305 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791 Time elapsed: 00:00:01
2018-02-08 13:38:08,564 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095 Time elapsed: 00:00:01
2018-02-08 13:38:08,831 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617 Time elapsed: 00:00:01
2018-02-08 13:38:09,088 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091 Time elapsed: 00:00:02
2018-02-08 13:38:09,431 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571 Time elapsed: 00:00:02
2018-02-08 13:38:09,686 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752 Time elapsed: 00:00:02
2018-02-08 13:38:09,944 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115 Time elapsed: 00:00:03
2018-02-08 13:38:10,198 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850 Time elapsed: 00:00:03
2018-02-08 13:38:10,545 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007 Time elapsed: 00:00:03
2018-02-08 13:38:10,808 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578 Time elapsed: 00:00:03
2018-02-08 13:38:11,067 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063 Time elapsed: 00:00:04
2018-02-08 13:38:11,323 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541 Time elapsed: 00:00:04
2018-02-08 13:38:11,675 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331 Time elapsed: 00:00:04
2018-02-08 13:38:11,937 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885 Time elapsed: 00:00:05
2018-02-08 13:38:12,206 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402 Time elapsed: 00:00:05
2018-02-08 13:38:12,471 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876 Time elapsed: 00:00:05
2018-02-08 13:38:12,831 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261 Time elapsed: 00:00:05
2018-02-08 13:38:13,102 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771 Time elapsed: 00:00:06
2018-02-08 13:38:13,371 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434 Time elapsed: 00:00:06
2018-02-08 13:38:13,643 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230 Time elapsed: 00:00:06
2018-02-08 13:38:13,996 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620 Time elapsed: 00:00:07
2018-02-08 13:38:14,260 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672 Time elapsed: 00:00:07
2018-02-08 13:38:14,516 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298 Time elapsed: 00:00:07
2018-02-08 13:38:14,783 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529 Time elapsed: 00:00:07
2018-02-08 13:38:15,126 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410 Time elapsed: 00:00:08
2018-02-08 13:38:15,385 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609 Time elapsed: 00:00:08
2018-02-08 13:38:15,669 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099 Time elapsed: 00:00:08
2018-02-08 13:38:15,940 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653 Time elapsed: 00:00:09
2018-02-08 13:38:16,286 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570 Time elapsed: 00:00:09
2018-02-08 13:38:16,553 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963 Time elapsed: 00:00:09
2018-02-08 13:38:16,825 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815 Time elapsed: 00:00:09
2018-02-08 13:38:17,091 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999 Time elapsed: 00:00:10
2018-02-08 13:38:17,445 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695 Time elapsed: 00:00:10
2018-02-08 13:38:17,719 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245 Time elapsed: 00:00:10
2018-02-08 13:38:17,979 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415 Time elapsed: 00:00:11
2018-02-08 13:38:18,250 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328 Time elapsed: 00:00:11
2018-02-08 13:38:18,518 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049 Time elapsed: 00:00:11
2018-02-08 13:38:18,596 __main__ [INFO ] End of training
2018-02-08 13:38:18,750 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:38:18,751 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:38:19,059 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945 Time elapsed: 00:00:00
2018-02-08 13:38:19,327 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585 Time elapsed: 00:00:00
2018-02-08 13:38:19,596 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036 Time elapsed: 00:00:00
2018-02-08 13:38:19,873 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844 Time elapsed: 00:00:01
2018-02-08 13:38:20,146 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920 Time elapsed: 00:00:01
2018-02-08 13:38:20,419 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863 Time elapsed: 00:00:01
2018-02-08 13:38:20,789 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650 Time elapsed: 00:00:02
2018-02-08 13:38:21,048 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923 Time elapsed: 00:00:02
2018-02-08 13:38:21,314 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288 Time elapsed: 00:00:02
2018-02-08 13:38:21,581 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297 Time elapsed: 00:00:02
2018-02-08 13:38:21,848 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633 Time elapsed: 00:00:03
2018-02-08 13:38:22,126 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329 Time elapsed: 00:00:03
2018-02-08 13:38:22,492 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222 Time elapsed: 00:00:03
2018-02-08 13:38:22,765 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798 Time elapsed: 00:00:04
2018-02-08 13:38:23,034 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300 Time elapsed: 00:00:04
2018-02-08 13:38:23,310 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864 Time elapsed: 00:00:04
2018-02-08 13:38:23,577 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590 Time elapsed: 00:00:04
2018-02-08 13:38:23,850 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607 Time elapsed: 00:00:05
2018-02-08 13:38:24,207 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056 Time elapsed: 00:00:05
2018-02-08 13:38:24,466 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954 Time elapsed: 00:00:05
2018-02-08 13:38:24,730 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403 Time elapsed: 00:00:05
2018-02-08 13:38:25,019 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444 Time elapsed: 00:00:06
2018-02-08 13:38:25,279 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682 Time elapsed: 00:00:06
2018-02-08 13:38:25,544 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167 Time elapsed: 00:00:06
2018-02-08 13:38:25,910 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971 Time elapsed: 00:00:07
2018-02-08 13:38:26,173 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051 Time elapsed: 00:00:07
2018-02-08 13:38:26,437 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551 Time elapsed: 00:00:07
2018-02-08 13:38:26,705 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389 Time elapsed: 00:00:07
2018-02-08 13:38:26,964 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053 Time elapsed: 00:00:08
2018-02-08 13:38:27,230 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556 Time elapsed: 00:00:08
2018-02-08 13:38:27,583 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131 Time elapsed: 00:00:08
2018-02-08 13:38:27,858 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897 Time elapsed: 00:00:09
2018-02-08 13:38:28,139 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355 Time elapsed: 00:00:09
2018-02-08 13:38:28,411 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367 Time elapsed: 00:00:09
2018-02-08 13:38:28,681 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858 Time elapsed: 00:00:09
2018-02-08 13:38:28,956 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398 Time elapsed: 00:00:10
2018-02-08 13:38:29,319 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153 Time elapsed: 00:00:10
2018-02-08 13:38:29,584 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232 Time elapsed: 00:00:10
2018-02-08 13:38:29,866 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708 Time elapsed: 00:00:11
2018-02-08 13:38:30,143 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540 Time elapsed: 00:00:11
2018-02-08 13:38:30,412 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636 Time elapsed: 00:00:11
2018-02-08 13:38:30,696 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333 Time elapsed: 00:00:11
2018-02-08 13:38:31,522 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953 Time elapsed: 00:00:12
2018-02-08 13:38:31,797 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544 Time elapsed: 00:00:13
2018-02-08 13:38:32,074 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447 Time elapsed: 00:00:13
2018-02-08 13:38:32,348 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667 Time elapsed: 00:00:13
2018-02-08 13:38:32,610 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969 Time elapsed: 00:00:13
2018-02-08 13:38:32,878 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715 Time elapsed: 00:00:14
2018-02-08 13:38:33,149 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796 Time elapsed: 00:00:14
2018-02-08 13:38:33,507 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617 Time elapsed: 00:00:14
2018-02-08 13:38:33,775 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010 Time elapsed: 00:00:15
2018-02-08 13:38:34,050 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204 Time elapsed: 00:00:15
2018-02-08 13:38:34,316 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228 Time elapsed: 00:00:15
2018-02-08 13:38:34,584 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751 Time elapsed: 00:00:15
2018-02-08 13:38:34,853 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178 Time elapsed: 00:00:16
2018-02-08 13:38:35,212 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059 Time elapsed: 00:00:16
2018-02-08 13:38:35,478 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651 Time elapsed: 00:00:16
2018-02-08 13:38:35,749 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126 Time elapsed: 00:00:16
2018-02-08 13:38:36,012 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984 Time elapsed: 00:00:17
2018-02-08 13:38:36,281 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388 Time elapsed: 00:00:17
2018-02-08 13:38:36,545 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202 Time elapsed: 00:00:17
2018-02-08 13:38:36,713 __main__ [INFO ] End of training
2018-02-08 13:42:23,329 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:42:23,360 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:42:23,363 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:42:23,364 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:42:27,250 training [INFO ] Epoch  1 Batch   50 Training err. 4.00557 Training err. RA 4.00557 Valid. err. 3.48398 Time elapsed: 00:00:00
2018-02-08 13:42:27,504 training [INFO ] Epoch  1 Batch  100 Training err. 3.38714 Training err. RA 3.69635 Valid. err. 3.29693 Time elapsed: 00:00:00
2018-02-08 13:42:27,752 training [INFO ] Epoch  1 Batch  150 Training err. 3.27903 Training err. RA 3.55724 Valid. err. 3.28478 Time elapsed: 00:00:00
2018-02-08 13:42:28,004 training [INFO ] Epoch  1 Batch  200 Training err. 3.26694 Training err. RA 3.48467 Valid. err. 3.25711 Time elapsed: 00:00:01
2018-02-08 13:42:28,255 training [INFO ] Epoch  1 Batch  250 Training err. 3.22302 Training err. RA 3.43234 Valid. err. 3.25932 Time elapsed: 00:00:01
2018-02-08 13:42:28,501 training [INFO ] Epoch  1 Batch  300 Training err. 3.27091 Training err. RA 3.40544 Valid. err. 3.22235 Time elapsed: 00:00:01
2018-02-08 13:42:28,871 training [INFO ] Epoch  2 Batch  350 Training err. 3.22708 Training err. RA 3.37996 Valid. err. 3.23641 Time elapsed: 00:00:02
2018-02-08 13:42:29,118 training [INFO ] Epoch  2 Batch  400 Training err. 3.22883 Training err. RA 3.36106 Valid. err. 3.24270 Time elapsed: 00:00:02
2018-02-08 13:42:29,357 training [INFO ] Epoch  2 Batch  450 Training err. 3.21708 Training err. RA 3.34507 Valid. err. 3.21119 Time elapsed: 00:00:02
2018-02-08 13:42:29,598 training [INFO ] Epoch  2 Batch  500 Training err. 3.20840 Training err. RA 3.33140 Valid. err. 3.22021 Time elapsed: 00:00:02
2018-02-08 13:42:29,840 training [INFO ] Epoch  2 Batch  550 Training err. 3.19217 Training err. RA 3.31874 Valid. err. 3.22075 Time elapsed: 00:00:03
2018-02-08 13:42:30,088 training [INFO ] Epoch  2 Batch  600 Training err. 3.21211 Training err. RA 3.30986 Valid. err. 3.17624 Time elapsed: 00:00:03
2018-02-08 13:42:30,453 training [INFO ] Epoch  3 Batch  650 Training err. 3.18726 Training err. RA 3.30043 Valid. err. 3.18480 Time elapsed: 00:00:03
2018-02-08 13:42:30,700 training [INFO ] Epoch  3 Batch  700 Training err. 3.18029 Training err. RA 3.29185 Valid. err. 3.17333 Time elapsed: 00:00:03
2018-02-08 13:42:30,955 training [INFO ] Epoch  3 Batch  750 Training err. 3.13680 Training err. RA 3.28151 Valid. err. 3.14519 Time elapsed: 00:00:04
2018-02-08 13:42:31,203 training [INFO ] Epoch  3 Batch  800 Training err. 3.14610 Training err. RA 3.27305 Valid. err. 3.11890 Time elapsed: 00:00:04
2018-02-08 13:42:31,468 training [INFO ] Epoch  3 Batch  850 Training err. 3.09031 Training err. RA 3.26230 Valid. err. 3.13257 Time elapsed: 00:00:04
2018-02-08 13:42:31,722 training [INFO ] Epoch  3 Batch  900 Training err. 3.13266 Training err. RA 3.25509 Valid. err. 3.06029 Time elapsed: 00:00:04
2018-02-08 13:42:32,068 training [INFO ] Epoch  4 Batch  950 Training err. 3.09806 Training err. RA 3.24683 Valid. err. 3.10612 Time elapsed: 00:00:05
2018-02-08 13:42:32,309 training [INFO ] Epoch  4 Batch 1000 Training err. 3.03138 Training err. RA 3.23606 Valid. err. 3.00200 Time elapsed: 00:00:05
2018-02-08 13:42:32,627 training [INFO ] Epoch  4 Batch 1050 Training err. 2.97144 Training err. RA 3.22346 Valid. err. 2.98352 Time elapsed: 00:00:05
2018-02-08 13:42:32,883 training [INFO ] Epoch  4 Batch 1100 Training err. 2.96006 Training err. RA 3.21148 Valid. err. 2.91469 Time elapsed: 00:00:06
2018-02-08 13:42:33,133 training [INFO ] Epoch  4 Batch 1150 Training err. 2.91060 Training err. RA 3.19840 Valid. err. 2.96271 Time elapsed: 00:00:06
2018-02-08 13:42:33,381 training [INFO ] Epoch  4 Batch 1200 Training err. 2.91926 Training err. RA 3.18677 Valid. err. 2.86259 Time elapsed: 00:00:06
2018-02-08 13:42:33,739 training [INFO ] Epoch  5 Batch 1250 Training err. 2.94904 Training err. RA 3.17726 Valid. err. 2.93614 Time elapsed: 00:00:06
2018-02-08 13:42:33,998 training [INFO ] Epoch  5 Batch 1300 Training err. 2.88275 Training err. RA 3.16593 Valid. err. 2.84100 Time elapsed: 00:00:07
2018-02-08 13:42:34,246 training [INFO ] Epoch  5 Batch 1350 Training err. 2.79315 Training err. RA 3.15213 Valid. err. 2.80879 Time elapsed: 00:00:07
2018-02-08 13:42:34,499 training [INFO ] Epoch  5 Batch 1400 Training err. 2.80843 Training err. RA 3.13985 Valid. err. 2.78132 Time elapsed: 00:00:07
2018-02-08 13:42:34,754 training [INFO ] Epoch  5 Batch 1450 Training err. 2.81000 Training err. RA 3.12848 Valid. err. 2.76690 Time elapsed: 00:00:07
2018-02-08 13:42:35,003 training [INFO ] Epoch  5 Batch 1500 Training err. 2.76896 Training err. RA 3.11649 Valid. err. 2.72641 Time elapsed: 00:00:08
2018-02-08 13:42:35,345 training [INFO ] Epoch  6 Batch 1550 Training err. 2.84835 Training err. RA 3.10784 Valid. err. 2.72677 Time elapsed: 00:00:08
2018-02-08 13:42:35,593 training [INFO ] Epoch  6 Batch 1600 Training err. 2.78168 Training err. RA 3.09765 Valid. err. 2.77181 Time elapsed: 00:00:08
2018-02-08 13:42:35,840 training [INFO ] Epoch  6 Batch 1650 Training err. 2.70593 Training err. RA 3.08578 Valid. err. 2.69299 Time elapsed: 00:00:09
2018-02-08 13:42:36,093 training [INFO ] Epoch  6 Batch 1700 Training err. 2.67776 Training err. RA 3.07378 Valid. err. 2.69678 Time elapsed: 00:00:09
2018-02-08 13:42:36,337 training [INFO ] Epoch  6 Batch 1750 Training err. 2.74859 Training err. RA 3.06449 Valid. err. 2.66705 Time elapsed: 00:00:09
2018-02-08 13:42:36,584 training [INFO ] Epoch  6 Batch 1800 Training err. 2.65122 Training err. RA 3.05301 Valid. err. 2.65134 Time elapsed: 00:00:09
2018-02-08 13:42:36,942 training [INFO ] Epoch  7 Batch 1850 Training err. 2.74894 Training err. RA 3.04479 Valid. err. 2.67937 Time elapsed: 00:00:10
2018-02-08 13:42:37,186 training [INFO ] Epoch  7 Batch 1900 Training err. 2.72901 Training err. RA 3.03648 Valid. err. 2.62862 Time elapsed: 00:00:10
2018-02-08 13:42:37,436 training [INFO ] Epoch  7 Batch 1950 Training err. 2.61894 Training err. RA 3.02578 Valid. err. 2.60147 Time elapsed: 00:00:10
2018-02-08 13:42:37,682 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59225 Training err. RA 3.01494 Valid. err. 2.58621 Time elapsed: 00:00:10
2018-02-08 13:42:37,947 training [INFO ] Epoch  7 Batch 2050 Training err. 2.69335 Training err. RA 3.00709 Valid. err. 2.57576 Time elapsed: 00:00:11
2018-02-08 13:42:38,195 training [INFO ] Epoch  7 Batch 2100 Training err. 2.56456 Training err. RA 2.99656 Valid. err. 2.55618 Time elapsed: 00:00:11
2018-02-08 13:42:38,538 training [INFO ] Epoch  8 Batch 2150 Training err. 2.63806 Training err. RA 2.98822 Valid. err. 2.54187 Time elapsed: 00:00:11
2018-02-08 13:42:38,791 training [INFO ] Epoch  8 Batch 2200 Training err. 2.70655 Training err. RA 2.98182 Valid. err. 2.54412 Time elapsed: 00:00:11
2018-02-08 13:42:39,031 training [INFO ] Epoch  8 Batch 2250 Training err. 2.57617 Training err. RA 2.97280 Valid. err. 2.53784 Time elapsed: 00:00:12
2018-02-08 13:42:39,274 training [INFO ] Epoch  8 Batch 2300 Training err. 2.54468 Training err. RA 2.96350 Valid. err. 2.53765 Time elapsed: 00:00:12
2018-02-08 13:42:39,525 training [INFO ] Epoch  8 Batch 2350 Training err. 2.60743 Training err. RA 2.95592 Valid. err. 2.53949 Time elapsed: 00:00:12
2018-02-08 13:42:39,777 training [INFO ] Epoch  8 Batch 2400 Training err. 2.49532 Training err. RA 2.94633 Valid. err. 2.50447 Time elapsed: 00:00:12
2018-02-08 13:42:40,039 training [INFO ] Epoch  8 Batch 2450 Training err. 2.57682 Training err. RA 2.93878 Valid. err. 2.53894 Time elapsed: 00:00:13
2018-02-08 13:42:40,386 training [INFO ] Epoch  9 Batch 2500 Training err. 2.61956 Training err. RA 2.93240 Valid. err. 2.53614 Time elapsed: 00:00:13
2018-02-08 13:42:40,631 training [INFO ] Epoch  9 Batch 2550 Training err. 2.58512 Training err. RA 2.92559 Valid. err. 2.48789 Time elapsed: 00:00:13
2018-02-08 13:42:40,886 training [INFO ] Epoch  9 Batch 2600 Training err. 2.49736 Training err. RA 2.91736 Valid. err. 2.47615 Time elapsed: 00:00:14
2018-02-08 13:42:41,135 training [INFO ] Epoch  9 Batch 2650 Training err. 2.55915 Training err. RA 2.91060 Valid. err. 2.48884 Time elapsed: 00:00:14
2018-02-08 13:42:41,389 training [INFO ] Epoch  9 Batch 2700 Training err. 2.44949 Training err. RA 2.90206 Valid. err. 2.49664 Time elapsed: 00:00:14
2018-02-08 13:42:41,637 training [INFO ] Epoch  9 Batch 2750 Training err. 2.50184 Training err. RA 2.89478 Valid. err. 2.45426 Time elapsed: 00:00:14
2018-02-08 13:42:41,988 training [INFO ] Epoch 10 Batch 2800 Training err. 2.55448 Training err. RA 2.88870 Valid. err. 2.48566 Time elapsed: 00:00:15
2018-02-08 13:42:42,238 training [INFO ] Epoch 10 Batch 2850 Training err. 2.56711 Training err. RA 2.88306 Valid. err. 2.46091 Time elapsed: 00:00:15
2018-02-08 13:42:42,485 training [INFO ] Epoch 10 Batch 2900 Training err. 2.45253 Training err. RA 2.87564 Valid. err. 2.43154 Time elapsed: 00:00:15
2018-02-08 13:42:42,737 training [INFO ] Epoch 10 Batch 2950 Training err. 2.50563 Training err. RA 2.86937 Valid. err. 2.44928 Time elapsed: 00:00:15
2018-02-08 13:42:42,989 training [INFO ] Epoch 10 Batch 3000 Training err. 2.43191 Training err. RA 2.86208 Valid. err. 2.40811 Time elapsed: 00:00:16
2018-02-08 13:42:43,229 training [INFO ] Epoch 10 Batch 3050 Training err. 2.44569 Training err. RA 2.85525 Valid. err. 2.44433 Time elapsed: 00:00:16
2018-02-08 13:42:43,373 __main__ [INFO ] End of training
2018-02-08 13:42:43,779 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:42:43,779 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:42:44,097 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004 Time elapsed: 00:00:00
2018-02-08 13:42:44,362 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220 Time elapsed: 00:00:00
2018-02-08 13:42:44,630 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708 Time elapsed: 00:00:00
2018-02-08 13:42:44,912 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226 Time elapsed: 00:00:01
2018-02-08 13:42:45,273 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791 Time elapsed: 00:00:01
2018-02-08 13:42:45,566 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095 Time elapsed: 00:00:01
2018-02-08 13:42:45,836 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617 Time elapsed: 00:00:02
2018-02-08 13:42:46,107 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091 Time elapsed: 00:00:02
2018-02-08 13:42:46,475 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571 Time elapsed: 00:00:02
2018-02-08 13:42:46,749 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752 Time elapsed: 00:00:02
2018-02-08 13:42:47,026 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115 Time elapsed: 00:00:03
2018-02-08 13:42:47,302 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850 Time elapsed: 00:00:03
2018-02-08 13:42:47,666 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007 Time elapsed: 00:00:03
2018-02-08 13:42:47,944 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578 Time elapsed: 00:00:04
2018-02-08 13:42:48,219 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063 Time elapsed: 00:00:04
2018-02-08 13:42:48,485 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541 Time elapsed: 00:00:04
2018-02-08 13:42:48,850 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331 Time elapsed: 00:00:05
2018-02-08 13:42:49,136 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885 Time elapsed: 00:00:05
2018-02-08 13:42:49,399 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402 Time elapsed: 00:00:05
2018-02-08 13:42:49,674 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876 Time elapsed: 00:00:05
2018-02-08 13:42:50,044 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261 Time elapsed: 00:00:06
2018-02-08 13:42:50,316 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771 Time elapsed: 00:00:06
2018-02-08 13:42:50,590 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434 Time elapsed: 00:00:06
2018-02-08 13:42:50,866 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230 Time elapsed: 00:00:07
2018-02-08 13:42:51,532 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620 Time elapsed: 00:00:07
2018-02-08 13:42:51,831 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672 Time elapsed: 00:00:08
2018-02-08 13:42:52,115 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298 Time elapsed: 00:00:08
2018-02-08 13:42:52,392 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529 Time elapsed: 00:00:08
2018-02-08 13:42:52,773 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410 Time elapsed: 00:00:08
2018-02-08 13:42:53,071 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609 Time elapsed: 00:00:09
2018-02-08 13:42:53,360 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099 Time elapsed: 00:00:09
2018-02-08 13:42:53,653 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653 Time elapsed: 00:00:09
2018-02-08 13:42:54,035 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570 Time elapsed: 00:00:10
2018-02-08 13:42:54,351 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963 Time elapsed: 00:00:10
2018-02-08 13:42:54,651 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815 Time elapsed: 00:00:10
2018-02-08 13:42:54,983 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999 Time elapsed: 00:00:11
2018-02-08 13:42:55,378 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695 Time elapsed: 00:00:11
2018-02-08 13:42:55,660 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245 Time elapsed: 00:00:11
2018-02-08 13:42:55,959 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415 Time elapsed: 00:00:12
2018-02-08 13:42:56,239 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328 Time elapsed: 00:00:12
2018-02-08 13:42:56,510 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049 Time elapsed: 00:00:12
2018-02-08 13:42:56,591 __main__ [INFO ] End of training
2018-02-08 13:42:56,746 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:42:56,747 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:42:57,084 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945 Time elapsed: 00:00:00
2018-02-08 13:42:57,372 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585 Time elapsed: 00:00:00
2018-02-08 13:42:57,692 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036 Time elapsed: 00:00:00
2018-02-08 13:42:58,010 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844 Time elapsed: 00:00:01
2018-02-08 13:42:58,313 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920 Time elapsed: 00:00:01
2018-02-08 13:42:58,603 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863 Time elapsed: 00:00:01
2018-02-08 13:42:58,990 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650 Time elapsed: 00:00:02
2018-02-08 13:42:59,262 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923 Time elapsed: 00:00:02
2018-02-08 13:42:59,546 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288 Time elapsed: 00:00:02
2018-02-08 13:42:59,818 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297 Time elapsed: 00:00:03
2018-02-08 13:43:00,096 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633 Time elapsed: 00:00:03
2018-02-08 13:43:00,372 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329 Time elapsed: 00:00:03
2018-02-08 13:43:00,738 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222 Time elapsed: 00:00:03
2018-02-08 13:43:01,010 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798 Time elapsed: 00:00:04
2018-02-08 13:43:01,281 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300 Time elapsed: 00:00:04
2018-02-08 13:43:01,540 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864 Time elapsed: 00:00:04
2018-02-08 13:43:01,805 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590 Time elapsed: 00:00:05
2018-02-08 13:43:02,081 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607 Time elapsed: 00:00:05
2018-02-08 13:43:02,466 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056 Time elapsed: 00:00:05
2018-02-08 13:43:02,747 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954 Time elapsed: 00:00:05
2018-02-08 13:43:03,025 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403 Time elapsed: 00:00:06
2018-02-08 13:43:03,299 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444 Time elapsed: 00:00:06
2018-02-08 13:43:03,587 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682 Time elapsed: 00:00:06
2018-02-08 13:43:03,873 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167 Time elapsed: 00:00:07
2018-02-08 13:43:04,278 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971 Time elapsed: 00:00:07
2018-02-08 13:43:04,555 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051 Time elapsed: 00:00:07
2018-02-08 13:43:04,837 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551 Time elapsed: 00:00:08
2018-02-08 13:43:05,111 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389 Time elapsed: 00:00:08
2018-02-08 13:43:05,421 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053 Time elapsed: 00:00:08
2018-02-08 13:43:05,694 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556 Time elapsed: 00:00:08
2018-02-08 13:43:06,067 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131 Time elapsed: 00:00:09
2018-02-08 13:43:06,347 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897 Time elapsed: 00:00:09
2018-02-08 13:43:06,621 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355 Time elapsed: 00:00:09
2018-02-08 13:43:06,894 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367 Time elapsed: 00:00:10
2018-02-08 13:43:07,153 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858 Time elapsed: 00:00:10
2018-02-08 13:43:07,421 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398 Time elapsed: 00:00:10
2018-02-08 13:43:07,796 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153 Time elapsed: 00:00:11
2018-02-08 13:43:08,074 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232 Time elapsed: 00:00:11
2018-02-08 13:43:08,356 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708 Time elapsed: 00:00:11
2018-02-08 13:43:08,625 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540 Time elapsed: 00:00:11
2018-02-08 13:43:08,902 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636 Time elapsed: 00:00:12
2018-02-08 13:43:09,180 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333 Time elapsed: 00:00:12
2018-02-08 13:43:09,545 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953 Time elapsed: 00:00:12
2018-02-08 13:43:09,830 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544 Time elapsed: 00:00:13
2018-02-08 13:43:10,096 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447 Time elapsed: 00:00:13
2018-02-08 13:43:10,359 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667 Time elapsed: 00:00:13
2018-02-08 13:43:10,616 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969 Time elapsed: 00:00:13
2018-02-08 13:43:10,891 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715 Time elapsed: 00:00:14
2018-02-08 13:43:11,151 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796 Time elapsed: 00:00:14
2018-02-08 13:43:11,508 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617 Time elapsed: 00:00:14
2018-02-08 13:43:11,774 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010 Time elapsed: 00:00:15
2018-02-08 13:43:12,038 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204 Time elapsed: 00:00:15
2018-02-08 13:43:12,300 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228 Time elapsed: 00:00:15
2018-02-08 13:43:12,567 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751 Time elapsed: 00:00:15
2018-02-08 13:43:12,836 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178 Time elapsed: 00:00:16
2018-02-08 13:43:13,212 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059 Time elapsed: 00:00:16
2018-02-08 13:43:13,477 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651 Time elapsed: 00:00:16
2018-02-08 13:43:13,742 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126 Time elapsed: 00:00:16
2018-02-08 13:43:14,007 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984 Time elapsed: 00:00:17
2018-02-08 13:43:14,272 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388 Time elapsed: 00:00:17
2018-02-08 13:43:14,535 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202 Time elapsed: 00:00:17
2018-02-08 13:43:14,692 __main__ [INFO ] End of training
2018-02-08 13:45:14,353 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:45:14,355 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:45:14,358 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:45:14,359 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:45:17,031 training [INFO ] Epoch  1 Batch    0 Training err. 0.08903 Training err. RA 0.08903 Valid. err. 4.44462 Time elapsed: 00:00:00
2018-02-08 13:45:17,120 training [INFO ] Epoch  1 Batch    0 Training err. 0.08881 Training err. RA 0.08892 Valid. err. 4.42976 Time elapsed: 00:00:00
2018-02-08 13:45:17,205 training [INFO ] Epoch  1 Batch    0 Training err. 0.08830 Training err. RA 0.08871 Valid. err. 4.41535 Time elapsed: 00:00:00
2018-02-08 13:45:17,298 training [INFO ] Epoch  1 Batch    0 Training err. 0.08795 Training err. RA 0.08852 Valid. err. 4.40005 Time elapsed: 00:00:00
2018-02-08 13:45:17,382 training [INFO ] Epoch  1 Batch    0 Training err. 0.08770 Training err. RA 0.08836 Valid. err. 4.38262 Time elapsed: 00:00:00
2018-02-08 13:45:17,467 training [INFO ] Epoch  1 Batch    0 Training err. 0.08761 Training err. RA 0.08824 Valid. err. 4.36629 Time elapsed: 00:00:00
2018-02-08 13:45:17,558 training [INFO ] Epoch  1 Batch    0 Training err. 0.08765 Training err. RA 0.08815 Valid. err. 4.35214 Time elapsed: 00:00:00
2018-02-08 13:45:17,642 training [INFO ] Epoch  1 Batch    0 Training err. 0.08703 Training err. RA 0.08801 Valid. err. 4.33871 Time elapsed: 00:00:00
2018-02-08 13:45:17,726 training [INFO ] Epoch  1 Batch    0 Training err. 0.08728 Training err. RA 0.08793 Valid. err. 4.32756 Time elapsed: 00:00:00
2018-02-08 13:45:17,823 training [INFO ] Epoch  1 Batch    0 Training err. 0.08637 Training err. RA 0.08777 Valid. err. 4.31162 Time elapsed: 00:00:01
2018-02-08 13:45:17,910 training [INFO ] Epoch  1 Batch    0 Training err. 0.08610 Training err. RA 0.08762 Valid. err. 4.29512 Time elapsed: 00:00:01
2018-02-08 13:45:17,999 training [INFO ] Epoch  1 Batch    0 Training err. 0.08537 Training err. RA 0.08743 Valid. err. 4.28068 Time elapsed: 00:00:01
2018-02-08 13:45:18,090 training [INFO ] Epoch  1 Batch    0 Training err. 0.08546 Training err. RA 0.08728 Valid. err. 4.26383 Time elapsed: 00:00:01
2018-02-08 13:45:18,174 training [INFO ] Epoch  1 Batch    0 Training err. 0.08521 Training err. RA 0.08713 Valid. err. 4.24654 Time elapsed: 00:00:01
2018-02-08 13:45:18,257 training [INFO ] Epoch  1 Batch    0 Training err. 0.08503 Training err. RA 0.08699 Valid. err. 4.23076 Time elapsed: 00:00:01
2018-02-08 13:45:18,353 training [INFO ] Epoch  1 Batch    0 Training err. 0.08527 Training err. RA 0.08689 Valid. err. 4.21751 Time elapsed: 00:00:01
2018-02-08 13:45:18,441 training [INFO ] Epoch  1 Batch    0 Training err. 0.08385 Training err. RA 0.08671 Valid. err. 4.19947 Time elapsed: 00:00:01
2018-02-08 13:45:18,524 training [INFO ] Epoch  1 Batch    0 Training err. 0.08481 Training err. RA 0.08660 Valid. err. 4.18562 Time elapsed: 00:00:01
2018-02-08 13:45:18,620 training [INFO ] Epoch  1 Batch    0 Training err. 0.08344 Training err. RA 0.08644 Valid. err. 4.16781 Time elapsed: 00:00:01
2018-02-08 13:45:18,705 training [INFO ] Epoch  1 Batch    0 Training err. 0.08386 Training err. RA 0.08631 Valid. err. 4.15277 Time elapsed: 00:00:01
2018-02-08 13:45:18,794 training [INFO ] Epoch  1 Batch    0 Training err. 0.08195 Training err. RA 0.08610 Valid. err. 4.13063 Time elapsed: 00:00:02
2018-02-08 13:45:18,896 training [INFO ] Epoch  1 Batch    0 Training err. 0.08286 Training err. RA 0.08595 Valid. err. 4.11486 Time elapsed: 00:00:02
2018-02-08 13:45:18,983 training [INFO ] Epoch  1 Batch    0 Training err. 0.08253 Training err. RA 0.08580 Valid. err. 4.09857 Time elapsed: 00:00:02
2018-02-08 13:45:19,067 training [INFO ] Epoch  1 Batch    0 Training err. 0.08169 Training err. RA 0.08563 Valid. err. 4.07864 Time elapsed: 00:00:02
2018-02-08 13:45:19,163 training [INFO ] Epoch  1 Batch    0 Training err. 0.08299 Training err. RA 0.08553 Valid. err. 4.06292 Time elapsed: 00:00:02
2018-02-08 13:45:19,247 training [INFO ] Epoch  1 Batch    0 Training err. 0.08097 Training err. RA 0.08535 Valid. err. 4.04279 Time elapsed: 00:00:02
2018-02-08 13:45:19,332 training [INFO ] Epoch  1 Batch    0 Training err. 0.08077 Training err. RA 0.08518 Valid. err. 4.02360 Time elapsed: 00:00:02
2018-02-08 13:45:19,427 training [INFO ] Epoch  1 Batch    0 Training err. 0.08126 Training err. RA 0.08504 Valid. err. 4.00444 Time elapsed: 00:00:02
2018-02-08 13:45:19,511 training [INFO ] Epoch  1 Batch    0 Training err. 0.07983 Training err. RA 0.08486 Valid. err. 3.98326 Time elapsed: 00:00:02
2018-02-08 13:45:19,594 training [INFO ] Epoch  1 Batch    0 Training err. 0.08092 Training err. RA 0.08473 Valid. err. 3.96656 Time elapsed: 00:00:02
2018-02-08 13:45:19,694 training [INFO ] Epoch  1 Batch    0 Training err. 0.07807 Training err. RA 0.08452 Valid. err. 3.94244 Time elapsed: 00:00:02
2018-02-08 13:45:19,781 training [INFO ] Epoch  1 Batch    0 Training err. 0.07914 Training err. RA 0.08435 Valid. err. 3.91970 Time elapsed: 00:00:03
2018-02-08 13:45:19,868 training [INFO ] Epoch  1 Batch    0 Training err. 0.07634 Training err. RA 0.08410 Valid. err. 3.89246 Time elapsed: 00:00:03
2018-02-08 13:45:19,968 training [INFO ] Epoch  1 Batch    0 Training err. 0.07815 Training err. RA 0.08393 Valid. err. 3.86926 Time elapsed: 00:00:03
2018-02-08 13:45:20,052 training [INFO ] Epoch  1 Batch    0 Training err. 0.07659 Training err. RA 0.08372 Valid. err. 3.84448 Time elapsed: 00:00:03
2018-02-08 13:45:20,137 training [INFO ] Epoch  1 Batch    0 Training err. 0.07653 Training err. RA 0.08352 Valid. err. 3.81475 Time elapsed: 00:00:03
2018-02-08 13:45:20,232 training [INFO ] Epoch  1 Batch    0 Training err. 0.07387 Training err. RA 0.08326 Valid. err. 3.78550 Time elapsed: 00:00:03
2018-02-08 13:45:20,317 training [INFO ] Epoch  1 Batch    0 Training err. 0.07562 Training err. RA 0.08306 Valid. err. 3.76001 Time elapsed: 00:00:03
2018-02-08 13:45:20,405 training [INFO ] Epoch  1 Batch    0 Training err. 0.07558 Training err. RA 0.08287 Valid. err. 3.73848 Time elapsed: 00:00:03
2018-02-08 13:45:20,502 training [INFO ] Epoch  1 Batch    0 Training err. 0.07535 Training err. RA 0.08268 Valid. err. 3.71568 Time elapsed: 00:00:03
2018-02-08 13:45:20,592 training [INFO ] Epoch  1 Batch    0 Training err. 0.07598 Training err. RA 0.08251 Valid. err. 3.69519 Time elapsed: 00:00:03
2018-02-08 13:45:20,676 training [INFO ] Epoch  1 Batch    0 Training err. 0.07247 Training err. RA 0.08228 Valid. err. 3.67104 Time elapsed: 00:00:03
2018-02-08 13:45:20,776 training [INFO ] Epoch  1 Batch    0 Training err. 0.07547 Training err. RA 0.08212 Valid. err. 3.64866 Time elapsed: 00:00:04
2018-02-08 13:45:20,862 training [INFO ] Epoch  1 Batch    0 Training err. 0.07262 Training err. RA 0.08190 Valid. err. 3.62481 Time elapsed: 00:00:04
2018-02-08 13:45:20,951 training [INFO ] Epoch  1 Batch    0 Training err. 0.07685 Training err. RA 0.08179 Valid. err. 3.61108 Time elapsed: 00:00:04
2018-02-08 13:45:21,048 training [INFO ] Epoch  1 Batch    0 Training err. 0.08011 Training err. RA 0.08175 Valid. err. 3.60667 Time elapsed: 00:00:04
2018-02-08 13:45:21,134 training [INFO ] Epoch  1 Batch    0 Training err. 0.07606 Training err. RA 0.08163 Valid. err. 3.59251 Time elapsed: 00:00:04
2018-02-08 13:45:21,219 training [INFO ] Epoch  1 Batch    0 Training err. 0.07390 Training err. RA 0.08147 Valid. err. 3.57444 Time elapsed: 00:00:04
2018-02-08 13:45:21,315 training [INFO ] Epoch  1 Batch    0 Training err. 0.07400 Training err. RA 0.08132 Valid. err. 3.55961 Time elapsed: 00:00:04
2018-02-08 13:45:21,404 training [INFO ] Epoch  1 Batch    0 Training err. 0.07074 Training err. RA 0.08111 Valid. err. 3.54018 Time elapsed: 00:00:04
2018-02-08 13:45:21,494 training [INFO ] Epoch  1 Batch    0 Training err. 0.07154 Training err. RA 0.08092 Valid. err. 3.52572 Time elapsed: 00:00:04
2018-02-08 13:45:21,592 training [INFO ] Epoch  1 Batch    0 Training err. 0.06999 Training err. RA 0.08071 Valid. err. 3.50858 Time elapsed: 00:00:04
2018-02-08 13:45:21,676 training [INFO ] Epoch  1 Batch    0 Training err. 0.07419 Training err. RA 0.08059 Valid. err. 3.49704 Time elapsed: 00:00:04
2018-02-08 13:45:21,764 training [INFO ] Epoch  1 Batch    0 Training err. 0.07052 Training err. RA 0.08040 Valid. err. 3.48373 Time elapsed: 00:00:05
2018-02-08 13:45:21,867 training [INFO ] Epoch  1 Batch    0 Training err. 0.06664 Training err. RA 0.08015 Valid. err. 3.46813 Time elapsed: 00:00:05
2018-02-08 13:45:21,958 training [INFO ] Epoch  1 Batch    0 Training err. 0.07148 Training err. RA 0.07999 Valid. err. 3.45798 Time elapsed: 00:00:05
2018-02-08 13:45:22,043 training [INFO ] Epoch  1 Batch    0 Training err. 0.06984 Training err. RA 0.07982 Valid. err. 3.44963 Time elapsed: 00:00:05
2018-02-08 13:45:22,141 training [INFO ] Epoch  1 Batch    0 Training err. 0.07014 Training err. RA 0.07965 Valid. err. 3.43391 Time elapsed: 00:00:05
2018-02-08 13:45:22,226 training [INFO ] Epoch  1 Batch    0 Training err. 0.06896 Training err. RA 0.07947 Valid. err. 3.42426 Time elapsed: 00:00:05
2018-02-08 13:45:22,316 training [INFO ] Epoch  1 Batch    0 Training err. 0.07096 Training err. RA 0.07933 Valid. err. 3.41912 Time elapsed: 00:00:05
2018-02-08 13:45:22,413 training [INFO ] Epoch  1 Batch    0 Training err. 0.06499 Training err. RA 0.07909 Valid. err. 3.40833 Time elapsed: 00:00:05
2018-02-08 13:45:22,498 training [INFO ] Epoch  1 Batch    0 Training err. 0.06937 Training err. RA 0.07893 Valid. err. 3.40424 Time elapsed: 00:00:05
2018-02-08 13:45:22,583 training [INFO ] Epoch  1 Batch    0 Training err. 0.06341 Training err. RA 0.07869 Valid. err. 3.39645 Time elapsed: 00:00:05
2018-02-08 13:45:22,680 training [INFO ] Epoch  1 Batch    0 Training err. 0.06585 Training err. RA 0.07849 Valid. err. 3.39038 Time elapsed: 00:00:05
2018-02-08 13:45:22,766 training [INFO ] Epoch  1 Batch    0 Training err. 0.06881 Training err. RA 0.07834 Valid. err. 3.39065 Time elapsed: 00:00:06
2018-02-08 13:45:22,854 training [INFO ] Epoch  1 Batch    0 Training err. 0.06463 Training err. RA 0.07813 Valid. err. 3.38015 Time elapsed: 00:00:06
2018-02-08 13:45:22,952 training [INFO ] Epoch  1 Batch    0 Training err. 0.07041 Training err. RA 0.07802 Valid. err. 3.37416 Time elapsed: 00:00:06
2018-02-08 13:45:23,037 training [INFO ] Epoch  1 Batch    0 Training err. 0.06716 Training err. RA 0.07786 Valid. err. 3.37262 Time elapsed: 00:00:06
2018-02-08 13:45:23,122 training [INFO ] Epoch  1 Batch    0 Training err. 0.06918 Training err. RA 0.07773 Valid. err. 3.37276 Time elapsed: 00:00:06
2018-02-08 13:45:23,219 training [INFO ] Epoch  1 Batch    0 Training err. 0.06263 Training err. RA 0.07751 Valid. err. 3.36576 Time elapsed: 00:00:06
2018-02-08 13:45:23,303 training [INFO ] Epoch  1 Batch    0 Training err. 0.06634 Training err. RA 0.07736 Valid. err. 3.36407 Time elapsed: 00:00:06
2018-02-08 13:45:23,389 training [INFO ] Epoch  1 Batch    0 Training err. 0.07165 Training err. RA 0.07728 Valid. err. 3.35681 Time elapsed: 00:00:06
2018-02-08 13:45:23,487 training [INFO ] Epoch  1 Batch    0 Training err. 0.06606 Training err. RA 0.07712 Valid. err. 3.34518 Time elapsed: 00:00:06
2018-02-08 13:45:23,571 training [INFO ] Epoch  1 Batch    0 Training err. 0.06387 Training err. RA 0.07695 Valid. err. 3.33945 Time elapsed: 00:00:06
2018-02-08 13:45:23,656 training [INFO ] Epoch  1 Batch    0 Training err. 0.06259 Training err. RA 0.07675 Valid. err. 3.33607 Time elapsed: 00:00:06
2018-02-08 13:45:23,753 training [INFO ] Epoch  1 Batch    0 Training err. 0.06287 Training err. RA 0.07657 Valid. err. 3.33350 Time elapsed: 00:00:07
2018-02-08 13:45:23,852 training [INFO ] Epoch  1 Batch    0 Training err. 0.06401 Training err. RA 0.07641 Valid. err. 3.33287 Time elapsed: 00:00:07
2018-02-08 13:45:23,939 training [INFO ] Epoch  1 Batch    0 Training err. 0.06487 Training err. RA 0.07626 Valid. err. 3.33022 Time elapsed: 00:00:07
2018-02-08 13:45:24,042 training [INFO ] Epoch  1 Batch    0 Training err. 0.06558 Training err. RA 0.07612 Valid. err. 3.32930 Time elapsed: 00:00:07
2018-02-08 13:45:24,127 training [INFO ] Epoch  1 Batch    0 Training err. 0.06615 Training err. RA 0.07600 Valid. err. 3.32374 Time elapsed: 00:00:07
2018-02-08 13:45:24,213 training [INFO ] Epoch  1 Batch    0 Training err. 0.06708 Training err. RA 0.07589 Valid. err. 3.31644 Time elapsed: 00:00:07
2018-02-08 13:45:24,309 training [INFO ] Epoch  1 Batch    0 Training err. 0.06755 Training err. RA 0.07579 Valid. err. 3.31191 Time elapsed: 00:00:07
2018-02-08 13:45:24,398 training [INFO ] Epoch  1 Batch    0 Training err. 0.06689 Training err. RA 0.07568 Valid. err. 3.31569 Time elapsed: 00:00:07
2018-02-08 13:45:24,481 training [INFO ] Epoch  1 Batch    0 Training err. 0.06914 Training err. RA 0.07560 Valid. err. 3.32012 Time elapsed: 00:00:07
2018-02-08 13:45:24,573 training [INFO ] Epoch  1 Batch    0 Training err. 0.06420 Training err. RA 0.07547 Valid. err. 3.30657 Time elapsed: 00:00:07
2018-02-08 13:45:24,657 training [INFO ] Epoch  1 Batch    0 Training err. 0.06871 Training err. RA 0.07539 Valid. err. 3.30903 Time elapsed: 00:00:07
2018-02-08 13:45:24,740 training [INFO ] Epoch  1 Batch    0 Training err. 0.06460 Training err. RA 0.07527 Valid. err. 3.30665 Time elapsed: 00:00:07
2018-02-08 13:45:24,838 training [INFO ] Epoch  1 Batch    0 Training err. 0.06527 Training err. RA 0.07515 Valid. err. 3.31120 Time elapsed: 00:00:08
2018-02-08 13:45:24,931 training [INFO ] Epoch  1 Batch    0 Training err. 0.06349 Training err. RA 0.07502 Valid. err. 3.31271 Time elapsed: 00:00:08
2018-02-08 13:45:25,013 training [INFO ] Epoch  1 Batch    0 Training err. 0.06499 Training err. RA 0.07491 Valid. err. 3.31493 Time elapsed: 00:00:08
2018-02-08 13:45:25,108 training [INFO ] Epoch  1 Batch    0 Training err. 0.06688 Training err. RA 0.07482 Valid. err. 3.31467 Time elapsed: 00:00:08
2018-02-08 13:45:25,191 training [INFO ] Epoch  1 Batch    0 Training err. 0.06345 Training err. RA 0.07470 Valid. err. 3.30893 Time elapsed: 00:00:08
2018-02-08 13:45:25,273 training [INFO ] Epoch  1 Batch    0 Training err. 0.06603 Training err. RA 0.07461 Valid. err. 3.30946 Time elapsed: 00:00:08
2018-02-08 13:45:25,366 training [INFO ] Epoch  1 Batch    0 Training err. 0.07029 Training err. RA 0.07456 Valid. err. 3.30656 Time elapsed: 00:00:08
2018-02-08 13:45:25,454 training [INFO ] Epoch  1 Batch    0 Training err. 0.06351 Training err. RA 0.07444 Valid. err. 3.31053 Time elapsed: 00:00:08
2018-02-08 13:45:25,537 training [INFO ] Epoch  1 Batch    0 Training err. 0.06633 Training err. RA 0.07436 Valid. err. 3.31973 Time elapsed: 00:00:08
2018-02-08 13:45:25,629 training [INFO ] Epoch  1 Batch    0 Training err. 0.06587 Training err. RA 0.07427 Valid. err. 3.31480 Time elapsed: 00:00:08
2018-02-08 13:45:25,713 training [INFO ] Epoch  1 Batch    0 Training err. 0.06622 Training err. RA 0.07419 Valid. err. 3.31059 Time elapsed: 00:00:08
2018-02-08 13:45:25,832 training [INFO ] Epoch  1 Batch    0 Training err. 0.07332 Training err. RA 0.07418 Valid. err. 3.30344 Time elapsed: 00:00:09
2018-02-08 13:45:25,936 training [INFO ] Epoch  1 Batch    0 Training err. 0.06667 Training err. RA 0.07411 Valid. err. 3.29641 Time elapsed: 00:00:09
2018-02-08 13:45:26,024 training [INFO ] Epoch  1 Batch    0 Training err. 0.06069 Training err. RA 0.07397 Valid. err. 3.29711 Time elapsed: 00:00:09
2018-02-08 13:45:26,121 training [INFO ] Epoch  1 Batch    0 Training err. 0.06503 Training err. RA 0.07388 Valid. err. 3.30516 Time elapsed: 00:00:09
2018-02-08 13:45:26,204 training [INFO ] Epoch  1 Batch    0 Training err. 0.07657 Training err. RA 0.07391 Valid. err. 3.29366 Time elapsed: 00:00:09
2018-02-08 13:45:26,299 training [INFO ] Epoch  1 Batch    0 Training err. 0.06868 Training err. RA 0.07386 Valid. err. 3.29454 Time elapsed: 00:00:09
2018-02-08 13:45:26,400 training [INFO ] Epoch  1 Batch    0 Training err. 0.06718 Training err. RA 0.07380 Valid. err. 3.29815 Time elapsed: 00:00:09
2018-02-08 13:45:26,483 training [INFO ] Epoch  1 Batch    0 Training err. 0.06126 Training err. RA 0.07368 Valid. err. 3.29253 Time elapsed: 00:00:09
2018-02-08 13:45:26,571 training [INFO ] Epoch  1 Batch    0 Training err. 0.06451 Training err. RA 0.07359 Valid. err. 3.30429 Time elapsed: 00:00:09
2018-02-08 13:45:26,669 training [INFO ] Epoch  1 Batch    0 Training err. 0.06218 Training err. RA 0.07349 Valid. err. 3.29645 Time elapsed: 00:00:09
2018-02-08 13:45:26,758 training [INFO ] Epoch  1 Batch    0 Training err. 0.06661 Training err. RA 0.07342 Valid. err. 3.28306 Time elapsed: 00:00:10
2018-02-08 13:45:26,855 training [INFO ] Epoch  1 Batch    0 Training err. 0.06637 Training err. RA 0.07336 Valid. err. 3.29105 Time elapsed: 00:00:10
2018-02-08 13:45:26,955 training [INFO ] Epoch  1 Batch    0 Training err. 0.06608 Training err. RA 0.07329 Valid. err. 3.27899 Time elapsed: 00:00:10
2018-02-08 13:45:27,041 training [INFO ] Epoch  1 Batch    0 Training err. 0.06230 Training err. RA 0.07320 Valid. err. 3.27902 Time elapsed: 00:00:10
2018-02-08 13:45:27,126 training [INFO ] Epoch  1 Batch    0 Training err. 0.06462 Training err. RA 0.07312 Valid. err. 3.27912 Time elapsed: 00:00:10
2018-02-08 13:45:27,223 training [INFO ] Epoch  1 Batch    0 Training err. 0.06268 Training err. RA 0.07303 Valid. err. 3.28189 Time elapsed: 00:00:10
2018-02-08 13:45:27,311 training [INFO ] Epoch  1 Batch    0 Training err. 0.07317 Training err. RA 0.07303 Valid. err. 3.27418 Time elapsed: 00:00:10
2018-02-08 13:45:27,405 training [INFO ] Epoch  1 Batch    0 Training err. 0.05844 Training err. RA 0.07290 Valid. err. 3.27811 Time elapsed: 00:00:10
2018-02-08 13:45:27,503 training [INFO ] Epoch  1 Batch    0 Training err. 0.06408 Training err. RA 0.07283 Valid. err. 3.27794 Time elapsed: 00:00:10
2018-02-08 13:45:27,586 training [INFO ] Epoch  1 Batch    0 Training err. 0.06152 Training err. RA 0.07273 Valid. err. 3.28845 Time elapsed: 00:00:10
2018-02-08 13:45:27,670 training [INFO ] Epoch  1 Batch    0 Training err. 0.05790 Training err. RA 0.07261 Valid. err. 3.29185 Time elapsed: 00:00:10
2018-02-08 13:45:27,768 training [INFO ] Epoch  1 Batch    0 Training err. 0.06595 Training err. RA 0.07255 Valid. err. 3.27812 Time elapsed: 00:00:11
2018-02-08 13:45:42,527 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:45:42,529 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:45:42,529 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:45:42,530 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:45:45,302 training [INFO ] Epoch  1 Batch   50 Training err. 4.03035 Training err. RA 4.03035 Valid. err. 3.50709 Time elapsed: 00:00:00
2018-02-08 13:45:45,550 training [INFO ] Epoch  1 Batch  100 Training err. 3.39612 Training err. RA 3.71323 Valid. err. 3.30058 Time elapsed: 00:00:00
2018-02-08 13:45:45,804 training [INFO ] Epoch  1 Batch  150 Training err. 3.28086 Training err. RA 3.56911 Valid. err. 3.28448 Time elapsed: 00:00:00
2018-02-08 13:45:46,054 training [INFO ] Epoch  1 Batch  200 Training err. 3.26572 Training err. RA 3.49326 Valid. err. 3.25552 Time elapsed: 00:00:01
2018-02-08 13:45:46,292 training [INFO ] Epoch  1 Batch  250 Training err. 3.22046 Training err. RA 3.43870 Valid. err. 3.25850 Time elapsed: 00:00:01
2018-02-08 13:45:46,529 training [INFO ] Epoch  1 Batch  300 Training err. 3.26909 Training err. RA 3.41043 Valid. err. 3.22067 Time elapsed: 00:00:01
2018-02-08 13:45:46,869 training [INFO ] Epoch  2 Batch  350 Training err. 3.22562 Training err. RA 3.38403 Valid. err. 3.23442 Time elapsed: 00:00:01
2018-02-08 13:45:47,114 training [INFO ] Epoch  2 Batch  400 Training err. 3.22523 Training err. RA 3.36418 Valid. err. 3.24022 Time elapsed: 00:00:02
2018-02-08 13:45:47,348 training [INFO ] Epoch  2 Batch  450 Training err. 3.21386 Training err. RA 3.34748 Valid. err. 3.20681 Time elapsed: 00:00:02
2018-02-08 13:45:47,597 training [INFO ] Epoch  2 Batch  500 Training err. 3.20333 Training err. RA 3.33306 Valid. err. 3.21255 Time elapsed: 00:00:02
2018-02-08 13:45:47,840 training [INFO ] Epoch  2 Batch  550 Training err. 3.18409 Training err. RA 3.31952 Valid. err. 3.21756 Time elapsed: 00:00:02
2018-02-08 13:45:48,081 training [INFO ] Epoch  2 Batch  600 Training err. 3.20270 Training err. RA 3.30979 Valid. err. 3.16652 Time elapsed: 00:00:03
2018-02-08 13:45:48,422 training [INFO ] Epoch  3 Batch  650 Training err. 3.17640 Training err. RA 3.29953 Valid. err. 3.16350 Time elapsed: 00:00:03
2018-02-08 13:45:48,663 training [INFO ] Epoch  3 Batch  700 Training err. 3.16497 Training err. RA 3.28991 Valid. err. 3.15214 Time elapsed: 00:00:03
2018-02-08 13:45:48,911 training [INFO ] Epoch  3 Batch  750 Training err. 3.10979 Training err. RA 3.27791 Valid. err. 3.11654 Time elapsed: 00:00:04
2018-02-08 13:45:49,155 training [INFO ] Epoch  3 Batch  800 Training err. 3.11798 Training err. RA 3.26791 Valid. err. 3.09167 Time elapsed: 00:00:04
2018-02-08 13:45:49,396 training [INFO ] Epoch  3 Batch  850 Training err. 3.04858 Training err. RA 3.25501 Valid. err. 3.11437 Time elapsed: 00:00:04
2018-02-08 13:45:49,643 training [INFO ] Epoch  3 Batch  900 Training err. 3.08748 Training err. RA 3.24570 Valid. err. 3.00356 Time elapsed: 00:00:04
2018-02-08 13:45:50,004 training [INFO ] Epoch  4 Batch  950 Training err. 3.05517 Training err. RA 3.23567 Valid. err. 3.06064 Time elapsed: 00:00:05
2018-02-08 13:45:50,255 training [INFO ] Epoch  4 Batch 1000 Training err. 2.97792 Training err. RA 3.22279 Valid. err. 2.95704 Time elapsed: 00:00:05
2018-02-08 13:45:50,503 training [INFO ] Epoch  4 Batch 1050 Training err. 2.90868 Training err. RA 3.20783 Valid. err. 2.93271 Time elapsed: 00:00:05
2018-02-08 13:45:50,751 training [INFO ] Epoch  4 Batch 1100 Training err. 2.91593 Training err. RA 3.19456 Valid. err. 2.87118 Time elapsed: 00:00:05
2018-02-08 13:45:51,013 training [INFO ] Epoch  4 Batch 1150 Training err. 2.87331 Training err. RA 3.18059 Valid. err. 2.90123 Time elapsed: 00:00:06
2018-02-08 13:45:51,259 training [INFO ] Epoch  4 Batch 1200 Training err. 2.87510 Training err. RA 3.16786 Valid. err. 2.82103 Time elapsed: 00:00:06
2018-02-08 13:45:51,603 training [INFO ] Epoch  5 Batch 1250 Training err. 2.91689 Training err. RA 3.15783 Valid. err. 2.86057 Time elapsed: 00:00:06
2018-02-08 13:45:51,856 training [INFO ] Epoch  5 Batch 1300 Training err. 2.85646 Training err. RA 3.14623 Valid. err. 2.81898 Time elapsed: 00:00:06
2018-02-08 13:45:52,103 training [INFO ] Epoch  5 Batch 1350 Training err. 2.76120 Training err. RA 3.13197 Valid. err. 2.78553 Time elapsed: 00:00:07
2018-02-08 13:45:52,341 training [INFO ] Epoch  5 Batch 1400 Training err. 2.78885 Training err. RA 3.11972 Valid. err. 2.77831 Time elapsed: 00:00:07
2018-02-08 13:45:52,585 training [INFO ] Epoch  5 Batch 1450 Training err. 2.79392 Training err. RA 3.10849 Valid. err. 2.76432 Time elapsed: 00:00:07
2018-02-08 13:45:52,831 training [INFO ] Epoch  5 Batch 1500 Training err. 2.75286 Training err. RA 3.09663 Valid. err. 2.72761 Time elapsed: 00:00:07
2018-02-08 13:45:53,168 training [INFO ] Epoch  6 Batch 1550 Training err. 2.84040 Training err. RA 3.08837 Valid. err. 2.73007 Time elapsed: 00:00:08
2018-02-08 13:45:53,405 training [INFO ] Epoch  6 Batch 1600 Training err. 2.77743 Training err. RA 3.07865 Valid. err. 2.78302 Time elapsed: 00:00:08
2018-02-08 13:45:53,649 training [INFO ] Epoch  6 Batch 1650 Training err. 2.70448 Training err. RA 3.06731 Valid. err. 2.70103 Time elapsed: 00:00:08
2018-02-08 13:45:53,902 training [INFO ] Epoch  6 Batch 1700 Training err. 2.67881 Training err. RA 3.05588 Valid. err. 2.71607 Time elapsed: 00:00:09
2018-02-08 13:45:54,149 training [INFO ] Epoch  6 Batch 1750 Training err. 2.75233 Training err. RA 3.04721 Valid. err. 2.68929 Time elapsed: 00:00:09
2018-02-08 13:45:54,400 training [INFO ] Epoch  6 Batch 1800 Training err. 2.65755 Training err. RA 3.03639 Valid. err. 2.66134 Time elapsed: 00:00:09
2018-02-08 13:45:54,731 training [INFO ] Epoch  7 Batch 1850 Training err. 2.76231 Training err. RA 3.02898 Valid. err. 2.68993 Time elapsed: 00:00:09
2018-02-08 13:45:54,985 training [INFO ] Epoch  7 Batch 1900 Training err. 2.73251 Training err. RA 3.02118 Valid. err. 2.64013 Time elapsed: 00:00:10
2018-02-08 13:45:55,228 training [INFO ] Epoch  7 Batch 1950 Training err. 2.62543 Training err. RA 3.01103 Valid. err. 2.62129 Time elapsed: 00:00:10
2018-02-08 13:45:55,473 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59956 Training err. RA 3.00074 Valid. err. 2.61292 Time elapsed: 00:00:10
2018-02-08 13:45:55,723 training [INFO ] Epoch  7 Batch 2050 Training err. 2.69944 Training err. RA 2.99339 Valid. err. 2.59283 Time elapsed: 00:00:10
2018-02-08 13:45:55,982 training [INFO ] Epoch  7 Batch 2100 Training err. 2.57575 Training err. RA 2.98345 Valid. err. 2.56877 Time elapsed: 00:00:11
2018-02-08 13:45:56,319 training [INFO ] Epoch  8 Batch 2150 Training err. 2.65044 Training err. RA 2.97571 Valid. err. 2.55899 Time elapsed: 00:00:11
2018-02-08 13:45:56,557 training [INFO ] Epoch  8 Batch 2200 Training err. 2.71342 Training err. RA 2.96975 Valid. err. 2.56918 Time elapsed: 00:00:11
2018-02-08 13:45:56,794 training [INFO ] Epoch  8 Batch 2250 Training err. 2.58290 Training err. RA 2.96115 Valid. err. 2.56248 Time elapsed: 00:00:11
2018-02-08 13:45:57,037 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55946 Training err. RA 2.95242 Valid. err. 2.55650 Time elapsed: 00:00:12
2018-02-08 13:45:57,273 training [INFO ] Epoch  8 Batch 2350 Training err. 2.61409 Training err. RA 2.94522 Valid. err. 2.56300 Time elapsed: 00:00:12
2018-02-08 13:45:57,525 training [INFO ] Epoch  8 Batch 2400 Training err. 2.50802 Training err. RA 2.93611 Valid. err. 2.51870 Time elapsed: 00:00:12
2018-02-08 13:45:57,773 training [INFO ] Epoch  8 Batch 2450 Training err. 2.59409 Training err. RA 2.92913 Valid. err. 2.53961 Time elapsed: 00:00:12
2018-02-08 13:45:58,122 training [INFO ] Epoch  9 Batch 2500 Training err. 2.62842 Training err. RA 2.92312 Valid. err. 2.55848 Time elapsed: 00:00:13
2018-02-08 13:45:58,368 training [INFO ] Epoch  9 Batch 2550 Training err. 2.59339 Training err. RA 2.91665 Valid. err. 2.50925 Time elapsed: 00:00:13
2018-02-08 13:45:58,613 training [INFO ] Epoch  9 Batch 2600 Training err. 2.51349 Training err. RA 2.90890 Valid. err. 2.48664 Time elapsed: 00:00:13
2018-02-08 13:45:58,870 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56849 Training err. RA 2.90247 Valid. err. 2.53922 Time elapsed: 00:00:13
2018-02-08 13:45:59,143 training [INFO ] Epoch  9 Batch 2700 Training err. 2.45930 Training err. RA 2.89427 Valid. err. 2.50157 Time elapsed: 00:00:14
2018-02-08 13:45:59,385 training [INFO ] Epoch  9 Batch 2750 Training err. 2.51868 Training err. RA 2.88744 Valid. err. 2.46913 Time elapsed: 00:00:14
2018-02-08 13:45:59,733 training [INFO ] Epoch 10 Batch 2800 Training err. 2.56469 Training err. RA 2.88168 Valid. err. 2.53210 Time elapsed: 00:00:14
2018-02-08 13:45:59,989 training [INFO ] Epoch 10 Batch 2850 Training err. 2.57640 Training err. RA 2.87632 Valid. err. 2.47347 Time elapsed: 00:00:15
2018-02-08 13:46:00,238 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46530 Training err. RA 2.86923 Valid. err. 2.44150 Time elapsed: 00:00:15
2018-02-08 13:46:00,494 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51712 Training err. RA 2.86327 Valid. err. 2.46894 Time elapsed: 00:00:15
2018-02-08 13:46:00,736 training [INFO ] Epoch 10 Batch 3000 Training err. 2.43737 Training err. RA 2.85617 Valid. err. 2.42447 Time elapsed: 00:00:15
2018-02-08 13:46:00,996 training [INFO ] Epoch 10 Batch 3050 Training err. 2.46517 Training err. RA 2.84976 Valid. err. 2.43790 Time elapsed: 00:00:16
2018-02-08 13:46:01,143 __main__ [INFO ] End of training
2018-02-08 13:46:01,552 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:46:01,553 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:46:01,877 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004 Time elapsed: 00:00:00
2018-02-08 13:46:02,150 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220 Time elapsed: 00:00:00
2018-02-08 13:46:02,414 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708 Time elapsed: 00:00:00
2018-02-08 13:46:02,676 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226 Time elapsed: 00:00:01
2018-02-08 13:46:03,037 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791 Time elapsed: 00:00:01
2018-02-08 13:46:03,295 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095 Time elapsed: 00:00:01
2018-02-08 13:46:03,560 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617 Time elapsed: 00:00:01
2018-02-08 13:46:03,827 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091 Time elapsed: 00:00:02
2018-02-08 13:46:04,190 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571 Time elapsed: 00:00:02
2018-02-08 13:46:04,458 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752 Time elapsed: 00:00:02
2018-02-08 13:46:04,728 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115 Time elapsed: 00:00:03
2018-02-08 13:46:05,007 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850 Time elapsed: 00:00:03
2018-02-08 13:46:05,359 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007 Time elapsed: 00:00:03
2018-02-08 13:46:05,627 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578 Time elapsed: 00:00:04
2018-02-08 13:46:05,898 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063 Time elapsed: 00:00:04
2018-02-08 13:46:06,158 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541 Time elapsed: 00:00:04
2018-02-08 13:46:06,514 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331 Time elapsed: 00:00:04
2018-02-08 13:46:06,782 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885 Time elapsed: 00:00:05
2018-02-08 13:46:07,050 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402 Time elapsed: 00:00:05
2018-02-08 13:46:07,316 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876 Time elapsed: 00:00:05
2018-02-08 13:46:07,675 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261 Time elapsed: 00:00:06
2018-02-08 13:46:07,947 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771 Time elapsed: 00:00:06
2018-02-08 13:46:08,225 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434 Time elapsed: 00:00:06
2018-02-08 13:46:08,489 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230 Time elapsed: 00:00:06
2018-02-08 13:46:08,844 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620 Time elapsed: 00:00:07
2018-02-08 13:46:09,114 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672 Time elapsed: 00:00:07
2018-02-08 13:46:09,379 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298 Time elapsed: 00:00:07
2018-02-08 13:46:09,653 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529 Time elapsed: 00:00:08
2018-02-08 13:46:10,050 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410 Time elapsed: 00:00:08
2018-02-08 13:46:10,308 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609 Time elapsed: 00:00:08
2018-02-08 13:46:10,568 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099 Time elapsed: 00:00:08
2018-02-08 13:46:10,824 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653 Time elapsed: 00:00:09
2018-02-08 13:46:11,168 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570 Time elapsed: 00:00:09
2018-02-08 13:46:11,431 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963 Time elapsed: 00:00:09
2018-02-08 13:46:11,698 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815 Time elapsed: 00:00:10
2018-02-08 13:46:11,962 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999 Time elapsed: 00:00:10
2018-02-08 13:46:12,301 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695 Time elapsed: 00:00:10
2018-02-08 13:46:12,558 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245 Time elapsed: 00:00:10
2018-02-08 13:46:12,817 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415 Time elapsed: 00:00:11
2018-02-08 13:46:13,077 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328 Time elapsed: 00:00:11
2018-02-08 13:46:13,332 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049 Time elapsed: 00:00:11
2018-02-08 13:46:13,416 __main__ [INFO ] End of training
2018-02-08 13:46:13,569 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:46:13,570 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:46:13,865 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945 Time elapsed: 00:00:00
2018-02-08 13:46:14,133 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585 Time elapsed: 00:00:00
2018-02-08 13:46:14,398 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036 Time elapsed: 00:00:00
2018-02-08 13:46:14,659 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844 Time elapsed: 00:00:01
2018-02-08 13:46:14,927 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920 Time elapsed: 00:00:01
2018-02-08 13:46:15,198 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863 Time elapsed: 00:00:01
2018-02-08 13:46:15,556 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650 Time elapsed: 00:00:01
2018-02-08 13:46:15,822 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923 Time elapsed: 00:00:02
2018-02-08 13:46:16,094 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288 Time elapsed: 00:00:02
2018-02-08 13:46:16,352 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297 Time elapsed: 00:00:02
2018-02-08 13:46:16,624 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633 Time elapsed: 00:00:03
2018-02-08 13:46:16,913 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329 Time elapsed: 00:00:03
2018-02-08 13:46:17,282 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222 Time elapsed: 00:00:03
2018-02-08 13:46:17,572 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798 Time elapsed: 00:00:03
2018-02-08 13:46:17,843 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300 Time elapsed: 00:00:04
2018-02-08 13:46:18,139 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864 Time elapsed: 00:00:04
2018-02-08 13:46:18,441 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590 Time elapsed: 00:00:04
2018-02-08 13:46:18,720 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607 Time elapsed: 00:00:05
2018-02-08 13:46:19,105 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056 Time elapsed: 00:00:05
2018-02-08 13:46:19,393 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954 Time elapsed: 00:00:05
2018-02-08 13:46:19,693 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403 Time elapsed: 00:00:06
2018-02-08 13:46:20,014 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444 Time elapsed: 00:00:06
2018-02-08 13:46:20,321 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682 Time elapsed: 00:00:06
2018-02-08 13:46:20,620 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167 Time elapsed: 00:00:07
2018-02-08 13:46:21,013 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971 Time elapsed: 00:00:07
2018-02-08 13:46:21,297 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051 Time elapsed: 00:00:07
2018-02-08 13:46:21,583 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551 Time elapsed: 00:00:08
2018-02-08 13:46:21,855 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389 Time elapsed: 00:00:08
2018-02-08 13:46:22,140 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053 Time elapsed: 00:00:08
2018-02-08 13:46:22,409 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556 Time elapsed: 00:00:08
2018-02-08 13:46:22,768 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131 Time elapsed: 00:00:09
2018-02-08 13:46:23,051 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897 Time elapsed: 00:00:09
2018-02-08 13:46:23,327 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355 Time elapsed: 00:00:09
2018-02-08 13:46:23,601 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367 Time elapsed: 00:00:10
2018-02-08 13:46:23,881 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858 Time elapsed: 00:00:10
2018-02-08 13:46:24,143 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398 Time elapsed: 00:00:10
2018-02-08 13:46:24,773 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153 Time elapsed: 00:00:11
2018-02-08 13:46:25,050 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232 Time elapsed: 00:00:11
2018-02-08 13:46:25,314 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708 Time elapsed: 00:00:11
2018-02-08 13:46:25,585 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540 Time elapsed: 00:00:12
2018-02-08 13:46:25,852 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636 Time elapsed: 00:00:12
2018-02-08 13:46:26,120 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333 Time elapsed: 00:00:12
2018-02-08 13:46:26,480 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953 Time elapsed: 00:00:12
2018-02-08 13:46:26,742 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544 Time elapsed: 00:00:13
2018-02-08 13:46:27,013 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447 Time elapsed: 00:00:13
2018-02-08 13:46:27,275 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667 Time elapsed: 00:00:13
2018-02-08 13:46:27,540 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969 Time elapsed: 00:00:13
2018-02-08 13:46:27,806 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715 Time elapsed: 00:00:14
2018-02-08 13:46:28,077 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796 Time elapsed: 00:00:14
2018-02-08 13:46:28,446 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617 Time elapsed: 00:00:14
2018-02-08 13:46:28,720 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010 Time elapsed: 00:00:15
2018-02-08 13:46:29,001 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204 Time elapsed: 00:00:15
2018-02-08 13:46:29,263 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228 Time elapsed: 00:00:15
2018-02-08 13:46:29,534 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751 Time elapsed: 00:00:15
2018-02-08 13:46:29,804 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178 Time elapsed: 00:00:16
2018-02-08 13:46:30,194 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059 Time elapsed: 00:00:16
2018-02-08 13:46:30,464 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651 Time elapsed: 00:00:16
2018-02-08 13:46:30,745 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126 Time elapsed: 00:00:17
2018-02-08 13:46:31,037 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984 Time elapsed: 00:00:17
2018-02-08 13:46:31,302 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388 Time elapsed: 00:00:17
2018-02-08 13:46:31,592 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202 Time elapsed: 00:00:18
2018-02-08 13:46:31,753 __main__ [INFO ] End of training
2018-02-08 13:46:37,498 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:46:37,500 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:46:37,503 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:46:37,505 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:46:40,092 training [INFO ] Epoch  1 Batch    0 Training err. 0.08874 Training err. RA 0.08874 Valid. err. 4.42753 Time elapsed: 00:00:00
2018-02-08 13:46:40,177 training [INFO ] Epoch  1 Batch    0 Training err. 0.08853 Training err. RA 0.08864 Valid. err. 4.41221 Time elapsed: 00:00:00
2018-02-08 13:46:40,270 training [INFO ] Epoch  1 Batch    0 Training err. 0.08829 Training err. RA 0.08852 Valid. err. 4.39790 Time elapsed: 00:00:00
2018-02-08 13:46:40,360 training [INFO ] Epoch  1 Batch    0 Training err. 0.08785 Training err. RA 0.08835 Valid. err. 4.38287 Time elapsed: 00:00:00
2018-02-08 13:46:40,444 training [INFO ] Epoch  1 Batch    0 Training err. 0.08742 Training err. RA 0.08817 Valid. err. 4.36570 Time elapsed: 00:00:00
2018-02-08 13:46:40,530 training [INFO ] Epoch  1 Batch    0 Training err. 0.08712 Training err. RA 0.08799 Valid. err. 4.34975 Time elapsed: 00:00:00
2018-02-08 13:46:40,624 training [INFO ] Epoch  1 Batch    0 Training err. 0.08746 Training err. RA 0.08792 Valid. err. 4.33572 Time elapsed: 00:00:00
2018-02-08 13:46:40,708 training [INFO ] Epoch  1 Batch    0 Training err. 0.08669 Training err. RA 0.08776 Valid. err. 4.32206 Time elapsed: 00:00:00
2018-02-08 13:46:40,794 training [INFO ] Epoch  1 Batch    0 Training err. 0.08703 Training err. RA 0.08768 Valid. err. 4.31094 Time elapsed: 00:00:00
2018-02-08 13:46:40,888 training [INFO ] Epoch  1 Batch    0 Training err. 0.08617 Training err. RA 0.08753 Valid. err. 4.29492 Time elapsed: 00:00:01
2018-02-08 13:46:40,974 training [INFO ] Epoch  1 Batch    0 Training err. 0.08557 Training err. RA 0.08735 Valid. err. 4.27862 Time elapsed: 00:00:01
2018-02-08 13:46:41,059 training [INFO ] Epoch  1 Batch    0 Training err. 0.08528 Training err. RA 0.08718 Valid. err. 4.26402 Time elapsed: 00:00:01
2018-02-08 13:46:41,157 training [INFO ] Epoch  1 Batch    0 Training err. 0.08512 Training err. RA 0.08702 Valid. err. 4.24692 Time elapsed: 00:00:01
2018-02-08 13:46:41,242 training [INFO ] Epoch  1 Batch    0 Training err. 0.08485 Training err. RA 0.08687 Valid. err. 4.23001 Time elapsed: 00:00:01
2018-02-08 13:46:41,326 training [INFO ] Epoch  1 Batch    0 Training err. 0.08450 Training err. RA 0.08671 Valid. err. 4.21452 Time elapsed: 00:00:01
2018-02-08 13:46:41,421 training [INFO ] Epoch  1 Batch    0 Training err. 0.08529 Training err. RA 0.08662 Valid. err. 4.20168 Time elapsed: 00:00:01
2018-02-08 13:46:41,507 training [INFO ] Epoch  1 Batch    0 Training err. 0.08374 Training err. RA 0.08645 Valid. err. 4.18366 Time elapsed: 00:00:01
2018-02-08 13:46:41,590 training [INFO ] Epoch  1 Batch    0 Training err. 0.08481 Training err. RA 0.08636 Valid. err. 4.17018 Time elapsed: 00:00:01
2018-02-08 13:46:41,688 training [INFO ] Epoch  1 Batch    0 Training err. 0.08331 Training err. RA 0.08620 Valid. err. 4.15287 Time elapsed: 00:00:01
2018-02-08 13:46:41,773 training [INFO ] Epoch  1 Batch    0 Training err. 0.08365 Training err. RA 0.08607 Valid. err. 4.13789 Time elapsed: 00:00:01
2018-02-08 13:46:41,865 training [INFO ] Epoch  1 Batch    0 Training err. 0.08164 Training err. RA 0.08586 Valid. err. 4.11608 Time elapsed: 00:00:02
2018-02-08 13:46:41,965 training [INFO ] Epoch  1 Batch    0 Training err. 0.08244 Training err. RA 0.08570 Valid. err. 4.10021 Time elapsed: 00:00:02
2018-02-08 13:46:42,049 training [INFO ] Epoch  1 Batch    0 Training err. 0.08202 Training err. RA 0.08554 Valid. err. 4.08366 Time elapsed: 00:00:02
2018-02-08 13:46:42,134 training [INFO ] Epoch  1 Batch    0 Training err. 0.08144 Training err. RA 0.08537 Valid. err. 4.06373 Time elapsed: 00:00:02
2018-02-08 13:46:42,228 training [INFO ] Epoch  1 Batch    0 Training err. 0.08261 Training err. RA 0.08526 Valid. err. 4.04798 Time elapsed: 00:00:02
2018-02-08 13:46:42,312 training [INFO ] Epoch  1 Batch    0 Training err. 0.08054 Training err. RA 0.08508 Valid. err. 4.02706 Time elapsed: 00:00:02
2018-02-08 13:46:42,397 training [INFO ] Epoch  1 Batch    0 Training err. 0.08061 Training err. RA 0.08492 Valid. err. 4.00831 Time elapsed: 00:00:02
2018-02-08 13:46:42,494 training [INFO ] Epoch  1 Batch    0 Training err. 0.08108 Training err. RA 0.08478 Valid. err. 3.98910 Time elapsed: 00:00:02
2018-02-08 13:46:42,579 training [INFO ] Epoch  1 Batch    0 Training err. 0.07917 Training err. RA 0.08459 Valid. err. 3.96693 Time elapsed: 00:00:02
2018-02-08 13:46:42,663 training [INFO ] Epoch  1 Batch    0 Training err. 0.08082 Training err. RA 0.08446 Valid. err. 3.94992 Time elapsed: 00:00:02
2018-02-08 13:46:42,761 training [INFO ] Epoch  1 Batch    0 Training err. 0.07717 Training err. RA 0.08422 Valid. err. 3.92485 Time elapsed: 00:00:02
2018-02-08 13:46:42,857 training [INFO ] Epoch  1 Batch    0 Training err. 0.07868 Training err. RA 0.08405 Valid. err. 3.90230 Time elapsed: 00:00:03
2018-02-08 13:46:42,947 training [INFO ] Epoch  1 Batch    0 Training err. 0.07604 Training err. RA 0.08381 Valid. err. 3.87526 Time elapsed: 00:00:03
2018-02-08 13:46:43,044 training [INFO ] Epoch  1 Batch    0 Training err. 0.07811 Training err. RA 0.08364 Valid. err. 3.85167 Time elapsed: 00:00:03
2018-02-08 13:46:43,129 training [INFO ] Epoch  1 Batch    0 Training err. 0.07645 Training err. RA 0.08344 Valid. err. 3.82624 Time elapsed: 00:00:03
2018-02-08 13:46:43,214 training [INFO ] Epoch  1 Batch    0 Training err. 0.07582 Training err. RA 0.08322 Valid. err. 3.79494 Time elapsed: 00:00:03
2018-02-08 13:46:43,312 training [INFO ] Epoch  1 Batch    0 Training err. 0.07269 Training err. RA 0.08294 Valid. err. 3.76303 Time elapsed: 00:00:03
2018-02-08 13:46:43,402 training [INFO ] Epoch  1 Batch    0 Training err. 0.07486 Training err. RA 0.08273 Valid. err. 3.73615 Time elapsed: 00:00:03
2018-02-08 13:46:43,488 training [INFO ] Epoch  1 Batch    0 Training err. 0.07493 Training err. RA 0.08253 Valid. err. 3.71338 Time elapsed: 00:00:03
2018-02-08 13:46:43,586 training [INFO ] Epoch  1 Batch    0 Training err. 0.07512 Training err. RA 0.08234 Valid. err. 3.69114 Time elapsed: 00:00:03
2018-02-08 13:46:43,672 training [INFO ] Epoch  1 Batch    0 Training err. 0.07559 Training err. RA 0.08218 Valid. err. 3.66984 Time elapsed: 00:00:03
2018-02-08 13:46:43,765 training [INFO ] Epoch  1 Batch    0 Training err. 0.07229 Training err. RA 0.08194 Valid. err. 3.64702 Time elapsed: 00:00:03
2018-02-08 13:46:43,865 training [INFO ] Epoch  1 Batch    0 Training err. 0.07508 Training err. RA 0.08178 Valid. err. 3.62470 Time elapsed: 00:00:04
2018-02-08 13:46:43,956 training [INFO ] Epoch  1 Batch    0 Training err. 0.07198 Training err. RA 0.08156 Valid. err. 3.60107 Time elapsed: 00:00:04
2018-02-08 13:46:44,042 training [INFO ] Epoch  1 Batch    0 Training err. 0.07670 Training err. RA 0.08145 Valid. err. 3.58812 Time elapsed: 00:00:04
2018-02-08 13:46:44,141 training [INFO ] Epoch  1 Batch    0 Training err. 0.08097 Training err. RA 0.08144 Valid. err. 3.58755 Time elapsed: 00:00:04
2018-02-08 13:46:44,226 training [INFO ] Epoch  1 Batch    0 Training err. 0.07631 Training err. RA 0.08133 Valid. err. 3.57517 Time elapsed: 00:00:04
2018-02-08 13:46:44,313 training [INFO ] Epoch  1 Batch    0 Training err. 0.07395 Training err. RA 0.08118 Valid. err. 3.55863 Time elapsed: 00:00:04
2018-02-08 13:46:44,411 training [INFO ] Epoch  1 Batch    0 Training err. 0.07324 Training err. RA 0.08102 Valid. err. 3.54442 Time elapsed: 00:00:04
2018-02-08 13:46:44,497 training [INFO ] Epoch  1 Batch    0 Training err. 0.07044 Training err. RA 0.08080 Valid. err. 3.52573 Time elapsed: 00:00:04
2018-02-08 13:46:44,589 training [INFO ] Epoch  1 Batch    0 Training err. 0.07127 Training err. RA 0.08062 Valid. err. 3.51251 Time elapsed: 00:00:04
2018-02-08 13:46:44,687 training [INFO ] Epoch  1 Batch    0 Training err. 0.06987 Training err. RA 0.08041 Valid. err. 3.49589 Time elapsed: 00:00:04
2018-02-08 13:46:44,774 training [INFO ] Epoch  1 Batch    0 Training err. 0.07401 Training err. RA 0.08029 Valid. err. 3.48608 Time elapsed: 00:00:04
2018-02-08 13:46:44,865 training [INFO ] Epoch  1 Batch    0 Training err. 0.07009 Training err. RA 0.08010 Valid. err. 3.47406 Time elapsed: 00:00:05
2018-02-08 13:46:44,963 training [INFO ] Epoch  1 Batch    0 Training err. 0.06622 Training err. RA 0.07985 Valid. err. 3.46001 Time elapsed: 00:00:05
2018-02-08 13:46:45,049 training [INFO ] Epoch  1 Batch    0 Training err. 0.07170 Training err. RA 0.07970 Valid. err. 3.45113 Time elapsed: 00:00:05
2018-02-08 13:46:45,136 training [INFO ] Epoch  1 Batch    0 Training err. 0.06944 Training err. RA 0.07952 Valid. err. 3.44390 Time elapsed: 00:00:05
2018-02-08 13:46:45,232 training [INFO ] Epoch  1 Batch    0 Training err. 0.07029 Training err. RA 0.07936 Valid. err. 3.42915 Time elapsed: 00:00:05
2018-02-08 13:46:45,319 training [INFO ] Epoch  1 Batch    0 Training err. 0.06840 Training err. RA 0.07918 Valid. err. 3.42110 Time elapsed: 00:00:05
2018-02-08 13:46:45,405 training [INFO ] Epoch  1 Batch    0 Training err. 0.07092 Training err. RA 0.07904 Valid. err. 3.41732 Time elapsed: 00:00:05
2018-02-08 13:46:45,508 training [INFO ] Epoch  1 Batch    0 Training err. 0.06503 Training err. RA 0.07881 Valid. err. 3.40850 Time elapsed: 00:00:05
2018-02-08 13:46:45,595 training [INFO ] Epoch  1 Batch    0 Training err. 0.06929 Training err. RA 0.07866 Valid. err. 3.40635 Time elapsed: 00:00:05
2018-02-08 13:46:45,682 training [INFO ] Epoch  1 Batch    0 Training err. 0.06323 Training err. RA 0.07841 Valid. err. 3.39933 Time elapsed: 00:00:05
2018-02-08 13:46:45,781 training [INFO ] Epoch  1 Batch    0 Training err. 0.06516 Training err. RA 0.07821 Valid. err. 3.39505 Time elapsed: 00:00:05
2018-02-08 13:46:45,873 training [INFO ] Epoch  1 Batch    0 Training err. 0.06846 Training err. RA 0.07806 Valid. err. 3.39651 Time elapsed: 00:00:06
2018-02-08 13:46:45,961 training [INFO ] Epoch  1 Batch    0 Training err. 0.06408 Training err. RA 0.07784 Valid. err. 3.38660 Time elapsed: 00:00:06
2018-02-08 13:46:46,060 training [INFO ] Epoch  1 Batch    0 Training err. 0.07113 Training err. RA 0.07774 Valid. err. 3.37866 Time elapsed: 00:00:06
2018-02-08 13:46:46,146 training [INFO ] Epoch  1 Batch    0 Training err. 0.06739 Training err. RA 0.07759 Valid. err. 3.37780 Time elapsed: 00:00:06
2018-02-08 13:46:46,232 training [INFO ] Epoch  1 Batch    0 Training err. 0.06918 Training err. RA 0.07747 Valid. err. 3.37786 Time elapsed: 00:00:06
2018-02-08 13:46:46,329 training [INFO ] Epoch  1 Batch    0 Training err. 0.06237 Training err. RA 0.07725 Valid. err. 3.37108 Time elapsed: 00:00:06
2018-02-08 13:46:46,415 training [INFO ] Epoch  1 Batch    0 Training err. 0.06645 Training err. RA 0.07710 Valid. err. 3.36881 Time elapsed: 00:00:06
2018-02-08 13:46:46,501 training [INFO ] Epoch  1 Batch    0 Training err. 0.07182 Training err. RA 0.07703 Valid. err. 3.35902 Time elapsed: 00:00:06
2018-02-08 13:46:46,600 training [INFO ] Epoch  1 Batch    0 Training err. 0.06588 Training err. RA 0.07688 Valid. err. 3.34677 Time elapsed: 00:00:06
2018-02-08 13:46:46,687 training [INFO ] Epoch  1 Batch    0 Training err. 0.06336 Training err. RA 0.07669 Valid. err. 3.34120 Time elapsed: 00:00:06
2018-02-08 13:46:46,773 training [INFO ] Epoch  1 Batch    0 Training err. 0.06257 Training err. RA 0.07650 Valid. err. 3.33799 Time elapsed: 00:00:06
2018-02-08 13:46:46,876 training [INFO ] Epoch  1 Batch    0 Training err. 0.06311 Training err. RA 0.07633 Valid. err. 3.33529 Time elapsed: 00:00:07
2018-02-08 13:46:46,967 training [INFO ] Epoch  1 Batch    0 Training err. 0.06393 Training err. RA 0.07617 Valid. err. 3.33520 Time elapsed: 00:00:07
2018-02-08 13:46:47,052 training [INFO ] Epoch  1 Batch    0 Training err. 0.06499 Training err. RA 0.07602 Valid. err. 3.33233 Time elapsed: 00:00:07
2018-02-08 13:46:47,151 training [INFO ] Epoch  1 Batch    0 Training err. 0.06571 Training err. RA 0.07589 Valid. err. 3.33104 Time elapsed: 00:00:07
2018-02-08 13:46:47,239 training [INFO ] Epoch  1 Batch    0 Training err. 0.06617 Training err. RA 0.07577 Valid. err. 3.32500 Time elapsed: 00:00:07
2018-02-08 13:46:47,325 training [INFO ] Epoch  1 Batch    0 Training err. 0.06738 Training err. RA 0.07567 Valid. err. 3.31618 Time elapsed: 00:00:07
2018-02-08 13:46:47,423 training [INFO ] Epoch  1 Batch    0 Training err. 0.06801 Training err. RA 0.07557 Valid. err. 3.31053 Time elapsed: 00:00:07
2018-02-08 13:46:47,509 training [INFO ] Epoch  1 Batch    0 Training err. 0.06645 Training err. RA 0.07546 Valid. err. 3.31568 Time elapsed: 00:00:07
2018-02-08 13:46:47,592 training [INFO ] Epoch  1 Batch    0 Training err. 0.06881 Training err. RA 0.07539 Valid. err. 3.32088 Time elapsed: 00:00:07
2018-02-08 13:46:47,689 training [INFO ] Epoch  1 Batch    0 Training err. 0.06442 Training err. RA 0.07526 Valid. err. 3.30540 Time elapsed: 00:00:07
2018-02-08 13:46:47,774 training [INFO ] Epoch  1 Batch    0 Training err. 0.06854 Training err. RA 0.07518 Valid. err. 3.30814 Time elapsed: 00:00:07
2018-02-08 13:46:47,864 training [INFO ] Epoch  1 Batch    0 Training err. 0.06479 Training err. RA 0.07506 Valid. err. 3.30564 Time elapsed: 00:00:08
2018-02-08 13:46:47,959 training [INFO ] Epoch  1 Batch    0 Training err. 0.06521 Training err. RA 0.07495 Valid. err. 3.31086 Time elapsed: 00:00:08
2018-02-08 13:46:48,048 training [INFO ] Epoch  1 Batch    0 Training err. 0.06331 Training err. RA 0.07482 Valid. err. 3.31284 Time elapsed: 00:00:08
2018-02-08 13:46:48,132 training [INFO ] Epoch  1 Batch    0 Training err. 0.06501 Training err. RA 0.07471 Valid. err. 3.31524 Time elapsed: 00:00:08
2018-02-08 13:46:48,227 training [INFO ] Epoch  1 Batch    0 Training err. 0.06693 Training err. RA 0.07462 Valid. err. 3.31458 Time elapsed: 00:00:08
2018-02-08 13:46:48,311 training [INFO ] Epoch  1 Batch    0 Training err. 0.06339 Training err. RA 0.07450 Valid. err. 3.30822 Time elapsed: 00:00:08
2018-02-08 13:46:48,396 training [INFO ] Epoch  1 Batch    0 Training err. 0.06591 Training err. RA 0.07441 Valid. err. 3.30824 Time elapsed: 00:00:08
2018-02-08 13:46:48,493 training [INFO ] Epoch  1 Batch    0 Training err. 0.07044 Training err. RA 0.07437 Valid. err. 3.30437 Time elapsed: 00:00:08
2018-02-08 13:46:48,578 training [INFO ] Epoch  1 Batch    0 Training err. 0.06335 Training err. RA 0.07425 Valid. err. 3.30858 Time elapsed: 00:00:08
2018-02-08 13:46:48,662 training [INFO ] Epoch  1 Batch    0 Training err. 0.06594 Training err. RA 0.07416 Valid. err. 3.31878 Time elapsed: 00:00:08
2018-02-08 13:46:48,759 training [INFO ] Epoch  1 Batch    0 Training err. 0.06552 Training err. RA 0.07407 Valid. err. 3.31351 Time elapsed: 00:00:08
2018-02-08 13:46:48,848 training [INFO ] Epoch  1 Batch    0 Training err. 0.06603 Training err. RA 0.07399 Valid. err. 3.30888 Time elapsed: 00:00:09
2018-02-08 13:46:48,965 training [INFO ] Epoch  1 Batch    0 Training err. 0.07348 Training err. RA 0.07399 Valid. err. 3.30103 Time elapsed: 00:00:09
2018-02-08 13:46:49,057 training [INFO ] Epoch  1 Batch    0 Training err. 0.06640 Training err. RA 0.07391 Valid. err. 3.29350 Time elapsed: 00:00:09
2018-02-08 13:46:49,143 training [INFO ] Epoch  1 Batch    0 Training err. 0.06073 Training err. RA 0.07378 Valid. err. 3.29456 Time elapsed: 00:00:09
2018-02-08 13:46:49,240 training [INFO ] Epoch  1 Batch    0 Training err. 0.06488 Training err. RA 0.07369 Valid. err. 3.30339 Time elapsed: 00:00:09
2018-02-08 13:46:49,325 training [INFO ] Epoch  1 Batch    0 Training err. 0.07634 Training err. RA 0.07372 Valid. err. 3.29049 Time elapsed: 00:00:09
2018-02-08 13:46:49,411 training [INFO ] Epoch  1 Batch    0 Training err. 0.06859 Training err. RA 0.07367 Valid. err. 3.29146 Time elapsed: 00:00:09
2018-02-08 13:46:49,506 training [INFO ] Epoch  1 Batch    0 Training err. 0.06713 Training err. RA 0.07361 Valid. err. 3.29569 Time elapsed: 00:00:09
2018-02-08 13:46:49,590 training [INFO ] Epoch  1 Batch    0 Training err. 0.06105 Training err. RA 0.07349 Valid. err. 3.28989 Time elapsed: 00:00:09
2018-02-08 13:46:49,676 training [INFO ] Epoch  1 Batch    0 Training err. 0.06444 Training err. RA 0.07340 Valid. err. 3.30289 Time elapsed: 00:00:09
2018-02-08 13:46:49,774 training [INFO ] Epoch  1 Batch    0 Training err. 0.06234 Training err. RA 0.07330 Valid. err. 3.29404 Time elapsed: 00:00:09
2018-02-08 13:46:49,865 training [INFO ] Epoch  1 Batch    0 Training err. 0.06645 Training err. RA 0.07324 Valid. err. 3.27983 Time elapsed: 00:00:10
2018-02-08 13:46:49,955 training [INFO ] Epoch  1 Batch    0 Training err. 0.06623 Training err. RA 0.07317 Valid. err. 3.28902 Time elapsed: 00:00:10
2018-02-08 13:46:50,049 training [INFO ] Epoch  1 Batch    0 Training err. 0.06602 Training err. RA 0.07311 Valid. err. 3.27569 Time elapsed: 00:00:10
2018-02-08 13:46:50,134 training [INFO ] Epoch  1 Batch    0 Training err. 0.06238 Training err. RA 0.07301 Valid. err. 3.27638 Time elapsed: 00:00:10
2018-02-08 13:46:50,218 training [INFO ] Epoch  1 Batch    0 Training err. 0.06462 Training err. RA 0.07294 Valid. err. 3.27627 Time elapsed: 00:00:10
2018-02-08 13:46:50,314 training [INFO ] Epoch  1 Batch    0 Training err. 0.06267 Training err. RA 0.07285 Valid. err. 3.27977 Time elapsed: 00:00:10
2018-02-08 13:46:50,398 training [INFO ] Epoch  1 Batch    0 Training err. 0.07353 Training err. RA 0.07286 Valid. err. 3.27088 Time elapsed: 00:00:10
2018-02-08 13:46:50,484 training [INFO ] Epoch  1 Batch    0 Training err. 0.05832 Training err. RA 0.07273 Valid. err. 3.27550 Time elapsed: 00:00:10
2018-02-08 13:46:50,580 training [INFO ] Epoch  1 Batch    0 Training err. 0.06382 Training err. RA 0.07265 Valid. err. 3.27497 Time elapsed: 00:00:10
2018-02-08 13:46:50,669 training [INFO ] Epoch  1 Batch    0 Training err. 0.06153 Training err. RA 0.07256 Valid. err. 3.28662 Time elapsed: 00:00:10
2018-02-08 13:46:50,752 training [INFO ] Epoch  1 Batch    0 Training err. 0.05779 Training err. RA 0.07244 Valid. err. 3.29024 Time elapsed: 00:00:10
2018-02-08 13:46:50,847 training [INFO ] Epoch  1 Batch    0 Training err. 0.06582 Training err. RA 0.07238 Valid. err. 3.27513 Time elapsed: 00:00:11
2018-02-08 13:46:50,932 training [INFO ] Epoch  1 Batch    0 Training err. 0.07114 Training err. RA 0.07237 Valid. err. 3.28222 Time elapsed: 00:00:11
2018-02-08 13:46:51,015 training [INFO ] Epoch  1 Batch    0 Training err. 0.06460 Training err. RA 0.07231 Valid. err. 3.27806 Time elapsed: 00:00:11
2018-02-08 13:46:51,111 training [INFO ] Epoch  1 Batch    0 Training err. 0.06055 Training err. RA 0.07221 Valid. err. 3.26464 Time elapsed: 00:00:11
2018-02-08 13:46:51,197 training [INFO ] Epoch  1 Batch    0 Training err. 0.06278 Training err. RA 0.07214 Valid. err. 3.27944 Time elapsed: 00:00:11
2018-02-08 13:46:51,281 training [INFO ] Epoch  1 Batch    0 Training err. 0.06274 Training err. RA 0.07206 Valid. err. 3.29634 Time elapsed: 00:00:11
2018-02-08 13:46:51,377 training [INFO ] Epoch  1 Batch    0 Training err. 0.07085 Training err. RA 0.07205 Valid. err. 3.27771 Time elapsed: 00:00:11
2018-02-08 13:46:51,461 training [INFO ] Epoch  1 Batch    0 Training err. 0.06075 Training err. RA 0.07196 Valid. err. 3.27194 Time elapsed: 00:00:11
2018-02-08 13:46:51,550 training [INFO ] Epoch  1 Batch    0 Training err. 0.06115 Training err. RA 0.07188 Valid. err. 3.27496 Time elapsed: 00:00:11
2018-02-08 13:46:51,645 training [INFO ] Epoch  1 Batch    0 Training err. 0.06059 Training err. RA 0.07179 Valid. err. 3.27958 Time elapsed: 00:00:11
2018-02-08 13:46:51,729 training [INFO ] Epoch  1 Batch    0 Training err. 0.06563 Training err. RA 0.07174 Valid. err. 3.27488 Time elapsed: 00:00:11
2018-02-08 13:46:51,819 training [INFO ] Epoch  1 Batch    0 Training err. 0.06536 Training err. RA 0.07169 Valid. err. 3.26999 Time elapsed: 00:00:11
2018-02-08 13:46:51,921 training [INFO ] Epoch  1 Batch    0 Training err. 0.06671 Training err. RA 0.07166 Valid. err. 3.26757 Time elapsed: 00:00:12
2018-02-08 13:46:52,005 training [INFO ] Epoch  1 Batch    0 Training err. 0.06295 Training err. RA 0.07159 Valid. err. 3.26263 Time elapsed: 00:00:12
2018-02-08 13:46:52,091 training [INFO ] Epoch  1 Batch    0 Training err. 0.07021 Training err. RA 0.07158 Valid. err. 3.26036 Time elapsed: 00:00:12
2018-02-08 13:46:52,187 training [INFO ] Epoch  1 Batch    0 Training err. 0.06196 Training err. RA 0.07151 Valid. err. 3.26013 Time elapsed: 00:00:12
2018-02-08 13:46:52,273 training [INFO ] Epoch  1 Batch    0 Training err. 0.06178 Training err. RA 0.07144 Valid. err. 3.25881 Time elapsed: 00:00:12
2018-02-08 13:46:52,363 training [INFO ] Epoch  1 Batch    0 Training err. 0.07206 Training err. RA 0.07144 Valid. err. 3.25792 Time elapsed: 00:00:12
2018-02-08 13:46:52,461 training [INFO ] Epoch  1 Batch    0 Training err. 0.06175 Training err. RA 0.07137 Valid. err. 3.26301 Time elapsed: 00:00:12
2018-02-08 13:46:52,546 training [INFO ] Epoch  1 Batch    0 Training err. 0.06530 Training err. RA 0.07133 Valid. err. 3.26749 Time elapsed: 00:00:12
2018-02-08 13:46:52,630 training [INFO ] Epoch  1 Batch    0 Training err. 0.06972 Training err. RA 0.07132 Valid. err. 3.26302 Time elapsed: 00:00:12
2018-02-08 13:46:52,726 training [INFO ] Epoch  1 Batch    0 Training err. 0.06870 Training err. RA 0.07130 Valid. err. 3.25569 Time elapsed: 00:00:12
2018-02-08 13:46:52,816 training [INFO ] Epoch  1 Batch    0 Training err. 0.06201 Training err. RA 0.07123 Valid. err. 3.24702 Time elapsed: 00:00:12
2018-02-08 13:46:52,908 training [INFO ] Epoch  1 Batch    0 Training err. 0.06504 Training err. RA 0.07119 Valid. err. 3.24992 Time elapsed: 00:00:13
2018-02-08 13:46:53,004 training [INFO ] Epoch  1 Batch    0 Training err. 0.06693 Training err. RA 0.07116 Valid. err. 3.25421 Time elapsed: 00:00:13
2018-02-08 13:46:53,089 training [INFO ] Epoch  1 Batch    0 Training err. 0.05969 Training err. RA 0.07108 Valid. err. 3.25797 Time elapsed: 00:00:13
2018-02-08 13:46:53,173 training [INFO ] Epoch  1 Batch    0 Training err. 0.06436 Training err. RA 0.07103 Valid. err. 3.25125 Time elapsed: 00:00:13
2018-02-08 13:46:53,272 training [INFO ] Epoch  1 Batch    0 Training err. 0.07156 Training err. RA 0.07104 Valid. err. 3.25331 Time elapsed: 00:00:13
2018-02-08 13:46:53,357 training [INFO ] Epoch  1 Batch    0 Training err. 0.06275 Training err. RA 0.07098 Valid. err. 3.25543 Time elapsed: 00:00:13
2018-02-08 13:46:53,441 training [INFO ] Epoch  1 Batch    0 Training err. 0.06133 Training err. RA 0.07092 Valid. err. 3.26712 Time elapsed: 00:00:13
2018-02-08 13:46:53,537 training [INFO ] Epoch  1 Batch    0 Training err. 0.06238 Training err. RA 0.07086 Valid. err. 3.28537 Time elapsed: 00:00:13
2018-02-08 13:46:53,621 training [INFO ] Epoch  1 Batch    0 Training err. 0.06257 Training err. RA 0.07081 Valid. err. 3.25953 Time elapsed: 00:00:13
2018-02-08 13:46:53,706 training [INFO ] Epoch  1 Batch    0 Training err. 0.05923 Training err. RA 0.07073 Valid. err. 3.26669 Time elapsed: 00:00:13
2018-02-08 13:46:53,807 training [INFO ] Epoch  1 Batch    0 Training err. 0.06697 Training err. RA 0.07070 Valid. err. 3.26133 Time elapsed: 00:00:13
2018-02-08 13:46:53,893 training [INFO ] Epoch  1 Batch    0 Training err. 0.06281 Training err. RA 0.07065 Valid. err. 3.25975 Time elapsed: 00:00:14
2018-02-08 13:46:53,978 training [INFO ] Epoch  1 Batch    0 Training err. 0.06069 Training err. RA 0.07059 Valid. err. 3.26066 Time elapsed: 00:00:14
2018-02-08 13:46:54,072 training [INFO ] Epoch  1 Batch    0 Training err. 0.06584 Training err. RA 0.07056 Valid. err. 3.25530 Time elapsed: 00:00:14
2018-02-08 13:46:54,161 training [INFO ] Epoch  1 Batch    0 Training err. 0.06096 Training err. RA 0.07050 Valid. err. 3.26264 Time elapsed: 00:00:14
2018-02-08 13:46:54,246 training [INFO ] Epoch  1 Batch    0 Training err. 0.06084 Training err. RA 0.07044 Valid. err. 3.25544 Time elapsed: 00:00:14
2018-02-08 13:46:54,343 training [INFO ] Epoch  1 Batch    0 Training err. 0.07633 Training err. RA 0.07047 Valid. err. 3.26387 Time elapsed: 00:00:14
2018-02-08 13:46:54,427 training [INFO ] Epoch  1 Batch    0 Training err. 0.06093 Training err. RA 0.07041 Valid. err. 3.25145 Time elapsed: 00:00:14
2018-02-08 13:46:54,511 training [INFO ] Epoch  1 Batch    0 Training err. 0.06490 Training err. RA 0.07038 Valid. err. 3.24520 Time elapsed: 00:00:14
2018-02-08 13:46:54,608 training [INFO ] Epoch  1 Batch    0 Training err. 0.06134 Training err. RA 0.07032 Valid. err. 3.25902 Time elapsed: 00:00:14
2018-02-08 13:46:54,716 training [INFO ] Epoch  1 Batch    0 Training err. 0.06333 Training err. RA 0.07028 Valid. err. 3.26979 Time elapsed: 00:00:14
2018-02-08 13:46:54,804 training [INFO ] Epoch  1 Batch    0 Training err. 0.06384 Training err. RA 0.07024 Valid. err. 3.24778 Time elapsed: 00:00:14
2018-02-08 13:46:54,907 training [INFO ] Epoch  1 Batch    0 Training err. 0.06776 Training err. RA 0.07023 Valid. err. 3.25179 Time elapsed: 00:00:15
2018-02-08 13:46:54,997 training [INFO ] Epoch  1 Batch    0 Training err. 0.06638 Training err. RA 0.07020 Valid. err. 3.26224 Time elapsed: 00:00:15
2018-02-08 13:46:55,082 training [INFO ] Epoch  1 Batch    0 Training err. 0.07078 Training err. RA 0.07021 Valid. err. 3.27018 Time elapsed: 00:00:15
2018-02-08 13:46:55,178 training [INFO ] Epoch  1 Batch    0 Training err. 0.05899 Training err. RA 0.07014 Valid. err. 3.25181 Time elapsed: 00:00:15
2018-02-08 13:46:55,262 training [INFO ] Epoch  1 Batch    0 Training err. 0.07003 Training err. RA 0.07014 Valid. err. 3.27019 Time elapsed: 00:00:15
2018-02-08 13:46:55,347 training [INFO ] Epoch  1 Batch    0 Training err. 0.06344 Training err. RA 0.07010 Valid. err. 3.26937 Time elapsed: 00:00:15
2018-02-08 13:46:55,442 training [INFO ] Epoch  1 Batch    0 Training err. 0.05858 Training err. RA 0.07003 Valid. err. 3.27574 Time elapsed: 00:00:15
2018-02-08 13:46:55,526 training [INFO ] Epoch  1 Batch    0 Training err. 0.06936 Training err. RA 0.07003 Valid. err. 3.26405 Time elapsed: 00:00:15
2018-02-08 13:46:55,611 training [INFO ] Epoch  1 Batch    0 Training err. 0.06430 Training err. RA 0.07000 Valid. err. 3.25397 Time elapsed: 00:00:15
2018-02-08 13:46:55,706 training [INFO ] Epoch  1 Batch    0 Training err. 0.05660 Training err. RA 0.06992 Valid. err. 3.25186 Time elapsed: 00:00:15
2018-02-08 13:46:55,791 training [INFO ] Epoch  1 Batch    0 Training err. 0.06921 Training err. RA 0.06991 Valid. err. 3.24201 Time elapsed: 00:00:15
2018-02-08 13:46:55,886 training [INFO ] Epoch  1 Batch    0 Training err. 0.06548 Training err. RA 0.06989 Valid. err. 3.25046 Time elapsed: 00:00:16
2018-02-08 13:46:55,983 training [INFO ] Epoch  1 Batch    0 Training err. 0.07137 Training err. RA 0.06990 Valid. err. 3.25601 Time elapsed: 00:00:16
2018-02-08 13:46:56,068 training [INFO ] Epoch  1 Batch    0 Training err. 0.06725 Training err. RA 0.06988 Valid. err. 3.24983 Time elapsed: 00:00:16
2018-02-08 13:46:56,152 training [INFO ] Epoch  1 Batch    0 Training err. 0.05945 Training err. RA 0.06982 Valid. err. 3.25553 Time elapsed: 00:00:16
2018-02-08 13:46:56,248 training [INFO ] Epoch  1 Batch    0 Training err. 0.06888 Training err. RA 0.06982 Valid. err. 3.25328 Time elapsed: 00:00:16
2018-02-08 13:46:56,332 training [INFO ] Epoch  1 Batch    0 Training err. 0.06762 Training err. RA 0.06981 Valid. err. 3.24438 Time elapsed: 00:00:16
2018-02-08 13:46:56,417 training [INFO ] Epoch  1 Batch    0 Training err. 0.06776 Training err. RA 0.06980 Valid. err. 3.23965 Time elapsed: 00:00:16
2018-02-08 13:46:56,514 training [INFO ] Epoch  1 Batch    0 Training err. 0.06009 Training err. RA 0.06974 Valid. err. 3.24388 Time elapsed: 00:00:16
2018-02-08 13:46:56,599 training [INFO ] Epoch  1 Batch    0 Training err. 0.06573 Training err. RA 0.06972 Valid. err. 3.23638 Time elapsed: 00:00:16
2018-02-08 13:46:56,691 training [INFO ] Epoch  1 Batch    0 Training err. 0.06662 Training err. RA 0.06970 Valid. err. 3.23694 Time elapsed: 00:00:16
2018-02-08 13:46:56,787 training [INFO ] Epoch  1 Batch    0 Training err. 0.06195 Training err. RA 0.06966 Valid. err. 3.23123 Time elapsed: 00:00:16
2018-02-08 13:46:56,879 training [INFO ] Epoch  1 Batch    0 Training err. 0.07118 Training err. RA 0.06967 Valid. err. 3.24502 Time elapsed: 00:00:17
2018-02-08 13:46:56,963 training [INFO ] Epoch  1 Batch    0 Training err. 0.06525 Training err. RA 0.06965 Valid. err. 3.23491 Time elapsed: 00:00:17
2018-02-08 13:46:57,059 training [INFO ] Epoch  1 Batch    0 Training err. 0.06112 Training err. RA 0.06960 Valid. err. 3.25192 Time elapsed: 00:00:17
2018-02-08 13:46:57,143 training [INFO ] Epoch  1 Batch    0 Training err. 0.06488 Training err. RA 0.06958 Valid. err. 3.24664 Time elapsed: 00:00:17
2018-02-08 13:46:57,227 training [INFO ] Epoch  1 Batch    0 Training err. 0.06383 Training err. RA 0.06955 Valid. err. 3.25097 Time elapsed: 00:00:17
2018-02-08 13:46:57,323 training [INFO ] Epoch  1 Batch    0 Training err. 0.05815 Training err. RA 0.06949 Valid. err. 3.25423 Time elapsed: 00:00:17
2018-02-08 13:46:57,407 training [INFO ] Epoch  1 Batch    0 Training err. 0.06796 Training err. RA 0.06948 Valid. err. 3.26445 Time elapsed: 00:00:17
2018-02-08 13:46:57,491 training [INFO ] Epoch  1 Batch    0 Training err. 0.07557 Training err. RA 0.06951 Valid. err. 3.28046 Time elapsed: 00:00:17
2018-02-08 13:46:57,593 training [INFO ] Epoch  1 Batch    0 Training err. 0.06393 Training err. RA 0.06948 Valid. err. 3.25687 Time elapsed: 00:00:17
2018-02-08 13:46:57,677 training [INFO ] Epoch  1 Batch    0 Training err. 0.06597 Training err. RA 0.06946 Valid. err. 3.26749 Time elapsed: 00:00:17
2018-02-08 13:46:57,761 training [INFO ] Epoch  1 Batch    0 Training err. 0.06101 Training err. RA 0.06942 Valid. err. 3.25620 Time elapsed: 00:00:17
2018-02-08 13:46:57,859 training [INFO ] Epoch  1 Batch    0 Training err. 0.06307 Training err. RA 0.06939 Valid. err. 3.25854 Time elapsed: 00:00:18
2018-02-08 13:46:57,948 training [INFO ] Epoch  1 Batch    0 Training err. 0.06453 Training err. RA 0.06937 Valid. err. 3.25672 Time elapsed: 00:00:18
2018-02-08 13:46:58,032 training [INFO ] Epoch  1 Batch    0 Training err. 0.06402 Training err. RA 0.06934 Valid. err. 3.24668 Time elapsed: 00:00:18
2018-02-08 13:46:58,129 training [INFO ] Epoch  1 Batch    0 Training err. 0.06217 Training err. RA 0.06930 Valid. err. 3.26209 Time elapsed: 00:00:18
2018-02-08 13:46:58,213 training [INFO ] Epoch  1 Batch    0 Training err. 0.06730 Training err. RA 0.06929 Valid. err. 3.24883 Time elapsed: 00:00:18
2018-02-08 13:46:58,296 training [INFO ] Epoch  1 Batch    0 Training err. 0.06352 Training err. RA 0.06926 Valid. err. 3.27002 Time elapsed: 00:00:18
2018-02-08 13:46:58,392 training [INFO ] Epoch  1 Batch    0 Training err. 0.06265 Training err. RA 0.06923 Valid. err. 3.25627 Time elapsed: 00:00:18
2018-02-08 13:46:58,481 training [INFO ] Epoch  1 Batch    0 Training err. 0.06393 Training err. RA 0.06921 Valid. err. 3.24053 Time elapsed: 00:00:18
2018-02-08 13:46:58,566 training [INFO ] Epoch  1 Batch    0 Training err. 0.06602 Training err. RA 0.06919 Valid. err. 3.24276 Time elapsed: 00:00:18
2018-02-08 13:46:58,662 training [INFO ] Epoch  1 Batch    0 Training err. 0.06365 Training err. RA 0.06916 Valid. err. 3.24293 Time elapsed: 00:00:18
2018-02-08 13:46:58,769 training [INFO ] Epoch  1 Batch    0 Training err. 0.07022 Training err. RA 0.06917 Valid. err. 3.24277 Time elapsed: 00:00:18
2018-02-08 13:46:58,860 training [INFO ] Epoch  1 Batch    0 Training err. 0.06692 Training err. RA 0.06916 Valid. err. 3.24857 Time elapsed: 00:00:19
2018-02-08 13:46:58,963 training [INFO ] Epoch  1 Batch    0 Training err. 0.06269 Training err. RA 0.06913 Valid. err. 3.26037 Time elapsed: 00:00:19
2018-02-08 13:46:59,047 training [INFO ] Epoch  1 Batch    0 Training err. 0.06585 Training err. RA 0.06911 Valid. err. 3.24388 Time elapsed: 00:00:19
2018-02-08 13:46:59,132 training [INFO ] Epoch  1 Batch    0 Training err. 0.06218 Training err. RA 0.06908 Valid. err. 3.23895 Time elapsed: 00:00:19
2018-02-08 13:46:59,229 training [INFO ] Epoch  1 Batch    0 Training err. 0.06356 Training err. RA 0.06905 Valid. err. 3.24444 Time elapsed: 00:00:19
2018-02-08 13:46:59,319 training [INFO ] Epoch  1 Batch    0 Training err. 0.06028 Training err. RA 0.06901 Valid. err. 3.25214 Time elapsed: 00:00:19
2018-02-08 13:46:59,410 training [INFO ] Epoch  1 Batch    0 Training err. 0.06415 Training err. RA 0.06899 Valid. err. 3.25238 Time elapsed: 00:00:19
2018-02-08 13:46:59,505 training [INFO ] Epoch  1 Batch    0 Training err. 0.06214 Training err. RA 0.06896 Valid. err. 3.24931 Time elapsed: 00:00:19
2018-02-08 13:46:59,591 training [INFO ] Epoch  1 Batch    0 Training err. 0.06359 Training err. RA 0.06893 Valid. err. 3.24538 Time elapsed: 00:00:19
2018-02-08 13:46:59,676 training [INFO ] Epoch  1 Batch    0 Training err. 0.06355 Training err. RA 0.06891 Valid. err. 3.24420 Time elapsed: 00:00:19
2018-02-08 13:46:59,775 training [INFO ] Epoch  1 Batch    0 Training err. 0.06271 Training err. RA 0.06888 Valid. err. 3.25294 Time elapsed: 00:00:19
2018-02-08 13:46:59,867 training [INFO ] Epoch  1 Batch    0 Training err. 0.06208 Training err. RA 0.06885 Valid. err. 3.24646 Time elapsed: 00:00:20
2018-02-08 13:46:59,958 training [INFO ] Epoch  1 Batch    0 Training err. 0.06358 Training err. RA 0.06883 Valid. err. 3.24118 Time elapsed: 00:00:20
2018-02-08 13:47:00,054 training [INFO ] Epoch  1 Batch    0 Training err. 0.06982 Training err. RA 0.06883 Valid. err. 3.24644 Time elapsed: 00:00:20
2018-02-08 13:47:00,152 training [INFO ] Epoch  1 Batch    0 Training err. 0.06462 Training err. RA 0.06881 Valid. err. 3.24812 Time elapsed: 00:00:20
2018-02-08 13:47:00,236 training [INFO ] Epoch  1 Batch    0 Training err. 0.06076 Training err. RA 0.06878 Valid. err. 3.24978 Time elapsed: 00:00:20
2018-02-08 13:47:00,335 training [INFO ] Epoch  1 Batch    0 Training err. 0.06629 Training err. RA 0.06876 Valid. err. 3.23855 Time elapsed: 00:00:20
2018-02-08 13:47:00,427 training [INFO ] Epoch  1 Batch    0 Training err. 0.05942 Training err. RA 0.06872 Valid. err. 3.24489 Time elapsed: 00:00:20
2018-02-08 13:47:00,512 training [INFO ] Epoch  1 Batch    0 Training err. 0.06442 Training err. RA 0.06870 Valid. err. 3.24540 Time elapsed: 00:00:20
2018-02-08 13:47:00,608 training [INFO ] Epoch  1 Batch    0 Training err. 0.06007 Training err. RA 0.06867 Valid. err. 3.25860 Time elapsed: 00:00:20
2018-02-08 13:47:00,692 training [INFO ] Epoch  1 Batch    0 Training err. 0.06335 Training err. RA 0.06864 Valid. err. 3.26086 Time elapsed: 00:00:20
2018-02-08 13:47:00,776 training [INFO ] Epoch  1 Batch    0 Training err. 0.06144 Training err. RA 0.06861 Valid. err. 3.25966 Time elapsed: 00:00:20
2018-02-08 13:47:00,883 training [INFO ] Epoch  1 Batch    0 Training err. 0.06088 Training err. RA 0.06858 Valid. err. 3.25095 Time elapsed: 00:00:21
2018-02-08 13:47:00,974 training [INFO ] Epoch  1 Batch    0 Training err. 0.06755 Training err. RA 0.06857 Valid. err. 3.25787 Time elapsed: 00:00:21
2018-02-08 13:47:01,065 training [INFO ] Epoch  1 Batch    0 Training err. 0.05837 Training err. RA 0.06853 Valid. err. 3.26829 Time elapsed: 00:00:21
2018-02-08 13:47:01,161 training [INFO ] Epoch  1 Batch    0 Training err. 0.07048 Training err. RA 0.06854 Valid. err. 3.25314 Time elapsed: 00:00:21
2018-02-08 13:47:01,247 training [INFO ] Epoch  1 Batch    0 Training err. 0.06375 Training err. RA 0.06852 Valid. err. 3.24494 Time elapsed: 00:00:21
2018-02-08 13:47:01,333 training [INFO ] Epoch  1 Batch    0 Training err. 0.06145 Training err. RA 0.06849 Valid. err. 3.24374 Time elapsed: 00:00:21
2018-02-08 13:47:01,433 training [INFO ] Epoch  1 Batch    0 Training err. 0.06851 Training err. RA 0.06849 Valid. err. 3.23438 Time elapsed: 00:00:21
2018-02-08 13:47:01,518 training [INFO ] Epoch  1 Batch    0 Training err. 0.06445 Training err. RA 0.06847 Valid. err. 3.23746 Time elapsed: 00:00:21
2018-02-08 13:47:01,603 training [INFO ] Epoch  1 Batch    0 Training err. 0.06693 Training err. RA 0.06846 Valid. err. 3.25357 Time elapsed: 00:00:21
2018-02-08 13:47:01,701 training [INFO ] Epoch  1 Batch    0 Training err. 0.05868 Training err. RA 0.06842 Valid. err. 3.27390 Time elapsed: 00:00:21
2018-02-08 13:47:01,786 training [INFO ] Epoch  1 Batch    0 Training err. 0.06687 Training err. RA 0.06842 Valid. err. 3.29004 Time elapsed: 00:00:21
2018-02-08 13:47:01,881 training [INFO ] Epoch  1 Batch    0 Training err. 0.07020 Training err. RA 0.06842 Valid. err. 3.25772 Time elapsed: 00:00:22
2018-02-08 13:47:01,981 training [INFO ] Epoch  1 Batch    0 Training err. 0.06802 Training err. RA 0.06842 Valid. err. 3.26297 Time elapsed: 00:00:22
2018-02-08 13:47:02,066 training [INFO ] Epoch  1 Batch    0 Training err. 0.05942 Training err. RA 0.06839 Valid. err. 3.27523 Time elapsed: 00:00:22
2018-02-08 13:47:02,150 training [INFO ] Epoch  1 Batch    0 Training err. 0.06696 Training err. RA 0.06838 Valid. err. 3.26673 Time elapsed: 00:00:22
2018-02-08 13:47:02,247 training [INFO ] Epoch  1 Batch    0 Training err. 0.06238 Training err. RA 0.06836 Valid. err. 3.25488 Time elapsed: 00:00:22
2018-02-08 13:47:02,331 training [INFO ] Epoch  1 Batch    0 Training err. 0.06205 Training err. RA 0.06833 Valid. err. 3.25533 Time elapsed: 00:00:22
2018-02-08 13:47:02,425 training [INFO ] Epoch  1 Batch    0 Training err. 0.06376 Training err. RA 0.06831 Valid. err. 3.25932 Time elapsed: 00:00:22
2018-02-08 13:47:02,523 training [INFO ] Epoch  1 Batch    0 Training err. 0.06019 Training err. RA 0.06828 Valid. err. 3.24545 Time elapsed: 00:00:22
2018-02-08 13:47:02,609 training [INFO ] Epoch  1 Batch    0 Training err. 0.06000 Training err. RA 0.06825 Valid. err. 3.25093 Time elapsed: 00:00:22
2018-02-08 13:47:02,696 training [INFO ] Epoch  1 Batch    0 Training err. 0.07225 Training err. RA 0.06826 Valid. err. 3.23608 Time elapsed: 00:00:22
2018-02-08 13:47:02,796 training [INFO ] Epoch  1 Batch    0 Training err. 0.05933 Training err. RA 0.06823 Valid. err. 3.23513 Time elapsed: 00:00:22
2018-02-08 13:47:02,890 training [INFO ] Epoch  1 Batch    0 Training err. 0.06413 Training err. RA 0.06821 Valid. err. 3.24033 Time elapsed: 00:00:23
2018-02-08 13:47:02,977 training [INFO ] Epoch  1 Batch    0 Training err. 0.07588 Training err. RA 0.06824 Valid. err. 3.23773 Time elapsed: 00:00:23
2018-02-08 13:47:03,075 training [INFO ] Epoch  1 Batch    0 Training err. 0.06619 Training err. RA 0.06823 Valid. err. 3.23555 Time elapsed: 00:00:23
2018-02-08 13:47:03,160 training [INFO ] Epoch  1 Batch    0 Training err. 0.06742 Training err. RA 0.06823 Valid. err. 3.23496 Time elapsed: 00:00:23
2018-02-08 13:47:03,246 training [INFO ] Epoch  1 Batch    0 Training err. 0.06331 Training err. RA 0.06821 Valid. err. 3.23263 Time elapsed: 00:00:23
2018-02-08 13:47:03,343 training [INFO ] Epoch  1 Batch    0 Training err. 0.06891 Training err. RA 0.06821 Valid. err. 3.23123 Time elapsed: 00:00:23
2018-02-08 13:47:03,436 training [INFO ] Epoch  1 Batch    0 Training err. 0.06631 Training err. RA 0.06821 Valid. err. 3.24097 Time elapsed: 00:00:23
2018-02-08 13:47:03,523 training [INFO ] Epoch  1 Batch    0 Training err. 0.06328 Training err. RA 0.06819 Valid. err. 3.24884 Time elapsed: 00:00:23
2018-02-08 13:47:03,627 training [INFO ] Epoch  1 Batch    0 Training err. 0.06612 Training err. RA 0.06818 Valid. err. 3.24412 Time elapsed: 00:00:23
2018-02-08 13:47:03,713 training [INFO ] Epoch  1 Batch    0 Training err. 0.06231 Training err. RA 0.06816 Valid. err. 3.24502 Time elapsed: 00:00:23
2018-02-08 13:47:03,803 training [INFO ] Epoch  1 Batch    0 Training err. 0.05975 Training err. RA 0.06812 Valid. err. 3.23794 Time elapsed: 00:00:23
2018-02-08 13:47:03,910 training [INFO ] Epoch  1 Batch    0 Training err. 0.06969 Training err. RA 0.06813 Valid. err. 3.24996 Time elapsed: 00:00:24
2018-02-08 13:47:03,999 training [INFO ] Epoch  1 Batch    0 Training err. 0.05886 Training err. RA 0.06810 Valid. err. 3.25128 Time elapsed: 00:00:24
2018-02-08 13:47:04,086 training [INFO ] Epoch  1 Batch    0 Training err. 0.06544 Training err. RA 0.06809 Valid. err. 3.25084 Time elapsed: 00:00:24
2018-02-08 13:47:04,180 training [INFO ] Epoch  1 Batch    0 Training err. 0.06043 Training err. RA 0.06806 Valid. err. 3.25933 Time elapsed: 00:00:24
2018-02-08 13:47:04,266 training [INFO ] Epoch  1 Batch    0 Training err. 0.06603 Training err. RA 0.06805 Valid. err. 3.24378 Time elapsed: 00:00:24
2018-02-08 13:47:04,352 training [INFO ] Epoch  1 Batch    0 Training err. 0.06100 Training err. RA 0.06802 Valid. err. 3.24211 Time elapsed: 00:00:24
2018-02-08 13:47:04,456 training [INFO ] Epoch  1 Batch    0 Training err. 0.07077 Training err. RA 0.06803 Valid. err. 3.23863 Time elapsed: 00:00:24
2018-02-08 13:47:04,548 training [INFO ] Epoch  1 Batch    0 Training err. 0.06800 Training err. RA 0.06803 Valid. err. 3.23372 Time elapsed: 00:00:24
2018-02-08 13:47:04,633 training [INFO ] Epoch  1 Batch    0 Training err. 0.06814 Training err. RA 0.06803 Valid. err. 3.22225 Time elapsed: 00:00:24
2018-02-08 13:47:04,733 training [INFO ] Epoch  1 Batch    0 Training err. 0.06267 Training err. RA 0.06801 Valid. err. 3.21808 Time elapsed: 00:00:24
2018-02-08 13:47:04,831 training [INFO ] Epoch  1 Batch    0 Training err. 0.06006 Training err. RA 0.06798 Valid. err. 3.22861 Time elapsed: 00:00:24
2018-02-08 13:47:04,927 training [INFO ] Epoch  1 Batch    0 Training err. 0.06444 Training err. RA 0.06797 Valid. err. 3.22650 Time elapsed: 00:00:25
2018-02-08 13:47:05,026 training [INFO ] Epoch  1 Batch    0 Training err. 0.05814 Training err. RA 0.06794 Valid. err. 3.22805 Time elapsed: 00:00:25
2018-02-08 13:47:05,112 training [INFO ] Epoch  1 Batch    0 Training err. 0.07084 Training err. RA 0.06795 Valid. err. 3.23170 Time elapsed: 00:00:25
2018-02-08 13:47:05,198 training [INFO ] Epoch  1 Batch    0 Training err. 0.06695 Training err. RA 0.06794 Valid. err. 3.21808 Time elapsed: 00:00:25
2018-02-08 13:47:05,298 training [INFO ] Epoch  1 Batch    0 Training err. 0.07020 Training err. RA 0.06795 Valid. err. 3.22282 Time elapsed: 00:00:25
2018-02-08 13:47:05,391 training [INFO ] Epoch  1 Batch    0 Training err. 0.06630 Training err. RA 0.06795 Valid. err. 3.23649 Time elapsed: 00:00:25
2018-02-08 13:47:05,478 training [INFO ] Epoch  1 Batch    0 Training err. 0.06376 Training err. RA 0.06793 Valid. err. 3.22158 Time elapsed: 00:00:25
2018-02-08 13:47:05,574 training [INFO ] Epoch  1 Batch    0 Training err. 0.06120 Training err. RA 0.06791 Valid. err. 3.22368 Time elapsed: 00:00:25
2018-02-08 13:47:05,657 training [INFO ] Epoch  1 Batch    0 Training err. 0.07417 Training err. RA 0.06793 Valid. err. 3.23626 Time elapsed: 00:00:25
2018-02-08 13:47:05,741 training [INFO ] Epoch  1 Batch    0 Training err. 0.07289 Training err. RA 0.06795 Valid. err. 3.23269 Time elapsed: 00:00:25
2018-02-08 13:47:05,841 training [INFO ] Epoch  1 Batch    0 Training err. 0.06399 Training err. RA 0.06793 Valid. err. 3.22959 Time elapsed: 00:00:25
2018-02-08 13:47:05,928 training [INFO ] Epoch  1 Batch    0 Training err. 0.05849 Training err. RA 0.06790 Valid. err. 3.22267 Time elapsed: 00:00:26
2018-02-08 13:47:06,012 training [INFO ] Epoch  1 Batch    0 Training err. 0.06383 Training err. RA 0.06789 Valid. err. 3.22230 Time elapsed: 00:00:26
2018-02-08 13:47:06,110 training [INFO ] Epoch  1 Batch    0 Training err. 0.06300 Training err. RA 0.06787 Valid. err. 3.21485 Time elapsed: 00:00:26
2018-02-08 13:47:06,196 training [INFO ] Epoch  1 Batch    0 Training err. 0.06629 Training err. RA 0.06786 Valid. err. 3.21303 Time elapsed: 00:00:26
2018-02-08 13:47:06,286 training [INFO ] Epoch  1 Batch    0 Training err. 0.06083 Training err. RA 0.06784 Valid. err. 3.21426 Time elapsed: 00:00:26
2018-02-08 13:47:06,378 training [INFO ] Epoch  1 Batch    0 Training err. 0.06368 Training err. RA 0.06782 Valid. err. 3.21470 Time elapsed: 00:00:26
2018-02-08 13:47:06,466 training [INFO ] Epoch  1 Batch    0 Training err. 0.06502 Training err. RA 0.06781 Valid. err. 3.21709 Time elapsed: 00:00:26
2018-02-08 13:47:06,550 training [INFO ] Epoch  1 Batch    0 Training err. 0.06325 Training err. RA 0.06780 Valid. err. 3.21544 Time elapsed: 00:00:26
2018-02-08 13:47:06,645 training [INFO ] Epoch  1 Batch    0 Training err. 0.06717 Training err. RA 0.06780 Valid. err. 3.22598 Time elapsed: 00:00:26
2018-02-08 13:47:06,730 training [INFO ] Epoch  1 Batch    0 Training err. 0.06333 Training err. RA 0.06778 Valid. err. 3.22554 Time elapsed: 00:00:26
2018-02-08 13:47:06,818 training [INFO ] Epoch  1 Batch    0 Training err. 0.06235 Training err. RA 0.06776 Valid. err. 3.22246 Time elapsed: 00:00:26
2018-02-08 13:47:06,919 training [INFO ] Epoch  1 Batch    0 Training err. 0.06279 Training err. RA 0.06775 Valid. err. 3.22267 Time elapsed: 00:00:27
2018-02-08 13:47:07,002 training [INFO ] Epoch  1 Batch    0 Training err. 0.06048 Training err. RA 0.06772 Valid. err. 3.22640 Time elapsed: 00:00:27
2018-02-08 13:47:07,101 training [INFO ] Epoch  1 Batch    0 Training err. 0.06742 Training err. RA 0.06772 Valid. err. 3.21961 Time elapsed: 00:00:27
2018-02-08 13:47:07,202 training [INFO ] Epoch  1 Batch    0 Training err. 0.06608 Training err. RA 0.06772 Valid. err. 3.21730 Time elapsed: 00:00:27
2018-02-08 13:47:07,286 training [INFO ] Epoch  1 Batch    0 Training err. 0.06393 Training err. RA 0.06770 Valid. err. 3.23543 Time elapsed: 00:00:27
2018-02-08 13:47:07,371 training [INFO ] Epoch  1 Batch    0 Training err. 0.06706 Training err. RA 0.06770 Valid. err. 3.24778 Time elapsed: 00:00:27
2018-02-08 13:47:07,466 training [INFO ] Epoch  1 Batch    0 Training err. 0.06335 Training err. RA 0.06769 Valid. err. 3.22767 Time elapsed: 00:00:27
2018-02-08 13:47:07,550 training [INFO ] Epoch  1 Batch    0 Training err. 0.06515 Training err. RA 0.06768 Valid. err. 3.21596 Time elapsed: 00:00:27
2018-02-08 13:47:07,634 training [INFO ] Epoch  1 Batch    0 Training err. 0.06688 Training err. RA 0.06768 Valid. err. 3.21532 Time elapsed: 00:00:27
2018-02-08 13:47:07,730 training [INFO ] Epoch  1 Batch    0 Training err. 0.06314 Training err. RA 0.06766 Valid. err. 3.21816 Time elapsed: 00:00:27
2018-02-08 13:47:07,817 training [INFO ] Epoch  1 Batch    0 Training err. 0.06219 Training err. RA 0.06764 Valid. err. 3.22270 Time elapsed: 00:00:27
2018-02-08 13:47:08,066 training [INFO ] Epoch  2 Batch    0 Training err. 0.06891 Training err. RA 0.06765 Valid. err. 3.23171 Time elapsed: 00:00:28
2018-02-08 13:47:08,155 training [INFO ] Epoch  2 Batch    0 Training err. 0.06736 Training err. RA 0.06765 Valid. err. 3.23022 Time elapsed: 00:00:28
2018-02-08 13:47:08,241 training [INFO ] Epoch  2 Batch    0 Training err. 0.07435 Training err. RA 0.06767 Valid. err. 3.22625 Time elapsed: 00:00:28
2018-02-08 13:47:08,337 training [INFO ] Epoch  2 Batch    0 Training err. 0.06744 Training err. RA 0.06767 Valid. err. 3.22569 Time elapsed: 00:00:28
2018-02-08 13:47:08,422 training [INFO ] Epoch  2 Batch    0 Training err. 0.06289 Training err. RA 0.06765 Valid. err. 3.22207 Time elapsed: 00:00:28
2018-02-08 13:47:08,506 training [INFO ] Epoch  2 Batch    0 Training err. 0.06115 Training err. RA 0.06763 Valid. err. 3.22596 Time elapsed: 00:00:28
2018-02-08 13:47:08,603 training [INFO ] Epoch  2 Batch    0 Training err. 0.07309 Training err. RA 0.06765 Valid. err. 3.21465 Time elapsed: 00:00:28
2018-02-08 13:47:08,687 training [INFO ] Epoch  2 Batch    0 Training err. 0.06824 Training err. RA 0.06765 Valid. err. 3.22833 Time elapsed: 00:00:28
2018-02-08 13:47:08,771 training [INFO ] Epoch  2 Batch    0 Training err. 0.07429 Training err. RA 0.06767 Valid. err. 3.23829 Time elapsed: 00:00:28
2018-02-08 13:47:08,869 training [INFO ] Epoch  2 Batch    0 Training err. 0.06190 Training err. RA 0.06765 Valid. err. 3.23125 Time elapsed: 00:00:29
2018-02-08 13:47:08,954 training [INFO ] Epoch  2 Batch    0 Training err. 0.06569 Training err. RA 0.06765 Valid. err. 3.22703 Time elapsed: 00:00:29
2018-02-08 13:47:09,061 training [INFO ] Epoch  2 Batch    0 Training err. 0.06177 Training err. RA 0.06763 Valid. err. 3.25625 Time elapsed: 00:00:29
2018-02-08 13:47:09,160 training [INFO ] Epoch  2 Batch    0 Training err. 0.06002 Training err. RA 0.06760 Valid. err. 3.24527 Time elapsed: 00:00:29
2018-02-08 13:47:09,246 training [INFO ] Epoch  2 Batch    0 Training err. 0.06175 Training err. RA 0.06759 Valid. err. 3.22639 Time elapsed: 00:00:29
2018-02-08 13:47:09,334 training [INFO ] Epoch  2 Batch    0 Training err. 0.06530 Training err. RA 0.06758 Valid. err. 3.22867 Time elapsed: 00:00:29
2018-02-08 13:47:09,430 training [INFO ] Epoch  2 Batch    0 Training err. 0.06871 Training err. RA 0.06758 Valid. err. 3.23536 Time elapsed: 00:00:29
2018-02-08 13:47:09,514 training [INFO ] Epoch  2 Batch    0 Training err. 0.06145 Training err. RA 0.06756 Valid. err. 3.23092 Time elapsed: 00:00:29
2018-02-08 13:47:09,598 training [INFO ] Epoch  2 Batch    0 Training err. 0.06653 Training err. RA 0.06756 Valid. err. 3.23609 Time elapsed: 00:00:29
2018-02-08 13:47:09,698 training [INFO ] Epoch  2 Batch    0 Training err. 0.06068 Training err. RA 0.06754 Valid. err. 3.23361 Time elapsed: 00:00:29
2018-02-08 13:47:09,782 training [INFO ] Epoch  2 Batch    0 Training err. 0.06193 Training err. RA 0.06752 Valid. err. 3.24657 Time elapsed: 00:00:29
2018-02-08 13:47:09,872 training [INFO ] Epoch  2 Batch    0 Training err. 0.05897 Training err. RA 0.06750 Valid. err. 3.23641 Time elapsed: 00:00:30
2018-02-08 13:47:09,971 training [INFO ] Epoch  2 Batch    0 Training err. 0.06275 Training err. RA 0.06748 Valid. err. 3.25581 Time elapsed: 00:00:30
2018-02-08 13:47:10,055 training [INFO ] Epoch  2 Batch    0 Training err. 0.06211 Training err. RA 0.06747 Valid. err. 3.26803 Time elapsed: 00:00:30
2018-02-08 13:47:10,139 training [INFO ] Epoch  2 Batch    0 Training err. 0.06351 Training err. RA 0.06745 Valid. err. 3.23680 Time elapsed: 00:00:30
2018-02-08 13:47:10,237 training [INFO ] Epoch  2 Batch    0 Training err. 0.07005 Training err. RA 0.06746 Valid. err. 3.24004 Time elapsed: 00:00:30
2018-02-08 13:47:10,320 training [INFO ] Epoch  2 Batch    0 Training err. 0.05817 Training err. RA 0.06743 Valid. err. 3.25041 Time elapsed: 00:00:30
2018-02-08 13:47:10,406 training [INFO ] Epoch  2 Batch    0 Training err. 0.06304 Training err. RA 0.06742 Valid. err. 3.25881 Time elapsed: 00:00:30
2018-02-08 13:47:10,521 training [INFO ] Epoch  2 Batch    0 Training err. 0.06786 Training err. RA 0.06742 Valid. err. 3.23653 Time elapsed: 00:00:30
2018-02-08 13:47:10,611 training [INFO ] Epoch  2 Batch    0 Training err. 0.06228 Training err. RA 0.06741 Valid. err. 3.24991 Time elapsed: 00:00:30
2018-02-08 13:47:10,698 training [INFO ] Epoch  2 Batch    0 Training err. 0.06917 Training err. RA 0.06741 Valid. err. 3.23938 Time elapsed: 00:00:30
2018-02-08 13:47:10,792 training [INFO ] Epoch  2 Batch    0 Training err. 0.05788 Training err. RA 0.06738 Valid. err. 3.25776 Time elapsed: 00:00:30
2018-02-08 13:47:10,881 training [INFO ] Epoch  2 Batch    0 Training err. 0.06112 Training err. RA 0.06737 Valid. err. 3.24923 Time elapsed: 00:00:31
2018-02-08 13:47:10,972 training [INFO ] Epoch  2 Batch    0 Training err. 0.05927 Training err. RA 0.06734 Valid. err. 3.25718 Time elapsed: 00:00:31
2018-02-08 13:47:11,067 training [INFO ] Epoch  2 Batch    0 Training err. 0.06169 Training err. RA 0.06732 Valid. err. 3.25594 Time elapsed: 00:00:31
2018-02-08 13:47:11,154 training [INFO ] Epoch  2 Batch    0 Training err. 0.05998 Training err. RA 0.06730 Valid. err. 3.25959 Time elapsed: 00:00:31
2018-02-08 13:47:11,238 training [INFO ] Epoch  2 Batch    0 Training err. 0.06213 Training err. RA 0.06729 Valid. err. 3.23800 Time elapsed: 00:00:31
2018-02-08 13:47:11,335 training [INFO ] Epoch  2 Batch    0 Training err. 0.05798 Training err. RA 0.06726 Valid. err. 3.24047 Time elapsed: 00:00:31
2018-02-08 13:47:11,426 training [INFO ] Epoch  2 Batch    0 Training err. 0.05987 Training err. RA 0.06724 Valid. err. 3.24726 Time elapsed: 00:00:31
2018-02-08 13:47:11,511 training [INFO ] Epoch  2 Batch    0 Training err. 0.06226 Training err. RA 0.06723 Valid. err. 3.25303 Time elapsed: 00:00:31
2018-02-08 13:47:11,605 training [INFO ] Epoch  2 Batch    0 Training err. 0.06744 Training err. RA 0.06723 Valid. err. 3.24108 Time elapsed: 00:00:31
2018-02-08 13:47:11,689 training [INFO ] Epoch  2 Batch    0 Training err. 0.06487 Training err. RA 0.06722 Valid. err. 3.26447 Time elapsed: 00:00:31
2018-02-08 13:47:11,772 training [INFO ] Epoch  2 Batch    0 Training err. 0.06493 Training err. RA 0.06721 Valid. err. 3.24373 Time elapsed: 00:00:31
2018-02-08 13:47:11,869 training [INFO ] Epoch  2 Batch    0 Training err. 0.06710 Training err. RA 0.06721 Valid. err. 3.23292 Time elapsed: 00:00:32
2018-02-08 13:47:11,953 training [INFO ] Epoch  2 Batch    0 Training err. 0.06138 Training err. RA 0.06720 Valid. err. 3.23580 Time elapsed: 00:00:32
2018-02-08 13:47:12,036 training [INFO ] Epoch  2 Batch    0 Training err. 0.07421 Training err. RA 0.06722 Valid. err. 3.22895 Time elapsed: 00:00:32
2018-02-08 13:47:12,131 training [INFO ] Epoch  2 Batch    0 Training err. 0.08600 Training err. RA 0.06727 Valid. err. 3.22397 Time elapsed: 00:00:32
2018-02-08 13:47:12,215 training [INFO ] Epoch  2 Batch    0 Training err. 0.07272 Training err. RA 0.06728 Valid. err. 3.22357 Time elapsed: 00:00:32
2018-02-08 13:47:12,304 training [INFO ] Epoch  2 Batch    0 Training err. 0.06630 Training err. RA 0.06728 Valid. err. 3.22608 Time elapsed: 00:00:32
2018-02-08 13:47:12,400 training [INFO ] Epoch  2 Batch    0 Training err. 0.06665 Training err. RA 0.06728 Valid. err. 3.22932 Time elapsed: 00:00:32
2018-02-08 13:47:12,484 training [INFO ] Epoch  2 Batch    0 Training err. 0.06205 Training err. RA 0.06727 Valid. err. 3.22885 Time elapsed: 00:00:32
2018-02-08 13:47:12,568 training [INFO ] Epoch  2 Batch    0 Training err. 0.06314 Training err. RA 0.06725 Valid. err. 3.22623 Time elapsed: 00:00:32
2018-02-08 13:47:12,663 training [INFO ] Epoch  2 Batch    0 Training err. 0.06301 Training err. RA 0.06724 Valid. err. 3.22195 Time elapsed: 00:00:32
2018-02-08 13:47:12,747 training [INFO ] Epoch  2 Batch    0 Training err. 0.06714 Training err. RA 0.06724 Valid. err. 3.23270 Time elapsed: 00:00:32
2018-02-08 13:47:12,835 training [INFO ] Epoch  2 Batch    0 Training err. 0.06397 Training err. RA 0.06723 Valid. err. 3.23436 Time elapsed: 00:00:32
2018-02-08 13:47:12,933 training [INFO ] Epoch  2 Batch    0 Training err. 0.05947 Training err. RA 0.06721 Valid. err. 3.23091 Time elapsed: 00:00:33
2018-02-08 13:47:13,017 training [INFO ] Epoch  2 Batch    0 Training err. 0.06491 Training err. RA 0.06720 Valid. err. 3.22825 Time elapsed: 00:00:33
2018-02-08 13:47:13,103 training [INFO ] Epoch  2 Batch    0 Training err. 0.06306 Training err. RA 0.06719 Valid. err. 3.23139 Time elapsed: 00:00:33
2018-02-08 13:47:13,201 training [INFO ] Epoch  2 Batch    0 Training err. 0.06370 Training err. RA 0.06718 Valid. err. 3.22138 Time elapsed: 00:00:33
2018-02-08 13:47:13,285 training [INFO ] Epoch  2 Batch    0 Training err. 0.06212 Training err. RA 0.06717 Valid. err. 3.23041 Time elapsed: 00:00:33
2018-02-08 13:47:13,369 training [INFO ] Epoch  2 Batch    0 Training err. 0.06600 Training err. RA 0.06717 Valid. err. 3.23769 Time elapsed: 00:00:33
2018-02-08 13:47:13,467 training [INFO ] Epoch  2 Batch    0 Training err. 0.05936 Training err. RA 0.06715 Valid. err. 3.23809 Time elapsed: 00:00:33
2018-02-08 13:47:13,551 training [INFO ] Epoch  2 Batch    0 Training err. 0.06396 Training err. RA 0.06714 Valid. err. 3.24887 Time elapsed: 00:00:33
2018-02-08 13:47:13,635 training [INFO ] Epoch  2 Batch    0 Training err. 0.05974 Training err. RA 0.06712 Valid. err. 3.24771 Time elapsed: 00:00:33
2018-02-08 13:47:13,730 training [INFO ] Epoch  2 Batch    0 Training err. 0.06227 Training err. RA 0.06710 Valid. err. 3.25377 Time elapsed: 00:00:33
2018-02-08 13:47:13,820 training [INFO ] Epoch  2 Batch    0 Training err. 0.06447 Training err. RA 0.06710 Valid. err. 3.26564 Time elapsed: 00:00:33
2018-02-08 13:47:13,910 training [INFO ] Epoch  2 Batch    0 Training err. 0.06092 Training err. RA 0.06708 Valid. err. 3.25584 Time elapsed: 00:00:34
2018-02-08 13:47:14,010 training [INFO ] Epoch  2 Batch    0 Training err. 0.06632 Training err. RA 0.06708 Valid. err. 3.24312 Time elapsed: 00:00:34
2018-02-08 13:47:14,103 training [INFO ] Epoch  2 Batch    0 Training err. 0.06355 Training err. RA 0.06707 Valid. err. 3.25179 Time elapsed: 00:00:34
2018-02-08 13:47:14,202 training [INFO ] Epoch  2 Batch    0 Training err. 0.06502 Training err. RA 0.06706 Valid. err. 3.25855 Time elapsed: 00:00:34
2018-02-08 13:47:14,297 training [INFO ] Epoch  2 Batch    0 Training err. 0.05948 Training err. RA 0.06704 Valid. err. 3.25432 Time elapsed: 00:00:34
2018-02-08 13:47:14,381 training [INFO ] Epoch  2 Batch    0 Training err. 0.06355 Training err. RA 0.06703 Valid. err. 3.25488 Time elapsed: 00:00:34
2018-02-08 13:47:14,469 training [INFO ] Epoch  2 Batch    0 Training err. 0.06963 Training err. RA 0.06704 Valid. err. 3.23938 Time elapsed: 00:00:34
2018-02-08 13:47:14,564 training [INFO ] Epoch  2 Batch    0 Training err. 0.06348 Training err. RA 0.06703 Valid. err. 3.22874 Time elapsed: 00:00:34
2018-02-08 13:47:14,651 training [INFO ] Epoch  2 Batch    0 Training err. 0.06189 Training err. RA 0.06702 Valid. err. 3.22219 Time elapsed: 00:00:34
2018-02-08 13:47:14,736 training [INFO ] Epoch  2 Batch    0 Training err. 0.05983 Training err. RA 0.06700 Valid. err. 3.22234 Time elapsed: 00:00:34
2018-02-08 13:47:14,860 training [INFO ] Epoch  2 Batch    0 Training err. 0.05942 Training err. RA 0.06698 Valid. err. 3.22890 Time elapsed: 00:00:35
2018-02-08 13:47:14,949 training [INFO ] Epoch  2 Batch    0 Training err. 0.06152 Training err. RA 0.06697 Valid. err. 3.23266 Time elapsed: 00:00:35
2018-02-08 13:47:15,035 training [INFO ] Epoch  2 Batch    0 Training err. 0.06322 Training err. RA 0.06696 Valid. err. 3.23197 Time elapsed: 00:00:35
2018-02-08 13:47:15,131 training [INFO ] Epoch  2 Batch    0 Training err. 0.06295 Training err. RA 0.06694 Valid. err. 3.23175 Time elapsed: 00:00:35
2018-02-08 13:47:15,215 training [INFO ] Epoch  2 Batch    0 Training err. 0.06310 Training err. RA 0.06693 Valid. err. 3.23205 Time elapsed: 00:00:35
2018-02-08 13:47:15,298 training [INFO ] Epoch  2 Batch    0 Training err. 0.06536 Training err. RA 0.06693 Valid. err. 3.21786 Time elapsed: 00:00:35
2018-02-08 13:47:15,395 training [INFO ] Epoch  2 Batch    0 Training err. 0.06508 Training err. RA 0.06693 Valid. err. 3.21982 Time elapsed: 00:00:35
2018-02-08 13:47:15,479 training [INFO ] Epoch  2 Batch    0 Training err. 0.06515 Training err. RA 0.06692 Valid. err. 3.23128 Time elapsed: 00:00:35
2018-02-08 13:47:15,564 training [INFO ] Epoch  2 Batch    0 Training err. 0.06602 Training err. RA 0.06692 Valid. err. 3.24291 Time elapsed: 00:00:35
2018-02-08 13:47:15,658 training [INFO ] Epoch  2 Batch    0 Training err. 0.06242 Training err. RA 0.06691 Valid. err. 3.22432 Time elapsed: 00:00:35
2018-02-08 13:47:15,748 training [INFO ] Epoch  2 Batch    0 Training err. 0.06543 Training err. RA 0.06690 Valid. err. 3.23369 Time elapsed: 00:00:35
2018-02-08 13:47:15,837 training [INFO ] Epoch  2 Batch    0 Training err. 0.06270 Training err. RA 0.06689 Valid. err. 3.23000 Time elapsed: 00:00:35
2018-02-08 13:47:15,937 training [INFO ] Epoch  2 Batch    0 Training err. 0.06265 Training err. RA 0.06688 Valid. err. 3.24323 Time elapsed: 00:00:36
2018-02-08 13:47:16,021 training [INFO ] Epoch  2 Batch    0 Training err. 0.06119 Training err. RA 0.06687 Valid. err. 3.24901 Time elapsed: 00:00:36
2018-02-08 13:47:16,104 training [INFO ] Epoch  2 Batch    0 Training err. 0.06279 Training err. RA 0.06686 Valid. err. 3.25237 Time elapsed: 00:00:36
2018-02-08 13:47:16,199 training [INFO ] Epoch  2 Batch    0 Training err. 0.06521 Training err. RA 0.06685 Valid. err. 3.25013 Time elapsed: 00:00:36
2018-02-08 13:47:16,283 training [INFO ] Epoch  2 Batch    0 Training err. 0.06295 Training err. RA 0.06684 Valid. err. 3.24040 Time elapsed: 00:00:36
2018-02-08 13:47:16,367 training [INFO ] Epoch  2 Batch    0 Training err. 0.06534 Training err. RA 0.06684 Valid. err. 3.24205 Time elapsed: 00:00:36
2018-02-08 13:47:16,461 training [INFO ] Epoch  2 Batch    0 Training err. 0.06884 Training err. RA 0.06685 Valid. err. 3.23638 Time elapsed: 00:00:36
2018-02-08 13:47:16,545 training [INFO ] Epoch  2 Batch    0 Training err. 0.06189 Training err. RA 0.06683 Valid. err. 3.24335 Time elapsed: 00:00:36
2018-02-08 13:47:16,637 training [INFO ] Epoch  2 Batch    0 Training err. 0.06426 Training err. RA 0.06683 Valid. err. 3.25849 Time elapsed: 00:00:36
2018-02-08 13:47:16,733 training [INFO ] Epoch  2 Batch    0 Training err. 0.06360 Training err. RA 0.06682 Valid. err. 3.25276 Time elapsed: 00:00:36
2018-02-08 13:47:16,823 training [INFO ] Epoch  2 Batch    0 Training err. 0.06449 Training err. RA 0.06681 Valid. err. 3.24548 Time elapsed: 00:00:36
2018-02-08 13:47:16,922 training [INFO ] Epoch  2 Batch    0 Training err. 0.07361 Training err. RA 0.06683 Valid. err. 3.23782 Time elapsed: 00:00:37
2018-02-08 13:47:17,018 training [INFO ] Epoch  2 Batch    0 Training err. 0.06504 Training err. RA 0.06683 Valid. err. 3.22766 Time elapsed: 00:00:37
2018-02-08 13:47:17,102 training [INFO ] Epoch  2 Batch    0 Training err. 0.05917 Training err. RA 0.06681 Valid. err. 3.23162 Time elapsed: 00:00:37
2018-02-08 13:47:17,195 training [INFO ] Epoch  2 Batch    0 Training err. 0.06321 Training err. RA 0.06680 Valid. err. 3.24703 Time elapsed: 00:00:37
2018-02-08 13:47:17,296 training [INFO ] Epoch  2 Batch    0 Training err. 0.07433 Training err. RA 0.06682 Valid. err. 3.22727 Time elapsed: 00:00:37
2018-02-08 13:47:17,385 training [INFO ] Epoch  2 Batch    0 Training err. 0.06778 Training err. RA 0.06682 Valid. err. 3.23027 Time elapsed: 00:00:37
2018-02-08 13:47:17,472 training [INFO ] Epoch  2 Batch    0 Training err. 0.06546 Training err. RA 0.06682 Valid. err. 3.23492 Time elapsed: 00:00:37
2018-02-08 13:47:17,567 training [INFO ] Epoch  2 Batch    0 Training err. 0.06009 Training err. RA 0.06680 Valid. err. 3.22871 Time elapsed: 00:00:37
2018-02-08 13:47:17,651 training [INFO ] Epoch  2 Batch    0 Training err. 0.06294 Training err. RA 0.06679 Valid. err. 3.24716 Time elapsed: 00:00:37
2018-02-08 13:47:17,739 training [INFO ] Epoch  2 Batch    0 Training err. 0.06088 Training err. RA 0.06678 Valid. err. 3.23574 Time elapsed: 00:00:37
2018-02-08 13:47:17,836 training [INFO ] Epoch  2 Batch    0 Training err. 0.06500 Training err. RA 0.06677 Valid. err. 3.22009 Time elapsed: 00:00:37
2018-02-08 13:47:17,920 training [INFO ] Epoch  2 Batch    0 Training err. 0.06456 Training err. RA 0.06677 Valid. err. 3.23127 Time elapsed: 00:00:38
2018-02-08 13:47:18,018 training [INFO ] Epoch  2 Batch    0 Training err. 0.06450 Training err. RA 0.06676 Valid. err. 3.21575 Time elapsed: 00:00:38
2018-02-08 13:47:18,114 training [INFO ] Epoch  2 Batch    0 Training err. 0.06082 Training err. RA 0.06675 Valid. err. 3.21827 Time elapsed: 00:00:38
2018-02-08 13:47:18,202 training [INFO ] Epoch  2 Batch    0 Training err. 0.06440 Training err. RA 0.06674 Valid. err. 3.21741 Time elapsed: 00:00:38
2018-02-08 13:47:18,296 training [INFO ] Epoch  2 Batch    0 Training err. 0.06136 Training err. RA 0.06673 Valid. err. 3.22247 Time elapsed: 00:00:38
2018-02-08 13:47:18,400 training [INFO ] Epoch  2 Batch    0 Training err. 0.07200 Training err. RA 0.06674 Valid. err. 3.21265 Time elapsed: 00:00:38
2018-02-08 13:47:18,489 training [INFO ] Epoch  2 Batch    0 Training err. 0.05700 Training err. RA 0.06672 Valid. err. 3.22179 Time elapsed: 00:00:38
2018-02-08 13:47:18,574 training [INFO ] Epoch  2 Batch    0 Training err. 0.06295 Training err. RA 0.06671 Valid. err. 3.21889 Time elapsed: 00:00:38
2018-02-08 13:47:18,671 training [INFO ] Epoch  2 Batch    0 Training err. 0.06061 Training err. RA 0.06669 Valid. err. 3.23189 Time elapsed: 00:00:38
2018-02-08 13:47:18,764 training [INFO ] Epoch  2 Batch    0 Training err. 0.05667 Training err. RA 0.06667 Valid. err. 3.23593 Time elapsed: 00:00:38
2018-02-08 13:47:18,854 training [INFO ] Epoch  2 Batch    0 Training err. 0.06399 Training err. RA 0.06666 Valid. err. 3.22091 Time elapsed: 00:00:39
2018-02-08 13:47:18,985 training [INFO ] Epoch  2 Batch    0 Training err. 0.07067 Training err. RA 0.06667 Valid. err. 3.23348 Time elapsed: 00:00:39
2018-02-08 13:47:19,071 training [INFO ] Epoch  2 Batch    0 Training err. 0.06381 Training err. RA 0.06667 Valid. err. 3.22620 Time elapsed: 00:00:39
2018-02-08 13:47:19,157 training [INFO ] Epoch  2 Batch    0 Training err. 0.05967 Training err. RA 0.06665 Valid. err. 3.21218 Time elapsed: 00:00:39
2018-02-08 13:47:19,259 training [INFO ] Epoch  2 Batch    0 Training err. 0.06193 Training err. RA 0.06664 Valid. err. 3.22883 Time elapsed: 00:00:39
2018-02-08 13:47:19,346 training [INFO ] Epoch  2 Batch    0 Training err. 0.06180 Training err. RA 0.06663 Valid. err. 3.24791 Time elapsed: 00:00:39
2018-02-08 13:47:19,435 training [INFO ] Epoch  2 Batch    0 Training err. 0.06975 Training err. RA 0.06664 Valid. err. 3.22861 Time elapsed: 00:00:39
2018-02-08 13:47:19,534 training [INFO ] Epoch  2 Batch    0 Training err. 0.06018 Training err. RA 0.06662 Valid. err. 3.22131 Time elapsed: 00:00:39
2018-02-08 13:47:19,625 training [INFO ] Epoch  2 Batch    0 Training err. 0.06050 Training err. RA 0.06661 Valid. err. 3.22502 Time elapsed: 00:00:39
2018-02-08 13:47:19,711 training [INFO ] Epoch  2 Batch    0 Training err. 0.05954 Training err. RA 0.06659 Valid. err. 3.23113 Time elapsed: 00:00:39
2018-02-08 13:47:19,812 training [INFO ] Epoch  2 Batch    0 Training err. 0.06468 Training err. RA 0.06659 Valid. err. 3.22587 Time elapsed: 00:00:39
2018-02-08 13:47:19,911 training [INFO ] Epoch  2 Batch    0 Training err. 0.06459 Training err. RA 0.06658 Valid. err. 3.22104 Time elapsed: 00:00:40
2018-02-08 13:47:19,998 training [INFO ] Epoch  2 Batch    0 Training err. 0.06587 Training err. RA 0.06658 Valid. err. 3.21905 Time elapsed: 00:00:40
2018-02-08 13:47:20,104 training [INFO ] Epoch  2 Batch    0 Training err. 0.06195 Training err. RA 0.06657 Valid. err. 3.21411 Time elapsed: 00:00:40
2018-02-08 13:47:39,477 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:47:39,479 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:47:39,480 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:47:39,481 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:47:42,783 training [INFO ] Epoch  1 Batch   50 Training err. 2.13050 Training err. RA 2.13050 Valid. err. 4.03202 Time elapsed: 00:00:00
2018-02-08 13:47:42,962 training [INFO ] Epoch  1 Batch  100 Training err. 1.91304 Training err. RA 2.02177 Valid. err. 3.53155 Time elapsed: 00:00:00
2018-02-08 13:47:43,148 training [INFO ] Epoch  1 Batch  150 Training err. 1.72624 Training err. RA 1.92326 Valid. err. 3.35543 Time elapsed: 00:00:00
2018-02-08 13:47:43,365 training [INFO ] Epoch  1 Batch  200 Training err. 1.67591 Training err. RA 1.86142 Valid. err. 3.30329 Time elapsed: 00:00:00
2018-02-08 13:47:43,552 training [INFO ] Epoch  1 Batch  250 Training err. 1.63727 Training err. RA 1.81659 Valid. err. 3.30655 Time elapsed: 00:00:01
2018-02-08 13:47:43,718 training [INFO ] Epoch  1 Batch  300 Training err. 1.64348 Training err. RA 1.78774 Valid. err. 3.28835 Time elapsed: 00:00:01
2018-02-08 13:47:43,901 training [INFO ] Epoch  1 Batch  350 Training err. 1.62462 Training err. RA 1.76444 Valid. err. 3.25310 Time elapsed: 00:00:01
2018-02-08 13:47:44,101 training [INFO ] Epoch  1 Batch  400 Training err. 1.64281 Training err. RA 1.74923 Valid. err. 3.25835 Time elapsed: 00:00:01
2018-02-08 13:47:44,324 training [INFO ] Epoch  1 Batch  450 Training err. 1.61867 Training err. RA 1.73473 Valid. err. 3.24213 Time elapsed: 00:00:01
2018-02-08 13:47:44,501 training [INFO ] Epoch  1 Batch  500 Training err. 1.60413 Training err. RA 1.72167 Valid. err. 3.26085 Time elapsed: 00:00:02
2018-02-08 13:47:44,676 training [INFO ] Epoch  1 Batch  550 Training err. 1.64018 Training err. RA 1.71426 Valid. err. 3.23461 Time elapsed: 00:00:02
2018-02-08 13:47:44,847 training [INFO ] Epoch  1 Batch  600 Training err. 1.63265 Training err. RA 1.70746 Valid. err. 3.22404 Time elapsed: 00:00:02
2018-02-08 13:47:45,152 training [INFO ] Epoch  2 Batch  650 Training err. 1.64866 Training err. RA 1.70293 Valid. err. 3.23344 Time elapsed: 00:00:02
2018-02-08 13:47:45,319 training [INFO ] Epoch  2 Batch  700 Training err. 1.57886 Training err. RA 1.69407 Valid. err. 3.23683 Time elapsed: 00:00:02
2018-02-08 13:47:45,484 training [INFO ] Epoch  2 Batch  750 Training err. 1.63367 Training err. RA 1.69004 Valid. err. 3.25559 Time elapsed: 00:00:03
2018-02-08 13:47:45,664 training [INFO ] Epoch  2 Batch  800 Training err. 1.59485 Training err. RA 1.68410 Valid. err. 3.24313 Time elapsed: 00:00:03
2018-02-08 13:47:45,861 training [INFO ] Epoch  2 Batch  850 Training err. 1.61483 Training err. RA 1.68002 Valid. err. 3.23769 Time elapsed: 00:00:03
2018-02-08 13:47:46,070 training [INFO ] Epoch  2 Batch  900 Training err. 1.60289 Training err. RA 1.67574 Valid. err. 3.21303 Time elapsed: 00:00:03
2018-02-08 13:47:46,266 training [INFO ] Epoch  2 Batch  950 Training err. 1.59007 Training err. RA 1.67123 Valid. err. 3.21480 Time elapsed: 00:00:03
2018-02-08 13:47:46,515 training [INFO ] Epoch  2 Batch 1000 Training err. 1.61873 Training err. RA 1.66860 Valid. err. 3.22129 Time elapsed: 00:00:04
2018-02-08 13:47:46,731 training [INFO ] Epoch  2 Batch 1050 Training err. 1.59890 Training err. RA 1.66528 Valid. err. 3.20906 Time elapsed: 00:00:04
2018-02-08 13:47:46,977 training [INFO ] Epoch  2 Batch 1100 Training err. 1.59425 Training err. RA 1.66205 Valid. err. 3.22677 Time elapsed: 00:00:04
2018-02-08 13:47:47,183 training [INFO ] Epoch  2 Batch 1150 Training err. 1.59784 Training err. RA 1.65926 Valid. err. 3.21034 Time elapsed: 00:00:04
2018-02-08 13:47:47,370 training [INFO ] Epoch  2 Batch 1200 Training err. 1.61624 Training err. RA 1.65747 Valid. err. 3.17940 Time elapsed: 00:00:04
2018-02-08 13:47:47,635 training [INFO ] Epoch  3 Batch 1250 Training err. 1.63230 Training err. RA 1.65646 Valid. err. 3.18443 Time elapsed: 00:00:05
2018-02-08 13:47:47,799 training [INFO ] Epoch  3 Batch 1300 Training err. 1.55657 Training err. RA 1.65262 Valid. err. 3.18731 Time elapsed: 00:00:05
2018-02-08 13:47:47,967 training [INFO ] Epoch  3 Batch 1350 Training err. 1.61258 Training err. RA 1.65114 Valid. err. 3.18298 Time elapsed: 00:00:05
2018-02-08 13:47:48,132 training [INFO ] Epoch  3 Batch 1400 Training err. 1.56612 Training err. RA 1.64810 Valid. err. 3.16853 Time elapsed: 00:00:05
2018-02-08 13:47:48,295 training [INFO ] Epoch  3 Batch 1450 Training err. 1.58460 Training err. RA 1.64591 Valid. err. 3.15268 Time elapsed: 00:00:05
2018-02-08 13:47:48,454 training [INFO ] Epoch  3 Batch 1500 Training err. 1.54602 Training err. RA 1.64258 Valid. err. 3.14018 Time elapsed: 00:00:06
2018-02-08 13:47:48,631 training [INFO ] Epoch  3 Batch 1550 Training err. 1.55477 Training err. RA 1.63975 Valid. err. 3.11500 Time elapsed: 00:00:06
2018-02-08 13:47:48,799 training [INFO ] Epoch  3 Batch 1600 Training err. 1.57917 Training err. RA 1.63786 Valid. err. 3.10382 Time elapsed: 00:00:06
2018-02-08 13:47:48,973 training [INFO ] Epoch  3 Batch 1650 Training err. 1.55753 Training err. RA 1.63542 Valid. err. 3.09623 Time elapsed: 00:00:06
2018-02-08 13:47:49,159 training [INFO ] Epoch  3 Batch 1700 Training err. 1.50513 Training err. RA 1.63159 Valid. err. 3.11936 Time elapsed: 00:00:06
2018-02-08 13:47:49,363 training [INFO ] Epoch  3 Batch 1750 Training err. 1.55338 Training err. RA 1.62936 Valid. err. 3.06535 Time elapsed: 00:00:06
2018-02-08 13:47:49,537 training [INFO ] Epoch  3 Batch 1800 Training err. 1.54140 Training err. RA 1.62691 Valid. err. 3.00815 Time elapsed: 00:00:07
2018-02-08 13:47:49,855 training [INFO ] Epoch  4 Batch 1850 Training err. 1.54371 Training err. RA 1.62466 Valid. err. 2.99983 Time elapsed: 00:00:07
2018-02-08 13:47:50,030 training [INFO ] Epoch  4 Batch 1900 Training err. 1.51275 Training err. RA 1.62172 Valid. err. 3.03385 Time elapsed: 00:00:07
2018-02-08 13:47:50,209 training [INFO ] Epoch  4 Batch 1950 Training err. 1.52409 Training err. RA 1.61922 Valid. err. 2.96940 Time elapsed: 00:00:07
2018-02-08 13:47:50,383 training [INFO ] Epoch  4 Batch 2000 Training err. 1.45265 Training err. RA 1.61505 Valid. err. 2.95917 Time elapsed: 00:00:07
2018-02-08 13:47:50,552 training [INFO ] Epoch  4 Batch 2050 Training err. 1.48661 Training err. RA 1.61192 Valid. err. 2.96096 Time elapsed: 00:00:08
2018-02-08 13:47:50,726 training [INFO ] Epoch  4 Batch 2100 Training err. 1.42713 Training err. RA 1.60752 Valid. err. 2.94128 Time elapsed: 00:00:08
2018-02-08 13:47:50,904 training [INFO ] Epoch  4 Batch 2150 Training err. 1.44954 Training err. RA 1.60384 Valid. err. 2.93452 Time elapsed: 00:00:08
2018-02-08 13:47:51,080 training [INFO ] Epoch  4 Batch 2200 Training err. 1.47182 Training err. RA 1.60084 Valid. err. 2.87925 Time elapsed: 00:00:08
2018-02-08 13:47:51,387 training [INFO ] Epoch  4 Batch 2250 Training err. 1.46007 Training err. RA 1.59772 Valid. err. 2.88156 Time elapsed: 00:00:08
2018-02-08 13:47:51,550 training [INFO ] Epoch  4 Batch 2300 Training err. 1.42148 Training err. RA 1.59388 Valid. err. 2.91895 Time elapsed: 00:00:09
2018-02-08 13:47:51,716 training [INFO ] Epoch  4 Batch 2350 Training err. 1.42849 Training err. RA 1.59037 Valid. err. 2.85552 Time elapsed: 00:00:09
2018-02-08 13:47:51,878 training [INFO ] Epoch  4 Batch 2400 Training err. 1.46200 Training err. RA 1.58769 Valid. err. 2.83472 Time elapsed: 00:00:09
2018-02-08 13:47:52,069 training [INFO ] Epoch  4 Batch 2450 Training err. 1.45388 Training err. RA 1.58496 Valid. err. 2.82658 Time elapsed: 00:00:09
2018-02-08 13:47:52,387 training [INFO ] Epoch  5 Batch 2500 Training err. 1.47418 Training err. RA 1.58274 Valid. err. 2.88439 Time elapsed: 00:00:09
2018-02-08 13:47:52,558 training [INFO ] Epoch  5 Batch 2550 Training err. 1.45873 Training err. RA 1.58031 Valid. err. 2.81751 Time elapsed: 00:00:10
2018-02-08 13:47:52,747 training [INFO ] Epoch  5 Batch 2600 Training err. 1.40892 Training err. RA 1.57702 Valid. err. 2.82630 Time elapsed: 00:00:10
2018-02-08 13:47:52,918 training [INFO ] Epoch  5 Batch 2650 Training err. 1.39040 Training err. RA 1.57350 Valid. err. 2.81910 Time elapsed: 00:00:10
2018-02-08 13:47:53,128 training [INFO ] Epoch  5 Batch 2700 Training err. 1.38488 Training err. RA 1.57000 Valid. err. 2.79817 Time elapsed: 00:00:10
2018-02-08 13:47:53,344 training [INFO ] Epoch  5 Batch 2750 Training err. 1.40349 Training err. RA 1.56698 Valid. err. 2.78968 Time elapsed: 00:00:10
2018-02-08 13:47:53,534 training [INFO ] Epoch  5 Batch 2800 Training err. 1.39663 Training err. RA 1.56393 Valid. err. 2.78951 Time elapsed: 00:00:11
2018-02-08 13:47:53,760 training [INFO ] Epoch  5 Batch 2850 Training err. 1.42334 Training err. RA 1.56147 Valid. err. 2.77100 Time elapsed: 00:00:11
2018-02-08 13:47:53,944 training [INFO ] Epoch  5 Batch 2900 Training err. 1.38038 Training err. RA 1.55834 Valid. err. 2.77835 Time elapsed: 00:00:11
2018-02-08 13:47:54,111 training [INFO ] Epoch  5 Batch 2950 Training err. 1.36033 Training err. RA 1.55499 Valid. err. 2.76854 Time elapsed: 00:00:11
2018-02-08 13:47:54,271 training [INFO ] Epoch  5 Batch 3000 Training err. 1.40967 Training err. RA 1.55257 Valid. err. 2.73402 Time elapsed: 00:00:11
2018-02-08 13:47:54,445 training [INFO ] Epoch  5 Batch 3050 Training err. 1.41082 Training err. RA 1.55024 Valid. err. 2.72833 Time elapsed: 00:00:12
2018-02-08 13:47:54,721 training [INFO ] Epoch  6 Batch 3100 Training err. 1.44347 Training err. RA 1.54852 Valid. err. 2.73543 Time elapsed: 00:00:12
2018-02-08 13:47:54,910 training [INFO ] Epoch  6 Batch 3150 Training err. 1.36681 Training err. RA 1.54564 Valid. err. 2.73782 Time elapsed: 00:00:12
2018-02-08 13:47:55,071 training [INFO ] Epoch  6 Batch 3200 Training err. 1.42130 Training err. RA 1.54369 Valid. err. 2.76682 Time elapsed: 00:00:12
2018-02-08 13:47:55,224 training [INFO ] Epoch  6 Batch 3250 Training err. 1.36663 Training err. RA 1.54097 Valid. err. 2.72290 Time elapsed: 00:00:12
2018-02-08 13:47:55,390 training [INFO ] Epoch  6 Batch 3300 Training err. 1.34958 Training err. RA 1.53807 Valid. err. 2.70818 Time elapsed: 00:00:12
2018-02-08 13:47:55,557 training [INFO ] Epoch  6 Batch 3350 Training err. 1.35268 Training err. RA 1.53530 Valid. err. 2.72980 Time elapsed: 00:00:13
2018-02-08 13:47:55,724 training [INFO ] Epoch  6 Batch 3400 Training err. 1.33343 Training err. RA 1.53233 Valid. err. 2.71696 Time elapsed: 00:00:13
2018-02-08 13:47:55,887 training [INFO ] Epoch  6 Batch 3450 Training err. 1.40420 Training err. RA 1.53048 Valid. err. 2.67666 Time elapsed: 00:00:13
2018-02-08 13:47:56,048 training [INFO ] Epoch  6 Batch 3500 Training err. 1.35223 Training err. RA 1.52793 Valid. err. 2.69664 Time elapsed: 00:00:13
2018-02-08 13:47:56,203 training [INFO ] Epoch  6 Batch 3550 Training err. 1.30729 Training err. RA 1.52482 Valid. err. 2.70418 Time elapsed: 00:00:13
2018-02-08 13:47:56,362 training [INFO ] Epoch  6 Batch 3600 Training err. 1.35877 Training err. RA 1.52252 Valid. err. 2.66888 Time elapsed: 00:00:13
2018-02-08 13:47:56,525 training [INFO ] Epoch  6 Batch 3650 Training err. 1.37519 Training err. RA 1.52050 Valid. err. 2.64235 Time elapsed: 00:00:14
2018-02-08 13:47:56,794 training [INFO ] Epoch  7 Batch 3700 Training err. 1.39378 Training err. RA 1.51879 Valid. err. 2.72028 Time elapsed: 00:00:14
2018-02-08 13:47:56,958 training [INFO ] Epoch  7 Batch 3750 Training err. 1.35039 Training err. RA 1.51654 Valid. err. 2.65501 Time elapsed: 00:00:14
2018-02-08 13:47:57,118 training [INFO ] Epoch  7 Batch 3800 Training err. 1.38553 Training err. RA 1.51482 Valid. err. 2.64771 Time elapsed: 00:00:14
2018-02-08 13:47:57,280 training [INFO ] Epoch  7 Batch 3850 Training err. 1.32136 Training err. RA 1.51231 Valid. err. 2.68448 Time elapsed: 00:00:14
2018-02-08 13:47:57,453 training [INFO ] Epoch  7 Batch 3900 Training err. 1.31497 Training err. RA 1.50978 Valid. err. 2.62450 Time elapsed: 00:00:15
2018-02-08 13:47:57,608 training [INFO ] Epoch  7 Batch 3950 Training err. 1.31206 Training err. RA 1.50727 Valid. err. 2.62322 Time elapsed: 00:00:15
2018-02-08 13:47:57,779 training [INFO ] Epoch  7 Batch 4000 Training err. 1.29064 Training err. RA 1.50456 Valid. err. 2.60800 Time elapsed: 00:00:15
2018-02-08 13:47:57,952 training [INFO ] Epoch  7 Batch 4050 Training err. 1.36629 Training err. RA 1.50286 Valid. err. 2.59380 Time elapsed: 00:00:15
2018-02-08 13:47:58,125 training [INFO ] Epoch  7 Batch 4100 Training err. 1.33063 Training err. RA 1.50076 Valid. err. 2.59694 Time elapsed: 00:00:15
2018-02-08 13:47:58,311 training [INFO ] Epoch  7 Batch 4150 Training err. 1.27730 Training err. RA 1.49806 Valid. err. 2.59878 Time elapsed: 00:00:15
2018-02-08 13:47:58,484 training [INFO ] Epoch  7 Batch 4200 Training err. 1.30156 Training err. RA 1.49573 Valid. err. 2.57258 Time elapsed: 00:00:16
2018-02-08 13:47:58,654 training [INFO ] Epoch  7 Batch 4250 Training err. 1.32981 Training err. RA 1.49377 Valid. err. 2.57594 Time elapsed: 00:00:16
2018-02-08 13:47:58,981 training [INFO ] Epoch  8 Batch 4300 Training err. 1.32699 Training err. RA 1.49183 Valid. err. 2.56292 Time elapsed: 00:00:16
2018-02-08 13:47:59,152 training [INFO ] Epoch  8 Batch 4350 Training err. 1.35129 Training err. RA 1.49022 Valid. err. 2.63688 Time elapsed: 00:00:16
2018-02-08 13:47:59,329 training [INFO ] Epoch  8 Batch 4400 Training err. 1.36044 Training err. RA 1.48874 Valid. err. 2.56235 Time elapsed: 00:00:16
2018-02-08 13:47:59,507 training [INFO ] Epoch  8 Batch 4450 Training err. 1.29528 Training err. RA 1.48657 Valid. err. 2.57984 Time elapsed: 00:00:17
2018-02-08 13:47:59,669 training [INFO ] Epoch  8 Batch 4500 Training err. 1.29530 Training err. RA 1.48444 Valid. err. 2.56578 Time elapsed: 00:00:17
2018-02-08 13:47:59,836 training [INFO ] Epoch  8 Batch 4550 Training err. 1.27989 Training err. RA 1.48220 Valid. err. 2.57531 Time elapsed: 00:00:17
2018-02-08 13:48:00,003 training [INFO ] Epoch  8 Batch 4600 Training err. 1.27700 Training err. RA 1.47997 Valid. err. 2.54872 Time elapsed: 00:00:17
2018-02-08 13:48:00,175 training [INFO ] Epoch  8 Batch 4650 Training err. 1.29888 Training err. RA 1.47802 Valid. err. 2.53568 Time elapsed: 00:00:17
2018-02-08 13:48:00,360 training [INFO ] Epoch  8 Batch 4700 Training err. 1.31467 Training err. RA 1.47628 Valid. err. 2.55811 Time elapsed: 00:00:17
2018-02-08 13:48:00,523 training [INFO ] Epoch  8 Batch 4750 Training err. 1.28261 Training err. RA 1.47424 Valid. err. 2.53979 Time elapsed: 00:00:18
2018-02-08 13:48:00,687 training [INFO ] Epoch  8 Batch 4800 Training err. 1.22767 Training err. RA 1.47167 Valid. err. 2.51833 Time elapsed: 00:00:18
2018-02-08 13:48:00,866 training [INFO ] Epoch  8 Batch 4850 Training err. 1.28857 Training err. RA 1.46979 Valid. err. 2.54859 Time elapsed: 00:00:18
2018-02-08 13:48:01,030 training [INFO ] Epoch  8 Batch 4900 Training err. 1.30927 Training err. RA 1.46815 Valid. err. 2.54318 Time elapsed: 00:00:18
2018-02-08 13:48:01,314 training [INFO ] Epoch  9 Batch 4950 Training err. 1.33540 Training err. RA 1.46681 Valid. err. 2.51033 Time elapsed: 00:00:18
2018-02-08 13:48:01,488 training [INFO ] Epoch  9 Batch 5000 Training err. 1.29039 Training err. RA 1.46504 Valid. err. 2.54880 Time elapsed: 00:00:19
2018-02-08 13:48:01,685 training [INFO ] Epoch  9 Batch 5050 Training err. 1.32807 Training err. RA 1.46369 Valid. err. 2.59033 Time elapsed: 00:00:19
2018-02-08 13:48:01,910 training [INFO ] Epoch  9 Batch 5100 Training err. 1.26488 Training err. RA 1.46174 Valid. err. 2.50323 Time elapsed: 00:00:19
2018-02-08 13:48:02,102 training [INFO ] Epoch  9 Batch 5150 Training err. 1.22579 Training err. RA 1.45945 Valid. err. 2.52424 Time elapsed: 00:00:19
2018-02-08 13:48:02,329 training [INFO ] Epoch  9 Batch 5200 Training err. 1.28328 Training err. RA 1.45775 Valid. err. 2.48893 Time elapsed: 00:00:19
2018-02-08 13:48:02,567 training [INFO ] Epoch  9 Batch 5250 Training err. 1.25533 Training err. RA 1.45583 Valid. err. 2.49021 Time elapsed: 00:00:20
2018-02-08 13:48:02,818 training [INFO ] Epoch  9 Batch 5300 Training err. 1.31364 Training err. RA 1.45448 Valid. err. 2.51034 Time elapsed: 00:00:20
2018-02-08 13:48:02,993 training [INFO ] Epoch  9 Batch 5350 Training err. 1.23910 Training err. RA 1.45247 Valid. err. 2.49174 Time elapsed: 00:00:20
2018-02-08 13:48:03,186 training [INFO ] Epoch  9 Batch 5400 Training err. 1.22245 Training err. RA 1.45034 Valid. err. 2.51147 Time elapsed: 00:00:20
2018-02-08 13:48:03,361 training [INFO ] Epoch  9 Batch 5450 Training err. 1.24395 Training err. RA 1.44845 Valid. err. 2.47472 Time elapsed: 00:00:20
2018-02-08 13:48:03,524 training [INFO ] Epoch  9 Batch 5500 Training err. 1.27491 Training err. RA 1.44687 Valid. err. 2.46500 Time elapsed: 00:00:21
2018-02-08 13:48:03,790 training [INFO ] Epoch 10 Batch 5550 Training err. 1.30581 Training err. RA 1.44560 Valid. err. 2.47778 Time elapsed: 00:00:21
2018-02-08 13:48:03,960 training [INFO ] Epoch 10 Batch 5600 Training err. 1.25415 Training err. RA 1.44389 Valid. err. 2.49186 Time elapsed: 00:00:21
2018-02-08 13:48:04,117 training [INFO ] Epoch 10 Batch 5650 Training err. 1.31936 Training err. RA 1.44279 Valid. err. 2.48396 Time elapsed: 00:00:21
2018-02-08 13:48:04,288 training [INFO ] Epoch 10 Batch 5700 Training err. 1.25635 Training err. RA 1.44115 Valid. err. 2.46138 Time elapsed: 00:00:21
2018-02-08 13:48:04,458 training [INFO ] Epoch 10 Batch 5750 Training err. 1.21587 Training err. RA 1.43919 Valid. err. 2.44779 Time elapsed: 00:00:22
2018-02-08 13:48:04,651 training [INFO ] Epoch 10 Batch 5800 Training err. 1.24385 Training err. RA 1.43751 Valid. err. 2.43355 Time elapsed: 00:00:22
2018-02-08 13:48:04,860 training [INFO ] Epoch 10 Batch 5850 Training err. 1.21885 Training err. RA 1.43564 Valid. err. 2.46455 Time elapsed: 00:00:22
2018-02-08 13:48:05,085 training [INFO ] Epoch 10 Batch 5900 Training err. 1.29687 Training err. RA 1.43447 Valid. err. 2.48696 Time elapsed: 00:00:22
2018-02-08 13:48:05,282 training [INFO ] Epoch 10 Batch 5950 Training err. 1.24803 Training err. RA 1.43290 Valid. err. 2.43464 Time elapsed: 00:00:22
2018-02-08 13:48:05,474 training [INFO ] Epoch 10 Batch 6000 Training err. 1.19142 Training err. RA 1.43089 Valid. err. 2.41929 Time elapsed: 00:00:23
2018-02-08 13:48:05,681 training [INFO ] Epoch 10 Batch 6050 Training err. 1.21768 Training err. RA 1.42912 Valid. err. 2.46275 Time elapsed: 00:00:23
2018-02-08 13:48:05,894 training [INFO ] Epoch 10 Batch 6100 Training err. 1.24564 Training err. RA 1.42762 Valid. err. 2.41840 Time elapsed: 00:00:23
2018-02-08 13:48:06,121 __main__ [INFO ] End of training
2018-02-08 13:48:06,606 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:48:06,607 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:48:06,881 training [INFO ] Epoch  1 Batch   50 Training err. 2.10471 Training err. RA 2.10471 Valid. err. 3.95759 Time elapsed: 00:00:00
2018-02-08 13:48:07,130 training [INFO ] Epoch  1 Batch  100 Training err. 1.87605 Training err. RA 1.99038 Valid. err. 3.46427 Time elapsed: 00:00:00
2018-02-08 13:48:07,334 training [INFO ] Epoch  1 Batch  150 Training err. 1.71137 Training err. RA 1.89738 Valid. err. 3.33957 Time elapsed: 00:00:00
2018-02-08 13:48:07,510 training [INFO ] Epoch  1 Batch  200 Training err. 1.65368 Training err. RA 1.83645 Valid. err. 3.29647 Time elapsed: 00:00:00
2018-02-08 13:48:07,739 training [INFO ] Epoch  1 Batch  250 Training err. 1.64500 Training err. RA 1.79816 Valid. err. 3.25603 Time elapsed: 00:00:01
2018-02-08 13:48:07,919 training [INFO ] Epoch  1 Batch  300 Training err. 1.62367 Training err. RA 1.76908 Valid. err. 3.24654 Time elapsed: 00:00:01
2018-02-08 13:48:08,075 training [INFO ] Epoch  1 Batch  350 Training err. 1.62564 Training err. RA 1.74859 Valid. err. 3.24587 Time elapsed: 00:00:01
2018-02-08 13:48:08,278 training [INFO ] Epoch  1 Batch  400 Training err. 1.63033 Training err. RA 1.73381 Valid. err. 3.23161 Time elapsed: 00:00:01
2018-02-08 13:48:08,540 training [INFO ] Epoch  2 Batch  450 Training err. 1.63652 Training err. RA 1.72300 Valid. err. 3.24918 Time elapsed: 00:00:01
2018-02-08 13:48:08,752 training [INFO ] Epoch  2 Batch  500 Training err. 1.61702 Training err. RA 1.71240 Valid. err. 3.25560 Time elapsed: 00:00:02
2018-02-08 13:48:08,922 training [INFO ] Epoch  2 Batch  550 Training err. 1.61478 Training err. RA 1.70353 Valid. err. 3.24043 Time elapsed: 00:00:02
2018-02-08 13:48:09,135 training [INFO ] Epoch  2 Batch  600 Training err. 1.60146 Training err. RA 1.69502 Valid. err. 3.21995 Time elapsed: 00:00:02
2018-02-08 13:48:09,299 training [INFO ] Epoch  2 Batch  650 Training err. 1.60614 Training err. RA 1.68818 Valid. err. 3.21926 Time elapsed: 00:00:02
2018-02-08 13:48:09,498 training [INFO ] Epoch  2 Batch  700 Training err. 1.60705 Training err. RA 1.68239 Valid. err. 3.22442 Time elapsed: 00:00:02
2018-02-08 13:48:09,681 training [INFO ] Epoch  2 Batch  750 Training err. 1.60348 Training err. RA 1.67713 Valid. err. 3.21376 Time elapsed: 00:00:03
2018-02-08 13:48:09,899 training [INFO ] Epoch  2 Batch  800 Training err. 1.61536 Training err. RA 1.67327 Valid. err. 3.19851 Time elapsed: 00:00:03
2018-02-08 13:48:10,171 training [INFO ] Epoch  3 Batch  850 Training err. 1.62027 Training err. RA 1.67015 Valid. err. 3.23147 Time elapsed: 00:00:03
2018-02-08 13:48:10,351 training [INFO ] Epoch  3 Batch  900 Training err. 1.61205 Training err. RA 1.66692 Valid. err. 3.21225 Time elapsed: 00:00:03
2018-02-08 13:48:10,559 training [INFO ] Epoch  3 Batch  950 Training err. 1.58351 Training err. RA 1.66253 Valid. err. 3.22185 Time elapsed: 00:00:03
2018-02-08 13:48:10,729 training [INFO ] Epoch  3 Batch 1000 Training err. 1.58722 Training err. RA 1.65877 Valid. err. 3.19222 Time elapsed: 00:00:04
2018-02-08 13:48:10,901 training [INFO ] Epoch  3 Batch 1050 Training err. 1.59174 Training err. RA 1.65557 Valid. err. 3.19267 Time elapsed: 00:00:04
2018-02-08 13:48:11,057 training [INFO ] Epoch  3 Batch 1100 Training err. 1.59900 Training err. RA 1.65300 Valid. err. 3.19414 Time elapsed: 00:00:04
2018-02-08 13:48:11,227 training [INFO ] Epoch  3 Batch 1150 Training err. 1.56755 Training err. RA 1.64929 Valid. err. 3.18949 Time elapsed: 00:00:04
2018-02-08 13:48:11,388 training [INFO ] Epoch  3 Batch 1200 Training err. 1.60525 Training err. RA 1.64745 Valid. err. 3.15527 Time elapsed: 00:00:04
2018-02-08 13:48:11,626 training [INFO ] Epoch  4 Batch 1250 Training err. 1.59618 Training err. RA 1.64540 Valid. err. 3.14577 Time elapsed: 00:00:05
2018-02-08 13:48:11,786 training [INFO ] Epoch  4 Batch 1300 Training err. 1.58283 Training err. RA 1.64299 Valid. err. 3.14334 Time elapsed: 00:00:05
2018-02-08 13:48:11,949 training [INFO ] Epoch  4 Batch 1350 Training err. 1.54088 Training err. RA 1.63921 Valid. err. 3.13543 Time elapsed: 00:00:05
2018-02-08 13:48:12,114 training [INFO ] Epoch  4 Batch 1400 Training err. 1.55146 Training err. RA 1.63608 Valid. err. 3.09689 Time elapsed: 00:00:05
2018-02-08 13:48:12,282 training [INFO ] Epoch  4 Batch 1450 Training err. 1.53671 Training err. RA 1.63265 Valid. err. 3.09587 Time elapsed: 00:00:05
2018-02-08 13:48:12,439 training [INFO ] Epoch  4 Batch 1500 Training err. 1.54585 Training err. RA 1.62976 Valid. err. 3.06291 Time elapsed: 00:00:05
2018-02-08 13:48:12,597 training [INFO ] Epoch  4 Batch 1550 Training err. 1.50729 Training err. RA 1.62581 Valid. err. 3.05392 Time elapsed: 00:00:05
2018-02-08 13:48:12,751 training [INFO ] Epoch  4 Batch 1600 Training err. 1.52966 Training err. RA 1.62280 Valid. err. 3.04657 Time elapsed: 00:00:06
2018-02-08 13:48:13,004 training [INFO ] Epoch  5 Batch 1650 Training err. 1.55464 Training err. RA 1.62074 Valid. err. 2.99306 Time elapsed: 00:00:06
2018-02-08 13:48:13,156 training [INFO ] Epoch  5 Batch 1700 Training err. 1.49842 Training err. RA 1.61714 Valid. err. 2.99659 Time elapsed: 00:00:06
2018-02-08 13:48:13,320 training [INFO ] Epoch  5 Batch 1750 Training err. 1.49872 Training err. RA 1.61376 Valid. err. 2.98142 Time elapsed: 00:00:06
2018-02-08 13:48:13,473 training [INFO ] Epoch  5 Batch 1800 Training err. 1.46304 Training err. RA 1.60957 Valid. err. 2.94522 Time elapsed: 00:00:06
2018-02-08 13:48:13,626 training [INFO ] Epoch  5 Batch 1850 Training err. 1.44592 Training err. RA 1.60515 Valid. err. 2.91632 Time elapsed: 00:00:07
2018-02-08 13:48:13,811 training [INFO ] Epoch  5 Batch 1900 Training err. 1.48740 Training err. RA 1.60205 Valid. err. 2.91316 Time elapsed: 00:00:07
2018-02-08 13:48:14,001 training [INFO ] Epoch  5 Batch 1950 Training err. 1.42520 Training err. RA 1.59751 Valid. err. 2.89091 Time elapsed: 00:00:07
2018-02-08 13:48:14,173 training [INFO ] Epoch  5 Batch 2000 Training err. 1.45432 Training err. RA 1.59393 Valid. err. 2.86280 Time elapsed: 00:00:07
2018-02-08 13:48:14,339 training [INFO ] Epoch  5 Batch 2050 Training err. 1.46535 Training err. RA 1.59080 Valid. err. 2.86183 Time elapsed: 00:00:07
2018-02-08 13:48:14,598 training [INFO ] Epoch  6 Batch 2100 Training err. 1.46396 Training err. RA 1.58778 Valid. err. 2.84280 Time elapsed: 00:00:07
2018-02-08 13:48:14,824 training [INFO ] Epoch  6 Batch 2150 Training err. 1.46210 Training err. RA 1.58486 Valid. err. 2.83211 Time elapsed: 00:00:08
2018-02-08 13:48:15,067 training [INFO ] Epoch  6 Batch 2200 Training err. 1.40946 Training err. RA 1.58087 Valid. err. 2.83189 Time elapsed: 00:00:08
2018-02-08 13:48:15,254 training [INFO ] Epoch  6 Batch 2250 Training err. 1.40233 Training err. RA 1.57690 Valid. err. 2.81882 Time elapsed: 00:00:08
2018-02-08 13:48:15,509 training [INFO ] Epoch  6 Batch 2300 Training err. 1.42677 Training err. RA 1.57364 Valid. err. 2.79068 Time elapsed: 00:00:08
2018-02-08 13:48:15,801 training [INFO ] Epoch  6 Batch 2350 Training err. 1.40417 Training err. RA 1.57003 Valid. err. 2.78728 Time elapsed: 00:00:09
2018-02-08 13:48:16,021 training [INFO ] Epoch  6 Batch 2400 Training err. 1.39611 Training err. RA 1.56641 Valid. err. 2.77890 Time elapsed: 00:00:09
2018-02-08 13:48:16,223 training [INFO ] Epoch  6 Batch 2450 Training err. 1.42357 Training err. RA 1.56349 Valid. err. 2.76651 Time elapsed: 00:00:09
2018-02-08 13:48:16,529 training [INFO ] Epoch  7 Batch 2500 Training err. 1.44809 Training err. RA 1.56119 Valid. err. 2.86147 Time elapsed: 00:00:09
2018-02-08 13:48:16,691 training [INFO ] Epoch  7 Batch 2550 Training err. 1.42100 Training err. RA 1.55844 Valid. err. 2.82976 Time elapsed: 00:00:10
2018-02-08 13:48:16,871 training [INFO ] Epoch  7 Batch 2600 Training err. 1.38223 Training err. RA 1.55505 Valid. err. 2.75630 Time elapsed: 00:00:10
2018-02-08 13:48:17,049 training [INFO ] Epoch  7 Batch 2650 Training err. 1.36536 Training err. RA 1.55147 Valid. err. 2.75520 Time elapsed: 00:00:10
2018-02-08 13:48:17,214 training [INFO ] Epoch  7 Batch 2700 Training err. 1.38210 Training err. RA 1.54833 Valid. err. 2.72745 Time elapsed: 00:00:10
2018-02-08 13:48:17,368 training [INFO ] Epoch  7 Batch 2750 Training err. 1.38614 Training err. RA 1.54538 Valid. err. 2.75094 Time elapsed: 00:00:10
2018-02-08 13:48:17,541 training [INFO ] Epoch  7 Batch 2800 Training err. 1.35457 Training err. RA 1.54198 Valid. err. 2.71862 Time elapsed: 00:00:10
2018-02-08 13:48:17,709 training [INFO ] Epoch  7 Batch 2850 Training err. 1.39653 Training err. RA 1.53942 Valid. err. 2.79963 Time elapsed: 00:00:11
2018-02-08 13:48:17,978 training [INFO ] Epoch  8 Batch 2900 Training err. 1.41098 Training err. RA 1.53721 Valid. err. 2.80246 Time elapsed: 00:00:11
2018-02-08 13:48:18,147 training [INFO ] Epoch  8 Batch 2950 Training err. 1.40078 Training err. RA 1.53490 Valid. err. 2.69914 Time elapsed: 00:00:11
2018-02-08 13:48:18,319 training [INFO ] Epoch  8 Batch 3000 Training err. 1.34751 Training err. RA 1.53177 Valid. err. 2.70145 Time elapsed: 00:00:11
2018-02-08 13:48:18,489 training [INFO ] Epoch  8 Batch 3050 Training err. 1.33677 Training err. RA 1.52858 Valid. err. 2.67870 Time elapsed: 00:00:11
2018-02-08 13:48:18,657 training [INFO ] Epoch  8 Batch 3100 Training err. 1.35214 Training err. RA 1.52573 Valid. err. 2.66846 Time elapsed: 00:00:12
2018-02-08 13:48:18,811 training [INFO ] Epoch  8 Batch 3150 Training err. 1.37011 Training err. RA 1.52326 Valid. err. 2.69898 Time elapsed: 00:00:12
2018-02-08 13:48:18,992 training [INFO ] Epoch  8 Batch 3200 Training err. 1.30859 Training err. RA 1.51991 Valid. err. 2.69465 Time elapsed: 00:00:12
2018-02-08 13:48:19,155 training [INFO ] Epoch  8 Batch 3250 Training err. 1.36789 Training err. RA 1.51757 Valid. err. 2.65693 Time elapsed: 00:00:12
2018-02-08 13:48:19,407 training [INFO ] Epoch  9 Batch 3300 Training err. 1.37989 Training err. RA 1.51548 Valid. err. 2.64830 Time elapsed: 00:00:12
2018-02-08 13:48:19,576 training [INFO ] Epoch  9 Batch 3350 Training err. 1.37471 Training err. RA 1.51338 Valid. err. 2.66282 Time elapsed: 00:00:12
2018-02-08 13:48:19,744 training [INFO ] Epoch  9 Batch 3400 Training err. 1.32324 Training err. RA 1.51059 Valid. err. 2.66407 Time elapsed: 00:00:13
2018-02-08 13:48:19,919 training [INFO ] Epoch  9 Batch 3450 Training err. 1.31073 Training err. RA 1.50769 Valid. err. 2.63068 Time elapsed: 00:00:13
2018-02-08 13:48:20,089 training [INFO ] Epoch  9 Batch 3500 Training err. 1.31413 Training err. RA 1.50492 Valid. err. 2.66122 Time elapsed: 00:00:13
2018-02-08 13:48:20,245 training [INFO ] Epoch  9 Batch 3550 Training err. 1.34772 Training err. RA 1.50271 Valid. err. 2.61635 Time elapsed: 00:00:13
2018-02-08 13:48:20,413 training [INFO ] Epoch  9 Batch 3600 Training err. 1.29017 Training err. RA 1.49976 Valid. err. 2.62795 Time elapsed: 00:00:13
2018-02-08 13:48:20,576 training [INFO ] Epoch  9 Batch 3650 Training err. 1.32186 Training err. RA 1.49732 Valid. err. 2.60490 Time elapsed: 00:00:13
2018-02-08 13:48:20,838 training [INFO ] Epoch 10 Batch 3700 Training err. 1.36579 Training err. RA 1.49554 Valid. err. 2.61330 Time elapsed: 00:00:14
2018-02-08 13:48:20,989 training [INFO ] Epoch 10 Batch 3750 Training err. 1.33523 Training err. RA 1.49341 Valid. err. 2.60195 Time elapsed: 00:00:14
2018-02-08 13:48:21,155 training [INFO ] Epoch 10 Batch 3800 Training err. 1.32962 Training err. RA 1.49125 Valid. err. 2.65686 Time elapsed: 00:00:14
2018-02-08 13:48:21,306 training [INFO ] Epoch 10 Batch 3850 Training err. 1.28053 Training err. RA 1.48851 Valid. err. 2.58844 Time elapsed: 00:00:14
2018-02-08 13:48:21,473 training [INFO ] Epoch 10 Batch 3900 Training err. 1.29120 Training err. RA 1.48598 Valid. err. 2.57968 Time elapsed: 00:00:14
2018-02-08 13:48:21,639 training [INFO ] Epoch 10 Batch 3950 Training err. 1.34350 Training err. RA 1.48418 Valid. err. 2.57298 Time elapsed: 00:00:15
2018-02-08 13:48:21,798 training [INFO ] Epoch 10 Batch 4000 Training err. 1.26884 Training err. RA 1.48149 Valid. err. 2.56748 Time elapsed: 00:00:15
2018-02-08 13:48:21,973 training [INFO ] Epoch 10 Batch 4050 Training err. 1.28733 Training err. RA 1.47909 Valid. err. 2.55265 Time elapsed: 00:00:15
2018-02-08 13:48:22,146 training [INFO ] Epoch 10 Batch 4100 Training err. 1.30747 Training err. RA 1.47700 Valid. err. 2.56971 Time elapsed: 00:00:15
2018-02-08 13:48:22,241 __main__ [INFO ] End of training
2018-02-08 13:48:22,394 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:48:22,395 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:48:22,581 training [INFO ] Epoch  1 Batch   50 Training err. 2.16901 Training err. RA 2.16901 Valid. err. 4.24334 Time elapsed: 00:00:00
2018-02-08 13:48:22,778 training [INFO ] Epoch  1 Batch  100 Training err. 2.08954 Training err. RA 2.12928 Valid. err. 4.06462 Time elapsed: 00:00:00
2018-02-08 13:48:22,954 training [INFO ] Epoch  1 Batch  150 Training err. 1.99240 Training err. RA 2.08365 Valid. err. 3.84774 Time elapsed: 00:00:00
2018-02-08 13:48:23,130 training [INFO ] Epoch  1 Batch  200 Training err. 1.91918 Training err. RA 2.04253 Valid. err. 3.64950 Time elapsed: 00:00:00
2018-02-08 13:48:23,299 training [INFO ] Epoch  1 Batch  250 Training err. 1.82671 Training err. RA 1.99937 Valid. err. 3.50109 Time elapsed: 00:00:00
2018-02-08 13:48:23,475 training [INFO ] Epoch  1 Batch  300 Training err. 1.75542 Training err. RA 1.95871 Valid. err. 3.41832 Time elapsed: 00:00:01
2018-02-08 13:48:23,650 training [INFO ] Epoch  1 Batch  350 Training err. 1.71683 Training err. RA 1.92416 Valid. err. 3.37016 Time elapsed: 00:00:01
2018-02-08 13:48:23,829 training [INFO ] Epoch  1 Batch  400 Training err. 1.70893 Training err. RA 1.89725 Valid. err. 3.34401 Time elapsed: 00:00:01
2018-02-08 13:48:23,997 training [INFO ] Epoch  1 Batch  450 Training err. 1.68766 Training err. RA 1.87396 Valid. err. 3.32650 Time elapsed: 00:00:01
2018-02-08 13:48:24,179 training [INFO ] Epoch  1 Batch  500 Training err. 1.66182 Training err. RA 1.85275 Valid. err. 3.31229 Time elapsed: 00:00:01
2018-02-08 13:48:24,344 training [INFO ] Epoch  1 Batch  550 Training err. 1.67806 Training err. RA 1.83687 Valid. err. 3.28834 Time elapsed: 00:00:01
2018-02-08 13:48:24,519 training [INFO ] Epoch  1 Batch  600 Training err. 1.65795 Training err. RA 1.82196 Valid. err. 3.28601 Time elapsed: 00:00:02
2018-02-08 13:48:24,787 training [INFO ] Epoch  2 Batch  650 Training err. 1.65973 Training err. RA 1.80948 Valid. err. 3.27070 Time elapsed: 00:00:02
2018-02-08 13:48:24,969 training [INFO ] Epoch  2 Batch  700 Training err. 1.64107 Training err. RA 1.79745 Valid. err. 3.26790 Time elapsed: 00:00:02
2018-02-08 13:48:25,159 training [INFO ] Epoch  2 Batch  750 Training err. 1.65070 Training err. RA 1.78767 Valid. err. 3.26279 Time elapsed: 00:00:02
2018-02-08 13:48:25,334 training [INFO ] Epoch  2 Batch  800 Training err. 1.64347 Training err. RA 1.77866 Valid. err. 3.25268 Time elapsed: 00:00:02
2018-02-08 13:48:25,514 training [INFO ] Epoch  2 Batch  850 Training err. 1.63494 Training err. RA 1.77020 Valid. err. 3.25360 Time elapsed: 00:00:03
2018-02-08 13:48:25,682 training [INFO ] Epoch  2 Batch  900 Training err. 1.60900 Training err. RA 1.76125 Valid. err. 3.25877 Time elapsed: 00:00:03
2018-02-08 13:48:25,865 training [INFO ] Epoch  2 Batch  950 Training err. 1.60169 Training err. RA 1.75285 Valid. err. 3.25058 Time elapsed: 00:00:03
2018-02-08 13:48:26,097 training [INFO ] Epoch  2 Batch 1000 Training err. 1.62059 Training err. RA 1.74624 Valid. err. 3.25952 Time elapsed: 00:00:03
2018-02-08 13:48:26,273 training [INFO ] Epoch  2 Batch 1050 Training err. 1.65260 Training err. RA 1.74178 Valid. err. 3.24246 Time elapsed: 00:00:03
2018-02-08 13:48:26,458 training [INFO ] Epoch  2 Batch 1100 Training err. 1.61302 Training err. RA 1.73592 Valid. err. 3.24217 Time elapsed: 00:00:04
2018-02-08 13:48:26,658 training [INFO ] Epoch  2 Batch 1150 Training err. 1.63061 Training err. RA 1.73135 Valid. err. 3.23326 Time elapsed: 00:00:04
2018-02-08 13:48:26,847 training [INFO ] Epoch  2 Batch 1200 Training err. 1.61409 Training err. RA 1.72646 Valid. err. 3.22871 Time elapsed: 00:00:04
2018-02-08 13:48:27,123 training [INFO ] Epoch  3 Batch 1250 Training err. 1.62091 Training err. RA 1.72224 Valid. err. 3.22963 Time elapsed: 00:00:04
2018-02-08 13:48:27,294 training [INFO ] Epoch  3 Batch 1300 Training err. 1.63580 Training err. RA 1.71891 Valid. err. 3.23828 Time elapsed: 00:00:04
2018-02-08 13:48:27,465 training [INFO ] Epoch  3 Batch 1350 Training err. 1.61708 Training err. RA 1.71514 Valid. err. 3.22904 Time elapsed: 00:00:05
2018-02-08 13:48:27,638 training [INFO ] Epoch  3 Batch 1400 Training err. 1.59484 Training err. RA 1.71085 Valid. err. 3.23341 Time elapsed: 00:00:05
2018-02-08 13:48:27,816 training [INFO ] Epoch  3 Batch 1450 Training err. 1.64218 Training err. RA 1.70848 Valid. err. 3.22925 Time elapsed: 00:00:05
2018-02-08 13:48:27,992 training [INFO ] Epoch  3 Batch 1500 Training err. 1.58417 Training err. RA 1.70433 Valid. err. 3.23908 Time elapsed: 00:00:05
2018-02-08 13:48:28,166 training [INFO ] Epoch  3 Batch 1550 Training err. 1.58236 Training err. RA 1.70040 Valid. err. 3.22830 Time elapsed: 00:00:05
2018-02-08 13:48:28,338 training [INFO ] Epoch  3 Batch 1600 Training err. 1.61079 Training err. RA 1.69760 Valid. err. 3.23332 Time elapsed: 00:00:05
2018-02-08 13:48:28,514 training [INFO ] Epoch  3 Batch 1650 Training err. 1.63984 Training err. RA 1.69585 Valid. err. 3.22151 Time elapsed: 00:00:06
2018-02-08 13:48:28,682 training [INFO ] Epoch  3 Batch 1700 Training err. 1.59734 Training err. RA 1.69295 Valid. err. 3.21940 Time elapsed: 00:00:06
2018-02-08 13:48:28,865 training [INFO ] Epoch  3 Batch 1750 Training err. 1.61528 Training err. RA 1.69073 Valid. err. 3.21333 Time elapsed: 00:00:06
2018-02-08 13:48:29,038 training [INFO ] Epoch  3 Batch 1800 Training err. 1.59839 Training err. RA 1.68817 Valid. err. 3.20888 Time elapsed: 00:00:06
2018-02-08 13:48:29,307 training [INFO ] Epoch  4 Batch 1850 Training err. 1.59589 Training err. RA 1.68567 Valid. err. 3.21012 Time elapsed: 00:00:06
2018-02-08 13:48:29,475 training [INFO ] Epoch  4 Batch 1900 Training err. 1.62021 Training err. RA 1.68395 Valid. err. 3.21234 Time elapsed: 00:00:07
2018-02-08 13:48:29,650 training [INFO ] Epoch  4 Batch 1950 Training err. 1.60936 Training err. RA 1.68204 Valid. err. 3.21141 Time elapsed: 00:00:07
2018-02-08 13:48:29,820 training [INFO ] Epoch  4 Batch 2000 Training err. 1.57535 Training err. RA 1.67937 Valid. err. 3.21059 Time elapsed: 00:00:07
2018-02-08 13:48:29,996 training [INFO ] Epoch  4 Batch 2050 Training err. 1.64270 Training err. RA 1.67848 Valid. err. 3.19826 Time elapsed: 00:00:07
2018-02-08 13:48:30,168 training [INFO ] Epoch  4 Batch 2100 Training err. 1.57556 Training err. RA 1.67603 Valid. err. 3.21412 Time elapsed: 00:00:07
2018-02-08 13:48:30,345 training [INFO ] Epoch  4 Batch 2150 Training err. 1.56964 Training err. RA 1.67355 Valid. err. 3.20431 Time elapsed: 00:00:07
2018-02-08 13:48:30,513 training [INFO ] Epoch  4 Batch 2200 Training err. 1.60333 Training err. RA 1.67196 Valid. err. 3.20294 Time elapsed: 00:00:08
2018-02-08 13:48:30,692 training [INFO ] Epoch  4 Batch 2250 Training err. 1.60425 Training err. RA 1.67045 Valid. err. 3.19372 Time elapsed: 00:00:08
2018-02-08 13:48:30,870 training [INFO ] Epoch  4 Batch 2300 Training err. 1.60119 Training err. RA 1.66895 Valid. err. 3.19380 Time elapsed: 00:00:08
2018-02-08 13:48:31,054 training [INFO ] Epoch  4 Batch 2350 Training err. 1.58020 Training err. RA 1.66706 Valid. err. 3.18830 Time elapsed: 00:00:08
2018-02-08 13:48:31,234 training [INFO ] Epoch  4 Batch 2400 Training err. 1.59399 Training err. RA 1.66553 Valid. err. 3.17725 Time elapsed: 00:00:08
2018-02-08 13:48:31,410 training [INFO ] Epoch  4 Batch 2450 Training err. 1.57796 Training err. RA 1.66375 Valid. err. 3.17891 Time elapsed: 00:00:09
2018-02-08 13:48:31,682 training [INFO ] Epoch  5 Batch 2500 Training err. 1.61490 Training err. RA 1.66277 Valid. err. 3.17121 Time elapsed: 00:00:09
2018-02-08 13:48:31,862 training [INFO ] Epoch  5 Batch 2550 Training err. 1.58391 Training err. RA 1.66122 Valid. err. 3.18816 Time elapsed: 00:00:09
2018-02-08 13:48:32,047 training [INFO ] Epoch  5 Batch 2600 Training err. 1.57364 Training err. RA 1.65954 Valid. err. 3.15994 Time elapsed: 00:00:09
2018-02-08 13:48:32,221 training [INFO ] Epoch  5 Batch 2650 Training err. 1.62075 Training err. RA 1.65881 Valid. err. 3.15811 Time elapsed: 00:00:09
2018-02-08 13:48:32,396 training [INFO ] Epoch  5 Batch 2700 Training err. 1.56006 Training err. RA 1.65698 Valid. err. 3.16299 Time elapsed: 00:00:09
2018-02-08 13:48:32,565 training [INFO ] Epoch  5 Batch 2750 Training err. 1.55512 Training err. RA 1.65513 Valid. err. 3.15440 Time elapsed: 00:00:10
2018-02-08 13:48:32,749 training [INFO ] Epoch  5 Batch 2800 Training err. 1.55211 Training err. RA 1.65329 Valid. err. 3.14833 Time elapsed: 00:00:10
2018-02-08 13:48:32,929 training [INFO ] Epoch  5 Batch 2850 Training err. 1.56831 Training err. RA 1.65180 Valid. err. 3.14184 Time elapsed: 00:00:10
2018-02-08 13:48:33,106 training [INFO ] Epoch  5 Batch 2900 Training err. 1.58885 Training err. RA 1.65071 Valid. err. 3.13574 Time elapsed: 00:00:10
2018-02-08 13:48:33,280 training [INFO ] Epoch  5 Batch 2950 Training err. 1.54801 Training err. RA 1.64897 Valid. err. 3.14150 Time elapsed: 00:00:10
2018-02-08 13:48:33,453 training [INFO ] Epoch  5 Batch 3000 Training err. 1.57118 Training err. RA 1.64767 Valid. err. 3.18210 Time elapsed: 00:00:11
2018-02-08 13:48:33,629 training [INFO ] Epoch  5 Batch 3050 Training err. 1.56957 Training err. RA 1.64639 Valid. err. 3.12853 Time elapsed: 00:00:11
2018-02-08 13:48:33,916 training [INFO ] Epoch  6 Batch 3100 Training err. 1.57402 Training err. RA 1.64523 Valid. err. 3.13419 Time elapsed: 00:00:11
2018-02-08 13:48:34,086 training [INFO ] Epoch  6 Batch 3150 Training err. 1.55809 Training err. RA 1.64384 Valid. err. 3.11110 Time elapsed: 00:00:11
2018-02-08 13:48:34,269 training [INFO ] Epoch  6 Batch 3200 Training err. 1.55929 Training err. RA 1.64252 Valid. err. 3.09792 Time elapsed: 00:00:11
2018-02-08 13:48:34,439 training [INFO ] Epoch  6 Batch 3250 Training err. 1.54944 Training err. RA 1.64109 Valid. err. 3.08439 Time elapsed: 00:00:12
2018-02-08 13:48:34,619 training [INFO ] Epoch  6 Batch 3300 Training err. 1.57778 Training err. RA 1.64013 Valid. err. 3.08272 Time elapsed: 00:00:12
2018-02-08 13:48:34,793 training [INFO ] Epoch  6 Batch 3350 Training err. 1.51154 Training err. RA 1.63821 Valid. err. 3.10557 Time elapsed: 00:00:12
2018-02-08 13:48:34,977 training [INFO ] Epoch  6 Batch 3400 Training err. 1.50522 Training err. RA 1.63626 Valid. err. 3.13963 Time elapsed: 00:00:12
2018-02-08 13:48:35,146 training [INFO ] Epoch  6 Batch 3450 Training err. 1.53778 Training err. RA 1.63483 Valid. err. 3.07483 Time elapsed: 00:00:12
2018-02-08 13:48:35,326 training [INFO ] Epoch  6 Batch 3500 Training err. 1.56252 Training err. RA 1.63380 Valid. err. 3.05680 Time elapsed: 00:00:12
2018-02-08 13:48:35,502 training [INFO ] Epoch  6 Batch 3550 Training err. 1.50821 Training err. RA 1.63203 Valid. err. 3.05165 Time elapsed: 00:00:13
2018-02-08 13:48:35,680 training [INFO ] Epoch  6 Batch 3600 Training err. 1.53885 Training err. RA 1.63073 Valid. err. 3.04974 Time elapsed: 00:00:13
2018-02-08 13:48:35,859 training [INFO ] Epoch  6 Batch 3650 Training err. 1.52093 Training err. RA 1.62923 Valid. err. 3.02828 Time elapsed: 00:00:13
2018-02-08 13:48:36,126 training [INFO ] Epoch  7 Batch 3700 Training err. 1.53049 Training err. RA 1.62789 Valid. err. 3.03044 Time elapsed: 00:00:13
2018-02-08 13:48:36,304 training [INFO ] Epoch  7 Batch 3750 Training err. 1.55006 Training err. RA 1.62686 Valid. err. 3.06236 Time elapsed: 00:00:13
2018-02-08 13:48:36,479 training [INFO ] Epoch  7 Batch 3800 Training err. 1.52038 Training err. RA 1.62546 Valid. err. 3.05141 Time elapsed: 00:00:14
2018-02-08 13:48:36,651 training [INFO ] Epoch  7 Batch 3850 Training err. 1.49776 Training err. RA 1.62380 Valid. err. 3.00513 Time elapsed: 00:00:14
2018-02-08 13:48:36,831 training [INFO ] Epoch  7 Batch 3900 Training err. 1.54942 Training err. RA 1.62284 Valid. err. 3.01460 Time elapsed: 00:00:14
2018-02-08 13:48:37,006 training [INFO ] Epoch  7 Batch 3950 Training err. 1.47719 Training err. RA 1.62100 Valid. err. 3.02330 Time elapsed: 00:00:14
2018-02-08 13:48:37,190 training [INFO ] Epoch  7 Batch 4000 Training err. 1.46507 Training err. RA 1.61905 Valid. err. 2.99114 Time elapsed: 00:00:14
2018-02-08 13:48:37,362 training [INFO ] Epoch  7 Batch 4050 Training err. 1.50354 Training err. RA 1.61762 Valid. err. 3.00995 Time elapsed: 00:00:14
2018-02-08 13:48:37,535 training [INFO ] Epoch  7 Batch 4100 Training err. 1.50988 Training err. RA 1.61631 Valid. err. 2.96921 Time elapsed: 00:00:15
2018-02-08 13:48:37,708 training [INFO ] Epoch  7 Batch 4150 Training err. 1.46994 Training err. RA 1.61455 Valid. err. 2.95189 Time elapsed: 00:00:15
2018-02-08 13:48:37,893 training [INFO ] Epoch  7 Batch 4200 Training err. 1.47796 Training err. RA 1.61292 Valid. err. 2.94399 Time elapsed: 00:00:15
2018-02-08 13:48:38,114 training [INFO ] Epoch  7 Batch 4250 Training err. 1.50449 Training err. RA 1.61165 Valid. err. 2.94324 Time elapsed: 00:00:15
2018-02-08 13:48:38,392 training [INFO ] Epoch  8 Batch 4300 Training err. 1.45967 Training err. RA 1.60988 Valid. err. 2.93127 Time elapsed: 00:00:15
2018-02-08 13:48:38,582 training [INFO ] Epoch  8 Batch 4350 Training err. 1.51833 Training err. RA 1.60883 Valid. err. 2.96369 Time elapsed: 00:00:16
2018-02-08 13:48:38,781 training [INFO ] Epoch  8 Batch 4400 Training err. 1.48074 Training err. RA 1.60737 Valid. err. 2.92496 Time elapsed: 00:00:16
2018-02-08 13:48:38,973 training [INFO ] Epoch  8 Batch 4450 Training err. 1.45845 Training err. RA 1.60570 Valid. err. 2.91752 Time elapsed: 00:00:16
2018-02-08 13:48:39,210 training [INFO ] Epoch  8 Batch 4500 Training err. 1.51852 Training err. RA 1.60473 Valid. err. 2.89804 Time elapsed: 00:00:16
2018-02-08 13:48:39,387 training [INFO ] Epoch  8 Batch 4550 Training err. 1.44122 Training err. RA 1.60293 Valid. err. 2.91889 Time elapsed: 00:00:16
2018-02-08 13:48:39,605 training [INFO ] Epoch  8 Batch 4600 Training err. 1.43257 Training err. RA 1.60108 Valid. err. 2.91394 Time elapsed: 00:00:17
2018-02-08 13:48:39,790 training [INFO ] Epoch  8 Batch 4650 Training err. 1.44307 Training err. RA 1.59938 Valid. err. 2.89542 Time elapsed: 00:00:17
2018-02-08 13:48:39,975 training [INFO ] Epoch  8 Batch 4700 Training err. 1.44413 Training err. RA 1.59773 Valid. err. 2.87316 Time elapsed: 00:00:17
2018-02-08 13:48:40,172 training [INFO ] Epoch  8 Batch 4750 Training err. 1.44031 Training err. RA 1.59607 Valid. err. 2.88412 Time elapsed: 00:00:17
2018-02-08 13:48:40,359 training [INFO ] Epoch  8 Batch 4800 Training err. 1.44607 Training err. RA 1.59451 Valid. err. 2.87338 Time elapsed: 00:00:17
2018-02-08 13:48:40,531 training [INFO ] Epoch  8 Batch 4850 Training err. 1.44556 Training err. RA 1.59297 Valid. err. 2.85170 Time elapsed: 00:00:18
2018-02-08 13:48:40,718 training [INFO ] Epoch  8 Batch 4900 Training err. 1.43531 Training err. RA 1.59137 Valid. err. 2.88748 Time elapsed: 00:00:18
2018-02-08 13:48:41,020 training [INFO ] Epoch  9 Batch 4950 Training err. 1.47559 Training err. RA 1.59020 Valid. err. 2.84012 Time elapsed: 00:00:18
2018-02-08 13:48:41,197 training [INFO ] Epoch  9 Batch 5000 Training err. 1.44779 Training err. RA 1.58877 Valid. err. 2.89288 Time elapsed: 00:00:18
2018-02-08 13:48:41,381 training [INFO ] Epoch  9 Batch 5050 Training err. 1.44476 Training err. RA 1.58735 Valid. err. 2.82704 Time elapsed: 00:00:18
2018-02-08 13:48:41,561 training [INFO ] Epoch  9 Batch 5100 Training err. 1.46781 Training err. RA 1.58617 Valid. err. 2.83631 Time elapsed: 00:00:19
2018-02-08 13:48:41,737 training [INFO ] Epoch  9 Batch 5150 Training err. 1.42672 Training err. RA 1.58463 Valid. err. 2.83634 Time elapsed: 00:00:19
2018-02-08 13:48:41,911 training [INFO ] Epoch  9 Batch 5200 Training err. 1.40706 Training err. RA 1.58292 Valid. err. 2.82341 Time elapsed: 00:00:19
2018-02-08 13:48:42,089 training [INFO ] Epoch  9 Batch 5250 Training err. 1.38396 Training err. RA 1.58102 Valid. err. 2.81140 Time elapsed: 00:00:19
2018-02-08 13:48:42,261 training [INFO ] Epoch  9 Batch 5300 Training err. 1.39389 Training err. RA 1.57926 Valid. err. 2.81727 Time elapsed: 00:00:19
2018-02-08 13:48:42,442 training [INFO ] Epoch  9 Batch 5350 Training err. 1.43241 Training err. RA 1.57789 Valid. err. 2.88159 Time elapsed: 00:00:20
2018-02-08 13:48:42,610 training [INFO ] Epoch  9 Batch 5400 Training err. 1.39209 Training err. RA 1.57617 Valid. err. 2.80821 Time elapsed: 00:00:20
2018-02-08 13:48:42,790 training [INFO ] Epoch  9 Batch 5450 Training err. 1.43179 Training err. RA 1.57484 Valid. err. 2.79996 Time elapsed: 00:00:20
2018-02-08 13:48:42,967 training [INFO ] Epoch  9 Batch 5500 Training err. 1.41870 Training err. RA 1.57342 Valid. err. 2.79273 Time elapsed: 00:00:20
2018-02-08 13:48:43,247 training [INFO ] Epoch 10 Batch 5550 Training err. 1.41717 Training err. RA 1.57201 Valid. err. 2.78250 Time elapsed: 00:00:20
2018-02-08 13:48:43,417 training [INFO ] Epoch 10 Batch 5600 Training err. 1.46020 Training err. RA 1.57102 Valid. err. 2.81096 Time elapsed: 00:00:21
2018-02-08 13:48:43,590 training [INFO ] Epoch 10 Batch 5650 Training err. 1.42388 Training err. RA 1.56971 Valid. err. 2.79953 Time elapsed: 00:00:21
2018-02-08 13:48:43,761 training [INFO ] Epoch 10 Batch 5700 Training err. 1.39495 Training err. RA 1.56818 Valid. err. 2.77850 Time elapsed: 00:00:21
2018-02-08 13:48:43,947 training [INFO ] Epoch 10 Batch 5750 Training err. 1.45427 Training err. RA 1.56719 Valid. err. 2.82686 Time elapsed: 00:00:21
2018-02-08 13:48:44,126 training [INFO ] Epoch 10 Batch 5800 Training err. 1.37980 Training err. RA 1.56557 Valid. err. 2.82231 Time elapsed: 00:00:21
2018-02-08 13:48:44,301 training [INFO ] Epoch 10 Batch 5850 Training err. 1.35554 Training err. RA 1.56378 Valid. err. 2.79819 Time elapsed: 00:00:21
2018-02-08 13:48:44,471 training [INFO ] Epoch 10 Batch 5900 Training err. 1.38943 Training err. RA 1.56230 Valid. err. 2.79668 Time elapsed: 00:00:22
2018-02-08 13:48:44,653 training [INFO ] Epoch 10 Batch 5950 Training err. 1.41024 Training err. RA 1.56102 Valid. err. 2.80399 Time elapsed: 00:00:22
2018-02-08 13:48:44,823 training [INFO ] Epoch 10 Batch 6000 Training err. 1.36585 Training err. RA 1.55940 Valid. err. 2.75452 Time elapsed: 00:00:22
2018-02-08 13:48:45,008 training [INFO ] Epoch 10 Batch 6050 Training err. 1.41058 Training err. RA 1.55817 Valid. err. 2.75452 Time elapsed: 00:00:22
2018-02-08 13:48:45,183 training [INFO ] Epoch 10 Batch 6100 Training err. 1.39396 Training err. RA 1.55682 Valid. err. 2.75667 Time elapsed: 00:00:22
2018-02-08 13:48:45,345 __main__ [INFO ] End of training
2018-02-08 13:53:41,997 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:53:41,999 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:53:42,002 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:53:42,023 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:53:45,050 training [INFO ] Epoch  1 Batch   50 Training err. 2.12313 Training err. RA 2.12313 Valid. err. 4.01540 Time elapsed: 00:00:00
2018-02-08 13:53:45,212 training [INFO ] Epoch  1 Batch  100 Training err. 1.90607 Training err. RA 2.01460 Valid. err. 3.51609 Time elapsed: 00:00:00
2018-02-08 13:53:45,385 training [INFO ] Epoch  1 Batch  150 Training err. 1.72161 Training err. RA 1.91694 Valid. err. 3.35002 Time elapsed: 00:00:00
2018-02-08 13:53:45,550 training [INFO ] Epoch  1 Batch  200 Training err. 1.67427 Training err. RA 1.85627 Valid. err. 3.29990 Time elapsed: 00:00:00
2018-02-08 13:53:45,720 training [INFO ] Epoch  1 Batch  250 Training err. 1.63753 Training err. RA 1.81252 Valid. err. 3.30180 Time elapsed: 00:00:01
2018-02-08 13:53:45,888 training [INFO ] Epoch  1 Batch  300 Training err. 1.64318 Training err. RA 1.78430 Valid. err. 3.28362 Time elapsed: 00:00:01
2018-02-08 13:53:46,067 training [INFO ] Epoch  1 Batch  350 Training err. 1.62478 Training err. RA 1.76151 Valid. err. 3.24985 Time elapsed: 00:00:01
2018-02-08 13:53:46,231 training [INFO ] Epoch  1 Batch  400 Training err. 1.64177 Training err. RA 1.74654 Valid. err. 3.25522 Time elapsed: 00:00:01
2018-02-08 13:53:46,398 training [INFO ] Epoch  1 Batch  450 Training err. 1.61798 Training err. RA 1.73226 Valid. err. 3.23960 Time elapsed: 00:00:01
2018-02-08 13:53:46,565 training [INFO ] Epoch  1 Batch  500 Training err. 1.60347 Training err. RA 1.71938 Valid. err. 3.25748 Time elapsed: 00:00:01
2018-02-08 13:53:46,733 training [INFO ] Epoch  1 Batch  550 Training err. 1.63916 Training err. RA 1.71209 Valid. err. 3.23273 Time elapsed: 00:00:02
2018-02-08 13:53:46,901 training [INFO ] Epoch  1 Batch  600 Training err. 1.63189 Training err. RA 1.70540 Valid. err. 3.22134 Time elapsed: 00:00:02
2018-02-08 13:53:47,177 training [INFO ] Epoch  2 Batch  650 Training err. 1.64811 Training err. RA 1.70100 Valid. err. 3.23091 Time elapsed: 00:00:02
2018-02-08 13:53:47,336 training [INFO ] Epoch  2 Batch  700 Training err. 1.57748 Training err. RA 1.69217 Valid. err. 3.23579 Time elapsed: 00:00:02
2018-02-08 13:53:47,509 training [INFO ] Epoch  2 Batch  750 Training err. 1.63374 Training err. RA 1.68828 Valid. err. 3.25385 Time elapsed: 00:00:02
2018-02-08 13:53:47,668 training [INFO ] Epoch  2 Batch  800 Training err. 1.59407 Training err. RA 1.68239 Valid. err. 3.24137 Time elapsed: 00:00:02
2018-02-08 13:53:47,840 training [INFO ] Epoch  2 Batch  850 Training err. 1.61406 Training err. RA 1.67837 Valid. err. 3.23531 Time elapsed: 00:00:03
2018-02-08 13:53:48,007 training [INFO ] Epoch  2 Batch  900 Training err. 1.60224 Training err. RA 1.67414 Valid. err. 3.21028 Time elapsed: 00:00:03
2018-02-08 13:53:48,178 training [INFO ] Epoch  2 Batch  950 Training err. 1.58966 Training err. RA 1.66969 Valid. err. 3.21136 Time elapsed: 00:00:03
2018-02-08 13:53:48,342 training [INFO ] Epoch  2 Batch 1000 Training err. 1.61811 Training err. RA 1.66712 Valid. err. 3.21827 Time elapsed: 00:00:03
2018-02-08 13:53:48,515 training [INFO ] Epoch  2 Batch 1050 Training err. 1.59752 Training err. RA 1.66380 Valid. err. 3.20509 Time elapsed: 00:00:03
2018-02-08 13:53:48,682 training [INFO ] Epoch  2 Batch 1100 Training err. 1.59291 Training err. RA 1.66058 Valid. err. 3.22109 Time elapsed: 00:00:03
2018-02-08 13:53:48,851 training [INFO ] Epoch  2 Batch 1150 Training err. 1.59684 Training err. RA 1.65781 Valid. err. 3.20740 Time elapsed: 00:00:04
2018-02-08 13:53:49,028 training [INFO ] Epoch  2 Batch 1200 Training err. 1.61508 Training err. RA 1.65603 Valid. err. 3.17627 Time elapsed: 00:00:04
2018-02-08 13:53:49,301 training [INFO ] Epoch  3 Batch 1250 Training err. 1.63129 Training err. RA 1.65504 Valid. err. 3.17994 Time elapsed: 00:00:04
2018-02-08 13:53:49,458 training [INFO ] Epoch  3 Batch 1300 Training err. 1.55500 Training err. RA 1.65119 Valid. err. 3.18282 Time elapsed: 00:00:04
2018-02-08 13:53:49,634 training [INFO ] Epoch  3 Batch 1350 Training err. 1.61259 Training err. RA 1.64976 Valid. err. 3.18119 Time elapsed: 00:00:04
2018-02-08 13:53:49,796 training [INFO ] Epoch  3 Batch 1400 Training err. 1.56620 Training err. RA 1.64678 Valid. err. 3.16735 Time elapsed: 00:00:05
2018-02-08 13:53:49,981 training [INFO ] Epoch  3 Batch 1450 Training err. 1.58739 Training err. RA 1.64473 Valid. err. 3.15605 Time elapsed: 00:00:05
2018-02-08 13:53:50,148 training [INFO ] Epoch  3 Batch 1500 Training err. 1.54803 Training err. RA 1.64151 Valid. err. 3.14588 Time elapsed: 00:00:05
2018-02-08 13:53:50,321 training [INFO ] Epoch  3 Batch 1550 Training err. 1.56001 Training err. RA 1.63888 Valid. err. 3.12628 Time elapsed: 00:00:05
2018-02-08 13:53:50,493 training [INFO ] Epoch  3 Batch 1600 Training err. 1.58761 Training err. RA 1.63727 Valid. err. 3.12196 Time elapsed: 00:00:05
2018-02-08 13:53:50,672 training [INFO ] Epoch  3 Batch 1650 Training err. 1.56870 Training err. RA 1.63520 Valid. err. 3.12682 Time elapsed: 00:00:05
2018-02-08 13:53:50,834 training [INFO ] Epoch  3 Batch 1700 Training err. 1.52466 Training err. RA 1.63195 Valid. err. 3.14724 Time elapsed: 00:00:06
2018-02-08 13:53:51,011 training [INFO ] Epoch  3 Batch 1750 Training err. 1.57273 Training err. RA 1.63025 Valid. err. 3.11888 Time elapsed: 00:00:06
2018-02-08 13:53:51,183 training [INFO ] Epoch  3 Batch 1800 Training err. 1.56838 Training err. RA 1.62853 Valid. err. 3.07633 Time elapsed: 00:00:06
2018-02-08 13:53:51,485 training [INFO ] Epoch  4 Batch 1850 Training err. 1.56891 Training err. RA 1.62692 Valid. err. 3.06968 Time elapsed: 00:00:06
2018-02-08 13:53:51,652 training [INFO ] Epoch  4 Batch 1900 Training err. 1.54171 Training err. RA 1.62468 Valid. err. 3.12135 Time elapsed: 00:00:06
2018-02-08 13:53:51,828 training [INFO ] Epoch  4 Batch 1950 Training err. 1.55971 Training err. RA 1.62301 Valid. err. 3.04930 Time elapsed: 00:00:07
2018-02-08 13:53:52,000 training [INFO ] Epoch  4 Batch 2000 Training err. 1.49247 Training err. RA 1.61975 Valid. err. 3.03826 Time elapsed: 00:00:07
2018-02-08 13:53:52,177 training [INFO ] Epoch  4 Batch 2050 Training err. 1.53579 Training err. RA 1.61770 Valid. err. 3.05091 Time elapsed: 00:00:07
2018-02-08 13:53:52,334 training [INFO ] Epoch  4 Batch 2100 Training err. 1.47230 Training err. RA 1.61424 Valid. err. 3.03012 Time elapsed: 00:00:07
2018-02-08 13:53:52,510 training [INFO ] Epoch  4 Batch 2150 Training err. 1.49240 Training err. RA 1.61141 Valid. err. 3.01652 Time elapsed: 00:00:07
2018-02-08 13:53:52,670 training [INFO ] Epoch  4 Batch 2200 Training err. 1.50949 Training err. RA 1.60909 Valid. err. 2.95927 Time elapsed: 00:00:07
2018-02-08 13:53:52,852 training [INFO ] Epoch  4 Batch 2250 Training err. 1.49656 Training err. RA 1.60659 Valid. err. 2.96071 Time elapsed: 00:00:08
2018-02-08 13:53:53,024 training [INFO ] Epoch  4 Batch 2300 Training err. 1.45883 Training err. RA 1.60338 Valid. err. 2.99200 Time elapsed: 00:00:08
2018-02-08 13:53:53,195 training [INFO ] Epoch  4 Batch 2350 Training err. 1.46196 Training err. RA 1.60037 Valid. err. 2.91422 Time elapsed: 00:00:08
2018-02-08 13:53:53,362 training [INFO ] Epoch  4 Batch 2400 Training err. 1.49130 Training err. RA 1.59810 Valid. err. 2.89490 Time elapsed: 00:00:08
2018-02-08 13:53:53,534 training [INFO ] Epoch  4 Batch 2450 Training err. 1.47776 Training err. RA 1.59564 Valid. err. 2.87281 Time elapsed: 00:00:08
2018-02-08 13:53:53,800 training [INFO ] Epoch  5 Batch 2500 Training err. 1.49808 Training err. RA 1.59369 Valid. err. 2.95694 Time elapsed: 00:00:09
2018-02-08 13:53:53,969 training [INFO ] Epoch  5 Batch 2550 Training err. 1.47976 Training err. RA 1.59146 Valid. err. 2.85902 Time elapsed: 00:00:09
2018-02-08 13:53:54,137 training [INFO ] Epoch  5 Batch 2600 Training err. 1.42899 Training err. RA 1.58833 Valid. err. 2.86398 Time elapsed: 00:00:09
2018-02-08 13:53:54,304 training [INFO ] Epoch  5 Batch 2650 Training err. 1.40509 Training err. RA 1.58487 Valid. err. 2.85492 Time elapsed: 00:00:09
2018-02-08 13:53:54,471 training [INFO ] Epoch  5 Batch 2700 Training err. 1.40221 Training err. RA 1.58149 Valid. err. 2.82132 Time elapsed: 00:00:09
2018-02-08 13:53:54,638 training [INFO ] Epoch  5 Batch 2750 Training err. 1.41363 Training err. RA 1.57844 Valid. err. 2.81091 Time elapsed: 00:00:09
2018-02-08 13:53:54,804 training [INFO ] Epoch  5 Batch 2800 Training err. 1.40724 Training err. RA 1.57538 Valid. err. 2.80930 Time elapsed: 00:00:10
2018-02-08 13:53:54,978 training [INFO ] Epoch  5 Batch 2850 Training err. 1.43355 Training err. RA 1.57289 Valid. err. 2.78461 Time elapsed: 00:00:10
2018-02-08 13:53:55,150 training [INFO ] Epoch  5 Batch 2900 Training err. 1.38894 Training err. RA 1.56972 Valid. err. 2.78510 Time elapsed: 00:00:10
2018-02-08 13:53:55,314 training [INFO ] Epoch  5 Batch 2950 Training err. 1.36537 Training err. RA 1.56626 Valid. err. 2.78144 Time elapsed: 00:00:10
2018-02-08 13:53:55,483 training [INFO ] Epoch  5 Batch 3000 Training err. 1.41425 Training err. RA 1.56373 Valid. err. 2.74065 Time elapsed: 00:00:10
2018-02-08 13:53:55,655 training [INFO ] Epoch  5 Batch 3050 Training err. 1.41520 Training err. RA 1.56129 Valid. err. 2.73425 Time elapsed: 00:00:10
2018-02-08 13:53:55,927 training [INFO ] Epoch  6 Batch 3100 Training err. 1.44767 Training err. RA 1.55946 Valid. err. 2.73910 Time elapsed: 00:00:11
2018-02-08 13:53:56,090 training [INFO ] Epoch  6 Batch 3150 Training err. 1.36769 Training err. RA 1.55641 Valid. err. 2.73695 Time elapsed: 00:00:11
2018-02-08 13:53:56,260 training [INFO ] Epoch  6 Batch 3200 Training err. 1.42128 Training err. RA 1.55430 Valid. err. 2.78148 Time elapsed: 00:00:11
2018-02-08 13:53:56,417 training [INFO ] Epoch  6 Batch 3250 Training err. 1.36304 Training err. RA 1.55136 Valid. err. 2.72128 Time elapsed: 00:00:11
2018-02-08 13:53:56,594 training [INFO ] Epoch  6 Batch 3300 Training err. 1.34921 Training err. RA 1.54830 Valid. err. 2.70882 Time elapsed: 00:00:11
2018-02-08 13:53:56,756 training [INFO ] Epoch  6 Batch 3350 Training err. 1.34902 Training err. RA 1.54532 Valid. err. 2.71624 Time elapsed: 00:00:12
2018-02-08 13:53:56,925 training [INFO ] Epoch  6 Batch 3400 Training err. 1.33198 Training err. RA 1.54219 Valid. err. 2.69499 Time elapsed: 00:00:12
2018-02-08 13:53:57,096 training [INFO ] Epoch  6 Batch 3450 Training err. 1.40121 Training err. RA 1.54014 Valid. err. 2.68143 Time elapsed: 00:00:12
2018-02-08 13:53:57,267 training [INFO ] Epoch  6 Batch 3500 Training err. 1.34965 Training err. RA 1.53742 Valid. err. 2.68674 Time elapsed: 00:00:12
2018-02-08 13:53:57,427 training [INFO ] Epoch  6 Batch 3550 Training err. 1.30022 Training err. RA 1.53408 Valid. err. 2.70193 Time elapsed: 00:00:12
2018-02-08 13:53:57,592 training [INFO ] Epoch  6 Batch 3600 Training err. 1.34993 Training err. RA 1.53152 Valid. err. 2.66195 Time elapsed: 00:00:12
2018-02-08 13:53:57,755 training [INFO ] Epoch  6 Batch 3650 Training err. 1.36930 Training err. RA 1.52930 Valid. err. 2.63213 Time elapsed: 00:00:13
2018-02-08 13:53:58,028 training [INFO ] Epoch  7 Batch 3700 Training err. 1.38979 Training err. RA 1.52742 Valid. err. 2.68559 Time elapsed: 00:00:13
2018-02-08 13:53:58,187 training [INFO ] Epoch  7 Batch 3750 Training err. 1.34590 Training err. RA 1.52500 Valid. err. 2.63984 Time elapsed: 00:00:13
2018-02-08 13:53:58,360 training [INFO ] Epoch  7 Batch 3800 Training err. 1.38028 Training err. RA 1.52309 Valid. err. 2.64067 Time elapsed: 00:00:13
2018-02-08 13:53:58,516 training [INFO ] Epoch  7 Batch 3850 Training err. 1.31431 Training err. RA 1.52038 Valid. err. 2.68959 Time elapsed: 00:00:13
2018-02-08 13:53:58,690 training [INFO ] Epoch  7 Batch 3900 Training err. 1.30702 Training err. RA 1.51764 Valid. err. 2.60674 Time elapsed: 00:00:13
2018-02-08 13:53:58,848 training [INFO ] Epoch  7 Batch 3950 Training err. 1.30575 Training err. RA 1.51496 Valid. err. 2.59446 Time elapsed: 00:00:14
2018-02-08 13:53:59,026 training [INFO ] Epoch  7 Batch 4000 Training err. 1.28118 Training err. RA 1.51204 Valid. err. 2.59071 Time elapsed: 00:00:14
2018-02-08 13:53:59,188 training [INFO ] Epoch  7 Batch 4050 Training err. 1.35842 Training err. RA 1.51014 Valid. err. 2.57302 Time elapsed: 00:00:14
2018-02-08 13:53:59,365 training [INFO ] Epoch  7 Batch 4100 Training err. 1.32715 Training err. RA 1.50791 Valid. err. 2.56619 Time elapsed: 00:00:14
2018-02-08 13:53:59,524 training [INFO ] Epoch  7 Batch 4150 Training err. 1.27114 Training err. RA 1.50506 Valid. err. 2.58794 Time elapsed: 00:00:14
2018-02-08 13:53:59,696 training [INFO ] Epoch  7 Batch 4200 Training err. 1.28438 Training err. RA 1.50243 Valid. err. 2.56032 Time elapsed: 00:00:14
2018-02-08 13:53:59,854 training [INFO ] Epoch  7 Batch 4250 Training err. 1.32069 Training err. RA 1.50029 Valid. err. 2.55737 Time elapsed: 00:00:15
2018-02-08 13:54:00,338 training [INFO ] Epoch  8 Batch 4300 Training err. 1.31887 Training err. RA 1.49818 Valid. err. 2.56067 Time elapsed: 00:00:15
2018-02-08 13:54:00,496 training [INFO ] Epoch  8 Batch 4350 Training err. 1.34963 Training err. RA 1.49648 Valid. err. 2.65297 Time elapsed: 00:00:15
2018-02-08 13:54:00,670 training [INFO ] Epoch  8 Batch 4400 Training err. 1.34796 Training err. RA 1.49479 Valid. err. 2.55219 Time elapsed: 00:00:15
2018-02-08 13:54:00,837 training [INFO ] Epoch  8 Batch 4450 Training err. 1.29144 Training err. RA 1.49250 Valid. err. 2.56394 Time elapsed: 00:00:16
2018-02-08 13:54:01,012 training [INFO ] Epoch  8 Batch 4500 Training err. 1.28650 Training err. RA 1.49021 Valid. err. 2.54372 Time elapsed: 00:00:16
2018-02-08 13:54:01,179 training [INFO ] Epoch  8 Batch 4550 Training err. 1.27181 Training err. RA 1.48781 Valid. err. 2.56475 Time elapsed: 00:00:16
2018-02-08 13:54:01,346 training [INFO ] Epoch  8 Batch 4600 Training err. 1.26592 Training err. RA 1.48540 Valid. err. 2.54261 Time elapsed: 00:00:16
2018-02-08 13:54:01,509 training [INFO ] Epoch  8 Batch 4650 Training err. 1.29047 Training err. RA 1.48331 Valid. err. 2.51766 Time elapsed: 00:00:16
2018-02-08 13:54:01,678 training [INFO ] Epoch  8 Batch 4700 Training err. 1.30612 Training err. RA 1.48142 Valid. err. 2.54555 Time elapsed: 00:00:16
2018-02-08 13:54:01,840 training [INFO ] Epoch  8 Batch 4750 Training err. 1.27565 Training err. RA 1.47926 Valid. err. 2.52684 Time elapsed: 00:00:17
2018-02-08 13:54:02,014 training [INFO ] Epoch  8 Batch 4800 Training err. 1.21269 Training err. RA 1.47648 Valid. err. 2.50508 Time elapsed: 00:00:17
2018-02-08 13:54:02,182 training [INFO ] Epoch  8 Batch 4850 Training err. 1.27427 Training err. RA 1.47439 Valid. err. 2.51909 Time elapsed: 00:00:17
2018-02-08 13:54:02,346 training [INFO ] Epoch  8 Batch 4900 Training err. 1.30061 Training err. RA 1.47262 Valid. err. 2.52471 Time elapsed: 00:00:17
2018-02-08 13:54:02,637 training [INFO ] Epoch  9 Batch 4950 Training err. 1.33361 Training err. RA 1.47122 Valid. err. 2.50367 Time elapsed: 00:00:17
2018-02-08 13:54:02,800 training [INFO ] Epoch  9 Batch 5000 Training err. 1.28440 Training err. RA 1.46935 Valid. err. 2.51366 Time elapsed: 00:00:18
2018-02-08 13:54:02,971 training [INFO ] Epoch  9 Batch 5050 Training err. 1.31646 Training err. RA 1.46784 Valid. err. 2.61335 Time elapsed: 00:00:18
2018-02-08 13:54:03,135 training [INFO ] Epoch  9 Batch 5100 Training err. 1.25882 Training err. RA 1.46579 Valid. err. 2.49367 Time elapsed: 00:00:18
2018-02-08 13:54:03,301 training [INFO ] Epoch  9 Batch 5150 Training err. 1.21691 Training err. RA 1.46337 Valid. err. 2.49821 Time elapsed: 00:00:18
2018-02-08 13:54:03,462 training [INFO ] Epoch  9 Batch 5200 Training err. 1.27339 Training err. RA 1.46154 Valid. err. 2.47283 Time elapsed: 00:00:18
2018-02-08 13:54:03,634 training [INFO ] Epoch  9 Batch 5250 Training err. 1.24354 Training err. RA 1.45947 Valid. err. 2.48703 Time elapsed: 00:00:18
2018-02-08 13:54:03,790 training [INFO ] Epoch  9 Batch 5300 Training err. 1.30444 Training err. RA 1.45800 Valid. err. 2.50446 Time elapsed: 00:00:19
2018-02-08 13:54:03,973 training [INFO ] Epoch  9 Batch 5350 Training err. 1.23461 Training err. RA 1.45592 Valid. err. 2.48248 Time elapsed: 00:00:19
2018-02-08 13:54:04,135 training [INFO ] Epoch  9 Batch 5400 Training err. 1.21128 Training err. RA 1.45365 Valid. err. 2.49034 Time elapsed: 00:00:19
2018-02-08 13:54:04,307 training [INFO ] Epoch  9 Batch 5450 Training err. 1.22888 Training err. RA 1.45159 Valid. err. 2.47550 Time elapsed: 00:00:19
2018-02-08 13:54:04,469 training [INFO ] Epoch  9 Batch 5500 Training err. 1.26803 Training err. RA 1.44992 Valid. err. 2.45416 Time elapsed: 00:00:19
2018-02-08 13:54:04,737 training [INFO ] Epoch 10 Batch 5550 Training err. 1.30293 Training err. RA 1.44860 Valid. err. 2.47015 Time elapsed: 00:00:20
2018-02-08 13:54:04,902 training [INFO ] Epoch 10 Batch 5600 Training err. 1.25158 Training err. RA 1.44684 Valid. err. 2.50228 Time elapsed: 00:00:20
2018-02-08 13:54:05,073 training [INFO ] Epoch 10 Batch 5650 Training err. 1.31027 Training err. RA 1.44563 Valid. err. 2.47648 Time elapsed: 00:00:20
2018-02-08 13:54:05,242 training [INFO ] Epoch 10 Batch 5700 Training err. 1.24940 Training err. RA 1.44391 Valid. err. 2.46505 Time elapsed: 00:00:20
2018-02-08 13:54:05,406 training [INFO ] Epoch 10 Batch 5750 Training err. 1.20679 Training err. RA 1.44185 Valid. err. 2.43770 Time elapsed: 00:00:20
2018-02-08 13:54:05,569 training [INFO ] Epoch 10 Batch 5800 Training err. 1.23915 Training err. RA 1.44010 Valid. err. 2.42223 Time elapsed: 00:00:20
2018-02-08 13:54:05,742 training [INFO ] Epoch 10 Batch 5850 Training err. 1.21301 Training err. RA 1.43816 Valid. err. 2.45252 Time elapsed: 00:00:21
2018-02-08 13:54:05,904 training [INFO ] Epoch 10 Batch 5900 Training err. 1.28531 Training err. RA 1.43686 Valid. err. 2.47980 Time elapsed: 00:00:21
2018-02-08 13:54:06,076 training [INFO ] Epoch 10 Batch 5950 Training err. 1.23999 Training err. RA 1.43521 Valid. err. 2.41830 Time elapsed: 00:00:21
2018-02-08 13:54:06,247 training [INFO ] Epoch 10 Batch 6000 Training err. 1.18703 Training err. RA 1.43314 Valid. err. 2.41264 Time elapsed: 00:00:21
2018-02-08 13:54:06,416 training [INFO ] Epoch 10 Batch 6050 Training err. 1.20575 Training err. RA 1.43126 Valid. err. 2.43735 Time elapsed: 00:00:21
2018-02-08 13:54:06,579 training [INFO ] Epoch 10 Batch 6100 Training err. 1.23568 Training err. RA 1.42966 Valid. err. 2.42371 Time elapsed: 00:00:21
2018-02-08 13:54:06,748 __main__ [INFO ] End of training
2018-02-08 13:54:07,129 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:54:07,130 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:54:07,301 training [INFO ] Epoch  1 Batch   50 Training err. 2.10471 Training err. RA 2.10471 Valid. err. 3.95759 Time elapsed: 00:00:00
2018-02-08 13:54:07,504 training [INFO ] Epoch  1 Batch  100 Training err. 1.87605 Training err. RA 1.99038 Valid. err. 3.46427 Time elapsed: 00:00:00
2018-02-08 13:54:07,674 training [INFO ] Epoch  1 Batch  150 Training err. 1.71137 Training err. RA 1.89738 Valid. err. 3.33957 Time elapsed: 00:00:00
2018-02-08 13:54:07,852 training [INFO ] Epoch  1 Batch  200 Training err. 1.65368 Training err. RA 1.83645 Valid. err. 3.29647 Time elapsed: 00:00:00
2018-02-08 13:54:08,034 training [INFO ] Epoch  1 Batch  250 Training err. 1.64500 Training err. RA 1.79816 Valid. err. 3.25603 Time elapsed: 00:00:00
2018-02-08 13:54:08,211 training [INFO ] Epoch  1 Batch  300 Training err. 1.62367 Training err. RA 1.76908 Valid. err. 3.24654 Time elapsed: 00:00:01
2018-02-08 13:54:08,383 training [INFO ] Epoch  1 Batch  350 Training err. 1.62564 Training err. RA 1.74859 Valid. err. 3.24587 Time elapsed: 00:00:01
2018-02-08 13:54:08,557 training [INFO ] Epoch  1 Batch  400 Training err. 1.63033 Training err. RA 1.73381 Valid. err. 3.23161 Time elapsed: 00:00:01
2018-02-08 13:54:08,827 training [INFO ] Epoch  2 Batch  450 Training err. 1.63652 Training err. RA 1.72300 Valid. err. 3.24918 Time elapsed: 00:00:01
2018-02-08 13:54:09,004 training [INFO ] Epoch  2 Batch  500 Training err. 1.61702 Training err. RA 1.71240 Valid. err. 3.25560 Time elapsed: 00:00:01
2018-02-08 13:54:09,177 training [INFO ] Epoch  2 Batch  550 Training err. 1.61478 Training err. RA 1.70353 Valid. err. 3.24043 Time elapsed: 00:00:02
2018-02-08 13:54:09,343 training [INFO ] Epoch  2 Batch  600 Training err. 1.60146 Training err. RA 1.69502 Valid. err. 3.21995 Time elapsed: 00:00:02
2018-02-08 13:54:09,514 training [INFO ] Epoch  2 Batch  650 Training err. 1.60614 Training err. RA 1.68818 Valid. err. 3.21926 Time elapsed: 00:00:02
2018-02-08 13:54:09,687 training [INFO ] Epoch  2 Batch  700 Training err. 1.60705 Training err. RA 1.68239 Valid. err. 3.22442 Time elapsed: 00:00:02
2018-02-08 13:54:09,853 training [INFO ] Epoch  2 Batch  750 Training err. 1.60348 Training err. RA 1.67713 Valid. err. 3.21376 Time elapsed: 00:00:02
2018-02-08 13:54:10,031 training [INFO ] Epoch  2 Batch  800 Training err. 1.61536 Training err. RA 1.67327 Valid. err. 3.19851 Time elapsed: 00:00:02
2018-02-08 13:54:10,298 training [INFO ] Epoch  3 Batch  850 Training err. 1.62027 Training err. RA 1.67015 Valid. err. 3.23147 Time elapsed: 00:00:03
2018-02-08 13:54:10,459 training [INFO ] Epoch  3 Batch  900 Training err. 1.61205 Training err. RA 1.66692 Valid. err. 3.21225 Time elapsed: 00:00:03
2018-02-08 13:54:10,640 training [INFO ] Epoch  3 Batch  950 Training err. 1.58351 Training err. RA 1.66253 Valid. err. 3.22185 Time elapsed: 00:00:03
2018-02-08 13:54:10,810 training [INFO ] Epoch  3 Batch 1000 Training err. 1.58722 Training err. RA 1.65877 Valid. err. 3.19222 Time elapsed: 00:00:03
2018-02-08 13:54:10,997 training [INFO ] Epoch  3 Batch 1050 Training err. 1.59174 Training err. RA 1.65557 Valid. err. 3.19267 Time elapsed: 00:00:03
2018-02-08 13:54:11,164 training [INFO ] Epoch  3 Batch 1100 Training err. 1.59900 Training err. RA 1.65300 Valid. err. 3.19414 Time elapsed: 00:00:04
2018-02-08 13:54:11,341 training [INFO ] Epoch  3 Batch 1150 Training err. 1.56755 Training err. RA 1.64929 Valid. err. 3.18949 Time elapsed: 00:00:04
2018-02-08 13:54:11,509 training [INFO ] Epoch  3 Batch 1200 Training err. 1.60525 Training err. RA 1.64745 Valid. err. 3.15527 Time elapsed: 00:00:04
2018-02-08 13:54:11,772 training [INFO ] Epoch  4 Batch 1250 Training err. 1.59618 Training err. RA 1.64540 Valid. err. 3.14577 Time elapsed: 00:00:04
2018-02-08 13:54:11,943 training [INFO ] Epoch  4 Batch 1300 Training err. 1.58283 Training err. RA 1.64299 Valid. err. 3.14334 Time elapsed: 00:00:04
2018-02-08 13:54:12,123 training [INFO ] Epoch  4 Batch 1350 Training err. 1.54088 Training err. RA 1.63921 Valid. err. 3.13543 Time elapsed: 00:00:04
2018-02-08 13:54:12,286 training [INFO ] Epoch  4 Batch 1400 Training err. 1.55146 Training err. RA 1.63608 Valid. err. 3.09689 Time elapsed: 00:00:05
2018-02-08 13:54:12,465 training [INFO ] Epoch  4 Batch 1450 Training err. 1.53671 Training err. RA 1.63265 Valid. err. 3.09587 Time elapsed: 00:00:05
2018-02-08 13:54:12,627 training [INFO ] Epoch  4 Batch 1500 Training err. 1.54585 Training err. RA 1.62976 Valid. err. 3.06291 Time elapsed: 00:00:05
2018-02-08 13:54:12,803 training [INFO ] Epoch  4 Batch 1550 Training err. 1.50729 Training err. RA 1.62581 Valid. err. 3.05392 Time elapsed: 00:00:05
2018-02-08 13:54:12,983 training [INFO ] Epoch  4 Batch 1600 Training err. 1.52966 Training err. RA 1.62280 Valid. err. 3.04657 Time elapsed: 00:00:05
2018-02-08 13:54:13,244 training [INFO ] Epoch  5 Batch 1650 Training err. 1.55464 Training err. RA 1.62074 Valid. err. 2.99306 Time elapsed: 00:00:06
2018-02-08 13:54:13,417 training [INFO ] Epoch  5 Batch 1700 Training err. 1.49842 Training err. RA 1.61714 Valid. err. 2.99659 Time elapsed: 00:00:06
2018-02-08 13:54:13,588 training [INFO ] Epoch  5 Batch 1750 Training err. 1.49872 Training err. RA 1.61376 Valid. err. 2.98142 Time elapsed: 00:00:06
2018-02-08 13:54:13,758 training [INFO ] Epoch  5 Batch 1800 Training err. 1.46304 Training err. RA 1.60957 Valid. err. 2.94522 Time elapsed: 00:00:06
2018-02-08 13:54:13,951 training [INFO ] Epoch  5 Batch 1850 Training err. 1.44592 Training err. RA 1.60515 Valid. err. 2.91632 Time elapsed: 00:00:06
2018-02-08 13:54:14,114 training [INFO ] Epoch  5 Batch 1900 Training err. 1.48740 Training err. RA 1.60205 Valid. err. 2.91316 Time elapsed: 00:00:06
2018-02-08 13:54:14,296 training [INFO ] Epoch  5 Batch 1950 Training err. 1.42520 Training err. RA 1.59751 Valid. err. 2.89091 Time elapsed: 00:00:07
2018-02-08 13:54:14,461 training [INFO ] Epoch  5 Batch 2000 Training err. 1.45432 Training err. RA 1.59393 Valid. err. 2.86280 Time elapsed: 00:00:07
2018-02-08 13:54:14,638 training [INFO ] Epoch  5 Batch 2050 Training err. 1.46535 Training err. RA 1.59080 Valid. err. 2.86183 Time elapsed: 00:00:07
2018-02-08 13:54:14,919 training [INFO ] Epoch  6 Batch 2100 Training err. 1.46396 Training err. RA 1.58778 Valid. err. 2.84280 Time elapsed: 00:00:07
2018-02-08 13:54:15,087 training [INFO ] Epoch  6 Batch 2150 Training err. 1.46210 Training err. RA 1.58486 Valid. err. 2.83211 Time elapsed: 00:00:07
2018-02-08 13:54:15,267 training [INFO ] Epoch  6 Batch 2200 Training err. 1.40946 Training err. RA 1.58087 Valid. err. 2.83189 Time elapsed: 00:00:08
2018-02-08 13:54:15,432 training [INFO ] Epoch  6 Batch 2250 Training err. 1.40233 Training err. RA 1.57690 Valid. err. 2.81882 Time elapsed: 00:00:08
2018-02-08 13:54:15,610 training [INFO ] Epoch  6 Batch 2300 Training err. 1.42677 Training err. RA 1.57364 Valid. err. 2.79068 Time elapsed: 00:00:08
2018-02-08 13:54:15,775 training [INFO ] Epoch  6 Batch 2350 Training err. 1.40417 Training err. RA 1.57003 Valid. err. 2.78728 Time elapsed: 00:00:08
2018-02-08 13:54:15,964 training [INFO ] Epoch  6 Batch 2400 Training err. 1.39611 Training err. RA 1.56641 Valid. err. 2.77890 Time elapsed: 00:00:08
2018-02-08 13:54:16,135 training [INFO ] Epoch  6 Batch 2450 Training err. 1.42357 Training err. RA 1.56349 Valid. err. 2.76651 Time elapsed: 00:00:09
2018-02-08 13:54:16,396 training [INFO ] Epoch  7 Batch 2500 Training err. 1.44809 Training err. RA 1.56119 Valid. err. 2.86147 Time elapsed: 00:00:09
2018-02-08 13:54:16,562 training [INFO ] Epoch  7 Batch 2550 Training err. 1.42100 Training err. RA 1.55844 Valid. err. 2.82976 Time elapsed: 00:00:09
2018-02-08 13:54:16,739 training [INFO ] Epoch  7 Batch 2600 Training err. 1.38223 Training err. RA 1.55505 Valid. err. 2.75630 Time elapsed: 00:00:09
2018-02-08 13:54:16,910 training [INFO ] Epoch  7 Batch 2650 Training err. 1.36536 Training err. RA 1.55147 Valid. err. 2.75520 Time elapsed: 00:00:09
2018-02-08 13:54:17,090 training [INFO ] Epoch  7 Batch 2700 Training err. 1.38210 Training err. RA 1.54833 Valid. err. 2.72745 Time elapsed: 00:00:09
2018-02-08 13:54:17,253 training [INFO ] Epoch  7 Batch 2750 Training err. 1.38614 Training err. RA 1.54538 Valid. err. 2.75094 Time elapsed: 00:00:10
2018-02-08 13:54:17,431 training [INFO ] Epoch  7 Batch 2800 Training err. 1.35457 Training err. RA 1.54198 Valid. err. 2.71862 Time elapsed: 00:00:10
2018-02-08 13:54:17,593 training [INFO ] Epoch  7 Batch 2850 Training err. 1.39653 Training err. RA 1.53942 Valid. err. 2.79963 Time elapsed: 00:00:10
2018-02-08 13:54:17,860 training [INFO ] Epoch  8 Batch 2900 Training err. 1.41098 Training err. RA 1.53721 Valid. err. 2.80246 Time elapsed: 00:00:10
2018-02-08 13:54:18,031 training [INFO ] Epoch  8 Batch 2950 Training err. 1.40078 Training err. RA 1.53490 Valid. err. 2.69914 Time elapsed: 00:00:10
2018-02-08 13:54:18,203 training [INFO ] Epoch  8 Batch 3000 Training err. 1.34751 Training err. RA 1.53177 Valid. err. 2.70145 Time elapsed: 00:00:11
2018-02-08 13:54:18,372 training [INFO ] Epoch  8 Batch 3050 Training err. 1.33677 Training err. RA 1.52858 Valid. err. 2.67870 Time elapsed: 00:00:11
2018-02-08 13:54:18,541 training [INFO ] Epoch  8 Batch 3100 Training err. 1.35214 Training err. RA 1.52573 Valid. err. 2.66846 Time elapsed: 00:00:11
2018-02-08 13:54:18,706 training [INFO ] Epoch  8 Batch 3150 Training err. 1.37011 Training err. RA 1.52326 Valid. err. 2.69898 Time elapsed: 00:00:11
2018-02-08 13:54:18,885 training [INFO ] Epoch  8 Batch 3200 Training err. 1.30859 Training err. RA 1.51991 Valid. err. 2.69465 Time elapsed: 00:00:11
2018-02-08 13:54:19,056 training [INFO ] Epoch  8 Batch 3250 Training err. 1.36789 Training err. RA 1.51757 Valid. err. 2.65693 Time elapsed: 00:00:11
2018-02-08 13:54:19,315 training [INFO ] Epoch  9 Batch 3300 Training err. 1.37989 Training err. RA 1.51548 Valid. err. 2.64830 Time elapsed: 00:00:12
2018-02-08 13:54:19,477 training [INFO ] Epoch  9 Batch 3350 Training err. 1.37471 Training err. RA 1.51338 Valid. err. 2.66282 Time elapsed: 00:00:12
2018-02-08 13:54:19,646 training [INFO ] Epoch  9 Batch 3400 Training err. 1.32324 Training err. RA 1.51059 Valid. err. 2.66407 Time elapsed: 00:00:12
2018-02-08 13:54:19,803 training [INFO ] Epoch  9 Batch 3450 Training err. 1.31073 Training err. RA 1.50769 Valid. err. 2.63068 Time elapsed: 00:00:12
2018-02-08 13:54:19,992 training [INFO ] Epoch  9 Batch 3500 Training err. 1.31413 Training err. RA 1.50492 Valid. err. 2.66122 Time elapsed: 00:00:12
2018-02-08 13:54:20,156 training [INFO ] Epoch  9 Batch 3550 Training err. 1.34772 Training err. RA 1.50271 Valid. err. 2.61635 Time elapsed: 00:00:13
2018-02-08 13:54:20,334 training [INFO ] Epoch  9 Batch 3600 Training err. 1.29017 Training err. RA 1.49976 Valid. err. 2.62795 Time elapsed: 00:00:13
2018-02-08 13:54:20,504 training [INFO ] Epoch  9 Batch 3650 Training err. 1.32186 Training err. RA 1.49732 Valid. err. 2.60490 Time elapsed: 00:00:13
2018-02-08 13:54:20,764 training [INFO ] Epoch 10 Batch 3700 Training err. 1.36579 Training err. RA 1.49554 Valid. err. 2.61330 Time elapsed: 00:00:13
2018-02-08 13:54:20,933 training [INFO ] Epoch 10 Batch 3750 Training err. 1.33523 Training err. RA 1.49341 Valid. err. 2.60195 Time elapsed: 00:00:13
2018-02-08 13:54:21,117 training [INFO ] Epoch 10 Batch 3800 Training err. 1.32962 Training err. RA 1.49125 Valid. err. 2.65686 Time elapsed: 00:00:13
2018-02-08 13:54:21,279 training [INFO ] Epoch 10 Batch 3850 Training err. 1.28053 Training err. RA 1.48851 Valid. err. 2.58844 Time elapsed: 00:00:14
2018-02-08 13:54:21,459 training [INFO ] Epoch 10 Batch 3900 Training err. 1.29120 Training err. RA 1.48598 Valid. err. 2.57968 Time elapsed: 00:00:14
2018-02-08 13:54:21,623 training [INFO ] Epoch 10 Batch 3950 Training err. 1.34350 Training err. RA 1.48418 Valid. err. 2.57298 Time elapsed: 00:00:14
2018-02-08 13:54:21,806 training [INFO ] Epoch 10 Batch 4000 Training err. 1.26884 Training err. RA 1.48149 Valid. err. 2.56748 Time elapsed: 00:00:14
2018-02-08 13:54:21,978 training [INFO ] Epoch 10 Batch 4050 Training err. 1.28733 Training err. RA 1.47909 Valid. err. 2.55265 Time elapsed: 00:00:14
2018-02-08 13:54:22,148 training [INFO ] Epoch 10 Batch 4100 Training err. 1.30747 Training err. RA 1.47700 Valid. err. 2.56971 Time elapsed: 00:00:15
2018-02-08 13:54:22,225 __main__ [INFO ] End of training
2018-02-08 13:54:22,376 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:54:22,377 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:54:22,554 training [INFO ] Epoch  1 Batch   50 Training err. 2.16901 Training err. RA 2.16901 Valid. err. 4.24334 Time elapsed: 00:00:00
2018-02-08 13:54:22,756 training [INFO ] Epoch  1 Batch  100 Training err. 2.08954 Training err. RA 2.12928 Valid. err. 4.06462 Time elapsed: 00:00:00
2018-02-08 13:54:22,931 training [INFO ] Epoch  1 Batch  150 Training err. 1.99240 Training err. RA 2.08365 Valid. err. 3.84774 Time elapsed: 00:00:00
2018-02-08 13:54:23,117 training [INFO ] Epoch  1 Batch  200 Training err. 1.91918 Training err. RA 2.04253 Valid. err. 3.64950 Time elapsed: 00:00:00
2018-02-08 13:54:23,290 training [INFO ] Epoch  1 Batch  250 Training err. 1.82671 Training err. RA 1.99937 Valid. err. 3.50109 Time elapsed: 00:00:00
2018-02-08 13:54:23,465 training [INFO ] Epoch  1 Batch  300 Training err. 1.75542 Training err. RA 1.95871 Valid. err. 3.41832 Time elapsed: 00:00:01
2018-02-08 13:54:23,643 training [INFO ] Epoch  1 Batch  350 Training err. 1.71683 Training err. RA 1.92416 Valid. err. 3.37016 Time elapsed: 00:00:01
2018-02-08 13:54:23,820 training [INFO ] Epoch  1 Batch  400 Training err. 1.70893 Training err. RA 1.89725 Valid. err. 3.34401 Time elapsed: 00:00:01
2018-02-08 13:54:24,001 training [INFO ] Epoch  1 Batch  450 Training err. 1.68766 Training err. RA 1.87396 Valid. err. 3.32650 Time elapsed: 00:00:01
2018-02-08 13:54:24,180 training [INFO ] Epoch  1 Batch  500 Training err. 1.66182 Training err. RA 1.85275 Valid. err. 3.31229 Time elapsed: 00:00:01
2018-02-08 13:54:24,353 training [INFO ] Epoch  1 Batch  550 Training err. 1.67806 Training err. RA 1.83687 Valid. err. 3.28834 Time elapsed: 00:00:01
2018-02-08 13:54:24,535 training [INFO ] Epoch  1 Batch  600 Training err. 1.65795 Training err. RA 1.82196 Valid. err. 3.28601 Time elapsed: 00:00:02
2018-02-08 13:54:24,807 training [INFO ] Epoch  2 Batch  650 Training err. 1.65973 Training err. RA 1.80948 Valid. err. 3.27070 Time elapsed: 00:00:02
2018-02-08 13:54:24,988 training [INFO ] Epoch  2 Batch  700 Training err. 1.64107 Training err. RA 1.79745 Valid. err. 3.26790 Time elapsed: 00:00:02
2018-02-08 13:54:25,173 training [INFO ] Epoch  2 Batch  750 Training err. 1.65070 Training err. RA 1.78767 Valid. err. 3.26279 Time elapsed: 00:00:02
2018-02-08 13:54:25,342 training [INFO ] Epoch  2 Batch  800 Training err. 1.64347 Training err. RA 1.77866 Valid. err. 3.25268 Time elapsed: 00:00:02
2018-02-08 13:54:25,525 training [INFO ] Epoch  2 Batch  850 Training err. 1.63494 Training err. RA 1.77020 Valid. err. 3.25360 Time elapsed: 00:00:03
2018-02-08 13:54:25,697 training [INFO ] Epoch  2 Batch  900 Training err. 1.60900 Training err. RA 1.76125 Valid. err. 3.25877 Time elapsed: 00:00:03
2018-02-08 13:54:25,882 training [INFO ] Epoch  2 Batch  950 Training err. 1.60169 Training err. RA 1.75285 Valid. err. 3.25058 Time elapsed: 00:00:03
2018-02-08 13:54:26,061 training [INFO ] Epoch  2 Batch 1000 Training err. 1.62059 Training err. RA 1.74624 Valid. err. 3.25952 Time elapsed: 00:00:03
2018-02-08 13:54:26,241 training [INFO ] Epoch  2 Batch 1050 Training err. 1.65260 Training err. RA 1.74178 Valid. err. 3.24246 Time elapsed: 00:00:03
2018-02-08 13:54:26,416 training [INFO ] Epoch  2 Batch 1100 Training err. 1.61302 Training err. RA 1.73592 Valid. err. 3.24217 Time elapsed: 00:00:04
2018-02-08 13:54:26,624 training [INFO ] Epoch  2 Batch 1150 Training err. 1.63061 Training err. RA 1.73135 Valid. err. 3.23326 Time elapsed: 00:00:04
2018-02-08 13:54:26,801 training [INFO ] Epoch  2 Batch 1200 Training err. 1.61409 Training err. RA 1.72646 Valid. err. 3.22871 Time elapsed: 00:00:04
2018-02-08 13:54:27,080 training [INFO ] Epoch  3 Batch 1250 Training err. 1.62091 Training err. RA 1.72224 Valid. err. 3.22963 Time elapsed: 00:00:04
2018-02-08 13:54:27,252 training [INFO ] Epoch  3 Batch 1300 Training err. 1.63580 Training err. RA 1.71891 Valid. err. 3.23828 Time elapsed: 00:00:04
2018-02-08 13:54:27,432 training [INFO ] Epoch  3 Batch 1350 Training err. 1.61708 Training err. RA 1.71514 Valid. err. 3.22904 Time elapsed: 00:00:05
2018-02-08 13:54:27,607 training [INFO ] Epoch  3 Batch 1400 Training err. 1.59484 Training err. RA 1.71085 Valid. err. 3.23341 Time elapsed: 00:00:05
2018-02-08 13:54:27,789 training [INFO ] Epoch  3 Batch 1450 Training err. 1.64218 Training err. RA 1.70848 Valid. err. 3.22925 Time elapsed: 00:00:05
2018-02-08 13:54:27,974 training [INFO ] Epoch  3 Batch 1500 Training err. 1.58417 Training err. RA 1.70433 Valid. err. 3.23908 Time elapsed: 00:00:05
2018-02-08 13:54:28,154 training [INFO ] Epoch  3 Batch 1550 Training err. 1.58236 Training err. RA 1.70040 Valid. err. 3.22830 Time elapsed: 00:00:05
2018-02-08 13:54:28,329 training [INFO ] Epoch  3 Batch 1600 Training err. 1.61079 Training err. RA 1.69760 Valid. err. 3.23332 Time elapsed: 00:00:05
2018-02-08 13:54:28,509 training [INFO ] Epoch  3 Batch 1650 Training err. 1.63984 Training err. RA 1.69585 Valid. err. 3.22151 Time elapsed: 00:00:06
2018-02-08 13:54:28,692 training [INFO ] Epoch  3 Batch 1700 Training err. 1.59734 Training err. RA 1.69295 Valid. err. 3.21940 Time elapsed: 00:00:06
2018-02-08 13:54:28,871 training [INFO ] Epoch  3 Batch 1750 Training err. 1.61528 Training err. RA 1.69073 Valid. err. 3.21333 Time elapsed: 00:00:06
2018-02-08 13:54:29,056 training [INFO ] Epoch  3 Batch 1800 Training err. 1.59839 Training err. RA 1.68817 Valid. err. 3.20888 Time elapsed: 00:00:06
2018-02-08 13:54:29,332 training [INFO ] Epoch  4 Batch 1850 Training err. 1.59589 Training err. RA 1.68567 Valid. err. 3.21012 Time elapsed: 00:00:06
2018-02-08 13:54:29,501 training [INFO ] Epoch  4 Batch 1900 Training err. 1.62021 Training err. RA 1.68395 Valid. err. 3.21234 Time elapsed: 00:00:07
2018-02-08 13:54:29,686 training [INFO ] Epoch  4 Batch 1950 Training err. 1.60936 Training err. RA 1.68204 Valid. err. 3.21141 Time elapsed: 00:00:07
2018-02-08 13:54:29,860 training [INFO ] Epoch  4 Batch 2000 Training err. 1.57535 Training err. RA 1.67937 Valid. err. 3.21059 Time elapsed: 00:00:07
2018-02-08 13:54:30,045 training [INFO ] Epoch  4 Batch 2050 Training err. 1.64270 Training err. RA 1.67848 Valid. err. 3.19826 Time elapsed: 00:00:07
2018-02-08 13:54:30,225 training [INFO ] Epoch  4 Batch 2100 Training err. 1.57556 Training err. RA 1.67603 Valid. err. 3.21412 Time elapsed: 00:00:07
2018-02-08 13:54:30,404 training [INFO ] Epoch  4 Batch 2150 Training err. 1.56964 Training err. RA 1.67355 Valid. err. 3.20431 Time elapsed: 00:00:08
2018-02-08 13:54:30,578 training [INFO ] Epoch  4 Batch 2200 Training err. 1.60333 Training err. RA 1.67196 Valid. err. 3.20294 Time elapsed: 00:00:08
2018-02-08 13:54:30,760 training [INFO ] Epoch  4 Batch 2250 Training err. 1.60425 Training err. RA 1.67045 Valid. err. 3.19372 Time elapsed: 00:00:08
2018-02-08 13:54:30,937 training [INFO ] Epoch  4 Batch 2300 Training err. 1.60119 Training err. RA 1.66895 Valid. err. 3.19380 Time elapsed: 00:00:08
2018-02-08 13:54:31,127 training [INFO ] Epoch  4 Batch 2350 Training err. 1.58020 Training err. RA 1.66706 Valid. err. 3.18830 Time elapsed: 00:00:08
2018-02-08 13:54:31,294 training [INFO ] Epoch  4 Batch 2400 Training err. 1.59399 Training err. RA 1.66553 Valid. err. 3.17725 Time elapsed: 00:00:08
2018-02-08 13:54:31,473 training [INFO ] Epoch  4 Batch 2450 Training err. 1.57796 Training err. RA 1.66375 Valid. err. 3.17891 Time elapsed: 00:00:09
2018-02-08 13:54:31,748 training [INFO ] Epoch  5 Batch 2500 Training err. 1.61490 Training err. RA 1.66277 Valid. err. 3.17121 Time elapsed: 00:00:09
2018-02-08 13:54:31,919 training [INFO ] Epoch  5 Batch 2550 Training err. 1.58391 Training err. RA 1.66122 Valid. err. 3.18816 Time elapsed: 00:00:09
2018-02-08 13:54:32,100 training [INFO ] Epoch  5 Batch 2600 Training err. 1.57364 Training err. RA 1.65954 Valid. err. 3.15994 Time elapsed: 00:00:09
2018-02-08 13:54:32,268 training [INFO ] Epoch  5 Batch 2650 Training err. 1.62075 Training err. RA 1.65881 Valid. err. 3.15811 Time elapsed: 00:00:09
2018-02-08 13:54:32,448 training [INFO ] Epoch  5 Batch 2700 Training err. 1.56006 Training err. RA 1.65698 Valid. err. 3.16299 Time elapsed: 00:00:10
2018-02-08 13:54:32,617 training [INFO ] Epoch  5 Batch 2750 Training err. 1.55512 Training err. RA 1.65513 Valid. err. 3.15440 Time elapsed: 00:00:10
2018-02-08 13:54:32,798 training [INFO ] Epoch  5 Batch 2800 Training err. 1.55211 Training err. RA 1.65329 Valid. err. 3.14833 Time elapsed: 00:00:10
2018-02-08 13:54:32,976 training [INFO ] Epoch  5 Batch 2850 Training err. 1.56831 Training err. RA 1.65180 Valid. err. 3.14184 Time elapsed: 00:00:10
2018-02-08 13:54:33,153 training [INFO ] Epoch  5 Batch 2900 Training err. 1.58885 Training err. RA 1.65071 Valid. err. 3.13574 Time elapsed: 00:00:10
2018-02-08 13:54:33,326 training [INFO ] Epoch  5 Batch 2950 Training err. 1.54801 Training err. RA 1.64897 Valid. err. 3.14150 Time elapsed: 00:00:10
2018-02-08 13:54:33,500 training [INFO ] Epoch  5 Batch 3000 Training err. 1.57118 Training err. RA 1.64767 Valid. err. 3.18210 Time elapsed: 00:00:11
2018-02-08 13:54:33,674 training [INFO ] Epoch  5 Batch 3050 Training err. 1.56957 Training err. RA 1.64639 Valid. err. 3.12853 Time elapsed: 00:00:11
2018-02-08 13:54:33,958 training [INFO ] Epoch  6 Batch 3100 Training err. 1.57402 Training err. RA 1.64523 Valid. err. 3.13419 Time elapsed: 00:00:11
2018-02-08 13:54:34,127 training [INFO ] Epoch  6 Batch 3150 Training err. 1.55809 Training err. RA 1.64384 Valid. err. 3.11110 Time elapsed: 00:00:11
2018-02-08 13:54:34,307 training [INFO ] Epoch  6 Batch 3200 Training err. 1.55929 Training err. RA 1.64252 Valid. err. 3.09792 Time elapsed: 00:00:11
2018-02-08 13:54:34,473 training [INFO ] Epoch  6 Batch 3250 Training err. 1.54944 Training err. RA 1.64109 Valid. err. 3.08439 Time elapsed: 00:00:12
2018-02-08 13:54:34,654 training [INFO ] Epoch  6 Batch 3300 Training err. 1.57778 Training err. RA 1.64013 Valid. err. 3.08272 Time elapsed: 00:00:12
2018-02-08 13:54:34,825 training [INFO ] Epoch  6 Batch 3350 Training err. 1.51154 Training err. RA 1.63821 Valid. err. 3.10557 Time elapsed: 00:00:12
2018-02-08 13:54:35,008 training [INFO ] Epoch  6 Batch 3400 Training err. 1.50522 Training err. RA 1.63626 Valid. err. 3.13963 Time elapsed: 00:00:12
2018-02-08 13:54:35,180 training [INFO ] Epoch  6 Batch 3450 Training err. 1.53778 Training err. RA 1.63483 Valid. err. 3.07483 Time elapsed: 00:00:12
2018-02-08 13:54:35,356 training [INFO ] Epoch  6 Batch 3500 Training err. 1.56252 Training err. RA 1.63380 Valid. err. 3.05680 Time elapsed: 00:00:12
2018-02-08 13:54:35,526 training [INFO ] Epoch  6 Batch 3550 Training err. 1.50821 Training err. RA 1.63203 Valid. err. 3.05165 Time elapsed: 00:00:13
2018-02-08 13:54:35,706 training [INFO ] Epoch  6 Batch 3600 Training err. 1.53885 Training err. RA 1.63073 Valid. err. 3.04974 Time elapsed: 00:00:13
2018-02-08 13:54:35,878 training [INFO ] Epoch  6 Batch 3650 Training err. 1.52093 Training err. RA 1.62923 Valid. err. 3.02828 Time elapsed: 00:00:13
2018-02-08 13:54:36,160 training [INFO ] Epoch  7 Batch 3700 Training err. 1.53049 Training err. RA 1.62789 Valid. err. 3.03044 Time elapsed: 00:00:13
2018-02-08 13:54:36,328 training [INFO ] Epoch  7 Batch 3750 Training err. 1.55006 Training err. RA 1.62686 Valid. err. 3.06236 Time elapsed: 00:00:13
2018-02-08 13:54:36,504 training [INFO ] Epoch  7 Batch 3800 Training err. 1.52038 Training err. RA 1.62546 Valid. err. 3.05141 Time elapsed: 00:00:14
2018-02-08 13:54:36,673 training [INFO ] Epoch  7 Batch 3850 Training err. 1.49776 Training err. RA 1.62380 Valid. err. 3.00513 Time elapsed: 00:00:14
2018-02-08 13:54:36,853 training [INFO ] Epoch  7 Batch 3900 Training err. 1.54942 Training err. RA 1.62284 Valid. err. 3.01460 Time elapsed: 00:00:14
2018-02-08 13:54:37,031 training [INFO ] Epoch  7 Batch 3950 Training err. 1.47719 Training err. RA 1.62100 Valid. err. 3.02330 Time elapsed: 00:00:14
2018-02-08 13:54:37,208 training [INFO ] Epoch  7 Batch 4000 Training err. 1.46507 Training err. RA 1.61905 Valid. err. 2.99114 Time elapsed: 00:00:14
2018-02-08 13:54:37,379 training [INFO ] Epoch  7 Batch 4050 Training err. 1.50354 Training err. RA 1.61762 Valid. err. 3.00995 Time elapsed: 00:00:14
2018-02-08 13:54:37,552 training [INFO ] Epoch  7 Batch 4100 Training err. 1.50988 Training err. RA 1.61631 Valid. err. 2.96921 Time elapsed: 00:00:15
2018-02-08 13:54:37,728 training [INFO ] Epoch  7 Batch 4150 Training err. 1.46994 Training err. RA 1.61455 Valid. err. 2.95189 Time elapsed: 00:00:15
2018-02-08 13:54:37,910 training [INFO ] Epoch  7 Batch 4200 Training err. 1.47796 Training err. RA 1.61292 Valid. err. 2.94399 Time elapsed: 00:00:15
2018-02-08 13:54:38,086 training [INFO ] Epoch  7 Batch 4250 Training err. 1.50449 Training err. RA 1.61165 Valid. err. 2.94324 Time elapsed: 00:00:15
2018-02-08 13:54:38,382 training [INFO ] Epoch  8 Batch 4300 Training err. 1.45967 Training err. RA 1.60988 Valid. err. 2.93127 Time elapsed: 00:00:16
2018-02-08 13:54:38,549 training [INFO ] Epoch  8 Batch 4350 Training err. 1.51833 Training err. RA 1.60883 Valid. err. 2.96369 Time elapsed: 00:00:16
2018-02-08 13:54:38,729 training [INFO ] Epoch  8 Batch 4400 Training err. 1.48074 Training err. RA 1.60737 Valid. err. 2.92496 Time elapsed: 00:00:16
2018-02-08 13:54:38,901 training [INFO ] Epoch  8 Batch 4450 Training err. 1.45845 Training err. RA 1.60570 Valid. err. 2.91752 Time elapsed: 00:00:16
2018-02-08 13:54:39,078 training [INFO ] Epoch  8 Batch 4500 Training err. 1.51852 Training err. RA 1.60473 Valid. err. 2.89804 Time elapsed: 00:00:16
2018-02-08 13:54:39,254 training [INFO ] Epoch  8 Batch 4550 Training err. 1.44122 Training err. RA 1.60293 Valid. err. 2.91889 Time elapsed: 00:00:16
2018-02-08 13:54:39,425 training [INFO ] Epoch  8 Batch 4600 Training err. 1.43257 Training err. RA 1.60108 Valid. err. 2.91394 Time elapsed: 00:00:17
2018-02-08 13:54:39,595 training [INFO ] Epoch  8 Batch 4650 Training err. 1.44307 Training err. RA 1.59938 Valid. err. 2.89542 Time elapsed: 00:00:17
2018-02-08 13:54:39,773 training [INFO ] Epoch  8 Batch 4700 Training err. 1.44413 Training err. RA 1.59773 Valid. err. 2.87316 Time elapsed: 00:00:17
2018-02-08 13:54:39,953 training [INFO ] Epoch  8 Batch 4750 Training err. 1.44031 Training err. RA 1.59607 Valid. err. 2.88412 Time elapsed: 00:00:17
2018-02-08 13:54:40,134 training [INFO ] Epoch  8 Batch 4800 Training err. 1.44607 Training err. RA 1.59451 Valid. err. 2.87338 Time elapsed: 00:00:17
2018-02-08 13:54:40,299 training [INFO ] Epoch  8 Batch 4850 Training err. 1.44556 Training err. RA 1.59297 Valid. err. 2.85170 Time elapsed: 00:00:17
2018-02-08 13:54:40,482 training [INFO ] Epoch  8 Batch 4900 Training err. 1.43531 Training err. RA 1.59137 Valid. err. 2.88748 Time elapsed: 00:00:18
2018-02-08 13:54:40,760 training [INFO ] Epoch  9 Batch 4950 Training err. 1.47559 Training err. RA 1.59020 Valid. err. 2.84012 Time elapsed: 00:00:18
2018-02-08 13:54:40,932 training [INFO ] Epoch  9 Batch 5000 Training err. 1.44779 Training err. RA 1.58877 Valid. err. 2.89288 Time elapsed: 00:00:18
2018-02-08 13:54:41,121 training [INFO ] Epoch  9 Batch 5050 Training err. 1.44476 Training err. RA 1.58735 Valid. err. 2.82704 Time elapsed: 00:00:18
2018-02-08 13:54:41,290 training [INFO ] Epoch  9 Batch 5100 Training err. 1.46781 Training err. RA 1.58617 Valid. err. 2.83631 Time elapsed: 00:00:18
2018-02-08 13:54:41,474 training [INFO ] Epoch  9 Batch 5150 Training err. 1.42672 Training err. RA 1.58463 Valid. err. 2.83634 Time elapsed: 00:00:19
2018-02-08 13:54:41,645 training [INFO ] Epoch  9 Batch 5200 Training err. 1.40706 Training err. RA 1.58292 Valid. err. 2.82341 Time elapsed: 00:00:19
2018-02-08 13:54:41,823 training [INFO ] Epoch  9 Batch 5250 Training err. 1.38396 Training err. RA 1.58102 Valid. err. 2.81140 Time elapsed: 00:00:19
2018-02-08 13:54:42,001 training [INFO ] Epoch  9 Batch 5300 Training err. 1.39389 Training err. RA 1.57926 Valid. err. 2.81727 Time elapsed: 00:00:19
2018-02-08 13:54:42,179 training [INFO ] Epoch  9 Batch 5350 Training err. 1.43241 Training err. RA 1.57789 Valid. err. 2.88159 Time elapsed: 00:00:19
2018-02-08 13:54:42,349 training [INFO ] Epoch  9 Batch 5400 Training err. 1.39209 Training err. RA 1.57617 Valid. err. 2.80821 Time elapsed: 00:00:19
2018-02-08 13:54:42,523 training [INFO ] Epoch  9 Batch 5450 Training err. 1.43179 Training err. RA 1.57484 Valid. err. 2.79996 Time elapsed: 00:00:20
2018-02-08 13:54:42,697 training [INFO ] Epoch  9 Batch 5500 Training err. 1.41870 Training err. RA 1.57342 Valid. err. 2.79273 Time elapsed: 00:00:20
2018-02-08 13:54:42,977 training [INFO ] Epoch 10 Batch 5550 Training err. 1.41717 Training err. RA 1.57201 Valid. err. 2.78250 Time elapsed: 00:00:20
2018-02-08 13:54:43,149 training [INFO ] Epoch 10 Batch 5600 Training err. 1.46020 Training err. RA 1.57102 Valid. err. 2.81096 Time elapsed: 00:00:20
2018-02-08 13:54:43,330 training [INFO ] Epoch 10 Batch 5650 Training err. 1.42388 Training err. RA 1.56971 Valid. err. 2.79953 Time elapsed: 00:00:20
2018-02-08 13:54:43,499 training [INFO ] Epoch 10 Batch 5700 Training err. 1.39495 Training err. RA 1.56818 Valid. err. 2.77850 Time elapsed: 00:00:21
2018-02-08 13:54:43,682 training [INFO ] Epoch 10 Batch 5750 Training err. 1.45427 Training err. RA 1.56719 Valid. err. 2.82686 Time elapsed: 00:00:21
2018-02-08 13:54:43,849 training [INFO ] Epoch 10 Batch 5800 Training err. 1.37980 Training err. RA 1.56557 Valid. err. 2.82231 Time elapsed: 00:00:21
2018-02-08 13:54:44,036 training [INFO ] Epoch 10 Batch 5850 Training err. 1.35554 Training err. RA 1.56378 Valid. err. 2.79819 Time elapsed: 00:00:21
2018-02-08 13:54:44,214 training [INFO ] Epoch 10 Batch 5900 Training err. 1.38943 Training err. RA 1.56230 Valid. err. 2.79668 Time elapsed: 00:00:21
2018-02-08 13:54:44,390 training [INFO ] Epoch 10 Batch 5950 Training err. 1.41024 Training err. RA 1.56102 Valid. err. 2.80399 Time elapsed: 00:00:22
2018-02-08 13:54:44,564 training [INFO ] Epoch 10 Batch 6000 Training err. 1.36585 Training err. RA 1.55940 Valid. err. 2.75452 Time elapsed: 00:00:22
2018-02-08 13:54:44,743 training [INFO ] Epoch 10 Batch 6050 Training err. 1.41058 Training err. RA 1.55817 Valid. err. 2.75452 Time elapsed: 00:00:22
2018-02-08 13:54:44,918 training [INFO ] Epoch 10 Batch 6100 Training err. 1.39396 Training err. RA 1.55682 Valid. err. 2.75667 Time elapsed: 00:00:22
2018-02-08 13:54:45,083 __main__ [INFO ] End of training
2018-02-08 13:57:43,288 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:57:43,290 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:57:43,293 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:57:43,293 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:57:45,940 training [INFO ] Epoch  1 Batch   50 Training err. 2.11362 Training err. RA 2.11362 Valid. err. 4.00094 Time elapsed: 00:00:00
2018-02-08 13:57:46,112 training [INFO ] Epoch  1 Batch  100 Training err. 1.91144 Training err. RA 2.01253 Valid. err. 3.55115 Time elapsed: 00:00:00
2018-02-08 13:57:46,273 training [INFO ] Epoch  1 Batch  150 Training err. 1.73674 Training err. RA 1.92060 Valid. err. 3.36116 Time elapsed: 00:00:00
2018-02-08 13:57:46,435 training [INFO ] Epoch  1 Batch  200 Training err. 1.67917 Training err. RA 1.86024 Valid. err. 3.30641 Time elapsed: 00:00:00
2018-02-08 13:57:46,601 training [INFO ] Epoch  1 Batch  250 Training err. 1.63720 Training err. RA 1.81563 Valid. err. 3.30068 Time elapsed: 00:00:00
2018-02-08 13:57:46,761 training [INFO ] Epoch  1 Batch  300 Training err. 1.64256 Training err. RA 1.78679 Valid. err. 3.28378 Time elapsed: 00:00:01
2018-02-08 13:57:46,931 training [INFO ] Epoch  1 Batch  350 Training err. 1.62248 Training err. RA 1.76332 Valid. err. 3.25254 Time elapsed: 00:00:01
2018-02-08 13:57:47,096 training [INFO ] Epoch  1 Batch  400 Training err. 1.64130 Training err. RA 1.74806 Valid. err. 3.25548 Time elapsed: 00:00:01
2018-02-08 13:57:47,254 training [INFO ] Epoch  1 Batch  450 Training err. 1.61728 Training err. RA 1.73353 Valid. err. 3.23984 Time elapsed: 00:00:01
2018-02-08 13:57:47,414 training [INFO ] Epoch  1 Batch  500 Training err. 1.60216 Training err. RA 1.72040 Valid. err. 3.25863 Time elapsed: 00:00:01
2018-02-08 13:57:47,576 training [INFO ] Epoch  1 Batch  550 Training err. 1.63793 Training err. RA 1.71290 Valid. err. 3.23259 Time elapsed: 00:00:01
2018-02-08 13:57:47,739 training [INFO ] Epoch  1 Batch  600 Training err. 1.63006 Training err. RA 1.70600 Valid. err. 3.22192 Time elapsed: 00:00:02
2018-02-08 13:57:48,008 training [INFO ] Epoch  2 Batch  650 Training err. 1.64705 Training err. RA 1.70146 Valid. err. 3.23225 Time elapsed: 00:00:02
2018-02-08 13:57:48,169 training [INFO ] Epoch  2 Batch  700 Training err. 1.57710 Training err. RA 1.69258 Valid. err. 3.23439 Time elapsed: 00:00:02
2018-02-08 13:57:48,341 training [INFO ] Epoch  2 Batch  750 Training err. 1.63206 Training err. RA 1.68854 Valid. err. 3.25152 Time elapsed: 00:00:02
2018-02-08 13:57:48,502 training [INFO ] Epoch  2 Batch  800 Training err. 1.59249 Training err. RA 1.68254 Valid. err. 3.23943 Time elapsed: 00:00:02
2018-02-08 13:57:48,673 training [INFO ] Epoch  2 Batch  850 Training err. 1.61277 Training err. RA 1.67844 Valid. err. 3.23479 Time elapsed: 00:00:03
2018-02-08 13:57:48,831 training [INFO ] Epoch  2 Batch  900 Training err. 1.60134 Training err. RA 1.67415 Valid. err. 3.20995 Time elapsed: 00:00:03
2018-02-08 13:57:49,011 training [INFO ] Epoch  2 Batch  950 Training err. 1.58780 Training err. RA 1.66961 Valid. err. 3.21113 Time elapsed: 00:00:03
2018-02-08 13:57:49,173 training [INFO ] Epoch  2 Batch 1000 Training err. 1.61641 Training err. RA 1.66695 Valid. err. 3.21657 Time elapsed: 00:00:03
2018-02-08 13:57:49,346 training [INFO ] Epoch  2 Batch 1050 Training err. 1.59584 Training err. RA 1.66356 Valid. err. 3.20323 Time elapsed: 00:00:03
2018-02-08 13:57:49,508 training [INFO ] Epoch  2 Batch 1100 Training err. 1.59110 Training err. RA 1.66027 Valid. err. 3.22027 Time elapsed: 00:00:03
2018-02-08 13:57:49,676 training [INFO ] Epoch  2 Batch 1150 Training err. 1.59443 Training err. RA 1.65741 Valid. err. 3.20265 Time elapsed: 00:00:04
2018-02-08 13:57:49,833 training [INFO ] Epoch  2 Batch 1200 Training err. 1.61223 Training err. RA 1.65552 Valid. err. 3.17120 Time elapsed: 00:00:04
2018-02-08 13:57:50,109 training [INFO ] Epoch  3 Batch 1250 Training err. 1.62804 Training err. RA 1.65442 Valid. err. 3.17410 Time elapsed: 00:00:04
2018-02-08 13:57:50,267 training [INFO ] Epoch  3 Batch 1300 Training err. 1.55222 Training err. RA 1.65049 Valid. err. 3.17567 Time elapsed: 00:00:04
2018-02-08 13:57:50,434 training [INFO ] Epoch  3 Batch 1350 Training err. 1.60779 Training err. RA 1.64891 Valid. err. 3.17380 Time elapsed: 00:00:04
2018-02-08 13:57:50,594 training [INFO ] Epoch  3 Batch 1400 Training err. 1.56157 Training err. RA 1.64579 Valid. err. 3.16705 Time elapsed: 00:00:04
2018-02-08 13:57:50,764 training [INFO ] Epoch  3 Batch 1450 Training err. 1.58014 Training err. RA 1.64353 Valid. err. 3.14218 Time elapsed: 00:00:05
2018-02-08 13:57:50,922 training [INFO ] Epoch  3 Batch 1500 Training err. 1.53958 Training err. RA 1.64006 Valid. err. 3.13095 Time elapsed: 00:00:05
2018-02-08 13:57:51,097 training [INFO ] Epoch  3 Batch 1550 Training err. 1.55133 Training err. RA 1.63720 Valid. err. 3.10486 Time elapsed: 00:00:05
2018-02-08 13:57:51,255 training [INFO ] Epoch  3 Batch 1600 Training err. 1.57867 Training err. RA 1.63537 Valid. err. 3.10230 Time elapsed: 00:00:05
2018-02-08 13:57:51,427 training [INFO ] Epoch  3 Batch 1650 Training err. 1.55547 Training err. RA 1.63295 Valid. err. 3.09827 Time elapsed: 00:00:05
2018-02-08 13:57:51,590 training [INFO ] Epoch  3 Batch 1700 Training err. 1.50713 Training err. RA 1.62925 Valid. err. 3.15857 Time elapsed: 00:00:05
2018-02-08 13:57:51,756 training [INFO ] Epoch  3 Batch 1750 Training err. 1.55501 Training err. RA 1.62713 Valid. err. 3.08427 Time elapsed: 00:00:06
2018-02-08 13:57:51,927 training [INFO ] Epoch  3 Batch 1800 Training err. 1.54588 Training err. RA 1.62487 Valid. err. 3.01704 Time elapsed: 00:00:06
2018-02-08 13:57:52,240 training [INFO ] Epoch  4 Batch 1850 Training err. 1.54541 Training err. RA 1.62272 Valid. err. 3.01177 Time elapsed: 00:00:06
2018-02-08 13:57:52,401 training [INFO ] Epoch  4 Batch 1900 Training err. 1.51565 Training err. RA 1.61991 Valid. err. 3.04370 Time elapsed: 00:00:06
2018-02-08 13:57:52,566 training [INFO ] Epoch  4 Batch 1950 Training err. 1.52701 Training err. RA 1.61752 Valid. err. 2.96407 Time elapsed: 00:00:06
2018-02-08 13:57:52,727 training [INFO ] Epoch  4 Batch 2000 Training err. 1.45410 Training err. RA 1.61344 Valid. err. 2.94927 Time elapsed: 00:00:07
2018-02-08 13:57:52,898 training [INFO ] Epoch  4 Batch 2050 Training err. 1.48613 Training err. RA 1.61033 Valid. err. 2.96175 Time elapsed: 00:00:07
2018-02-08 13:57:53,065 training [INFO ] Epoch  4 Batch 2100 Training err. 1.42346 Training err. RA 1.60588 Valid. err. 2.93244 Time elapsed: 00:00:07
2018-02-08 13:57:53,228 training [INFO ] Epoch  4 Batch 2150 Training err. 1.44450 Training err. RA 1.60213 Valid. err. 2.93736 Time elapsed: 00:00:07
2018-02-08 13:57:53,388 training [INFO ] Epoch  4 Batch 2200 Training err. 1.47142 Training err. RA 1.59916 Valid. err. 2.86908 Time elapsed: 00:00:07
2018-02-08 13:57:53,557 training [INFO ] Epoch  4 Batch 2250 Training err. 1.45306 Training err. RA 1.59591 Valid. err. 2.86861 Time elapsed: 00:00:07
2018-02-08 13:57:53,718 training [INFO ] Epoch  4 Batch 2300 Training err. 1.41756 Training err. RA 1.59204 Valid. err. 2.91210 Time elapsed: 00:00:08
2018-02-08 13:57:53,882 training [INFO ] Epoch  4 Batch 2350 Training err. 1.41909 Training err. RA 1.58836 Valid. err. 2.83691 Time elapsed: 00:00:08
2018-02-08 13:57:54,051 training [INFO ] Epoch  4 Batch 2400 Training err. 1.45490 Training err. RA 1.58558 Valid. err. 2.81623 Time elapsed: 00:00:08
2018-02-08 13:57:54,213 training [INFO ] Epoch  4 Batch 2450 Training err. 1.44387 Training err. RA 1.58268 Valid. err. 2.80002 Time elapsed: 00:00:08
2018-02-08 13:57:54,484 training [INFO ] Epoch  5 Batch 2500 Training err. 1.46707 Training err. RA 1.58037 Valid. err. 2.89939 Time elapsed: 00:00:08
2018-02-08 13:57:54,638 training [INFO ] Epoch  5 Batch 2550 Training err. 1.44734 Training err. RA 1.57776 Valid. err. 2.79672 Time elapsed: 00:00:09
2018-02-08 13:57:54,809 training [INFO ] Epoch  5 Batch 2600 Training err. 1.40001 Training err. RA 1.57435 Valid. err. 2.79327 Time elapsed: 00:00:09
2018-02-08 13:57:54,971 training [INFO ] Epoch  5 Batch 2650 Training err. 1.37801 Training err. RA 1.57064 Valid. err. 2.79244 Time elapsed: 00:00:09
2018-02-08 13:57:55,144 training [INFO ] Epoch  5 Batch 2700 Training err. 1.37025 Training err. RA 1.56693 Valid. err. 2.76817 Time elapsed: 00:00:09
2018-02-08 13:57:55,300 training [INFO ] Epoch  5 Batch 2750 Training err. 1.38783 Training err. RA 1.56367 Valid. err. 2.74548 Time elapsed: 00:00:09
2018-02-08 13:57:55,471 training [INFO ] Epoch  5 Batch 2800 Training err. 1.38144 Training err. RA 1.56042 Valid. err. 2.74438 Time elapsed: 00:00:09
2018-02-08 13:57:55,629 training [INFO ] Epoch  5 Batch 2850 Training err. 1.40921 Training err. RA 1.55777 Valid. err. 2.73010 Time elapsed: 00:00:10
2018-02-08 13:57:55,798 training [INFO ] Epoch  5 Batch 2900 Training err. 1.36234 Training err. RA 1.55440 Valid. err. 2.71670 Time elapsed: 00:00:10
2018-02-08 13:57:55,959 training [INFO ] Epoch  5 Batch 2950 Training err. 1.33842 Training err. RA 1.55074 Valid. err. 2.72274 Time elapsed: 00:00:10
2018-02-08 13:57:56,130 training [INFO ] Epoch  5 Batch 3000 Training err. 1.38843 Training err. RA 1.54803 Valid. err. 2.68584 Time elapsed: 00:00:10
2018-02-08 13:57:56,291 training [INFO ] Epoch  5 Batch 3050 Training err. 1.38568 Training err. RA 1.54537 Valid. err. 2.67672 Time elapsed: 00:00:10
2018-02-08 13:57:56,563 training [INFO ] Epoch  6 Batch 3100 Training err. 1.42204 Training err. RA 1.54338 Valid. err. 2.68487 Time elapsed: 00:00:10
2018-02-08 13:57:56,724 training [INFO ] Epoch  6 Batch 3150 Training err. 1.34692 Training err. RA 1.54026 Valid. err. 2.67991 Time elapsed: 00:00:11
2018-02-08 13:57:56,889 training [INFO ] Epoch  6 Batch 3200 Training err. 1.40169 Training err. RA 1.53810 Valid. err. 2.72029 Time elapsed: 00:00:11
2018-02-08 13:57:57,058 training [INFO ] Epoch  6 Batch 3250 Training err. 1.34224 Training err. RA 1.53508 Valid. err. 2.67132 Time elapsed: 00:00:11
2018-02-08 13:57:57,224 training [INFO ] Epoch  6 Batch 3300 Training err. 1.32647 Training err. RA 1.53192 Valid. err. 2.66946 Time elapsed: 00:00:11
2018-02-08 13:57:57,390 training [INFO ] Epoch  6 Batch 3350 Training err. 1.33425 Training err. RA 1.52897 Valid. err. 2.67493 Time elapsed: 00:00:11
2018-02-08 13:57:57,561 training [INFO ] Epoch  6 Batch 3400 Training err. 1.31202 Training err. RA 1.52578 Valid. err. 2.64352 Time elapsed: 00:00:11
2018-02-08 13:57:57,728 training [INFO ] Epoch  6 Batch 3450 Training err. 1.38506 Training err. RA 1.52374 Valid. err. 2.63746 Time elapsed: 00:00:12
2018-02-08 13:57:57,907 training [INFO ] Epoch  6 Batch 3500 Training err. 1.32713 Training err. RA 1.52093 Valid. err. 2.64231 Time elapsed: 00:00:12
2018-02-08 13:57:58,081 training [INFO ] Epoch  6 Batch 3550 Training err. 1.29132 Training err. RA 1.51770 Valid. err. 2.65632 Time elapsed: 00:00:12
2018-02-08 13:57:58,246 training [INFO ] Epoch  6 Batch 3600 Training err. 1.33235 Training err. RA 1.51513 Valid. err. 2.62086 Time elapsed: 00:00:12
2018-02-08 13:57:58,412 training [INFO ] Epoch  6 Batch 3650 Training err. 1.34907 Training err. RA 1.51285 Valid. err. 2.60118 Time elapsed: 00:00:12
2018-02-08 13:57:58,675 training [INFO ] Epoch  7 Batch 3700 Training err. 1.37020 Training err. RA 1.51092 Valid. err. 2.68258 Time elapsed: 00:00:13
2018-02-08 13:57:58,842 training [INFO ] Epoch  7 Batch 3750 Training err. 1.33401 Training err. RA 1.50856 Valid. err. 2.61723 Time elapsed: 00:00:13
2018-02-08 13:57:59,020 training [INFO ] Epoch  7 Batch 3800 Training err. 1.36790 Training err. RA 1.50671 Valid. err. 2.60169 Time elapsed: 00:00:13
2018-02-08 13:57:59,187 training [INFO ] Epoch  7 Batch 3850 Training err. 1.30369 Training err. RA 1.50408 Valid. err. 2.61837 Time elapsed: 00:00:13
2018-02-08 13:57:59,357 training [INFO ] Epoch  7 Batch 3900 Training err. 1.29256 Training err. RA 1.50136 Valid. err. 2.58560 Time elapsed: 00:00:13
2018-02-08 13:57:59,525 training [INFO ] Epoch  7 Batch 3950 Training err. 1.29643 Training err. RA 1.49877 Valid. err. 2.57422 Time elapsed: 00:00:13
2018-02-08 13:57:59,692 training [INFO ] Epoch  7 Batch 4000 Training err. 1.26960 Training err. RA 1.49591 Valid. err. 2.56503 Time elapsed: 00:00:14
2018-02-08 13:57:59,857 training [INFO ] Epoch  7 Batch 4050 Training err. 1.34776 Training err. RA 1.49408 Valid. err. 2.55144 Time elapsed: 00:00:14
2018-02-08 13:58:00,035 training [INFO ] Epoch  7 Batch 4100 Training err. 1.31474 Training err. RA 1.49189 Valid. err. 2.55726 Time elapsed: 00:00:14
2018-02-08 13:58:00,207 training [INFO ] Epoch  7 Batch 4150 Training err. 1.26333 Training err. RA 1.48914 Valid. err. 2.56543 Time elapsed: 00:00:14
2018-02-08 13:58:00,376 training [INFO ] Epoch  7 Batch 4200 Training err. 1.28261 Training err. RA 1.48668 Valid. err. 2.53977 Time elapsed: 00:00:14
2018-02-08 13:58:00,545 training [INFO ] Epoch  7 Batch 4250 Training err. 1.30453 Training err. RA 1.48453 Valid. err. 2.53524 Time elapsed: 00:00:14
2018-02-08 13:58:00,833 training [INFO ] Epoch  8 Batch 4300 Training err. 1.30638 Training err. RA 1.48246 Valid. err. 2.52509 Time elapsed: 00:00:15
2018-02-08 13:58:01,002 training [INFO ] Epoch  8 Batch 4350 Training err. 1.34057 Training err. RA 1.48083 Valid. err. 2.56822 Time elapsed: 00:00:15
2018-02-08 13:58:01,177 training [INFO ] Epoch  8 Batch 4400 Training err. 1.34229 Training err. RA 1.47926 Valid. err. 2.53193 Time elapsed: 00:00:15
2018-02-08 13:58:01,335 training [INFO ] Epoch  8 Batch 4450 Training err. 1.28108 Training err. RA 1.47703 Valid. err. 2.54226 Time elapsed: 00:00:15
2018-02-08 13:58:01,512 training [INFO ] Epoch  8 Batch 4500 Training err. 1.27787 Training err. RA 1.47482 Valid. err. 2.52999 Time elapsed: 00:00:15
2018-02-08 13:58:01,670 training [INFO ] Epoch  8 Batch 4550 Training err. 1.26228 Training err. RA 1.47248 Valid. err. 2.53590 Time elapsed: 00:00:16
2018-02-08 13:58:01,844 training [INFO ] Epoch  8 Batch 4600 Training err. 1.25953 Training err. RA 1.47017 Valid. err. 2.52194 Time elapsed: 00:00:16
2018-02-08 13:58:02,014 training [INFO ] Epoch  8 Batch 4650 Training err. 1.28460 Training err. RA 1.46817 Valid. err. 2.49990 Time elapsed: 00:00:16
2018-02-08 13:58:02,188 training [INFO ] Epoch  8 Batch 4700 Training err. 1.29852 Training err. RA 1.46637 Valid. err. 2.51725 Time elapsed: 00:00:16
2018-02-08 13:58:02,345 training [INFO ] Epoch  8 Batch 4750 Training err. 1.26697 Training err. RA 1.46427 Valid. err. 2.50143 Time elapsed: 00:00:16
2018-02-08 13:58:02,519 training [INFO ] Epoch  8 Batch 4800 Training err. 1.20751 Training err. RA 1.46159 Valid. err. 2.49425 Time elapsed: 00:00:16
2018-02-08 13:58:02,681 training [INFO ] Epoch  8 Batch 4850 Training err. 1.26813 Training err. RA 1.45960 Valid. err. 2.49951 Time elapsed: 00:00:17
2018-02-08 13:58:02,856 training [INFO ] Epoch  8 Batch 4900 Training err. 1.28678 Training err. RA 1.45784 Valid. err. 2.49722 Time elapsed: 00:00:17
2018-02-08 13:58:03,130 training [INFO ] Epoch  9 Batch 4950 Training err. 1.32699 Training err. RA 1.45651 Valid. err. 2.48382 Time elapsed: 00:00:17
2018-02-08 13:58:03,291 training [INFO ] Epoch  9 Batch 5000 Training err. 1.27717 Training err. RA 1.45472 Valid. err. 2.50502 Time elapsed: 00:00:17
2018-02-08 13:58:03,465 training [INFO ] Epoch  9 Batch 5050 Training err. 1.31305 Training err. RA 1.45332 Valid. err. 2.58159 Time elapsed: 00:00:17
2018-02-08 13:58:03,629 training [INFO ] Epoch  9 Batch 5100 Training err. 1.25302 Training err. RA 1.45135 Valid. err. 2.47689 Time elapsed: 00:00:18
2018-02-08 13:58:03,801 training [INFO ] Epoch  9 Batch 5150 Training err. 1.20928 Training err. RA 1.44900 Valid. err. 2.49464 Time elapsed: 00:00:18
2018-02-08 13:58:03,963 training [INFO ] Epoch  9 Batch 5200 Training err. 1.26725 Training err. RA 1.44726 Valid. err. 2.45348 Time elapsed: 00:00:18
2018-02-08 13:58:04,144 training [INFO ] Epoch  9 Batch 5250 Training err. 1.24147 Training err. RA 1.44530 Valid. err. 2.46200 Time elapsed: 00:00:18
2018-02-08 13:58:04,305 training [INFO ] Epoch  9 Batch 5300 Training err. 1.29841 Training err. RA 1.44391 Valid. err. 2.48903 Time elapsed: 00:00:18
2018-02-08 13:58:04,482 training [INFO ] Epoch  9 Batch 5350 Training err. 1.22617 Training err. RA 1.44188 Valid. err. 2.46592 Time elapsed: 00:00:18
2018-02-08 13:58:04,640 training [INFO ] Epoch  9 Batch 5400 Training err. 1.20468 Training err. RA 1.43968 Valid. err. 2.48207 Time elapsed: 00:00:19
2018-02-08 13:58:04,814 training [INFO ] Epoch  9 Batch 5450 Training err. 1.22813 Training err. RA 1.43774 Valid. err. 2.45551 Time elapsed: 00:00:19
2018-02-08 13:58:04,976 training [INFO ] Epoch  9 Batch 5500 Training err. 1.25607 Training err. RA 1.43609 Valid. err. 2.43257 Time elapsed: 00:00:19
2018-02-08 13:58:05,250 training [INFO ] Epoch 10 Batch 5550 Training err. 1.29259 Training err. RA 1.43479 Valid. err. 2.45041 Time elapsed: 00:00:19
2018-02-08 13:58:05,410 training [INFO ] Epoch 10 Batch 5600 Training err. 1.24682 Training err. RA 1.43312 Valid. err. 2.45647 Time elapsed: 00:00:19
2018-02-08 13:58:05,587 training [INFO ] Epoch 10 Batch 5650 Training err. 1.30874 Training err. RA 1.43202 Valid. err. 2.45967 Time elapsed: 00:00:19
2018-02-08 13:58:05,746 training [INFO ] Epoch 10 Batch 5700 Training err. 1.24477 Training err. RA 1.43037 Valid. err. 2.44468 Time elapsed: 00:00:20
2018-02-08 13:58:05,924 training [INFO ] Epoch 10 Batch 5750 Training err. 1.20346 Training err. RA 1.42840 Valid. err. 2.42285 Time elapsed: 00:00:20
2018-02-08 13:58:06,092 training [INFO ] Epoch 10 Batch 5800 Training err. 1.23418 Training err. RA 1.42673 Valid. err. 2.41386 Time elapsed: 00:00:20
2018-02-08 13:58:06,265 training [INFO ] Epoch 10 Batch 5850 Training err. 1.20777 Training err. RA 1.42485 Valid. err. 2.42869 Time elapsed: 00:00:20
2018-02-08 13:58:06,423 training [INFO ] Epoch 10 Batch 5900 Training err. 1.28219 Training err. RA 1.42365 Valid. err. 2.44801 Time elapsed: 00:00:20
2018-02-08 13:58:06,599 training [INFO ] Epoch 10 Batch 5950 Training err. 1.23369 Training err. RA 1.42205 Valid. err. 2.41715 Time elapsed: 00:00:20
2018-02-08 13:58:06,756 training [INFO ] Epoch 10 Batch 6000 Training err. 1.18255 Training err. RA 1.42005 Valid. err. 2.40539 Time elapsed: 00:00:21
2018-02-08 13:58:06,937 training [INFO ] Epoch 10 Batch 6050 Training err. 1.20285 Training err. RA 1.41826 Valid. err. 2.41513 Time elapsed: 00:00:21
2018-02-08 13:58:07,103 training [INFO ] Epoch 10 Batch 6100 Training err. 1.22947 Training err. RA 1.41671 Valid. err. 2.40002 Time elapsed: 00:00:21
2018-02-08 13:58:07,262 __main__ [INFO ] End of training
2018-02-08 13:58:07,641 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:58:07,642 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:58:07,827 training [INFO ] Epoch  1 Batch   50 Training err. 2.10471 Training err. RA 2.10471 Valid. err. 3.95759 Time elapsed: 00:00:00
2018-02-08 13:58:08,031 training [INFO ] Epoch  1 Batch  100 Training err. 1.87605 Training err. RA 1.99038 Valid. err. 3.46427 Time elapsed: 00:00:00
2018-02-08 13:58:08,202 training [INFO ] Epoch  1 Batch  150 Training err. 1.71137 Training err. RA 1.89738 Valid. err. 3.33957 Time elapsed: 00:00:00
2018-02-08 13:58:08,375 training [INFO ] Epoch  1 Batch  200 Training err. 1.65368 Training err. RA 1.83645 Valid. err. 3.29647 Time elapsed: 00:00:00
2018-02-08 13:58:08,546 training [INFO ] Epoch  1 Batch  250 Training err. 1.64500 Training err. RA 1.79816 Valid. err. 3.25603 Time elapsed: 00:00:00
2018-02-08 13:58:08,716 training [INFO ] Epoch  1 Batch  300 Training err. 1.62367 Training err. RA 1.76908 Valid. err. 3.24654 Time elapsed: 00:00:01
2018-02-08 13:58:08,890 training [INFO ] Epoch  1 Batch  350 Training err. 1.62564 Training err. RA 1.74859 Valid. err. 3.24587 Time elapsed: 00:00:01
2018-02-08 13:58:09,069 training [INFO ] Epoch  1 Batch  400 Training err. 1.63033 Training err. RA 1.73381 Valid. err. 3.23161 Time elapsed: 00:00:01
2018-02-08 13:58:09,338 training [INFO ] Epoch  2 Batch  450 Training err. 1.63652 Training err. RA 1.72300 Valid. err. 3.24918 Time elapsed: 00:00:01
2018-02-08 13:58:09,507 training [INFO ] Epoch  2 Batch  500 Training err. 1.61702 Training err. RA 1.71240 Valid. err. 3.25560 Time elapsed: 00:00:01
2018-02-08 13:58:09,676 training [INFO ] Epoch  2 Batch  550 Training err. 1.61478 Training err. RA 1.70353 Valid. err. 3.24043 Time elapsed: 00:00:02
2018-02-08 13:58:09,848 training [INFO ] Epoch  2 Batch  600 Training err. 1.60146 Training err. RA 1.69502 Valid. err. 3.21995 Time elapsed: 00:00:02
2018-02-08 13:58:10,027 training [INFO ] Epoch  2 Batch  650 Training err. 1.60614 Training err. RA 1.68818 Valid. err. 3.21926 Time elapsed: 00:00:02
2018-02-08 13:58:10,200 training [INFO ] Epoch  2 Batch  700 Training err. 1.60705 Training err. RA 1.68239 Valid. err. 3.22442 Time elapsed: 00:00:02
2018-02-08 13:58:10,375 training [INFO ] Epoch  2 Batch  750 Training err. 1.60348 Training err. RA 1.67713 Valid. err. 3.21376 Time elapsed: 00:00:02
2018-02-08 13:58:10,543 training [INFO ] Epoch  2 Batch  800 Training err. 1.61536 Training err. RA 1.67327 Valid. err. 3.19851 Time elapsed: 00:00:02
2018-02-08 13:58:10,802 training [INFO ] Epoch  3 Batch  850 Training err. 1.62027 Training err. RA 1.67015 Valid. err. 3.23147 Time elapsed: 00:00:03
2018-02-08 13:58:10,978 training [INFO ] Epoch  3 Batch  900 Training err. 1.61205 Training err. RA 1.66692 Valid. err. 3.21225 Time elapsed: 00:00:03
2018-02-08 13:58:11,155 training [INFO ] Epoch  3 Batch  950 Training err. 1.58351 Training err. RA 1.66253 Valid. err. 3.22185 Time elapsed: 00:00:03
2018-02-08 13:58:11,327 training [INFO ] Epoch  3 Batch 1000 Training err. 1.58722 Training err. RA 1.65877 Valid. err. 3.19222 Time elapsed: 00:00:03
2018-02-08 13:58:11,503 training [INFO ] Epoch  3 Batch 1050 Training err. 1.59174 Training err. RA 1.65557 Valid. err. 3.19267 Time elapsed: 00:00:03
2018-02-08 13:58:11,667 training [INFO ] Epoch  3 Batch 1100 Training err. 1.59900 Training err. RA 1.65300 Valid. err. 3.19414 Time elapsed: 00:00:04
2018-02-08 13:58:11,852 training [INFO ] Epoch  3 Batch 1150 Training err. 1.56755 Training err. RA 1.64929 Valid. err. 3.18949 Time elapsed: 00:00:04
2018-02-08 13:58:12,022 training [INFO ] Epoch  3 Batch 1200 Training err. 1.60525 Training err. RA 1.64745 Valid. err. 3.15527 Time elapsed: 00:00:04
2018-02-08 13:58:12,286 training [INFO ] Epoch  4 Batch 1250 Training err. 1.59618 Training err. RA 1.64540 Valid. err. 3.14577 Time elapsed: 00:00:04
2018-02-08 13:58:12,455 training [INFO ] Epoch  4 Batch 1300 Training err. 1.58283 Training err. RA 1.64299 Valid. err. 3.14334 Time elapsed: 00:00:04
2018-02-08 13:58:12,629 training [INFO ] Epoch  4 Batch 1350 Training err. 1.54088 Training err. RA 1.63921 Valid. err. 3.13543 Time elapsed: 00:00:04
2018-02-08 13:58:12,797 training [INFO ] Epoch  4 Batch 1400 Training err. 1.55146 Training err. RA 1.63608 Valid. err. 3.09689 Time elapsed: 00:00:05
2018-02-08 13:58:12,977 training [INFO ] Epoch  4 Batch 1450 Training err. 1.53671 Training err. RA 1.63265 Valid. err. 3.09587 Time elapsed: 00:00:05
2018-02-08 13:58:13,150 training [INFO ] Epoch  4 Batch 1500 Training err. 1.54585 Training err. RA 1.62976 Valid. err. 3.06291 Time elapsed: 00:00:05
2018-02-08 13:58:13,333 training [INFO ] Epoch  4 Batch 1550 Training err. 1.50729 Training err. RA 1.62581 Valid. err. 3.05392 Time elapsed: 00:00:05
2018-02-08 13:58:13,504 training [INFO ] Epoch  4 Batch 1600 Training err. 1.52966 Training err. RA 1.62280 Valid. err. 3.04657 Time elapsed: 00:00:05
2018-02-08 13:58:13,766 training [INFO ] Epoch  5 Batch 1650 Training err. 1.55464 Training err. RA 1.62074 Valid. err. 2.99306 Time elapsed: 00:00:06
2018-02-08 13:58:13,946 training [INFO ] Epoch  5 Batch 1700 Training err. 1.49842 Training err. RA 1.61714 Valid. err. 2.99659 Time elapsed: 00:00:06
2018-02-08 13:58:14,121 training [INFO ] Epoch  5 Batch 1750 Training err. 1.49872 Training err. RA 1.61376 Valid. err. 2.98142 Time elapsed: 00:00:06
2018-02-08 13:58:14,287 training [INFO ] Epoch  5 Batch 1800 Training err. 1.46304 Training err. RA 1.60957 Valid. err. 2.94522 Time elapsed: 00:00:06
2018-02-08 13:58:14,454 training [INFO ] Epoch  5 Batch 1850 Training err. 1.44592 Training err. RA 1.60515 Valid. err. 2.91632 Time elapsed: 00:00:06
2018-02-08 13:58:14,618 training [INFO ] Epoch  5 Batch 1900 Training err. 1.48740 Training err. RA 1.60205 Valid. err. 2.91316 Time elapsed: 00:00:06
2018-02-08 13:58:14,791 training [INFO ] Epoch  5 Batch 1950 Training err. 1.42520 Training err. RA 1.59751 Valid. err. 2.89091 Time elapsed: 00:00:07
2018-02-08 13:58:14,961 training [INFO ] Epoch  5 Batch 2000 Training err. 1.45432 Training err. RA 1.59393 Valid. err. 2.86280 Time elapsed: 00:00:07
2018-02-08 13:58:15,142 training [INFO ] Epoch  5 Batch 2050 Training err. 1.46535 Training err. RA 1.59080 Valid. err. 2.86183 Time elapsed: 00:00:07
2018-02-08 13:58:15,438 training [INFO ] Epoch  6 Batch 2100 Training err. 1.46396 Training err. RA 1.58778 Valid. err. 2.84280 Time elapsed: 00:00:07
2018-02-08 13:58:15,606 training [INFO ] Epoch  6 Batch 2150 Training err. 1.46210 Training err. RA 1.58486 Valid. err. 2.83211 Time elapsed: 00:00:07
2018-02-08 13:58:15,782 training [INFO ] Epoch  6 Batch 2200 Training err. 1.40946 Training err. RA 1.58087 Valid. err. 2.83189 Time elapsed: 00:00:08
2018-02-08 13:58:15,955 training [INFO ] Epoch  6 Batch 2250 Training err. 1.40233 Training err. RA 1.57690 Valid. err. 2.81882 Time elapsed: 00:00:08
2018-02-08 13:58:16,128 training [INFO ] Epoch  6 Batch 2300 Training err. 1.42677 Training err. RA 1.57364 Valid. err. 2.79068 Time elapsed: 00:00:08
2018-02-08 13:58:16,296 training [INFO ] Epoch  6 Batch 2350 Training err. 1.40417 Training err. RA 1.57003 Valid. err. 2.78728 Time elapsed: 00:00:08
2018-02-08 13:58:16,471 training [INFO ] Epoch  6 Batch 2400 Training err. 1.39611 Training err. RA 1.56641 Valid. err. 2.77890 Time elapsed: 00:00:08
2018-02-08 13:58:16,641 training [INFO ] Epoch  6 Batch 2450 Training err. 1.42357 Training err. RA 1.56349 Valid. err. 2.76651 Time elapsed: 00:00:08
2018-02-08 13:58:16,913 training [INFO ] Epoch  7 Batch 2500 Training err. 1.44809 Training err. RA 1.56119 Valid. err. 2.86147 Time elapsed: 00:00:09
2018-02-08 13:58:17,077 training [INFO ] Epoch  7 Batch 2550 Training err. 1.42100 Training err. RA 1.55844 Valid. err. 2.82976 Time elapsed: 00:00:09
2018-02-08 13:58:17,252 training [INFO ] Epoch  7 Batch 2600 Training err. 1.38223 Training err. RA 1.55505 Valid. err. 2.75630 Time elapsed: 00:00:09
2018-02-08 13:58:17,411 training [INFO ] Epoch  7 Batch 2650 Training err. 1.36536 Training err. RA 1.55147 Valid. err. 2.75520 Time elapsed: 00:00:09
2018-02-08 13:58:17,583 training [INFO ] Epoch  7 Batch 2700 Training err. 1.38210 Training err. RA 1.54833 Valid. err. 2.72745 Time elapsed: 00:00:09
2018-02-08 13:58:17,744 training [INFO ] Epoch  7 Batch 2750 Training err. 1.38614 Training err. RA 1.54538 Valid. err. 2.75094 Time elapsed: 00:00:10
2018-02-08 13:58:17,917 training [INFO ] Epoch  7 Batch 2800 Training err. 1.35457 Training err. RA 1.54198 Valid. err. 2.71862 Time elapsed: 00:00:10
2018-02-08 13:58:18,081 training [INFO ] Epoch  7 Batch 2850 Training err. 1.39653 Training err. RA 1.53942 Valid. err. 2.79963 Time elapsed: 00:00:10
2018-02-08 13:58:18,339 training [INFO ] Epoch  8 Batch 2900 Training err. 1.41098 Training err. RA 1.53721 Valid. err. 2.80246 Time elapsed: 00:00:10
2018-02-08 13:58:18,501 training [INFO ] Epoch  8 Batch 2950 Training err. 1.40078 Training err. RA 1.53490 Valid. err. 2.69914 Time elapsed: 00:00:10
2018-02-08 13:58:18,678 training [INFO ] Epoch  8 Batch 3000 Training err. 1.34751 Training err. RA 1.53177 Valid. err. 2.70145 Time elapsed: 00:00:11
2018-02-08 13:58:18,838 training [INFO ] Epoch  8 Batch 3050 Training err. 1.33677 Training err. RA 1.52858 Valid. err. 2.67870 Time elapsed: 00:00:11
2018-02-08 13:58:19,018 training [INFO ] Epoch  8 Batch 3100 Training err. 1.35214 Training err. RA 1.52573 Valid. err. 2.66846 Time elapsed: 00:00:11
2018-02-08 13:58:19,187 training [INFO ] Epoch  8 Batch 3150 Training err. 1.37011 Training err. RA 1.52326 Valid. err. 2.69898 Time elapsed: 00:00:11
2018-02-08 13:58:19,363 training [INFO ] Epoch  8 Batch 3200 Training err. 1.30859 Training err. RA 1.51991 Valid. err. 2.69465 Time elapsed: 00:00:11
2018-02-08 13:58:19,522 training [INFO ] Epoch  8 Batch 3250 Training err. 1.36789 Training err. RA 1.51757 Valid. err. 2.65693 Time elapsed: 00:00:11
2018-02-08 13:58:19,785 training [INFO ] Epoch  9 Batch 3300 Training err. 1.37989 Training err. RA 1.51548 Valid. err. 2.64830 Time elapsed: 00:00:12
2018-02-08 13:58:19,956 training [INFO ] Epoch  9 Batch 3350 Training err. 1.37471 Training err. RA 1.51338 Valid. err. 2.66282 Time elapsed: 00:00:12
2018-02-08 13:58:20,131 training [INFO ] Epoch  9 Batch 3400 Training err. 1.32324 Training err. RA 1.51059 Valid. err. 2.66407 Time elapsed: 00:00:12
2018-02-08 13:58:20,293 training [INFO ] Epoch  9 Batch 3450 Training err. 1.31073 Training err. RA 1.50769 Valid. err. 2.63068 Time elapsed: 00:00:12
2018-02-08 13:58:20,465 training [INFO ] Epoch  9 Batch 3500 Training err. 1.31413 Training err. RA 1.50492 Valid. err. 2.66122 Time elapsed: 00:00:12
2018-02-08 13:58:20,635 training [INFO ] Epoch  9 Batch 3550 Training err. 1.34772 Training err. RA 1.50271 Valid. err. 2.61635 Time elapsed: 00:00:12
2018-02-08 13:58:20,807 training [INFO ] Epoch  9 Batch 3600 Training err. 1.29017 Training err. RA 1.49976 Valid. err. 2.62795 Time elapsed: 00:00:13
2018-02-08 13:58:20,970 training [INFO ] Epoch  9 Batch 3650 Training err. 1.32186 Training err. RA 1.49732 Valid. err. 2.60490 Time elapsed: 00:00:13
2018-02-08 13:58:21,243 training [INFO ] Epoch 10 Batch 3700 Training err. 1.36579 Training err. RA 1.49554 Valid. err. 2.61330 Time elapsed: 00:00:13
2018-02-08 13:58:21,411 training [INFO ] Epoch 10 Batch 3750 Training err. 1.33523 Training err. RA 1.49341 Valid. err. 2.60195 Time elapsed: 00:00:13
2018-02-08 13:58:21,591 training [INFO ] Epoch 10 Batch 3800 Training err. 1.32962 Training err. RA 1.49125 Valid. err. 2.65686 Time elapsed: 00:00:13
2018-02-08 13:58:21,756 training [INFO ] Epoch 10 Batch 3850 Training err. 1.28053 Training err. RA 1.48851 Valid. err. 2.58844 Time elapsed: 00:00:14
2018-02-08 13:58:21,942 training [INFO ] Epoch 10 Batch 3900 Training err. 1.29120 Training err. RA 1.48598 Valid. err. 2.57968 Time elapsed: 00:00:14
2018-02-08 13:58:22,116 training [INFO ] Epoch 10 Batch 3950 Training err. 1.34350 Training err. RA 1.48418 Valid. err. 2.57298 Time elapsed: 00:00:14
2018-02-08 13:58:22,294 training [INFO ] Epoch 10 Batch 4000 Training err. 1.26884 Training err. RA 1.48149 Valid. err. 2.56748 Time elapsed: 00:00:14
2018-02-08 13:58:22,465 training [INFO ] Epoch 10 Batch 4050 Training err. 1.28733 Training err. RA 1.47909 Valid. err. 2.55265 Time elapsed: 00:00:14
2018-02-08 13:58:22,646 training [INFO ] Epoch 10 Batch 4100 Training err. 1.30747 Training err. RA 1.47700 Valid. err. 2.56971 Time elapsed: 00:00:15
2018-02-08 13:58:22,733 __main__ [INFO ] End of training
2018-02-08 13:58:22,885 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:58:22,886 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:58:23,082 training [INFO ] Epoch  1 Batch   50 Training err. 2.16901 Training err. RA 2.16901 Valid. err. 4.24334 Time elapsed: 00:00:00
2018-02-08 13:58:23,287 training [INFO ] Epoch  1 Batch  100 Training err. 2.08954 Training err. RA 2.12928 Valid. err. 4.06462 Time elapsed: 00:00:00
2018-02-08 13:58:23,462 training [INFO ] Epoch  1 Batch  150 Training err. 1.99240 Training err. RA 2.08365 Valid. err. 3.84774 Time elapsed: 00:00:00
2018-02-08 13:58:23,648 training [INFO ] Epoch  1 Batch  200 Training err. 1.91918 Training err. RA 2.04253 Valid. err. 3.64950 Time elapsed: 00:00:00
2018-02-08 13:58:23,825 training [INFO ] Epoch  1 Batch  250 Training err. 1.82671 Training err. RA 1.99937 Valid. err. 3.50109 Time elapsed: 00:00:00
2018-02-08 13:58:24,017 training [INFO ] Epoch  1 Batch  300 Training err. 1.75542 Training err. RA 1.95871 Valid. err. 3.41832 Time elapsed: 00:00:01
2018-02-08 13:58:24,200 training [INFO ] Epoch  1 Batch  350 Training err. 1.71683 Training err. RA 1.92416 Valid. err. 3.37016 Time elapsed: 00:00:01
2018-02-08 13:58:24,378 training [INFO ] Epoch  1 Batch  400 Training err. 1.70893 Training err. RA 1.89725 Valid. err. 3.34401 Time elapsed: 00:00:01
2018-02-08 13:58:24,546 training [INFO ] Epoch  1 Batch  450 Training err. 1.68766 Training err. RA 1.87396 Valid. err. 3.32650 Time elapsed: 00:00:01
2018-02-08 13:58:24,729 training [INFO ] Epoch  1 Batch  500 Training err. 1.66182 Training err. RA 1.85275 Valid. err. 3.31229 Time elapsed: 00:00:01
2018-02-08 13:58:24,899 training [INFO ] Epoch  1 Batch  550 Training err. 1.67806 Training err. RA 1.83687 Valid. err. 3.28834 Time elapsed: 00:00:02
2018-02-08 13:58:25,087 training [INFO ] Epoch  1 Batch  600 Training err. 1.65795 Training err. RA 1.82196 Valid. err. 3.28601 Time elapsed: 00:00:02
2018-02-08 13:58:25,375 training [INFO ] Epoch  2 Batch  650 Training err. 1.65973 Training err. RA 1.80948 Valid. err. 3.27070 Time elapsed: 00:00:02
2018-02-08 13:58:25,560 training [INFO ] Epoch  2 Batch  700 Training err. 1.64107 Training err. RA 1.79745 Valid. err. 3.26790 Time elapsed: 00:00:02
2018-02-08 13:58:25,746 training [INFO ] Epoch  2 Batch  750 Training err. 1.65070 Training err. RA 1.78767 Valid. err. 3.26279 Time elapsed: 00:00:02
2018-02-08 13:58:25,922 training [INFO ] Epoch  2 Batch  800 Training err. 1.64347 Training err. RA 1.77866 Valid. err. 3.25268 Time elapsed: 00:00:03
2018-02-08 13:58:26,111 training [INFO ] Epoch  2 Batch  850 Training err. 1.63494 Training err. RA 1.77020 Valid. err. 3.25360 Time elapsed: 00:00:03
2018-02-08 13:58:26,288 training [INFO ] Epoch  2 Batch  900 Training err. 1.60900 Training err. RA 1.76125 Valid. err. 3.25877 Time elapsed: 00:00:03
2018-02-08 13:58:26,468 training [INFO ] Epoch  2 Batch  950 Training err. 1.60169 Training err. RA 1.75285 Valid. err. 3.25058 Time elapsed: 00:00:03
2018-02-08 13:58:26,644 training [INFO ] Epoch  2 Batch 1000 Training err. 1.62059 Training err. RA 1.74624 Valid. err. 3.25952 Time elapsed: 00:00:03
2018-02-08 13:58:26,826 training [INFO ] Epoch  2 Batch 1050 Training err. 1.65260 Training err. RA 1.74178 Valid. err. 3.24246 Time elapsed: 00:00:03
2018-02-08 13:58:27,023 training [INFO ] Epoch  2 Batch 1100 Training err. 1.61302 Training err. RA 1.73592 Valid. err. 3.24217 Time elapsed: 00:00:04
2018-02-08 13:58:27,246 training [INFO ] Epoch  2 Batch 1150 Training err. 1.63061 Training err. RA 1.73135 Valid. err. 3.23326 Time elapsed: 00:00:04
2018-02-08 13:58:27,443 training [INFO ] Epoch  2 Batch 1200 Training err. 1.61409 Training err. RA 1.72646 Valid. err. 3.22871 Time elapsed: 00:00:04
2018-02-08 13:58:27,742 training [INFO ] Epoch  3 Batch 1250 Training err. 1.62091 Training err. RA 1.72224 Valid. err. 3.22963 Time elapsed: 00:00:04
2018-02-08 13:58:27,949 training [INFO ] Epoch  3 Batch 1300 Training err. 1.63580 Training err. RA 1.71891 Valid. err. 3.23828 Time elapsed: 00:00:05
2018-02-08 13:58:28,129 training [INFO ] Epoch  3 Batch 1350 Training err. 1.61708 Training err. RA 1.71514 Valid. err. 3.22904 Time elapsed: 00:00:05
2018-02-08 13:58:28,325 training [INFO ] Epoch  3 Batch 1400 Training err. 1.59484 Training err. RA 1.71085 Valid. err. 3.23341 Time elapsed: 00:00:05
2018-02-08 13:58:28,520 training [INFO ] Epoch  3 Batch 1450 Training err. 1.64218 Training err. RA 1.70848 Valid. err. 3.22925 Time elapsed: 00:00:05
2018-02-08 13:58:28,708 training [INFO ] Epoch  3 Batch 1500 Training err. 1.58417 Training err. RA 1.70433 Valid. err. 3.23908 Time elapsed: 00:00:05
2018-02-08 13:58:28,885 training [INFO ] Epoch  3 Batch 1550 Training err. 1.58236 Training err. RA 1.70040 Valid. err. 3.22830 Time elapsed: 00:00:05
2018-02-08 13:58:29,086 training [INFO ] Epoch  3 Batch 1600 Training err. 1.61079 Training err. RA 1.69760 Valid. err. 3.23332 Time elapsed: 00:00:06
2018-02-08 13:58:29,263 training [INFO ] Epoch  3 Batch 1650 Training err. 1.63984 Training err. RA 1.69585 Valid. err. 3.22151 Time elapsed: 00:00:06
2018-02-08 13:58:29,458 training [INFO ] Epoch  3 Batch 1700 Training err. 1.59734 Training err. RA 1.69295 Valid. err. 3.21940 Time elapsed: 00:00:06
2018-02-08 13:58:29,632 training [INFO ] Epoch  3 Batch 1750 Training err. 1.61528 Training err. RA 1.69073 Valid. err. 3.21333 Time elapsed: 00:00:06
2018-02-08 13:58:29,825 training [INFO ] Epoch  3 Batch 1800 Training err. 1.59839 Training err. RA 1.68817 Valid. err. 3.20888 Time elapsed: 00:00:06
2018-02-08 13:58:30,122 training [INFO ] Epoch  4 Batch 1850 Training err. 1.59589 Training err. RA 1.68567 Valid. err. 3.21012 Time elapsed: 00:00:07
2018-02-08 13:58:30,345 training [INFO ] Epoch  4 Batch 1900 Training err. 1.62021 Training err. RA 1.68395 Valid. err. 3.21234 Time elapsed: 00:00:07
2018-02-08 13:58:30,526 training [INFO ] Epoch  4 Batch 1950 Training err. 1.60936 Training err. RA 1.68204 Valid. err. 3.21141 Time elapsed: 00:00:07
2018-02-08 13:58:30,713 training [INFO ] Epoch  4 Batch 2000 Training err. 1.57535 Training err. RA 1.67937 Valid. err. 3.21059 Time elapsed: 00:00:07
2018-02-08 13:58:30,893 training [INFO ] Epoch  4 Batch 2050 Training err. 1.64270 Training err. RA 1.67848 Valid. err. 3.19826 Time elapsed: 00:00:08
2018-02-08 13:58:31,084 training [INFO ] Epoch  4 Batch 2100 Training err. 1.57556 Training err. RA 1.67603 Valid. err. 3.21412 Time elapsed: 00:00:08
2018-02-08 13:58:31,268 training [INFO ] Epoch  4 Batch 2150 Training err. 1.56964 Training err. RA 1.67355 Valid. err. 3.20431 Time elapsed: 00:00:08
2018-02-08 13:58:31,455 training [INFO ] Epoch  4 Batch 2200 Training err. 1.60333 Training err. RA 1.67196 Valid. err. 3.20294 Time elapsed: 00:00:08
2018-02-08 13:58:31,647 training [INFO ] Epoch  4 Batch 2250 Training err. 1.60425 Training err. RA 1.67045 Valid. err. 3.19372 Time elapsed: 00:00:08
2018-02-08 13:58:31,837 training [INFO ] Epoch  4 Batch 2300 Training err. 1.60119 Training err. RA 1.66895 Valid. err. 3.19380 Time elapsed: 00:00:08
2018-02-08 13:58:32,034 training [INFO ] Epoch  4 Batch 2350 Training err. 1.58020 Training err. RA 1.66706 Valid. err. 3.18830 Time elapsed: 00:00:09
2018-02-08 13:58:32,217 training [INFO ] Epoch  4 Batch 2400 Training err. 1.59399 Training err. RA 1.66553 Valid. err. 3.17725 Time elapsed: 00:00:09
2018-02-08 13:58:32,394 training [INFO ] Epoch  4 Batch 2450 Training err. 1.57796 Training err. RA 1.66375 Valid. err. 3.17891 Time elapsed: 00:00:09
2018-02-08 13:58:32,672 training [INFO ] Epoch  5 Batch 2500 Training err. 1.61490 Training err. RA 1.66277 Valid. err. 3.17121 Time elapsed: 00:00:09
2018-02-08 13:58:32,849 training [INFO ] Epoch  5 Batch 2550 Training err. 1.58391 Training err. RA 1.66122 Valid. err. 3.18816 Time elapsed: 00:00:09
2018-02-08 13:58:33,050 training [INFO ] Epoch  5 Batch 2600 Training err. 1.57364 Training err. RA 1.65954 Valid. err. 3.15994 Time elapsed: 00:00:10
2018-02-08 13:58:33,239 training [INFO ] Epoch  5 Batch 2650 Training err. 1.62075 Training err. RA 1.65881 Valid. err. 3.15811 Time elapsed: 00:00:10
2018-02-08 13:58:33,422 training [INFO ] Epoch  5 Batch 2700 Training err. 1.56006 Training err. RA 1.65698 Valid. err. 3.16299 Time elapsed: 00:00:10
2018-02-08 13:58:33,598 training [INFO ] Epoch  5 Batch 2750 Training err. 1.55512 Training err. RA 1.65513 Valid. err. 3.15440 Time elapsed: 00:00:10
2018-02-08 13:58:33,792 training [INFO ] Epoch  5 Batch 2800 Training err. 1.55211 Training err. RA 1.65329 Valid. err. 3.14833 Time elapsed: 00:00:10
2018-02-08 13:58:33,971 training [INFO ] Epoch  5 Batch 2850 Training err. 1.56831 Training err. RA 1.65180 Valid. err. 3.14184 Time elapsed: 00:00:11
2018-02-08 13:58:34,162 training [INFO ] Epoch  5 Batch 2900 Training err. 1.58885 Training err. RA 1.65071 Valid. err. 3.13574 Time elapsed: 00:00:11
2018-02-08 13:58:34,354 training [INFO ] Epoch  5 Batch 2950 Training err. 1.54801 Training err. RA 1.64897 Valid. err. 3.14150 Time elapsed: 00:00:11
2018-02-08 13:58:34,535 training [INFO ] Epoch  5 Batch 3000 Training err. 1.57118 Training err. RA 1.64767 Valid. err. 3.18210 Time elapsed: 00:00:11
2018-02-08 13:58:34,712 training [INFO ] Epoch  5 Batch 3050 Training err. 1.56957 Training err. RA 1.64639 Valid. err. 3.12853 Time elapsed: 00:00:11
2018-02-08 13:58:34,987 training [INFO ] Epoch  6 Batch 3100 Training err. 1.57402 Training err. RA 1.64523 Valid. err. 3.13419 Time elapsed: 00:00:12
2018-02-08 13:58:35,168 training [INFO ] Epoch  6 Batch 3150 Training err. 1.55809 Training err. RA 1.64384 Valid. err. 3.11110 Time elapsed: 00:00:12
2018-02-08 13:58:35,356 training [INFO ] Epoch  6 Batch 3200 Training err. 1.55929 Training err. RA 1.64252 Valid. err. 3.09792 Time elapsed: 00:00:12
2018-02-08 13:58:35,537 training [INFO ] Epoch  6 Batch 3250 Training err. 1.54944 Training err. RA 1.64109 Valid. err. 3.08439 Time elapsed: 00:00:12
2018-02-08 13:58:35,744 training [INFO ] Epoch  6 Batch 3300 Training err. 1.57778 Training err. RA 1.64013 Valid. err. 3.08272 Time elapsed: 00:00:12
2018-02-08 13:58:35,929 training [INFO ] Epoch  6 Batch 3350 Training err. 1.51154 Training err. RA 1.63821 Valid. err. 3.10557 Time elapsed: 00:00:13
2018-02-08 13:58:36,124 training [INFO ] Epoch  6 Batch 3400 Training err. 1.50522 Training err. RA 1.63626 Valid. err. 3.13963 Time elapsed: 00:00:13
2018-02-08 13:58:36,303 training [INFO ] Epoch  6 Batch 3450 Training err. 1.53778 Training err. RA 1.63483 Valid. err. 3.07483 Time elapsed: 00:00:13
2018-02-08 13:58:36,490 training [INFO ] Epoch  6 Batch 3500 Training err. 1.56252 Training err. RA 1.63380 Valid. err. 3.05680 Time elapsed: 00:00:13
2018-02-08 13:58:36,659 training [INFO ] Epoch  6 Batch 3550 Training err. 1.50821 Training err. RA 1.63203 Valid. err. 3.05165 Time elapsed: 00:00:13
2018-02-08 13:58:36,846 training [INFO ] Epoch  6 Batch 3600 Training err. 1.53885 Training err. RA 1.63073 Valid. err. 3.04974 Time elapsed: 00:00:13
2018-02-08 13:58:37,035 training [INFO ] Epoch  6 Batch 3650 Training err. 1.52093 Training err. RA 1.62923 Valid. err. 3.02828 Time elapsed: 00:00:14
2018-02-08 13:58:37,327 training [INFO ] Epoch  7 Batch 3700 Training err. 1.53049 Training err. RA 1.62789 Valid. err. 3.03044 Time elapsed: 00:00:14
2018-02-08 13:58:37,518 training [INFO ] Epoch  7 Batch 3750 Training err. 1.55006 Training err. RA 1.62686 Valid. err. 3.06236 Time elapsed: 00:00:14
2018-02-08 13:58:37,716 training [INFO ] Epoch  7 Batch 3800 Training err. 1.52038 Training err. RA 1.62546 Valid. err. 3.05141 Time elapsed: 00:00:14
2018-02-08 13:58:37,903 training [INFO ] Epoch  7 Batch 3850 Training err. 1.49776 Training err. RA 1.62380 Valid. err. 3.00513 Time elapsed: 00:00:15
2018-02-08 13:58:38,112 training [INFO ] Epoch  7 Batch 3900 Training err. 1.54942 Training err. RA 1.62284 Valid. err. 3.01460 Time elapsed: 00:00:15
2018-02-08 13:58:38,330 training [INFO ] Epoch  7 Batch 3950 Training err. 1.47719 Training err. RA 1.62100 Valid. err. 3.02330 Time elapsed: 00:00:15
2018-02-08 13:58:38,558 training [INFO ] Epoch  7 Batch 4000 Training err. 1.46507 Training err. RA 1.61905 Valid. err. 2.99114 Time elapsed: 00:00:15
2018-02-08 13:58:38,746 training [INFO ] Epoch  7 Batch 4050 Training err. 1.50354 Training err. RA 1.61762 Valid. err. 3.00995 Time elapsed: 00:00:15
2018-02-08 13:58:38,951 training [INFO ] Epoch  7 Batch 4100 Training err. 1.50988 Training err. RA 1.61631 Valid. err. 2.96921 Time elapsed: 00:00:16
2018-02-08 13:58:39,177 training [INFO ] Epoch  7 Batch 4150 Training err. 1.46994 Training err. RA 1.61455 Valid. err. 2.95189 Time elapsed: 00:00:16
2018-02-08 13:58:39,400 training [INFO ] Epoch  7 Batch 4200 Training err. 1.47796 Training err. RA 1.61292 Valid. err. 2.94399 Time elapsed: 00:00:16
2018-02-08 13:58:39,607 training [INFO ] Epoch  7 Batch 4250 Training err. 1.50449 Training err. RA 1.61165 Valid. err. 2.94324 Time elapsed: 00:00:16
2018-02-08 13:58:39,972 training [INFO ] Epoch  8 Batch 4300 Training err. 1.45967 Training err. RA 1.60988 Valid. err. 2.93127 Time elapsed: 00:00:17
2018-02-08 13:58:40,216 training [INFO ] Epoch  8 Batch 4350 Training err. 1.51833 Training err. RA 1.60883 Valid. err. 2.96369 Time elapsed: 00:00:17
2018-02-08 13:58:40,437 training [INFO ] Epoch  8 Batch 4400 Training err. 1.48074 Training err. RA 1.60737 Valid. err. 2.92496 Time elapsed: 00:00:17
2018-02-08 13:58:40,633 training [INFO ] Epoch  8 Batch 4450 Training err. 1.45845 Training err. RA 1.60570 Valid. err. 2.91752 Time elapsed: 00:00:17
2018-02-08 13:58:40,845 training [INFO ] Epoch  8 Batch 4500 Training err. 1.51852 Training err. RA 1.60473 Valid. err. 2.89804 Time elapsed: 00:00:17
2018-02-08 13:58:41,034 training [INFO ] Epoch  8 Batch 4550 Training err. 1.44122 Training err. RA 1.60293 Valid. err. 2.91889 Time elapsed: 00:00:18
2018-02-08 13:58:41,229 training [INFO ] Epoch  8 Batch 4600 Training err. 1.43257 Training err. RA 1.60108 Valid. err. 2.91394 Time elapsed: 00:00:18
2018-02-08 13:58:41,410 training [INFO ] Epoch  8 Batch 4650 Training err. 1.44307 Training err. RA 1.59938 Valid. err. 2.89542 Time elapsed: 00:00:18
2018-02-08 13:58:41,597 training [INFO ] Epoch  8 Batch 4700 Training err. 1.44413 Training err. RA 1.59773 Valid. err. 2.87316 Time elapsed: 00:00:18
2018-02-08 13:58:41,775 training [INFO ] Epoch  8 Batch 4750 Training err. 1.44031 Training err. RA 1.59607 Valid. err. 2.88412 Time elapsed: 00:00:18
2018-02-08 13:58:41,950 training [INFO ] Epoch  8 Batch 4800 Training err. 1.44607 Training err. RA 1.59451 Valid. err. 2.87338 Time elapsed: 00:00:19
2018-02-08 13:58:42,131 training [INFO ] Epoch  8 Batch 4850 Training err. 1.44556 Training err. RA 1.59297 Valid. err. 2.85170 Time elapsed: 00:00:19
2018-02-08 13:58:42,312 training [INFO ] Epoch  8 Batch 4900 Training err. 1.43531 Training err. RA 1.59137 Valid. err. 2.88748 Time elapsed: 00:00:19
2018-02-08 13:58:42,609 training [INFO ] Epoch  9 Batch 4950 Training err. 1.47559 Training err. RA 1.59020 Valid. err. 2.84012 Time elapsed: 00:00:19
2018-02-08 13:58:42,789 training [INFO ] Epoch  9 Batch 5000 Training err. 1.44779 Training err. RA 1.58877 Valid. err. 2.89288 Time elapsed: 00:00:19
2018-02-08 13:58:42,968 training [INFO ] Epoch  9 Batch 5050 Training err. 1.44476 Training err. RA 1.58735 Valid. err. 2.82704 Time elapsed: 00:00:20
2018-02-08 13:58:43,148 training [INFO ] Epoch  9 Batch 5100 Training err. 1.46781 Training err. RA 1.58617 Valid. err. 2.83631 Time elapsed: 00:00:20
2018-02-08 13:58:43,323 training [INFO ] Epoch  9 Batch 5150 Training err. 1.42672 Training err. RA 1.58463 Valid. err. 2.83634 Time elapsed: 00:00:20
2018-02-08 13:58:43,494 training [INFO ] Epoch  9 Batch 5200 Training err. 1.40706 Training err. RA 1.58292 Valid. err. 2.82341 Time elapsed: 00:00:20
2018-02-08 13:58:43,675 training [INFO ] Epoch  9 Batch 5250 Training err. 1.38396 Training err. RA 1.58102 Valid. err. 2.81140 Time elapsed: 00:00:20
2018-02-08 13:58:43,852 training [INFO ] Epoch  9 Batch 5300 Training err. 1.39389 Training err. RA 1.57926 Valid. err. 2.81727 Time elapsed: 00:00:20
2018-02-08 13:58:44,031 training [INFO ] Epoch  9 Batch 5350 Training err. 1.43241 Training err. RA 1.57789 Valid. err. 2.88159 Time elapsed: 00:00:21
2018-02-08 13:58:44,205 training [INFO ] Epoch  9 Batch 5400 Training err. 1.39209 Training err. RA 1.57617 Valid. err. 2.80821 Time elapsed: 00:00:21
2018-02-08 13:58:44,382 training [INFO ] Epoch  9 Batch 5450 Training err. 1.43179 Training err. RA 1.57484 Valid. err. 2.79996 Time elapsed: 00:00:21
2018-02-08 13:58:44,554 training [INFO ] Epoch  9 Batch 5500 Training err. 1.41870 Training err. RA 1.57342 Valid. err. 2.79273 Time elapsed: 00:00:21
2018-02-08 13:58:44,830 training [INFO ] Epoch 10 Batch 5550 Training err. 1.41717 Training err. RA 1.57201 Valid. err. 2.78250 Time elapsed: 00:00:21
2018-02-08 13:58:44,998 training [INFO ] Epoch 10 Batch 5600 Training err. 1.46020 Training err. RA 1.57102 Valid. err. 2.81096 Time elapsed: 00:00:22
2018-02-08 13:58:45,182 training [INFO ] Epoch 10 Batch 5650 Training err. 1.42388 Training err. RA 1.56971 Valid. err. 2.79953 Time elapsed: 00:00:22
2018-02-08 13:58:45,350 training [INFO ] Epoch 10 Batch 5700 Training err. 1.39495 Training err. RA 1.56818 Valid. err. 2.77850 Time elapsed: 00:00:22
2018-02-08 13:58:45,535 training [INFO ] Epoch 10 Batch 5750 Training err. 1.45427 Training err. RA 1.56719 Valid. err. 2.82686 Time elapsed: 00:00:22
2018-02-08 13:58:45,706 training [INFO ] Epoch 10 Batch 5800 Training err. 1.37980 Training err. RA 1.56557 Valid. err. 2.82231 Time elapsed: 00:00:22
2018-02-08 13:58:45,889 training [INFO ] Epoch 10 Batch 5850 Training err. 1.35554 Training err. RA 1.56378 Valid. err. 2.79819 Time elapsed: 00:00:23
2018-02-08 13:58:46,065 training [INFO ] Epoch 10 Batch 5900 Training err. 1.38943 Training err. RA 1.56230 Valid. err. 2.79668 Time elapsed: 00:00:23
2018-02-08 13:58:46,253 training [INFO ] Epoch 10 Batch 5950 Training err. 1.41024 Training err. RA 1.56102 Valid. err. 2.80399 Time elapsed: 00:00:23
2018-02-08 13:58:46,439 training [INFO ] Epoch 10 Batch 6000 Training err. 1.36585 Training err. RA 1.55940 Valid. err. 2.75452 Time elapsed: 00:00:23
2018-02-08 13:58:46,631 training [INFO ] Epoch 10 Batch 6050 Training err. 1.41058 Training err. RA 1.55817 Valid. err. 2.75452 Time elapsed: 00:00:23
2018-02-08 13:58:46,863 training [INFO ] Epoch 10 Batch 6100 Training err. 1.39396 Training err. RA 1.55682 Valid. err. 2.75667 Time elapsed: 00:00:23
2018-02-08 13:58:47,117 __main__ [INFO ] End of training
2018-02-08 13:59:28,602 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 13:59:28,604 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 13:59:28,607 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 13:59:28,608 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 13:59:31,504 training [INFO ] Epoch  1 Batch    0 Training err. 0.08867 Training err. RA 0.08867 Valid. err. 4.42311 Time elapsed: 00:00:00
2018-02-08 13:59:31,590 training [INFO ] Epoch  1 Batch    0 Training err. 0.08854 Training err. RA 0.08860 Valid. err. 4.40801 Time elapsed: 00:00:00
2018-02-08 13:59:31,674 training [INFO ] Epoch  1 Batch    0 Training err. 0.08838 Training err. RA 0.08853 Valid. err. 4.39383 Time elapsed: 00:00:00
2018-02-08 13:59:31,767 training [INFO ] Epoch  1 Batch    0 Training err. 0.08796 Training err. RA 0.08839 Valid. err. 4.37889 Time elapsed: 00:00:00
2018-02-08 13:59:31,856 training [INFO ] Epoch  1 Batch    0 Training err. 0.08751 Training err. RA 0.08821 Valid. err. 4.36174 Time elapsed: 00:00:00
2018-02-08 13:59:31,947 training [INFO ] Epoch  1 Batch    0 Training err. 0.08722 Training err. RA 0.08805 Valid. err. 4.34538 Time elapsed: 00:00:00
2018-02-08 13:59:32,043 training [INFO ] Epoch  1 Batch    0 Training err. 0.08723 Training err. RA 0.08793 Valid. err. 4.33145 Time elapsed: 00:00:00
2018-02-08 13:59:32,132 training [INFO ] Epoch  1 Batch    0 Training err. 0.08657 Training err. RA 0.08776 Valid. err. 4.31823 Time elapsed: 00:00:00
2018-02-08 13:59:32,217 training [INFO ] Epoch  1 Batch    0 Training err. 0.08680 Training err. RA 0.08765 Valid. err. 4.30720 Time elapsed: 00:00:00
2018-02-08 13:59:32,311 training [INFO ] Epoch  1 Batch    0 Training err. 0.08612 Training err. RA 0.08750 Valid. err. 4.29116 Time elapsed: 00:00:01
2018-02-08 13:59:32,400 training [INFO ] Epoch  1 Batch    0 Training err. 0.08567 Training err. RA 0.08733 Valid. err. 4.27510 Time elapsed: 00:00:01
2018-02-08 13:59:32,495 training [INFO ] Epoch  1 Batch    0 Training err. 0.08524 Training err. RA 0.08716 Valid. err. 4.26119 Time elapsed: 00:00:01
2018-02-08 13:59:32,588 training [INFO ] Epoch  1 Batch    0 Training err. 0.08487 Training err. RA 0.08698 Valid. err. 4.24443 Time elapsed: 00:00:01
2018-02-08 13:59:32,674 training [INFO ] Epoch  1 Batch    0 Training err. 0.08484 Training err. RA 0.08683 Valid. err. 4.22744 Time elapsed: 00:00:01
2018-02-08 13:59:32,761 training [INFO ] Epoch  1 Batch    0 Training err. 0.08479 Training err. RA 0.08669 Valid. err. 4.21197 Time elapsed: 00:00:01
2018-02-08 13:59:32,858 training [INFO ] Epoch  1 Batch    0 Training err. 0.08483 Training err. RA 0.08658 Valid. err. 4.19919 Time elapsed: 00:00:01
2018-02-08 13:59:32,942 training [INFO ] Epoch  1 Batch    0 Training err. 0.08363 Training err. RA 0.08640 Valid. err. 4.18161 Time elapsed: 00:00:01
2018-02-08 13:59:33,029 training [INFO ] Epoch  1 Batch    0 Training err. 0.08449 Training err. RA 0.08630 Valid. err. 4.16852 Time elapsed: 00:00:01
2018-02-08 13:59:33,130 training [INFO ] Epoch  1 Batch    0 Training err. 0.08288 Training err. RA 0.08612 Valid. err. 4.15129 Time elapsed: 00:00:01
2018-02-08 13:59:33,216 training [INFO ] Epoch  1 Batch    0 Training err. 0.08328 Training err. RA 0.08598 Valid. err. 4.13676 Time elapsed: 00:00:01
2018-02-08 13:59:33,300 training [INFO ] Epoch  1 Batch    0 Training err. 0.08174 Training err. RA 0.08577 Valid. err. 4.11531 Time elapsed: 00:00:02
2018-02-08 13:59:33,395 training [INFO ] Epoch  1 Batch    0 Training err. 0.08228 Training err. RA 0.08561 Valid. err. 4.09993 Time elapsed: 00:00:02
2018-02-08 13:59:33,485 training [INFO ] Epoch  1 Batch    0 Training err. 0.08190 Training err. RA 0.08545 Valid. err. 4.08380 Time elapsed: 00:00:02
2018-02-08 13:59:33,573 training [INFO ] Epoch  1 Batch    0 Training err. 0.08158 Training err. RA 0.08529 Valid. err. 4.06445 Time elapsed: 00:00:02
2018-02-08 13:59:33,668 training [INFO ] Epoch  1 Batch    0 Training err. 0.08233 Training err. RA 0.08517 Valid. err. 4.04882 Time elapsed: 00:00:02
2018-02-08 13:59:33,754 training [INFO ] Epoch  1 Batch    0 Training err. 0.08047 Training err. RA 0.08499 Valid. err. 4.02848 Time elapsed: 00:00:02
2018-02-08 13:59:33,844 training [INFO ] Epoch  1 Batch    0 Training err. 0.08038 Training err. RA 0.08482 Valid. err. 4.01017 Time elapsed: 00:00:02
2018-02-08 13:59:33,940 training [INFO ] Epoch  1 Batch    0 Training err. 0.08103 Training err. RA 0.08469 Valid. err. 3.99128 Time elapsed: 00:00:02
2018-02-08 13:59:34,024 training [INFO ] Epoch  1 Batch    0 Training err. 0.07919 Training err. RA 0.08450 Valid. err. 3.96982 Time elapsed: 00:00:02
2018-02-08 13:59:34,116 training [INFO ] Epoch  1 Batch    0 Training err. 0.08118 Training err. RA 0.08439 Valid. err. 3.95435 Time elapsed: 00:00:02
2018-02-08 13:59:34,215 training [INFO ] Epoch  1 Batch    0 Training err. 0.07724 Training err. RA 0.08416 Valid. err. 3.93035 Time elapsed: 00:00:02
2018-02-08 13:59:34,301 training [INFO ] Epoch  1 Batch    0 Training err. 0.07864 Training err. RA 0.08398 Valid. err. 3.90755 Time elapsed: 00:00:03
2018-02-08 13:59:34,385 training [INFO ] Epoch  1 Batch    0 Training err. 0.07594 Training err. RA 0.08374 Valid. err. 3.88070 Time elapsed: 00:00:03
2018-02-08 13:59:34,488 training [INFO ] Epoch  1 Batch    0 Training err. 0.07768 Training err. RA 0.08356 Valid. err. 3.85716 Time elapsed: 00:00:03
2018-02-08 13:59:34,573 training [INFO ] Epoch  1 Batch    0 Training err. 0.07624 Training err. RA 0.08335 Valid. err. 3.83182 Time elapsed: 00:00:03
2018-02-08 13:59:34,658 training [INFO ] Epoch  1 Batch    0 Training err. 0.07624 Training err. RA 0.08315 Valid. err. 3.80098 Time elapsed: 00:00:03
2018-02-08 13:59:34,754 training [INFO ] Epoch  1 Batch    0 Training err. 0.07331 Training err. RA 0.08289 Valid. err. 3.77108 Time elapsed: 00:00:03
2018-02-08 13:59:34,844 training [INFO ] Epoch  1 Batch    0 Training err. 0.07490 Training err. RA 0.08268 Valid. err. 3.74491 Time elapsed: 00:00:03
2018-02-08 13:59:34,935 training [INFO ] Epoch  1 Batch    0 Training err. 0.07522 Training err. RA 0.08249 Valid. err. 3.72292 Time elapsed: 00:00:03
2018-02-08 13:59:35,031 training [INFO ] Epoch  1 Batch    0 Training err. 0.07506 Training err. RA 0.08230 Valid. err. 3.70037 Time elapsed: 00:00:03
2018-02-08 13:59:35,120 training [INFO ] Epoch  1 Batch    0 Training err. 0.07542 Training err. RA 0.08213 Valid. err. 3.67977 Time elapsed: 00:00:03
2018-02-08 13:59:35,211 training [INFO ] Epoch  1 Batch    0 Training err. 0.07281 Training err. RA 0.08191 Valid. err. 3.65584 Time elapsed: 00:00:03
2018-02-08 13:59:35,305 training [INFO ] Epoch  1 Batch    0 Training err. 0.07523 Training err. RA 0.08176 Valid. err. 3.63308 Time elapsed: 00:00:04
2018-02-08 13:59:35,391 training [INFO ] Epoch  1 Batch    0 Training err. 0.07182 Training err. RA 0.08153 Valid. err. 3.60888 Time elapsed: 00:00:04
2018-02-08 13:59:35,476 training [INFO ] Epoch  1 Batch    0 Training err. 0.07640 Training err. RA 0.08142 Valid. err. 3.59484 Time elapsed: 00:00:04
2018-02-08 13:59:35,577 training [INFO ] Epoch  1 Batch    0 Training err. 0.08069 Training err. RA 0.08140 Valid. err. 3.59233 Time elapsed: 00:00:04
2018-02-08 13:59:35,662 training [INFO ] Epoch  1 Batch    0 Training err. 0.07642 Training err. RA 0.08129 Valid. err. 3.57889 Time elapsed: 00:00:04
2018-02-08 13:59:35,747 training [INFO ] Epoch  1 Batch    0 Training err. 0.07389 Training err. RA 0.08114 Valid. err. 3.56203 Time elapsed: 00:00:04
2018-02-08 13:59:35,851 training [INFO ] Epoch  1 Batch    0 Training err. 0.07387 Training err. RA 0.08099 Valid. err. 3.54801 Time elapsed: 00:00:04
2018-02-08 13:59:35,936 training [INFO ] Epoch  1 Batch    0 Training err. 0.07070 Training err. RA 0.08079 Valid. err. 3.52866 Time elapsed: 00:00:04
2018-02-08 13:59:36,035 training [INFO ] Epoch  1 Batch    0 Training err. 0.07090 Training err. RA 0.08059 Valid. err. 3.51479 Time elapsed: 00:00:04
2018-02-08 13:59:36,140 training [INFO ] Epoch  1 Batch    0 Training err. 0.07031 Training err. RA 0.08039 Valid. err. 3.49887 Time elapsed: 00:00:04
2018-02-08 13:59:36,237 training [INFO ] Epoch  1 Batch    0 Training err. 0.07384 Training err. RA 0.08027 Valid. err. 3.48816 Time elapsed: 00:00:04
2018-02-08 13:59:36,326 training [INFO ] Epoch  1 Batch    0 Training err. 0.06984 Training err. RA 0.08008 Valid. err. 3.47571 Time elapsed: 00:00:05
2018-02-08 13:59:36,427 training [INFO ] Epoch  1 Batch    0 Training err. 0.06628 Training err. RA 0.07983 Valid. err. 3.46073 Time elapsed: 00:00:05
2018-02-08 13:59:36,531 training [INFO ] Epoch  1 Batch    0 Training err. 0.07117 Training err. RA 0.07967 Valid. err. 3.45164 Time elapsed: 00:00:05
2018-02-08 13:59:36,629 training [INFO ] Epoch  1 Batch    0 Training err. 0.06975 Training err. RA 0.07950 Valid. err. 3.44436 Time elapsed: 00:00:05
2018-02-08 13:59:36,727 training [INFO ] Epoch  1 Batch    0 Training err. 0.07011 Training err. RA 0.07934 Valid. err. 3.43051 Time elapsed: 00:00:05
2018-02-08 13:59:36,816 training [INFO ] Epoch  1 Batch    0 Training err. 0.06868 Training err. RA 0.07916 Valid. err. 3.42206 Time elapsed: 00:00:05
2018-02-08 13:59:36,915 training [INFO ] Epoch  1 Batch    0 Training err. 0.07092 Training err. RA 0.07902 Valid. err. 3.41830 Time elapsed: 00:00:05
2018-02-08 13:59:37,010 training [INFO ] Epoch  1 Batch    0 Training err. 0.06531 Training err. RA 0.07879 Valid. err. 3.40892 Time elapsed: 00:00:05
2018-02-08 13:59:37,106 training [INFO ] Epoch  1 Batch    0 Training err. 0.06904 Training err. RA 0.07864 Valid. err. 3.40595 Time elapsed: 00:00:05
2018-02-08 13:59:37,207 training [INFO ] Epoch  1 Batch    0 Training err. 0.06313 Training err. RA 0.07839 Valid. err. 3.39838 Time elapsed: 00:00:05
2018-02-08 13:59:37,305 training [INFO ] Epoch  1 Batch    0 Training err. 0.06540 Training err. RA 0.07819 Valid. err. 3.39346 Time elapsed: 00:00:06
2018-02-08 13:59:37,392 training [INFO ] Epoch  1 Batch    0 Training err. 0.06862 Training err. RA 0.07804 Valid. err. 3.39393 Time elapsed: 00:00:06
2018-02-08 13:59:37,479 training [INFO ] Epoch  1 Batch    0 Training err. 0.06469 Training err. RA 0.07784 Valid. err. 3.38375 Time elapsed: 00:00:06
2018-02-08 13:59:37,585 training [INFO ] Epoch  1 Batch    0 Training err. 0.07068 Training err. RA 0.07773 Valid. err. 3.37673 Time elapsed: 00:00:06
2018-02-08 13:59:37,683 training [INFO ] Epoch  1 Batch    0 Training err. 0.06733 Training err. RA 0.07758 Valid. err. 3.37561 Time elapsed: 00:00:06
2018-02-08 13:59:37,772 training [INFO ] Epoch  1 Batch    0 Training err. 0.06859 Training err. RA 0.07745 Valid. err. 3.37621 Time elapsed: 00:00:06
2018-02-08 13:59:37,875 training [INFO ] Epoch  1 Batch    0 Training err. 0.06227 Training err. RA 0.07723 Valid. err. 3.36972 Time elapsed: 00:00:06
2018-02-08 13:59:37,965 training [INFO ] Epoch  1 Batch    0 Training err. 0.06711 Training err. RA 0.07709 Valid. err. 3.36707 Time elapsed: 00:00:06
2018-02-08 13:59:38,059 training [INFO ] Epoch  1 Batch    0 Training err. 0.07172 Training err. RA 0.07701 Valid. err. 3.35900 Time elapsed: 00:00:06
2018-02-08 13:59:38,154 training [INFO ] Epoch  1 Batch    0 Training err. 0.06649 Training err. RA 0.07687 Valid. err. 3.34648 Time elapsed: 00:00:06
2018-02-08 13:59:38,252 training [INFO ] Epoch  1 Batch    0 Training err. 0.06385 Training err. RA 0.07669 Valid. err. 3.34038 Time elapsed: 00:00:07
2018-02-08 13:59:38,340 training [INFO ] Epoch  1 Batch    0 Training err. 0.06285 Training err. RA 0.07651 Valid. err. 3.33680 Time elapsed: 00:00:07
2018-02-08 13:59:38,439 training [INFO ] Epoch  1 Batch    0 Training err. 0.06319 Training err. RA 0.07633 Valid. err. 3.33338 Time elapsed: 00:00:07
2018-02-08 13:59:38,531 training [INFO ] Epoch  1 Batch    0 Training err. 0.06379 Training err. RA 0.07617 Valid. err. 3.33270 Time elapsed: 00:00:07
2018-02-08 13:59:38,618 training [INFO ] Epoch  1 Batch    0 Training err. 0.06513 Training err. RA 0.07603 Valid. err. 3.32995 Time elapsed: 00:00:07
2018-02-08 13:59:38,721 training [INFO ] Epoch  1 Batch    0 Training err. 0.06529 Training err. RA 0.07589 Valid. err. 3.32955 Time elapsed: 00:00:07
2018-02-08 13:59:38,806 training [INFO ] Epoch  1 Batch    0 Training err. 0.06562 Training err. RA 0.07577 Valid. err. 3.32458 Time elapsed: 00:00:07
2018-02-08 13:59:38,902 training [INFO ] Epoch  1 Batch    0 Training err. 0.06730 Training err. RA 0.07566 Valid. err. 3.31669 Time elapsed: 00:00:07
2018-02-08 13:59:38,999 training [INFO ] Epoch  1 Batch    0 Training err. 0.06774 Training err. RA 0.07556 Valid. err. 3.31136 Time elapsed: 00:00:07
2018-02-08 13:59:39,093 training [INFO ] Epoch  1 Batch    0 Training err. 0.06669 Training err. RA 0.07546 Valid. err. 3.31520 Time elapsed: 00:00:07
2018-02-08 13:59:39,177 training [INFO ] Epoch  1 Batch    0 Training err. 0.06931 Training err. RA 0.07538 Valid. err. 3.31893 Time elapsed: 00:00:07
2018-02-08 13:59:39,276 training [INFO ] Epoch  1 Batch    0 Training err. 0.06451 Training err. RA 0.07526 Valid. err. 3.30499 Time elapsed: 00:00:08
2018-02-08 13:59:39,364 training [INFO ] Epoch  1 Batch    0 Training err. 0.06880 Training err. RA 0.07518 Valid. err. 3.30700 Time elapsed: 00:00:08
2018-02-08 13:59:39,448 training [INFO ] Epoch  1 Batch    0 Training err. 0.06488 Training err. RA 0.07506 Valid. err. 3.30449 Time elapsed: 00:00:08
2018-02-08 13:59:39,550 training [INFO ] Epoch  1 Batch    0 Training err. 0.06536 Training err. RA 0.07495 Valid. err. 3.30907 Time elapsed: 00:00:08
2018-02-08 13:59:39,634 training [INFO ] Epoch  1 Batch    0 Training err. 0.06359 Training err. RA 0.07482 Valid. err. 3.31043 Time elapsed: 00:00:08
2018-02-08 13:59:39,719 training [INFO ] Epoch  1 Batch    0 Training err. 0.06500 Training err. RA 0.07472 Valid. err. 3.31226 Time elapsed: 00:00:08
2018-02-08 13:59:39,815 training [INFO ] Epoch  1 Batch    0 Training err. 0.06616 Training err. RA 0.07462 Valid. err. 3.31266 Time elapsed: 00:00:08
2018-02-08 13:59:39,908 training [INFO ] Epoch  1 Batch    0 Training err. 0.06350 Training err. RA 0.07450 Valid. err. 3.30716 Time elapsed: 00:00:08
2018-02-08 13:59:39,991 training [INFO ] Epoch  1 Batch    0 Training err. 0.06582 Training err. RA 0.07441 Valid. err. 3.30787 Time elapsed: 00:00:08
2018-02-08 13:59:40,092 training [INFO ] Epoch  1 Batch    0 Training err. 0.07017 Training err. RA 0.07436 Valid. err. 3.30468 Time elapsed: 00:00:08
2018-02-08 13:59:40,175 training [INFO ] Epoch  1 Batch    0 Training err. 0.06339 Training err. RA 0.07425 Valid. err. 3.30886 Time elapsed: 00:00:08
2018-02-08 13:59:40,263 training [INFO ] Epoch  1 Batch    0 Training err. 0.06621 Training err. RA 0.07416 Valid. err. 3.31760 Time elapsed: 00:00:09
2018-02-08 13:59:40,357 training [INFO ] Epoch  1 Batch    0 Training err. 0.06588 Training err. RA 0.07408 Valid. err. 3.31244 Time elapsed: 00:00:09
2018-02-08 13:59:40,441 training [INFO ] Epoch  1 Batch    0 Training err. 0.06623 Training err. RA 0.07400 Valid. err. 3.30814 Time elapsed: 00:00:09
2018-02-08 13:59:40,553 training [INFO ] Epoch  1 Batch    0 Training err. 0.07363 Training err. RA 0.07399 Valid. err. 3.30054 Time elapsed: 00:00:09
2018-02-08 13:59:40,650 training [INFO ] Epoch  1 Batch    0 Training err. 0.06667 Training err. RA 0.07392 Valid. err. 3.29318 Time elapsed: 00:00:09
2018-02-08 13:59:40,735 training [INFO ] Epoch  1 Batch    0 Training err. 0.06089 Training err. RA 0.07379 Valid. err. 3.29414 Time elapsed: 00:00:09
2018-02-08 13:59:40,818 training [INFO ] Epoch  1 Batch    0 Training err. 0.06485 Training err. RA 0.07370 Valid. err. 3.30238 Time elapsed: 00:00:09
2018-02-08 13:59:40,917 training [INFO ] Epoch  1 Batch    0 Training err. 0.07619 Training err. RA 0.07373 Valid. err. 3.29094 Time elapsed: 00:00:09
2018-02-08 13:59:41,002 training [INFO ] Epoch  1 Batch    0 Training err. 0.06849 Training err. RA 0.07368 Valid. err. 3.29238 Time elapsed: 00:00:09
2018-02-08 13:59:41,091 training [INFO ] Epoch  1 Batch    0 Training err. 0.06720 Training err. RA 0.07362 Valid. err. 3.29617 Time elapsed: 00:00:09
2018-02-08 13:59:41,187 training [INFO ] Epoch  1 Batch    0 Training err. 0.06133 Training err. RA 0.07350 Valid. err. 3.29030 Time elapsed: 00:00:09
2018-02-08 13:59:41,275 training [INFO ] Epoch  1 Batch    0 Training err. 0.06452 Training err. RA 0.07342 Valid. err. 3.30220 Time elapsed: 00:00:10
2018-02-08 13:59:41,361 training [INFO ] Epoch  1 Batch    0 Training err. 0.06195 Training err. RA 0.07331 Valid. err. 3.29480 Time elapsed: 00:00:10
2018-02-08 13:59:41,456 training [INFO ] Epoch  1 Batch    0 Training err. 0.06647 Training err. RA 0.07325 Valid. err. 3.28131 Time elapsed: 00:00:10
2018-02-08 13:59:41,546 training [INFO ] Epoch  1 Batch    0 Training err. 0.06639 Training err. RA 0.07319 Valid. err. 3.28899 Time elapsed: 00:00:10
2018-02-08 13:59:41,629 training [INFO ] Epoch  1 Batch    0 Training err. 0.06574 Training err. RA 0.07312 Valid. err. 3.27725 Time elapsed: 00:00:10
2018-02-08 13:59:41,729 training [INFO ] Epoch  1 Batch    0 Training err. 0.06239 Training err. RA 0.07302 Valid. err. 3.27695 Time elapsed: 00:00:10
2018-02-08 13:59:41,814 training [INFO ] Epoch  1 Batch    0 Training err. 0.06485 Training err. RA 0.07295 Valid. err. 3.27697 Time elapsed: 00:00:10
2018-02-08 13:59:41,902 training [INFO ] Epoch  1 Batch    0 Training err. 0.06266 Training err. RA 0.07286 Valid. err. 3.28001 Time elapsed: 00:00:10
2018-02-08 13:59:41,994 training [INFO ] Epoch  1 Batch    0 Training err. 0.07308 Training err. RA 0.07286 Valid. err. 3.27230 Time elapsed: 00:00:10
2018-02-08 13:59:42,085 training [INFO ] Epoch  1 Batch    0 Training err. 0.05826 Training err. RA 0.07274 Valid. err. 3.27629 Time elapsed: 00:00:10
2018-02-08 13:59:42,168 training [INFO ] Epoch  1 Batch    0 Training err. 0.06406 Training err. RA 0.07266 Valid. err. 3.27596 Time elapsed: 00:00:10
2018-02-08 13:59:42,265 training [INFO ] Epoch  1 Batch    0 Training err. 0.06165 Training err. RA 0.07257 Valid. err. 3.28611 Time elapsed: 00:00:11
2018-02-08 13:59:42,348 training [INFO ] Epoch  1 Batch    0 Training err. 0.05799 Training err. RA 0.07245 Valid. err. 3.28953 Time elapsed: 00:00:11
2018-02-08 13:59:42,433 training [INFO ] Epoch  1 Batch    0 Training err. 0.06559 Training err. RA 0.07239 Valid. err. 3.27672 Time elapsed: 00:00:11
2018-02-08 13:59:42,527 training [INFO ] Epoch  1 Batch    0 Training err. 0.07102 Training err. RA 0.07238 Valid. err. 3.28261 Time elapsed: 00:00:11
2018-02-08 13:59:42,616 training [INFO ] Epoch  1 Batch    0 Training err. 0.06461 Training err. RA 0.07231 Valid. err. 3.27912 Time elapsed: 00:00:11
2018-02-08 13:59:42,699 training [INFO ] Epoch  1 Batch    0 Training err. 0.06044 Training err. RA 0.07222 Valid. err. 3.26717 Time elapsed: 00:00:11
2018-02-08 13:59:42,797 training [INFO ] Epoch  1 Batch    0 Training err. 0.06286 Training err. RA 0.07214 Valid. err. 3.27941 Time elapsed: 00:00:11
2018-02-08 13:59:42,883 training [INFO ] Epoch  1 Batch    0 Training err. 0.06288 Training err. RA 0.07207 Valid. err. 3.29554 Time elapsed: 00:00:11
2018-02-08 13:59:42,972 training [INFO ] Epoch  1 Batch    0 Training err. 0.07070 Training err. RA 0.07206 Valid. err. 3.28008 Time elapsed: 00:00:11
2018-02-08 13:59:43,072 training [INFO ] Epoch  1 Batch    0 Training err. 0.06085 Training err. RA 0.07197 Valid. err. 3.27394 Time elapsed: 00:00:11
2018-02-08 13:59:43,155 training [INFO ] Epoch  1 Batch    0 Training err. 0.06088 Training err. RA 0.07188 Valid. err. 3.27640 Time elapsed: 00:00:11
2018-02-08 13:59:43,248 training [INFO ] Epoch  1 Batch    0 Training err. 0.06052 Training err. RA 0.07179 Valid. err. 3.28025 Time elapsed: 00:00:11
2018-02-08 13:59:43,340 training [INFO ] Epoch  1 Batch    0 Training err. 0.06569 Training err. RA 0.07175 Valid. err. 3.27610 Time elapsed: 00:00:12
2018-02-08 13:59:43,423 training [INFO ] Epoch  1 Batch    0 Training err. 0.06557 Training err. RA 0.07170 Valid. err. 3.27056 Time elapsed: 00:00:12
2018-02-08 13:59:43,506 training [INFO ] Epoch  1 Batch    0 Training err. 0.06674 Training err. RA 0.07166 Valid. err. 3.26892 Time elapsed: 00:00:12
2018-02-08 13:59:43,604 training [INFO ] Epoch  1 Batch    0 Training err. 0.06288 Training err. RA 0.07160 Valid. err. 3.26442 Time elapsed: 00:00:12
2018-02-08 13:59:43,689 training [INFO ] Epoch  1 Batch    0 Training err. 0.07049 Training err. RA 0.07159 Valid. err. 3.26207 Time elapsed: 00:00:12
2018-02-08 13:59:43,774 training [INFO ] Epoch  1 Batch    0 Training err. 0.06179 Training err. RA 0.07152 Valid. err. 3.26174 Time elapsed: 00:00:12
2018-02-08 13:59:43,869 training [INFO ] Epoch  1 Batch    0 Training err. 0.06181 Training err. RA 0.07144 Valid. err. 3.26083 Time elapsed: 00:00:12
2018-02-08 13:59:43,963 training [INFO ] Epoch  1 Batch    0 Training err. 0.07199 Training err. RA 0.07145 Valid. err. 3.25951 Time elapsed: 00:00:12
2018-02-08 13:59:44,048 training [INFO ] Epoch  1 Batch    0 Training err. 0.06178 Training err. RA 0.07138 Valid. err. 3.26407 Time elapsed: 00:00:12
2018-02-08 13:59:44,146 training [INFO ] Epoch  1 Batch    0 Training err. 0.06548 Training err. RA 0.07134 Valid. err. 3.26809 Time elapsed: 00:00:12
2018-02-08 13:59:44,233 training [INFO ] Epoch  1 Batch    0 Training err. 0.06978 Training err. RA 0.07132 Valid. err. 3.26436 Time elapsed: 00:00:12
2018-02-08 13:59:44,316 training [INFO ] Epoch  1 Batch    0 Training err. 0.06870 Training err. RA 0.07131 Valid. err. 3.25771 Time elapsed: 00:00:13
2018-02-08 13:59:44,413 training [INFO ] Epoch  1 Batch    0 Training err. 0.06191 Training err. RA 0.07124 Valid. err. 3.24927 Time elapsed: 00:00:13
2018-02-08 13:59:44,498 training [INFO ] Epoch  1 Batch    0 Training err. 0.06518 Training err. RA 0.07120 Valid. err. 3.25192 Time elapsed: 00:00:13
2018-02-08 13:59:44,588 training [INFO ] Epoch  1 Batch    0 Training err. 0.06706 Training err. RA 0.07117 Valid. err. 3.25562 Time elapsed: 00:00:13
2018-02-08 13:59:44,680 training [INFO ] Epoch  1 Batch    0 Training err. 0.05970 Training err. RA 0.07109 Valid. err. 3.25869 Time elapsed: 00:00:13
2018-02-08 13:59:44,764 training [INFO ] Epoch  1 Batch    0 Training err. 0.06427 Training err. RA 0.07104 Valid. err. 3.25294 Time elapsed: 00:00:13
2018-02-08 13:59:44,848 training [INFO ] Epoch  1 Batch    0 Training err. 0.07189 Training err. RA 0.07105 Valid. err. 3.25402 Time elapsed: 00:00:13
2018-02-08 13:59:44,944 training [INFO ] Epoch  1 Batch    0 Training err. 0.06276 Training err. RA 0.07099 Valid. err. 3.25610 Time elapsed: 00:00:13
2018-02-08 13:59:45,027 training [INFO ] Epoch  1 Batch    0 Training err. 0.06127 Training err. RA 0.07093 Valid. err. 3.26696 Time elapsed: 00:00:13
2018-02-08 13:59:45,115 training [INFO ] Epoch  1 Batch    0 Training err. 0.06252 Training err. RA 0.07087 Valid. err. 3.28342 Time elapsed: 00:00:13
2018-02-08 13:59:45,211 training [INFO ] Epoch  1 Batch    0 Training err. 0.06247 Training err. RA 0.07082 Valid. err. 3.26048 Time elapsed: 00:00:13
2018-02-08 13:59:45,301 training [INFO ] Epoch  1 Batch    0 Training err. 0.05924 Training err. RA 0.07074 Valid. err. 3.26689 Time elapsed: 00:00:14
2018-02-08 13:59:45,385 training [INFO ] Epoch  1 Batch    0 Training err. 0.06685 Training err. RA 0.07071 Valid. err. 3.26192 Time elapsed: 00:00:14
2018-02-08 13:59:45,482 training [INFO ] Epoch  1 Batch    0 Training err. 0.06270 Training err. RA 0.07066 Valid. err. 3.25982 Time elapsed: 00:00:14
2018-02-08 13:59:45,572 training [INFO ] Epoch  1 Batch    0 Training err. 0.06069 Training err. RA 0.07060 Valid. err. 3.26063 Time elapsed: 00:00:14
2018-02-08 13:59:45,658 training [INFO ] Epoch  1 Batch    0 Training err. 0.06585 Training err. RA 0.07057 Valid. err. 3.25579 Time elapsed: 00:00:14
2018-02-08 13:59:45,756 training [INFO ] Epoch  1 Batch    0 Training err. 0.06096 Training err. RA 0.07051 Valid. err. 3.26210 Time elapsed: 00:00:14
2018-02-08 13:59:45,840 training [INFO ] Epoch  1 Batch    0 Training err. 0.06078 Training err. RA 0.07044 Valid. err. 3.25632 Time elapsed: 00:00:14
2018-02-08 13:59:45,933 training [INFO ] Epoch  1 Batch    0 Training err. 0.07627 Training err. RA 0.07048 Valid. err. 3.26354 Time elapsed: 00:00:14
2018-02-08 13:59:46,028 training [INFO ] Epoch  1 Batch    0 Training err. 0.06094 Training err. RA 0.07042 Valid. err. 3.25276 Time elapsed: 00:00:14
2018-02-08 13:59:46,120 training [INFO ] Epoch  1 Batch    0 Training err. 0.06496 Training err. RA 0.07039 Valid. err. 3.24655 Time elapsed: 00:00:14
2018-02-08 13:59:46,208 training [INFO ] Epoch  1 Batch    0 Training err. 0.06147 Training err. RA 0.07033 Valid. err. 3.25795 Time elapsed: 00:00:14
2018-02-08 13:59:46,329 training [INFO ] Epoch  1 Batch    0 Training err. 0.06342 Training err. RA 0.07029 Valid. err. 3.26760 Time elapsed: 00:00:15
2018-02-08 13:59:46,412 training [INFO ] Epoch  1 Batch    0 Training err. 0.06396 Training err. RA 0.07025 Valid. err. 3.24864 Time elapsed: 00:00:15
2018-02-08 13:59:46,495 training [INFO ] Epoch  1 Batch    0 Training err. 0.06813 Training err. RA 0.07024 Valid. err. 3.25165 Time elapsed: 00:00:15
2018-02-08 13:59:46,598 training [INFO ] Epoch  1 Batch    0 Training err. 0.06638 Training err. RA 0.07022 Valid. err. 3.26126 Time elapsed: 00:00:15
2018-02-08 13:59:46,681 training [INFO ] Epoch  1 Batch    0 Training err. 0.07073 Training err. RA 0.07022 Valid. err. 3.26882 Time elapsed: 00:00:15
2018-02-08 13:59:46,765 training [INFO ] Epoch  1 Batch    0 Training err. 0.05882 Training err. RA 0.07015 Valid. err. 3.25235 Time elapsed: 00:00:15
2018-02-08 13:59:46,863 training [INFO ] Epoch  1 Batch    0 Training err. 0.07009 Training err. RA 0.07015 Valid. err. 3.26911 Time elapsed: 00:00:15
2018-02-08 13:59:46,956 training [INFO ] Epoch  1 Batch    0 Training err. 0.06348 Training err. RA 0.07011 Valid. err. 3.26868 Time elapsed: 00:00:15
2018-02-08 13:59:47,039 training [INFO ] Epoch  1 Batch    0 Training err. 0.05860 Training err. RA 0.07004 Valid. err. 3.27438 Time elapsed: 00:00:15
2018-02-08 13:59:47,139 training [INFO ] Epoch  1 Batch    0 Training err. 0.06935 Training err. RA 0.07004 Valid. err. 3.26401 Time elapsed: 00:00:15
2018-02-08 13:59:47,223 training [INFO ] Epoch  1 Batch    0 Training err. 0.06435 Training err. RA 0.07001 Valid. err. 3.25372 Time elapsed: 00:00:15
2018-02-08 13:59:47,315 training [INFO ] Epoch  1 Batch    0 Training err. 0.05663 Training err. RA 0.06993 Valid. err. 3.25054 Time elapsed: 00:00:16
2018-02-08 13:59:47,409 training [INFO ] Epoch  1 Batch    0 Training err. 0.06919 Training err. RA 0.06993 Valid. err. 3.24230 Time elapsed: 00:00:16
2018-02-08 13:59:47,494 training [INFO ] Epoch  1 Batch    0 Training err. 0.06552 Training err. RA 0.06990 Valid. err. 3.25006 Time elapsed: 00:00:16
2018-02-08 13:59:47,578 training [INFO ] Epoch  1 Batch    0 Training err. 0.07128 Training err. RA 0.06991 Valid. err. 3.25480 Time elapsed: 00:00:16
2018-02-08 13:59:47,678 training [INFO ] Epoch  1 Batch    0 Training err. 0.06710 Training err. RA 0.06989 Valid. err. 3.24932 Time elapsed: 00:00:16
2018-02-08 13:59:47,761 training [INFO ] Epoch  1 Batch    0 Training err. 0.05941 Training err. RA 0.06983 Valid. err. 3.25418 Time elapsed: 00:00:16
2018-02-08 13:59:47,848 training [INFO ] Epoch  1 Batch    0 Training err. 0.06882 Training err. RA 0.06983 Valid. err. 3.25294 Time elapsed: 00:00:16
2018-02-08 13:59:47,946 training [INFO ] Epoch  1 Batch    0 Training err. 0.06779 Training err. RA 0.06982 Valid. err. 3.24448 Time elapsed: 00:00:16
2018-02-08 13:59:48,030 training [INFO ] Epoch  1 Batch    0 Training err. 0.06781 Training err. RA 0.06981 Valid. err. 3.23915 Time elapsed: 00:00:16
2018-02-08 13:59:48,121 training [INFO ] Epoch  1 Batch    0 Training err. 0.06016 Training err. RA 0.06975 Valid. err. 3.24297 Time elapsed: 00:00:16
2018-02-08 13:59:48,220 training [INFO ] Epoch  1 Batch    0 Training err. 0.06545 Training err. RA 0.06973 Valid. err. 3.23665 Time elapsed: 00:00:16
2018-02-08 13:59:48,311 training [INFO ] Epoch  1 Batch    0 Training err. 0.06646 Training err. RA 0.06971 Valid. err. 3.23712 Time elapsed: 00:00:17
2018-02-08 13:59:48,394 training [INFO ] Epoch  1 Batch    0 Training err. 0.06184 Training err. RA 0.06967 Valid. err. 3.23164 Time elapsed: 00:00:17
2018-02-08 13:59:48,487 training [INFO ] Epoch  1 Batch    0 Training err. 0.07107 Training err. RA 0.06968 Valid. err. 3.24407 Time elapsed: 00:00:17
2018-02-08 13:59:48,570 training [INFO ] Epoch  1 Batch    0 Training err. 0.06528 Training err. RA 0.06965 Valid. err. 3.23393 Time elapsed: 00:00:17
2018-02-08 13:59:48,659 training [INFO ] Epoch  1 Batch    0 Training err. 0.06115 Training err. RA 0.06961 Valid. err. 3.24893 Time elapsed: 00:00:17
2018-02-08 13:59:48,755 training [INFO ] Epoch  1 Batch    0 Training err. 0.06480 Training err. RA 0.06958 Valid. err. 3.24534 Time elapsed: 00:00:17
2018-02-08 13:59:48,838 training [INFO ] Epoch  1 Batch    0 Training err. 0.06393 Training err. RA 0.06955 Valid. err. 3.25002 Time elapsed: 00:00:17
2018-02-08 13:59:48,931 training [INFO ] Epoch  1 Batch    0 Training err. 0.05804 Training err. RA 0.06949 Valid. err. 3.25218 Time elapsed: 00:00:17
2018-02-08 13:59:49,027 training [INFO ] Epoch  1 Batch    0 Training err. 0.06798 Training err. RA 0.06949 Valid. err. 3.26142 Time elapsed: 00:00:17
2018-02-08 13:59:49,116 training [INFO ] Epoch  1 Batch    0 Training err. 0.07562 Training err. RA 0.06952 Valid. err. 3.27763 Time elapsed: 00:00:17
2018-02-08 13:59:49,199 training [INFO ] Epoch  1 Batch    0 Training err. 0.06389 Training err. RA 0.06949 Valid. err. 3.25588 Time elapsed: 00:00:17
2018-02-08 13:59:49,298 training [INFO ] Epoch  1 Batch    0 Training err. 0.06591 Training err. RA 0.06947 Valid. err. 3.26540 Time elapsed: 00:00:18
2018-02-08 13:59:49,382 training [INFO ] Epoch  1 Batch    0 Training err. 0.06098 Training err. RA 0.06943 Valid. err. 3.25499 Time elapsed: 00:00:18
2018-02-08 13:59:49,465 training [INFO ] Epoch  1 Batch    0 Training err. 0.06317 Training err. RA 0.06940 Valid. err. 3.25714 Time elapsed: 00:00:18
2018-02-08 13:59:49,561 training [INFO ] Epoch  1 Batch    0 Training err. 0.06449 Training err. RA 0.06937 Valid. err. 3.25584 Time elapsed: 00:00:18
2018-02-08 13:59:49,649 training [INFO ] Epoch  1 Batch    0 Training err. 0.06399 Training err. RA 0.06934 Valid. err. 3.24676 Time elapsed: 00:00:18
2018-02-08 13:59:49,733 training [INFO ] Epoch  1 Batch    0 Training err. 0.06216 Training err. RA 0.06931 Valid. err. 3.26155 Time elapsed: 00:00:18
2018-02-08 13:59:49,827 training [INFO ] Epoch  1 Batch    0 Training err. 0.06733 Training err. RA 0.06930 Valid. err. 3.24817 Time elapsed: 00:00:18
2018-02-08 13:59:49,916 training [INFO ] Epoch  1 Batch    0 Training err. 0.06355 Training err. RA 0.06927 Valid. err. 3.26734 Time elapsed: 00:00:18
2018-02-08 13:59:50,004 training [INFO ] Epoch  1 Batch    0 Training err. 0.06261 Training err. RA 0.06924 Valid. err. 3.25556 Time elapsed: 00:00:18
2018-02-08 13:59:50,101 training [INFO ] Epoch  1 Batch    0 Training err. 0.06397 Training err. RA 0.06921 Valid. err. 3.24006 Time elapsed: 00:00:18
2018-02-08 13:59:50,184 training [INFO ] Epoch  1 Batch    0 Training err. 0.06597 Training err. RA 0.06920 Valid. err. 3.24289 Time elapsed: 00:00:18
2018-02-08 13:59:50,269 training [INFO ] Epoch  1 Batch    0 Training err. 0.06363 Training err. RA 0.06917 Valid. err. 3.24268 Time elapsed: 00:00:19
2018-02-08 13:59:50,381 training [INFO ] Epoch  1 Batch    0 Training err. 0.07019 Training err. RA 0.06917 Valid. err. 3.24215 Time elapsed: 00:00:19
2018-02-08 13:59:50,465 training [INFO ] Epoch  1 Batch    0 Training err. 0.06692 Training err. RA 0.06916 Valid. err. 3.24791 Time elapsed: 00:00:19
2018-02-08 13:59:50,548 training [INFO ] Epoch  1 Batch    0 Training err. 0.06272 Training err. RA 0.06913 Valid. err. 3.25908 Time elapsed: 00:00:19
2018-02-08 13:59:50,646 training [INFO ] Epoch  1 Batch    0 Training err. 0.06575 Training err. RA 0.06912 Valid. err. 3.24377 Time elapsed: 00:00:19
2018-02-08 13:59:50,729 training [INFO ] Epoch  1 Batch    0 Training err. 0.06210 Training err. RA 0.06908 Valid. err. 3.23949 Time elapsed: 00:00:19
2018-02-08 13:59:50,812 training [INFO ] Epoch  1 Batch    0 Training err. 0.06355 Training err. RA 0.06906 Valid. err. 3.24438 Time elapsed: 00:00:19
2018-02-08 13:59:50,908 training [INFO ] Epoch  1 Batch    0 Training err. 0.06035 Training err. RA 0.06902 Valid. err. 3.25119 Time elapsed: 00:00:19
2018-02-08 13:59:50,997 training [INFO ] Epoch  1 Batch    0 Training err. 0.06410 Training err. RA 0.06899 Valid. err. 3.25155 Time elapsed: 00:00:19
2018-02-08 13:59:51,086 training [INFO ] Epoch  1 Batch    0 Training err. 0.06216 Training err. RA 0.06896 Valid. err. 3.24948 Time elapsed: 00:00:19
2018-02-08 13:59:51,181 training [INFO ] Epoch  1 Batch    0 Training err. 0.06360 Training err. RA 0.06894 Valid. err. 3.24475 Time elapsed: 00:00:19
2018-02-08 13:59:51,265 training [INFO ] Epoch  1 Batch    0 Training err. 0.06360 Training err. RA 0.06891 Valid. err. 3.24360 Time elapsed: 00:00:20
2018-02-08 13:59:51,354 training [INFO ] Epoch  1 Batch    0 Training err. 0.06266 Training err. RA 0.06888 Valid. err. 3.25210 Time elapsed: 00:00:20
2018-02-08 13:59:51,453 training [INFO ] Epoch  1 Batch    0 Training err. 0.06204 Training err. RA 0.06885 Valid. err. 3.24606 Time elapsed: 00:00:20
2018-02-08 13:59:51,536 training [INFO ] Epoch  1 Batch    0 Training err. 0.06355 Training err. RA 0.06883 Valid. err. 3.24112 Time elapsed: 00:00:20
2018-02-08 13:59:51,623 training [INFO ] Epoch  1 Batch    0 Training err. 0.06985 Training err. RA 0.06883 Valid. err. 3.24565 Time elapsed: 00:00:20
2018-02-08 13:59:51,722 training [INFO ] Epoch  1 Batch    0 Training err. 0.06457 Training err. RA 0.06882 Valid. err. 3.24693 Time elapsed: 00:00:20
2018-02-08 13:59:51,813 training [INFO ] Epoch  1 Batch    0 Training err. 0.06074 Training err. RA 0.06878 Valid. err. 3.24878 Time elapsed: 00:00:20
2018-02-08 13:59:51,903 training [INFO ] Epoch  1 Batch    0 Training err. 0.06624 Training err. RA 0.06877 Valid. err. 3.23816 Time elapsed: 00:00:20
2018-02-08 13:59:52,001 training [INFO ] Epoch  1 Batch    0 Training err. 0.05941 Training err. RA 0.06873 Valid. err. 3.24418 Time elapsed: 00:00:20
2018-02-08 13:59:52,090 training [INFO ] Epoch  1 Batch    0 Training err. 0.06445 Training err. RA 0.06871 Valid. err. 3.24443 Time elapsed: 00:00:20
2018-02-08 13:59:52,173 training [INFO ] Epoch  1 Batch    0 Training err. 0.06004 Training err. RA 0.06867 Valid. err. 3.25746 Time elapsed: 00:00:20
2018-02-08 13:59:52,268 training [INFO ] Epoch  1 Batch    0 Training err. 0.06340 Training err. RA 0.06865 Valid. err. 3.25887 Time elapsed: 00:00:21
2018-02-08 13:59:52,357 training [INFO ] Epoch  1 Batch    0 Training err. 0.06138 Training err. RA 0.06862 Valid. err. 3.25760 Time elapsed: 00:00:21
2018-02-08 13:59:52,440 training [INFO ] Epoch  1 Batch    0 Training err. 0.06083 Training err. RA 0.06858 Valid. err. 3.25006 Time elapsed: 00:00:21
2018-02-08 13:59:52,532 training [INFO ] Epoch  1 Batch    0 Training err. 0.06759 Training err. RA 0.06858 Valid. err. 3.25628 Time elapsed: 00:00:21
2018-02-08 13:59:52,615 training [INFO ] Epoch  1 Batch    0 Training err. 0.05845 Training err. RA 0.06853 Valid. err. 3.26597 Time elapsed: 00:00:21
2018-02-08 13:59:52,711 training [INFO ] Epoch  1 Batch    0 Training err. 0.07048 Training err. RA 0.06854 Valid. err. 3.25249 Time elapsed: 00:00:21
2018-02-08 13:59:52,825 training [INFO ] Epoch  1 Batch    0 Training err. 0.06372 Training err. RA 0.06852 Valid. err. 3.24452 Time elapsed: 00:00:21
2018-02-08 13:59:52,917 training [INFO ] Epoch  1 Batch    0 Training err. 0.06143 Training err. RA 0.06849 Valid. err. 3.24345 Time elapsed: 00:00:21
2018-02-08 13:59:53,013 training [INFO ] Epoch  1 Batch    0 Training err. 0.06855 Training err. RA 0.06849 Valid. err. 3.23452 Time elapsed: 00:00:21
2018-02-08 13:59:53,116 training [INFO ] Epoch  1 Batch    0 Training err. 0.06446 Training err. RA 0.06847 Valid. err. 3.23712 Time elapsed: 00:00:21
2018-02-08 13:59:53,202 training [INFO ] Epoch  1 Batch    0 Training err. 0.06699 Training err. RA 0.06847 Valid. err. 3.25199 Time elapsed: 00:00:21
2018-02-08 13:59:53,298 training [INFO ] Epoch  1 Batch    0 Training err. 0.05870 Training err. RA 0.06843 Valid. err. 3.27131 Time elapsed: 00:00:22
2018-02-08 13:59:53,406 training [INFO ] Epoch  1 Batch    0 Training err. 0.06685 Training err. RA 0.06842 Valid. err. 3.28671 Time elapsed: 00:00:22
2018-02-08 13:59:53,491 training [INFO ] Epoch  1 Batch    0 Training err. 0.07014 Training err. RA 0.06843 Valid. err. 3.25731 Time elapsed: 00:00:22
2018-02-08 13:59:53,575 training [INFO ] Epoch  1 Batch    0 Training err. 0.06786 Training err. RA 0.06843 Valid. err. 3.26297 Time elapsed: 00:00:22
2018-02-08 13:59:53,674 training [INFO ] Epoch  1 Batch    0 Training err. 0.05944 Training err. RA 0.06839 Valid. err. 3.27464 Time elapsed: 00:00:22
2018-02-08 13:59:53,758 training [INFO ] Epoch  1 Batch    0 Training err. 0.06698 Training err. RA 0.06838 Valid. err. 3.26656 Time elapsed: 00:00:22
2018-02-08 13:59:53,844 training [INFO ] Epoch  1 Batch    0 Training err. 0.06235 Training err. RA 0.06836 Valid. err. 3.25589 Time elapsed: 00:00:22
2018-02-08 13:59:53,940 training [INFO ] Epoch  1 Batch    0 Training err. 0.06204 Training err. RA 0.06833 Valid. err. 3.25675 Time elapsed: 00:00:22
2018-02-08 13:59:54,035 training [INFO ] Epoch  1 Batch    0 Training err. 0.06369 Training err. RA 0.06831 Valid. err. 3.26036 Time elapsed: 00:00:22
2018-02-08 13:59:54,135 training [INFO ] Epoch  1 Batch    0 Training err. 0.06029 Training err. RA 0.06828 Valid. err. 3.24644 Time elapsed: 00:00:22
2018-02-08 13:59:54,231 training [INFO ] Epoch  1 Batch    0 Training err. 0.05999 Training err. RA 0.06825 Valid. err. 3.25085 Time elapsed: 00:00:22
2018-02-08 13:59:54,324 training [INFO ] Epoch  1 Batch    0 Training err. 0.07221 Training err. RA 0.06827 Valid. err. 3.23702 Time elapsed: 00:00:23
2018-02-08 13:59:54,409 training [INFO ] Epoch  1 Batch    0 Training err. 0.05935 Training err. RA 0.06823 Valid. err. 3.23580 Time elapsed: 00:00:23
2018-02-08 13:59:54,503 training [INFO ] Epoch  1 Batch    0 Training err. 0.06408 Training err. RA 0.06821 Valid. err. 3.24061 Time elapsed: 00:00:23
2018-02-08 13:59:54,591 training [INFO ] Epoch  1 Batch    0 Training err. 0.07608 Training err. RA 0.06824 Valid. err. 3.23797 Time elapsed: 00:00:23
2018-02-08 13:59:54,688 training [INFO ] Epoch  1 Batch    0 Training err. 0.06622 Training err. RA 0.06824 Valid. err. 3.23600 Time elapsed: 00:00:23
2018-02-08 13:59:54,789 training [INFO ] Epoch  1 Batch    0 Training err. 0.06753 Training err. RA 0.06823 Valid. err. 3.23543 Time elapsed: 00:00:23
2018-02-08 13:59:54,874 training [INFO ] Epoch  1 Batch    0 Training err. 0.06330 Training err. RA 0.06821 Valid. err. 3.23307 Time elapsed: 00:00:23
2018-02-08 13:59:54,963 training [INFO ] Epoch  1 Batch    0 Training err. 0.06907 Training err. RA 0.06822 Valid. err. 3.23147 Time elapsed: 00:00:23
2018-02-08 13:59:55,066 training [INFO ] Epoch  1 Batch    0 Training err. 0.06641 Training err. RA 0.06821 Valid. err. 3.24086 Time elapsed: 00:00:23
2018-02-08 13:59:55,150 training [INFO ] Epoch  1 Batch    0 Training err. 0.06334 Training err. RA 0.06819 Valid. err. 3.24854 Time elapsed: 00:00:23
2018-02-08 13:59:55,236 training [INFO ] Epoch  1 Batch    0 Training err. 0.06607 Training err. RA 0.06818 Valid. err. 3.24417 Time elapsed: 00:00:23
2018-02-08 13:59:55,337 training [INFO ] Epoch  1 Batch    0 Training err. 0.06224 Training err. RA 0.06816 Valid. err. 3.24509 Time elapsed: 00:00:24
2018-02-08 13:59:55,420 training [INFO ] Epoch  1 Batch    0 Training err. 0.05970 Training err. RA 0.06813 Valid. err. 3.23833 Time elapsed: 00:00:24
2018-02-08 13:59:55,503 training [INFO ] Epoch  1 Batch    0 Training err. 0.06965 Training err. RA 0.06813 Valid. err. 3.24931 Time elapsed: 00:00:24
2018-02-08 13:59:55,597 training [INFO ] Epoch  1 Batch    0 Training err. 0.05880 Training err. RA 0.06810 Valid. err. 3.25062 Time elapsed: 00:00:24
2018-02-08 13:59:55,686 training [INFO ] Epoch  1 Batch    0 Training err. 0.06538 Training err. RA 0.06809 Valid. err. 3.25071 Time elapsed: 00:00:24
2018-02-08 13:59:55,769 training [INFO ] Epoch  1 Batch    0 Training err. 0.06043 Training err. RA 0.06806 Valid. err. 3.25820 Time elapsed: 00:00:24
2018-02-08 13:59:55,863 training [INFO ] Epoch  1 Batch    0 Training err. 0.06606 Training err. RA 0.06805 Valid. err. 3.24382 Time elapsed: 00:00:24
2018-02-08 13:59:55,951 training [INFO ] Epoch  1 Batch    0 Training err. 0.06091 Training err. RA 0.06803 Valid. err. 3.24215 Time elapsed: 00:00:24
2018-02-08 13:59:56,039 training [INFO ] Epoch  1 Batch    0 Training err. 0.07066 Training err. RA 0.06804 Valid. err. 3.23952 Time elapsed: 00:00:24
2018-02-08 13:59:56,135 training [INFO ] Epoch  1 Batch    0 Training err. 0.06804 Training err. RA 0.06804 Valid. err. 3.23443 Time elapsed: 00:00:24
2018-02-08 13:59:56,219 training [INFO ] Epoch  1 Batch    0 Training err. 0.06819 Training err. RA 0.06804 Valid. err. 3.22320 Time elapsed: 00:00:24
2018-02-08 13:59:56,304 training [INFO ] Epoch  1 Batch    0 Training err. 0.06267 Training err. RA 0.06802 Valid. err. 3.21869 Time elapsed: 00:00:25
2018-02-08 13:59:56,405 training [INFO ] Epoch  1 Batch    0 Training err. 0.06004 Training err. RA 0.06799 Valid. err. 3.22899 Time elapsed: 00:00:25
2018-02-08 13:59:56,487 training [INFO ] Epoch  1 Batch    0 Training err. 0.06436 Training err. RA 0.06797 Valid. err. 3.22701 Time elapsed: 00:00:25
2018-02-08 13:59:56,570 training [INFO ] Epoch  1 Batch    0 Training err. 0.05832 Training err. RA 0.06794 Valid. err. 3.22819 Time elapsed: 00:00:25
2018-02-08 13:59:56,670 training [INFO ] Epoch  1 Batch    0 Training err. 0.07088 Training err. RA 0.06795 Valid. err. 3.23148 Time elapsed: 00:00:25
2018-02-08 13:59:56,753 training [INFO ] Epoch  1 Batch    0 Training err. 0.06694 Training err. RA 0.06795 Valid. err. 3.21866 Time elapsed: 00:00:25
2018-02-08 13:59:56,838 training [INFO ] Epoch  1 Batch    0 Training err. 0.07032 Training err. RA 0.06796 Valid. err. 3.22245 Time elapsed: 00:00:25
2018-02-08 13:59:56,932 training [INFO ] Epoch  1 Batch    0 Training err. 0.06636 Training err. RA 0.06795 Valid. err. 3.23608 Time elapsed: 00:00:25
2018-02-08 13:59:57,023 training [INFO ] Epoch  1 Batch    0 Training err. 0.06371 Training err. RA 0.06793 Valid. err. 3.22188 Time elapsed: 00:00:25
2018-02-08 13:59:57,113 training [INFO ] Epoch  1 Batch    0 Training err. 0.06120 Training err. RA 0.06791 Valid. err. 3.22351 Time elapsed: 00:00:25
2018-02-08 13:59:57,225 training [INFO ] Epoch  1 Batch    0 Training err. 0.07424 Training err. RA 0.06793 Valid. err. 3.23608 Time elapsed: 00:00:25
2018-02-08 13:59:57,313 training [INFO ] Epoch  1 Batch    0 Training err. 0.07290 Training err. RA 0.06795 Valid. err. 3.23306 Time elapsed: 00:00:26
2018-02-08 13:59:57,408 training [INFO ] Epoch  1 Batch    0 Training err. 0.06400 Training err. RA 0.06794 Valid. err. 3.23006 Time elapsed: 00:00:26
2018-02-08 13:59:57,507 training [INFO ] Epoch  1 Batch    0 Training err. 0.05852 Training err. RA 0.06790 Valid. err. 3.22264 Time elapsed: 00:00:26
2018-02-08 13:59:57,593 training [INFO ] Epoch  1 Batch    0 Training err. 0.06378 Training err. RA 0.06789 Valid. err. 3.22225 Time elapsed: 00:00:26
2018-02-08 13:59:57,686 training [INFO ] Epoch  1 Batch    0 Training err. 0.06294 Training err. RA 0.06787 Valid. err. 3.21510 Time elapsed: 00:00:26
2018-02-08 13:59:57,781 training [INFO ] Epoch  1 Batch    0 Training err. 0.06621 Training err. RA 0.06787 Valid. err. 3.21345 Time elapsed: 00:00:26
2018-02-08 13:59:57,867 training [INFO ] Epoch  1 Batch    0 Training err. 0.06076 Training err. RA 0.06784 Valid. err. 3.21486 Time elapsed: 00:00:26
2018-02-08 13:59:57,958 training [INFO ] Epoch  1 Batch    0 Training err. 0.06362 Training err. RA 0.06783 Valid. err. 3.21525 Time elapsed: 00:00:26
2018-02-08 13:59:58,059 training [INFO ] Epoch  1 Batch    0 Training err. 0.06509 Training err. RA 0.06782 Valid. err. 3.21768 Time elapsed: 00:00:26
2018-02-08 13:59:58,142 training [INFO ] Epoch  1 Batch    0 Training err. 0.06326 Training err. RA 0.06780 Valid. err. 3.21613 Time elapsed: 00:00:26
2018-02-08 13:59:58,233 training [INFO ] Epoch  1 Batch    0 Training err. 0.06722 Training err. RA 0.06780 Valid. err. 3.22543 Time elapsed: 00:00:26
2018-02-08 13:59:58,343 training [INFO ] Epoch  1 Batch    0 Training err. 0.06327 Training err. RA 0.06779 Valid. err. 3.22523 Time elapsed: 00:00:27
2018-02-08 13:59:58,426 training [INFO ] Epoch  1 Batch    0 Training err. 0.06234 Training err. RA 0.06777 Valid. err. 3.22266 Time elapsed: 00:00:27
2018-02-08 13:59:58,513 training [INFO ] Epoch  1 Batch    0 Training err. 0.06282 Training err. RA 0.06775 Valid. err. 3.22303 Time elapsed: 00:00:27
2018-02-08 13:59:58,609 training [INFO ] Epoch  1 Batch    0 Training err. 0.06046 Training err. RA 0.06773 Valid. err. 3.22707 Time elapsed: 00:00:27
2018-02-08 13:59:58,701 training [INFO ] Epoch  1 Batch    0 Training err. 0.06740 Training err. RA 0.06772 Valid. err. 3.21976 Time elapsed: 00:00:27
2018-02-08 13:59:58,784 training [INFO ] Epoch  1 Batch    0 Training err. 0.06618 Training err. RA 0.06772 Valid. err. 3.21750 Time elapsed: 00:00:27
2018-02-08 13:59:58,877 training [INFO ] Epoch  1 Batch    0 Training err. 0.06405 Training err. RA 0.06771 Valid. err. 3.23491 Time elapsed: 00:00:27
2018-02-08 13:59:58,969 training [INFO ] Epoch  1 Batch    0 Training err. 0.06707 Training err. RA 0.06771 Valid. err. 3.24635 Time elapsed: 00:00:27
2018-02-08 13:59:59,062 training [INFO ] Epoch  1 Batch    0 Training err. 0.06320 Training err. RA 0.06769 Valid. err. 3.22790 Time elapsed: 00:00:27
2018-02-08 13:59:59,157 training [INFO ] Epoch  1 Batch    0 Training err. 0.06515 Training err. RA 0.06768 Valid. err. 3.21682 Time elapsed: 00:00:27
2018-02-08 13:59:59,241 training [INFO ] Epoch  1 Batch    0 Training err. 0.06682 Training err. RA 0.06768 Valid. err. 3.21591 Time elapsed: 00:00:27
2018-02-08 13:59:59,327 training [INFO ] Epoch  1 Batch    0 Training err. 0.06313 Training err. RA 0.06766 Valid. err. 3.21869 Time elapsed: 00:00:28
2018-02-08 13:59:59,432 training [INFO ] Epoch  1 Batch    0 Training err. 0.06218 Training err. RA 0.06765 Valid. err. 3.22294 Time elapsed: 00:00:28
2018-02-08 13:59:59,663 training [INFO ] Epoch  2 Batch    0 Training err. 0.06898 Training err. RA 0.06765 Valid. err. 3.23171 Time elapsed: 00:00:28
2018-02-08 13:59:59,756 training [INFO ] Epoch  2 Batch    0 Training err. 0.06738 Training err. RA 0.06765 Valid. err. 3.23082 Time elapsed: 00:00:28
2018-02-08 13:59:59,843 training [INFO ] Epoch  2 Batch    0 Training err. 0.07422 Training err. RA 0.06767 Valid. err. 3.22621 Time elapsed: 00:00:28
2018-02-08 13:59:59,936 training [INFO ] Epoch  2 Batch    0 Training err. 0.06743 Training err. RA 0.06767 Valid. err. 3.22547 Time elapsed: 00:00:28
2018-02-08 14:00:00,040 training [INFO ] Epoch  2 Batch    0 Training err. 0.06294 Training err. RA 0.06766 Valid. err. 3.22245 Time elapsed: 00:00:28
2018-02-08 14:00:00,147 training [INFO ] Epoch  2 Batch    0 Training err. 0.06117 Training err. RA 0.06763 Valid. err. 3.22620 Time elapsed: 00:00:28
2018-02-08 14:00:00,246 training [INFO ] Epoch  2 Batch    0 Training err. 0.07327 Training err. RA 0.06765 Valid. err. 3.21506 Time elapsed: 00:00:28
2018-02-08 14:00:00,333 training [INFO ] Epoch  2 Batch    0 Training err. 0.06817 Training err. RA 0.06765 Valid. err. 3.22821 Time elapsed: 00:00:29
2018-02-08 14:00:00,429 training [INFO ] Epoch  2 Batch    0 Training err. 0.07427 Training err. RA 0.06767 Valid. err. 3.23800 Time elapsed: 00:00:29
2018-02-08 14:00:00,516 training [INFO ] Epoch  2 Batch    0 Training err. 0.06188 Training err. RA 0.06766 Valid. err. 3.23135 Time elapsed: 00:00:29
2018-02-08 14:00:00,607 training [INFO ] Epoch  2 Batch    0 Training err. 0.06557 Training err. RA 0.06765 Valid. err. 3.22712 Time elapsed: 00:00:29
2018-02-08 14:00:00,738 training [INFO ] Epoch  2 Batch    0 Training err. 0.06186 Training err. RA 0.06763 Valid. err. 3.25459 Time elapsed: 00:00:29
2018-02-08 14:00:00,825 training [INFO ] Epoch  2 Batch    0 Training err. 0.06002 Training err. RA 0.06761 Valid. err. 3.24496 Time elapsed: 00:00:29
2018-02-08 14:00:00,916 training [INFO ] Epoch  2 Batch    0 Training err. 0.06170 Training err. RA 0.06759 Valid. err. 3.22691 Time elapsed: 00:00:29
2018-02-08 14:00:01,011 training [INFO ] Epoch  2 Batch    0 Training err. 0.06530 Training err. RA 0.06758 Valid. err. 3.22883 Time elapsed: 00:00:29
2018-02-08 14:00:01,107 training [INFO ] Epoch  2 Batch    0 Training err. 0.06866 Training err. RA 0.06759 Valid. err. 3.23483 Time elapsed: 00:00:29
2018-02-08 14:00:01,191 training [INFO ] Epoch  2 Batch    0 Training err. 0.06137 Training err. RA 0.06757 Valid. err. 3.23109 Time elapsed: 00:00:29
2018-02-08 14:00:01,287 training [INFO ] Epoch  2 Batch    0 Training err. 0.06648 Training err. RA 0.06756 Valid. err. 3.23623 Time elapsed: 00:00:30
2018-02-08 14:00:01,376 training [INFO ] Epoch  2 Batch    0 Training err. 0.06070 Training err. RA 0.06754 Valid. err. 3.23352 Time elapsed: 00:00:30
2018-02-08 14:00:01,459 training [INFO ] Epoch  2 Batch    0 Training err. 0.06196 Training err. RA 0.06753 Valid. err. 3.24584 Time elapsed: 00:00:30
2018-02-08 14:00:01,557 training [INFO ] Epoch  2 Batch    0 Training err. 0.05899 Training err. RA 0.06750 Valid. err. 3.23532 Time elapsed: 00:00:30
2018-02-08 14:00:01,640 training [INFO ] Epoch  2 Batch    0 Training err. 0.06292 Training err. RA 0.06749 Valid. err. 3.25373 Time elapsed: 00:00:30
2018-02-08 14:00:01,728 training [INFO ] Epoch  2 Batch    0 Training err. 0.06216 Training err. RA 0.06747 Valid. err. 3.26588 Time elapsed: 00:00:30
2018-02-08 14:00:01,826 training [INFO ] Epoch  2 Batch    0 Training err. 0.06345 Training err. RA 0.06746 Valid. err. 3.23681 Time elapsed: 00:00:30
2018-02-08 14:00:01,914 training [INFO ] Epoch  2 Batch    0 Training err. 0.07010 Training err. RA 0.06746 Valid. err. 3.23921 Time elapsed: 00:00:30
2018-02-08 14:00:01,998 training [INFO ] Epoch  2 Batch    0 Training err. 0.05819 Training err. RA 0.06744 Valid. err. 3.24928 Time elapsed: 00:00:30
2018-02-08 14:00:02,100 training [INFO ] Epoch  2 Batch    0 Training err. 0.06308 Training err. RA 0.06742 Valid. err. 3.25692 Time elapsed: 00:00:30
2018-02-08 14:00:02,183 training [INFO ] Epoch  2 Batch    0 Training err. 0.06792 Training err. RA 0.06743 Valid. err. 3.23630 Time elapsed: 00:00:30
2018-02-08 14:00:02,267 training [INFO ] Epoch  2 Batch    0 Training err. 0.06244 Training err. RA 0.06741 Valid. err. 3.24811 Time elapsed: 00:00:31
2018-02-08 14:00:02,363 training [INFO ] Epoch  2 Batch    0 Training err. 0.06915 Training err. RA 0.06742 Valid. err. 3.23887 Time elapsed: 00:00:31
2018-02-08 14:00:02,449 training [INFO ] Epoch  2 Batch    0 Training err. 0.05787 Training err. RA 0.06739 Valid. err. 3.25613 Time elapsed: 00:00:31
2018-02-08 14:00:02,533 training [INFO ] Epoch  2 Batch    0 Training err. 0.06120 Training err. RA 0.06737 Valid. err. 3.24856 Time elapsed: 00:00:31
2018-02-08 14:00:02,627 training [INFO ] Epoch  2 Batch    0 Training err. 0.05932 Training err. RA 0.06735 Valid. err. 3.25563 Time elapsed: 00:00:31
2018-02-08 14:00:02,716 training [INFO ] Epoch  2 Batch    0 Training err. 0.06168 Training err. RA 0.06733 Valid. err. 3.25369 Time elapsed: 00:00:31
2018-02-08 14:00:02,799 training [INFO ] Epoch  2 Batch    0 Training err. 0.06005 Training err. RA 0.06731 Valid. err. 3.25757 Time elapsed: 00:00:31
2018-02-08 14:00:02,892 training [INFO ] Epoch  2 Batch    0 Training err. 0.06213 Training err. RA 0.06729 Valid. err. 3.23638 Time elapsed: 00:00:31
2018-02-08 14:00:02,975 training [INFO ] Epoch  2 Batch    0 Training err. 0.05797 Training err. RA 0.06727 Valid. err. 3.23833 Time elapsed: 00:00:31
2018-02-08 14:00:03,066 training [INFO ] Epoch  2 Batch    0 Training err. 0.05983 Training err. RA 0.06724 Valid. err. 3.24525 Time elapsed: 00:00:31
2018-02-08 14:00:03,161 training [INFO ] Epoch  2 Batch    0 Training err. 0.06227 Training err. RA 0.06723 Valid. err. 3.25125 Time elapsed: 00:00:31
2018-02-08 14:00:03,244 training [INFO ] Epoch  2 Batch    0 Training err. 0.06742 Training err. RA 0.06723 Valid. err. 3.23976 Time elapsed: 00:00:31
2018-02-08 14:00:03,327 training [INFO ] Epoch  2 Batch    0 Training err. 0.06488 Training err. RA 0.06722 Valid. err. 3.26190 Time elapsed: 00:00:32
2018-02-08 14:00:03,421 training [INFO ] Epoch  2 Batch    0 Training err. 0.06499 Training err. RA 0.06722 Valid. err. 3.24249 Time elapsed: 00:00:32
2018-02-08 14:00:03,509 training [INFO ] Epoch  2 Batch    0 Training err. 0.06718 Training err. RA 0.06722 Valid. err. 3.23212 Time elapsed: 00:00:32
2018-02-08 14:00:03,592 training [INFO ] Epoch  2 Batch    0 Training err. 0.06142 Training err. RA 0.06720 Valid. err. 3.23447 Time elapsed: 00:00:32
2018-02-08 14:00:03,686 training [INFO ] Epoch  2 Batch    0 Training err. 0.07411 Training err. RA 0.06722 Valid. err. 3.22864 Time elapsed: 00:00:32
2018-02-08 14:00:03,774 training [INFO ] Epoch  2 Batch    0 Training err. 0.08611 Training err. RA 0.06727 Valid. err. 3.22243 Time elapsed: 00:00:32
2018-02-08 14:00:03,857 training [INFO ] Epoch  2 Batch    0 Training err. 0.07268 Training err. RA 0.06729 Valid. err. 3.22245 Time elapsed: 00:00:32
2018-02-08 14:00:03,954 training [INFO ] Epoch  2 Batch    0 Training err. 0.06627 Training err. RA 0.06729 Valid. err. 3.22508 Time elapsed: 00:00:32
2018-02-08 14:00:04,036 training [INFO ] Epoch  2 Batch    0 Training err. 0.06654 Training err. RA 0.06728 Valid. err. 3.22925 Time elapsed: 00:00:32
2018-02-08 14:00:04,130 training [INFO ] Epoch  2 Batch    0 Training err. 0.06210 Training err. RA 0.06727 Valid. err. 3.22841 Time elapsed: 00:00:32
2018-02-08 14:00:04,225 training [INFO ] Epoch  2 Batch    0 Training err. 0.06309 Training err. RA 0.06726 Valid. err. 3.22587 Time elapsed: 00:00:32
2018-02-08 14:00:04,308 training [INFO ] Epoch  2 Batch    0 Training err. 0.06302 Training err. RA 0.06725 Valid. err. 3.22193 Time elapsed: 00:00:33
2018-02-08 14:00:04,395 training [INFO ] Epoch  2 Batch    0 Training err. 0.06711 Training err. RA 0.06725 Valid. err. 3.23279 Time elapsed: 00:00:33
2018-02-08 14:00:04,488 training [INFO ] Epoch  2 Batch    0 Training err. 0.06386 Training err. RA 0.06724 Valid. err. 3.23400 Time elapsed: 00:00:33
2018-02-08 14:00:04,571 training [INFO ] Epoch  2 Batch    0 Training err. 0.05941 Training err. RA 0.06721 Valid. err. 3.23104 Time elapsed: 00:00:33
2018-02-08 14:00:04,654 training [INFO ] Epoch  2 Batch    0 Training err. 0.06487 Training err. RA 0.06721 Valid. err. 3.22846 Time elapsed: 00:00:33
2018-02-08 14:00:04,750 training [INFO ] Epoch  2 Batch    0 Training err. 0.06311 Training err. RA 0.06720 Valid. err. 3.23103 Time elapsed: 00:00:33
2018-02-08 14:00:04,834 training [INFO ] Epoch  2 Batch    0 Training err. 0.06366 Training err. RA 0.06719 Valid. err. 3.22134 Time elapsed: 00:00:33
2018-02-08 14:00:04,921 training [INFO ] Epoch  2 Batch    0 Training err. 0.06214 Training err. RA 0.06717 Valid. err. 3.23072 Time elapsed: 00:00:33
2018-02-08 14:00:05,017 training [INFO ] Epoch  2 Batch    0 Training err. 0.06603 Training err. RA 0.06717 Valid. err. 3.23708 Time elapsed: 00:00:33
2018-02-08 14:00:05,110 training [INFO ] Epoch  2 Batch    0 Training err. 0.05946 Training err. RA 0.06715 Valid. err. 3.23713 Time elapsed: 00:00:33
2018-02-08 14:00:05,193 training [INFO ] Epoch  2 Batch    0 Training err. 0.06398 Training err. RA 0.06714 Valid. err. 3.24755 Time elapsed: 00:00:33
2018-02-08 14:00:05,287 training [INFO ] Epoch  2 Batch    0 Training err. 0.05959 Training err. RA 0.06712 Valid. err. 3.24665 Time elapsed: 00:00:34
2018-02-08 14:00:05,369 training [INFO ] Epoch  2 Batch    0 Training err. 0.06227 Training err. RA 0.06711 Valid. err. 3.25213 Time elapsed: 00:00:34
2018-02-08 14:00:05,458 training [INFO ] Epoch  2 Batch    0 Training err. 0.06450 Training err. RA 0.06710 Valid. err. 3.26415 Time elapsed: 00:00:34
2018-02-08 14:00:05,553 training [INFO ] Epoch  2 Batch    0 Training err. 0.06103 Training err. RA 0.06708 Valid. err. 3.25394 Time elapsed: 00:00:34
2018-02-08 14:00:05,636 training [INFO ] Epoch  2 Batch    0 Training err. 0.06626 Training err. RA 0.06708 Valid. err. 3.24219 Time elapsed: 00:00:34
2018-02-08 14:00:05,719 training [INFO ] Epoch  2 Batch    0 Training err. 0.06362 Training err. RA 0.06707 Valid. err. 3.25122 Time elapsed: 00:00:34
2018-02-08 14:00:05,817 training [INFO ] Epoch  2 Batch    0 Training err. 0.06493 Training err. RA 0.06707 Valid. err. 3.25750 Time elapsed: 00:00:34
2018-02-08 14:00:05,900 training [INFO ] Epoch  2 Batch    0 Training err. 0.05938 Training err. RA 0.06705 Valid. err. 3.25383 Time elapsed: 00:00:34
2018-02-08 14:00:05,983 training [INFO ] Epoch  2 Batch    0 Training err. 0.06371 Training err. RA 0.06704 Valid. err. 3.25378 Time elapsed: 00:00:34
2018-02-08 14:00:06,084 training [INFO ] Epoch  2 Batch    0 Training err. 0.06957 Training err. RA 0.06704 Valid. err. 3.23900 Time elapsed: 00:00:34
2018-02-08 14:00:06,167 training [INFO ] Epoch  2 Batch    0 Training err. 0.06338 Training err. RA 0.06703 Valid. err. 3.22866 Time elapsed: 00:00:34
2018-02-08 14:00:06,251 training [INFO ] Epoch  2 Batch    0 Training err. 0.06180 Training err. RA 0.06702 Valid. err. 3.22206 Time elapsed: 00:00:35
2018-02-08 14:00:06,345 training [INFO ] Epoch  2 Batch    0 Training err. 0.05980 Training err. RA 0.06700 Valid. err. 3.22236 Time elapsed: 00:00:35
2018-02-08 14:00:06,456 training [INFO ] Epoch  2 Batch    0 Training err. 0.05943 Training err. RA 0.06698 Valid. err. 3.22853 Time elapsed: 00:00:35
2018-02-08 14:00:06,540 training [INFO ] Epoch  2 Batch    0 Training err. 0.06151 Training err. RA 0.06697 Valid. err. 3.23149 Time elapsed: 00:00:35
2018-02-08 14:00:06,633 training [INFO ] Epoch  2 Batch    0 Training err. 0.06311 Training err. RA 0.06696 Valid. err. 3.23137 Time elapsed: 00:00:35
2018-02-08 14:00:06,717 training [INFO ] Epoch  2 Batch    0 Training err. 0.06290 Training err. RA 0.06695 Valid. err. 3.23138 Time elapsed: 00:00:35
2018-02-08 14:00:06,806 training [INFO ] Epoch  2 Batch    0 Training err. 0.06311 Training err. RA 0.06694 Valid. err. 3.23226 Time elapsed: 00:00:35
2018-02-08 14:00:06,907 training [INFO ] Epoch  2 Batch    0 Training err. 0.06532 Training err. RA 0.06693 Valid. err. 3.21807 Time elapsed: 00:00:35
2018-02-08 14:00:06,990 training [INFO ] Epoch  2 Batch    0 Training err. 0.06498 Training err. RA 0.06693 Valid. err. 3.21998 Time elapsed: 00:00:35
2018-02-08 14:00:07,084 training [INFO ] Epoch  2 Batch    0 Training err. 0.06510 Training err. RA 0.06692 Valid. err. 3.23134 Time elapsed: 00:00:35
2018-02-08 14:00:07,179 training [INFO ] Epoch  2 Batch    0 Training err. 0.06612 Training err. RA 0.06692 Valid. err. 3.24255 Time elapsed: 00:00:35
2018-02-08 14:00:07,263 training [INFO ] Epoch  2 Batch    0 Training err. 0.06243 Training err. RA 0.06691 Valid. err. 3.22498 Time elapsed: 00:00:36
2018-02-08 14:00:07,350 training [INFO ] Epoch  2 Batch    0 Training err. 0.06548 Training err. RA 0.06691 Valid. err. 3.23348 Time elapsed: 00:00:36
2018-02-08 14:00:07,446 training [INFO ] Epoch  2 Batch    0 Training err. 0.06266 Training err. RA 0.06690 Valid. err. 3.23000 Time elapsed: 00:00:36
2018-02-08 14:00:07,529 training [INFO ] Epoch  2 Batch    0 Training err. 0.06257 Training err. RA 0.06688 Valid. err. 3.24333 Time elapsed: 00:00:36
2018-02-08 14:00:07,612 training [INFO ] Epoch  2 Batch    0 Training err. 0.06126 Training err. RA 0.06687 Valid. err. 3.24901 Time elapsed: 00:00:36
2018-02-08 14:00:07,708 training [INFO ] Epoch  2 Batch    0 Training err. 0.06285 Training err. RA 0.06686 Valid. err. 3.25078 Time elapsed: 00:00:36
2018-02-08 14:00:07,799 training [INFO ] Epoch  2 Batch    0 Training err. 0.06509 Training err. RA 0.06686 Valid. err. 3.24875 Time elapsed: 00:00:36
2018-02-08 14:00:07,883 training [INFO ] Epoch  2 Batch    0 Training err. 0.06299 Training err. RA 0.06685 Valid. err. 3.24006 Time elapsed: 00:00:36
2018-02-08 14:00:07,981 training [INFO ] Epoch  2 Batch    0 Training err. 0.06541 Training err. RA 0.06684 Valid. err. 3.24245 Time elapsed: 00:00:36
2018-02-08 14:00:08,068 training [INFO ] Epoch  2 Batch    0 Training err. 0.06877 Training err. RA 0.06685 Valid. err. 3.23661 Time elapsed: 00:00:36
2018-02-08 14:00:08,156 training [INFO ] Epoch  2 Batch    0 Training err. 0.06186 Training err. RA 0.06684 Valid. err. 3.24379 Time elapsed: 00:00:36
2018-02-08 14:00:08,250 training [INFO ] Epoch  2 Batch    0 Training err. 0.06432 Training err. RA 0.06683 Valid. err. 3.25813 Time elapsed: 00:00:36
2018-02-08 14:00:08,333 training [INFO ] Epoch  2 Batch    0 Training err. 0.06365 Training err. RA 0.06682 Valid. err. 3.25160 Time elapsed: 00:00:37
2018-02-08 14:00:08,419 training [INFO ] Epoch  2 Batch    0 Training err. 0.06454 Training err. RA 0.06682 Valid. err. 3.24495 Time elapsed: 00:00:37
2018-02-08 14:00:08,517 training [INFO ] Epoch  2 Batch    0 Training err. 0.07367 Training err. RA 0.06683 Valid. err. 3.23777 Time elapsed: 00:00:37
2018-02-08 14:00:08,600 training [INFO ] Epoch  2 Batch    0 Training err. 0.06508 Training err. RA 0.06683 Valid. err. 3.22734 Time elapsed: 00:00:37
2018-02-08 14:00:08,688 training [INFO ] Epoch  2 Batch    0 Training err. 0.05920 Training err. RA 0.06681 Valid. err. 3.23176 Time elapsed: 00:00:37
2018-02-08 14:00:08,786 training [INFO ] Epoch  2 Batch    0 Training err. 0.06331 Training err. RA 0.06680 Valid. err. 3.24732 Time elapsed: 00:00:37
2018-02-08 14:00:08,869 training [INFO ] Epoch  2 Batch    0 Training err. 0.07433 Training err. RA 0.06682 Valid. err. 3.22764 Time elapsed: 00:00:37
2018-02-08 14:00:08,952 training [INFO ] Epoch  2 Batch    0 Training err. 0.06784 Training err. RA 0.06682 Valid. err. 3.23121 Time elapsed: 00:00:37
2018-02-08 14:00:09,048 training [INFO ] Epoch  2 Batch    0 Training err. 0.06548 Training err. RA 0.06682 Valid. err. 3.23517 Time elapsed: 00:00:37
2018-02-08 14:00:09,140 training [INFO ] Epoch  2 Batch    0 Training err. 0.06024 Training err. RA 0.06680 Valid. err. 3.22932 Time elapsed: 00:00:37
2018-02-08 14:00:09,226 training [INFO ] Epoch  2 Batch    0 Training err. 0.06296 Training err. RA 0.06679 Valid. err. 3.24701 Time elapsed: 00:00:37
2018-02-08 14:00:09,321 training [INFO ] Epoch  2 Batch    0 Training err. 0.06090 Training err. RA 0.06678 Valid. err. 3.23632 Time elapsed: 00:00:38
2018-02-08 14:00:09,404 training [INFO ] Epoch  2 Batch    0 Training err. 0.06502 Training err. RA 0.06677 Valid. err. 3.22100 Time elapsed: 00:00:38
2018-02-08 14:00:09,499 training [INFO ] Epoch  2 Batch    0 Training err. 0.06460 Training err. RA 0.06677 Valid. err. 3.23146 Time elapsed: 00:00:38
2018-02-08 14:00:09,596 training [INFO ] Epoch  2 Batch    0 Training err. 0.06444 Training err. RA 0.06676 Valid. err. 3.21652 Time elapsed: 00:00:38
2018-02-08 14:00:09,680 training [INFO ] Epoch  2 Batch    0 Training err. 0.06076 Training err. RA 0.06675 Valid. err. 3.21829 Time elapsed: 00:00:38
2018-02-08 14:00:09,774 training [INFO ] Epoch  2 Batch    0 Training err. 0.06452 Training err. RA 0.06674 Valid. err. 3.21778 Time elapsed: 00:00:38
2018-02-08 14:00:09,875 training [INFO ] Epoch  2 Batch    0 Training err. 0.06130 Training err. RA 0.06673 Valid. err. 3.22256 Time elapsed: 00:00:38
2018-02-08 14:00:09,963 training [INFO ] Epoch  2 Batch    0 Training err. 0.07190 Training err. RA 0.06674 Valid. err. 3.21330 Time elapsed: 00:00:38
2018-02-08 14:00:10,051 training [INFO ] Epoch  2 Batch    0 Training err. 0.05702 Training err. RA 0.06672 Valid. err. 3.22269 Time elapsed: 00:00:38
2018-02-08 14:00:10,151 training [INFO ] Epoch  2 Batch    0 Training err. 0.06302 Training err. RA 0.06671 Valid. err. 3.21883 Time elapsed: 00:00:38
2018-02-08 14:00:10,235 training [INFO ] Epoch  2 Batch    0 Training err. 0.06069 Training err. RA 0.06670 Valid. err. 3.23093 Time elapsed: 00:00:38
2018-02-08 14:00:10,319 training [INFO ] Epoch  2 Batch    0 Training err. 0.05675 Training err. RA 0.06667 Valid. err. 3.23480 Time elapsed: 00:00:39
2018-02-08 14:00:10,414 training [INFO ] Epoch  2 Batch    0 Training err. 0.06398 Training err. RA 0.06667 Valid. err. 3.22138 Time elapsed: 00:00:39
2018-02-08 14:00:10,526 training [INFO ] Epoch  2 Batch    0 Training err. 0.07071 Training err. RA 0.06668 Valid. err. 3.23388 Time elapsed: 00:00:39
2018-02-08 14:00:10,609 training [INFO ] Epoch  2 Batch    0 Training err. 0.06384 Training err. RA 0.06667 Valid. err. 3.22599 Time elapsed: 00:00:39
2018-02-08 14:00:10,705 training [INFO ] Epoch  2 Batch    0 Training err. 0.05965 Training err. RA 0.06665 Valid. err. 3.21307 Time elapsed: 00:00:39
2018-02-08 14:00:10,798 training [INFO ] Epoch  2 Batch    0 Training err. 0.06194 Training err. RA 0.06664 Valid. err. 3.22778 Time elapsed: 00:00:39
2018-02-08 14:00:10,883 training [INFO ] Epoch  2 Batch    0 Training err. 0.06185 Training err. RA 0.06663 Valid. err. 3.24718 Time elapsed: 00:00:39
2018-02-08 14:00:10,982 training [INFO ] Epoch  2 Batch    0 Training err. 0.06972 Training err. RA 0.06664 Valid. err. 3.23029 Time elapsed: 00:00:39
2018-02-08 14:00:11,070 training [INFO ] Epoch  2 Batch    0 Training err. 0.06020 Training err. RA 0.06662 Valid. err. 3.22253 Time elapsed: 00:00:39
2018-02-08 14:00:11,158 training [INFO ] Epoch  2 Batch    0 Training err. 0.06038 Training err. RA 0.06661 Valid. err. 3.22530 Time elapsed: 00:00:39
2018-02-08 14:00:11,254 training [INFO ] Epoch  2 Batch    0 Training err. 0.05958 Training err. RA 0.06659 Valid. err. 3.23029 Time elapsed: 00:00:40
2018-02-08 14:00:11,340 training [INFO ] Epoch  2 Batch    0 Training err. 0.06474 Training err. RA 0.06659 Valid. err. 3.22558 Time elapsed: 00:00:40
2018-02-08 14:00:11,423 training [INFO ] Epoch  2 Batch    0 Training err. 0.06458 Training err. RA 0.06659 Valid. err. 3.22037 Time elapsed: 00:00:40
2018-02-08 14:00:11,520 training [INFO ] Epoch  2 Batch    0 Training err. 0.06581 Training err. RA 0.06658 Valid. err. 3.21909 Time elapsed: 00:00:40
2018-02-08 14:00:11,603 training [INFO ] Epoch  2 Batch    0 Training err. 0.06194 Training err. RA 0.06657 Valid. err. 3.21473 Time elapsed: 00:00:40
2018-02-08 14:00:11,687 training [INFO ] Epoch  2 Batch    0 Training err. 0.07003 Training err. RA 0.06658 Valid. err. 3.21207 Time elapsed: 00:00:40
2018-02-08 14:00:11,789 training [INFO ] Epoch  2 Batch    0 Training err. 0.06091 Training err. RA 0.06657 Valid. err. 3.21185 Time elapsed: 00:00:40
2018-02-08 14:00:11,873 training [INFO ] Epoch  2 Batch    0 Training err. 0.06052 Training err. RA 0.06655 Valid. err. 3.21160 Time elapsed: 00:00:40
2018-02-08 14:00:11,958 training [INFO ] Epoch  2 Batch    0 Training err. 0.07072 Training err. RA 0.06656 Valid. err. 3.21100 Time elapsed: 00:00:40
2018-02-08 14:00:12,052 training [INFO ] Epoch  2 Batch    0 Training err. 0.06075 Training err. RA 0.06655 Valid. err. 3.21705 Time elapsed: 00:00:40
2018-02-08 14:00:12,142 training [INFO ] Epoch  2 Batch    0 Training err. 0.06435 Training err. RA 0.06655 Valid. err. 3.22092 Time elapsed: 00:00:40
2018-02-08 14:00:12,225 training [INFO ] Epoch  2 Batch    0 Training err. 0.06902 Training err. RA 0.06655 Valid. err. 3.21791 Time elapsed: 00:00:40
2018-02-08 14:00:12,320 training [INFO ] Epoch  2 Batch    0 Training err. 0.06769 Training err. RA 0.06655 Valid. err. 3.21154 Time elapsed: 00:00:41
2018-02-08 14:00:12,403 training [INFO ] Epoch  2 Batch    0 Training err. 0.06120 Training err. RA 0.06654 Valid. err. 3.20329 Time elapsed: 00:00:41
2018-02-08 14:00:12,493 training [INFO ] Epoch  2 Batch    0 Training err. 0.06424 Training err. RA 0.06654 Valid. err. 3.20629 Time elapsed: 00:00:41
2018-02-08 14:00:12,588 training [INFO ] Epoch  2 Batch    0 Training err. 0.06569 Training err. RA 0.06653 Valid. err. 3.21065 Time elapsed: 00:00:41
2018-02-08 14:00:12,671 training [INFO ] Epoch  2 Batch    0 Training err. 0.05876 Training err. RA 0.06652 Valid. err. 3.21394 Time elapsed: 00:00:41
2018-02-08 14:00:12,754 training [INFO ] Epoch  2 Batch    0 Training err. 0.06321 Training err. RA 0.06651 Valid. err. 3.20840 Time elapsed: 00:00:41
2018-02-08 14:00:12,855 training [INFO ] Epoch  2 Batch    0 Training err. 0.07059 Training err. RA 0.06652 Valid. err. 3.21004 Time elapsed: 00:00:41
2018-02-08 14:00:12,942 training [INFO ] Epoch  2 Batch    0 Training err. 0.06224 Training err. RA 0.06651 Valid. err. 3.21229 Time elapsed: 00:00:41
2018-02-08 14:00:13,025 training [INFO ] Epoch  2 Batch    0 Training err. 0.06039 Training err. RA 0.06650 Valid. err. 3.22390 Time elapsed: 00:00:41
2018-02-08 14:00:13,125 training [INFO ] Epoch  2 Batch    0 Training err. 0.06152 Training err. RA 0.06649 Valid. err. 3.24019 Time elapsed: 00:00:41
2018-02-08 14:00:13,210 training [INFO ] Epoch  2 Batch    0 Training err. 0.06155 Training err. RA 0.06647 Valid. err. 3.21761 Time elapsed: 00:00:41
2018-02-08 14:00:13,293 training [INFO ] Epoch  2 Batch    0 Training err. 0.05826 Training err. RA 0.06646 Valid. err. 3.22451 Time elapsed: 00:00:42
2018-02-08 14:00:13,388 training [INFO ] Epoch  2 Batch    0 Training err. 0.06608 Training err. RA 0.06646 Valid. err. 3.21941 Time elapsed: 00:00:42
2018-02-08 14:00:13,476 training [INFO ] Epoch  2 Batch    0 Training err. 0.06191 Training err. RA 0.06645 Valid. err. 3.21824 Time elapsed: 00:00:42
2018-02-08 14:00:13,559 training [INFO ] Epoch  2 Batch    0 Training err. 0.06000 Training err. RA 0.06643 Valid. err. 3.21802 Time elapsed: 00:00:42
2018-02-08 14:00:13,655 training [INFO ] Epoch  2 Batch    0 Training err. 0.06510 Training err. RA 0.06643 Valid. err. 3.21334 Time elapsed: 00:00:42
2018-02-08 14:00:13,738 training [INFO ] Epoch  2 Batch    0 Training err. 0.06017 Training err. RA 0.06642 Valid. err. 3.21978 Time elapsed: 00:00:42
2018-02-08 14:00:13,826 training [INFO ] Epoch  2 Batch    0 Training err. 0.05989 Training err. RA 0.06640 Valid. err. 3.21418 Time elapsed: 00:00:42
2018-02-08 14:00:13,925 training [INFO ] Epoch  2 Batch    0 Training err. 0.07534 Training err. RA 0.06642 Valid. err. 3.22389 Time elapsed: 00:00:42
2018-02-08 14:00:14,008 training [INFO ] Epoch  2 Batch    0 Training err. 0.06020 Training err. RA 0.06641 Valid. err. 3.21150 Time elapsed: 00:00:42
2018-02-08 14:00:14,096 training [INFO ] Epoch  2 Batch    0 Training err. 0.06408 Training err. RA 0.06640 Valid. err. 3.20546 Time elapsed: 00:00:42
2018-02-08 14:00:14,192 training [INFO ] Epoch  2 Batch    0 Training err. 0.06035 Training err. RA 0.06639 Valid. err. 3.21989 Time elapsed: 00:00:42
2018-02-08 14:00:14,275 training [INFO ] Epoch  2 Batch    0 Training err. 0.06286 Training err. RA 0.06638 Valid. err. 3.22562 Time elapsed: 00:00:43
2018-02-08 14:00:14,359 training [INFO ] Epoch  2 Batch    0 Training err. 0.06374 Training err. RA 0.06638 Valid. err. 3.20755 Time elapsed: 00:00:43
2018-02-08 14:00:14,452 training [INFO ] Epoch  2 Batch    0 Training err. 0.06776 Training err. RA 0.06638 Valid. err. 3.21343 Time elapsed: 00:00:43
2018-02-08 14:00:14,540 training [INFO ] Epoch  2 Batch    0 Training err. 0.06607 Training err. RA 0.06638 Valid. err. 3.21946 Time elapsed: 00:00:43
2018-02-08 14:00:14,624 training [INFO ] Epoch  2 Batch    0 Training err. 0.06962 Training err. RA 0.06639 Valid. err. 3.22928 Time elapsed: 00:00:43
2018-02-08 14:00:14,720 training [INFO ] Epoch  2 Batch    0 Training err. 0.05828 Training err. RA 0.06637 Valid. err. 3.21175 Time elapsed: 00:00:43
2018-02-08 14:00:14,808 training [INFO ] Epoch  2 Batch    0 Training err. 0.06966 Training err. RA 0.06638 Valid. err. 3.22873 Time elapsed: 00:00:43
2018-02-08 14:00:14,892 training [INFO ] Epoch  2 Batch    0 Training err. 0.06284 Training err. RA 0.06637 Valid. err. 3.22843 Time elapsed: 00:00:43
2018-02-08 14:00:14,990 training [INFO ] Epoch  2 Batch    0 Training err. 0.05820 Training err. RA 0.06635 Valid. err. 3.23373 Time elapsed: 00:00:43
2018-02-08 14:00:15,080 training [INFO ] Epoch  2 Batch    0 Training err. 0.06903 Training err. RA 0.06636 Valid. err. 3.22360 Time elapsed: 00:00:43
2018-02-08 14:00:15,169 training [INFO ] Epoch  2 Batch    0 Training err. 0.06376 Training err. RA 0.06635 Valid. err. 3.21215 Time elapsed: 00:00:43
2018-02-08 14:00:15,265 training [INFO ] Epoch  2 Batch    0 Training err. 0.05607 Training err. RA 0.06633 Valid. err. 3.21118 Time elapsed: 00:00:44
2018-02-08 14:00:15,348 training [INFO ] Epoch  2 Batch    0 Training err. 0.06863 Training err. RA 0.06633 Valid. err. 3.20182 Time elapsed: 00:00:44
2018-02-08 14:00:15,437 training [INFO ] Epoch  2 Batch    0 Training err. 0.06477 Training err. RA 0.06633 Valid. err. 3.20910 Time elapsed: 00:00:44
2018-02-08 14:00:15,535 training [INFO ] Epoch  2 Batch    0 Training err. 0.07078 Training err. RA 0.06634 Valid. err. 3.21892 Time elapsed: 00:00:44
2018-02-08 14:00:15,619 training [INFO ] Epoch  2 Batch    0 Training err. 0.06674 Training err. RA 0.06634 Valid. err. 3.20931 Time elapsed: 00:00:44
2018-02-08 14:00:15,702 training [INFO ] Epoch  2 Batch    0 Training err. 0.05858 Training err. RA 0.06633 Valid. err. 3.21134 Time elapsed: 00:00:44
2018-02-08 14:00:15,798 training [INFO ] Epoch  2 Batch    0 Training err. 0.06801 Training err. RA 0.06633 Valid. err. 3.21420 Time elapsed: 00:00:44
2018-02-08 14:00:15,889 training [INFO ] Epoch  2 Batch    0 Training err. 0.06695 Training err. RA 0.06633 Valid. err. 3.20562 Time elapsed: 00:00:44
2018-02-08 14:00:15,974 training [INFO ] Epoch  2 Batch    0 Training err. 0.06671 Training err. RA 0.06633 Valid. err. 3.20018 Time elapsed: 00:00:44
2018-02-08 14:00:16,074 training [INFO ] Epoch  2 Batch    0 Training err. 0.05987 Training err. RA 0.06632 Valid. err. 3.20257 Time elapsed: 00:00:44
2018-02-08 14:00:16,162 training [INFO ] Epoch  2 Batch    0 Training err. 0.06446 Training err. RA 0.06631 Valid. err. 3.19715 Time elapsed: 00:00:44
2018-02-08 14:00:16,249 training [INFO ] Epoch  2 Batch    0 Training err. 0.06553 Training err. RA 0.06631 Valid. err. 3.19804 Time elapsed: 00:00:44
2018-02-08 14:00:16,343 training [INFO ] Epoch  2 Batch    0 Training err. 0.06130 Training err. RA 0.06630 Valid. err. 3.19284 Time elapsed: 00:00:45
2018-02-08 14:00:16,429 training [INFO ] Epoch  2 Batch    0 Training err. 0.07041 Training err. RA 0.06631 Valid. err. 3.20525 Time elapsed: 00:00:45
2018-02-08 14:00:16,518 training [INFO ] Epoch  2 Batch    0 Training err. 0.06435 Training err. RA 0.06631 Valid. err. 3.19432 Time elapsed: 00:00:45
2018-02-08 14:00:16,615 training [INFO ] Epoch  2 Batch    0 Training err. 0.06052 Training err. RA 0.06630 Valid. err. 3.20659 Time elapsed: 00:00:45
2018-02-08 14:00:16,698 training [INFO ] Epoch  2 Batch    0 Training err. 0.06424 Training err. RA 0.06629 Valid. err. 3.20463 Time elapsed: 00:00:45
2018-02-08 14:00:16,785 training [INFO ] Epoch  2 Batch    0 Training err. 0.06345 Training err. RA 0.06629 Valid. err. 3.21065 Time elapsed: 00:00:45
2018-02-08 14:00:16,882 training [INFO ] Epoch  2 Batch    0 Training err. 0.05772 Training err. RA 0.06627 Valid. err. 3.21008 Time elapsed: 00:00:45
2018-02-08 14:00:16,973 training [INFO ] Epoch  2 Batch    0 Training err. 0.06706 Training err. RA 0.06627 Valid. err. 3.21832 Time elapsed: 00:00:45
2018-02-08 14:00:17,062 training [INFO ] Epoch  2 Batch    0 Training err. 0.07582 Training err. RA 0.06629 Valid. err. 3.23364 Time elapsed: 00:00:45
2018-02-08 14:00:17,167 training [INFO ] Epoch  2 Batch    0 Training err. 0.06332 Training err. RA 0.06628 Valid. err. 3.21531 Time elapsed: 00:00:45
2018-02-08 14:00:17,255 training [INFO ] Epoch  2 Batch    0 Training err. 0.06554 Training err. RA 0.06628 Valid. err. 3.22372 Time elapsed: 00:00:46
2018-02-08 14:00:17,338 training [INFO ] Epoch  2 Batch    0 Training err. 0.06027 Training err. RA 0.06627 Valid. err. 3.21430 Time elapsed: 00:00:46
2018-02-08 14:00:17,436 training [INFO ] Epoch  2 Batch    0 Training err. 0.06219 Training err. RA 0.06626 Valid. err. 3.21577 Time elapsed: 00:00:46
2018-02-08 14:00:17,526 training [INFO ] Epoch  2 Batch    0 Training err. 0.06342 Training err. RA 0.06626 Valid. err. 3.21514 Time elapsed: 00:00:46
2018-02-08 14:00:17,616 training [INFO ] Epoch  2 Batch    0 Training err. 0.06308 Training err. RA 0.06625 Valid. err. 3.20743 Time elapsed: 00:00:46
2018-02-08 14:00:17,720 training [INFO ] Epoch  2 Batch    0 Training err. 0.06167 Training err. RA 0.06624 Valid. err. 3.21947 Time elapsed: 00:00:46
2018-02-08 14:00:17,804 training [INFO ] Epoch  2 Batch    0 Training err. 0.06674 Training err. RA 0.06624 Valid. err. 3.20962 Time elapsed: 00:00:46
2018-02-08 14:00:17,896 training [INFO ] Epoch  2 Batch    0 Training err. 0.06295 Training err. RA 0.06624 Valid. err. 3.22215 Time elapsed: 00:00:46
2018-02-08 14:00:17,996 training [INFO ] Epoch  2 Batch    0 Training err. 0.06186 Training err. RA 0.06623 Valid. err. 3.21513 Time elapsed: 00:00:46
2018-02-08 14:00:18,089 training [INFO ] Epoch  2 Batch    0 Training err. 0.06357 Training err. RA 0.06622 Valid. err. 3.20001 Time elapsed: 00:00:46
2018-02-08 14:00:18,178 training [INFO ] Epoch  2 Batch    0 Training err. 0.06501 Training err. RA 0.06622 Valid. err. 3.20262 Time elapsed: 00:00:46
2018-02-08 14:00:18,274 training [INFO ] Epoch  2 Batch    0 Training err. 0.06255 Training err. RA 0.06621 Valid. err. 3.20234 Time elapsed: 00:00:47
2018-02-08 14:00:18,361 training [INFO ] Epoch  2 Batch    0 Training err. 0.06926 Training err. RA 0.06622 Valid. err. 3.20465 Time elapsed: 00:00:47
2018-02-08 14:00:51,105 __main__ [INFO ] 
==============================
Starting experiment test_small
==============================
2018-02-08 14:00:51,107 __main__ [INFO ] Removing old results directory ./experiments/test_small/out
2018-02-08 14:00:51,109 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 1 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 20,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 14:00:51,109 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 14:00:53,906 training [INFO ] Epoch  1 Batch   50 Training err. 4.05386 Training err. RA 4.05386 Valid. err. 3.53772 Time elapsed: 00:00:00
2018-02-08 14:00:54,159 training [INFO ] Epoch  1 Batch  100 Training err. 3.40398 Training err. RA 3.72892 Valid. err. 3.29780 Time elapsed: 00:00:00
2018-02-08 14:00:54,423 training [INFO ] Epoch  1 Batch  150 Training err. 3.27868 Training err. RA 3.57884 Valid. err. 3.28205 Time elapsed: 00:00:00
2018-02-08 14:00:54,687 training [INFO ] Epoch  1 Batch  200 Training err. 3.26424 Training err. RA 3.50019 Valid. err. 3.25430 Time elapsed: 00:00:01
2018-02-08 14:00:54,954 training [INFO ] Epoch  1 Batch  250 Training err. 3.22115 Training err. RA 3.44438 Valid. err. 3.25855 Time elapsed: 00:00:01
2018-02-08 14:00:55,205 training [INFO ] Epoch  1 Batch  300 Training err. 3.27052 Training err. RA 3.41540 Valid. err. 3.22173 Time elapsed: 00:00:01
2018-02-08 14:00:55,561 training [INFO ] Epoch  2 Batch  350 Training err. 3.22603 Training err. RA 3.38835 Valid. err. 3.23619 Time elapsed: 00:00:02
2018-02-08 14:00:55,813 training [INFO ] Epoch  2 Batch  400 Training err. 3.22834 Training err. RA 3.36835 Valid. err. 3.24189 Time elapsed: 00:00:02
2018-02-08 14:00:56,069 training [INFO ] Epoch  2 Batch  450 Training err. 3.21583 Training err. RA 3.35140 Valid. err. 3.20906 Time elapsed: 00:00:02
2018-02-08 14:00:56,345 training [INFO ] Epoch  2 Batch  500 Training err. 3.20582 Training err. RA 3.33684 Valid. err. 3.21614 Time elapsed: 00:00:02
2018-02-08 14:00:56,619 training [INFO ] Epoch  2 Batch  550 Training err. 3.18762 Training err. RA 3.32328 Valid. err. 3.22208 Time elapsed: 00:00:03
2018-02-08 14:00:56,924 training [INFO ] Epoch  2 Batch  600 Training err. 3.20623 Training err. RA 3.31352 Valid. err. 3.16864 Time elapsed: 00:00:03
2018-02-08 14:00:57,344 training [INFO ] Epoch  3 Batch  650 Training err. 3.17745 Training err. RA 3.30306 Valid. err. 3.16550 Time elapsed: 00:00:03
2018-02-08 14:00:57,672 training [INFO ] Epoch  3 Batch  700 Training err. 3.16794 Training err. RA 3.29341 Valid. err. 3.15500 Time elapsed: 00:00:04
2018-02-08 14:00:57,958 training [INFO ] Epoch  3 Batch  750 Training err. 3.11026 Training err. RA 3.28120 Valid. err. 3.11545 Time elapsed: 00:00:04
2018-02-08 14:00:58,267 training [INFO ] Epoch  3 Batch  800 Training err. 3.11598 Training err. RA 3.27087 Valid. err. 3.09543 Time elapsed: 00:00:04
2018-02-08 14:00:58,544 training [INFO ] Epoch  3 Batch  850 Training err. 3.04756 Training err. RA 3.25773 Valid. err. 3.13130 Time elapsed: 00:00:05
2018-02-08 14:00:58,838 training [INFO ] Epoch  3 Batch  900 Training err. 3.08907 Training err. RA 3.24836 Valid. err. 3.00342 Time elapsed: 00:00:05
2018-02-08 14:00:59,218 training [INFO ] Epoch  4 Batch  950 Training err. 3.05505 Training err. RA 3.23819 Valid. err. 3.06178 Time elapsed: 00:00:05
2018-02-08 14:00:59,480 training [INFO ] Epoch  4 Batch 1000 Training err. 2.97969 Training err. RA 3.22527 Valid. err. 2.95626 Time elapsed: 00:00:06
2018-02-08 14:00:59,739 training [INFO ] Epoch  4 Batch 1050 Training err. 2.91126 Training err. RA 3.21031 Valid. err. 2.93112 Time elapsed: 00:00:06
2018-02-08 14:01:00,006 training [INFO ] Epoch  4 Batch 1100 Training err. 2.91535 Training err. RA 3.19691 Valid. err. 2.86828 Time elapsed: 00:00:06
2018-02-08 14:01:00,325 training [INFO ] Epoch  4 Batch 1150 Training err. 2.87201 Training err. RA 3.18278 Valid. err. 2.90085 Time elapsed: 00:00:06
2018-02-08 14:01:00,607 training [INFO ] Epoch  4 Batch 1200 Training err. 2.87647 Training err. RA 3.17002 Valid. err. 2.81445 Time elapsed: 00:00:07
2018-02-08 14:01:01,247 training [INFO ] Epoch  5 Batch 1250 Training err. 2.91305 Training err. RA 3.15974 Valid. err. 2.86522 Time elapsed: 00:00:07
2018-02-08 14:01:02,408 training [INFO ] Epoch  5 Batch 1300 Training err. 2.85142 Training err. RA 3.14788 Valid. err. 2.80231 Time elapsed: 00:00:08
2018-02-08 14:01:02,695 training [INFO ] Epoch  5 Batch 1350 Training err. 2.75608 Training err. RA 3.13337 Valid. err. 2.77165 Time elapsed: 00:00:09
2018-02-08 14:01:02,955 training [INFO ] Epoch  5 Batch 1400 Training err. 2.77749 Training err. RA 3.12066 Valid. err. 2.76291 Time elapsed: 00:00:09
2018-02-08 14:01:03,218 training [INFO ] Epoch  5 Batch 1450 Training err. 2.78181 Training err. RA 3.10897 Valid. err. 2.74584 Time elapsed: 00:00:09
2018-02-08 14:01:03,463 training [INFO ] Epoch  5 Batch 1500 Training err. 2.74151 Training err. RA 3.09672 Valid. err. 2.70265 Time elapsed: 00:00:10
2018-02-08 14:01:03,827 training [INFO ] Epoch  6 Batch 1550 Training err. 2.82482 Training err. RA 3.08795 Valid. err. 2.69931 Time elapsed: 00:00:10
2018-02-08 14:01:04,116 training [INFO ] Epoch  6 Batch 1600 Training err. 2.76174 Training err. RA 3.07776 Valid. err. 2.74902 Time elapsed: 00:00:10
2018-02-08 14:01:04,458 training [INFO ] Epoch  6 Batch 1650 Training err. 2.68373 Training err. RA 3.06582 Valid. err. 2.67739 Time elapsed: 00:00:10
2018-02-08 14:01:04,723 training [INFO ] Epoch  6 Batch 1700 Training err. 2.66382 Training err. RA 3.05400 Valid. err. 2.66774 Time elapsed: 00:00:11
2018-02-08 14:01:05,053 training [INFO ] Epoch  6 Batch 1750 Training err. 2.73485 Training err. RA 3.04488 Valid. err. 2.66280 Time elapsed: 00:00:11
2018-02-08 14:01:05,339 training [INFO ] Epoch  6 Batch 1800 Training err. 2.64184 Training err. RA 3.03368 Valid. err. 2.63639 Time elapsed: 00:00:11
2018-02-08 14:01:05,767 training [INFO ] Epoch  7 Batch 1850 Training err. 2.74293 Training err. RA 3.02582 Valid. err. 2.69452 Time elapsed: 00:00:12
2018-02-08 14:01:06,034 training [INFO ] Epoch  7 Batch 1900 Training err. 2.72189 Training err. RA 3.01783 Valid. err. 2.62361 Time elapsed: 00:00:12
2018-02-08 14:01:06,645 training [INFO ] Epoch  7 Batch 1950 Training err. 2.61239 Training err. RA 3.00743 Valid. err. 2.60619 Time elapsed: 00:00:13
2018-02-08 14:01:06,925 training [INFO ] Epoch  7 Batch 2000 Training err. 2.59028 Training err. RA 2.99700 Valid. err. 2.59615 Time elapsed: 00:00:13
2018-02-08 14:01:07,197 training [INFO ] Epoch  7 Batch 2050 Training err. 2.68956 Training err. RA 2.98950 Valid. err. 2.58207 Time elapsed: 00:00:13
2018-02-08 14:01:07,462 training [INFO ] Epoch  7 Batch 2100 Training err. 2.57163 Training err. RA 2.97955 Valid. err. 2.56024 Time elapsed: 00:00:14
2018-02-08 14:01:07,821 training [INFO ] Epoch  8 Batch 2150 Training err. 2.64175 Training err. RA 2.97170 Valid. err. 2.54708 Time elapsed: 00:00:14
2018-02-08 14:01:08,082 training [INFO ] Epoch  8 Batch 2200 Training err. 2.71029 Training err. RA 2.96576 Valid. err. 2.55295 Time elapsed: 00:00:14
2018-02-08 14:01:08,327 training [INFO ] Epoch  8 Batch 2250 Training err. 2.57659 Training err. RA 2.95711 Valid. err. 2.55657 Time elapsed: 00:00:14
2018-02-08 14:01:08,587 training [INFO ] Epoch  8 Batch 2300 Training err. 2.55168 Training err. RA 2.94829 Valid. err. 2.54411 Time elapsed: 00:00:15
2018-02-08 14:01:08,849 training [INFO ] Epoch  8 Batch 2350 Training err. 2.60763 Training err. RA 2.94105 Valid. err. 2.56075 Time elapsed: 00:00:15
2018-02-08 14:01:09,108 training [INFO ] Epoch  8 Batch 2400 Training err. 2.50970 Training err. RA 2.93206 Valid. err. 2.51488 Time elapsed: 00:00:15
2018-02-08 14:01:09,371 training [INFO ] Epoch  8 Batch 2450 Training err. 2.59207 Training err. RA 2.92512 Valid. err. 2.52698 Time elapsed: 00:00:15
2018-02-08 14:01:09,721 training [INFO ] Epoch  9 Batch 2500 Training err. 2.63095 Training err. RA 2.91924 Valid. err. 2.53583 Time elapsed: 00:00:16
2018-02-08 14:01:09,984 training [INFO ] Epoch  9 Batch 2550 Training err. 2.58866 Training err. RA 2.91276 Valid. err. 2.50286 Time elapsed: 00:00:16
2018-02-08 14:01:10,261 training [INFO ] Epoch  9 Batch 2600 Training err. 2.50504 Training err. RA 2.90492 Valid. err. 2.48171 Time elapsed: 00:00:16
2018-02-08 14:01:10,544 training [INFO ] Epoch  9 Batch 2650 Training err. 2.56641 Training err. RA 2.89853 Valid. err. 2.52625 Time elapsed: 00:00:17
2018-02-08 14:01:10,839 training [INFO ] Epoch  9 Batch 2700 Training err. 2.46285 Training err. RA 2.89046 Valid. err. 2.50890 Time elapsed: 00:00:17
2018-02-08 14:01:11,131 training [INFO ] Epoch  9 Batch 2750 Training err. 2.51941 Training err. RA 2.88371 Valid. err. 2.45985 Time elapsed: 00:00:17
2018-02-08 14:01:11,527 training [INFO ] Epoch 10 Batch 2800 Training err. 2.56927 Training err. RA 2.87810 Valid. err. 2.50200 Time elapsed: 00:00:18
2018-02-08 14:01:11,781 training [INFO ] Epoch 10 Batch 2850 Training err. 2.57386 Training err. RA 2.87276 Valid. err. 2.46355 Time elapsed: 00:00:18
2018-02-08 14:01:12,035 training [INFO ] Epoch 10 Batch 2900 Training err. 2.46235 Training err. RA 2.86568 Valid. err. 2.43938 Time elapsed: 00:00:18
2018-02-08 14:01:12,309 training [INFO ] Epoch 10 Batch 2950 Training err. 2.51448 Training err. RA 2.85973 Valid. err. 2.46910 Time elapsed: 00:00:18
2018-02-08 14:01:12,584 training [INFO ] Epoch 10 Batch 3000 Training err. 2.44106 Training err. RA 2.85275 Valid. err. 2.42117 Time elapsed: 00:00:19
2018-02-08 14:01:12,857 training [INFO ] Epoch 10 Batch 3050 Training err. 2.46249 Training err. RA 2.84636 Valid. err. 2.42251 Time elapsed: 00:00:19
2018-02-08 14:01:13,017 __main__ [INFO ] End of training
2018-02-08 14:01:13,445 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 2 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.23,
  "optimizer": {
    "name": "SGD",
    "kwargs": {
      "lr": 0.23,
      "weight_decay": 0
    }
  },
  "reset_state_every": 120,
  "num_timesteps": 30,
  "batch_size": 2,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 14:01:13,446 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 14:01:13,767 training [INFO ] Epoch  1 Batch   50 Training err. 3.98441 Training err. RA 3.98441 Valid. err. 3.45004 Time elapsed: 00:00:00
2018-02-08 14:01:14,055 training [INFO ] Epoch  1 Batch  100 Training err. 3.35629 Training err. RA 3.67035 Valid. err. 3.29220 Time elapsed: 00:00:00
2018-02-08 14:01:14,341 training [INFO ] Epoch  1 Batch  150 Training err. 3.26785 Training err. RA 3.53618 Valid. err. 3.24708 Time elapsed: 00:00:00
2018-02-08 14:01:14,604 training [INFO ] Epoch  1 Batch  200 Training err. 3.25617 Training err. RA 3.46618 Valid. err. 3.23226 Time elapsed: 00:00:01
2018-02-08 14:01:14,971 training [INFO ] Epoch  2 Batch  250 Training err. 3.25477 Training err. RA 3.42390 Valid. err. 3.25791 Time elapsed: 00:00:01
2018-02-08 14:01:15,243 training [INFO ] Epoch  2 Batch  300 Training err. 3.21742 Training err. RA 3.38949 Valid. err. 3.22095 Time elapsed: 00:00:01
2018-02-08 14:01:15,527 training [INFO ] Epoch  2 Batch  350 Training err. 3.21519 Training err. RA 3.36459 Valid. err. 3.22617 Time elapsed: 00:00:02
2018-02-08 14:01:15,797 training [INFO ] Epoch  2 Batch  400 Training err. 3.22102 Training err. RA 3.34664 Valid. err. 3.20091 Time elapsed: 00:00:02
2018-02-08 14:01:16,168 training [INFO ] Epoch  3 Batch  450 Training err. 3.23406 Training err. RA 3.33413 Valid. err. 3.21571 Time elapsed: 00:00:02
2018-02-08 14:01:16,442 training [INFO ] Epoch  3 Batch  500 Training err. 3.17487 Training err. RA 3.31821 Valid. err. 3.19752 Time elapsed: 00:00:02
2018-02-08 14:01:16,710 training [INFO ] Epoch  3 Batch  550 Training err. 3.19650 Training err. RA 3.30714 Valid. err. 3.20115 Time elapsed: 00:00:03
2018-02-08 14:01:16,990 training [INFO ] Epoch  3 Batch  600 Training err. 3.18205 Training err. RA 3.29672 Valid. err. 3.16850 Time elapsed: 00:00:03
2018-02-08 14:01:17,365 training [INFO ] Epoch  4 Batch  650 Training err. 3.19008 Training err. RA 3.28851 Valid. err. 3.17007 Time elapsed: 00:00:03
2018-02-08 14:01:17,623 training [INFO ] Epoch  4 Batch  700 Training err. 3.11261 Training err. RA 3.27595 Valid. err. 3.12578 Time elapsed: 00:00:04
2018-02-08 14:01:17,909 training [INFO ] Epoch  4 Batch  750 Training err. 3.11257 Training err. RA 3.26506 Valid. err. 3.10063 Time elapsed: 00:00:04
2018-02-08 14:01:18,182 training [INFO ] Epoch  4 Batch  800 Training err. 3.07596 Training err. RA 3.25324 Valid. err. 3.07541 Time elapsed: 00:00:04
2018-02-08 14:01:18,558 training [INFO ] Epoch  5 Batch  850 Training err. 3.08426 Training err. RA 3.24330 Valid. err. 3.05331 Time elapsed: 00:00:05
2018-02-08 14:01:18,829 training [INFO ] Epoch  5 Batch  900 Training err. 2.99452 Training err. RA 3.22948 Valid. err. 2.99885 Time elapsed: 00:00:05
2018-02-08 14:01:19,101 training [INFO ] Epoch  5 Batch  950 Training err. 2.96057 Training err. RA 3.21533 Valid. err. 2.93402 Time elapsed: 00:00:05
2018-02-08 14:01:19,374 training [INFO ] Epoch  5 Batch 1000 Training err. 2.90627 Training err. RA 3.19987 Valid. err. 2.88876 Time elapsed: 00:00:05
2018-02-08 14:01:19,729 training [INFO ] Epoch  6 Batch 1050 Training err. 2.94456 Training err. RA 3.18771 Valid. err. 2.87261 Time elapsed: 00:00:06
2018-02-08 14:01:20,001 training [INFO ] Epoch  6 Batch 1100 Training err. 2.88204 Training err. RA 3.17382 Valid. err. 2.84771 Time elapsed: 00:00:06
2018-02-08 14:01:20,282 training [INFO ] Epoch  6 Batch 1150 Training err. 2.83992 Training err. RA 3.15930 Valid. err. 2.80434 Time elapsed: 00:00:06
2018-02-08 14:01:20,552 training [INFO ] Epoch  6 Batch 1200 Training err. 2.81179 Training err. RA 3.14482 Valid. err. 2.79230 Time elapsed: 00:00:07
2018-02-08 14:01:20,919 training [INFO ] Epoch  7 Batch 1250 Training err. 2.87505 Training err. RA 3.13403 Valid. err. 2.84620 Time elapsed: 00:00:07
2018-02-08 14:01:21,184 training [INFO ] Epoch  7 Batch 1300 Training err. 2.80446 Training err. RA 3.12136 Valid. err. 2.76672 Time elapsed: 00:00:07
2018-02-08 14:01:21,452 training [INFO ] Epoch  7 Batch 1350 Training err. 2.75177 Training err. RA 3.10767 Valid. err. 2.73298 Time elapsed: 00:00:08
2018-02-08 14:01:21,755 training [INFO ] Epoch  7 Batch 1400 Training err. 2.74506 Training err. RA 3.09472 Valid. err. 2.72529 Time elapsed: 00:00:08
2018-02-08 14:01:22,139 training [INFO ] Epoch  8 Batch 1450 Training err. 2.80993 Training err. RA 3.08490 Valid. err. 2.83410 Time elapsed: 00:00:08
2018-02-08 14:01:22,410 training [INFO ] Epoch  8 Batch 1500 Training err. 2.74940 Training err. RA 3.07371 Valid. err. 2.70609 Time elapsed: 00:00:08
2018-02-08 14:01:22,693 training [INFO ] Epoch  8 Batch 1550 Training err. 2.69297 Training err. RA 3.06143 Valid. err. 2.67099 Time elapsed: 00:00:09
2018-02-08 14:01:22,973 training [INFO ] Epoch  8 Batch 1600 Training err. 2.67870 Training err. RA 3.04947 Valid. err. 2.69653 Time elapsed: 00:00:09
2018-02-08 14:01:23,340 training [INFO ] Epoch  9 Batch 1650 Training err. 2.74763 Training err. RA 3.04032 Valid. err. 2.63570 Time elapsed: 00:00:09
2018-02-08 14:01:23,607 training [INFO ] Epoch  9 Batch 1700 Training err. 2.69706 Training err. RA 3.03023 Valid. err. 2.64963 Time elapsed: 00:00:10
2018-02-08 14:01:23,944 training [INFO ] Epoch  9 Batch 1750 Training err. 2.62272 Training err. RA 3.01859 Valid. err. 2.66815 Time elapsed: 00:00:10
2018-02-08 14:01:24,391 training [INFO ] Epoch  9 Batch 1800 Training err. 2.63472 Training err. RA 3.00792 Valid. err. 2.62999 Time elapsed: 00:00:10
2018-02-08 14:01:24,889 training [INFO ] Epoch 10 Batch 1850 Training err. 2.68278 Training err. RA 2.99913 Valid. err. 2.61695 Time elapsed: 00:00:11
2018-02-08 14:01:25,215 training [INFO ] Epoch 10 Batch 1900 Training err. 2.66005 Training err. RA 2.99021 Valid. err. 2.66245 Time elapsed: 00:00:11
2018-02-08 14:01:25,478 training [INFO ] Epoch 10 Batch 1950 Training err. 2.56757 Training err. RA 2.97937 Valid. err. 2.57415 Time elapsed: 00:00:12
2018-02-08 14:01:25,737 training [INFO ] Epoch 10 Batch 2000 Training err. 2.60866 Training err. RA 2.97011 Valid. err. 2.56328 Time elapsed: 00:00:12
2018-02-08 14:01:26,002 training [INFO ] Epoch 10 Batch 2050 Training err. 2.58682 Training err. RA 2.96076 Valid. err. 2.56049 Time elapsed: 00:00:12
2018-02-08 14:01:26,091 __main__ [INFO ] End of training
2018-02-08 14:01:26,246 __main__ [INFO ] 
--------------------------------------------------
Starting training for model 3 out of 3 with hyperparameters:
{
  "linear_dropout": 0,
  "recurrent_dropout": 0,
  "l2_penalty": 0,
  "num_epochs": 10,
  "learning_rate": 0.1,
  "optimizer": {
    "name": "SGD",
    "kwargs": {}
  },
  "reset_state_every": 120,
  "num_timesteps": 10,
  "batch_size": 4,
  "num_layers": 1,
  "hidden_size": 0,
  "network_type": "lstm"
}
--------------------------------------------------
2018-02-08 14:01:26,247 __main__ [INFO ] Specified network hidden size was 0. This will be set to the size of the alphabet which is 84
2018-02-08 14:01:26,553 training [INFO ] Epoch  1 Batch   50 Training err. 4.27504 Training err. RA 4.27504 Valid. err. 4.08945 Time elapsed: 00:00:00
2018-02-08 14:01:26,834 training [INFO ] Epoch  1 Batch  100 Training err. 3.95429 Training err. RA 4.11466 Valid. err. 3.72585 Time elapsed: 00:00:00
2018-02-08 14:01:27,133 training [INFO ] Epoch  1 Batch  150 Training err. 3.64266 Training err. RA 3.95733 Valid. err. 3.47036 Time elapsed: 00:00:00
2018-02-08 14:01:27,404 training [INFO ] Epoch  1 Batch  200 Training err. 3.46395 Training err. RA 3.83398 Valid. err. 3.36844 Time elapsed: 00:00:01
2018-02-08 14:01:27,674 training [INFO ] Epoch  1 Batch  250 Training err. 3.36835 Training err. RA 3.74086 Valid. err. 3.32920 Time elapsed: 00:00:01
2018-02-08 14:01:27,954 training [INFO ] Epoch  1 Batch  300 Training err. 3.34991 Training err. RA 3.67570 Valid. err. 3.29863 Time elapsed: 00:00:01
2018-02-08 14:01:28,326 training [INFO ] Epoch  2 Batch  350 Training err. 3.30946 Training err. RA 3.62338 Valid. err. 3.27650 Time elapsed: 00:00:02
2018-02-08 14:01:28,601 training [INFO ] Epoch  2 Batch  400 Training err. 3.30015 Training err. RA 3.58298 Valid. err. 3.25923 Time elapsed: 00:00:02
2018-02-08 14:01:28,874 training [INFO ] Epoch  2 Batch  450 Training err. 3.24823 Training err. RA 3.54578 Valid. err. 3.26288 Time elapsed: 00:00:02
2018-02-08 14:01:29,150 training [INFO ] Epoch  2 Batch  500 Training err. 3.22659 Training err. RA 3.51386 Valid. err. 3.26297 Time elapsed: 00:00:02
2018-02-08 14:01:29,413 training [INFO ] Epoch  2 Batch  550 Training err. 3.27174 Training err. RA 3.49185 Valid. err. 3.24633 Time elapsed: 00:00:03
2018-02-08 14:01:29,685 training [INFO ] Epoch  2 Batch  600 Training err. 3.24963 Training err. RA 3.47167 Valid. err. 3.23329 Time elapsed: 00:00:03
2018-02-08 14:01:30,051 training [INFO ] Epoch  3 Batch  650 Training err. 3.25897 Training err. RA 3.45531 Valid. err. 3.24222 Time elapsed: 00:00:03
2018-02-08 14:01:30,324 training [INFO ] Epoch  3 Batch  700 Training err. 3.21443 Training err. RA 3.43810 Valid. err. 3.23798 Time elapsed: 00:00:04
2018-02-08 14:01:30,600 training [INFO ] Epoch  3 Batch  750 Training err. 3.23009 Training err. RA 3.42423 Valid. err. 3.24300 Time elapsed: 00:00:04
2018-02-08 14:01:30,876 training [INFO ] Epoch  3 Batch  800 Training err. 3.19704 Training err. RA 3.41003 Valid. err. 3.23864 Time elapsed: 00:00:04
2018-02-08 14:01:31,164 training [INFO ] Epoch  3 Batch  850 Training err. 3.24392 Training err. RA 3.40026 Valid. err. 3.22590 Time elapsed: 00:00:04
2018-02-08 14:01:31,442 training [INFO ] Epoch  3 Batch  900 Training err. 3.21918 Training err. RA 3.39020 Valid. err. 3.21607 Time elapsed: 00:00:05
2018-02-08 14:01:31,819 training [INFO ] Epoch  4 Batch  950 Training err. 3.22075 Training err. RA 3.38128 Valid. err. 3.22056 Time elapsed: 00:00:05
2018-02-08 14:01:32,106 training [INFO ] Epoch  4 Batch 1000 Training err. 3.19058 Training err. RA 3.37175 Valid. err. 3.21954 Time elapsed: 00:00:05
2018-02-08 14:01:32,383 training [INFO ] Epoch  4 Batch 1050 Training err. 3.22515 Training err. RA 3.36477 Valid. err. 3.22403 Time elapsed: 00:00:06
2018-02-08 14:01:32,684 training [INFO ] Epoch  4 Batch 1100 Training err. 3.18162 Training err. RA 3.35644 Valid. err. 3.21444 Time elapsed: 00:00:06
2018-02-08 14:01:32,957 training [INFO ] Epoch  4 Batch 1150 Training err. 3.21696 Training err. RA 3.35038 Valid. err. 3.20682 Time elapsed: 00:00:06
2018-02-08 14:01:33,229 training [INFO ] Epoch  4 Batch 1200 Training err. 3.18562 Training err. RA 3.34351 Valid. err. 3.19167 Time elapsed: 00:00:06
2018-02-08 14:01:33,595 training [INFO ] Epoch  5 Batch 1250 Training err. 3.20504 Training err. RA 3.33797 Valid. err. 3.18971 Time elapsed: 00:00:07
2018-02-08 14:01:33,866 training [INFO ] Epoch  5 Batch 1300 Training err. 3.17188 Training err. RA 3.33159 Valid. err. 3.18051 Time elapsed: 00:00:07
2018-02-08 14:01:34,138 training [INFO ] Epoch  5 Batch 1350 Training err. 3.19685 Training err. RA 3.32660 Valid. err. 3.18551 Time elapsed: 00:00:07
2018-02-08 14:01:34,411 training [INFO ] Epoch  5 Batch 1400 Training err. 3.12587 Training err. RA 3.31943 Valid. err. 3.17389 Time elapsed: 00:00:08
2018-02-08 14:01:34,680 training [INFO ] Epoch  5 Batch 1450 Training err. 3.18007 Training err. RA 3.31462 Valid. err. 3.16053 Time elapsed: 00:00:08
2018-02-08 14:01:34,955 training [INFO ] Epoch  5 Batch 1500 Training err. 3.14168 Training err. RA 3.30886 Valid. err. 3.18556 Time elapsed: 00:00:08
2018-02-08 14:01:35,326 training [INFO ] Epoch  6 Batch 1550 Training err. 3.16449 Training err. RA 3.30420 Valid. err. 3.16131 Time elapsed: 00:00:09
2018-02-08 14:01:35,593 training [INFO ] Epoch  6 Batch 1600 Training err. 3.14153 Training err. RA 3.29912 Valid. err. 3.12897 Time elapsed: 00:00:09
2018-02-08 14:01:35,874 training [INFO ] Epoch  6 Batch 1650 Training err. 3.15175 Training err. RA 3.29465 Valid. err. 3.11355 Time elapsed: 00:00:09
2018-02-08 14:01:36,148 training [INFO ] Epoch  6 Batch 1700 Training err. 3.04500 Training err. RA 3.28731 Valid. err. 3.19367 Time elapsed: 00:00:09
2018-02-08 14:01:36,419 training [INFO ] Epoch  6 Batch 1750 Training err. 3.13327 Training err. RA 3.28291 Valid. err. 3.08858 Time elapsed: 00:00:10
2018-02-08 14:01:36,685 training [INFO ] Epoch  6 Batch 1800 Training err. 3.07752 Training err. RA 3.27720 Valid. err. 3.08398 Time elapsed: 00:00:10
2018-02-08 14:01:37,097 training [INFO ] Epoch  7 Batch 1850 Training err. 3.07960 Training err. RA 3.27186 Valid. err. 3.06153 Time elapsed: 00:00:10
2018-02-08 14:01:37,371 training [INFO ] Epoch  7 Batch 1900 Training err. 3.10005 Training err. RA 3.26734 Valid. err. 3.08232 Time elapsed: 00:00:11
2018-02-08 14:01:37,638 training [INFO ] Epoch  7 Batch 1950 Training err. 3.07702 Training err. RA 3.26246 Valid. err. 3.04708 Time elapsed: 00:00:11
2018-02-08 14:01:37,924 training [INFO ] Epoch  7 Batch 2000 Training err. 2.97345 Training err. RA 3.25523 Valid. err. 3.02540 Time elapsed: 00:00:11
2018-02-08 14:01:38,199 training [INFO ] Epoch  7 Batch 2050 Training err. 3.04993 Training err. RA 3.25023 Valid. err. 3.00636 Time elapsed: 00:00:11
2018-02-08 14:01:38,477 training [INFO ] Epoch  7 Batch 2100 Training err. 2.98401 Training err. RA 3.24389 Valid. err. 2.98333 Time elapsed: 00:00:12
2018-02-08 14:01:38,852 training [INFO ] Epoch  8 Batch 2150 Training err. 2.99700 Training err. RA 3.23815 Valid. err. 2.97953 Time elapsed: 00:00:12
2018-02-08 14:01:39,157 training [INFO ] Epoch  8 Batch 2200 Training err. 3.03055 Training err. RA 3.23343 Valid. err. 2.96544 Time elapsed: 00:00:12
2018-02-08 14:01:39,447 training [INFO ] Epoch  8 Batch 2250 Training err. 3.01131 Training err. RA 3.22849 Valid. err. 2.93447 Time elapsed: 00:00:13
2018-02-08 14:01:39,726 training [INFO ] Epoch  8 Batch 2300 Training err. 2.90731 Training err. RA 3.22151 Valid. err. 2.97667 Time elapsed: 00:00:13
2018-02-08 14:01:40,004 training [INFO ] Epoch  8 Batch 2350 Training err. 2.92393 Training err. RA 3.21518 Valid. err. 2.90969 Time elapsed: 00:00:13
2018-02-08 14:01:40,300 training [INFO ] Epoch  8 Batch 2400 Training err. 2.92303 Training err. RA 3.20909 Valid. err. 2.90715 Time elapsed: 00:00:14
2018-02-08 14:01:40,581 training [INFO ] Epoch  8 Batch 2450 Training err. 2.90866 Training err. RA 3.20296 Valid. err. 2.89796 Time elapsed: 00:00:14
2018-02-08 14:01:40,982 training [INFO ] Epoch  9 Batch 2500 Training err. 2.94641 Training err. RA 3.19783 Valid. err. 2.91617 Time elapsed: 00:00:14
2018-02-08 14:01:41,275 training [INFO ] Epoch  9 Batch 2550 Training err. 2.94055 Training err. RA 3.19279 Valid. err. 2.85010 Time elapsed: 00:00:15
2018-02-08 14:01:41,554 training [INFO ] Epoch  9 Batch 2600 Training err. 2.85469 Training err. RA 3.18628 Valid. err. 2.85204 Time elapsed: 00:00:15
2018-02-08 14:01:41,845 training [INFO ] Epoch  9 Batch 2650 Training err. 2.79852 Training err. RA 3.17897 Valid. err. 2.83228 Time elapsed: 00:00:15
2018-02-08 14:01:42,142 training [INFO ] Epoch  9 Batch 2700 Training err. 2.84669 Training err. RA 3.17281 Valid. err. 2.82751 Time elapsed: 00:00:15
2018-02-08 14:01:42,438 training [INFO ] Epoch  9 Batch 2750 Training err. 2.86604 Training err. RA 3.16724 Valid. err. 2.80178 Time elapsed: 00:00:16
2018-02-08 14:01:42,875 training [INFO ] Epoch 10 Batch 2800 Training err. 2.88933 Training err. RA 3.16227 Valid. err. 2.81059 Time elapsed: 00:00:16
2018-02-08 14:01:43,160 training [INFO ] Epoch 10 Batch 2850 Training err. 2.83507 Training err. RA 3.15653 Valid. err. 2.78651 Time elapsed: 00:00:16
2018-02-08 14:01:43,437 training [INFO ] Epoch 10 Batch 2900 Training err. 2.84318 Training err. RA 3.15113 Valid. err. 2.82126 Time elapsed: 00:00:17
2018-02-08 14:01:43,714 training [INFO ] Epoch 10 Batch 2950 Training err. 2.75439 Training err. RA 3.14441 Valid. err. 2.78984 Time elapsed: 00:00:17
2018-02-08 14:01:44,079 training [INFO ] Epoch 10 Batch 3000 Training err. 2.78920 Training err. RA 3.13849 Valid. err. 2.76388 Time elapsed: 00:00:17
2018-02-08 14:01:44,576 training [INFO ] Epoch 10 Batch 3050 Training err. 2.81157 Training err. RA 3.13313 Valid. err. 2.75202 Time elapsed: 00:00:18
2018-02-08 14:01:44,831 __main__ [INFO ] End of training
